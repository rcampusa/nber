                                NBER WORKING PAPER SERIES




                   THE POLITICAL ECONOMY OF INDIRECT CONTROL

                                       Gerard Padró i Miquel
                                           Pierre Yared

                                        Working Paper 15748
                                http://www.nber.org/papers/w15748


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     February 2010




We would like to thank Daron Acemoglu, Effi Benmelech, Carmen Beviá, Claudine Desrieux, Dennis
Gromb, Mike Golosov, Johannes Horner, Narayana Kocherlakota, Gilat Levy, Robert Powell, Nancy
Qian, Ronny Razin, Kjetil Storesletten, Aleh Tsyvinski, and seminar participants at INSEAD, Kellogg
MEDS, Minneapolis Fed, Paris School of Economics, and the Social Determinants of Conflict Conference
for comments. Gerard Padró i Miquel gratefully acknowledges financial support from ESRC under
grant RES-061-250170. All remaining mistakes are our own. The views expressed herein are those
of the authors and do not necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2010 by Gerard Padró i Miquel and Pierre Yared. All rights reserved. Short sections of text, not
to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.
The Political Economy of Indirect Control
Gerard Padró i Miquel and Pierre Yared
NBER Working Paper No. 15748
February 2010
JEL No. D02,D82,H1

                                                ABSTRACT

This paper characterizes the efficient sequential equilibrium when a government uses indirect control
to exert its authority. We develop a dynamic principal-agent model in which a principal (a government)
delegates the prevention of a disturbance—such as riots, protests, terrorism, crime, or tax evasion—to
an agent who has an advantage in accomplishing this task. Our setting is a standard dynamic principal-
agent model with two additional features. First, the principal is allowed to exert direct control by intervening
with an endogenously determined intensity of force which is costly to both players. Second, the principal
suffers from limited commitment. Using recursive methods, we derive a fully analytical characterization
of the likelihood, intensity, and duration of intervention. The first main insight from our model is that
repeated and costly interventions are a feature of the efficient equilibrium. This is because they serve
as a punishment to induce the agent into desired behavior. The second main insight is a detailed analysis
of a fundamental tradeoff between the intensity and duration of intervention which is driven by the
principal’s inability to commit. Finally, we derive sharp predictions regarding the impact of various
factors on likelihood, intensity, and duration of intervention. We discuss these results in the context
of some historical episodes.


Gerard Padró i Miquel
STICERD
London School of Economics
Houghton Street
London, WC2A 2AE
United Kingdom
and NBER
g.padro@lse.ac.uk

Pierre Yared
Columbia University
Graduate School of Business
Uris Hall, 3022 Broadway
New York, NY 10027
pyared@columbia.edu
1       Introduction
In exerting their authority, governments often use indirect control: Certain political re-
sponsibilities are left to local agents or warlords who have an advantage in ful lling them.
These tasks range from the provision of law and order, the prevention of riots and protests,
the control of terrorism and insurgency, to the collection of taxes. For example, by the
  rst century, the Romans had established a series of client states and chieftaincies along
their borders which gave them control of a vast territory with great economy of force.
These clients were kept in line by a combination of subsidies and favors and by the threat
of occasional military intervention.1 Beyond Roman times, this strategy of indirect con-
trol through local agents has been used by the British during colonial times and the Turks
during the Ottoman era, and it is tacitly used today by many governments.2 This sug-
gests the following question: What are the trade-o s faced by a government in the use of
rewards and interventions to allign the incentives of the local agent with its own?
    In answering this question, it is important to take into account that the interaction
between a government and a local agent is inherently dynamic, and that there are three
key political economy frictions to consider.
    First, the local agent cannot commit to ful lling his delegated task. Second, the local
agent's actions, which often occur through informal channels, are imperfectly observed
by the government. Third, the government cannot commit to providing rewards or using
interventions. While the rst two constraints point to a classic moral hazard problem,
in this context it is important to take into account how the third constraint interacts
with the rst two. As such, a modi ed dynamic principal-agent model (in which the
government is the principal) can provide guidance on the implications of these frictions.
    In this paper, we develop such a model. The principal delegates the prevention of a
disturbance{such as riots, protests, terrorism, crime, or tax evasion{to an agent who has
an advantage in accomplishing this task. Our setting is a standard dynamic principal-
agent model with two additional features which are natural in our application.3 First,
    1
      See Syme (1933) and Luttwak (1976).
    2
      This is particularly the case in governments that have tenuous control over parts of their territory, for
instance, in Pakistan's Federally Administered Tribal Areas and in rural areas in many African countries.
On this point, see Herbst (2000) and Reno (1998). Recent interventions such as Pakistan in its tribal
territories, Russia in Chechnya, Israel in the Palestinian Territories, or Indonesia in Banda Aceh arguably
  t the pattern. The United Kingdom also suspended local administration and deployed the army during
The Troubles in Northern Ireland from 1968 to 1998.
    3
      The literature on dynamic principal-agent relationships is vast and cannot be summarized here. Some
examples are Acemoglu, Golosov, and Tsyvinski (2008), Albuquerque and Hopenhayn (2002), Ambrus
and Egorov (2009), Atkeson and Lucas (1992), Fong and Li (2009), Golosov, Kocherlakota, and Tsyvinski
(2003), Phelan (1995), and Thomas and Worrall (1990). Also see Debs (2009), Egorov and Sonin (2009),


                                                      1
the principal is allowed to exert direct control by intervening with an endogenously de-
termined intensity of force which is costly to both players. Second, the principal su ers
from limited commitment. We focus on characterizing the likelihood, intensity, and du-
ration of intervention in the e cient sequential equilibrium. Using the recursive methods
of Abreu, Pearce, and Stacchetti (1990), we derive a fully analytical characterization.
The rst main insight from our model is that repeated and costly interventions are a
feature of this equilibrium. This is because they serve as a punishment to induce the
agent into desired behavior.4 A second insight, which emerges from our explicit charac-
terization, is the existence of a fundamental tradeo between the intensity and duration
of intervention that is driven by the principal's inability to commit. Finally, we derive
sharp predictions regarding the impact of various factors on the likelihood, intensity, and
duration of intervention.
    More speci cally, we construct a repeated game between a principal and an agent
where in every period, the principal decides whether or not to intervene. Under interven-
tion, he chooses the intensity of force, where higher intensity is costly to both the agent
and the principal (i.e., it does not help to reduce the probability of a disturbance) and
features diminishing returns (i.e., the marginal pain in icted on the agent is decreasing
in intensity). The principal cannot commit to future actions. If the principal does not
intervene, the agent can reduce the probability of disturbances by exerting unobservable
e ort which can be high or low. Both players are strictly better o under high e ort by the
agent compared to intervention by the principal. Nonetheless, there are two limitations to
the extent to which intervention can be avoided. First, the agent cannot commit to high
e ort once the threat of intervention has subsided. Second, the principal does not observe
the agent's e ort, and since disturbances might happen even under high e ort, the agent
can always unobservably deviate and pretend to have exerted high e ort. Therefore, the
Nash equilibrium of the stage game is intervention with minimal force (i.e., direct control).
We consider the e cient sequential equilibrium of this game in which reputation sustains
Guriev (2004), and Myerson (2008) for applications to delegation problems in dictatorships.
   4
     The use of costly interventions as punishment is very common in situations of indirect control. In
his discussion of the Ottoman Empire, Luttwak (2007) writes:

          "The Turks were simply too few to hunt down hidden rebels, but they did not have
      to: they went to the village chiefs and town notables instead, to demand their surrender,
      or else. A massacre once in a while remained an e ective warning for decades. So it was
      mostly by social pressure rather than brute force that the Ottomans preserved their rule: it
      was the leaders of each ethnic or religious group inclined to rebellion that did their best to
      keep things quiet, and if they failed, they were quite likely to tell the Turks where to nd
      the rebels before more harm was done." (p.40)




                                                    2
equilibrium actions, and we fully characterize in closed form the long run dynamics of the
e cient sequential equilibrium.
    Our rst result is that repeated and costly interventions are a feature of the e cient
equilibrium. Speci cally, the equilibrium after a su cient number of disturbances features
two phases of play: a cooperative phase and a punishment phase that sustain each other.
In the cooperative phase, the agent exerts high e ort because he knows that a disturbance
can trigger a transition to the punishment phase. In the punishment phase, the principal
temporarily intervenes with a unique endogenous level of intensive force. The principal
exerts costly force because failure to do so triggers the agent to choose low e ort in
all future cooperative phases, making direct control{i.e., permanent intervention with
minimal intensity{a necessity. Importantly, the strategy which maximizes the principal's
welfare under cooperation also minimizes the agent's welfare under punishment. This is
because conditional on the agent exerting high e ort, the e cient strategy must minimize
the likelihood of punishment. To keep the agent's incentive constraint satis ed, minimum
likelihood is achieved by providing the worst feasible payo to the agent in the punishment
phase.5
    This characterization of the equilibrium is related to the insights due to the model
of Green and Porter (1984) who present an example of a sequential equilibrium with
two oligopolistic rms playing symmetric strategies which alternate between cooperation
and price wars. Importantly, in contrast to this work, our result emerges in a setting
in which we consider the e cient equilibrium under general history-dependent strategies,
and using the methods of Abreu, Pearce, and Stacchetti (1990) we explictly characterize
our equilibrium and consider tradeo s and comparative statics.
    Our second result follows from our explicit characterization of the worst feasible pun-
ishment to the agent. Recall that the principal cannot commit to future actions. As a
consequence, he can always deviate to permanent direct control, which constitutes his
min-max payo . This generates an incentive compatibility constraint on the side of the
principal that produces a fundamental tradeo between the duration and the intensity
of credible interventions. In particular, he can only be induced to intervene with costly
intensity if cooperation is expected to resume in the future, and higher intensity is only
incentive compatible if cooperation resumes sooner. This link between intensity and du-
ration generates a non-monotonic relationship between intensity and the agent's welfare
under punishment. At low levels of intensity, the agent's welfare naturally declines when
   5
    This pattern of repeated military intervention is arguably alligned with many of the examples de-
scribed in footnote 2. For instance, Jaeger and Paserman (2008) nd that Israel occasionally responds to
Palestinian attacks with interventions whereas Palestinian terrorist attacks are random.


                                                  3
intensity rises. However, at higher levels of intensity, diminishing returns set in and the
counteracting e ect of shorter duration makes his expected welfare actually increasing in
intensity. Since the principal seeks to minimize the agent's welfare under punishment, it
follows that there is a unique and interior level of intensity that is used.
    Our nal result concerns the e ect of three important factors on the likelihood, inten-
sity, and duration of intervention in the e cient equilibrium. First, we consider the e ect
of a decline in the cost of intensity to the principal. Second, we consider the e ect of a
rise in the cost of disturbances to the principal. Finally, we consider the e ect of a rise in
the cost of e ort to the agent.
    We show that all three changes increase the intensity and decrease the duration of
intervention. In the rst case, it is clear that a reduction in the marginal cost of intensity
increases its use. In the second case, as the cost of disturbances rises, so do the returns
to leveraging the comparative advantage of the agent. As the prospect of direct control
becomes worse, the principal is willing to raise the intensity of intervention. In the third
case, as the cost of e ort for the agent rises, higher levels of intensity become necessary to
satisfy the agent's incentive constraint. In all three cases, due to the principal's incentive
constraint, these increases in the level of intensity necessitate a decline in the duration of
intervention.
    Even though all three changes increase the intensity and decrease the duration of in-
tervention, only the third also raises its likelihood. Speci cally, if the cost of intensity
to the principal declines or if the cost of disturbances to the principal rises, then harsher
punishments are feasible. Because the agent's incentive compatibility constraint is slack-
ened by these changes, such punishments can be applied less often without weakening
incentives for the agent. Therefore, the likelihood of intervention declines. In contrast, if
the cost of e ort to the agent rises, then incentives are harder to provide for the agent,
and the likelihood of intervention must rise following the realization of a disturbance.6
    As an aside, note that our benchmark model ignores three additional issues. First, it
ignores the possibility that permanent concessions by the principal can reduce the presence
of disturbances in the future. Second, it ignores the possibility that the agent's identity
can change over time because of political transitions. Third, it ignores the possibility that
high intensity levels by the principal today can raise the cost of e ort by the agent in the
future, for example if the agent becomes more antagonistic. These issues are discussed in
our extensions which show that our main conclusions are unchanged.
   6
    In other words, when the cost of e ort increases, the principal uses two margins to adjust punishments.
He increases both intensity and likelihood to meet the tighter incentive compatibility constraint of the
agent.


                                                    4
    This paper contributes to three di erent literatures. First, it contributes to the dy-
namic principal-agent literature described in footnote 3 by allowing for costly intervention
by a principal who su ers from limited commitment. Speci cally, our model has the same
structure as Fong and Li (2009) who also consider the e ect of limited commitment by the
principal in a labor market setting, though in contrast to their work we allow for costly
intervention. Second, our paper contributes to the literature on costly political con ict by
providing a formal framework for investigating the transitional dynamics between con ict
and cooperation.7 In particular, our model bears a similar structure to Yared (2009),
though in contrast to this work, we introduce variable intervention intensity which allows
for payo s below the repeated static Nash equilibrium. This implies that, in contrast to
this work, phases of intervention cannot last forever and must necessarily precede phases
of cooperation. Third, our paper contributes to the literature on punishments dating back
to the work of Becker (1968). In contrast to this work which considers static models, we
consider a dynamic environment in which the government lacks the commitment to pun-
ish.8 This allows for an analysis of the e cient time structure of punishments together
with the tradeo between the duration and intensity of punishments.
    The paper is organized as follows. Section 2 describes the model. Section 3 de nes
the e cient sequential equilibrium. Section 4 characterizes the equilibrium and provides
our main results. Section 5 provides extensions, and we discuss our results in the context
of some historical episodes in Section 6. Section 7 concludes. The Appendix contains all
proofs and additional material not included in the text.


2       Model
We consider a dynamic environment in which a principal seeks to induce an agent into
limiting disturbances. In every period, the principal has two options. On the one hand,
he can forcefully intervene to control disturbances himself, and in doing so he chooses the
intensity of force. On the other hand, the principal can withhold force and allow the agent
to exert unobservable e ort in controlling disturbances. In this situation, if a disturbance
    7
     Some examples of work in this literature are Acemoglu and Robinson (2006), Anderlini, Gerardi, and
Laguno (2009), Baliga and Sj•    ostr•
                                     om (2004), Chassang and Padro i Miquel (2009), Esteban and Ray
(2008), Fearon (1995), Jackson and Morelli (2008), and Powell (1999). Schwarz and Sonin (2004) show
that the ability commit to randomizing between costly con ict and cooperation can induce cooperation.
We do not assume the ability to commit to randomization, and the realization of costly con ict is driven
by future expectations.
   8
     Some examples of models of punishments are Acemoglu and Wolitsky (2009), Dal Bo and Di Tella
(2003), Dal Bo, Dal Bo and di Tella (2006), and Polinski and Shavell (1979,1984). We discuss our
relationship to the literature on punishments in greater detail in Section 4.2.


                                                   5
occurs, the principal cannot determine if it is due to the agent's negligence or due to
bad luck. In addition to this informational asymmetry, both the principal and the agent
su er from limited commitment. In our benchmark model, we rule out payments from the
principal to the agent{which are standard in the dynamic principal-agent literature{since
our focus on is on the use of interventions. This is done purely for expositional simplicity.
We allow for payments in Section 5.1 and show that none of our results are altered.
      More formally, there are time periods t = f0; :::; 1g where in every period t, the
principal (p) and the agent (a) repeat the following interaction. The principal publicly
chooses ft = f0; 1g, where ft = 1 represents a decision to intervene. If ft = 1, then
the principal publicly decides the intensity of force it         0. In this case, the payo to
the principal is         p   Ait and the payo to the agent is wa g (it ), where A > 0 and
g 0 ( ) ; g 00 ( ) > 0 with g (0) = 0, g 0 (0) = 1, and limit !1 g 0 (it ) = 0. The concavity of
g ( ) captures the fact that there are diminishing returns to the use of intensity by the
principal. The parameter A captures the marginal cost of intensive force.9 Within the
term       p      Ait is embedded the cost of a stochastic disturbance, where p represents the
probability of such a disturbance and represents its cost to the principal. Analogously,
within the term wa Ag (it ) is the cost of the damage su ered by the agent when the
principal intervenes.10
      Importantly, conditional on intervention by the principal, both the principal and the
agent are strictly better o under minimal force. Intuitively, choosing it > 0 imposes more
physical damage on the agent. Moreover, it is statically ine cient from the perspective
of the principal since it is more costly to use and does not diminish the likelihood of a
disturbance. Therefore, conditional on ft = 1, the principal would always choose it = 0
in a one-shot version of this game.
      The proper interpretation of it = 0 is not the absence of force, but rather the principal's
statically optimal level of force, meaning the level of intensity associated with the principal
seeking to directly minimize immediate disturbances. Thus, wa corresponds to the agent's
disutility under this level intensity. This normalization has no qualitative e ect on our
results and yields considerable notational ease.11
      The principal can also decide to not intervene by choosing ft = 0. In this case, the
agent privately chooses whether to exert high e ort (et = ) or low e ort (et = 0 < ) in
preventing a disturbance. Nature then stochastically chooses the realization of a publicly
   9
     For instance, A can decline if there is less international rebuke for the use of force.
  10
     In practice, the agent can be a leader, a political party, or an entire society. In situations in which
the agent is a group, the damage su ered by the agent can involve the killing of members of the group.
  11
     More generally, all of our results hold if the level of intensity is costly to the principal but also a ects
the probability p of a disturbance under intervention if p is a convex function of intensity.


                                                       6
observed disturbance st = f0; 1g, where st = 0 represents the absence of a disturbance.
If a disturbance does not occur, the principal receives 0, and if it occurs, the principal
receives     . Independently of the shock, the agent loses et from exerting e ort. The
stochastic realization of a disturbance occurs as follows. If et = , then a disturbance
occurs with probability a ( ) 2 (0; 1) and if et = 0, then it occurs with probability
                                                                                       12
  a (0) 2 ( a ( ) ; 1]. Therefore, high e ort reduces the likelihood of a disturbance.    The
                                                       13
parameter captures the cost of e ort to the agent. The game is displayed in Figure 1.

                                            Figure 1: Game




    Let uj (ft ; it ; et ; st ) represent the payo to j at t, where value of it is only relevant if
ft = 1 and the values of et and st are only relevant if ft = 0. Each player j has a period
zero welfare
                                       X1
                                            t
                                    E0        uj (ft ; it ; et ; st ) , 2 (0; 1) .
                                    t=0

   12
      Due to the variety of applications, we do not take a stance on microfounding the source of distur-
bances. One can interpret these disturbances as being generated by a short-lived player who bene ts
from their realization (such as cross border raids into the Roman Empire by Germanic tribes) and who is
less successful under intervention by the principal or high e ort by the agent. Moreover, the realization
of a disturbance could stochastically force the principal to make a permanent concession bene cial to this
player. Under this interpretation, the principal may be able to unilaterally make a concession to end all
disturbances, a situation we consider in Section 5.2.
   13
      The cost can rise for instance if it becomes more politically costly for the agent to antagonize rival
factions contributing to the disturbances. Alternatively, the agent might actually have an increased prefer-
ence for disturbances. In this case, without a ecting any of our results, one can modify the interpretation
so that et subsumes the fact that the agent receives utility from the realization of a disturbance.


                                                     7
       We make the following assumptions.

       Assumption 1 (ine ciency of intervention)                p   >   a   ( ) and   > wa .

       Assumption 2 (desirability of intervention)              a   (0) >    p.


    Assumption 1 states that, relative to payo s under intervention, both the principal and
the agent are strictly better o if the agent exerts high e ort in preventing a disturbance.
Intuitively, the agent is better informed about the sources of disturbances and is better
than the principal at preventing them. Moreover, from an ex-ante perspective, the agent
prefers to exert high e ort to prevent a disturbance versus enduring the damage from any
intervention by the principal. In sum, this assumption implies that allowing the agent to
exert e ort dominates intervention by the principal.
    Assumption 2 states that the principal is strictly better o using intervention to pre-
vent a disturbance versus letting the agent exert low e ort in preventing such a distur-
bance. This assumption has an important implication. Speci cally, in a one-shot version
of this game, ft = 1 and it = 0 is the unique static Nash equilibrium. This is because
conditional on ft = 0, the agent chooses et = 0. Thus, by Assumption 2, the principal
chooses ft = 1 and it = 0. Since the agent cannot commit to controlling disturbances,
the principal must intervene to do so himself.14 We refer to this situation with ft = 1 and
it = 0 as direct control.
    Permanent direct control is always a sequential equilibrium of the repeated game.
However, since it is ine cient (by Assumption 1), one can imagine that repeated game
strategies can enhance the welfare of both players. Nevertheless, there are three political
economy frictions to consider. First, the principal cannot commit to refraining from using
intervention in the future, since he also su ers from limited commitment. Moreover, he
cannot commit to using more than minimal force under intervention. Second, the agent
cannot commit to choosing high e ort. Finally, the principal does not observe the e ort
by the agent. Consequently, if a disturbance occurs, the principal cannot determine if
this is accidental (i.e., et = ) or if this is intentional (i.e., et = 0).
    Note that our simple benchmark model ignores four additional issues. First, as we
mentioned, it ignores the possibility that the principal can pay the agent for reducing dis-
turbances. Second, it ignores the possibility that permanent concessions by the principal
can reduce the presence of disturbances in the future. Third, it ignores the possibility
  14
    Assumption 2 facilitates exposition by guaranteeing a unique long run equilibrium. If it is violated,
the worst punishment to the principal is rede ned as equal to     a (0) = (1   ) and none of our main
results are changed. Section 5.2 provides an extension with a permanent concession which is isomorphic
to this scenario.

                                                   8
that the agent's identity can change over time because of political transitions. Fourth,
it ignores the possibility that high intensity levels by the principal today can raise the
cost of e ort by the agent in the future, for example if the agent becomes more antago-
nistic. These issues are discussed in Section 5 which shows that our main conclusions are
unchanged.


3     Equilibrium De nition
In this section, we present our recursive method for the characterization of the e cient
sequential equilibria of the game. We provide a formal de nition of these equilibria in
the Appendix. The important feature of a sequential equilibrium is that each player
dynamically chooses his best response given the strategy of his rival at every public
history.15
    Since we are concerned with e ciency, we characterize the set of equilibria which
maximize the period 0 welfare of the principal subject to providing the agent with some
minimal period 0 welfare U0 . The most important feature of these equilibria due to
the original insight achieved by Abreu (1988) is that they are sustained by the worst
punishment. More speci cally, all public deviations from equilibrium actions by a given
player lead to his worst punishment o the equilibrium path, which we denote by J for
the principal and U for the agent. Note that

                                                          p
                                        J =                   and
                                                     1
                                                     wa
                                        U
                                                 1

because the principal cannot receive a lower payo than under permanent direct control,
as he could revert to it at any point. Moreover, for the same reason, the agent can be
credibly punished by the principal at least as harshly as under permanent direct control.
    Note that in characterizing this equilibrium, we take into account that it may be
e cient for players to choose correlated strategies so as to potentially randomize over the
choice of intervention, intensity, and e ort. Let zt = fzt1 ; zt2 g 2 Z   [0; 1]2 represent a
pair of i.i.d. publicly observed random variables independent of st , of all actions, and
of each other, where these are drawn from a bivariate continuous c.d.f. G ( ). Let zt1 be
revealed prior to the choice of ft so as to allow the principal to randomize over the use of
  15
     Because the principal's strategy is public by de nition, any deviation by the agent to a non-public
strategy is irrelevant (see Fudenberg, Levine, and Maskin, 1994).



                                                     9
intervention and let zt2 be revealed immediately following the choice of ft so as to allow
the principal to randomize over intensity or the agent to randomize over the e ort.
    As is the case in many incentive problems, an e cient sequential equilibrium can be
represented in a recursive fashion, and this is a useful simpli cation for characterizing
equilibrium dynamics.16 Speci cally, at any public history, the entire public history of
the game is subsumed in the continuation value to each player, and associated with these
two continuation values is a continuation sequence of actions and continuation values.
More speci cally, let U represent the continuation value of the agent at a given history.
Associated with U is J (U ), which represents the highest continuation value achievable by
the principal in a sequential equilibrium conditional on the agent achieving a continuation
value of U . More formally, letting = fz ; iz ; ez ; UzF ; UzH ; UzL z2Z ; the recursive program
which characterizes the e cient sequential equilibrium is
                  Z "                                                                                               #
                                                  fz           p    Aiz + J UzF +
J (U ) = max                                                                      H
                                                                                                                        dGz
                        (1        fz )      a (ez )  +           (1   a (ez )) J Uz +             a   (ez ) J UzL
                                                                                                                        (1)
                                                               s.t.
                     Z "                                                                                #
                                                fz wa g (iz ) + UzF +
               U=                                                   H
                                                                                                            dGz ,       (2)
                             (1      fz )      ez + (1    a (ez )) Uz +               a   (ez ) UzL
                                         J UzF ; J UzH ; J UzL                     J 8z                                 (3)
                                                   UzF ; UzH ; UzL    U 8z                                              (4)
                                               p      Aiz + J UzF              J 8z                                     (5)
                                         UzH       UzL (   a   (0)    a   (ez ))     ez 8z                              (6)
                                    fz 2 [0; 1] , iz        0, and ez = f0; g 8z.                                       (7)

    (1) represents the continuation value to the principal written in a recursive fashion at
a given history. fz , iz , and ez represent the use of intervention, the choice of intensity, and
the choice of e ort, respectively, conditional on today's random public signal z = fz 1 ; z 2 g.
UzF represents the continuation value promised to the agent for tomorrow conditional on
intervention being used today at z. If intervention is not used, then the continuation
value promised to the agent for tomorrow conditional on z is UzH if s = 0 (there is no
disturbance) and UzL if s = 1 (there is a disturbance). Note that fz depends only on z 1
since it is chosen prior to the realization of z 2 , but all other variables depend on z 1 as
  16
       This is a consequence of the insights from the work of Abreu, Pearce, and Stacchetti (1990).



                                                                10
well as z 2 .
    Equation (2) represents the promise keeping constraint which ensures that the agent
is achieving a continuation value of U . Constraints (7) ensure that the allocation is
feasible. Constraints (3) (6) represent the incentive compatibility constraints of this
game. Without these constraints, the solution to the problem starting from an initial
U0 is simple: The principal refrains from intervention forever. Constraints (3) (6)
capture the ine ciencies introduced by the presence of limited commitment and imperfect
information which ultimately lead to the need for intervention. Constraint (3) captures
the fact that at any history, the principal cannot commit to refraining permanent direct
control which provides a continuation welfare of J. Constraint (4) captures the fact
that at any history, the agent cannot commit to high e ort, as he can choose low e ort
forever and ensure himself a continuation value of at least U . Importantly, constraint
(5) captures the fact that at any history, the principal cannot commit to using intensive
force since this is costly. Constraint (5) ensures that the principal prefers to use intensive
force and be rewarded for it in the future compared to his best deviation which involves
using intervention with zero intensive force forever. Constraints (3) (5) capture the
constraint of limited commitment. Under perfect information, they imply that if players
are su ciently patient, the permanent absence of intervention can be sustained by the
o -equilibrium threat of intervention. Constraint (6) captures the additional constraint
of imperfect information: If the principal requests ez = , the agent can always privately
choose ez = 0 without detection. Constraint (6) ensures that the agent's punishment
from this deviation is weakly exceeded by the equilibrium path reward for choosing high
e ort.17


4      Analysis
We focus our analysis on the likelihood, the intensity, and the duration of intervention
which are formally de ned below.

De nition 1 (i) The likelihood of intervention at t is Pr fft+1 = 1jft = 0 and st = 1g,
(ii) the intensity of intervention at t is E fit jft = 1g, and (iii) the duration of intervention
at t is Pr fft+1 = 1jft = 1g.

   This de nition states that the likelihood of intervention is the probability that the
principal intervenes following a disturbance; the intensity of intervention is the expected
  17
    Note that we have ignored the constraint that the agent does not deviate to high e ort if ez = 0 since
such a constraint never binds in equilibrium.

                                                   11
intensity of the force used by the principal; and the duration of intervention is the prob-
ability that intervention continues into the next period.
    We also focus on long run equilibrium dynamics. We do so because these dynamics
can be explicitly characterized in closed form, and because we can show that phases of
intervention occur only in the long run.18 More speci cally, we rst show in Section
4.1 that the e cient contract in the long run is characterized by two phases of play: a
cooperative phase and a punishment phase, where these two phases sustain each other.
Second, we describe in Section 4.2 an important tradeo between the duration and the
intensity of intervention. Finally, in Section 4.3 we consider comparative statics.
    To facilitate exposition, we assume that players are su ciently patient for the remain-
der of our discussion.

       Assumption 3 (High Patience)               > b.

       The exact value of b is described in the Appendix.19


4.1       Characterization
Let
                  (U ) = fz (U ) ; iz (U ) ; ez (U ) ; UzF (U ) ; UzH (U ) ; UzL (U )   z2Z

represent an argument which solves (1) (7). Since (U ) may not be unique, we focus
on the unique solution which satis es the Bang-Bang property as described by Abreu,
Pearce, and Stacchetti (1990).20 In our context, the Bang-Bang property is satis ed if
the equilibrium continuation value pairs at t following the realization of zt1 are extreme
points in the set of sequential equilibrium continuation values. De ne

                                                      a(0)
                                  U=                                        .                           (8)
                                           (1     ) ( a (0)      a   ( ))
  18
      See Yared (2009) for a similar model which more explicitly describes short run transitional dynamics.
  19
      This assumption guarantees that the likelihood of punishment is bounded away from 1 and that the
duration of punishment is bounded away from 0, which guarantees that the long run equilibrium can be
explicitly characterized. The value of b is below 1 as long as is su ciently bounded away from wa
so that permanent reversion to the static Nash equilibrium is a su cient enough threat to induce high
e ort.
   20
      E cient equilibria which do not satisfy the Bang-Bang property emerge here in part because infor-
mation is coarse, an issue which is discussed in Yared (2009). The Bang-Bang equilibrium we describe
is the unique optimum if players are constrained to one-period memory and if a rich and asymptoti-
cally uninformative public signal of the agent's e ort is available to the principal. Details available upon
request.




                                                    12
Let limt!1 Pr Ut U represent the long run probability that the agent receives a con-
tinuation value (following the realization of zt1 ) which is weakly below U in the solution
to the program.

Proposition 1 (characterization)

  1. limt!1 Pr Ut      U = 1 8U0 , and

  2. If U    U , then Efz (U ) = U     U = U               U and 8z

                              iz (U ) = i ,
                             ez (U ) =        ,
                           UzF (U ) = (U               wa + g (i )) = ,
                           UzH (U ) = U , and
                           UzL (U ) = U                =( (   a   (0)     a   ( )))

     for i and U which satisfy

                             g 0 (i ) (   p          ( )) + Ai
                                                       a
                         1 =                                     , and                 (9)
                                 A                  wa + g (i )
                                ( p           a ( ))    + Ai (wa g (i ))
                         U =                                             .
                                   (1           ) (( p    a ( ))  + Ai )

    This proposition states that in the long run, continuation values are weakly below
U and it explicitly characterizes the solution for U      U . More speci cally, in the long
run, the principal exerts a unique level of intensity i , the agent exerts high e ort, and
continuation values for tomorrow are conditioned on whether or not intervention is used
and whether or not a disturbance occurs in the absence of intervention. The continuation
value U is therefore provided to the agent by randomizing over a cooperative phase and
a punishment phase. In the cooperative phase, intervention is not used and the agent
and principal receive U and J U , respectively, following the realization of zt1 . In the
punishment phase, intervention is used and the agent and principal receive U and J (U ) =
J, respectively, following the realization of zt1 .
    More speci cally, in the cooperative phase at t, the principal does not intervene (ft =
0) and the agent chooses high e ort (et = ). If there is no disturbance at t (st = 0),
then the cooperative phase at t + 1 occurs with probability 1. If there is a disturbance
at t (st = 1), then the cooperative phase at t + 1 occurs with probability 1 l , and
the punishment phase at t + 1 occurs with probability l . In contrast, in the punishment

                                                  13
phase at t, principal chooses intervention (ft = 1) and a unique level of intensity it = i .
The punishment phase at t + 1 occurs with probability d and the cooperative phase
at t + 1 occurs with probability 1 d . Note that given De nition 1, it is clear from
this characterization that the e cient likelihood, intensity, and duration of intervention
correspond to l , i , and d , respectively, and these can be characterized explicitly in our
framework.21
    The intuition behind the second part of Proposition 1 is that in equilibrium, phases of
cooperation and phases of punishment sustain each other. In the cooperative phase, the
agent exerts high e ort because he knows that failure to do so raises the probability of a
disturbance which can trigger a transition to the punishment phase. In the punishment
phase, the principal temporarily intervenes with a unique level of intensive force. The
principal exerts costly force since he knows that failure to do so would trigger the agent
to choose low e ort in all future cooperative phases, making direct control{i.e., permanent
intervention with minimal intensity{a necessity.22
    These long run cycles between punishment and cooperation are driven by the princi-
pal's inability to commit. Recall that he can always take the option of permanent direct
control which ensures him a ow payo            p  per period. If he applies higher intensity
i > 0 when he intervenes, he is receiving a ow payo below direct control. He would
only do so if in the future he expects phases in which he receives ow payo s above       p .

These are the cooperative phases in which the agent exerts high e ort and the principal
receives     a( ) .

    As a consequence, the values of U and J U are intimately linked. To formally see
why, consider the system of equations which characterizes the long run equilibrium:

                    U =         +         (1     a   ( )l )U +     a   ( )l U                 (10)
                    U = wa          g (i ) +         d U + (1      d )U                       (11)
                J U     =       a   ( )    +     (1        a   ( )l )J U +      a   ( )l J    (12)
                    J =         p         Ai +        (1       d )J U + d J .                 (13)

(10) and (11) represent the continuation value to the agent during cooperation and pun-
ishment, respectively. (10) shows that in the cooperative phase, the agent exerts high
e ort today and faces two possibilities tomorrow. If a disturbance occurs and he is not
  21
    More speci cally, UzF (U ) = (1 d ) U + d U and UzL U = (1 l ) U + l U .
  22
    More precisely, permanent direct control is one of many means of implementing the worst punish-
ment for the principal. There are many other continuation games which provide the principal with a
continuation value of J which can serve as punishment.



                                                      14
forgiven, play moves to punishment and he obtains U . Otherwise, cooperation is main-
tained and he receives U tomorrow. (11) shows that in the punishment phase, the agent
endures punishment with intensity i today, and he receives U tomorrow with probability
d and U tomorrow with probability 1 d . (12) and (13) are analogously de ned for
the principal. In particular, (12) shows that during cooperation the principal su ers from
disturbances with probability a ( ), and (13) shows that during punishment the principal
su ers from disturbances with a higher probability p and he also su ers from intervening
with force.23
    Crucially, the value of U does not depend on the value of i since U is self-generating
in equilibrium.24 Moreover, as discussed in Section 3, J is independent of i because it
simply corresponds to the repeated static Nash payo to the principal{i.e., direct control.
Therefore, (10) (13) is a system of four equations and ve unknowns{U , J U , l , i ,
and d {where the value of i is selected to maximize J U .
    This system of equations allows us to trace exactly how the cooperative and punish-
ment phases sustain each other. Since U is exogenously determined, equation (10) implies
that the lower is U , then the lower is the implied value of l . Intuitively, the harsher the
punishment, the less often it needs to be used. Because J is also exogenous, (12) shows
that J U is decreasing in l . Since payo s under intervention are xed for the principal,
he is better o if he needs to intervene less often. As a consequence, the highest possible
J U is attained by the lowest U , as this makes for the longest sustainable cooperative
phase{i.e., the lowest sustainable likelihood of punishment l .
    Similarly, equations (11) and (13) imply that, conditional on i , the higher is J U ,
then the higher is the implied value of d , and the lower is the implied value of U . This
is because the higher the principal's welfare under cooperation, the more easily can the
principal be induced to punish for longer, as his value under punishment is anchored at
J. Longer punishments lower U which again increases J U . Consequently, the e cient
i that maximizes the principal's value of cooperation simultaneously also minimizes the
agent's value of punishment U . In the next subsection we analyze this e cient choice of
i.
    Before this analysis, we need to shed some light on the rst part of Proposition 1.
In order to build some intuition, note that U is important for two reasons. First, it
can be shown that if U         U , fz (U ) = 0 8z so that intervention is used with zero
probability. The reason is that punishing is too costly and ine cient for both the principal
  23
     Note that equations (10) and (13) naturally emerge from equations (6) and (5), the incentive com-
patibility constraints on the agent and principal, respectively.
  24
     That is, U is derived by combining (2) with (6) (which binds) given that ez U = and UzH U = U .


                                                 15
and the agent, and hence it is never used if not absolutely necessary{i.e., unless the
promised value U is very low. It follows that continuation values have to eventually
travel below U . If there was zero probability of continuation values traveling below U ,
then there would be zero probability of intervention along the equilibrium path, and the
agent would therefore choose low e ort forever. This would obviously violate the incentive
compatibility constraint of the principal by Assumption 2.25 Therefore, intervention must
occur along the equilibrium path to induce high e ort which means that continuation
values must eventually decline below U .
    The second reason U is important is because once continuation values have declined
below U , in the future they cannot increase above U . This is again a consequence of the
ine ciency of punishing. The e cient equilibrium therefore delays forceful intervention as
much as possible. Due to the incentive compatibility constraint of the agent, such delay is
longer the lower is the value of the agent under punishment. Such value is kept at its lowest
by remaining in the cycle of punishment and cooperation (with high e ort by the agent)
forever, conditional on having arrived to a period of intervention. If instead continuation
values in the future were to move back above U after intervention, the principal would
be forced to intervene more often or more intensely from today onward in order to satisfy
the promise keeping constraint (2), which is ine cient.26
    To understand equilibrium path dynamics, consider Figure 2 which depicts J (U ) as a
function of U . The y-axis represents J (U ) and the x-axis represents U , with U situated
on the x-axis. Note that an e cient equilibrium necessarily begins on the downward
sloping portion of J (U ) since it is not possible to make the principal better o along this
portion without making the agent worse o . Along the upward sloping portion of J ( ),
both the principal and agent can be made better o from an increase in U since this is
associated with a lower probability of intervention which is costly to both players. Along
the downward sloping portion of J ( ), the principal is made worse o from an increase
in U since this is associated with a higher probability realization of low e ort by the
agent which is costly to the principal but bene cial to the agent. Along the equilibrium
  25
      In a model which allows for payments from the principal to the agent, the second part of Proposition 1
holds exactly, though the rst part may not necessarily do so since a long enough absence of disturbances
can lead to the permanent absence of intervention. See Section 5.1 for a discussion.
   26
      Technically, if UzH (U ) > U , then (6) would not bind which is ine cient by the concavity of J ( ).
The reason why UzF (U ) U is a consequence of Assumption 3 which states that the discount factor is
su ciently large. Intuitively, as rises, the constraint of limited commitment on the side of the principal
is slackened, which implies that the equilibrium approaches the commitment benchmark in which the
principal punishes forever (i.e., UzF (U ) approaches U ).
   Note that this rst part of Proposition 1 holds for all solutions, not just those which satisfy the Bang-
Bang property.



                                                    16
path, whenever the principal requests high e ort from the agent, he rewards (punishes)
the agent for the absence (realization) of a disturbance with an increase (decrease) in
continuation value. Therefore, the sequence of disturbances will eventually cause the
continuation value to the agent to decline below U , and it will remain there in the long
run.27



                                            Figure 2: J (U )




4.2       Tradeo        between Intensity and Duration of Intervention
In this section, we consider the choice of intensity in the e cient equilibrium together with
its implications for the likelihood and duration of intervention. In doing so, we highlight
a fundamental tradeo between the intensity and duration of intervention.
    To this end, it is useful to consider the wider implications of the system given by
(10) (13). In particular, consider an exogenous level of intensity i{i.e., not necessarily
the optimal level i . For a given i, this system of equations is linear in four unknowns and
 27
      For more details, see the Appendix.



                                                  17
it is therefore solvable. Take the solutions for l and d given i, and call them l (i) and
d (i) as they are now a function of the exogenous level of i that we are considering. In
other words, l (i) corresponds to the likelihood of intervention under intensity i and d (i)
corresponds to the duration of intervention under intensity i.

Proposition 2 (e cient intervention) The optimal levels of l , i , and d satisfy
l = l (i ) and d = d (i ) for i de ned in (9) where l ( ) and d ( ) are continuously
di erentiable functions with l0 (i) < (>) 0 if i < (>) i and d0 (i) < 0.

    Proposition 2 states that, in the set of equilibria with the same structure as the e cient
equilibrium, an increase in intensity reduces the likelihood of intervention for i < i and
it increases the likelihood of intervention for i > i . Moreover, an increase in intensity
always reduces the duration of intervention. This proposition implies that there is a
tradeo between the intensity and duration of intervention, and that the optimal level of
intensity i corresponds to the point which minimizes the likelihood of intervention. This
proposition is displayed graphically in Figure 3, where intensity i is on the x-axis and
the implied likelihood and duration of intervention{l (i) and d (i), respectively{are on the
y-axis.
    The principal's incentives to intervene are the driving force behind Proposition 2.
Again, recall that the principal can always deviate to permanent direct control, which
gives him a xed exogenous payo . As a consequence, if the intensity of intervention rises,
then the principal can only be induced to exert this level of intensity if the resumption
of cooperation following intervention is more likely. This is the logic behind (13) and it
implies that d0 (i) < 0, so that the duration of intervention is declining in intensity.
    Now consider what this implies for the welfare of the agent under punishment, U . At
low levels of i, an increase in intensity naturally means that the prospect of punishment
is worse for the agent, and U decreases in i. However, at higher levels of i, diminishing
returns set in and the smaller marginal increase in pain g 0 (i) is outweighed by the reduction
in punishment duration implied by (13). As a consequence, above a certain i, U becomes




                                              18
increasing in i.

              Figure 3: Likelihood, Intensity, and Duration of Intervention




    Since the agent's value under punishment rst decreases and then increases with in-
tensity, the likelihood of intervention l (i) rst decreases and then increases with intensity,
as implied by (10). As the punishment for the agent becomes worse, a smaller likelihood
of punishment is needed to satisfy (10). As previously discussed, lower likelihood is better
from the perspective of the principal because it maximizes the duration of cooperation
(i.e., the probability of transitioning to the cooperative phase tomorrow starting from the
cooperative phase today is maximized). Therefore, the principal always chooses the level
of intensity that minimizes likelihood. As stated in Proposition 2, this level is i .
    As an aside, note that our selection of an interior point i relies on our assumption
that g 0 (0) is su ciently high. If g 0 (0) were small, then one could construct environments
in which i = 0 so that indirect control is not sustainable and the principal resorts to
permanent direct control, as in Yared (2009). Intuitively, the punishment to the agent is
not su ciently dire to warrant its use by the principal. Moreover, note that the uniqueness
of i de ned in (9) is guaranteed by the global concavity of g ( ). If instead g ( ) were weakly


                                              19
convex, there would be no tradeo between the duration and intensity of intervention, and
the optimal level of intensity would be either 0 or the maximal feasible level of intensity.
    These results are related to static models of punishment which study a variety of
situations, such as extortion and slavery.28 They are also related to the law and eco-
nomics literature which considers the tradeo between the likelihood of punishment (i.e.,
the probability of capturing criminals) and the harshness of punishment (i.e., the length
of incarceration).29 As in our environment, this literature establishes that choosing the
harshest existing punishment is suboptimal because costly punishments must be exercised
in equilibrium. Second, the law and economics literature highlights a complementarity
between the likelihood and the harshness of punishment which is also present in our frame-
work. More speci cally, in our model an increase l and a reduction in U are complemen-
tary tools for the reduction of the punishment continuation value U L U . Nonetheless,
in contrast to our dynamic model, static models by de nition cannot distinguish between
the intensity and the duration of punishment, and hence they cannot provide any answers
to the motivating questions of our analysis. In this regard, the tradeo in our model
between the intensity and duration of punishment and its relationship to the absence of
commitment on the side of the principal is novel to the literature on punishment.30


4.3       Comparative Statics
In this section, we consider the e ect of three factors on the e cient likelihood, intensity,
and duration of intervention. First, we consider the e ect of a decline in the cost of
intensity to the principal (A). Second, we consider the e ect of a rise in the cost of distur-
bances to the principal ( ).31 Finally, we consider the e ect of a rise in the cost of e ort
to the agent ( ), where this can occur for instance if it becomes more politically costly
for the agent to antagonize rival factions contributing to disturbances or alternatively if
he acquires a higher preference for the realization of disturbances. We make the following
assumption to facilitate our discussion.

       Assumption 4 g (i) = i for 0 <          < 1.

       As we discuss further below, the only purpose of this assumption is to make the e ect
  28
     See Dal Bo and Di Tella (2003) and Dal Bo, Dal Bo and di Tella (2006) for an application to political
capture and Chwe (1990) and Acemoglu and Wolitzky (2009) for labor contracts with limited liability.
  29
     See, for instance, the seminal articles by Becker (1968) and Polinsky and Shavell (1979,1984).
  30
     Because applying punishments is costly to the principal, static models need to assume that the
principal can commit to some punishment intensity as a function of observable outcomes.
  31
     One can also interpret this parameter as re ecting the preferences of the principal, so an increase in
  re ects a transition to a principal who is less tolerant of disturbances.

                                                    20
on duration of a change in A or          unambiguous. The comparative statics are summarized
in the below proposition.32

Proposition 3 (comparative statics)

   1. If A decreases (increases), then l decreases (increases), i increases (decreases),
      and d decreases (increases),

   2. If   increases (decreases), then l decreases (increases), i increases (decreases),
      and d decreases (increases), and

   3. If increases (decreases), then l increases (decreases), i increases (decreases), and
      d decreases (increases):

    This proposition states that all three changes increase the e cient intensity and de-
crease the e cient duration of intervention. However, only the third change also raises
its likelihood whereas the rst two changes decrease its likelihood.
    To see why intensity must rise, consider the rst case. If the cost of intensity declines,
then the principal's return to intensity rises since it is cheaper to provide incentives to
the agent via intensive force.33 In the second case, if the cost of disturbances rise, the
principal should raise the intensity of intervention since the return to delegating to the
agent rises relatively to direct control. As direct control worsens, higher intensity becomes
incentive compatible. In the third case, if the cost of e ort for the agent rises, then it is
harder for the principal to provide incentives to the agent with lower levels of intensity,
and higher levels of intensity become e cient.34 In all three cases, because the principal
  32
     Performing comparative statics with respect to the probability of a disturbance is not straightforward
given that this would a ect the values of p , a ( ), and a (0) jointly. However, one can show that a
uniform proportional increase in these probabilities has the same e ect as an increase in . Details
available upon request.
  33
     This is arguably the case in some of our motivating examples, since international rebuke against
the use of violence in restive regions changes over time and often causes governments to change their
intervention strategy.
  34
     This comparative static is particularly tting for understanding the case of the Roman Empire,
which utilized more brutal force in the western region of the Empire{where chieftain control was tenuous
and therefore needed higher e ort{ relative to the eastern regions{where client rulers had more control.
Speci cally, Luttwak (1975) writes:

           "[T]he client rulers of the east normally enjoyed secure political control over their sub-
       jects...By contrast, in the less structured polities of Europe, the prudence of the well-
       informed would not necessarily restrain all those capable of acting against Roman interest...
       [O]ne can therefore say that while Roman military power was freely converted into political
       power vis-a-vis the sophisticated polities of the East, when employed against the primitive
       peoples of Europe its main use was the direct application of force." (p.32-33)



                                                    21
needs more inducement to use more intensive punishments, these increases in the level of
intensity necessitate a decline in the duration of intervention.
    Though all three changes increase the intensity and decrease the duration of interven-
tion, only the third also raises its likelihood. Speci cally, if the cost of intensity to the
principal declines or if the cost of disturbances to the principal rises, then higher intensity
slackens the agent's incentive constraint. As a consequence, the principal can a ord to
forgive him more often without weakening incentives, and the likelihood of intervention
declines. In contrast, if the cost of e ort to the agent rises, then incentives are harder to
provide for the agent, so that likelihood of intervention must rise following the realization
of a disturbance.
    Note that the comparative statics with respect to the likelihood and the duration
of intervention rely on the fact that the principal responds optimally to changes in the
environment by increasing the level of intensity. To see why, consider the e ect of each of
these factors absent any change in the level of intensity, where the ensuing hypothetical
suboptimal equilibrium can be constructed as in Section 4.2. Consider the e ect of a
decrease in the cost of intensity to the principal or an increase in the cost of disturbances
to the principal absent any change in i. In this circumstance, the implied likelihood
of intervention declines and implied duration of intervention rises. This is because it
becomes easier to provide incentives to the principal to use force (i.e., either the cost
of force is lower or the marginal bene t of resuming cooperation rises). Since incentives
to the principal are easier to provide but i is xed, the duration of intervention can
rise. Therefore punishment becomes more severe for the agent, and the likelihood of
intervention declines.35 In contrast, when i is allowed to adjust, Proposition 3 shows
that the increase in intensity is so large that it requires a reduction in the duration of
intervention. This nal comparative static relies on Assumption 4, and one can construct
environments in which a decline in A or a rise in           would barely change i , thereby
                                                          36
generating an increase in the duration of intervention.
    Analogously, one can consider the e ect of a rise in the cost of e ort to the agent, ab-
sent any change in i. In this circumstance, the implied likelihood of intervention rises and
the implied duration of punishment declines. This is because it becomes more di cult to
provide incentives to the agent to exert high e ort, so that the likelihood of intervention
rises, reducing the value of cooperation for the principal. Because the principal puts lower
value on cooperation, the duration of intervention must decline so as to provide the prin-
 35
   Formally, this is equivalent to stating that d (i) is decreasing in A and increasing in .
 36
   This would be true for instance if g ( ) features high curvature around i , for instance if
 i g 00 (i ) =g 0 (i ) > 1:


                                              22
cipal with enough inducement to exert the same level of intensity. In this circumstance,
the optimal level of intensity rises and therefore mitigates the rise in the likelihood of
intervention, and this reinforces the decline in the duration of intervention.37


5      Extensions
Our benchmark model ignores four additional issues. First, it ignores the possibility that
the principal can pay the agent for reducing disturbances. Second, it ignores the possibility
that permanent concessions by the principal can reduce the presence of disturbances in
the future. Third, it ignores the possibility that the agent's identity can change over
time because of political transitions. Fourth, it ignores the possibility that high intensity
levels by the principal today can raise the cost of e ort by the agent in the future, for
example if the agent becomes more antagonistic. These issues are discussed in the below
four extensions which show that our main conclusions are unchanged.38


5.1     Temporary Payments
Our benchmark model ignores the presence of payments from the principal to the agent
which are standard in principal-agent relationships. Consider an extension of our model
where if the principal does intervene at t (ft = 0), he chooses a payment ct 0 which he
makes to the agent prior to the choice of e ort by the agent. Thus, conditional on ft = 0,
the payo to the principal at t is ct st and the payo to the agent is ct et . Under
this extension, our model is isomorphic to Fong and Li (2009) with the exception that
their model is a special case of ours with it constrained to 0 at every date.
    Under this extension, the prospect of future payment can serve as a reward for the
successful avoidance of disturbances and the use of intervention continues to serve as a
punishment for disturbances. Moreover, payment is never used during intervention since
the principal would like to make the agent su er as much as possible. As such, the second
part of Proposition 1, Proposition 2, and Proposition 3 are preserved.
    More speci cally, if a su cient number of disturbances occur, then continuation val-
ues must decline below U de ned in (8) and punishment necessarily occurs. Intuitively,
because of limited liability, it is ine cient to provide incentives using payments alone,
and it is e cient to use punishments in the form of intervention. Moreover, by analogous
  37
     The rise in the likelihood of intervention occurs independently of Assumption 4 since the principal
must be strictly worse o if rises.
  38
     Due to space restrictions, we describe these results informally, but more details are available upon
request.


                                                   23
reasoning as in Proposition 1, continuation values cannot rise above U once they have
declined below it. Therefore, continuation values must be trapped below U if intervention
is ever used along the equilibrium path, and no payment will ever be made going forward
in this situation.
    The main di erence between the benchmark model and the extended model is that
under some conditions, the extended model admits another long run equilibrium in which
intervention is not used.39 In this alternate long run equilibrium which is described in
Fong and Li (2009), the principal does not use intervention, and he only uses payment in
the provision of incentives. More speci cally, the long run equilibrium features a payment
phase in which the principal pays the agent and a no-payment phase in which the principal
does not pay the agent. In both phases, the principal requests high e ort from the agent.
The absence of a disturbance leads to a probabilistic exit from the no-payment phase and
the presence of a disturbance leads to a probabilistic exit from the payment phase.
    Thus, the equilibrium of the extended model can feature history-dependence in the
long run contract. On the one hand, su cient absences of disturbances can lead to an
equilibrium which features no intervention and repeated payment.40 On the other hand, a
su cient realization of disturbances can lead to an equilibrium which features no payment
and repeated intervention as in our benchmark model.


5.2     Permanent Concessions
Consider an extension of our benchmark model where if the principal does not intervene
at t (ft = 0), he can choose a permanent concession which we refer to as Ct = f0; 1g. If
Ct = 0, then no concession is made and the rest of the period proceeds as in our benchmark
model. In contrast, if Ct = 1, a permanent concession is made which ends the game and
provides a continuation value J C to the principal and U C to the agent starting from t. Such
a concession can come in the form of independence, land, or political representation, for
instance, and we assume that it satis es the agent and ends all disturbances. Speci cally,
suppose that U C > 0, so that it provides the agent with more utility than low e ort
forever.
    Clearly, if J C < J, then the principal cannot possibly be induced to make a concession
since he prefers permanent direct control. Therefore, the equilibrium would be exactly as
the one we have characterized. Conversely, if J C >       a ( ) = (1     ), then the e cient
  39
     This requires a condition which guarantees the existence of a trigger-strategy equilibrium in which
payment induces high e ort. Absent this condition, the unique long run equilibrium involves repeated
intervention.
  40
     This is also the case if the initial condition U0 is chosen to be su ciently high.


                                                  24
equilibrium involves no intervention since the concession provides a better payo to the
principal than the best payo under indirect control. In this case, the principal simply
makes the concession in period 0 and the game ends. We therefore consider the more
interesting case in which J C 2 (J;     a ( ) = (1     )).
    In this situation, the provision of this concession serves as a reward for the successful
avoidance of disturbances and the use of intervention continues to serve as a punishment
for disturbances.41 Clearly, if a su cient number of disturbances are avoided, then in-
tervention never takes place and the long run equilibrium features the concession by the
principal together with the end of all con ict so as to reward the agent for good behavior.
In contrast, if a su cient number of disturbances occur, then continuation values de-
cline below U de ned in (8) and punishment necessarily occurs. Moreover, by analogous
reasoning as in Proposition 1, continuation values cannot rise above U once they have
declined below it. Therefore, continuation values must be trapped below U if intervention
is ever used along the equilibrium path, and no concession will ever be made going forward
in this situation.
    The equilibrium of the extended model thus admits two potential long run outcomes,
one with a permanent concession and the other which is analogous in structure to the
one which we consider. Thus, as in our benchmark environment, the second equilibrium
features phases of cooperation and punishment which sustain each other, it features a
tradeo between the intensity and duration of intervention, and it features the same
comparative statics. Nevertheless, the equilibrium is not quantitatively identical to the
one in the benchmark model precisely because the min-max for the principal is now J C
as opposed to J. In other words, the principal cannot experience a continuation value
below that which he can guarantee himself by making a concession to the agent. This
implies that the agent's welfare under punishment U must be higher in the extended
model. Thus, the likelihood of punishment is higher and its duration shorter because it
is harder to provide incentives to the principal and to the agent.42
    As an aside, note that if the principal lacks commitment to concessions and if a
concession costs the principal J C (1     ) in every period, then nothing changes as long as
J > J, since concessions can be enforced. If instead J C < J, then temporary concessions
  C

may be featured along the equilibrium path, but the long run characterization of the
equilibrium is exactly as in our benchmark model.
  41
     This is because rewarding the agent by allowing low e ort is ine cient for the principal as well as
the agent.
  42
     We have implicitly assumed that an analogous condition to Assumption 3 holds so that the implied
duration of punishment is bounded away from zero.



                                                  25
5.3     Political Transitions
Our model additionally ignores the role of political transitions since it assumes that the
two players interact with each other forever. This issue is particularly relevant for the
case of the agent since the dynamics of the equilibrium are generated by the need for
the principal to punish the agent for the realization of past disturbances. Clearly, there
is no need for the principal to punish an agent who cannot possibly be blamed for past
disturbances.
    To explore this issue further, imagine if in every period there is a probability 1 q that
the incumbent agent is exogenously replaced by another identical agent, where replace-
ment yields an exogenous continuation value to the incumbent. Moreover, to simplify
discussion, consider the e cient sequential equilibrium which maximizes the principal's
period 0 welfare, where the e cient equilibrium now clearly speci es the identity of the
agent whom the principal faces.
    It is easy to show that in such a setting, the second part of Proposition 1 will hold for
the long run interaction between the principal and a given agent, where in Proposition
1 and in (8) is replaced by q which corresponds to the relevant discount factor for the
agent.43 In other words, our characterization of the cooperative and punishment phases
holds for the interaction between the principal and an agent after several disturbances have
occurred during the agent's tenure. This equilibrium features phases of cooperation and
punishment which sustain each other. Moreover, one can show that for q su ciently close
to 1, it features the same tradeo between the intensity and duration of intervention, and
it features same exact comparative statics. Nonetheless, the model is not quantitatively
equivalent to our benchmark environment since the principal's and the agent's discount
factors di er from one another. Moreover, one can show that as q declines, it becomes
more di cult for the principal to provide incentives to the agent so that the likelihood of
intervention rises and the duration of intervention declines.
    An important new feature of the extended model which is not present in the benchmark
model in that a political transition causes the continuation value to the agent to rise
above U . This is because it is ine cient for the principal to punish an agent who is
not responsible for the exertion of e ort in the past by providing him with low welfare.
Note further that it is straightforward to combine this extension with that of Section 5.2
which allows the principal to make a permanent concession. In such a setting, the long
run will always feature a permanent concession by the principal. This is because even
  43
    This statement refers to the continuation value to the agent adjusted by the continuation value
associated with replacement.



                                                26
if one agent is punished and may never receive the concession himself, there is always a
positive probability going forward that the agent which replaces him will be successful at
preventing disturbances and will therefore be rewarded with a permanent concession.
    An additional issue to consider is the possibility that the principal can endogenously
replace the agent with another identical agent via assassination or demotion. More specif-
ically, imagine if at the beginning of every period, the principal can replace the agent,
where replacement provides the agent with a continuation value U R , where for simplicity
we assume that U R is strictly below U in the equilibrium which does not allow for replace-
ment. Replacement entails an exogenous cost          0 borne by the principal, capturing the
cost of removal of the incumbent or training of a replacement agent.44 Our benchmark
model is embedded in this extended model for = 1, so that replacement is in nitely
costly to the principal, and it is never chosen along the equilibrium path since it is strictly
dominated by direct control. Moreover, it is clear that if = 0, then intervention is never
used as a form of punishment since it is strictly dominated by costless replacement.45 In
this situation, our extended model is analogous to the classical Ferejohn (1986) model of
electoral control, with the exception that we consider history-dependent strategies. More
generally, one can show that there is a cuto for the cost of replacement        below which
replacement serves as the unique form of punishment and above which intervention is the
unique form of punishment.46 Thus, our model coincides exactly to the case for which
the cost c exceeds the cuto .


5.4     Endogenous E ort Cost
Our model additionally ignores the fact that the use of intensity by the principal can
potentially make it more di cult for the agent to exert e ort in preventing disturbances.
This would occur if the agent loses political credibility with the population he is supposed
to control. To explore this issue further, imagine if the cost of high e ort depends on
time so that it is denoted by t and it can either be low ( t = L ) or high ( t = H ):
  44
      In this environment, we can ignore without any loss of generality the principal's incentives to replace
an incumbent since this does not provide any additional welfare to the principal given that future agents
are identical to the incumbent. Speci cally, any out of equilibrium removal of an incumbent can prompt
all future agents to punish the principal by exerting zero e ort forever.
   45
      Technically, the upward sloping portion of J ( ) is replaced by a at region along which probabilistic
replacement takes place.
   46
      The argument behind the presence of a unique form of punishment is analogous to that behind
Lemma 3 in the Appendix.




                                                     27
                  L
Suppose   0   =       and imagine the following process for       t:

                                  (
                                      H
                                          if fk = 1 and ik > ei for any k < t
                          t   =       L
                                                                              .
                                          otherwise

This means that if the principal ever exceeds a certain level of intensity, then the cost of
high e ort for the agent permanently rises. Moreover, suppose ei is below the optimal level
of intensity in an environment in which t = L for all t. This means that if the principal
uses the same level of intensity as in our benchmark environment, the cost of e ort for
the agent permanently rises.
    Imagine if the level of H is su ciently low that one can construct an equilibrium
with the same structure as in our benchmark setting in which the agent can be induced
to exert this level of e ort. We can show that in this case the principal always lets the
cost of e ort rise in the extended model. The intuition for this is that the rise in the cost
of e ort to the agent serves as an additional form of long run punishment for the agent
and therefore provides even better incentives to the agent to exert high e ort along the
equilibrium path.
    More speci cally, in the e cient equilibrium of the extended model, the principal
chooses the likelihood, intensity, and duration of intervention associated with the level
of e ort equal to H in our benchmark model. Given Proposition 3, this means that
the likelihood of intervention is higher, the intensity of intervention is higher, and the
duration of intervention is lower compared to the original equilibrium in which the cost of
e ort does not rise and remains at L . Therefore, the level of intensity rises to reinforce
the rise in the cost of e ort to the agent.
    To understand this, note that the rst instance of a punishment phase provides the
principal with a continuation value of J independently of whether the cost of e ort to the
agent rises or remains the same going forward. Therefore, from an ex-ante perspective,
the e cient strategy for the principal is to minimize the welfare under a punishment phase
for the agent so as to provide the best incentives for the agent to exert e ort along the
equilibrium path. In providing these ex-ante incentives, the principal therefore has two
options. One option is to choose it = ei so as to prevent the cost of e ort from rising. The
second option is to choose i > ei and to let the cost of e ort rise, where i represents the
level of intensity which minimizes the agent's welfare from punishment conditional on the
cost of e ort equal to H going forward. It is clear that the principal should choose the
second option since, starting from the punishment phase, the agent expects higher levels
of intensive force and a higher cost of e ort going forward under i versus ei.


                                                    28
    Therefore, the long run equilibrium in this extended model features a cooperative and
punishment phase which sustain each other as in our benchmark environment, though
these are associated with a higher cost of e ort to the agent. Moreover, the tradeo
between the intensity and duration of intervention remain and none of our comparative
statics change.
    As an aside, note that these conclusions change if instead H is so high that one cannot
construct any equilibrium which sustains high e ort by the agent. In this situation, levels
of intensity above ei cannot be credibly used by the principal since the agent will never
exert high e ort in the future. Consequently, the optimal punishment for the principal
features a cooperative phase and a punishment phase as in our benchmark environment,
though the principal sets the level of intensity at ei in order to prevent the cost of e ort to
the agent from rising. Given Proposition 2, this means that there is a higher likelihood
of intervention, a lower intensity of intervention, and a longer duration of intervention in
comparison to our benchmark environment. Moreover, note that our comparative statics
in Proposition 3 must be modi ed to take into account the fact that the level of intensity
does not change with small changes in the environment. Consequently, not only is it the
case that the level of intensity does not change, but the duration of intervention actually
rises if A declines or if rises. This is because, holding the level of intensity constant,
these changes enhance the incentives of the principal to punish and hence increase the
duration of intervention, and this e ect cannot be undone by a rise in intensity as in our
benchmark environment.


6      Discussion
6.1     Application: Counterinsurgency
As discussed in the introduction, there are many applications of our model. A particu-
larly relevant application to current a airs is counterinsurgency policy.47 The majority of
modern manuals of counterinsurgency agree that the best way to deal with insurgencies
is by obtaining the collaboration of the local leadership.48 This principle is rst out-
lined in Galula (1963). In this seminal work he suggests that setting up indirect control
relationships might be helpful:

           "[The counterinsurgent] may, at the same time, utilize to the utmost those
  47
     In this application, the realization of a disturbance corresponds to a successful attack by insurgents.
See footnote 12 for how one can model the incentives of the insurgents in our framework.
  48
     See Nagl (2002) for a discussion.

                                                    29
     who are willing to support him actively, giving them increased privileges and
     power, and ruling through them, however disliked they may be." (p.102)

   Similarly, he suggests that a counterinsurgent can obtain the collaboration of the local
leadership with the implicit threat of military intervention:

        "The general line could be: stay neutral and peace will soon return to the
     area. Help the insurgent, and we will be obliged to carry on more military
     operations and thus in ict more destruction." (p.109)

    Our model of indirect control is thus relevant for counterinsurgency policy. Specif-
ically, the use of military interventions in this scenario is an important issue in policy
discussions. Indeed, some experts have defended the use of punitive interventions. For
example, military strategist Luttwak (2007) writes:

         "The simple starting point is that insurgents are not the only ones who
     can intimidate or terrorize civilians. For instance, whenever insurgents are
     believed to be present in a village, small town, or distinct city district...the
     local notables can be compelled to surrender them to the authorities, under
     the threat of escalating punishments...Occupiers can thus be successful without
     need of any specialized counterinsurgency methods or tactics if they are willing
     to out-terrorize the insurgents, so that the fear of reprisals outweighs the desire
     to help the insurgents or their threats." (p.40-41)

    Our model makes three contributions to this policy discussion. First, the model iden-
ti es circumstances in which temporary costly interventions{which serve as a form of
punishment to the local agent{are optimal. More speci cally, it shows that this requires
the presence of political economy frictions: double-sided lack of commitment and asym-
metric information. It also requires certain additional assumptions. For example, it is
necessary that the local agent be more e cient at controlling insurgents relative to the
government (Assumption 1) since delegation is otherwise suboptimal. Moreover, it is
necessary that the use of excessive force by the government be su ciently painful to the
local agent (g 0 (0) is su ciently high) since otherwise temporary costly intervention is
suboptimal. Finally, our extensions of Section 5.1 and 5.2 suggest that even if temporary
and costly interventions are sometimes optimal, they need only be used if a su cient
number of disturbances have occurred. Otherwise, the optimal policy in the model is to
provide incentives in the form of rewards, either in the form of payment or in the form


                                             30
of a permanent concessions such as infrastructure investment, political representation, or
autonomy.
     The second contribution of the model to the policy discussion is that it identi es
basic principles that the government must consider when conducting a costly intervention.
Importantly, maximal force is ine cient, both because the government must actually use
it in equilibrium and also because, if it is too expensive for the government, then it will not
be used for su ciently long. In other words, the government should take into account its
own inability to commit to using force. Moreover, according to the model, the government
should use costly intervention as seldomly as possible. What our analysis in Section 4.2
shows is that the optimal contract sets the likelihood of intervention as low as possible
so that it is possible for the principal to forgive the agent as often as possible. Therefore
automatic knee-jerk reactions after every disturbance are a signal of suboptimal conduct.
In addition, the analysis of Section 4.3 provides precise conditions under which the use of
force should be increased or decreased.
     The third contribution of the model is that it sheds some light on the role of interna-
tional pressure against the use of violent interventions (i.e., a rise in A). On the one hand,
Proposition 3 states that a government responds to an increase in international pressure
by reducing intensity i , which is the intended consequence of this international pressure.
However, on the other hand, Proposition 3 also predicts that the government will also
respond with a higher frequency of intervention (higher l ) and a higher duration of in-
tervention (higher d ). In sum, international pressure alone cannot remove the need for
intervention, and it can have the unintended consequence of making them more frequent
and longer. Nonetheless, to the extent that the international community can play a role,
the extension in Section 5.2 suggests that one method of actually eradicating equilibrium
interventions is to pursue policies which make permanent concessions more desirable than
indirect control to the government in question (e.g., setting J C above        a ( ) = (1     )
via favors, international concessions, or foreign aid).


6.2     Example: Israel in Palestinian Territories
In this section, we consider the historical example of Israeli policy in the Palestinian
Territories following the Oslo Accords of 1993. This set of agreements put Israel and the
Palestinian Authority (PA) in a relationship of indirect control.49 More speci cally, under
  49
    Jamal (2005) writes: "This policy of strict control over all realms of life continued until the estab-
lishment of the PA in 1994; then the occupied territories were divided into three areas with di erent legal
status, and Israeli control of the West Bank and Gaza Strip was transformed from direct to indirect"
(p.29). See also Kristianasen (1999) and Said (2000).


                                                    31
this set of arrangements, Israel would free areas from military occupation in exchange for
the PA's agreement to exert the highest e ort in minimizing terrorist attacks against
Israel from these areas.50 As in our model, it soon became clear that Israel reserved the
right to intervene militarily, and further progress along the peace process (i.e., the making
of concessions as in Section 5.2) was conditional on the absence of Palestinian violence.51
     There was a clear informational asymmetry between Israel and the PA regarding the
e orts of the latter. While the extent to which the PA consistently exerted e ort is
unknown, there are some instances in which visible actions were taken. For example,
1200 suspected islamists were arrested, the Islamic University and some thirty Hamas
institutions were raided, and the Gaza mosques were put under PA control following a
string of suicide bombings in Tel Aviv and Jerusalem in 1996. There are other examples
of such crackdowns, and also rumours that the PA cooperated with the Israeli Defense
Forces by providing information on the location of Hamas and Islamic Jihad activists
throughout the 1990s.52 Nevertheless, at other instances, the extent of PA cooperation
was unclear, and indeed, Prime Minister Sharon repeatedly accused Yasser Arafat of not
being a "partner for peace."53
     While our paper focuses on the e cient equilibrium, a natural question concerns the
extent to which the reaction of actors in the world is in line with what is prescribed by
the equilibrium strategies in our model. In particular, there is no question that there was
a steady increase in Israeli military intensity and punitive measures, such as house demo-
litions and assassinations, throughout the 1990s. This rise culminated in the restoration
of military control over the entirety of the West Bank in 2002.54 Whether or not this shift
in Israeli policy was optimal is an important question which cannot be answered here.
  50
     Beinin (2006) writes: "Rabin initially saw the Declaration of Principles as a security arrangement.
Shortly before its approval he explained:

          I prefer the Palestinians to cope with the problem of enforcing order in Gaza. The
       Palestinians will be better at it than we because they will allow no appeals to the Supreme
       Court and will prevent the Association for Civil Rights from critizising conditions there by
       denying it access to the area." (p.29)

  In the interim agreement on the West Bank and Gaza reached in 1995 (known either as Oslo II or
Taba Accords) it is explicitly stated: "Except for the Palestinian Police and the Israeli military forces, no
other armed forces shall be established or operate in the West Bank and the Gaza Strip." Therefore, the
PA was charged with uprooting armed factions. These security guarantees were even more explicit in the
Wye River Memorandum of 1998, where the PA is required to outlaw and combat terrorist organizations.
  51
     For instance, Israel militarily intervened with a closure of the territories after the 1996 suicide bomb-
ings. See Rabbani (2006).
  52
     See Kristianasen (1999).
  53
     See, for instance, his declarations on April 2nd, 2002.
  54
     See Hammami and Tamari (2006).



                                                     32
However, what we can ask is the following: could the increase in military intensity be
understood through the lens of our model?
    Our comparative statics from section 4.3 suggest that our model may guide us in
understanding these patterns. More speci cally, there are three parameter changes which
can result in increases in intensity in our model. First, and most obvious, the model
predicts that an increase in intensity follows an increase in , the cost to Israel of a
Palestinian attack. The increasing use of suicide bombings by Hamas and Islamic Jihad
throughout the 1990s might thus explain the rise in the Israeli use of force. Moreover,
following Ariel Sharon's visit to the Temple Mount in September 28, 2000, there was a
dramatic increase in the number of terrorist attacks as part of the al-Aqsa Intifada.55
Such increase in the deadliness and frequency of terrorist attacks is therefore in line with
the rise in Israel's intensity of intervention.56
    Second, the model predicts that an increase in , the cost to the agent of preventing
disturbances, is also associated with an increase in the intensity of intervention. This cost
can increase due to a loss of legitimacy of the agent, or due to an increased preference for
attacks by the agent (or the population he is representing). These two forces were present
in the Palestinian territories. The perception that Israel was not keeping up its side of
the bargain, mostly due to the growth in settler population, together with the rampant
corruption in the PA administration both increased the popularity enjoyed by Hamas,
and with it the support for terrorist activities. In December 1995, 77.9% of Palestinians
supported the peace process, but such support steadily declined and was only 44.1% in
December 1999.57
    Finally, the model also predicts an increase in intensity if there is a reduction in the
marginal cost of violence, A. After 9/11 international public opinion and in particular
American opinion became more tolerant of heavy handed action against terrorism.58 To
the extent that international rebuke is a large component of A, such changes in attitudes
may have contributed to the rise in military intensity by Israel.
    While we show that the shift in Israeli policy was in the same direction as implied by
our model's comparative statics, we cannot claim that Israel's use of military intervention
  55
     In terms of the model, this can be seen both as an increase in or an increase in a and p .
  56
     See Baliga and Sj•
                      ostr•
                          om (2009) for an interesting model of provocateurs that incite escalation.
  57
     Data from the Jerusalem Media and Communication Center, as cited in Jamal (2005,p151). On the
steady erosion of PA popularity leading to the outbreak of the second Intifada, see also Hammami and
Tamari (2001).
  58
     When asked in a Time/CNN survey days after the attacks, 41% reported feeling less favorable
toward Palestinians as a result of 9/11, and just 3% felt more favorable. This information is available at
http://www.americans-world.org/digest/regional issues/IsraelPalestinians/viewIsrPal.cfm




                                                   33
was itself optimal or that its itensity was optimally chosen.59 Nonetheless, our discussion
suggests that the comparative statics in the model are in line with the tradeo s faced by
actual policymakers in the world.


7      Conclusion
We have characterized the e cient use of repeated interventions in a model of indirect
control. Our explicit closed form solution for the long run dynamics of the e cient se-
quential equilibrium highlights a fundamental tradeo between the intensity and duration
of interventions. It also allows us to consider the separate e ects of a fall in the cost of
intensity to the principal, a rise in the cost of disturbances to the principal, and a rise in
the cost of e ort to the agent.
    Our model abstracts from a number of potentially important issues. First, in answer-
ing our motivating questions, we have abstracted away from the static components of
intervention and the means by which a principal directly a ects the level of disturbances
(i.e., we let p be exogenous). Future work should also focus on the static features of
intervention and consider how they interact with the dynamic features which we describe.
Second, we have ignored the presence of persistent sources of private information. For
example, the agent's cost of e ort could be unobservable to the principal. Alternatively,
the principal may have a private cost of using force. In this latter scenario, a principal
with a high cost of force may use more intensive force in order to pretend to have a low
cost and to provide better inducements to the agent. We have ignored the presence of
persistent hidden information not for realism but for convenience since it maintains the
common knowledge of preferences over continuation contracts and simpli es the recursive
structure of the e cient sequential equilibria. Understanding the interaction between
persistent and temporary hidden information is an important area for future research.
  59
    To make such statements one would have to argue that the conditions outlined in the previous sub-
section (including whether a su cient number of disturbances ocurred before intervention, and whether
the use of positive incentives such as territorial concessions was contemplated and used) were satis ed.




                                                  34
8        Appendix
8.1        Equilibrium De nition
We consider equilibria in which each player conditions his strategy on past public infor-
mation. Let h0t = fz 1t ; f t 1 ; z 2t 1 ; it 1 ; st 1 g, the history of public information at t after
the realization of zt1 .60 Let h1t = fh0t ; f t 1 ; z 2t g, the history of public information at t after
                                                                                               1
the realization of zt2 . De ne a strategy = f p ; p g where p = fft (h0t ) ; it (h1t )gt=0 and
              1 1                                                      0              0     1
  a = fet (ht )gt=0 for p and a which are feasible if ft (ht ) 2 f0; 1g 8ht , it (ht )           0 8h1t ,
and et (h1t ) = f0; g 8h1t .
    Given , de ne the equilibrium expected continuation values for player j at h0t and h1t ,
respectively, as Uj jh0t and Uj jh1t where jh0t and jh1t correspond to continuation
strategies following h0t and h1t , respectively. Let j jh0t and j jh1t denote the entire set of
feasible continuation strategies for j after h0t and h1t , respectively.

De nition 2            is a sequential equilibrium if it is feasible and if for j = p; a

                                               0
                      Uj     jh0t       Uj     j jh0t ;   j jh0t   8 0j jh0t 2   j jh0t   8h0t and
                                               0
                      Uj     jh1t       Uj     j jh1t ;   j jh1t   8 0j jh1t 2   j jh1t   8h1t .

    In order to build a sequential equilibrium allocation which is generated by a particular
strategy, let qt0 = fz 1t ; z 2t 1 ; st 1 g and qt1 = fz 1t ; z 2t ; st 1 g, the exogenous equilibrium
history of public signals and states after the realizations of zt1 and zt2 , respectively. De ne
an equilibrium allocation as a function of the exogenous history:

                                                                             1
                                       = ft qt0 ; it qt1 ; et qt1            t=0
                                                                                   .

   Let F denote the set of feasible allocations with continuation allocations from t
onward which are measurable with respect to public information generated up to t. Let
Uj jqt0 and Uj jqt1 correspond to the equilibrium continuation value to player j fol-
lowing the realization of qt0 and qt1 , respectively. The following lemma provides necessary
and su cient conditions for to be generated by sequential equilibrium strategies.
  60
       Without loss of generality, we let it = 0 if ft = 0 and et = 0 if ft = 1.




                                                          35
Lemma 1        2 F is a sequential equilibrium allocation if and only if

                                     Uj   jqt0   U j for j = p; a 8qt0 ,                         (14)
                       Up     jqt1       + U p 8qt1 s.t. ft qt0 = 1, and
                                           p                                                     (15)
                   8                 0         n                               o 1 9
                   >
                   >              (1    a ( )) Uj      jqt+1      jqt1 ; st = 0     >
                                                                                    >
                   >
                   >
                                                          0
                                                                              o A ; >
                                                                                    >
                   >
                   >        + @               n                                     >
                                                                                    >
                   <               + a ( ) E Uj jqt+1   0       jqt1 ; st = 1       =
Ua    jqt1   max             0              n                                o 1      8qt1 s.t. ft qt0 = 0
                   >
                   >           (1      (0))  U    j          jq 1
                                                                  ; s   =   0       >
                                                                                    >
                   >
                   >         @
                                     a
                                           n
                                               j     0
                                                   qt+1         t     t
                                                                            o A     >
                                                                                    >
                   >
                   >                                                                >
                                                                                    >
                   :            + a (0) E Uj jqt+1 0
                                                              1
                                                            jqt ; st = 1            ;

                                                                                                 (16)

for U p =           p = (1     ) and some U a wa = (1          ).
Proof. Step 1. The necessity of (14) for j = p follows from the fact that the principal
can choose fk0 (qk0 ) = 1 8k t and 8qk0 and i0k (qk1 ) = 0 8k t and 8qk1 , and this delivers
continuation value U p . The necessity of (14) for j = a follows from the fact that the agent
can choose e0k (qk1 ) = 0 8k t and 8qk1 , and this delivers a continuation value of at least
U a . Step 2. The necessity of (15) follows from the fact that conditional on ft (qt0 ) = 1, the
principal can choose fk0 (qk0 ) = 1 8k > t and 8qk0 and i0k (qk1 ) = 0 8k t and 8qk1 , and this
delivers continuation value            p + U p . The necessity of (16) follows from the fact that

conditional on ft (qt ) = 0, the agent can unobservably choose e0t (qt1 ) 6= et (qt1 ) and follow
                         0  0

the equilibrium strategy 8k > t and 8qk1 . Step 3. For su ciency, consider a feasible
allocation which satis es (14) (16) and construct the following o -equilibrium strategy.
Any observable deviation by the principal results in a reversion to the repeated static Nash
equilibrium. We only consider single period deviations since < 1 and since continuation
values are bounded. If ft0 (qt0 ) = 1, then a deviation by the principal to ft0 (qt0 ) = 0 is
weakly dominated by (14) and Assumption 2. Moreover, a deviation by the principal to
i0 (qt1 ) 6= i (qt1 ) is weakly dominated by (15). If ft (qt0 ) = 0, then a deviation by the principal
to ft0 (qt0 ) = 1 is weakly dominated by (14). If ft (qt0 ) = 0, then a deviation by the agent to
e0t (qt1 ) 6= et (qt1 ) is weakly dominated by (16).


8.2      Implications of Assumption 3
The value of b satis es




                                                    36
            8                                                                                9
            >
            >                                                                                >
                                                                                             >
            <                                            1              g 0 (i ) i           =
  b = max                                              ;
            >
            > (1          (0))   wa (       (0)   a ( )) A         a (0)                       >
            :         a                 a
                                                                                   wa + g (i ) >
                                                                                               ;
                                                             a (0)      a( )


for i which satis es (9). Given the functions l (i) and d (i) de ned in Section 4.2, the
  rst part of this assumption implies that l (0) < 1 so that an equilibrium in which high
e ort is sustained by the threat of the repeated static Nash equilibrium exists. Since l (i)
is declining in i for i < i by Proposition 2, this assumption guarantees that l (i ) < 1.
The second part of this assumption implies that d (i ) > 0. These features guarantee that
the set of values U 2 U ; U are self-generating so that the long run equilibrium can be
explicitly characterized.


8.3    Proofs of Additional Lemmas
In this section we prove several important lemmas which are required for proving our
propositions. Let represent the set of sequential equilibrium continuation values and
let U max the highest continuation value to the agent in this set.

Lemma 2 (i) is convex and compact, (ii) J (U ) = J (U max ) = J, and (iii) J (U ) is
weakly concave.
Proof. Step 1. The weak concavity of the program and the convexity of the constraint
set in (1) (7) guarantees that is convex. Step 2. If we set an arbitrarily high upper
bound for i in (1) (7), then the compactness of the constraint set together with the fact
that < 1 guarantees that that is closed and bounded by the Dominated Convergence
Theorem. Step 3. By (3), J (U )         J and J (U max )    J. Step 4. By Assumptions
1 and 2 and equations (4) and (6), it must be that fz (U ) = 1 8z since otherwise an
increase in fz for some z must satisfy (3) (7) and strictly reduces the welfare of the
agent. If J (U ) > J, then an increase iz must satisfy (3) (7) and strictly reduces the
welfare of the agent. Therefore J (U ) = J. Step 5. By Assumption 1 and equations
(4) and (6), fz (U max ) = 0 8z since otherwise a decrease in fz for some z must satisfy
(3) (7) and strictly increase the welfare of the agent. If J (U max ) > J, then a decrease
in ez or an increase in UzH strictly increases the welfare of the principal while satisfying
(3) (7), and if this were not feasible then U max = 0, which violates (3) since it implies
J (U max ) =     a (0) . Therefore, J (U
                                         max
                                             ) = J. Step 6. The weak concavity of J ( )
follows directly from the rst and second parts of the lemma.

                                                  37
Lemma 3 9i s.t. the solution to (1)                     (7) cannot admit iz (U ) 6= i for any z given
fz (U ) = 1.

Proof. Step 1. De ne i = Eiz (U ). By Step 4 of the proof of Lemma 2, fz (U ) = 1 8z. It
must be that iz (U ) = i 8z since otherwise a perturbation which sets iz (U ) = Eiz (U ) 8z
continues to satisfy (3) (7) and strictly reduces the welfare of the agent by the concavity
of g (i) and J (U ). Step 2. Let Jb U jbi correspond to the maximizer of (1) (7) subject
to the additional constraints that fz = 1 and iz = bi 8z for some bi. Note that for any two
value U 0 and U 00 where wa g bi = (1          ) U 0 < U 00 , it must be that

                                             0                            1         0                    1
                                                 U 00    wa + g bi                      U0   wa + g bi
                                           J@                             A        J@                    A
           Jb U 00 jbi    Jb U 0 jbi
                                       =                                                                     (17)
                   U 00   U0                                             U 00      U0

                                           J (U 00 )     J (U 0 )
                                                                  ,                                          (18)
                                               U 00      U0

where we have appealed to the concavity of J ( ). Step 3. Imagine if 9bi 6= i s.t.
Jb U jbi = J (U ) for some U . Let U
                                   b bi      wa g bi = (1     ) denote the value
which solves Jb U
                b bi jbi = J for such bi, which must exist by the concavity of Jb ( ) since

Jb U jbi                                                      b bi
                 J for some U . By step 1 and Assumption 3, J U                                > Jb U
                                                                                                    b bi jbi , so

that by (18) Jb U jbi < J (U ) 8U U   b bi . Therefore, Jb U jbi < J (U ) 8U and 8bi =
                                                                                     6 i.
Step 4. By step 3, iz (U ) = i if fz (U ) = 1 8z .

         e 2 (U ; U max ) and some m > 0 s.t.
Lemma 4 9U

                          fz (U ) = 0 8z and 8U U  e and
                                           (
                                             = J + m (U U )                        if U U e.
                                    J (U )
                                             < J + m (U U )                               e
                                                                                   if U > U

Proof. Step 1. Consider two continuation values U 0 < U 00 s.t. Efz (U 0 ) > 0 and
Efz (U 00 ) > 0. It follows given Lemma 3 that

                               J (U ) = J (U 0 ) + m (U        U 0 ) 8U 2 [U 0 ; U 00 ]                      (19)
                                                        J (U 00 )     J (U 0 )
                                       where m =                               .
                                                            U 00      U0


                                                         38
To see why, let U W (U ) correspond to the expected continuation value to the agent con-
ditional on fz = 1 and let U P (U ) correspond to the expected continuation value to the
agent conditional on fz = 0. Optimality and the concavity of J ( ) thus require

                  J (U ) = J U W (U ) Efz (U ) + J U P (U ) (1                Efz (U )) .                (20)

By (20) and the concavity of J ( ), it follows that U W (U ) and U P (U ) are on the
same line segment in J ( ) for a given U . By the concavity of J ( ), one can choose
                     W
8z, UzF U W (U ) = U (U ) wa +g(i ) U W (U ) which is weak if i > 0, so that

                                             U W (U 00 ) wa +g(i )           U W (U 0 ) wa +g(i )
       W
  J U (U )   00             W
                       J U (U )  0     J                                J
                                  =                        U W (U 00 ) U W (U 0 )
                                                                                                     . (21)
     U W (U 00 )       U W (U 0 )

By the concavity of J ( ), this implies U W (U 00 ) and U W (U 0 ) are on the same line seg-
ment. Therefore, (19) applies. Step 2. Since Efz (U ) = 1 by step 3 of the proof of
Lemma 2, it follows from step 1 that (19) applies for U 0 = U and some U 00 = U     e    U.
It follows that fz (U ) = 0 8z and 8U     Ue if U
                                                e > U and f (U ) = 0 8z and 8U > U      e if
                                                              z
e = U . Step 3. If U
U                     e = U , then Ef (U ) = 0 8U > U , but this is not possible since (2)
                                      z
                        L
and (6) imply that EUz (U ) < U and cannot be arbitrarily close to U . Therefore m > 0.
Step 4. It cannot be that U e = U max since this violates part 2 of Lemma 2:

Lemma 5 U   e = U.
                                                         h     i
Proof. Step 1. ez (U ) = if fz (U ) = 0 and U 2 U ; U         e . Suppose this is not the
case and consider a solution for which ez (U ) = 0 and fz (U ) = 0. Because the constraint
set is convex, one can perturb this solution without changing welfare so that (6) binds
and UzL (U ) = UzH (U ). However, this implies that UzL (U ) < ez (U ) +h UzLi (U ).
                                                                                  e , this
Because optimality given the concavity of J ( ) requires ez (U ) + UzL (U ) 2 U ; U
means given Lemma 4 that          a (0)  + J UzL (U ) < J, which violates (3). Step 2.
Suppose U < U  e . By Assumption 3, there exists a solution to (1) (7) s.t. f (U ) = 0
                                h      i                                        z
                                     e
and ez (U ) = 8z and 8U 2 U ; U . Moreover, given the concavity of the program and
convexity of the constraint set in (1) (7) such a solution can feature UzH (U ) = U H (U )
and UzL (U ) = U L (U ) 8z. This implies that

              e
            J U         J U                            e
                                                  J UH U              J UH U
      m=                        = (1   a   ( ))                                       +     a   ( ) m,
                   e
                   U    U                                 e
                                                       UH U          UH U



                                                  39
              e >U
but since U H U  e , this violates Lemma 4. Step 3. Suppose U > U
                                                                e so that by Lemma
     e+
4, J U       < J + m (U       U ) for > 0 arbitrarily small. Consider a perturbation which
        e+
sets ez U       =     and lets (6) bind so that UzL        e+
                                                           U          < UzH    e+
                                                                               U          e 8z. This
                                                                                         <U
                                                           e+
perturbation yields a payo to the principal equal to J + m U                          U , violating the
             e in Lemma 4.
de nition of U


8.4    Proof of Proposition 1
Step 1. We begin by characterizing the solution for U 2 U ; U to prove the second
part of the proposition and having done this we prove the rst part of the proposition.
By steps 4 and 5 of the proof of Lemma 2 and by Lemma 4, the solution which satis es
the Bang-Bang property is characterized by a probability Efz (U ) = U U = U U ,
where

 U = E wa           g (iz (U )) + UzF (U ) jfz (U ) = 1
 U = E         ez (U ) +    (1       a   (ez (U ))) UzH (U ) +   a   ez (U ) UzL (U     jfz (U ) = 0 ,

and the analogous expected continuation values for the principal are J U and J (U ) = J,
respectively. Therefore, one only needs to characterize iz (U ), ez U , UzF (U ), UzH U ,
and UzL U to achieve an full description of equilibrium actions. Step 2. By Lemma
3 iz (U ) = i 8z. By step 2 of the proof of Lemma 5, ez U = 8z. Step 3. By
Lemmas 4 and 5 UzH U = U and UzL (U ) = U                = ( ( a (0)      a ( ))) < U since

otherwise (6) does not bind and a perturbation which reduces Uz and raises UzL strictly
                                                                   H

raises welfare. Step 4. The fact that UzF (U ) = (U wa + g (i )) = 8z is implied by (2)
and the fact that (5) binds since otherwise the principal is receiving a continuation value
above J. Step 5. We are left to characterize i and U . Note that the equilibrium can be
represented by a system of 4 equations: (10) (12) and

                       J         p        Ai +     (1    d )J U + d J .                            (22)

(22) is an equality if d     0 which occurs if (U wa + g (i )) =     U , where we have
taken Lemma 4 into account. (10) (12) and (22) represent a system of 4 equations and
5 unknowns: J U , U ; l , i , and d , where the fth unknown is pinned down by the fact
that these variables are chosen to maximize J U . Note that given steps 1-4, d < 1 and




                                                  40
l 2 (0; 1) so that by algebraic substitution, it is the case that

                                a   (0)
                                                    wa + g (i )
                      a   (0)            a   ( )
 J U (1       )                                                 ((                p       a   ( ))   + Ai )     (   p   + Ai ) ,
                                             wa + g (i )
                                                                                     (23)
which is an equality if and only if (22) is an equality. Step 6. Note that i which
satis es (9) maximizes the right hand side of (23). Moreover, by Assumption 3, it is
the case in the optimum that (22) binds since the implied value of d exceeds 0 so that
UzF (U ) = (U wa + g (i )) =      U . Substitution into (11) yields U which completes the
proof of the second part. Step 7. Lemmas 4 and 5 imply that if Pr Ut U 8t > 0, then
Pr fft = 0 8tg > 0. However, (2) and (6) imply that Pr fUt+1 < Ut      jft = 0g > 0 8t for
some > 0, which means that Pr Ut U 8t = 0. Step 8. Pr Ut+1 U jUt U = 1
by steps 3 and 6, so that by step 7, limt!1 Pr Ut U = 1 8U0 . Q.E.D.


8.5    Proof of Proposition 2
Step 1. An equilibrium with the given structure satis es (10) (13) and entails functions
l (i) and d (i) de ned by:

                                                                              a+      p       1
                                    1         a   ( ) l (i) =
                                                                               a+     p       1
                                                                              p+      a       1
                                                          d (i) =
                                                                               a+     p       1

for

                                                                    a   (0)
                                                                                wa + g (i)
                                                          a   (0)        ( )
                                                                          a
                                a        =                                                                                  (24)
                                                                         wa + g (i)
                                                      (       p      a ( ))
                                    p    =                                                                                  (25)
                                                  (   p           a ( ))   + Ai

where Assumption 3 and the fact that < 1 implies a 2 [0; 1], p 2 [0; 1], and a + p 1 >
0 for all i   i, where i > i . Step 2. By some algebra, l0 (i) has the same sign as
   p @ a =@i (1    a ) @ p =@i which equals


                                                          g 0 (i)                           A
                    p (1            a)                                                                      .               (26)
                                                          wa + g (i)          (   p       a ( ))     + Ai



                                                                        41
Since g ( ) is concave, it follows that (26) is negative if i < i and positive if i > i . Step
3. By some algebra, d0 (i) has the same sign as 1          p @ a =@i + a @ p =@i which equals


                                                A
                                                                                                                             (27)
                         [         (! a g(i))] [( a ( )     p)                        Ai]
                                                      a (0)
                        ig 0 (i) (1    a)                                           (! a    g(i))          p
                                               a (0)     a( )


The element outside the square brackets is always positive. Consider i < i , where the
concavity of g ( ) guarantees that

                   g 0 (i) [(   a   ( )   p)            Ai]       A(             (! a       g(i))) > 0.                      (28)

By some algebra, one can show that given (28), the element inside the square brackets
in (27) is decreasing in i for i < i . Since d (0) = 1, it follows that d0 (0)  0, so
                        0
this fact implies that d (i) < 0 for i < i . Consider i     i . By rearranging terms,
 1     p @ a =@i + a @ p =@i can also be expressed as


                          g 0 (i)                                     g 0 (i)                                  A
      1    p   a                     +             a p                          +                                            ;
                          (! a g(i))                                  (! a g(i)) (               a   ( )           p)   Ai

which is negative for i         i since the left hand side of (28) is weakly negative in this case.
Q.E.D.


8.6       Proof of Proposition 3
Step 1. Implicit di erentiation of (9) taking into account the concavity of g ( ) yields
the comparative statics with respect to i . Step 2. Given a and p de ned in the proof
of Proposition 2, it is the case that if a particular parameter x = fA; ; g changes, the
e ect on l has the same sign as

                                                  @ a                       @ p
                                              p              (1        a)       ,                                            (29)
                                                  @x                        @x

where we have used the fact that                  p @ a =@i           (1        a ) @ p =@i     = 0 at i . The e ect on
d has the same sign as

                                 @ a          @ p                               @ a             @ p    @i
                   1       p         +    a              +        1         p       +       a             .                  (30)
                                 @x           @x                                 @i              @i    @x



                                                             42
Step 3. Given (29), the comparative statics with respect to l are implied by the fact that
@ a =@A = @ a =@ = 0, @ a =@ < 0, @ p =@A < 0, @ p =@ > 0, and @ p =@ = 0. Step
4. Given (30), the e ect of an increase in on d is implied by the fact that @ a =@ < 0,
@ p =@ = 0, @i=@ > 0, and 1        p @ a =@i + a @ p =@i < 0 from Proposition 2. Letting
x = A, substitution into (30) taking Assumption 4 into account together with @i=@A =
    0       00
 p g (i) =Ag (i) yields:

                                            !
               a p    1       p   (1   a)       @ p       i    1             @ p i
                                                      p              +   a
                          p                      @i       A (1   )            @i A

which has the same sign as    a + p    1, which is unambiguously positive given the
de nition of i . Analogous arguments imply the comparative static with respect to .
Q.E.D.




                                                43
9    Bibliography
Abreu, Dilip (1988) "On the Theory of In nitely Repeated Games with Discounting,"
Econometrica, 56, 383-397.
    Abreu, Dilip, David Pearce, and Ennio Stacchetti (1990) "Towards a Theory
of Discounted Repeated Games with Imperfect Monitoring," Econometrica, 58, 1041-1063.
    Acemoglu, Daron, Mikhail Golosov, and Aleh Tsyvinski (2008) "Political
Economy of Mechanisms," Econometrica, 76, 619-641.
    Acemoglu, Daron and James A. Robinson (2006), Economic Origins of Dicta-
torship and Democracy, Cambridge University Press; New York.
    Acemoglu, Daron and Alexander Wolitzky (2009) "The Economics of Labor
Coercion," Working Paper.
    Albuquerque, Rui and Hugo Hopenhayn (2002) "Optimal Lending Contracts
and Firm Dynamics," Review of Economic Studies, 71, 285-315.
    Ambrus, Attila and Georgy Egorov (2009) "Delegation and Non-monetary in-
centives", Working Paper.
    Anderlini, Luca, Dino Gerardi, and Roger Laguno (2009) "Social Memory,
Evidence, and Con ict," forthcoming in Review of Economic Dynamics.
    Atkeson, Andrew and Robert Lucas (1992) "On E cient Distribution with
Private Information," Review of Economic Studies, 59, 427-453.
    Baliga, Sandeep and Tomas Sj•     ostr•om (2004) "Arms Races and Negotiations,"
Review of Economic Studies, 71, 351-369.
    Baliga, Sandeep and Tomas Sj•      ostr•om (2009) "The Strategy of Manipulating
Con ict," Working Paper.
    Beinin, Joel (2006) "The Oslo Process and the Limits of a Pax Americana," in
The Struggle for Sovereignty: Palestine and Israel 1993-2005, edited by Joel Beinin and
Rebecca L. Stein. Stanford University Press.
    Chassang, Sylvain and Gerard Padro i Miquel (2009) "Economic Shocks and
Civil War," Quarterly Journal of Political Science, 4, 211-228.
    Chwe, Michael Suk-Young (1990) "Why Were Workers Whipped? Pain in a
Principal-Agent Model," Economic Journal, 100, 1109-1121
    Dal Bo, Ernesto, Pedro Dal Bo, and Rafael Di Tella (2006) "Plata o Plomo?:
Bribe and Punishment in a Theory of Political In uence," American Political Science
Review, 100, 41-53.
    Dal Bo, Ernesto and Rafael Di Tella (2003) "Capture by Threat," Journal of
Political Economy, 111, 1123-1154, .


                                          44
    Debs, Alexandre (2008) "Political Strength and Economic E ciency in a Multi-
Agent State," Working Paper.
    Egorov, Georgy and Konstantin Sonin (2009) "Dictatorships and their Viziers:
Endogenizing the Loyalty-Competence Tradeo ," forthcoming in Journal of the European
Economic Association.
    Esteban, Joan and Debraj Ray (2008) "On the Salience of Ethnic Con ict,"
forthcoming, American Economic Review.
    Fearon, James D. (1995) "Rationalist Explanations for War," International Orga-
nization, 49, 379-414.
    Ferejohn, John (1986) "Incumbent Performance and Electoral Control," Public
Choice, 50, 5-25.
    Fong, Yuk-fai and Jin Li (2009) "Relational Contracts, Limited Liability, and
Employment Dynamics," Working Paper.
    Fudenberg, Drew, David Levine, and Eric Maskin (1994) "The Folk Theorem
with Imperfect Public Information," Econometrica, 62, 997-1039.
    Golosov, Mikhail, Narayana Kocherlakota, and Aleh Tsyvinski (2003) "Op-
timal Indirect and Capital Taxation," Review of Economic Studies, 70, 569-587.
    Green, Edward J. and Robert H. Porter (1984) "Noncooperative Collusion
Under Imperfect Price Information," Econometrica, 52, 87-100.
    Guriev, Sergei (2004) "Red Tape and Corruption," Journal of Development Eco-
nomics, 73, 489-504.
    Hammami, Rema and Salim Tamari (2001) "The Second Uprising: End or New
Beginning?," Journal of Palestine Studies, 30, 5-25.
    Hammami, Rema and Salim Tamari (2006) "Anatomy of Another Rebellion:
from Intifada to Interregnum," in The Struggle for Sovereignty: Palestine and Israel 1993-
2005, edited by Joel Beinin and Rebecca L. Stein. Stanford University Press.
    Herbst, Je rey (2000) States and Power in Africa, Princeton University Press,
Princeton.
    Jackson, Matthew O. and Massimo Morelli (2008) "Strategic Militarization,
Deterrence, and War," Working Paper.
    Jaeger, David A. and M. Daniele Paserman (2008) "The Cycle of Violence?: An
Empirical Analysis of Fatalities in the Israeli-Palestinian Con ict," American Economic
Review, 98, 1591-1604.
    Jamal, Amal (2005) The Palestinian National Movement: Politics of Contention,
1967-2005. Bloomington and Indianapolis: Indiana University Press.



                                           45
    Kristianasen, Wendy (1999) "Challenge and Counterchallenge: Hamas's Response
to Oslo," Journal of Palestine Studies, 28, 19-36.
    Luttwak, Edward N. (1976) The Grand Strategy of the Roman Empire, Johns
Hopkins University Press, Baltimore and London.
    Luttwak, Edward N. (2007) "Dead End: Counterinsurgency Warfare as Military
Malpractice," Harper's Magazine, February, 33-42.
    Myerson, Roger (2008) "Leadership, Trust, and Power: Dynamic Moral Hazard in
High O ce," Working Paper.
    Nagl, John A. (2002) Learning to Eat Soup with a Knife: Counterinsurgency
Lessons from Malaya and Vietnam, Chigaco University Press, Chicago.
    Phelan, Christopher (1995) "Repeated Moral Hazard and One-Sided Commit-
ment," Journal of Economic Theory, 66, 488-506.
    Polinsky, A. Mitchell and Steven Shavell (1979) "The Optimal Tradeo between
the Probability and Magnitude of Fines," American Economic Review, 69, 880-891.
    Polinsky, A. Mitchell and Steven Shavell (1984) "The Optimal Use of Fines
and Imprisonment," Journal of Public Economics, 24, 89-99.
    Powell, Robert (1999) In the Shadow of Power: States and Strategies in Interna-
tional Politics, Princeton University Press; Princeton.
    Rabbani, Mouin (2006) "Palestinian Authority, Israel Rule," in The Struggle for
Sovereignty: Palestine and Israel 1993-2005, edited by Joel Beinin and Rebecca L. Stein.
Stanford University Press.
    Reno, William (1998) Warlords Politics and African States, Lynne Rienner Pub-
lishers; London.
    Said, Edward W. (2000) The End of the Peace Process. London: Granta Publica-
tions.
    Syme, Ronald (1933) "Some Notes on the Legions under Augustus," Journal of
Roman Studies, 23: 14-33.
    Schwarz, Michael and Konstantin Sonin (2004) "A Theory of Brinksmanship,
Con icts, and Commitments," Journal of Law, Economics, and Organization, forthcom-
ing.
    Thomas, Jonathan and Tim Worrall (1990) "Income Fluctuation and Asym-
metric Information: An Example of a Repeated Principal-Agent Problem," Journal of
Economic Theory 51, 367-390.
    Yared, Pierre (2009) "A Dynamic Theory of War and Peace", Working Paper.




                                          46
