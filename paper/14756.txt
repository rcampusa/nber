                                NBER WORKING PAPER SERIES




          A MARTINGALE REPRESENTATION FOR MATCHING ESTIMATORS

                                           Alberto Abadie
                                           Guido Imbens

                                        Working Paper 14756
                                http://www.nber.org/papers/w14756


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     February 2009




We thank Rustam Ibragimov, Don Rubin, and seminar participants at Harvard/MIT, Brown, Georgetown,
UPenn, Montreal, and the 2009 Conference on Causal Inference in Statistics and the Quantitative Sciences
at the Banff International Research Station for useful comments and suggestions. We are also grateful
to Greg Weyland, from the US Census Bureau, for patiently explaining to us the intricacies of the
hot deck imputation algorithms employed in the Current Population Survey. The views expressed
herein are those of the author(s) and do not necessarily reflect the views of the National Bureau of
Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2009 by Alberto Abadie and Guido Imbens. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice,
is given to the source.
A Martingale Representation for Matching Estimators
Alberto Abadie and Guido Imbens
NBER Working Paper No. 14756
February 2009, Revised April 2010
JEL No. C13,C14,C21

                                               ABSTRACT

Matching estimators (Rubin, 1973a, 1977; Rosenbaum, 2002) are widely used in statistical data analysis.
However, the large sample distribution of matching estimators has been derived only for particular
cases (Abadie and Imbens, 2006). This article establishes a martingale representation for matching
estimators. This representation allows the use of martingale limit theorems to derive the large sample
distribution of matching estimators. As an illustration of the applicability of the theory, we derive the
asymptotic distribution of a matching estimator when matching is carried out without replacement,
a result previously unavailable in the literature. In addition, we apply the techniques proposed in this
article to derive a correction to the standard error of a sample mean when missing data are imputed
using the “hot deck”, a matching imputation method widely used in the Current Population Survey
(CPS) and other large surveys in the social sciences. We demonstrate the empirical relevance of our
methods using two Monte Carlo designs based on actual data sets. In these realistic Monte Carlo exercises
the large sample distribution of matching estimators derived in this article provides an accurate approximation
to the small sample behavior of these estimators. In addition, our simulations show that standard errors
that do not take into account hot deck imputation of missing data may be severely downward biased,
while standard errors that incorporate the correction proposed in this article for hot deck imputation
perform extremely well. This result demonstrates the practical relevance of the standard error correction
for the hot deck proposed in this article.


Alberto Abadie
John F. Kennedy School of Government
Harvard University
79 JFK Street
Cambridge, MA 02138
and NBER
alberto_abadie@harvard.edu

Guido Imbens
Department of Economics
Littauer Center
Harvard University
1805 Cambridge Street
Cambridge, MA 02138
and NBER
imbens@fas.harvard.edu
                                   I. Introduction

Matching methods provide simple and intuitive tools for adjusting the distribution of co-
variates among samples from different populations. Probably because of their transparency
and intuitive appeal, matching methods are widely used in evaluation research to estimate
treatment effects when all treatment confounders are observed (Rubin, 1977; Dehejia and
Wahba, 1999; Rosenbaum, 2002, Hansen, 2004). Matching is also used for the analysis
of missing data, where it is often referred to as “hot deck imputation” (Little and Rubin,
2002). As a notorious example, missing weekly earnings are currently imputed using hot
deck methods for more than 30 percent of the records with weekly earnings data in the
monthly U.S. Current Population Survey (CPS) files (Bollinger and Hirsch, 2009).
   In spite of the pervasiveness of matching methods, the asymptotic distribution of match-
ing estimators has been derived only for special cases (Abadie and Imbens, 2006). In the
absence of large sample approximation results to the distribution of matching estimators,
empirical researchers employing matching methods have sometimes used the bootstrap as
a basis for inference. However, recent results have shown that, in general, the bootstrap
does not provide valid large sample inference for matching estimators (Abadie and Im-
bens, 2008). Similarly, the properties of statistics based on data imputed using sequential
hot deck methods, like those employed in the CPS and other large surveys, are not well-
understood, and empirical researchers using these surveys typically ignore missing data
imputation issues when they construct standard errors. Andridge and Little (2010) pro-
vide a recent survey on hot deck imputation methods.
   The main contribution of this article is to establish a martingale representation for
matching estimators. This representation allows the use of martingale limit theorems (Hall
and Heyde, 1980; Billingsley, 1995; Shorack, 2000) to derive the asymptotic distribution
of matching estimators. Because the martingale representation applies to a large class
of matching estimators, the applicability of the methods presented in this article is very
broad. Despite its simplicity and immediate implications, the martingale representation
of matching estimators described in this article seems to have been previously unnoticed


                                            1
in the literature. The use of martingale methods is attractive because the limit behavior
of martingale sequences has been extensively studied in the statistics literature (see, for
example, Hall and Heyde, 1980).
   As an illustration of the usefulness of the theory, we apply the martingale methods
proposed in this paper to derive the asymptotic distribution of a matching estimator when
matching is carried out without replacement, a result previously unavailable in the litera-
ture. In addition, we apply the techniques proposed in this article to derive a correction to
the standard error of a sample mean when missing data are imputed using the hot deck.
   Finally, we demonstrate the empirical relevance of our methods using two Monte Carlo
designs based on actual data sets. In these realistic Monte Carlo exercises the large sample
distribution of matching estimators derived in this article provides an accurate approxima-
tion to the small sample behavior of these estimators. In addition, our simulations show
that standard errors that do not take into account hot deck imputation of missing data may
be severely downward biased while standard errors that incorporate the correction proposed
in this article for hot deck imputation perform extremely well. This result demonstrates
the practical relevance of the standard error correction for the hot deck proposed in this
article.
   The rest of the article is organized as follows. Section II describes matching estima-
tors. Section III presents the main result of the article, which establishes a martingale
representation for matching estimators. In section IV, we apply martingale techniques to
analyze the large sample properties of a matching estimator when matching is carried out
without replacement. In section V, we apply martingale techniques to study hot deck im-
putation. Section VI describes of the Monte Carlo simulation exercises and reports the
results. Section VII concludes.


                              II. Matching Estimators

Let W be a binary variable that indicates membership to a particular population of interest.
Empirical researchers often compare the distributions of some variable, Y , between units
with W = 1 and units with W = 0 after adjusting for the differences in a (k × 1) vector of

                                             2
observed covariates, X. For example, in discrimination litigation research, W may represent
membership in a certain demographic group, Y may represent labor wages, and X may
represent a vector of variables describing job and/or worker characteristics. In evaluation
research, W typically indicates exposure to an active treatment or intervention, Y is an
outcome of interest, and X is a vector of observed confounders. As in that literature, we
will say that units with W = 1 are “treated” and units with W = 0 are “untreated”. Let
                                         h                    i
                      τ = E[Y |W = 1] − E E[Y |X, W = 0] W = 1 .                          (1)

In evaluation research, τ is given a causal interpretation as the “average treatment effect
on the treated” under unconfoundedness assumptions (Rubin, 1977). Applied researchers
often use matching methods to estimate τ . Other parameters of interest that can be
estimated by matching methods include: (i) the “average treatment effect”, which is of
widespread interest in evaluation studies, (ii) parameters that focus on features of the
distribution of Y other than the mean, (iii) parameters estimated by hot deck imputation
methods in the presence of missing data. Rosenbaum (2002), Imbens (2004), and Rubin
(2006) provide detailed surveys of the literature. For concreteness, and to avoid tedious
repetition or unnecessary abstraction, in this section we discuss matching estimation of τ
only. However, the techniques proposed in this paper are of immediate application to the
estimation of parameters other than τ via matching (see, for example, section V).
   Also, to avoid notational clutter, we consider only estimators with a fixed number
of matches, M , per unit. However, as it will be explained later, our techniques can be
immediately applied to estimators for which the number of matches may differ across units
(see, e.g., Hansen, 2004). Consider two random samples of sizes N0 and N1 of untreated
and treated units, respectively. Pooling these two samples, we obtain a sample of size
N = N0 + N1 containing both treated and untreated units. For each unit in the pooled
sample we observe the triple (Y, X, W ). For each treated unit i, let JM (i) be the indices
of M untreated units with values in the covariates similar to Xi (where M is some small
positive integer). In other words, JM (i) is a set of M matches for observation i. To simplify
notation, we will assume that at least one of the variables in the vector X has a continuous

                                              3
distribution, so perfect matches happen with probability zero. Let k · k be some norm in
Rk (typically the Euclidean norm). Let 1A be the indicator function for the event A. For
matching with replacement JM (i) consists of the indices of the M untreated observations
with the closest value covariate values to Xi :
            (                                       N
                                                                                             !        )
                                                    X
   JM (i) =   j ∈ {1, . . . , N } s.t. Wj = 0,            (1 − Wk ) 1{kXi −Xj k≤kXi −Xk k}       ≤M       .
                                                    k=1

For matching without replacement, the elements of {JM (i) s.t. Wi = 1} are non-overlapping
subsets of {j ∈ {1, . . . , N } s.t. Wj = 0}, chosen to minimize the sum of the matching dis-
crepancies:                                                            
                              N
                              X            1     X
                                    Wi                   kXi − Xj k .
                              i=1
                                           M
                                               j∈JM (i)

In both cases, the matching estimator of τ is defined as:
                                      N
                                  1 X            1            X          
                             τb =        W i Yi −                       Yj .                                  (2)
                                  N1 i=1          M
                                                             j∈JM (i)

Many other matching schemes are possible (see, e.g., Gu and Rosenbaum, 1993; Rosen-
baum, 2002; Hansen, 2004; Diamond and Sekhon, 2008; Iacus, King, and Porro, 2009), and
the results in this article are of broad generality. Notice that in this article we reserve the
term “matching” for procedures that use a small number, M , of matches. Estimators that
treat the number of matches as a function of the sample size (with M → ∞ as N → ∞)
have been proposed by Heckman, Ichimura, and Todd (1998) and others. Under certain
conditions, these estimators have asymptotically linear representations, so their large sam-
ple distributions can be derived using the standard machinery for asymptotically linear
estimators. In contrast, despite the pervasiveness of matching estimators that use a small
number of matches (e.g., hot deck imputation in the CPS), the previous literature does not
provide a general framework for establishing their large sample properties.


        III. A Martingale Representation for Matching Estimators

This section derives a martingale representation for matching estimators. For w ∈ {0, 1},
let µw (x) = E[Y |X = x, W = w] and σw2 (x) = var(Y |X = x, W = w). Assume that these

                                                   4
functions are bounded. Given equation (2), we can write τb − τ = DN + RN , where
                         N
                     1 X                               
                DN =        Wi µ1 (Xi ) − µ0 (Xi ) − τ
                     N1 i=1
                             N
                         1 X                     1             X                      
                     +          Wi Yi − µ1 (Xi ) −                         Yj − µ0 (Xj ) ,
                         N1 i=1                    M
                                                               j∈JM (i)

and
                                     N
                                 1 X                 1         X                 
                         RN =           Wi µ0 (Xi ) −                     µ0 (Xj ) .
                                 N1 i=1               M
                                                              j∈JM (i)

The term RN is the conditional bias of matching estimator described in Abadie and Imbens
(2006). This term is zero if all matches are perfect (that is, if all matching discrepancies,
Xi − Xj for j ∈ JM (i), are zero), or if the regression µ0 is a constant function. In most
cases of interest, however, this term is different from zero, as perfect matches happen with
probability zero for continuous covariates. The order of magnitude of RN depends on the
number of continuous covariates, as well as the magnitude of N0 relative to N1 . Under
                      √
appropriate conditions N 1 RN converges in probability to zero (see section IV for the case
of matching without replacement, or Abadie and Imbens, 2006, for the case of matching
with replacement).
   Next, it will be shown that the term DN is a martingale array with respect to a certain
filtration. First notice that:
                              N
                           1 X                              
                     DN =        Wi µ1 (Xi ) − µ0 (Xi ) − τ
                          N1 i=1
                              N                        
                          1 X                     KN,i                   
                        +         Wi − (1 − Wi )           Yi − µWi (Xi ) ,
                          N1 i=1                   M

where KN,i is the number of times that observation i (with Wi = 0) is used as a match:
                                               N
                                               X
                                      KN,i =         1{i∈JM (j)} .
                                               j=1

Therefore, we can write:
                                       p              2N
                                                      X
                                           N1 DN =          ξN,k ,
                                                      k=1


                                                 5
where
         
            1                           
          √ Wk µ1 (Xk ) − µ0 (Xk ) − τ                                                if 1 ≤ k ≤ N,
         
         
             N1 
ξN,k   =    1                        KN,k−N
                                            
                                                                  
          √      Wk−N − (1 − Wk−N )          Yk−N − µWk−N (Xk−N )                     if N + 1 ≤ k ≤ 2N.
         
         
             N1                         M

Let XN = {X1 , . . . , XN } and WN = {W1 , . . . , WN }. Consider the σ-fields FN,k = σ{WN ,
X1 , . . . , Xk } for 1 ≤ k ≤ N and FN,k = σ{WN , XN , Y1 , . . . , Yk−N } for N + 1 ≤ k ≤ 2N .
Then, and this is the key insight in this article,
                               ( i                            )
                                 X
                                     ξN,j , FN,i , 1 ≤ i ≤ 2N
                                       j=1
                                                                                         √
is a martingale for each N ≥ 1. As a result, the asymptotic behavior of                      N1 DN can
be analyzed using martingale methods. Analogous martingale representations hold for
alternative matching estimators. Regardless of the choice of matching scheme, if matches
                                                                          √
depend only on the covariates X, a martingale representation holds for N1 DN . The
reason is that no matter how matching is implemented, (i) the number of times that
unit k is used as a match, KN,k , is a deterministic function of XN and WN , and (ii)
E[Yk − µWk (Xk ) | XN , WN , Y1 , . . . , Yk−1 ] = 0.
    So far, we have considered the case where KN,i is fixed given XN and WN , for all
1 ≤ i ≤ N . This assumption does not hold for certain matching schemes that break
matching ties using randomization. Notice, however, that any sequence of randomized
tie-breaks can be included in the set of variables that span FN,k for N + 1 ≤ k ≤ 2N to
preserve the martingale representation of DN .


                 IV. Application: Matching without Replacement

In this section, we illustrate the usefulness of the martingale representation of matching
estimators by deriving the asymptotic distribution of a matching estimator when matching
is done without replacement, so KN,i ∈ {0, 1} for every unit i with Wi = 0.
    For 1 ≤ k ≤ N , the conditional variances of the martingale differences are given by:

                     2                 1
                  E[ξN,k |FN,k−1 ] =      Wk E[(µ1 (Xk ) − µ0 (Xk ) − τ )2 |FN,k−1 ]
                                       N1

                                                    6
                                        1
                                    =      Wk E[(µ1 (Xk ) − µ0 (Xk ) − τ )2 |Wk = 1].
                                        N1
For N + 1 ≤ k ≤ 2N , the conditional variances of the martingale differences are given by:
                        "                               2                                #
   2               1                            KN,k−N                           2
E[ξN,k |FN,k−1 ] =    E    Wk−N − (1 − Wk−N )                Yk−N − µWk−N (Xk−N ) FN,k−1
                   N1                              M
                                                                        
                   1          2                        KN,k−N 2
                 =      Wk−N σ1 (Xk−N ) + (1 − Wk−N )          σ0 (Xk−N )
                   N1                                    M2
                                          σ02 (Xk−N )
                                                     
                   1          2
                 =    Wk−N σ1 (Xk−N ) +                 + rN,k−N ,
                   N1                          M
where
                                                                      σ02 (Xk−N )
                                                                                       
                        1                    KN,k−N 2
             rN,k−N   =          (1 − Wk−N )       σ0 (Xk−N ) − W k−N                       .
                        N1                    M2                           M
Assume that the conditional variance function σ02 (x) is Lipschitz-continuous, with Lipschitz
                                                                           (M,m)
constant equal to c1 . For 1 ≤ i ≤ N such that Wi = 1, let kUN0 ,N1 ,i k be the m-th matching
discrepancy for treated unit i when untreated units are matched without replacement to
treated units in such a way that the sum of the matching discrepancies is minimized.
That is, if unit i is a treated observation, and unit j is the m-th match for unit i, then
   (M,m)
kUN0 ,N1 ,i k = kXi − Xj k. Lipschitz-continuity of σ02 (x) implies:
                          2N                         N   M
                          X                    c1 1 X X          (M,m)
                                   rN,k−N     ≤ 2           Wi kUN0 ,N1 ,i k.
                         k=N +1
                                               M N1 i=1 m=1

Because the average matching discrepancy converges to zero in probability (see Proposition
1 in the appendix for a stronger result), the Weak Law of Large Numbers implies
                                        2N
                                                                p
                                        X
                                                 2
                                              E[ξN,k |FN,k−1 ] → σ 2 ,
                                        k=1

where
                                                             σ02 (X)
                                                                        
            2                                    2   2
           σ = E[(µ1 (X) − µ0 (X) − τ ) |W = 1] + E σ1 (X) +         W =1 .                     (3)
                                                                M
In view of this result, to apply a Martingale Central Limit Theorem to DN , it is sufficient
to check the Lindeberg condition,
                          2N
                          X
                                    2
                                 E[ξN,k 1{|ξN,k |≥ε} ] → 0          for all ε > 0
                          k=1


                                                       7
(Billingsley, 1995, see Hall and Heyde, 1980, and Shorack, 2000, for alternative conditions).
Because for all δ > 0, |ξN,k |2 1{|ξN,k |≥ε} εδ ≤ |ξN,k |2+δ , it follows that Lindeberg’s condition is
implied by Lyapounov’s condition:
                                2N
                                X
                                         2+δ
                                      E[ξN,k ]→0          for some δ > 0,
                                k=1

For the matching estimators considered in this section, this can be easily established under
usual regularity conditions regarding boundedness of moments. Under these conditions,
the Central Limit Theorem for Triangular Martingale Arrays implies:

                                                      d
                                        p
                                            N1 DN −→ N (0, σ 2 ).
                                               √           p
The proof concludes by showing that                N1 RN → 0. If µ0 is Lipschitz-continuous, then
there exists a constant c2 such that
                                                    N   M
                           p                 1 1 XX             (M,m)
                               N1 R N ≤ c 2 √              Wi kUN0 ,N1 ,i k.
                                              N1 M i=1 m=1

Proposition 1 in the appendix shows that under some conditions, and if there exists c > 0
and r > k where k is the number of (continuous) covariates, such that N1r /N0 ≤ c, then,
                                         N   M
                                    1 XX             (M,m)       p
                                   √            Wi kUN0 ,N1 ,i k → 0,
                                     N1 i=1 m=1
     √
so       N1 RN vanishes asymptotically.
     The conditions of Proposition 1 assume that all covariates have continuous distributions.
This is done without loss of generality. Discrete covariates with a finite number of support
points can be easily dealt with by conditioning on their values, in which case k is equal to
the number of continuous covariates in X. The proof of Proposition 1 indicates that the
support conditions in this proposition can also be relaxed. However, the requirement that
the size of the untreated group is of larger order of magnitude than the size of the treated
group is crucial to the result in the proposition. To see that r = 1 is not sufficient (even
in the one-dimensional case), consider the case with M = 1 and N0 = N1 . Then, because
matching is done without replacement and all treated units are matched, the matching

                                                      8
estimator is equal to the difference in sample means of Y between treated and nontreated,
regardless of the total sample size N .
    Proposition 1 provides conditions under which matching discrepancies are negligible in
large samples. In practical terms, Proposition 1 demonstrates the benefits of having a large
“donor pool” of control units for matching estimators. Notice however that, for particular
applications, researchers can assess the quality of the matches directly from the data. When
matching discrepancies are large the resulting bias can be eliminated or reduced using the
bias correction techniques in Rubin (1973b), Quade (1982), and Abadie and Imbens (2009).
These authors propose a bias-corrected matching estimator that adjusts each matched pair
for its contribution to the conditional bias term:
                            N
                        1 X                        1     X                           
                 τbbc =        Wi (Yi − µ
                                        b0 (Xi )) −                 (Yj − µ
                                                                          b0 (Xj(i) )) ,            (4)
                        N1 i=1                      M
                                                         j∈JM (i)


where µ
      b0 (·) is an estimator of µ0 (·). Abadie and Imbens (2009) show that under cer-
tain conditions this bias-correction technique eliminates the asymptotic bias of matching
estimators without affecting the asymptotic variance.
                                                                                  √
    Under the conditions of Proposition 1, the conditional bias term,                 N1 RN , is asymp-
totically negligible, so we obtain:
                                    p          d
                                     N1 τb − τ → N (0, σ 2 ),

where σ 2 is given in equation (3). Straightforward calculations show that the variance
estimator
                                        N
                                   1 X              1     X               2
                          b2 =
                          σ                 W i Yi −                Yj − τb                         (5)
                                 N1 − 1 i=1          M
                                                         j∈JM (i)

is consistent for σ 2 .
                                                                            b2 /N1 as an
    Despite the simplicity of this result, to our knowledge the validity of σ
estimator of the variance of τb when matching is done without replacement has not been
                                                     b2 /N1 is not a valid estimator of the
established previously. Conversely, it is known that σ
variance of τb when matching is done with replacement (Abadie and Imbens, 2006).



                                               9
                       V. Application: Hot Deck Imputation

In this section, we consider a “cell hot deck” imputation scheme where incomplete records
of Y are imputed using complete observations within the same “cell” of the covariates,
X. That is, the support of the covariates is partitioned into T cells, C1 , . . . CT , and each
incomplete record of Y is filled using a complete record from the same cell. Other hot deck
imputation procedures are possible (see, for example, Little and Rubin, 2002). However,
the cell hot deck methods is probably the most widely used in practice, as it is the one
used by the US Census Bureau to impute missing data in the Current Population Survey
(CPS), the decennial census, the Survey of Income and Program Participation (SIPP), and
other large surveys. Derivations similar to the ones presented in this section can be applied
to alternative hot deck imputation schemes.
   Cell hot deck imputation methods like the one employed in the CPS can be justified by
a “Missing and Coarsening at Random” assumption. Let W be an indicator for complete
record, that is W = 1 indicates that Y is observed. A missing and coarsening at random
assumption states that Y is independent of (X, W ) conditional on X ∈ Ct , for 1 ≤ t ≤ T .
Missing and coarsening at random may be a strong assumption in many contexts where
data are imputed using the cell hot deck. However, without this assumption, or a similar
one, the cell hot deck will produce inconsistent estimators in general. Therefore, in our
analysis we assume missing and coarsening at random. Let µ = E[Y ], µ(x) = E[Y |X = x],
µt = E[Y |X ∈ Ct ] and σt2 = var(Y |X ∈ Ct ). Let j(i) be the index of the observation used
to impute Y for observation i (if Wi = 1, then j(i) = i). Let
                                         N
                                      1 X
                                 Ȳ =       Yj(i)
                                      N i=1
                                        N
                                     1 X
                                   =       Wi (1 + KN,i )Yi ,                              (6)
                                     N i=1
where now KN,i is the number of times that observation i is used to impute an incomplete
record. The variables KN,i depend on how imputations are chosen from the complete
records within a cell. One possibility is the random cell hot deck, which imputes missing
records using a record chosen at random among the complete observation in the same cell.

                                              10
The CPS and other large surveys use a more complicated procedure called the sequential
cell hot deck. The sequential cell hot deck imputes missing records using the last complete
record in the same cell. That is, unlike the random cell hot deck, the sequential cell hot
deck uses information about the order of the observations in the sample.
   Notice that
                                              N
                                           1 X
                                  Ȳ − µ =       (µ(Xi ) − µ)
                                           N i=1
                                             N
                                          1 X
                                        +       Wi (1 + KN,i )(Yi − µ(Xi ))
                                          N i=1
                                             N
                                          1 X
                                        +       (µ(Xj(i) ) − µ(Xi )).
                                          N i=1

By the Missing and Coarsening at Random assumption, µ(Xj(i) ) − µ(Xi ) = 0 for all i.
Assume that the second moment of KN,i exists, and that for each cell, t, we have:
            N
                                              "     N
                                                                                 #
         1 X                                    1  X                               p
               1{Xi ∈Ct } Wi (1 + KN,i )2 − E          1{Xi ∈Ct } Wi (1 + KN,i )2 −→ 0,                      (7)
        Nt i=1                                  Nt i=1

which can be usually established using negative association properties of {KN,i s.t. Wi =
1, Xi ∈ Ct } (Joag-Dev and Proschan, 1983). We can write:
                                                             2N
                                              Ȳ − µ X
                                                 √ =     ξN,k ,
                                              σ/ N   k=1

where
                "   T                   #       "   T                 N
                                                                                                       #
                    X   Nt                            X   Nt          1  X
      σ2 = E                      (µt − µ)2 + E                   σt2        1{Xi ∈Ct } Wi (1 + KN,i )2 ,
                    t=1
                              N                       t=1
                                                             N        Nt i=1

and
                         1
                
                         √
                         (µ(Xk ) − µ)                                          if 1 ≤ k ≤ N,
        ξN,k   =   σ   N
                     1                                 
                  √ Wk−N (1 + KN,k−N ) Yk−N − µ(Xk−N )
                                                                              if N + 1 ≤ k ≤ 2N.
                   σ N
Let XN = {X1 , . . . , XN }, WN = {W1 , . . . , WN } and JN = {j(1), . . . , j(N )}.                        Con-
sider the σ-fields FN,k = σ{WN , X1 , . . . , Xk } for 1 ≤ k ≤ N and FN,k = σ{WN , XN ,

                                                        11
JN , Y1 , . . . , Yk−N } for N + 1 ≤ k ≤ 2N . Then,
                                    ( i                            )
                                      X
                                          ξN,j , FN,i , 1 ≤ i ≤ 2N
                                        j=1

is a martingale for each N ≥ 1. Equation (7) along with the Central Limit Theorem for
martingale arrays (e.g., Theorem 3.2 in Hall and Heyde, 1980) imply:
                                            Ȳ − µ d
                                               √ −→ N (0, 1).
                                            σ/ N
Consider now the usual variance estimator that ignores missing data imputation:
                                                     N
                                        2    1 X
                                       σ
                                       b =           (Yj(i) − Ȳ )2 .                       (8)
                                           N − 1 i=1

Notice that
                                 T                       T     
                          2
                                 X   Nt               2
                                                           X   Nt            p
                        b −
                        σ                     (µt − µ) −                 σt2 −→ 0.
                                 t=1
                                        N                  t=1
                                                                 N
                        PN
In addition, because       i=1   1{Xi ∈Ct } Wi (1 + KN,i ) = Nt , then
                  N                                      N
              1 X                             2      1 X                    2
                     1{Xi ∈Ct } Wi (1 + KN,i ) = 1 +        1{Xi ∈Ct } Wi (KN,i + KN,i ).
              Nt i=1                                 Nt i=1

This suggests using the following estimator of the variance of the re-scaled estimator:
                                T      N
                                                                       !
                2            1 X      X
              σbadj  b2 +
                    =σ                                    2
                                         1{Xi ∈Ct } Wi (KN,i   + KN,i ) σbt2
                           N t=1 i=1
                             T              N
                                                                               !
                           X      N t     1  X
                     b2 +
                    =σ                                             2
                                                   1{Xi ∈Ct } Wi (KN,i + KN,i ) σbt2 .  (9)
                            t=1
                                  N      N t i=1

      bt2 is the sample variance of Y calculated from the complete observations in cell Ct .
where σ
Notice that this formula applies no matter how imputation is done within the cells (for
example, randomized or based on the order of the observations in the sample) as long as
equation (7) holds.


                                   VI. Monte Carlo Analysis

This section reports the results of two Monte Carlo simulations based on actual data.
Section VI.A uses the Boston HMDA data set, a data set collected by the Federal Reserve

                                                    12
Bank of Boston to investigate racial discrimination in mortgage credit markets, to assess
the quality of the large sample approximation to the distribution of matching estimators
derived in section IV. Section VI.B uses CPS data to investigate the performance of the
standard error correction for missing data imputation derived in section V.


A. Matching without Replacement in the Boston HMDA Dataset

In order to detect potential discriminatory practices of mortgage credit lenders against
minority applicants, the U.S. Home Mortgage Disclosure Act (HMDA) of 1975 requires
lenders to routinely disclose information on mortgage applications, including the race and
ethnicity of the applicants. The information collected under the HMDA does not include,
however, data on the credit histories of the applicants, and other loan and applicant char-
acteristics that are considered to be important factors in determining the approval or denial
of mortgage loans. The absence of such information has generated some skepticism about
whether the HMDA data can effectively be used to detect discrimination in the mortgage
credit market. To overcome this criticism, the Federal Reserve Bank of Boston collected an
additional set of 38 variables included in mortgage applications for a sample of applications
in the Boston metropolitan area in 1990. The Boston HMDA data set includes all mortgage
applications by black and Hispanic applicants in the Boston metropolitan area in 1990, as
well as a random sample of mortgage applications by white applicants in the same year and
geographical area. Regression analysis of the Boston HMDA data indicated that minority
applicants were more likely to be denied mortgage than white applicants with the same
characteristics (Munnell et al., 1996).
   In this section, we use the Boston HMDA data set to evaluate the empirical performance
of the large sample approximation to the distribution of matching estimators derived in
section IV. The HMDA data provides a relevant context for this evaluation because the
Federal Reserve System employs matching in the HMDA data as an screening device for
fair lending regulation compliance (Avery, Beeson, and Calem, 1997, Avery, Canner, and
Cook, 2005). We restrict our sample to single-family residences and male applicants who
are white non-Hispanic or black non-Hispanic, not self-employed, who were approved for

                                             13
private mortgage insurance, and who do not have a public record of default or bankruptcy
at the time of the application. This leaves us with a sample of 148 black applicants and
1336 white applicants, for a total of 1484 applicants.
   In the context of this application, the outcome variable, Y , is an indicator variable that
takes value one if the mortgage application was denied, and zero if the mortgage application
was approved, W is a binary indicator that takes value one for black applicants, and X is
a vector of six applicant and loan characteristics used in Munnell et al. (1996): housing
expense to income ratio, total debt payments to income ratio, consumer credit history,
mortgage credit history, regional unemployment rate in the applicant’s industry, and loan
amount to appraised value ratio (see Munnell et al., 1996, for a precise definition of these
variables).
   To run our simulations for samples sizes of N1 black observations and N0 white obser-
vations we proceed in five steps. First, for the entire sample, we estimate a logistic model
of the mortgage denial indicator on the black indicator and the covariates in X. Second,
we draw (with replacement) N1 observations from the empirical distribution of X for black
applicants and N0 observations from the empirical distribution of X for white applicants.
Third, for each individual in the simulated sample, we generate the mortgage denial indica-
tor, Y , using the logistic model estimated in the first step. Fourth, for the simulated sample,
we compute τb, the matching estimator in equation (2), matching without replacement, the
                                                                                              b2 ,
bias-corrected version of this estimator, τbbc , in equation (4), and the variance estimator, σ
in equation (5). All covariates are normalized to have unit variance prior to matching, and
a logistic model is employed to calculate the bias correction. Finally, we repeat steps two
to four for a total number of 10000 simulations. That is, in this simulation we sample from
a population distribution of the covariates that is equal to the distribution of the covariates
in the HMDA sample of 1484 applicants. The distribution of Y conditional W and X in
our simulation is given by a logistic model with parameters equal to those estimated in the
HMDA sample of 1484 applicants. In this Monte Carlo design, the parameter τ in equation
(1) is equal to 0.099, which represents the difference in the probability of denial between



                                               14
black applicants and white applicants of the same characteristics in our simulation.
   Table I reports the results of the simulation, for different sample sizes, N1 and N0 .
Column (1) reports the bias of τb relative to τ . As suggested by the results in section
IV, our simulation results indicate that for a fixed N1 the bias of τb decreases when N0
increases. For small samples, however, the bias of τb may be substantial, reflecting the
high dimensionality of the vector of matching variables. The bias-corrected estimator in
column (2) generates much smaller biases. Columns (3) and (4) report the variance of τb
across simulations and the average, also across simulations, of the variance estimator of τb
                                                                      b2 /N1 provides
in equation (5). Even in fairly small samples (N1 = 25 and N0 = 250), σ
a very precise approximation to the variance of τb. Finally, columns (5) and (6) report
coverage rates of nominal 95% confidence intervals constructed with (b  b2 ) and (b
                                                                     τ, σ               b2 ),
                                                                                  τbc , σ
respectively. The results indicate that, in this simulation, the Normal approximation to
the distribution of matching estimators derived in section IV is very accurate, especially
when the bias of the matching estimator is corrected using the bias correction techniques
in Rubin (1973b), Quade (1982), and Abadie and Imbens (2009).


B. Hot Deck Imputation in the Current Population Survey

Hot deck methods have long been used to impute missing data in large surveys (see, for
example, Andridge and Little, 2010). However, the sampling properties of complex hot deck
imputation methods, like the sequential hot deck used by the Census Bureau in the CPS,
are largely unknown. This void in the literature has become an object of serious concern
in recent years, because the proportion of observations in the CPS with imputed values
of weekly earnings has increased steadily: from around 16 percent in 1979, when weekly
earnings were included in the monthly survey questionnaire, to more than 30 percent in
recent years (Hirsch and Schumacher, 2004; Bollinger and Hirsch, 2009).
   In this section we investigate the performance of the approximation to the distribution
of a sample mean proposed in section V, when data are imputed using a sequential hot
deck like in the CPS. In order to make our exercise as realistic as possible we base our
Monte Carlo design on actual CPS data.

                                             15
   Hot deck imputation in the CPS Outgoing Rotation Groups is done through a series of
steps, each one imputing a specific survey item. Here, we focus on imputation of missing
earnings, because earnings are affected by imputation rates that are much higher than for
other survey items. As for other missing survey items, imputation of weekly earnings for
non-hourly workers is implemented through a cell hot deck procedure. Observations are
assigned to cells defined by age, race, gender, education, occupation, hours worked, and
receipt of overtime wages, tips, or commissions, for a total of 11,520 cells (see Bollinger and
Hirsch, 2006, for details). Then each missing record is imputed using the value of weekly
earnings of last complete record in the same cell.
   The imputation of weekly earnings in the CPS Outgoing Rotation Groups cannot be
perfectly reproduced with the CPS public use data files. The main reason is that the
race variable used by the imputation algorithm is different from the one included in the
public use data release. Nevertheless, the Monte Carlo exercise carried out in this section is
designed to reproduce as closely as possible the imputation algorithm used by the Census
Bureau for weekly earnings. In our simulation we use data from the CPS monthly file
of August 2009. In order to simplify the analysis, we first restrict our sample to male
individuals working for a pay, who are white, aged 25 to 64, have a high school diploma or
equivalent, hold one job only, have a tertiary occupation, do not receive overtime wages,
tips, or commissions, and work 40 hours/week. In addition, we discard four observations
with zero recorded weekly earnings. This leaves us with 856 observations in 30 of the 11,520
original hot deck cells. The 30 hot deck cells are defined by three categories of age, two
of education, and five of occupation. The average number of observations per cell is 28.53,
the minimum is 2, and the maximum is 149. In this sample the percentage of observations
with missing weekly earnings is 32.83, and each cell has at least two complete observations.
   For a fixed number of observations, N , the simulation proceeds as follows. First, for
                                                                   ∗        ∗
each cell t we simulate two observations of log weekly earnings, Yt,1 and Yt,2 , from a normal
distribution with the same mean and variance as in the distribution of log weekly earnings
                                                                         ∗        ∗
for complete the CPS observations in the same cell. In our simulation, Yt,1 and Yt,2 represent



                                              16
the last two complete observations in cell t in previous CPS waves. Second, we sample N
observation from the multinomial distribution of cell frequencies in the CPS sample. For
each of these N observations, we simulate log weekly earnings using a normal distribution
with the same mean and variance as log weekly earnings for complete CPS observations
in the same cell. Then, for each observation we mark weekly earnings as unrecorded with
probability equal to the proportion of missing weekly earnings in the same cell of the CPS
sample. Third, in our simulated sample of N observations, we impute missing log weekly
                                                                                  ∗
earnings using the last complete observation in the cell (which may possibly be Yt,2 ). This
creates a partially imputed sample with N values of log weekly earnings. Four, we calculate
the sample average, Ȳ in equation (6), as well as the usual and adjusted variance estimators:
b2 and σ
σ        2
       badj                                                                              bt2
            in equations (8) and (9), respectively. To compute the intra-cell variances, σ
                                                                                   ∗        ∗
of equation (9), we use all the complete simulated observations in the cell plus Yt,1 and Yt,2 .
                                                 ∗        ∗
Simulating two complete observations per cell, Yt,1 and Yt,2 , that correspond to the last two
                                                                             bt2 even for
complete observations in the cell in previous CPS waves allows us to compute σ
cells with no other complete observations in the simulation. Finally, we repeat steps one
to four for a total number of 50000 simulations.
   The results are reported on Table II for sample sizes 50, 100, 200, and 856, the actual
number of observations in the CPS sample. The average of our adjusted variance estimator
across simulations, in column (2), closely approximates the variance of Ȳ , in column (1),
even for fairly small sample sizes. In contrast, columns (3) and (4) show that the usual
variance estimator is severely downward biased, and that the bias of this estimator (as
a percentage of the true variance) increases with the sample size. For 856 observations,
that is the actual size of the CPS data sample used in the simulation, the usual variance
estimator is only 58 percent of the true variance of Ȳ . Large sample sizes make possible that
some observations are repeatedly used for imputation, increasing the difference between the
adjusted and unadjusted variances in equation (9). This happens when missing observations
arrive consecutively to a cell, without the observation used for imputation being “refreshed”
by another complete observation. Columns (5) and (6) report coverage rates of nominal 95%



                                              17
                                        2
confidence intervals constructed with σ
                                      badj     b2 , respectively. The results show coverage
                                           and σ
rates close to nominal coverage in column (5), when the adjusted variance estimator is used
to construct confidence interval. In contrast, confidence intervals calculated with the usual
variance estimator suffer from severe under-coverage, as reported in column (6).


                                    VII. Conclusion

This article establishes a martingale array representation for matching estimators. This
representation allows the use of well-known martingale limit theorems to determine the
large sample distribution of matching estimators. Because the martingale representation
applies to a large class of matching estimators, the applicability of the methods presented
in this article is very broad. Specific applications include matching estimators of average
treatment effects as well as “hot deck” imputation methods for missing data. Two realistic
simulations demonstrate the empirical relevance of the results of this article.




                                             18
                                            Appendix

Proposition 1: Let F0 and F1 be the distributions of X given W = 0 and X given W =              1,
respectively. Assume that F0 and F1 have a common support that is a Cartesian product           of
intervals, and that the densities f0 (x) and f1 (x) are bounded and bounded away from zero: f   ≤
f0 ≤ f¯ and f ≤ f1 ≤ f¯. Assume that there exists c > 0 and r > k where k is the number         of
(continuous) covariates, such that N1r /N0 ≤ c. Then,
                                       N M
                                  1 XX             (M,m)       p
                                 √            Wi kUN0 ,N1 ,i k → 0.
                                   N1 i=1 m=1

Proof of Proposition 1: By changing units of measurement, we can always make the support
of the covariates equal to the unit k-cube. (This only adds a multiplicative constant to our
bounds.) Notice that we can always divide a unit k-cube into N1k identical cubes, for N1 =
1, 2, 3, . . ..
     Divide the support of F0 and F1 into N1k identical cubes. Let ZM,N0 ,N1 be the number of such
cells where the number of untreated observation is less than M times the number of observations
from the treated sample. Let MN1 be the maximum number of observations from the treated
sample in a single cell. Let mN0 ,N1 be the minimum number of untreated observations in a single
cell. Notice that for any series, f (N1 ), such that 1 ≤ f (N1 ) < N1 , we have:
                                        N1
                                        X
                Pr(ZM,N0 ,N1 > 0) ≤           Pr(mN0 ,N1 < M n) Pr(MN1 = n)
                                        n=1
                                        bf (N1 )c
                                          X
                                    ≤               Pr(mN0 ,N1 < M n) Pr(MN1 = n)
                                         n=1
                                         N1
                                         X
                                    +                Pr(mN0 ,N1 < M n) Pr(MN1 = n)
                                     n=bf (N1 )c+1
                                    ≤ f (N1 ) Pr(mN0 ,N1 < M f (N1 ))
                                    + (N1 − f (N1 )) Pr(MN1 > f (N1 )).

Let DN1 ,n be the number of cells where the number of treated observations is larger than n. Let
0 < α < min{r − k, 1}. Consider f (N1 ) = N1α . For N1 large enough, f¯/N1k < 1. Using Bonferroni
Inequality we obtain for N1 large enough:

                      Pr(MN1 > f (N1 )) = Pr(DN1 ,N1α ≥ 1)
                                        ≤ N k Pr B(N1 , f¯/N k ) > N α ,
                                                                      
                                                     1              1     1

where B(N, p) denotes a Binomial random variable with parameters (N, p). Using Bennett’s
bound for binomial tails (e.g., Shorack and Wellner, 1996, p. 440), we obtain:
                                                                                    !
                                        B(N 1 , ¯/N k ) − f¯/N k−1
                                                f                    N α − f¯/N k−1
   Pr B(N1 , f¯/N1 ) > N1
                 k        α                        1          1        1       1
                            
                               = Pr               √                >     √
                                                    N1                      N1


                                                    19
                                         (        "                        !   !   #)
                                        f¯/N1k−1 N1α+k−1           N1α+k−1
                               ≤ exp −                      log              −1 +1
                                       1 − f¯/N1k      f¯             f¯
                                    (             "                   !     !      #)
                                            1               N  α+k−1
                                                                                f¯
                               = exp −              N1α log   1
                                                                         − 1 + k−1    .
                                       1 − f¯/N1k               f¯             N1

Similarly, let CN0 ,N1 ,m be the number of cells with less than m untreated observations. Then,
using Bonferroni Inequality:

                          Pr(mN0 ,N1 < m) = Pr(CN0 ,N1 ,m ≥ 1)
                                                     N1   k
                                                     X                          
                                                ≤             Pr B(N0 , pn ) < m ,
                                                     n=1

where pn is the probability that an untreated observation falls in cell n. Then, because for all n,
pn ≥ f /N1k , we obtain:

                         Pr(mN0 ,N1 < m) ≤ N1k Pr B(N0 , f /N1k ) < m .
                                                                        


Also, for large enough N1 , there exists δ such that (M c/f )/N1r−α−k < δ < 1. Using Chernoff’s
bound for the lower tail of a sum of independent Poisson trials (e.g., Motwani and Raghavan,
1995, p. 70), we obtain that for large enough N1 :
                                                                              !
                                                                          α+k
                                                                  N 0 M N
          Pr B(N0 , f /N1k ) < M N1α = Pr B(N0 , f /N1k ) < f k           1
                                    
                                                                 N1 f N0
                                                                              !
                                                                  N 0  M c/f
                                       ≤ Pr B(N0 , f /N1k ) < f k r−α−k
                                                                 N1 N1
                                                                               2 
                                       ≤ exp −(f N0 /N1k ) 1 − (M c/f )/N1r−α−k /2
                                                                    
                                       ≤ exp −f N1r−k (1 − δ)2 /2c .

This proves an exponential bound for Pr(ZM,N0 ,N1 > 0).
    Rearrange the observations so the first N1 observations in the sample are the treated obser-
                                (M,m)
vations. For 1 ≤ i ≤ N1 , let kUN0 ,N1 ,i k be the m-th matching discrepancy for treated unit i when
untreated units are matched without replacement to treated units in such a way that the sum of
                                                                      (M,m)
the matching discrepancies is minimized. For 1 ≤ i ≤ N1 , let kVN0 ,N1 ,i k be the m-th matching
discrepancy for treated unit i when untreated units are matched without replacement to treated
units in such a way that the matches are first done within cells and, after all possible within-cell
matches are exhausted, untreated units that were not previously used as a match are matched
without replacement to previously unmatched treated units in other cells. Notice that:
                             N1 X
                                M                         N1 X
                                                             M
                                           (M,m)                       (M,m)
                             X                            X
                                        kUN0 ,N1 ,i k ≤             kVN0 ,N1 ,i k.
                              i=1 m=1                     i=1 m=1

Let dN1 ,k be the diameter of the cells. Let Ck be the diameter of the unit k-cube. Notice that if
the unit k-cube is divided in N1k identical cells, then Ck = N1 dN1 ,k . For 1 ≤ n ≤ N1k , let AN1 ,n

                                                    20
be the n-th cell. Then,

                                                     N1    k
                h                                 i
                      (M,m)
                                                     X
            E       kVN0 ,N1 ,i k   ZM,N0 ,N1   =0 ≤    dN1 ,k Pr(X1,i ∈ AN1 ,n |ZN0 ,N1 = 0)
                                                         n=1
                                                      ≤ dN1 ,k
                                                        Ck
                                                      =    .
                                                        N1
Now,
        N1 X M                                       N1 X M
  "                                  #           "                      #
    1 X           (M,m)                           1 X          (M,m)
 E √            kUN0 ,N1 ,i k            ≤   E √            kV         k
     N1 i=1 m=1                                   N1 i=1 m=1 N0 ,N1 ,i
                                                     N1 X M
                                              "                                       #
                                                  1 X          (M,m)
                                         =   E √            kV         k ZM,N0 ,N1 = 0 Pr(ZM,N0 ,N1 = 0)
                                                  N1 i=1 m=1 N0 ,N1 ,i
                                                     N1 X M
                                              "                                       #
                                                  1 X          (M,m)
                                         +   E √            kV         k ZM,N0 ,N1 > 0 Pr(ZM,N0 ,N1 > 0)
                                                  N1 i=1 m=1 N0 ,N1 ,i
                                                Ck    p
                                         ≤   M√     + N1 M Ck Pr(ZM,N0 ,N1 > 0) −→ 0.
                                                 N1
Markov’s Inequality produces the desired result.                                                       




                                                         21
                                       References

Abadie, A. and Imbens, G.W. (2006), “Large Sample Properties of Matching Estimators for
   Average Treatment Effects,” Econometrica , vol. 74, no. 1, 235-267.

Abadie, A. and Imbens, G.W. (2008), “On the Failure of the Bootstrap for Matching Estima-
   tors,” Econometrica , vol. 76, no. 6, 1537-1558.

Abadie, A. and Imbens, G.W. (2009), “Bias Corrected Matching Estimators for Average
   Treatment Effects,” Journal of Business and Economic Statistics (forthcoming).

Andridge, R.R. and Little, R.J.A. (2010), “A Review of Hot Deck Imputation for Survey
   Non-response,” International Statistical Review (forthcoming).

Avery, R.B., Beeson, P.E., and Calem, P.S. (1997), “Using HMDA Data as a Regulatory
    Screen for Fair Lending Compliance,” Journal of Financial Services Research, vol. 11, 9-42.

Avery, R.B, Canner, G.B., and Cook, R.E. (2005), “New Information Reported Under
    HMDA and Its Application in Fair Lending Enforcement,” Federal Reserve Bulletin, vol.
    91, 344-394.

Billingsley, P. (1995), Probability and Measure, third edition. Wiley, New York.

Bollinger, C.R. and Hirsch, B.T. (2009), “Wage Gap Estimation with Proxies and Nonre-
   sponse,” mimeo.

Dehejia, R. and Wahba, S. (1999), “Causal Effects in Nonexperimental Studies: Reevaluating
   the Evaluation of Training Programs,” Journal of the American Statistical Association, 94,
   1053-1062.

Diamond, A. and Sekhon, J.S. (2008), “Genetic Matching for Estimating Causal Effects: A
    New Method of Achieving Balance in Observational Studies,” UC Berkeley.

Gu, X.S. and Rosenbaum, P.R. (1993), “Comparison of Multivariate Matching Methods:
    Structures, Distances and Algorithms,” Journal of Computational and Graphical Statistics,
    2, 405-420.

Hall, P. and Heyde C.C. (1980), Martingale Limit Theory and its Applications. Academic
   Press, New York.

Hansen, B.B. (2004), “Full Matching in an Observational Study of Coaching for the SAT,”
   Journal of the American Statistical Association, 99, 609-618.

Heckman, J., Ichimura, H., and Todd, P. (1998), “Matching as an Econometric Evaluation
   Estimator,” Review of Economic Studies, vol. 65, 261-294.

Hirsch, B.T. and Schumacher, E.J. (2004), “Match Bias in Wage Gap Estimates Due to
    Earnings Imputation,” Journal of Labor Economics, vol. 22, no. 3, 689-722.

Iacus, S.M., King, G., and Porro, G. (2009),“Causal Inference Without Balance Checking:
    Coarsened Exact Matching,” mimeo.

                                             22
Imbens, G.W. (2004), “Nonparametric Estimation of Average Treatment Effects under Exo-
    geneity: A Review,” Review of Economics and Statistics , vol. 86, no. 1, 4-29.

Little, R.J.A. and Rubin, D.B. (2002), Statistical Analysis with Missing Data, second edition.
    Wiley-Interscience, New York.

Motwani, R. and Raghavan, P. (1995), Randomized Algorithms. Cambridge University Press,
   New York.

Munnell, A.H., Tootell, G.M.B., Browne, L.E. and McEneaney, J. (1996), “Mortgage
   Lending in Boston: Interpreting HMDA Data,” American Economic Review, vol. 86, no.
   1, 25-53.

Quade, D. (1982), “Nonparametric Analysis of Covariance by Matching”, Biometrics, 38, 597-
   611.

Rosenbaum, P.R. (2002), Observational Studies, second edition. Springer, New York.

Rubin, D.B. (1973a), “Matching to Reduce Bias in Observational Studies,” Biometrics, 29,
    159-183.

Rubin, D.B. (1973b), “The Use of Matched Sampling and Regression Adjustments to Remove
    Bias in Observational Studies,” Biometrics, 29, 185-203.

Rubin, D.B. (1977), “Assignment to Treatment Group on the Basis of a Covariate”, Journal of
    Educational Statistics, 2, 1-26.

Rubin, D.B. (2006), Matched Sampling for Causal Effects. Cambridge University Press, New
    York.

Shorack, G.R. (2000), Probability for Statisticians. Springer, New York.

Shorack, G.R. and Wellner, J.A. (1986), Empirical Processes with Applications to Statistics.
   Wiley, New York.




                                             23
                             Table I – Boston HMDA Data, Simulation Results
                 Black-White Difference in Mortgage Denial Probability for Matched Pairs
                                       (Number of simulations = 10000)
    Sample sizes                   Bias                    Variance             Coverage of 95% C.I.
                           (1)            (2)          (3)        (4)           (5) √            (6) √
                       |E[b
                          τ ] − τ | |E[b τbc ] − τ | var(b
                                                         τ ) E[b   2
                                                                 σ /N1 ]  τb±1.96 σ
                                                                                  b/ N1 τbbc ±1.96 σb / N1
N1 = 25   N0 = 250       0.0143         0.0012       0.0091     0.0091        0.9225           0.9348
          N0 = 500       0.0106         0.0001       0.0092     0.0091        0.9244           0.9394
          N0 = 1000      0.0077         0.0002       0.0090     0.0091        0.9263           0.9430
N1 = 50   N0 = 500       0.0106         0.0011       0.0045     0.0045        0.9427           0.9458
          N0 = 1000      0.0073         0.0009       0.0044     0.0046        0.9427           0.9456
N1 = 100 N0 = 1000       0.0090         0.0001       0.0023     0.0023        0.9436           0.9468




                                                   24
            Table II – Current Population Survey Data, Simulation Results
                              Average Log Weekly Earnings
                            (Number of simulations = 50000)
Sample size             Variance             Ratio          Coverage of 95% C.I.
               (1)        (2)         (3)      (4)           (5) √            (6) √
   N         var(Ȳ ) E[b 2
                         σadj /N ] E[b 2
                                     σ /N ] (3)/(1) Ȳ ±1.96 σbadj / N Ȳ ±1.96 σb/ N
   50        0.0072     0.0071      0.0052   0.7262        0.9436           0.8973
  100        0.0039     0.0039      0.0026   0.6701        0.9476           0.8888
  200        0.0021     0.0021      0.0013   0.6342        0.9492           0.8799
  856        0.0005     0.0005      0.0003   0.5834        0.9482           0.8661




                                       25
