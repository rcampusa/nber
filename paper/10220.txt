                                 NBER WORKING PAPER SERIES




                    MEASURING THE EFFECTS OF MONETARY POLICY:
                          A FACTOR-AUGMENTED VECTOR
                        AUTOREGRESSIVE (FAVAR) APPROACH

                                            Ben S. Bernanke
                                              Jean Boivin
                                              Piotr Eliasz

                                         Working Paper 10220
                                 http://www.nber.org/papers/w10220


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                      January 2004




Thanks to Christopher Sims, Mark Watson, Tao Zha and participants at the 2003 NBER Summer Institute
for useful comments. Boivin would like to thank National Science Foundation for financial support (SES-
0214104). The views expressed herein are those of the authors and not necessarily those of the National
Bureau of Economic Research.

©2003 by Ben S. Bernanke, Jean Boivin, and Piotr Eliasz. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit, including ©
notice, is given to the source.
Measuring the Effects of Monetary Policy:
A Factor-Augmented Vector Autoregressive (FAVAR) Approach
Ben S. Bernanke, Jean Boivin, and Piotr Eliasz
NBER Working Paper No. 10220
January 2004
JEL No. E3, E4, E5, C3

                                            ABSTRACT

Structural vector autoregressions (VARs) are widely used to trace out the effect of monetary policy

innovations on the economy. However, the sparse information sets typically used in these empirical

models lead to at least two potential problems with the results. First, to the extent that central banks

and the private sector have information not reflected in the VAR, the measurement of policy

innovations is likely to be contaminated. A second problem is that impulse responses can be

observed only for the included variables, which generally constitute only a small subset of the

variables that the researcher and policymaker care about. In this paper we investigate one potential

solution to this limited information problem, which combines the standard structural VAR analysis

with recent developments in factor analysis for large data sets. We find that the information that our

factor-augmented VAR (FAVAR) methodology exploits is indeed important to properly identify the

monetary transmission mechanism. Overall, our results provide a comprehensive and coherent

picture of the effect of monetary policy on the economy.

Ben Bernanke                                           Piotr Eliasz
Board of Governors of the Federal Reserve              Princeton University
20th Street and Constitution Avenue, NW                001 Fisher Hall
Washington, DC 20551                                   Princeton, NJ 08544
ben.s.bernanke@frb.gov                                 peliasz@princeton.edu

Jean Boivin
Columbia Business School
Uris Hall, Room 719
3022 Broadway
New York, NY 10027-6902
and NBER
jb903@columbia.edu
1. Introduction

       Since Bernanke and Blinder (1992) and Sims (1992), a considerable literature has

developed that employs vector autoregression (VAR) methods to attempt to identify and

measure the effects of monetary policy innovations on macroeconomic variables (see

Christiano, Eichenbaum, and Evans, 2000, for a survey). The key insight of this

approach is that identification of the effects of monetary policy shocks requires only a

plausible identification of those shocks (for example, as the unforecasted innovation of

the federal funds rate in Bernanke and Blinder, 1992) and does not require identification

of the remainder of the macroeconomic model. These methods generally deliver

empirically plausible assessments of the dynamic responses of key macroeconomic

variables to monetary policy innovations, and they have been widely used both in

assessing the empirical fit of structural models (see, for example, Boivin and Giannoni,

2003; Christiano, Eichenbaum, and Evans, 2001) and in policy applications.

       The VAR approach to measuring the effects of monetary policy shocks appears to

deliver a great deal of useful structural information, especially for such a simple method.

Naturally, the approach does not lack for criticism. For example, researchers have

disagreed about the appropriate strategy for identifying policy shocks (Christiano,

Eichenbaum, and Evans, 2000, survey some of the alternatives; see also Bernanke and

Mihov, 1998). Alternative identifications of monetary policy innovations can, of course,

lead to different inferences about the shape and timing of the responses of economic

variables. Another issue is that the standard VAR approach addresses only the effects of

unanticipated changes in monetary policy, not the arguably more important effects of the




                                                                                            1
systematic portion of monetary policy or the choice of monetary policy rule (Sims and

Zha, 1998; Cochrane, 1996; Bernanke, Gertler, and Watson, 1997).

        Several criticisms of the VAR approach to monetary policy identification center

around the relatively small amount of information used by low-dimensional VARs.                      To

conserve degrees of freedom, standard VARs rarely employ more than six to eight

variables.1 This small number of variables is unlikely to span the information sets used

by actual central banks, who are known to follow literally hundreds of data series, or by

the financial market participants and other observers. The sparse information sets used in

typical analyses lead to at least two potential sets of problems with the results. First, to

the extent that central banks and the private sector have information not reflected in the

VAR analysis, the measurement of policy innovations is likely to be contaminated. A

standard illustration of this potential problem, which we explore in this paper, is the Sims

(1992) interpretation of the so-called “price puzzle”, the conventional finding in the VAR

literature that a contractionary monetary policy shock is followed by a slight increase in

the price level, rather than a decrease as standard economic theory would predict. Sims’s

explanation for the price puzzle is that it is the result of imperfectly controlling for

information that the central bank may have about future inflation. If the Fed

systematically tightens policy in anticipation of future inflation, and if these signals of

future inflation are not adequately captured by the data series in the VAR, then what

appears to the VAR to be a policy shock may in fact be a response of the central bank to

new information about inflation. Since the policy response is likely only to partially

offset the inflationary pressure, the finding that a policy tightening is followed by rising


1
  Leeper, Sims, and Zha (1996) increase the number of variables included by applying Bayesian priors, but
their VAR systems still typically contain less than 20 variables.


                                                                                                          2
prices is explained. Of course, if Sims’ explanation of the price puzzle is correct, then all

the estimated responses of economic variables to the monetary policy innovation are

incorrect, not just the price response.

         A second problem arising from the use of sparse information sets in VAR

analyses of monetary policy is that impulse responses can be observed only for the

included variables, which generally constitute only a small subset of the variables that the

researcher and policymakers care about. For example, both for policy analysis and model

validation purposes, we may be interested in the effects of monetary policy shocks on

variables such as total factor productivity, real wages, profits, investment, and many

others. Another reason to be interested in the responses of many variables is that no

single time series may correspond precisely to a particular theoretical construct. The

concept of “economic activity”, for example, may not be perfectly represented by

industrial production or real GDP. To assess the effects of a policy change on “economic

activity”, therefore, one might wish to observe the responses of multiple indicators

including, say, employment and sales, to the policy change.2 Unfortunately, as we have

already noted, inclusion of additional variables in standard VARs is severely limited by

degrees-of-freedom problems.

         Is it possible to condition VAR analyses of monetary policy on richer information

sets, without giving up the statistical advantages of restricting the analysis to a small

number of series? In this paper we consider one approach to this problem, which

combines the standard VAR analysis with factor analysis.3 Recent research in dynamic


2
  An alternative is to treat “economic activity” as an unobserved factor with multiple observable indicators.
That is essentially the approach we take in this paper.
3
  Lippi and Reichlin (1998) consider a related latent factor approach that also exploits the information from
a large data set. Their approach differs in that they identify the common factors as the structural shocks,


                                                                                                            3
factor models suggests that the information from a large number of time series can be

usefully summarized by a relatively small number of estimated indexes, or factors. For

example, Stock and Watson (2002) develop an approximate dynamic factor model to

summarize the information in large data sets for forecasting purposes.4 They show that

forecasts based on these factors outperform univariate autoregressions, small vector

autoregressions, and leading indicator models in simulated forecasting exercises.

Bernanke and Boivin (2003) show that the use of estimated factors can improve the

estimation of the Fed’s policy reaction function.

        If a small number of estimated factors effectively summarize large amounts of

information about the economy, then a natural solution to the degrees-of-freedom

problem in VAR analyses is to augment standard VARs with estimated factors. In this

paper we consider the estimation and properties of factor-augmented vector

autoregressive models (FAVARs), then apply these models to the monetary policy issues

raised above.

        The rest of the paper is organized as follows. Section 2 lays out the theory and

estimation of FAVARs. We consider both a two-step estimation method, in which the

factors are estimated by principal components prior to the estimation of the factor-

augmented VAR; and a one-step method, which makes use of Bayesian likelihood

methods and Gibbs sampling to estimate the factors and the FAVAR simultaneously.

Section 3 applies the FAVAR methodology and revisits the evidence on the effect of


using long-run restrictions. In our approach, the latent factors correspond instead to concepts such as
economic activity. While complementary to theirs, our approach allows 1) a direct mapping with existing
VAR results, 2) measurement of the marginal contribution of the latent factors and 3) a structural
interpretation to some equations, such as the policy reaction function.
4
  In this paper we follow the Stock and Watson approach to the estimation of factors (which they call
“diffusion indexes”). We also employ a likelihood-based approach not used by Stock and Watson. Sargent



                                                                                                     4
monetary policy on wide range of key macroeconomic indicators. In brief, we find that

the information that the FAVAR methodology extracts is indeed important and leads to

broadly plausible estimates for the responses of a wide variety of macroeconomic

variables to monetary policy shocks. We also find that the advantages of using the

computationally more burdensome Gibbs sampling procedure instead of the two-step

method appear to be modest in this application. Section 4 concludes. An appendix

provides more detail concerning the application of the Gibbs sampling procedure to

FAVAR estimation.



2. Econometric framework and estimation



        Let Yt be an M × 1 vector of observable economic variables assumed to have

pervasive effects throughout the economy. For now, we do not need to specify whether

our ultimate interest is in forecasting the Yt or in uncovering structural relationships

among these variables. Following the standard approach, we might proceed by

estimating a VAR, a structural VAR (SVAR), or other multivariate time series model

using data for the Yt alone. However, in many applications, additional economic

information, not fully captured by the Yt , may be relevant to modeling the dynamics of

these series. Let us suppose that this additional information can be summarized by an

K × 1 vector of unobserved factors, Ft , where K is “small”. We might think of the

unobserved factors as diffuse concepts such as “economic activity” or “credit conditions”



and Sims (1977) first provided a dynamic generalization of classical factor analysis. Forni and Reichlin
(1996, 1998) and Forni, Hallin, Lippi, and Reichlin (2000) develop a related approach.


                                                                                                           5
that cannot easily be represented by one or two series but rather are reflected in a wide

range of economic variables. Assume that the joint dynamics of ( Ft , Yt ) are given by:




             Ft           Ft −1 
(2.1)        Y  = Φ ( L)  Y  + ν t
             t            t −1 



where Φ(L) is a conformable lag polynomial of finite order d , which may contain a

priori restrictions as in the structural VAR literature. The error term ν t is mean zero with

covariance matrix Q .

        Equation (2.1) is a VAR in ( Ft , Yt ) . This system reduces to a standard VAR in

Yt if the terms of Φ (L) that relate Yt to Ft −1 are all zero; otherwise, we will refer to

equation (2.1) as a factor-augmented vector autoregression, or FAVAR. There is thus a

direct mapping into the existing VAR results, and (2.1) provides a way of assessing the

marginal contribution of the additional information contained in Ft . Besides, if the true

system is a FAVAR, note that estimation of (2.1) as a standard VAR system in Yt —that

is, with the factors omitted—will in general lead to biased estimates of the VAR

coefficients and related quantities of interest, such as impulse response coefficients.

        Equation (2.1) cannot be estimated directly because the factors Ft are

unobservable. However, if we interpret the factors as representing forces that potentially

affect many economic variables, we may hope to infer something about the factors from

observations on a variety of economic time series. For concreteness, suppose that we

have available a number of background, or “informational” time series, collectively



                                                                                             6
denoted by the N × 1 vector X t . The number of informational time series N is “large”

(in particular, N may be greater than T , the number of time periods) and will be

assumed to be much greater than the number of factors ( K + M << N ). We assume that

the informational time series X t are related to the unobservable factors Ft and the

observable factors Yt by:




(2.2)       X t ' = Λ f Ft '+ Λ yYt '+ et '




where Λ f is an N × K matrix of factor loadings, Λ y is N × M , and the N × 1 vector of

error terms et are mean zero and will be assumed either weakly correlated or

uncorrelated, depending on whether estimation is by principal components or likelihood

methods (see below). Equation (2.2) captures the idea that both Yt and Ft , which in

general can be correlated, represent pervasive forces that drive the common dynamics

of X t . Conditional on the Yt , the X t are thus noisy measures of the underlying

unobserved factors Ft . The implication of equation (2.2) that X t depends only on the

current and not lagged values of the factors is not restrictive in practice, as Ft can be

interpreted as including arbitrary lags of the fundamental factors; thus, Stock and Watson

(1998) refer to equation (2.2) – without observable factors – as a dynamic factor model.

        In this paper we consider two approaches to estimating (2.1)-(2.2). The first one is

a two-step principal components approach, which provides a non-parametric way of

uncovering the space spanned by the common components, Ct = ( Ft ', Yt ') ' , in (2.2). The




                                                                                              7
second is a single-step Bayesian likelihood approach. These approaches differ in various

dimensions and it is not clear a priori that one should be favored over the other.

         The two-step procedure is analogous to that used in the forecasting exercises of

Stock and Watson. In the first step, the common components, Ct , are estimated using the

first K+M principal components of X t .5 Notice that the estimation of the first step does

not exploit the fact that Yt is observed. However, as shown in Stock and Watson (2002),

when N is large and the number of principal components used is at least as large as the

true number of factors, the principal components consistently recover the space spanned

by both Ft and Yt . F̂t is obtained as the part of the space covered by Ĉt that is not

covered by Yt .6 In the second step, the FAVAR, equation (2.1), is estimated by standard

methods, with Ft replaced by F̂t . This procedure has the advantages of being

computationally simple and easy to implement. As discussed by Stock and Watson, it

also imposes few distributional assumptions and allows for some degree of cross-

correlation in the idiosyncratic error term et . However, the two-step approach implies the

presence of “generated regressors” in the second step. To obtain accurate confidence

intervals on the impulse response functions reported below, we implement a bootstrap

procedure, based on Kilian (1998), that accounts for the uncertainty in the factor

estimation.7


5
  A useful feature of this framework, as implemented by an EM algorithm, is that it permits one to deal
systematically with data irregularities. In their application, Bernanke and Boivin (2003) estimate factors in
cases in which X includes both monthly and quarterly series, series that are introduced mid-sample or are
discontinued, and series with missing values.
6
  How this is accomplished depends on the specific identifying assumption used in the second step. We
describe below our procedure for the recursive assumption used in the empirical application.
7
  Note that in theory, when N is large relative to T, the uncertainty in the uncertainty in the factor estimates
can be ignored; see Bai (2002).


                                                                                                               8
       In principle, an alternative is to estimate (2.1) and (2.2) jointly by maximum

likelihood. However, for very large dimensional models of the sort considered here, the

irregular nature of the likelihood function makes MLE estimation infeasible in practice.

In this paper we thus consider the joint estimation by likelihood-based Gibbs sampling

techniques, developed by Geman and Geman (1984), Gelman and Rubin (1992), Carter

and Kohn (1994) and surveyed in Kim and Nelson (1999). Their application to large

dynamic factor models is discussed in Eliasz (2002). Kose, Otrok and Whiteman (2000,

2003) use similar methodology to study international business cycles. The Gibbs

sampling approach provides empirical approximation of the marginal posterior densities

of the factors and parameters via an iterative sampling procedure. As discussed in

Appendix A, we implement a multi-move version of the Gibbs sampler in which factors

are sampled conditional on the most recent draws of the model parameters, and then the

parameters are sampled conditional on the most recent draws of the factors. As the

statistical literature has shown, this Bayesian approach, by approximating marginal

likelihoods by empirical densities, helps to circumvent the high-dimensionality problem

of the model. Moreover, the Gibbs-sampling algorithm is guaranteed to trace the shape of

the joint likelihood, even if the likelihood is irregular and complicated.



       Identification

       Before proceeding, we need to discuss identification of the model (2.1) – (2.2),

specifically the restrictions necessary to identify uniquely the factors and the associated

loadings. In two-step estimation by principal components, the factors are obtained

entirely from the observation equation (2.2), and identification of the factors is standard.




                                                                                               9
In this case we can choose either to restrict loadings by Λ f ' Λ f / N = I or restrict the

factors by F ′F / T = I . Either approach delivers the same common component F Λ f '

and the same factor space. Here we impose the factor restriction, obtaining Fˆ = T Zˆ ,

where the Ẑ are the eigenvectors corresponding to the K largest eigenvalues of XX ′ ,

sorted in descending order. This approach identifies the factors against any rotations.

        In the “one-step” (joint estimation) likelihood method, implemented by Gibbs

sampling, the factors are effectively identified by both the observation equation (2.2) and

the transition equation (2.1). In this case, ensuring identification also requires that we

identify the factors Ft against rotations of the form Ft * = AFt − BYt , where A is K × K

and nonsingular, and B is K × M . We prefer not to restrict the VAR dynamics

described by equation (2.1), and so we need to impose restrictions in the observation

equation, (2.2). Substituting for Ft in (2.2) we obtain




(2.3)     X t = Λ f A −1 Ft* + (Λy + Λ f A −1 B)Yt + et




Hence unique identification of the factors and their loadings requires Λ f A −1 = Λ f and

Λy + Λ f A −1 B = Λ y . Sufficient conditions are to set the upper K × K block of Λ f to an

identity matrix and the upper K × M block of Λ y to zero. The key to identification here

is to make an assumption that restricts the channels by which the Y ’s contemporaneously

affect the X ’s. In principle, since factors are only estimated up to a rotation, the choice

of the block to set equal to an identity matrix should not affect the space spanned by the

estimated factors. The specific choice made restricts, however, the contemporaneous




                                                                                              10
impact of Yt on those K variables and therefore such variables should be chosen for that

block that do not respond contemporaneously to innovations in Yt .

       A separate identification issue concerns the identification of innovations in the

VAR part of the model, such as identifying monetary policy innovations which is the

subject of the next section. Importantly, FAVAR approach affords flexibility in

identifying innovations - once factors are estimated standard procedures (e.g., structural

VAR procedures as in Bernanke and Mihov, 1998) can be applied. One caveat is that use

of the Gibbs sampling methodology may impose significant computational costs when

complex identification schemes are employed. For example, if we impose restrictions that

overidentify the transition equation, we need to perform numerical optimization at each

step of the Gibbs sampling procedure. This may easily become excessively time

consuming. In part for computational simplicity we use a simple recursive ordering in our

empirical application below.

       The two methods differ on many dimensions. A clear advantage of the two-step

approach is computational simplicity. However, this approach does not exploit the

structure of the transition equation in the estimation of the factors. Whether or not this is

a disadvantage depends on how well specified the model is, and from a comparison of the

results from the two methods we may be able to assess whether the advantages of jointly

estimating the model are worth the computational costs.




                                                                                            11
3. Application: The dynamic effects of monetary policy

        As discussed in the Introduction, an extensive literature has employed VARs to

study the dynamic effects of innovations to monetary policy on a variety of economic

variables. A variety of identification schemes have been employed, including simple

recursive frameworks, “contemporaneous” restrictions (on the matrix relating structural

shocks to VAR disturbances), “long-run” restrictions (on the shape of impulse responses

at long horizons), and mixtures of contemporaneous and long-run restrictions.8

Alternative estimation procedures have been employed as well, including Bayesian

approaches (Leeper, Sims, and Zha, 1996). However, the basic idea in virtually all cases

is to identify “shocks” to monetary policy with the estimated innovations to a variable or

linear combination of variables in the VAR. Once this identification is made, estimating

dynamic responses to monetary policy innovations (as measured by impulse response

functions) is straightforward.

        The fact that this simple method typically gives plausible and useful results with

minimal identifying assumptions accounts for its extensive application, both by academic

researchers and by practitioners in central banks. Nevertheless, a number of critiques of

the approach have been made (see, for example, Rudebusch, 1998). Here we focus on

two issues, both related to the fact that degrees-of-freedom problems necessarily limit the

number of time series that can be included in an estimated VAR. We then evaluate the




8
  Recursive frameworks are employed, inter alia, in Bernanke and Blinder (1992), Sims (1992), Strongin
(1995), and Christiano, Eichenbaum, and Evans (2000). Examples of papers with contemporaneous, non-
recursive restrictions are Gordon and Leeper (1994), Leeper, Sims, and Zha (1996), and Bernanke and
Mihov (1998a). Long-run restrictions are employed by Lastrapes and Selgin (1995) and Gerlach and Smets
(1995). Gali (1992) and Bernanke and Mihov (1998b) use a mixture of contemporaneous and long-run
restrictions. Faust and Leeper (1997) and Pagan and Robertson (1998) point out some dangers of relying
too heavily on long-run restrictions for identification in VARs.


                                                                                                   12
ability of FAVARs—which, potentially, can include much more information than

standard VARs—to ameliorate these problems.

         First, as emphasized by Bernanke and Boivin (2003), central banks routinely

monitor a large number of economic variables. One rationale for this practice is that

many variables may contain information that is useful in predicting output, inflation, and

other variables which enter into the central bank’s objective function (Stock and Watson,

2002; Kozicki, 2001). Standard VARs of necessity include only a relatively small

number of time series, implying that the information set employed by the econometrician

differs from (is a subset of) that of the monetary policy-makers. To the extent that

policy-makers react to variables not included in the VAR, monetary policy “shocks” and

the implied dynamic responses of the economy will be mismeasured by the

econometrician.9 A possible example of the effects of shock mismeasurement is the

“price puzzle” discussed in the Introduction. We will check below whether including

broader information set ameliorates the price puzzle.

         Even if monetary policy shocks are properly identified, standard VAR analyses

have the shortcoming that the dynamic responses of only those few variables included in

the estimated VAR can be observed. As discussed in the Introduction, this limitation

may be a problem for at least two reasons. First, for purposes both of policy analysis and

model validation, it is often useful to know the effects of monetary policy on a lengthy




9
  Another source of mismeasurement arises from the fact that most VAR studies typically use revised, as
opposed to “real-time” data. Croushore and Evans (1999) do not find this issue to be important for the
identification of monetary policy shocks, a view consistent with evidence presented in a forecasting context
by Bernanke and Boivin (2003). However, Orphanides (2001) argues that assessment of Fed policy
depends sensitively on whether revised or real-time data are used.


                                                                                                         13
list of variables.10 Second, the choice of a specific data series to represent a general

economic concept (e.g., industrial production for “economic activity”, the consumer price

index for “the price level”) is often arbitrary to some degree, and estimation results may

depend on idiosyncratic features of the particular variable chosen. To assess the effects

of monetary policy on a concept like “economic activity”, it is of interest to observe the

responses of a variety of indicators of activity, not only one or two.

        The FAVAR framework is well-suited for addressing both issues. First, the

estimated system (2.1)-(2.2) can be used to draw out the dynamic responses of not only

the “main” variables Yt but of any series contained in X t . Hence the “reasonableness”

of a particular identification can be checked against the behavior of many variables, not

just three or four. Second, one might also consider constructing the impulse response

functions of factors (or linear combinations of the factors) that can be shown to stand in

for a broad concept like “economic activity.”



        Empirical Implementation

        We applied both the two-step and “one-step” (joint estimation) methodologies to

the estimation of monetary FAVARs. In our applications, X t consists of a balanced

panel of 120 monthly macroeconomic time series (updates of series used in Stock and

Watson, 1998 and 1999). These series are initially transformed to induce stationarity. The

description of the series in the data set and their transformation is described in Appendix

B. The data span the period from January 1959 through August 2001.


10
  One approach to this problem is to assume no feedback from variables outside the basic VAR, that is, a
block-recursive structure with the base VAR ordered first (see Bernanke and Gertler, 1995). However, the
no-feedback assumption is dubious in many cases.


                                                                                                      14
        For the baseline analysis, we assume that the federal funds rate is the only

observable factor, i.e. the only variable included in Yt . In doing so, we treat the federal

funds rate as a factor and interpret it as the monetary policy instrument. This is based on

the presumption that monetary policy has pervasive effect on the economy, X t .

Moreover, the federal funds rate should not suffer from measurement error issues, which

would otherwise imply the presence of an idiosyncratic component in the federal funds

rate. The latent factors are then understood as capturing real activity and general price

movements. A key advantage of this specification is that we do not have to take a stand

on the appropriate measure of the real activity or inflation.

        We order the federal funds rate last and treat its innovations as monetary policy

“shocks”, in the standard way. This ordering imposes the identifying assumption that

latent factors do not respond to monetary policy innovations within the month. To

implement this identification scheme, it is useful to define two categories of variables:

“slow-moving” and “fast-moving”. A “slow-moving” variable is one that is largely

predetermined as of the current period, while a “fast-moving” variable – think of an

asset-price – is highly sensitive to contemporaneous economic news or shocks. The

classification of variables between each category is provided in the data Appendix.

        As discussed above, the joint likelihood estimation only requires that the first K

variables in the data set are selected from the set of “slow-moving” variables and that the

recursive structure is imposed in the transition equation. For the two-step estimation this

identification requires first controlling for the part of Ĉt that corresponds to the federal

funds rate. This is achieved in the following way. First, “slow-moving” factors, F s t , are




                                                                                                15
estimated as the principal components of the “slow-moving” variables. Second, the

following regression,



(3.1)            Cˆ t = bF s Fˆ s t + bY Yt + et ,

is estimated and F̂t constructed from Cˆ t − bˆY Yt . Note that in so far as F̂ s t and Yt are

correlated, so are F̂t and Yt . Finally, the VAR in F̂t and Yt , is estimated and identified

recursively using this ordering.

        The recursive assumption may be subject to criticism if components of the

estimated factors, not accounted for by the federal funds rate, nevertheless respond

contemporaneously to interest rate shocks. One way to address this potential problem

would be to extract “slow-moving” and “fast-moving” factors from the respective blocks

of data and order the “fast-moving” factors after the federal funds rate in the VAR

ordering. However the “fast-moving” factors obtained in this way follow interest rate

movements very closely and consequently introduce collinearity in the system. We

interpret the results of this exercise as suggesting that there is little informational content

in the “fast-moving” factors that is not already accounted for by the federal funds rate.

We therefore adhere to our original formulation.



        Empirical Results

        Our main results are shown in Figures 1-4 below. Each Figure shows impulse

responses with 90% confidence intervals of a selection of key macroeconomic variables

to a monetary policy shock. Figures 1 and 2 show the results for the FAVAR model with

3 latent factors, estimated by principal components and likelihood methods, respectively.


                                                                                                 16
We used 13 lags but employing 7 lags led to very similar results as found with the greater

number of lags. Likelihood-based estimates employed 10,000 iterations of the Gibbs

sampling procedure (of which the first 2,000 were discarded to minimize the effects of

initial conditions). To assure convergence of the algorithm, we imposed proper but

diffuse priors on parameters of the observation and the VAR equations.11 Prior

specifications are discussed in the Appendix. There seemed to be no problems achieving

convergence, and alternative starting values or the use of 20,000 iterations gave

essentially the same results. We standardize the monetary shock to correspond to a 25-

basis-point innovation in the federal funds rate.12

         An important practical question is how many factors are needed to capture the

information necessary to properly model the effect of monetary policy. Bai and Ng

(2002) provide a criterion to determine the number of factors present in the data set, X t .

However, this does not address the question of how many factors should be included in

the VAR and due to computational constraint cannot be readily implemented in the

likelihood-based estimation. To explore the effect of increasing the number of factors, we

thus consider an alternative specification with 5 latent factors. The results are reported in

Figures 3 and 4. Increasing the number of factors beyond this did not change qualitative

nature of our results.

         As we have discussed, an advantage of the FAVAR approach is that impulse

response functions can be constructed for any variable in the informational data set, that

is, for any element of X t . This gives both more information and provides a more



11
  We have also experimented with flat priors which yielded the same qualitative results.
12
  Note that the figures report impulse responses, in standard deviation units, to 25 basis points shock in the
federal funds rate.


                                                                                                           17
comprehensive check on the empirical plausibility of the specification. In that respect,

the most successful specification, in terms of plausibility, appears to be the two-step

principal component approach with 5 factors, reported in Figure 3. In this case, the

responses are generally of the expected sign and magnitude: following a contractionary

monetary policy shock, real activity measures decline, prices eventually go down and

money aggregates decline. The dividend yields initially jump above the steady state and

eventually go down. Overall these results seem to provide a consistent and sensible

measure of the effect of monetary policy. Note that we display only 20 responses of all

120 that in principle could be investigated.

       The FAVAR model appears successful in capturing relevant information. First,

the price puzzle is not present in our FAVAR model estimated by two-step approach,

even when only three factors are included. Given that our recursive identification of the

policy shocks is consistent with existing structural VARs that display the price puzzle,

our result might suggest that a few factors are sufficient to properly capture the

information that Sims argued might be missing from these VARs. Second, increasing the

number of factors generally tends to produce results more consistent with conventional

wisdom. This is particularly obvious when comparing the response of money aggregates

for the 2-step approach in Figure 1 and 3: the apparent liquidity puzzle in Figures 1

disappears when more factors are included. The amount of information included in the

empirical analysis is thus crucial to yield a plausible picture of the effects of monetary

policy, and the FAVAR approach shows some success at exploiting this information.

       But, as is obvious from the likelihood-based results reported in Figures 2 and 4,

information is not all the story. In this case, responses of prices and money aggregates are




                                                                                             18
very imprecisely estimated and display both a price and liquidity puzzle. Increasing the

number of factors does not appear to improve the results. This might suggest in fact that

the policy shock has not been properly identified. This is a possibility that would be

worth considering in future research. It is important to stress, however, that although we

considered a recursive identification of the policy shock, there is nothing in our proposed

approach – other than the computational constraints mentioned above – that prevents

using alternative, non-recursive, identification schemes. However, the fact that the two-

step approach is relatively successful with the same identification scheme might suggest

that the likelihood-based estimation suffers from the additional structure it imposes,

which might not be entirely supported empirically.

        To assess if differences between results of the two estimation methods are due to

their alternative identification or the estimation method itself, we also generated factors

under the same identification. It was accomplished by setting loadings on Y to zero in the

observation equation for the likelihood-based estimation and by omitting a “cleaning”

regression (3.1) in case of the principal components method. These are the alternative

ways of partialling out the effects of the federal funds rate from the estimated factors. As

it turns out, the two sets of factors generated in this way are significantly different. The

factors estimated by principal component fully explain the variance of likelihood-

estimated factors but the opposite is not true. Moreover, the principal component factors

have greater short run variation. We interpret these findings as evidence that the

differences in identification are not the sole source of the differences in results. Since it is

the likelihood method that imposes additional structure on the model, we may expect PC

factors to carry more information.




                                                                                               19
       While the two methods yield somewhat different responses for money aggregates

and the consumer price index, overall the point estimates of the responses are quite

similar. We find it remarkable that the two rather different methods, producing distinct

factor estimates as discussed above, give qualitatively similar results. On the other hand,

the degree of uncertainty about the estimates implied by the two methods is quite

different. In fact, for some series such as the consumer price index and industrial

production, the likelihood based approach yields much wider confidence intervals. This

might suggest that the likelihood-based factors do not successfully capture information

about these variables. The next subsection investigates this possibility by including in the

set of observable factors, Yt , the consumer price index and industrial production.



       VAR – FAVAR Comparison

       The benchmark specification considered thus far has the advantage of imposing

minimal assumptions about the common components. In particular, we did not impose

specific observable concepts for real activity or prices.

       Our methodology does not prevent, however, assuming that factors, other than the

federal funds rate, are also observed. For instance, we can expand Yt to also include

industrial production, as a measure of real activity and the consumer price index as a

measure of prices. The resulting FAVAR system thus nests a standard VAR in the

variables that are directly suggested by standard monetary models: a monetary policy

indicator, a real-activity measure and a price index. By comparing the results with and

without the factors, it is then possible to determine the marginal contributions of the

information contained in the factors.



                                                                                           20
       The impulse response functions from this alternative FAVAR specification are

presented in Figure 5, for no factor, one factor and three factors. The Figure also

reproduces the response obtained from the benchmark specification, with the federal

funds rate assumed to be the only observable factor. The top panel shows the results from

the two-step estimation and the bottom panel from the likelihood-based estimation.

       When there is no factor, i.e. the standard VAR specification, there is a strong

price puzzle and the response of industrial production is very persistent, inconsistent with

long-run money neutrality. For the two-step estimation, adding one factor to standard

VAR changes the responses dramatically. The price puzzle is considerably reduced and

the response of industrial production eventually returns toward zero. In this case, adding

one factor appears to be all that is needed. For the likelihood-based estimation, adding

three factors tends to produce qualitatively the same responses as for the two-step

estimation, although somewhat more pronounced. The estimated factors from both

methods thus seem to contain useful information, beyond that already contained in the

standard VAR.

       An interesting aspect of these results is that the responses from the two-step

estimation of the benchmark FAVAR are essentially the same as the one obtained from

expanding the standard VAR by three factors from either estimation methods. This

suggests that the two-step estimation of the benchmark FAVAR properly captures

information about real-activity and prices, even though no such measure is imposed as

observable factor. This is not the case for the likelihood-based factors and this seems to

explain, at least in part, the appeared less successful for the benchmark FAVAR.




                                                                                             21
           This comparison suggests that the FAVAR approach is successful at extracting

pertinent information from a large data set of macroeconomic indicators. That does not

mean, however, that the FAVAR approach is the only way to obtain reasonable results.

There exist, of course, other VAR specifications that could lead to reasonable results over

some periods. For example, some authors have “improved” their results by adding

variables such as an index of commodity prices to the VAR.13 But unless these variables

are part of the theoretical model the researcher has in mind, it is not clear on what

grounds they are selected, other than the fact that they ‘work’. The advantage of our

approach is to put discipline on the process, by explicitly recognizing in the econometric

model the scope for additional information. As a result, the fact that adding the

commodity price index – or any other variables – fixes or not the price puzzle is not

directly relevant to this comparison.



           Variance Decomposition

           Other than impulse response functions, another exercise typically performed in

the standard VAR context is variance decomposition. This consists of determining the

fraction of the forecasting error of a variable, at a given horizon, that is attributable to a

particular shock. Variance decomposition results follow immediately from the

coefficients of the MA representation of the VAR system and the variance of the

structural shocks. For instance the fraction variance of (Yt + k − Yˆt + k ) due to the monetary

policy shock could be expressed as:




13
     For instance, Sims (1992), Bernanke and Mihov (1998) and Christiano, Eichenbaum and Evans (1999).


                                                                                                     22
                                      var(Yt + k − Yˆt + k |t | ε t )
                                                                   MP


                                         var(Yt + k − Yˆt + k |t )

A standard result of the VAR literature is that the monetary policy shock explains a

relatively small fraction of the forecast error of real activity measures or inflation.

        But, as emphasized by equation (2.2), part of the variance of the macroeconomic

variables comes from their idiosyncratic component, which might reflect in part

measurement error and upon which business cycle determinants should have no

influence. As a result, it is not clear that the standard VAR variance decomposition

provides an accurate measure of the relative importance of the structural shocks. In this

context, the FAVAR framework suggests a potentially more appealing version of this

decomposition, where the relative importance of a structural shock is assessed relative

only to the portion of the variable explained by the common factors. More precisely, this

variance decomposition for X it can be expressed as:

                                       Λ i var(Ct + k − Cˆ t + k |t | ε t ) Λ i '
                                                                          MP


                                           Λ i var(C t + k − Cˆ t + k |t ) Λ i '

where        Λi         denotes        the         ith       line         of        Λ = [Λ f , Λ y ]   and

var(Ct + k − Cˆ t + k |t | ε t MP ) / var(Ct + k − Cˆ t + k |t ) is the standard VAR variance decomposition

based on (2.1).

        Table 1 reports the results for the same twenty macroeconomic indicators

analyzed in the previous Figures. These are based on the two-step estimation of the

benchmark specification. The first column reports the contribution of the monetary policy

shock to the variance of the forecast of the common component, at the sixty-month

horizon. The second column contains the R2 of the common component for each of these


                                                                                                        23
variables.14 The product of the two columns is the equivalent of the standard VAR

variance decomposition.

           Apart from the interest rates and the exchange rate, the contribution of the policy

shock is between 3.2% and 13.2%. This suggests a relatively small but still non-trivial

effect of the monetary policy shock. In particular, the policy shock explains 13.2%,

12.9% and 12.6% of capacity utilization, new orders and unemployment respectively, and

7.6% of industrial production. Looking at the R2 of the common component, three

observations stand out. First, the factors explain a sizeable fraction of these variables, in

particular for the most often used macroeconomic indicators: industrial production

(70.7%), employment (72.3%), unemployment (81.6%) and the consumer price index

(86.9%). This confirms that the FAVAR framework, estimated by the two-step principal

component approach, does capture important dimensions of the business cycle

movements. Second, given the R2 of the common components, the discrepancies between

the standard VAR decomposition and the one introduced here are considerable: for

instance, the standard VAR decomposition of industrial production would imply a

contribution of the policy shock equal to 5.3% instead of 7.6%, and for new orders, 8.0%

instead of 12.9%. Finally, the R2 of the common components is particularly low for the

money aggregates, being 10.3% for the monetary base and 5.2% for M2. This implies

that we should have less confidence on the impulse response estimates for these

variables. Interestingly, these are variables for which the impulse response functions from

the two estimation methods differ the most.




14
     Note that since FFR is assumed to be an observed factor, the corresponding R2 is one by construction.


                                                                                                             24
4. Conclusion


       This paper has introduced a method for incorporating a broad range of

conditioning information, summarized by a small number of factors, in otherwise

standard VAR analyses. We have shown how to identify and estimate a factor-

augmented vector autoregression, or FAVAR, by both a two-step method based on

estimation of principal components and a more computationally demanding, Bayesian

method based on Gibbs sampling. Another key advantage of the FAVAR approach is that

it permits us to obtain the responses of a large set of variables to monetary policy

innovations, which provides both a more comprehensive picture of the effects of policy

innovations as well as a more complete check of the empirical plausibility of the

underlying specification.

       In our monetary application of FAVAR methods, we find that overall the two

methods produce qualitatively similar results, although the two-step approach tends to

produce more plausible responses, without having to impose explicit measures of real-

activity or prices. Moreover, the results provide some support for the view that the “price

puzzle” results from the exclusion of conditioning information. The conditioning

information also leads to reasonable responses of money aggregates. These results thus

suggest that there is a scope to exploit more information in empirical macroeconomic

modeling.

       Future work should investigate more fully the properties of FAVARs, alternative

estimation methods and alternative identification schemes. In particular, further

comparison of the estimation methods based on principal components and on Gibbs

sampling is likely to be worthwhile. Another interesting direction is to try to interpret the



                                                                                          25
estimated factors more explicitly. For example, according to the original Sims (1992)

hypothesis, if the addition of factors mitigates the price puzzle, then the factors should

contain information about future inflation not otherwise captured in the VAR. The

marginal contribution of the estimated factors for forecasting inflation can be checked

directly.15




15
  Stock and Watson (1999) and Bernanke and Boivin (2003) have shown that, generally, factor methods
are useful for forecasting inflation.


                                                                                                      26
Appendix A: Estimation by Likelihood-Based Gibbs Sampling

        This appendix discusses the estimation of FAVARs by likelihood-based Gibbs

sampling. For further details see Eliasz (2002).

        To estimate equations (2.1) and (2.2) jointly via likelihood methods, we transform

the model into the following state-space form:



              X t  Λ f    Λ y   Ft  et 
(A.1)        Y  =               +  
              t 0          I  Yt   0 




              Ft           Ft −1 
(A.2)         Y  = Φ ( L)  Y  + ν t
              t            t −1 



where Yt is an M × 1 vector of observable economic variables in whose dynamic

properties we are interested, Ft is an K × 1 vector of unobserved factors, and X t is an

N × 1 vector of time series that incorporate information about the unobserved factors, all

as described in the text. Time is indexed t = 1, 2, ... , T . The coefficient matrices Λ f and

Λ y are N × K and N × M , respectively, and Φ (L) is a conformable lag polynomial of

finite order d . The loadings Λ f and Λ y are restricted as discussed in the text. The

error vectors et and ν t are N × 1 and ( K + M ) × 1 , respectively, and are assumed to be

distributed according to et ~ N (0, R) and ν t ~ N (0, Q) , with et and ν t independent

and R diagonal.

        (A.1) is the measurement or observation equation, and (A.2), which is identical to

(2.1), is the transition equation. Inclusion of Yt in the measurement equation (A.1) as


                                                                                             27
well as in the transition equation (A.2) does not change the model but allows for both

notational and computational simplification.

        We take a Bayesian perspective, treating the model’s parameters

θ = (Λ f , Λy , R, vec(Φ ), Q) as random variables; and where we define vec(Φ) as a

column vector of the elements of the stacked matrix Φ of the parameters of the lag

operator Φ (L) . Likelihood estimation by multi-move Gibbs sampling (Carter and Kohn,

1994), proceeds by alternately sampling the parameters θ and the unobserved factors Ft .

                               ′       ′ ′           ′     ′             ′      ′ ′
To be more specific, define X t = ( X t , Yt )′ , e t = (et ,0)′ , and Ft = ( Ft , Yt )′ and

rewrite the measurement and transition equations (A.1) and (A.2) as



(A.3)         X t = ΛFt + e t

(A.4)         Ft = Φ ( L)Ft −1 + ν t



                                                            ′
where Λ is the loading matrix from (A.1) and R = cov(e t e t ) is the covariance matrix R

augmented by zeros in the obvious way. For this exposition we assume that the order d

of Φ(L) equals one, otherwise we would rewrite (A.4) in a standard way to express it as

                                                              ~
a first-order Markov process (see Eliasz, 2002). Further, let X T = ( X1 , X 2 ,..., X T ) be the

                                                                 ~
history of X from period 1 through period T, and likewise define FT = (F1 , F2 ,..., FT ) .

                                                                           ~
        Our problem is to characterize the marginal posterior densities of FT and θ ,

               ~          ~                           ~       ~           ~
respectively p(FT ) = ∫ p(FT ,θ )dθ and p (θ ) = ∫ p (FT ,θ )dF , where p(FT ,θ ) is the
                                                                  T


joint posterior density and the integrals are taken with respect to the supports of θ and



                                                                                               28
~                                                                         ~
FT , respectively. Given these marginal posterior densities, estimates of FT and θ can be

obtained as the medians or means of these densities.

         To obtain empirical approximations to these densities, we follow Kim and Nelson

(1999, chapter 8) and apply multi-move Gibbs sampling to the state-space model (A.3)-

(A.4).    The Gibbs sampling methodology proceeds as follows: First, choose a set of

starting values for the parameters θ , say θ 0 . Second, conditional on θ 0 and the data

~                              ~        ~                                  ~ ~
X T , draw a set of values for FT , say FT1 from the conditional density p(FT X T ,θ 0 ) .

                                            ~
Third, conditional on the sampled values of FT and the data, draw a set of values of the

                                                                ~ ~
parameters θ , say θ 1 , from the conditional distribution p (θ X T , FT1 ). The final two steps

                                                                                ~
constitute one iteration, and are repeated until the empirical distributions of FTs and θ s

converge, where s indexes the iteration. It has been shown (Geman and Geman, 1994),

that as the number of iterations s → ∞ , the marginal and joint distributions of the
                  ~
sampled values of FTs and θ s converge to the true corresponding distributions at an

exponential rate. In practice, though, convergence can be slow and should be carefully

checked, for example by using alternative starting values. More details on each step are

given below.




         1. Choice of θ 0

         In general, it is good practice to try a variety of starting parameter values to see if

they generate similar empirical distributions. As Gelman and Rubin (1992) argue, a

single sequence from the Gibbs sampler, even if it has apparently converged, may give a


                                                                                              29
“false sense of security”. At the same time, in a problem as large as the one at hand, for

which computational capacity constrains the number of feasible runs, a meaningful

choice of θ 0 may be advisable. An obvious choice was to use parameter estimates

obtained from principal components estimation of (A.1) and the vector autoregression

(A.2). We constrained these parameter estimates to satisfy the normalization, discussed

in the text, that the upper K × ( K + M ) block of loadings Λ is restricted to be

[I K ,0 K ×M ] . We used these parameter estimates as starting values for θ in most runs, but

we have confirmed the robustness of the key results for alternative starting values. For

example, we also tried starting values such that (1) vec(Φ) = 0 , (2) Q = I , (3) Λ f = 0 ,

(4) Λy = OLS estimates from the regression of X on Y , and (5) R = residual covariance

matrix from the regression of X on Y , and obtained similar results to those reported in

the text.



                                                       ~ ~
        2. Drawing from the conditional distribution p(FT X T ,θ )

        As in Nelson and Kim (p. 191), the conditional distribution of the whole history

             ~ ~
of factors p(FT X T ,θ ) can be expressed as the product of conditional distributions of

factors at each date t as follows:



                                                  T −1
                 ~ ~                   ~                               ~
(A.5)         p (F T X T ,θ ) = p (F T X T ,θ )   ∏ p (F
                                                  t =1
                                                           t   Ft +1 , X t ,θ )




                                                                                           30
      ~
where X t = ( X1 , X 2 ,..., X t ) . (A.5) relies on the Markov property of Ft , which implies

that p (F t Ft +1 , Ft + 2 ,..., FT , X T ,θ ) = p (F t Ft +1 , X t ,θ ) .

          Because the state-space model (A.3)-(A.4) is linear and Gaussian, we have



                       ~
                   F T X T ,θ ~ N (FT T , PT T )
(A.6)                          ~
                   F t Ft +1 , X t ,θ ~ N (Ft t ,Ft +1 , Pt t ,Ft +1 )   t = T − 1,...,1




where



                                 ~
                   FT T = E (F T X T ,θ )
                                    ~
                   PT T = Cov(F T X T ,θ )
(A.7)                                       ~
                   Ft t ,F = E (F t Ft +1 , X t ,θ ) = E (F t Ft +1 , Ft t ,θ )
                          t +1
                                               ~
                   Pt t ,F = Cov(F t Ft +1 , X t ,θ ) = Cov(F t Ft +1 , Ft t ,θ )
                          t +1




where the notation Ft t refers to the expectation of Ft conditional on information dated t

or earlier. To obtain these, we first calculate Ft t and Pt t , t = 1,2,...T , by Kalman filter,

                                                ~
conditional on θ and the data through period t, X t , with starting values of zeros for the

factors and the identity matrix for the covariance matrix (Hamilton, 1994). The last

iteration of the filter yields FT T and PT T , which together with the first line of (A.6)

allows us to draw a value for FT . Treating this drawn value as extra information, we can

move “backwards in time” through the sample, using the Kalman filter to obtain updated




                                                                                                 31
values of FT −1 T −1,FT and PT −1 T −1,FT ; drawing a value of FT −1 using the second line of (A.6);

and continuing in similar manner to draw values for Ft , t = T − 2, T − 3,...,1.

         If the order d of Φ(L) exceeds one, as it does in our applications, then lags of

the factors appear in the state vector Ft and Q is singular, as is Pt t ,Ft +1 for any t < T .

(The singularity of these two covariance matrices follows from the fact that, in this case,

Ft and Ft +1 have common components.) In this case we cannot condition on the full

vector Ft +1 when drawing Ft , but only on the first d elements of Ft +1 . Kim and Nelson

(1999, p. 194-6) show how to modify the Kalman filter algorithm in this case.



                                                           ~ ~
         3. Drawing from the conditional distribution p (θ X T , FT ).

         Conditional on the observed data and the estimated factors from the previous

iteration, a new iteration is begun by drawing a new value of the parameters θ . With

known factors, (A.3) and (A.4) amount to standard regression equations, with (A.3)

specifying the distribution of Λ and R , and (A.4) the distribution of vec(Φ) and Q .

Consider (A.3) first. Because the errors are uncorrelated, we can apply OLS to (A.3)

equation by equation to obtain Λ̂ and ê . We set Rij = 0, i ≠ j and assume a proper

(conjugate) but diffuse Inverse-Gamma (3, 0.001) prior for Rii . Standard Bayesian results

(see Bauwens, Lubrano and Richard, 1999, p. 58) deliver posterior of the form:

                                 % , F% ~ iG ( R , T + 0.001)
                            R ii X T   T        ii



                            ˆ '[ M −1 + (F% ( i ) ' F% ( i ) ) −1 ]−1 Λ
where Rii = 3 + eˆi ' eˆi + Λ                                         ˆ . Here M −1 denotes variance parameter
                              i   0        T          T                 i       0



in the prior on the coefficients of the i -th equation, Λ i , which, conditional on the drawn



                                                                                                            32
                                                     ~
                          (               )
value of Rii , is N 0, Rii M 0 −1 . We set M 0 = I . FT( i ) corresponds to the regressors of the

i -th equation. We draw values for Λ i from the posterior N (Λ i , Rii M i −1 ) , where


              (            )     ˆ and M = M + F% ( i ) ' F% ( i ) .
Λ i = M i −1 F%T( i ) ' F%T( i ) Λ i    i   0    T          T



          Turning to (A.4), we see that this system has a standard VAR form and can thus

                                                      ˆ ), Qˆ . Proceeding similarly as
also be estimated equation by equation, to obtain vec(Φ

before, we impose a diffuse conjugate Normal-Wishart prior,

                           vec ( Φ ) | Q ~ N ( 0, Q ⊗ Ω0 ) , Q ~ iW ( Q0 , K + M + 2 ) ,

where vec(Φ ) is the rows of Φ stacked in a column vector of length d ( K + M ) 2 . We

choose its parameters so as to express the belief that parameters on longer lags are more

likely to be zero, in the spirit of the Minnesota prior. Following Kadiyala and Karlsson

(1997) we set the diagonal elements of Q0 to the residual variances of the corresponding

d - lag univariate autoregressions, σˆ i2 . To match prior variances of the Minnesota prior

we construct diagonal elements of Ω0 so that the prior variance of parameter on k lagged

j'th variable in i'th equation equals σ i 2 / kσ j 2 . We start by drawing Q from the Inverse-

Wishart, iW (Q, T + K + M + 2) , where Q = Q0 + Vˆ 'Vˆ + Φ    0     T −1 T −1
                                                                                   ˆ and Vˆ is
                                                         ˆ '[Ω + (F% ' F% ) −1 ]−1 Φ

the matrix of OLS residuals. Conditional on the sampled Q , we then draw {Φ ijt } from

the conditional normal according to

                                 vec(Φ ) ~ N (vec(Φ ), Q ⊗ Ω)


                                                    (                  )
                                                                           −1
                             ˆ and Ω = Ω −1 + F% ' F%
where Φ = Ω(F%T −1 ' F%T −1 )Φ                                                  . Stationarity is enforced by
                                        0       T −1 T −1



discarding draws of Φ that contain roots greater than or equal to 1.001 in absolute value.




                                                                                                                33
This completes the sampling of the parameters θ conditional on the estimated factors

from the previous iteration and the observed data.

       Steps 2 and 3 are repeated for each iteration s . Inference is based on the
                 ~
distribution of (FTs ,θ s ) , for s ≥ B , with B large enough to guarantee convergence of the

algorithm. As noted, the empirical distribution from the sampling procedure should well

approximate the joint posterior or normalized joint likelihood. Calculating medians and
              ~
quantiles of (FTs ,θ s ) for s = B,..., S provides estimates of the values of the factors and

the model parameters and the associated confidence regions. Note that the Gibbs-

sampling algorithm is guaranteed to closely approximate the shape of the likelihood,

especially around its peak, even if the likelihood is rather irregular and complicated, as is

typically the case in the large models considered in this paper.




                                                                                            34
Appendix B - Data Description
All series were directly taken from DRI/McGraw Hill Basic Economics Database. Format
is as in Stock & Watson’s papers: series number; series mnemonic; data span;
transformation code and series description as appears in the database. The transformation
codes are: 1 – no transformation; 2 – first difference; 4 – logarithm; 5 – first difference of
logarithm. An asterisk, ‘*’, next to the mnemonic denotes a variable assumed to be
“slow-moving” in the estimation.

Real output and income

1. IPP*         1959:01-2001:08   5 INDUSTRIAL PRODUCTION: PRODUCTS, TOTAL (1992=100,SA)
2. IPF*         1959:01-2001:08   5 INDUSTRIAL PRODUCTION: FINAL PRODUCTS (1992=100,SA)
3. IPC*         1959:01-2001:08   5 INDUSTRIAL PRODUCTION: CONSUMER GOODS (1992=100,SA)
4. IPCD*        1959:01-2001:08   5 INDUSTRIAL PRODUCTION: DURABLE CONS. GOODS (1992=100,SA)
5. IPCN*        1959:01-2001:08   5 INDUSTRIAL PRODUCTION: NONDURABLE CONS. GOODS (1992=100,SA)
6. IPE*         1959:01-2001:08   5 INDUSTRIAL PRODUCTION: BUSINESS EQUIPMENT (1992=100,SA)
7. IPI*         1959:01-2001:08   5 INDUSTRIAL PRODUCTION: INTERMEDIATE PRODUCTS (1992=100,SA)
8. IPM*         1959:01-2001:08   5 INDUSTRIAL PRODUCTION: MATERIALS (1992=100,SA)
9. IPMD*        1959:01-2001:08   5 INDUSTRIAL PRODUCTION: DURABLE GOODS MATERIALS (1992=100,SA)
10. IPMND*      1959:01-2001:08   5 INDUSTRIAL PRODUCTION: NONDUR. GOODS MATERIALS (1992=100,SA)
11. IPMFG*      1959:01-2001:08   5 INDUSTRIAL PRODUCTION: MANUFACTURING (1992=100,SA)
12. IPD*        1959:01-2001:08   5 INDUSTRIAL PRODUCTION: DURABLE MANUFACTURING (1992=100,SA)
13. IPN*        1959:01-2001:08   5 INDUSTRIAL PRODUCTION: NONDUR. MANUFACTURING (1992=100,SA)
14. IPMIN*      1959:01-2001:08   5 INDUSTRIAL PRODUCTION: MINING (1992=100,SA)
15. IPUT*       1959:01-2001:08   5 INDUSTRIAL PRODUCTION: UTILITIES (1992-=100,SA)
16. IP*         1959:01-2001:08   5 INDUSTRIAL PRODUCTION: TOTAL INDEX (1992=100,SA)
17. IPXMCA*     1959:01-2001:08   1 CAPACITY UTIL RATE: MANUFAC.,TOTAL(% OF CAPACITY,SA)(FRB)
18. PMI*        1959:01-2001:08   1 PURCHASING MANAGERS' INDEX (SA)
19. PMP*        1959:01-2001:08   1 NAPM PRODUCTION INDEX (PERCENT)
20. GMPYQ*      1959:01-2001:08   5 PERSONAL INCOME (CHAINED) (SERIES #52) (BIL 92$,SAAR)
21. GMYXPQ*     1959:01-2001:08   5 PERSONAL INC. LESS TRANS. PAYMENTS (CHAINED) (#51) (BIL 92$,SAAR)


Employment and hours

22.   LHEL*     1959:01-2001:08   5 INDEX OF HELP-WANTED ADVERTISING IN NEWSPAPERS (1967=100;SA)
23.   LHELX*    1959:01-2001:08   4 EMPLOYMENT: RATIO; HELP-WANTED ADS:NO. UNEMPLOYED CLF
24.   LHEM*     1959:01-2001:08   5 CIVILIAN LABOR FORCE: EMPLOYED, TOTAL (THOUS.,SA)
25.   LHNAG*    1959:01-2001:08   5 CIVILIAN LABOR FORCE: EMPLOYED, NONAG.INDUSTRIES (THOUS.,SA)
26.   LHUR*     1959:01-2001:08   1 UNEMPLOYMENT RATE: ALL WORKERS, 16 YEARS & OVER (%,SA)
27.   LHU680*   1959:01-2001:08   1 UNEMPLOY.BY DURATION: AVERAGE(MEAN)DURATION IN WEEKS (SA)
28.   LHU5*     1959:01-2001:08   1 UNEMPLOY.BY DURATION: PERS UNEMPL.LESS THAN 5 WKS (THOUS.,SA)
29.   LHU14*    1959:01-2001:08   1 UNEMPLOY.BY DURATION: PERS UNEMPL.5 TO 14 WKS (THOUS.,SA)
30.   LHU15*    1959:01-2001:08   1 UNEMPLOY.BY DURATION: PERS UNEMPL.15 WKS + (THOUS.,SA)
31.   LHU26*    1959:01-2001:08   1 UNEMPLOY.BY DURATION: PERS UNEMPL.15 TO 26 WKS (THOUS.,SA)
32.   LPNAG*    1959:01-2001:08   5 EMPLOYEES ON NONAG. PAYROLLS: TOTAL (THOUS.,SA)
33.   LP*       1959:01-2001:08   5 EMPLOYEES ON NONAG PAYROLLS: TOTAL, PRIVATE (THOUS,SA)
34.   LPGD*     1959:01-2001:08   5 EMPLOYEES ON NONAG. PAYROLLS: GOODS-PRODUCING (THOUS.,SA)
35.   LPMI*     1959:01-2001:08   5 EMPLOYEES ON NONAG. PAYROLLS: MINING (THOUS.,SA)
36.   LPCC*     1959:01-2001:08   5 EMPLOYEES ON NONAG. PAYROLLS: CONTRACT CONSTRUC. (THOUS.,SA)
37.   LPEM*     1959:01-2001:08   5 EMPLOYEES ON NONAG. PAYROLLS: MANUFACTURING (THOUS.,SA)
38.   LPED*     1959:01-2001:08   5 EMPLOYEES ON NONAG. PAYROLLS: DURABLE GOODS (THOUS.,SA)
39.   LPEN*     1959:01-2001:08   5 EMPLOYEES ON NONAG. PAYROLLS: NONDURABLE GOODS (THOUS.,SA)
40.   LPSP*     1959:01-2001:08   5 EMPLOYEES ON NONAG. PAYROLLS: SERVICE-PRODUCING (THOUS.,SA)
41.   LPTU*     1959:01-2001:08   5 EMPLOYEES ON NONAG. PAYROLLS: TRANS. & PUBLIC UTIL. (THOUS.,SA)
42.   LPT*      1959:01-2001:08   5 EMPLOYEES ON NONAG. PAYROLLS: WHOLESALE & RETAIL (THOUS.,SA)
43.   LPFR*     1959:01-2001:08   5 EMPLOYEES ON NONAG. PAYROLLS: FINANCE,INS.&REAL EST (THOUS.,SA
44.   LPS*      1959:01-2001:08   5 EMPLOYEES ON NONAG. PAYROLLS: SERVICES (THOUS.,SA)
45.   LPGOV*    1959:01-2001:08   5 EMPLOYEES ON NONAG. PAYROLLS: GOVERNMENT (THOUS.,SA)
46.   LPHRM*    1959:01-2001:08   1 AVG. WEEKLY HRS. OF PRODUCTION WKRS.: MANUFACTURING (SA)




                                                                                                   35
47. LPMOSA*      1959:01-2001:08   1 AVG. WEEKLY HRS. OF PROD. WKRS.: MFG.,OVERTIME HRS. (SA)
48. PMEMP*       1959:01-2001:08   1 NAPM EMPLOYMENT INDEX (PERCENT)


Consumption

49.   GMCQ*      1959:01-2001:08   5 PERSONAL CONSUMPTION EXPEND (CHAINED) - TOTAL (BIL 92$,SAAR)
50.   GMCDQ*     1959:01-2001:08   5 PERSONAL CONSUMPTION EXPEND (CHAINED) – TOT. DUR. (BIL 96$,SAAR)
51.   GMCNQ*     1959:01-2001:08   5 PERSONAL CONSUMPTION EXPEND (CHAINED) – NONDUR. (BIL 92$,SAAR)
52.   GMCSQ*     1959:01-2001:08   5 PERSONAL CONSUMPTION EXPEND (CHAINED) - SERVICES (BIL 92$,SAAR)
53.   GMCANQ*    1959:01-2001:08   5 PERSONAL CONS EXPEND (CHAINED) - NEW CARS (BIL 96$,SAAR)


Housing starts and sales

54.   HSFR       1959:01-2001:08   4 HOUSING STARTS:NONFARM(1947-58);TOT.(1959-)(THOUS.,SA
55.   HSNE       1959:01-2001:08   4 HOUSING STARTS:NORTHEAST (THOUS.U.)S.A.
56.   HSMW       1959:01-2001:08   4 HOUSING STARTS:MIDWEST(THOUS.U.)S.A.
57.   HSSOU      1959:01-2001:08   4 HOUSING STARTS:SOUTH (THOUS.U.)S.A.
58.   HSWST      1959:01-2001:08   4 HOUSING STARTS:WEST (THOUS.U.)S.A.
59.   HSBR       1959:01-2001:08   4 HOUSING AUTHORIZED: TOTAL NEW PRIV HOUSING (THOUS.,SAAR)
60.   HMOB       1959:01-2001:08   4 MOBILE HOMES: MANUFACTURERS' SHIPMENTS (THOUS.OF UNITS,SAAR)


Real inventories, orders and unfilled orders

61.   PMNV       1959:01-2001:08   1 NAPM INVENTORIES INDEX (PERCENT)
62.   PMNO       1959:01-2001:08   1 NAPM NEW ORDERS INDEX (PERCENT)
63.   PMDEL      1959:01-2001:08   1 NAPM VENDOR DELIVERIES INDEX (PERCENT)
64.   MOCMQ      1959:01-2001:08   5 NEW ORDERS (NET) - CONSUMER GOODS & MATERIALS, 1992 $ (BCI)
65.   MSONDQ     1959:01-2001:08   5 NEW ORDERS, NONDEFENSE CAPITAL GOODS, IN 1992 DOLLARS (BCI)


Stock prices

66.   FSNCOM     1959:01-2001:08   5 NYSE COMMON STOCK PRICE INDEX: COMPOSITE (12/31/65=50)
67.   FSPCOM     1959:01-2001:08   5 S&P'S COMMON STOCK PRICE INDEX: COMPOSITE (1941-43=10)
68.   FSPIN      1959:01-2001:08   5 S&P'S COMMON STOCK PRICE INDEX: INDUSTRIALS (1941-43=10)
69.   FSPCAP     1959:01-2001:08   5 S&P'S COMMON STOCK PRICE INDEX: CAPITAL GOODS (1941-43=10)
70.   FSPUT      1959:01-2001:08   5 S&P'S COMMON STOCK PRICE INDEX: UTILITIES (1941-43=10)
71.   FSDXP      1959:01-2001:08   1 S&P'S COMPOSITE COMMON STOCK: DIVIDEND YIELD (% PER ANNUM)
72.   FSPXE      1959:01-2001:08   1 S&P'S COMPOSITE COMMON STOCK: PRICE-EARNINGS RATIO (%,NSA)


Exchange rates

73.   EXRSW      1959:01-2001:08   5 FOREIGN EXCHANGE RATE: SWITZERLAND (SWISS FRANC PER U.S.$)
74.   EXRJAN     1959:01-2001:08   5 FOREIGN EXCHANGE RATE: JAPAN (YEN PER U.S.$)
75.   EXRUK      1959:01-2001:08   5 FOREIGN EXCHANGE RATE: UNITED KINGDOM (CENTS PER POUND)
76.   EXRCAN     1959:01-2001:08   5 FOREIGN EXCHANGE RATE: CANADA (CANADIAN $ PER U.S.$)


Interest rates

77.   FYFF       1959:01-2001:08   1 INTEREST RATE: FEDERAL FUNDS (EFFECTIVE) (% PER ANNUM,NSA)
78.   FYGM3      1959:01-2001:08   1 INTEREST RATE: U.S.TREASURY BILLS,SEC MKT,3-MO.(% PER ANN,NSA)
79.   FYGM6      1959:01-2001:08   1 INTEREST RATE: U.S.TREASURY BILLS,SEC MKT,6-MO.(% PER ANN,NSA)
80.   FYGT1      1959:01-2001:08   1 INTEREST RATE: U.S.TREASURY CONST MATUR. ,1-YR.(% PER ANN,NSA)



                                                                                                   36
81.   FYGT5      1959:01-2001:08   1 INTEREST RATE: U.S.TREASURY CONST MATUR., 5-YR.(% PER ANN,NSA)
82.   FYGT10     1959:01-2001:08   1 INTEREST RATE: U.S.TREASURY CONST MATUR.,10-YR.(% PER ANN,NSA)
83.   FYAAAC     1959:01-2001:08   1 BOND YIELD: MOODY'S AAA CORPORATE (% PER ANNUM)
84.   FYBAAC     1959:01-2001:08   1 BOND YIELD: MOODY'S BAA CORPORATE (% PER ANNUM)
85.   SFYGM3     1959:01-2001:08   1 Spread FYGM3 - FYFF
86.   SFYGM6     1959:01-2001:08   1 Spread FYGM6 - FYFF
87.   SFYGT1     1959:01-2001:08   1 Spread FYGT1 - FYFF
88.   SFYGT5     1959:01-2001:08   1 Spread FYGT5 - FYFF
89.   SFYGT10    1959:01-2001:08   1 Spread FYGT10 - FYFF
90.   SFYAAAC    1959:01-2001:08   1 Spread FYAAAC - FYFF
91.   SFYBAAC    1959:01-2001:08   1 Spread FYBAAC - FYFF


Money and credit quantity aggregates

92. FM1          1959:01-2001:08   5 MONEY STOCK: M1 (BIL$,SA)
93. FM2          1959:01-2001:08   5 MONEY STOCK:M2 (BIL$, SA)
94. FM3          1959:01-2001:08   5 MONEY STOCK: M3 (BIL$,SA)
95. FM2DQ        1959:01-2001:08   5 MONEY SUPPLY - M2 IN 1992 DOLLARS (BCI)
96. FMFBA        1959:01-2001:08   5 MONETARY BASE, ADJ FOR RESERVE REQUIREMENT CHANGES(MIL$,SA)
97. FMRRA        1959:01-2001:08   5 DEPOSITORY INST RESERVES:TOTAL,ADJ FOR RES. REQ CHGS(MIL$,SA)
98. FMRNBA       1959:01-2001:08   5 DEPOSITORY INST RESERVES:NONBOR. ,ADJ RES REQ CHGS(MIL$,SA)
99. FCLNQ        1959:01-2001:08   5 COMMERCIAL & INDUST. LOANS OUSTANDING IN 1992 DOLLARS (BCI)
100. FCLBMC      1959:01-2001:08   1 WKLY RP LG COM. BANKS: NET CHANGE COM & IND. LOANS(BIL$,SAAR)
101. CCINRV      1959:01-2001:08   5 CONSUMER CREDIT OUTSTANDING NONREVOLVING G19


Price indexes

102.   PMCP      1959:01-2001:08   1 NAPM COMMODITY PRICES INDEX (PERCENT)
103.   PWFSA*    1959:01-2001:08   5 PRODUCER PRICE INDEX: FINISHED GOODS (82=100,SA)
104.   PWFCSA*   1959:01-2001:08   5 PRODUCER PRICE INDEX:FINISHED CONSUMER GOODS (82=100,SA)
105.   PWIMSA*   1959:01-2001:08   5 PRODUCER PRICE INDEX:INTERMED MAT.SUP & COMPONENTS(82=100,SA)
106.   PWCMSA*   1959:01-2001:08   5 PRODUCER PRICE INDEX:CRUDE MATERIALS (82=100,SA)
107.   PSM99Q*   1959:01-2001:08   5 INDEX OF SENSITIVE MATERIALS PRICES (1990=100)(BCI-99A)
108.   PUNEW*    1959:01-2001:08   5 CPI-U: ALL ITEMS (82-84=100,SA)
109.   PU83*     1959:01-2001:08   5 CPI-U: APPAREL & UPKEEP (82-84=100,SA)
110.   PU84*     1959:01-2001:08   5 CPI-U: TRANSPORTATION (82-84=100,SA)
111.   PU85*     1959:01-2001:08   5 CPI-U: MEDICAL CARE (82-84=100,SA)
112.   PUC*      1959:01-2001:08   5 CPI-U: COMMODITIES (82-84=100,SA)
113.   PUCD*     1959:01-2001:08   5 CPI-U: DURABLES (82-84=100,SA)
114.   PUS*      1959:01-2001:08   5 CPI-U: SERVICES (82-84=100,SA)
115.   PUXF*     1959:01-2001:08   5 CPI-U: ALL ITEMS LESS FOOD (82-84=100,SA)
116.   PUXHS*    1959:01-2001:08   5 CPI-U: ALL ITEMS LESS SHELTER (82-84=100,SA)
117.   PUXM*     1959:01-2001:08   5 CPI-U: ALL ITEMS LESS MIDICAL CARE (82-84=100,SA)


Average hourly earnings

118. LEHCC*      1959:01-2001:08   5 AVG HR EARNINGS OF CONSTR WKRS: CONSTRUCTION ($,SA)
119. LEHM*       1959:01-2001:08   5 AVG HR EARNINGS OF PROD WKRS: MANUFACTURING ($,SA)


Miscellaneous

120. HHSNTN      1959:01-2001:08   1 U. OF MICH. INDEX OF CONSUMER EXPECTATIONS(BCD-83)




                                                                                                  37
                     FFR                     IP                   CPI         3m TREASURY BILLS   5y TREASURYBONDS
        0.2                         2                  0.5                 0.2                  0.1

                                    1                    0
          0                                                                  0                        0
                                    0                  -0.5

        -0.2                       -1                   -1                 -0.2                 -0.1
               0             48          0        48       0            48      0            48      0           48
                MONETARY BASE                M2          EXCHANGE RATE YEN COMMODITY PRICE INDEX CAPACITY UTIL RATE
        0.5                       0.5                  0.5                  0.1                  0.1



          0                         0                    0                   0                        0



        -0.5               -0.5                   -0.5                 -0.1                   -0.1
            0           48      0              48      0            48      0              48      0            48
        PERSONAL CONSUMPTION      DURABLE CONS        NONDURABLE CONS         UNEMPLOYMENT           EMPLOYMENT
          1                   1                      1                  0.1                    0.1

        0.5                       0.5                  0.5
                                                                             0                        0
          0                         0                    0

        -0.5                -0.5                   -0.5                 -0.1                        -0.1
            0            48      0              48      0            48      0                 48     0              48
         AVG HOURLY EARNINGS      HOUSING STARTS          NEW ORDERS               DIVIDENDS        CONSUMER EXPECTATIONS
        0.5                  0.1                    0.1                0.05

                                                                                                      0
          0                         0                    0                   0



        -0.5                      -0.1                 -0.1              -0.05                      -0.1
               0             48          0        48          0         48     0               48          0        48




Figure 1. Impulse responses generated from FAVAR with 3 factors and FFR estimated by
principal components with 2 step bootstrap.




                                                                                                                            38
                        FFR                              IP                               CPI                   3m TREASURY BILLS               5y TREASURY BONDS
         0.3                              4                               10                              0.3                             0.3

         0.2                              2                                5                              0.2                             0.2

         0.1                              0                                0                              0.1                             0.1

          0                               -2                               -5                               0                               0

        -0.1                              -4                             -10                             -0.1                            -0.1
               0                   48          0                    48          0               48            0               48     0                 48
                   MONETARY BASE                        M2                      EXCHANGE RATE YEN          COMMODITY PRICE INDEX      CAPACITY UTIL RATE
         10                              10                                1                              0.2                    0.2

                                          5                                                               0.1                             0.1
          5                                                                0
                                          0                                                                 0                               0
          0                                                                -1
                                          -5                                                             -0.1                            -0.1

          -5                            -10                                -2                            -0.2                            -0.2
            0              48                  0                    48          0                  48           0                  48           0                48
          PERSONAL CONSUMPTION                     DURABLE CONS                     NONDURABLE CONS                 UNEMPLOYMENT                    EMPLOYMENT
          4                               2                                4                            0.15                              0.1

          2                                                                2                              0.1                               0
                                          1
          0                                                                0                            0.05                             -0.1
                                          0
          -2                                                               -2                               0                            -0.2

          -4                              -1                               -4                           -0.05                            -0.3
            0                48                0                    48          0                  48           0                  48        0              48
           AVG HOURLY EARNINGS                     HOUSING STARTS                     NEW ORDERS                      DIVIDENDS           CONSUMER EXPECTATIONS
          5                             0.2                              0.2                              0.1                           0.05

                                        0.1                              0.1                            0.05                                0

          0                               0                                0                                0                           -0.05

                                        -0.1                             -0.1                           -0.05                            -0.1

          -5                            -0.2                             -0.2                            -0.1                           -0.15
               0                   48          0                    48          0                  48           0                  48           0                48




Figure 2. Impulse responses generated from FAVAR with 3 factors and FFR estimated by
Gibbs sampling.




                                                                                                                                                                      39
                     FFR                     IP                   CPI         3m TREASURY BILLS   5y TREASURYBONDS
        0.2                         2                  0.5                 0.2                  0.1

                                    1                    0
          0                                                                  0                        0
                                    0                  -0.5

        -0.2                       -1                   -1                 -0.2                 -0.1
               0             48          0        48       0            48      0            48      0           48
                MONETARY BASE                M2          EXCHANGE RATE YEN COMMODITY PRICE INDEX CAPACITY UTIL RATE
        0.5                         1                    1                  0.1                  0.1

                                                       0.5
          0                         0                                        0                        0
                                                         0

        -0.5                -1                   -0.5                 -0.1                   -0.1
            0           48     0              48      0            48      0              48      0            48
        PERSONAL CONSUMPTION     DURABLE CONS        NONDURABLE CONS         UNEMPLOYMENT           EMPLOYMENT
          1                  1                      1                  0.1                    0.1

        0.5                       0.5                  0.5
                                                                             0                        0
          0                         0                    0

        -0.5                -0.5                   -0.5                 -0.1                        -0.1
            0            48      0              48      0            48      0                 48     0              48
         AVG HOURLY EARNINGS      HOUSING STARTS          NEW ORDERS               DIVIDENDS        CONSUMER EXPECTATIONS
        0.5                  0.1                    0.1                0.05

                                                                                                      0
          0                         0                    0                   0



        -0.5                      -0.1                 -0.1              -0.05                      -0.1
               0             48          0        48          0         48     0               48          0        48




Figure 3. Impulse responses generated from FAVAR with 5 factors and FFR estimated by
principal components with 2 step bootstrap.




                                                                                                                            40
                        FFR                              IP                               CPI                   3m TREASURY BILLS               5y TREASURY BONDS
         0.3                              4                               10                              0.3                           0.15

         0.2                              2                                5                              0.2                             0.1

         0.1                              0                                0                              0.1                           0.05

          0                               -2                               -5                               0                               0

        -0.1                              -4                             -10                             -0.1                    -0.05
               0                   48          0                    48          0               48           0                48       0                 48
                   MONETARY BASE                        M2                      EXCHANGE RATE YEN          COMMODITY PRICE INDEX        CAPACITY UTIL RATE
         10                              10                                1                            0.05                       0.2

                                          5                                                                 0                             0.1
          5                                                                0
                                          0                                                             -0.05                               0
          0                                                                -1
                                          -5                                                             -0.1                            -0.1

          -5                            -10                                -2                           -0.15                            -0.2
            0              48                  0                    48          0                  48           0                  48           0                48
          PERSONAL CONSUMPTION                     DURABLE CONS                     NONDURABLE CONS                 UNEMPLOYMENT                    EMPLOYMENT
          4                               2                                4                              0.3                             0.1

          2                                                                2                              0.2                               0
                                          1
          0                                                                0                              0.1                            -0.1
                                          0
          -2                                                               -2                               0                            -0.2

          -4                              -1                               -4                            -0.1                            -0.3
            0                48                0                    48          0                  48           0                  48        0              48
           AVG HOURLY EARNINGS                     HOUSING STARTS                     NEW ORDERS                      DIVIDENDS           CONSUMER EXPECTATIONS
          4                             0.2                              0.2                            0.15                            0.05

          2                             0.1                              0.1                              0.1                               0

          0                               0                                0                            0.05                            -0.05

          -2                            -0.1                             -0.1                               0                            -0.1

          -4                            -0.2                             -0.2                           -0.05                           -0.15
               0                   48          0                    48          0                  48           0                  48           0                48




Figure 4. Impulse responses generated from FAVAR with 5 factors and FFR estimated by
Gibbs sampling.




                                                                                                                                                                      41
                                    Two-Step PC Estimation
                   FFR                               IP                                    CPI
        0.15                     0.1                                         0.6

                                                                             0.4
                                   0
         0.1
                                                                             0.2

                                 -0.1                                             0
        0.05
                                 -0.2                                       -0.2

                                                                            -0.4
          0
                                 -0.3
                                                                            -0.6

       -0.05                     -0.4                                       -0.8
               0            48          0                            48               0          48
                                        Likelihood Based Estimation
                   FFR                                IP                                   CPI
        0.15                      0.6                                             1

                                  0.4
                                                                                 0.5
         0.1
                                  0.2

                                    0                                             0
        0.05
                                 -0.2
                                                                             -0.5
                                 -0.4
           0
                                                                                 -1
                                 -0.6

       -0.05                     -0.8                                        -1.5
               0            48          0                             48               0         48
                                            Baseline (Y=FFR, K=5)
                                            VAR (Y=IP,CPI,FFR, K=0)
                                            VAR & 1 factor (Y=IP,CPI,FFR, K=1)
                                            VAR & 3 factor (Y=IP,CPI,FFR, K=3)




Figure 5. VAR – FAVAR comparison. The top panel displays estimated responses for the
two-step principal component estimation and the bottom panel for the likelihood based
estimation.




                                                                                                      42
Table 1. Contribution of the policy shock to variance of the common component



                 Variables                      Variance           R2
                                              Decomposition
                 Federal funds rate             0.4538          *1.0000
                 Industrial production          0.0763          0.7074
                 Consumer price index           0.0441          0.8699
                 3-month treasury bill          0.4440          0.9751
                 5-year bond                    0.4354          0.9250
                 Monetary Base                  0.0500          0.1039
                 M2                             0.1035          0.0518
                 Exchange rate (Yen/$)          0.2816          0.0252
                 Commodity price Index          0.0750          0.6518
                 Capacity utilization           0.1328          0.7533
                 Personal consumption           0.0535          0.1076
                 Durable consumption            0.0850          0.0616
                 Non-durable cons.              0.0327          0.0621
                 Unemployment                   0.1263          0.8168
                 Employment                     0.0934          0.7073
                 Aver. Hourly Earnings          0.0965          0.0721
                 Housing Starts                 0.0816          0.3872
                 New Orders                     0.1291          0.6236
                 S&P dividend yield             0.1136          0.5486
                 Consumer Expectations          0.0514          0.7005

The column entitled “Variance Decomposition” reports the fraction of the variance of the
forecast error of the common component, at the 60-month horizon, explained by the
policy shock. “R2” refers to the fraction of the variance of the variable explained by the
common factors, ( F̂t , Yt ). See text for details.
*This is by construction.




                                                                                        43
                                      References

Bai, Jushan, “Estimating Cross-Section Common Stochastic Trends in Non-Stationary
Panel Data”, Journal of Econometrics, forthcoming.

Balke, Nathan and Kenneth Emery, “Understanding the Price Puzzle”, Federal Reserve
Bank of Dallas, Economic Review, Fourth Quarter 1994, 15-26.

Bauwens, Luc, Michel Lubrano and Jean-Francois Richard, Bayesian Inference in
Dynamic Econometric Models, Oxford University Press, 1999.

Bernanke, Ben and Alan Blinder, “The Federal Funds Rate and the Channels of Monetary
Transmission”, American Economic Review 82, September 1992, 901-21.

Bernanke, Ben and Jean Boivin, “Monetary Policy in a Data-Rich Environment”, Journal
of Monetary Economics 50:3, April 2003, 525-546.

Bernanke, Ben, and Mark Gertler, “Inside the Black Box: The Credit Channel of
Monetary Transmission”, Journal of Economic Perspectives 9,. Fall 1995, 27-48.

Bernanke, Ben, Mark Gertler, and Mark Watson, “Systematic Monetary Policy and the
Effects of Oil Price Shocks”, Brookings Papers on Economic Activity, 1997:1, 91-142.

Bernanke, Ben and Ilian Mihov, “Measuring Monetary Policy”, Quarterly Journal of
Economics 113, August 1998, 869-902.

Bernanke, Ben and Ilian Mihov, “The Liquidity Effect and Long-Run Neutrality”, in B.
McCallum and C. Plosser, eds., Carnegie Rochester Conference Series on Public Policy
49, 1998, 149-94.

Boivin, Jean, and Marc Giannoni, “Has Monetary Policy Become More Effective?”
NBER Working Paper no. 9459, 2003.

Carter, C.K. and P. Kohn, “On Gibbs Sampling for State Space Models”, Biometrika 81,
1994, 541-53.

Christiano, Lawrence, “Modeling the Liquidity Effect of a Money Shock”, Federal
Reserve Bank of Minneapolis, Quarterly Review 15, 1991, 3-34.

Christiano, Lawrence and Martin Eichenbaum, “Identification and the Liquidity Effect of
a Monetary Policy Shock”, in A. Cukierman, Z. Hercowitz, and L. Leiderman, eds.,
Political Economy, Growth, and Business Cycles, Cambridge: MIT Press, 1992, 335-370.




                                                                                       44
Christiano, Laurence, Martin Eichenbaum, and Charles Evans, “Monetary Policy Shocks:
What Have We Learned and to What End?”, in J. Taylor and M.Woodford, eds.,
Handbook of Macroeconomics, Amsterdam: North-Holland 2000.

Cochrane, John, “Shocks”, Carnegie Rochester Conference on Public Policy, vol. 41,
1994, 295-34.

Cochrane, John, “What Do the VARs Mean? Measuring the Output Effects of Monetary
Policy”, unpublished, University of Chicago, August 1996.

Croushore, Dean, and Charles Evans, “Data Revisions and the Identification of Monetary
Policy Shocks”, manuscript, Federal Reserve Bank of Philadelphia, 1999.

Eichenbaum, Martin, “Comment on ‘Interpreting the Macroeconomic Time Series Facts:
The Effects of Monetary Policy’”, European Economic Review 36, 1992, 1001-1011.

Eliasz, Piotr, “Likelihood-Based Inference in Large Dynamic Factor Models Using Gibbs
Sampling,” Princeton University, unpublished, 2002.

Faust, Jon and Eric Leeper, “When Do Long-Run Identifying Restrictions Give Reliable
Results?”, Journal of Business and Economic Statistics 15, 1997, 345-53.

Forni, M., M. Hallin, M. Lippi, and L. Reichlin, “The Generalized Dynamic Factor
Model: Identification and Estimation”, Review of Economics and Statistics 82,
November 2000, 540-54.

Forni, M. and L. Reichlin, “Dynamic Common Factors in Large Cross-Sections”,
Empirical Economics 21, 1998, 27-42.

Forni, M. and L. Reichlin, “Let’s Get Real: A Dynamic Factor Analytical Approach to
Disaggregated Business Cycles”, Review of Economic Studies, 65, 1998, 453-74.

Galì, Jordi, “How Well Does the IS-LM Model Fit Postwar Data?”, Quarterly Journal of
Economics 107, 1992, 709-38.

Gelman, A. and D. B. Rubin, “A Single Sequence from the Gibbs Sampler Gives a False
Sense of Security”, in J. M. Bernardo, J. O. Berger, A. P. Dawid, and A. F. M. Smith,
eds., Bayesian Statistics, Oxford: Oxford University Press, 1992.

Geman, S. and D. Geman, “Stochastic Relaxation, Gibbs Distributions and the Bayesian
Restoration of Images”, IEEE Transactions on Pattern Analysis and Machine
Intelligence, 6, 1984, 721-41.

Gerlach, Stefan and Frank Smets, “The Monetary Transmission Mechanism: Evidence
from the G-7 Countries”, Centre for Economic Policy Research discussion paper 1219,
1995.



                                                                                      45
Giannone D., Reichlin L. and Sala L. (2002), “Tracking Greenspan: Systematic and
Unsystematic Monetary Policy Revisited”.

Gordon, David and Eric Leeper, “The Dynamic Impacts of Monetary Policy: An Exercise
in Tentative Identification”, Journal of Political Economy 102, 1994, 1228-1247.

Hanson, Michael, “The ‘Price Puzzle’ Reconsidered”, working paper, Wesleyan
University, 2000.

Kadiyala, Rao and Sune Karlsson, "Numerical Methods for Estimation and Inference in
Bayesian VAR-Models", Journal of Applied Econometrics, Vol. 12, 1997, 99-132.

Kim, Chang-Jin and Charles R. Nelson, State-Space Models with Regime Switching,
Cambridge MA: MIT Press, 1999.

Kose, Ayhan, Christopher Otrok and Charles H. Whiteman, "International Business
Cycles: World, Region, and Country-Specific Factors", American Economic
Review, forthcoming.

Kose, Ayhan, Christopher Otrok and Charles H. Whiteman, "Understanding The
Evolution of World Business Cycles", unpublished paper, 2003.

Kozicki, Sharon, “Why Do Central Banks Monitor So Many Inflation Indicators?”,
Federal Reserve Bank of Kansas City, Economic Review 86, Third Quarter 2001, 5-42.

Lastrapes, William and George Slegin, “The Liquidity Effect: Identifying Short-Run
Interest Rate Dynamics Using Long-Run Restrictions”, Journal of Macroeconomics 17,
1995, 387-404.

Leeper, Eric, Christopher Sims, and Tao Zha, “What Does Monetary Policy Do?”,
Brookings Papers on Economic Activity 1996: 2, 1-63.

Leeper, Eric and Tao Zha, “Assessing Simple Policy Rules: A View from a Complete
Macroeconomic Model”, Federal Reserve Bank of St. Louis, July/August 2001, 83-110.

Orphanides, Athanasios, “Monetary Policy Rules Based on Real-Time Data”, American
Economic Review 91, September 2001, 964-85.

Pagan, Adrian, and J. C. Robertson, “Structural Models of the Liquidity Effect”, Review
of Economics and Statistics 80, 1998, 202-17.

Quah, Danny and Thomas Sargent, “A Dynamic Index Model for Large Cross Sections”,
in J. Stock and M. Watson, eds., Business Cycles, Indicators, and Forecasting, Chicago:
University of Chicago Press for NBER, 1993, 285-306




                                                                                     46
Rudebusch, Glenn, “Do Measures of Monetary Policy in a VAR Make Sense?”,
International Economic Review 39, November 1998, 907-31.

Sims, Christopher, “Interpreting the Macroeconomic Time Series Facts: The Effects of
Monetary Policy”, European Economic Review 36, 975-1000, 1992.

Sims, Christopher and Tao Zha, “Does Monetary Policy Generate Recessions?”, Federal
Reserve Bank of Atlanta, July 1998.

Stock, James, and Mark Watson, “New Indexes of Coincident and Leading Economic
Indicators”, NBER Macroeconomics Annual (4), Cambridge MA: MIT Press, 1989.

_______, “Diffusion Indexes”, NBER working paper 6702, 1998.

_______, “Forecasting Inflation”, Journal of Monetary Economics, 44, 1999, 293-335.

_______, “Macroeconomic Forecasting Using Diffusion Indexes”, Journal of Business
Economics and Statistics, 20:2, 2002, 147–162.

Strongin, Steven, “The Identification of Monetary Policy Disturbances: Explaining the
Liquidity Puzzle”, Journal of Monetary Economics 34, 1995, 463-97.




                                                                                        47
