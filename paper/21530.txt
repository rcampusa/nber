                              NBER WORKING PAPER SERIES

             PUBLIC AUDIT OVERSIGHT AND REPORTING CREDIBILITY:
                EVIDENCE FROM THE PCAOB INSPECTION REGIME

                                        Brandon Gipper
                                        Christian Leuz
                                         Mark Maffett

                                     Working Paper 21530
                              http://www.nber.org/papers/w21530

                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                         September 2015, Revised December 2019

For helpful comments and suggestions, we thank Ray Ball, Matthias Breuer, John Coates, Carol
Dee, Moritz Hiemann, Andrew Karolyi, Woochan Kim, Robert Knechel, S.P. Kothari, Clive
Lennox, Brian Miller, Miguel Minutti-Meza, Eddie Riedel, and Nemit Shroff; workshop
participants at Bocconi, Boston University, Chicago Booth, Columbia University, the Colorado
Summer Accounting Conference, the EAA conference, the FARS conference, the GCGC
Conference at Stanford, LMU/TU Munich, Ohio State University, PCAOB/JAR conference, UC
Riverside, and UCLA; and two anonymous reviewers. We also thank the PCAOB for numerous
discussions. Brandon Gipper was an Economic Research Fellow at the PCAOB, and Christian
Leuz was an Economic Advisor to the PCAOB. As a matter of policy, the PCAOB disclaims
responsibility for any private publication or statement by any of its Economic Research Fellows.
The views expressed in this paper are the views of the authors and do not necessarily reflect the
views of the Board, individual Board members, or the staff of the PCAOB. This study was not
funded by the PCAOB. Brandon Gipper gratefully acknowledges financial support from Stanford
University Graduate School of Business and the MBA Class of 1969 Faculty Scholarship.
Christian Leuz gratefully acknowledges financial support by the Initiative on Global Markets.
Mark Maffett gratefully acknowledges financial support from the University of Chicago Booth
School of Business and the Centel Foundation/Robert P. Reuss Faculty Research Fund. The
programs performing the statistical analyses in this paper are available on request. Send
correspondence to Christian Leuz, University of Chicago, Booth School of Business, 5807 S.
Woodlawn Ave., Chicago, IL 60637; telephone: +1 (773)-834-1996. E-mail:
cleuz@chicagobooth.edu. The views expressed herein are those of the authors and do not
necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2015 by Brandon Gipper, Christian Leuz, and Mark Maffett. All rights reserved. Short sections
of text, not to exceed two paragraphs, may be quoted without explicit permission provided that
full credit, including © notice, is given to the source.
Public Audit Oversight and Reporting Credibility: Evidence from the PCAOB Inspection
Regime
Brandon Gipper, Christian Leuz, and Mark Maffett
NBER Working Paper No. 21530
September 2015, Revised December 2019
JEL No. G14,G18,G38,K22,M41,M42,M48

                                         ABSTRACT

This paper studies the impact of public audit oversight on financial reporting credibility. We
analyze changes in market responses to earnings news after public audit oversight is introduced,
exploiting that the regime onset depends on fiscal year-ends, auditors, and the rollout of auditor
inspections. We find that investors respond more strongly to earnings news following public audit
oversight. Corroborating these findings, we find an increase in volume responses to 10-K filings
after the new regime. Our results show that public audit oversight can enhance reporting
credibility and that this credibility is priced in capital markets.


Brandon Gipper                                  Mark Maffett
Stanford University                             Booth School of Business
Graduate School of Business                     University of Chicago
655 Knight Way                                  5807 S. Woodlawn Ave
Stanford, CA 94305                              Chicago, IL 60637
gipperbr@stanford.edu                           mark.maffett@Chicagobooth.edu

Christian Leuz
Booth School of Business
University of Chicago
5807 S. Woodlawn Avenue
Chicago, IL 60637-1610
and NBER
cleuz@chicagobooth.edu
Introduction

       This paper studies the impact of regulatory oversight of auditing on financial reporting

credibility in capital markets. Theory suggests that credibility strengthens the response of investors

to a signal (e.g., Holthausen and Verrecchia 1988; Kim and Verrecchia 1991). Moreover, credible

financial reporting could generate significant cost of capital benefits (e.g., Diamond and

Verrecchia 1991). Thus, credible reporting is often viewed as a cornerstone of well-functioning

capital markets (Summers 1999). However, what assures reporting credibility? High-profile

accounting scandals illustrate that reporting credibility can quickly vanish, often triggering

regulatory responses to restore it (Hail, Tahoun, and Wang 2018). Thus, examining whether

regulatory oversight enhances reporting credibility is important. We analyze this question and

(more broadly) the role of reporting credibility in capital markets by exploiting a change in audit

oversight. The focus on audit oversight maps well into our broader research question because

auditors’ assurance of firms’ financial reporting is essentially a credence good for outside

investors.

       In 2002, the U.S. Congress passed the Sarbanes-Oxley Act (“SOX”) in an effort to restore

reporting credibility after several scandals in the early 2000s. To achieve this objective, SOX

focused on the process by which financial reports are prepared and audited. One of its core

provisions was the creation of the Public Company Accounting Oversight Board (“PCAOB”),

which was tasked with overseeing and inspecting all audit firms (“auditors”) of SEC-registered

public companies (“firms” or “issuers”). This new regime represents a major shift from self-

regulation to public oversight of the audit profession. It did not come with new financial

disclosures, but rather was intended to increase the credibility of independent auditing and firms’

audited financials.



                                                  1
         In light of the numerous agency problems in auditing (e.g., Watts and Zimmerman 1983;

Duflo et al. 2013), stricter oversight could, in principle, increase audit quality and in turn raise the

credibility of financial reporting. However, it is not clear whether public oversight necessarily

improves upon peer review. Auditing faces economic trade-offs between expertise, incentives, and

independence (e.g., Hilary and Lennox 2005; DeFond 2010; DeFond and Zhang 2014). Similarly,

regulatory economics points to potential problems with public sector regulators, such as resource

constraints, inefficient bureaucracies, regulatory capture, and political pressure (e.g., Demsetz

1968; Stigler 1971; La Porta, Lopez-De-Silanes, and Shleifer 2006). Thus, the effect of the new

oversight regime on reporting credibility is not obvious; widespread skepticism remains as to

whether the PCAOB regime has reassured investors (e.g., Coates and Srinivasan 2014). 1

         We analyze marketwide changes in reporting credibility after the introduction of the

PCAOB to learn about the role of reporting credibility in capital markets and to study whether

public oversight can enhance or restore credibility after a major shock. The hypothesized

mechanism for such an effect is that the new oversight regime spurs improvements in auditing

relative to the peer review regime (e.g., because of larger penalties, better enforcement, or because

PCAOB inspections identify more audit deficiencies) and that investors learn about these

improvements and adjust their assessments of firms’ reporting credibility accordingly. 2

         Our identification strategy exploits the staggered rollout of the PCAOB regime, which

affects firms at different points in time depending on their auditors, fiscal year-ends, and the timing

of the new auditor inspections. The PCAOB regime was rolled out in three phases: (1) one-time


1
  See, for example, Wall Street Journal (2010) and Hilzenrath (2010). Consistent with these concerns, Hilzenrath
(2010) states that “the [PCAOB] looks a lot like the system it was designed to replace: slow to act, veiled in secrecy
and weak—or weak willed,” and Glover, Prawitt, and Taylor (2009) characterize the PCAOB’s inspection model as
“inefficient and dysfunctional.”
2
  Our analysis is a joint test of the hypotheses that (a) audit oversight has an effect and (b) investors have reasonably
accurate assessments of changes in audit oversight and auditing. Thus, in our analysis, a no result could have several
explanations and could occur even if public audit oversight is effective.

                                                           2
limited-scope inspections for the U.S. Big Four auditors (Deloitte & Touche, Ernst & Young,

KPMG, and PricewaterhouseCoopers) in 2003; (2) annual full inspections (starting in 2004) for

all auditors with more than 100 issuers (hereafter, “large auditors”); and (3) triennial, full

inspections (starting in 2004) for auditors headquartered in the United States that issued a report

for one to no more than 100 issuers (hereafter, “small auditors”). Because the first two phases are

clustered in time, we use firms with non-U.S. auditors as a control group. For the third phase, we

exploit the staggering of the 3-year rollout and use other triennially inspected auditors as a control

group. For all phases, we use a generalized difference-in-differences design that compares earnings

response coefficients (ERCs) before and after the respective inspections have taken place and

firms’ auditors have been treated.

       Relying on prior theoretical work (e.g., Holthausen and Verrecchia 1988; Kim and

Verrecchia 1991), we measure investors’ assessments of reporting credibility based on how

strongly they respond to a given amount of earnings news. Ceteris paribus, the market response to

earnings news should increase (regardless of its sign) if investors believe the numbers are more

credible. We operationalize reporting credibility by computing an ERC, which reflects short-

window stock market reactions to (standardized) unexpected earnings news at the earnings

announcement. Specifically, we measure ERCs based on the association between 3-day cumulative

abnormal returns (CARs) centered on the earnings announcement date and unexpected earnings

news (defined as the difference between a firm’s actual, annual earnings per share (EPS), and the

median analyst forecast). Prior research has used ERCs to assess the credibility of audit firms (e.g.,

Teoh and Wong 1993) and the credibility effects of earnings restatements (e.g., Wilson 2008;

Chen, Cheng, and Lo 2014). We build on this prior literature and use ERCs to study the effects of




                                                  3
public audit oversight on financial reporting credibility. 3

        From a research design perspective, ERCs are well suited for our identification strategy,

which exploits the staggered introduction of the PCAOB regime as well as variation in auditors’

and firms’ fiscal year-ends. First, an ERC should not change in anticipation of an expected (future)

improvement in credibility, but only after more credible earnings are released. Moreover, ERCs

are measured over a short window around firms’ earnings announcements, which are spread out

in calendar time and depend on predetermined fiscal year-ends. These features are critical when

using a staggered research design like ours. Despite its conceptual appeal, the use of ERCs requires

assumptions and has drawbacks. First, ERCs require a measure of expected earnings in order to

determine earnings news. We use consensus analyst forecasts, which are known to exhibit biases

and to imperfectly reflect investors’ expectations. Second, ERCs are not directly observable for a

given announcement but must be estimated from a sample of announcements, which likely

introduces noise and reduces the power of the analyses.

        In our empirical analysis, we first examine changes in reporting credibility for U.S. firms

with large auditors after limited and full inspections, relative to non-U.S. firms traded on U.S.

exchanges (i.e., cross-listed firms) with large non-U.S. auditors. These cross-listed firms are

subject to U.S. market events and other aspects of the U.S. regulatory regime, but their non-U.S.

auditors are outside the scope of the PCAOB’s initial inspections. Consistent with public oversight

increasing investors’ assessments of reporting credibility, we find that the ERCs of firms with

auditors that are subject to the new PCAOB regime increase significantly compared to the ERCs

of the control group. The effect becomes statistically significant after the PCAOB releases the

reports from its 2003 limited inspections and strengthens even more after the PCAOB conducts


3
 We also validate ERCs as an approach to studying reporting credibility and its effects in markets, showing that
ERCs decline when the quality of auditing is in question. See Internet Appendix §2.

                                                         4
the full inspections in 2004. We also find that the ERC effects are concentrated in profitable firms,

which is expected based on prior work showing that loss firms have minimal ERCs because of the

transitory nature of losses (e.g., Hayn 1995). The estimated credibility effects are economically

meaningful, suggesting an almost 20% increase in ERCs. They are also comparable in magnitude

to ERC declines around major credibility shocks.

         Our key empirical challenge is to isolate the effects of the PCAOB regime from other

events, including (a) any other contemporaneous macroeconomic or capital market changes, (b)

other SOX provisions unrelated to audit oversight, and (c) market responses to the accounting

scandals. For instance, regulatory changes for firms’ internal controls (stipulated by SOX Section

404[b]) could improve reporting credibility independent of public audit oversight. Similarly, after

the Enron scandal, investors likely expected firms (especially former Arthur Andersen clients) to

provide more assurance about their financial reporting, even in the absence of a regulatory

response (e.g., Leuz and Schrand 2009). We perform a number of additional analyses to address

this challenge and corroborate our inferences. First, we provide evidence that concurrent changes

in firms’ information environments are unlikely to drive our results. 4 Second, we show that the

increase in ERCs after the regime change is not concentrated in former Arthur Andersen clients,

where firm responses should be most pronounced. Third, our results are even stronger for firms

that were exempt from Section 404[b] compliance, and are also robust to separately controlling

for the onset of SOX Sections 302[a] and 404[b].

         Our second set of analyses focuses on changes in reporting credibility for firms with small

auditors, for which the new regime was phased in over 3 years. This staggered implementation


4
  We show that our findings cannot be explained by changes in (a) the magnitude of unexpected earnings, (b) the
timing and relative amount of disclosure prior to the earnings announcement, (c) analysts’ forecast bias, (d) the accrual
component of reported earnings, (v) management earnings guidance, or (e) guidance bundling. We also check whether
changes in the bundling of earnings announcements with 10-K releases drive our results.

                                                           5
allows us to estimate ERC changes within small auditors using only the variation in the timing of

initial treatment, eliminating the need to use cross-listed foreign firms as a control group.

Importantly, for small auditors, there is very little overlap between the introduction of PCAOB

inspections and the effective dates of other SOX provisions. Thus, this setting allows us to more

cleanly disentangle the impact of the PCAOB regime from other SOX provisions as well as other

concurrent events. Similar to our findings for large auditors, our results indicate a significant

increase in ERCs as the new regime is rolled out; again, the effects are concentrated in profit firms.

        As a final sensitivity check, we use abnormal trading volume around firms’ 10-K filings as

an alternative proxy for reporting credibility. While this proxy is conceptually less appealing than

ERCs, it is still based on the idea that investors trade more in response to more credible financial

reports (Kim and Verrecchia 1991). Consistent with this prediction (and with the ERC results), we

find that abnormal volume responses to 10-K filings increase under the new regime.

        Our paper contributes to the literature in several ways. First, we provide evidence on the

pricing of reporting (or signal) credibility in capital markets, as measured by investors’ responses

to earnings news. Prior research provides evidence that the assurance by external auditors enhances

the pricing of earnings news in the capital markets; this research often focuses on auditor reputation

and similar attributes (e.g., Teoh and Wong 1993; Moreland 1995; Wilson 2008; Chen, Cheng,

and Lo 2014; Marshall, Schroeder, and Yohn 2018). By exploiting a regime change in audit

oversight that is arguably exogenous to any given auditor or firm, we provide novel evidence on

credibility effects in capital markets and the extent to which public oversight can increase the

credibility of audited financial reports. It is not a priori obvious that such a government intervention

improves reporting credibility or that it restores confidence after a major shock like the accounting

scandals of the early 2000s. As such, our study also adds to the literature on the merits of private



                                                   6
versus public enforcement of regulation (La Porta, Lopez-De-Silanes, and Shleifer 2006; Jackson

and Roe 2009), which generally focuses on the activities of securities regulators. For example,

Duro, Heese, and Ormazabal (2018) examine the effects of disclosing SEC oversight activities on

investor responses to earnings news. Prior auditing studies have focused on litigation and

reputation as mechanisms that discipline or incentivize auditors (DeFond 2010 & 2012). In

contrast, we provide evidence on auditors and on the public regulatory oversight of auditing.

       Second, we contribute to the literature on the effects of SOX (see Coates and Srinivasan

2014 and Leuz and Wysocki 2016 for reviews). Many of these studies evaluate the effects of SOX

as a whole (e.g., Chhaochharia and Grinstein 2007; Iliev 2010). For instance, Iliev (2010) examines

specific costs (audit fees) and benefits (earnings quality) as well as the net effects of SOX on

smaller firms’ market value. In turn, we provide evidence on the capital market effects of the

introduction of the PCAOB, an integral part of SOX. Although a large literature studies the

PCAOB (see Abernathy, Barnes, and Stefaniak 2013 and DeFond and Zhang 2014 for reviews), it

does not provide a capital market-based assessment of the new regime, which is our focus. Prior

studies investigate differences in audit quality for auditors subject to PCAOB inspections using

variation in inspections of non-U.S. auditors (e.g., Lamoreaux 2016; Fung, Raman, and Zhu 2014).

Previous research also studies PCAOB inspection reports, including their content and effects on

returns, client responses, and audit quality (e.g., Lennox and Pittman 2010; DeFond and Lennox

2011 and 2017; Gunny and Zhang 2013), as well as market reactions and client responses to the

2007 PCAOB sanctions against Deloitte & Touche (e.g., Dee, Lulseged, and Zhang 2011; Boone,

Khurana, and Raman 2015). Among other things, this research suggests that the PCAOB regime

led to changes in auditing and that capital markets and clients respond to PCAOB inspection

reports. These findings help explain the mechanism for our results, but they do not imply that the



                                                7
new regime enhanced reporting credibility as perceived by investors. In fact, a frequent criticism

of the PCAOB is that its inspections lead to costly process outcomes (e.g., more documentation

and work for auditors) that do not significantly enhance audit or reporting quality. By providing

evidence that the PCAOB regime increases investors’ assessments of reporting credibility, we add

to this work by showing that these changes in public oversight of auditing matter to investors. Of

course, the new regime has costs and we do not examine net benefits.

        A few studies examine the PCAOB regime change overall. Specifically, our paper

complements Shroff (2019) and Aobdia and Shroff (2017), who focus on real- and audit-market

effects. Perhaps closest to ours are Krishnan, Krishnan, and Song (2017), who examine the effects

of first-time PCAOB inspections of foreign auditors of U.S. cross-listed firms on the value

relevance of earnings and book value. 5 They find that the value relevance of accounting numbers

increases in the post-inspection period for clients of inspected auditors. However, this effect is

estimated relative to other clients of the same auditor and hence exists only for inspected-client

engagements, and not the audit firm. Our analysis provides evidence of an increase in reporting

credibility for all U.S. firms after their auditors are subject to the PCAOB regime.

2.      Empirical Approach, Institutional Setting, and Presumed Mechanism

        Our empirical analysis connects key dates for the rollout of the PCAOB oversight regime

to subsequent changes in the market’s assessment of reporting credibility for U.S. firms overall.

We deliberately take the approach of studying marketwide shifts in investors’ assessments of

reporting credibility. An alternative approach would be to examine specific audit process outcomes

(e.g., inspection findings, audit hours, audit opinions). While studying such outcomes is clearly



5
  Although the value relevance approach also tests whether the market pricing of accounting numbers changes, the
long-run nature of value relevance regressions makes it difficult to control for concurrent but unrelated economic
shocks and does not allow for a research design that exploits the rollout of the new regime (as does our study).

                                                        8
important, these outcomes do not indicate whether public audit oversight enhances reporting

credibility in capital markets. It is conceivable that auditors spend more time on documentation in

the new regime but that investors do not value this increase in audit hours. For this reason, we do

not focus on inspection reports or specific audit outcomes, but instead examine investor responses

to earnings news in capital markets.

         Because we take a market-based approach, our analysis cannot separately evaluate the

impact of specific regime elements, such as changes in audit standards, inspections, or penalties.

Instead, our analysis assesses the effects of the new public oversight regime overall relative to the

prior regime. Because this approach does not specify the mechanism through which public

oversight affects reporting credibility, it is important to spell out a potential mechanism that links

the change in audit oversight to changes in investors’ credibility assessments. Specifically, we

expect a credibility effect in markets if (1) the new public regime represents a meaningful change

in audit oversight relative to the peer review regime; (2) PCAOB inspections identify meaningful

deficiencies in the way audits are conducted, and stricter oversight spurs improvements in auditing

that extend beyond a single engagement; 6 and (3) investors learn about these changes and adjust

their assessments of reporting credibility for U.S. firms accordingly.

         To gauge the plausibility of this mechanism, we conduct an extensive search for

descriptive, institutional, and academic evidence on each of the three elements of this presumed

mechanism. Section 1 of the Internet Appendix (“IA§1”) presents this evidence. We briefly

summarize it here.


6
 We view the PCAOB as primarily playing an oversight and enforcement role. Although auditors are likely aware of
changes they could make that would improve audit quality, such changes are costly, and it is not obvious that firms
are willing to pay for them. The observed level of audit quality is not necessarily optimal for the market as a whole
because individual auditors and firms do not internalize the full costs of a marketwide decline in the credibility of the
audit profession or corporate reporting. In this situation, stricter public oversight could force auditors to undertake
costly changes that they likely would not have made in the absence of oversight, which includes inspections and
potential penalties.

                                                           9
       First, we examine whether the shift from (private) peer review to (public) PCAOB

oversight represents a meaningful change in audit regulation (see IA§1 Part 1). The peer review

regime was funded by the profession itself, and auditors were inspected by other auditors. Even

for large auditors, peer reviews were relatively infrequent—occurring only once every 3 years. A

perceived lack of independence and weak enforcement were frequently raised concerns about the

peer review regime (e.g., Fogarty 1996; Hilary and Lennox 2005; Glover, Prawitt, and Taylor

2009; Doty 2011). In contrast, the PCAOB is a quasi-public agency established by SOX, funded

largely by issuers, and overseen by the SEC. Section 104 of SOX tasks the PCAOB with the

responsibility of inspecting registered accounting firms (i.e., auditors) and their audits of public

issuers. PCAOB inspections extend to the (issuer-specific) engagement level. For large auditors

(i.e., those that issue audit reports for more than 100 issuers), the PCAOB conducts annual

inspections. All other auditors are subject to triennial inspections.

       A PCAOB inspection assesses an auditor’s compliance with: SOX, the rules and standards

of the PCAOB, SEC rules, and professional audit standards (PCAOB 2004a). A full inspection

includes (1) reviews of selected audits, (2) an evaluation of the sufficiency, documentation, and

communication of the quality control systems, and (3) other testing of audit procedures as deemed

necessary. The PCAOB has substantial enforcement authority and a wide array of penalties (see

IA§1 Part 2).

       To corroborate the mechanism’s second element, we provide descriptive evidence that (a)

PCAOB inspections identify meaningful weaknesses and deficiencies in auditing procedures (see

IA§1 Part 3) and (b) that these findings lead to subsequent changes in auditing and financial

reporting that last beyond the respective engagement (see IA§1 Part 4). Conceptually, lasting

improvements in audit procedures beyond a single engagement are critical for the market to



                                                  10
increase its overall assessment of credibility, as the mere revelation of previously unidentified

deficiencies will likely lower investors’ credibility assessments. Although stricter oversight could

initially reveal more audit failures (to which investors presumably respond negatively), a stricter

regime should ultimately enhance credibility if it leads to broader improvements in audit quality

that spillover to other engagements and auditors. 7 Toward this end, the PCAOB regime not only

identifies deficiencies but also requires subsequent changes in audit procedures (known as

“remediation”). If, during their fieldwork, inspectors identify potential deficiencies in one or

multiple engagements, the PCAOB gives the auditor the opportunity to respond. If the response is

not satisfactory, the deficiency is included in the inspection report as a “Part I finding.” While the

inspection report does not reveal which engagements were inspected or had Part I findings,

auditors are required under PCAOB rules to remediate Part I findings, both contemporaneously,

by performing additional audit work to validate the issued audit opinion, and prospectively, in

future audit engagements. Consistent with this, DeFond and Lennox (2017) provide large sample

evidence that PCAOB inspections improve internal control audits.

        The PCAOB also evaluates auditors’ firmwide quality control systems. If the auditor

addresses any quality control criticisms successfully within a 12-month remediation period, the

findings remain confidential. Otherwise, the PCAOB publicly releases these criticisms as “Part II

findings.” In 2004, when the new regime was phased-in, all Big Four auditors had quality control

criticisms in their initial limited inspections (PCAOB Release 104-2006-078). The existence of

these Part II findings indicates that inspections led to audit- and firmwide quality control changes.

Such evidence is particularly important for our analysis because quality control criticisms by



7
  Note that although the PCAOB does not reveal which engagements were inspected, it does produce publicly
observable outcomes (specifically, auditor-level inspection reports) that allow investors to update credibility
assessments.

                                                      11
definition are broader, extending beyond a single engagement.

       The mechanism’s third element is public information about the new oversight regime and

the resulting changes in auditing practices that enable investors to update their credibility

assessments. In IA§1 Part 5, we provide examples of numerous public sources that allowed

investors to learn about the scope and effectiveness of the new regime. These examples illustrate

that investors had meaningful information from several sources—including (1) the legislation

creating the PCAOB as well as the initial authoritative pronouncements issued by the PCAOB; (2)

PCAOB inspection reports and auditor responses to these reports; and (3) the news media—upon

which they could rely to form assessments of the regime’s effects on reporting credibility.

       In sum, the institutional facts and descriptive evidence presented above support each of the

three elements of the mechanism by which the new oversight regime could create greater reporting

credibility for U.S. firms. Whether such regulatory oversight improves investors’ credibility

assessments of audited financial statements is an empirical question.

3.     Empirical Measures, Research Design, and Sample Selection

3.1    Defining and measuring reporting credibility

       Theory suggests that credibility strengthens the response of investors to signals. More

specifically, investors should respond more strongly to a given level of earnings surprise (relative

to expectations) if they believe that reported earnings accurately reflect economic performance.

Holthausen and Verrecchia (1988) formalize this prediction using a noisy-rational expectations

model with two consecutive information releases: an analyst forecast and an earnings

announcement. Under fairly general conditions, they show that the variance of the price reaction

to the earnings announcement (i.e., the second release) is unambiguously nondecreasing in the

signal-to-noise ratio of the earnings surprise (see their proposition 1). An increase in credibility is



                                                  12
tantamount to an increase in the signal-to-noise ratio and, more specifically, to an increase in

investors’ assessments of the precision of the earnings news (see also Kim and Verrecchia 1991).

Thus, we use the strength (or sensitivity) of short-term market responses to earnings surprises as a

proxy for credibility. This construct is commonly referred to as the earnings response coefficient

(ERC) and is estimated by regressing abnormal returns at the earnings announcement on the

respective earnings news (see Section 4.1 for notation and more details).

         In addition to its sound theoretical underpinning, there is also a substantial empirical

precedent for using ERCs as a proxy for investors’ assessments of reporting credibility (see

Kothari 2001; Dechow, Ge, and Schrand 2010 for reviews). 8 Even more relevant to us, many

empirical studies use ERCs in audit-specific settings as a proxy for reporting credibility and to

assess the capital market effects of changes in audit quality (e.g., Teoh and Wong 1993;

Hackenbrack and Hogan 2002; Francis and Ke 2006; Wilson 2008; Chen, Cheng, and Lo 2014;

Marshall, Schroeder, and Yohn 2018).

3.2      Research design and earnings response coefficients

         From a research design perspective, ERCs are also well suited for our identification

strategy, which exploits the staggered introduction of the PCAOB regime and variation in auditors’

and firms’ fiscal year-ends. 9 ERCs should not change in anticipation of future improvements in

audit quality and reporting credibility. That is, ERCs reflect the credibility of reported earnings at

a specific point in time (i.e., the earnings announcement). This feature is critical when using a

staggered design. In contrast, firms’ stock returns, market values, or cost of capital would likely




8
  In IA§2, we provide additional evidence to support our use of ERCs to capture audit-related differences in reporting
credibility; this includes an examination of the ERCs and F-scores of Big Four auditor clients and an examination of
ERC changes following the PCAOB’s enforcement action against Deloitte & Touche in December 2007.
9
  In IA§3, we present a stylized time line for the introduction of the PCAOB regime and the related changes in reporting
credibility and ERCs. This time line provides the conceptual underpinnings for our research design.

                                                          13
reflect the PCAOB regime’s impact much earlier, and hence would not allow us to exploit the

staggered introduction. In addition, ERCs are measured over short windows around firms’ earnings

announcements, which are spread out in calendar time and depend on predetermined fiscal year-

ends. These are desirable features from an identification perspective.

       However, there are also some assumptions and drawbacks. First, ERCs require a measure

of expected earnings in order to determine earnings news. We use consensus analyst forecasts,

which are known to exhibit biases and imperfectly reflect investors’ expectations. Second, ERCs

are not directly observable for a given announcement but must be estimated from a sample of

announcements. This likely introduces noise and reduces the power of the analyses. We use several

approaches to deal with this noise and also consider abnormal volume reactions around the release

of firms’ 10-Ks as an alternative measure of reporting credibility (see Section 4.4). Third, ERCs

change for reasons other than reporting credibility. We directly control for several known ERC

determinants (see Collins and Kothari 1989) and employ a difference-in-differences design that

strips out time-invariant biases in the ERC estimation in order to isolate credibility effects.

       Nonetheless, we recognize that stricter audit oversight could have other effects beyond

changes in reporting credibility that indirectly affect firms’ disclosure and reporting. Thus, we

acknowledge that our analysis does not capture all the reporting effects of public audit oversight;

instead, it focuses on credibility changes as measured by ERCs. We also note that the potential

effects of audit oversight on disclosure and reporting could potentially confound an ERC analysis.

Given this concern, we gauge the extent to which changes in ERC components and/or disclosure

and reporting affect our inferences (see Section 4.2 for details).

3.3    Timing of the regime change and control firms

       If public audit oversight is effective in increasing reporting credibility, we expect ERCs to



                                                 14
increase after auditors and firms are treated under the new regime. Thus, it is critical to isolate the

timing of the treatment and to determine what counterfactual to use.

        In June 2003, the PCAOB began limited inspections of U.S. Big Four auditors. The

PCAOB conducted fieldwork and released inspection reports at approximately the same time for

all limited inspections (see Table A1 in Appendix A). In 2004, the PCAOB conducted full

inspections of large U.S. auditors and the first round of triennial inspections of small U.S. auditors.

We examine the effects of the new regime on reporting credibility for each of the three distinct

phases of the PCAOB regime introduction (i.e., limited, full, and triennial inspections). For each

phase, we use a difference-in-differences analysis. It is unclear ex ante when investors adjust their

credibility assessment and hence which phase is most relevant. The initial 2003 inspections were

limited in scope. 10 Additionally, it takes time for auditors to adjust their audit procedures in

meaningful ways and for investors to learn about these changes. Thus, the first full inspections are

more likely to be the relevant treatment for large auditors.

        Furthermore, limited and initial full inspections are clustered in time. Therefore, the first

set of analyses relies on non-U.S. firms that are cross-listed on U.S. exchanges. This control group

has several desirable features as well as potential drawbacks. The first benefit is that cross-listed

control firms are audited by non-U.S. Big Four and Grant Thornton affiliates that (in 2003 or 2004)

are not subject to PCAOB inspections, but are still required to comply with other SOX provisions

at the same time as U.S. issuers (with one exception discussed later). 11 This feature helps us

separate the PCAOB regime and other SOX provisions. Second, these issuers are exposed to the



10
   Limited inspections involved all components of full inspections, but were scaled down in extent (e.g., a lower
number of individual audit engagements inspected), because, at that time, the PCAOB was still in the process of
staffing up and building out its inspection regime (PCAOB 2004b). In the United States, the Big Four voluntarily
agreed to participate in the limited inspections as the official PCAOB registration process had not yet begun.
11
   In IA§1 Table IA6A, we provide details on the timing of the adoption of other SOX provisions, broken down by
U.S. versus foreign firms and accelerated filer status.

                                                       15
U.S. market conditions and information environment, which makes it more likely that the

treatment and control groups would have similar ERC trends in the absence of the PCAOB regime.

However, we acknowledge that foreign, cross-listed issuers could be differentially affected by

shocks in the United States (e.g., Bailey, Karolyi, and Salva 2006), which could bias our analysis.

For this reason, we carefully examine the validity of the parallel trends assumption in our setting

(see Section 4.1 and IA§4). Third, foreign cross-listed issuers could experience similar treatments

at home if these countries implement audit oversight reforms similar to those in the United States. 12

Moreover, it is possible that non-U.S. auditors change their procedures because the PCAOB

inspects their U.S. affiliates. Both spillover effects would lead us to underestimate the impact of

the U.S. audit regime. Given these possibilities, it is useful to have a set of analyses that does not

rely on foreign control firms.

         In the triennial inspection analyses, we exploit the fact that the PCAOB phased-in small-

auditor inspections over 3 years, which allows us to use (only) U.S. firms whose auditors have not

yet been inspected by the PCAOB as the control group. Thus, we can identify the effects of the

new oversight regime based solely on differences in inspection timing. This within-group design

greatly mitigates concerns about the parallel trends assumption. 13 The 3-year rollout helps control

for unrelated macroeconomic shocks and concurrent regulatory changes (including SOX). The

primary drawbacks of this analysis are (a) the relatively small sample of U.S. issuers with

triennially inspected, small auditors and (b) the possibility that auditors in later inspection cohorts

could make anticipatory adjustments based on the results from earlier inspection cohorts. This


12
   In IA§1 Table IA6B, we provide details on the adoption timing of audit oversight regulation in other countries and
discuss our basis for concluding that these regulations likely have little impact on our analyses.
13
    In IA§1 Table IA6D, we explicitly compare the timing of the initial PCAOB triennial inspections and the
implementation of SOX provisions 404[b] and 302[a] and find that the overlap is very small (around 10% or less). To
assess the similarity of clients of triennially inspected auditors, we compare firm characteristics across the years in
which the auditors were initially inspected (or the years in which their inspection reports were released). We find no
systematic differences across firms inspected in different years (untabulated).

                                                         16
concern about preemptive auditor adjustments also arises in our large-auditor analysis, though to

a lesser extent.

        Although we examine three different events related to the rollout of the PCAOB regime, it

is important to note that that these events are not independent. Moreover, there is the possibility

that our effects could be biased downward if audit firms make changes ahead of their inspections

and the market anticipates these changes (particularly for later triennial inspections). However,

several aspects of our research design and credibility measure suggest that such anticipation effects

are likely to be small. First, as noted before, ERCs should change only after the new regime is in

place and hence do not reflect expected future improvements in credibility. Second, given the

credibility issues auditors faced in the wake of the accounting scandals, any voluntary (or pre-

regime) improvements were likely to be viewed with skepticism by the market. Third, the large

number of Part I findings in PCAOB inspection reports (even in later stages of the regime rollout)

provides little indication of anticipatory improvements by the auditors. Thus, it is reasonable to

expect that investor responses to earnings surprises do not change until auditors have been treated

by the new regime and investors learn about these changes.

        Based on this logic, the earliest possible date that the ERC could reflect an increase in

credibility is after the completion of the PCAOB’s inspection fieldwork for a given auditor. The

latest date for an ERC response is the public release of the inspection report. As it is not obvious

exactly when the market updates its assessment (and hence when ERCs respond), we use both

dates as alternative cutoffs and estimate treatment effects based on ERCs at the first earnings

announcement after each alternative date.

        Using the fieldwork end date as the cutoff, we define an issuer as treated when its fiscal




                                                 17
year-end occurs in or after the month that inspection fieldwork ends for its auditor. 14 By that time,

the auditor can use information from its PCAOB inspection to improve other audits that have not

advanced from the planning stage. 15 If the inspection leads to lasting improvements in audit quality

beyond the inspected engagements, and investors learn about these improvements (or expect them

to have taken place), reporting credibility could increase shortly after fieldwork is completed.

However, many fiscal year-ends occur well after the completion of fieldwork and there is a lag

from a firm’s fiscal year-end until its earnings announcement. Thus, there is generally a

considerable amount of time between the completion of the fieldwork and our measurement of

ERCs, giving auditors time to adjust their procedures and for the market to become aware of these

changes. If we use the release date of the PCAOB inspection report as an alternative cutoff, there

is an even longer period during which the auditor can adjust procedures and investors can learn

about these changes. When we use the report release date as the cutoff, we define an issuer as

treated when it first announces earnings after the PCAOB posts the inspection report for the firm’s

auditor online.

         Importantly, while inspection reports do not reveal which audit engagements were

inspected, they provide investors with information about the changes in audit procedures that arise

from the inspections. Thus, the reports allow investors to update their assessments about the

strictness of audit oversight (e.g., relative to their expectations at the enactment of SOX). In

principle, this adjustment could go either direction. For instance, it is conceivable that the

inspection reports reveal that the oversight regime is less strict than expected, so credibility goes


14
   For the Big Four, fieldwork typically lasts between 5 to 7 months. For small auditors, inspections are shorter, so we
add 30 days to fieldwork completion when defining the cutoff date to allow small auditors to adjust audit procedures.
See Table A1 and Figures A1 and A2 in Appendix A for more details on timing and an illustration of our research
design for annually inspected auditors. See the Internet Appendix for an illustration for triennially inspected auditors.
15
   Aobdia (2018) notes that PCAOB inspectors normally share feedback on auditing deficiencies during on-site
inspections. For example, the substance of the inspection comment forms, which are a precursor to Part I findings, is
shared on site during fieldwork (Riley et al. 2008).

                                                          18
down. For this reason, we do not compute incremental changes in the ERC from the end of

fieldwork to the report release. Rather, we estimate long-run changes in (short-window) ERCs

relative to the pre-PCAOB-regime period and test whether ERCs have increased.

3.4      Sample selection and composition

         We obtain (a) accounting, auditor, and market data from Compustat, (b) additional auditor

data from Audit Analytics, (c) analyst forecasts and accounting data from I/B/E/S, (d) market data

from CRSP, and (e) fieldwork and inspection dates from the PCAOB’s Web site. All data are

publicly available. For the analyses of annually inspected auditors, we define a roughly 4-year

window around treatment such that we typically have 2 fiscal year-ends before and after the

respective cutoff date. For the limited inspections, using the fieldwork (inspection report) cutoff

date, the sample period is from December 2001 to November 2005 (June 2002 to May 2006) and

the sample includes firms whose fiscal year-ends that fall into this window. For the limited

inspections, we include the full sample of cross-listed control firms because (at that time) there

were no formal cooperative agreements between the PCAOB and the home-country regulators of

non-U.S. firms to conduct inspections in non-U.S. jurisdictions. For the full inspections of Big

Four and Tier-Two auditors, using the fieldwork (inspection-report) cutoff date, the sample period

is from June 2002 to December 2006 (July 2003 to November 2007) and the sample includes firms

whose fiscal year-ends that fall into this window. For the full inspection control sample, we

exclude cross-listed firms from countries with an inspection agreement with the PCAOB during

or before our analysis window. 16 The control group also includes firms from countries unavailable


16
   The PCAOB commenced full inspections on some non-U.S. Big Four affiliates in 2005. In April 2005, KPMG
Canada was the first inspected. Australia signed an agreement with the PCAOB on July 16, 2007. We exclude
Australian control firms when there is an overlap with the timing of the full inspection report release. We also exclude
firms from South Korea, which signed a confidential undated agreement with the PCOAB. See
http://pcaobus.org/International/Pages/RegulatoryCooperation.aspx for details.


                                                          19
for inspection. 17

         Panel A of Table 1 provides details about the sample composition for the limited and full

inspection analyses for the treatment and control groups by auditor, inspection type, and treatment

date. For the limited inspections, the number of treatment firms is similar across auditors. For the

full inspections, among the Big Four, there are a similar number of treatment firms, whereas other

large (Tier-Two) auditors have fewer firms than the Big Four. Combining inspections and

respective groups, our treatment sample includes 4,289 unique domestically audited firms over

37,001 firm-years, while our control sample includes 579 unique non-U.S. firms over 3,765 firm-

years. 18 In IA§5, we provide a breakdown of the treatment and control samples by auditor location.

         Panel B of Table 1 provides details about the sample for the triennially inspected auditor

analyses. The sample size is 1,338 firm-year observations. As expected, there is significant

variation in inspection timing because of the triennial cycle. To avoid overlap with the 2008

financial crisis, we exclude fiscal years ending after Q2 of 2008 from our analysis.

3.5      Descriptive statistics

         Panels A–D of Table 2 present descriptive statistics for domestic issuers with large

annually inspected auditors (i.e., the treatment group in the limited and full inspection analyses),

cross-listed firms with non-U.S. auditors (i.e., the control group in the limited and full inspection

analyses), a comparison of means between these subsamples, and issuers with triennially inspected

auditors, respectively. The first two variables are the key inputs to estimate the ERC: the CAR at

the earnings announcement and the earnings surprise or unexpected earnings (UE). Our primary

control variables are Loss, Size, Market-to-book, Leverage, Persistence, and Beta. The other


17
  http://pcaobus.org/International/Inspections/Pages/IssuerClientsWithoutAccess.aspx (accessed January 2015).
18
  Non-U.S. Grant Thornton affiliates are included in the full inspection control sample. Other Tier-Two auditors are
not included, because Audit Analytics does not identify foreign affiliates for these auditors. We do not include Grant
Thornton in the control group for the limited inspections in order to provide a clean within-Big-Four comparison.

                                                         20
variables in Table 2 are used in additional sensitivity tests. We also count the number of days

between the respective cutoff date for the auditor’s initial treatment (i.e., either the end of fieldwork

or the report release) and the firm’s earnings announcement at which the first post-treatment ERC

is measured (Timing: Treatment to first EA (in days)). The variable indicates that our design allows

for a substantial time lag during which auditors could adjust their procedures and where investors

could learn and price the effects of the regime change.

        In panel C, we see that the control sample is similar to the treatment sample along most

dimensions, including mean Loss, Market-to-book, Leverage, and Persistence. However, the two

groups differ in terms of Size and Beta, which is unsurprising given that exchange-traded, cross-

listed firms tend to be quite large. Thus, it is important to include these variables as controls

(interacted with UE). In addition, we run analyses in which we explicitly match firms based on

these two characteristics. The final two columns of Table 2 show that Size and Beta are no longer

statistically significantly different across the treatment and control groups when matched.

        Panel D reports the descriptive statistics for the control variables for the firms with

triennially inspected auditors. As expected, these firms are smaller and more highly levered.

4.      Empirical Results

4.1     Analysis of large, annually inspected auditors

        Our first set of analyses examines changes in reporting credibility for firms whose auditors

were subject to the 2003 limited inspections as well as the initial full inspections in 2004. We

estimate the following equation:



                                                                                                     (1)




                                                   21
CAR is the 3-day (t-1, t=0, and t+1) cumulative abnormal return for firm i, centered on the earnings

announcement date and market-adjusted by the CRSP value-weighted index. UE is the difference

between the actual, annual EPS and the median analyst forecast for annual EPS, both from I/B/E/S.

Treated is an indicator that equals one when a firm’s auditor is a U.S. Big Four or Tier-Two

auditor, and zero otherwise. Post is an indicator that equals one after the treatment by the new

regime, and zero otherwise. As discussed in Section 3.3, we use two alternative cutoffs: the

fieldwork end date and inspection report release date (see Appendix A for details). For analyses

using the fieldwork end date, Post equals one if a firm’s fiscal year-ends in the same month as the

fieldwork or later. For analyses using the inspection report date, Post equals one if a firm’s fourth

quarter earnings announcement falls on or after the release of the inspection report. While auditors’

fieldwork end and inspection report release dates are clustered in time, the Post variable is coded

based on clients’ fiscal year-ends or earnings-announcement dates, respectively, which provides

more variation. In Equation (1), our primary coefficient of interest is β 7 , which measures the

incremental change in the ERC for firms whose auditors have been treated by the PCAOB regime.

A positive coefficient indicates an increased response to earnings news under the new regime,

which we interpret as an increase in reporting credibility.

       We include controls for a variety of firm characteristics shown by prior research to be

important determinants of a firm’s ERC. First, we include Loss, an indicator variable that equals

one if a firm reports negative earnings, and zero otherwise; we also include UE×Loss. As losses

are less persistent than profits, the response to negative earnings is likely lower than the response

to positive earnings (Hayn 1995). Second, we include Size, Market-to-book, Leverage, Persistence,

and Beta as well as the interaction of these variables with UE, given that prior work shows that

ERCs are a function of the riskiness, growth, and persistence in earnings (e.g., Collins and Kothari



                                                 22
1989; Easton and Zmijewski 1989; Dhaliwal, Lee, and Fargher 1991).

         We include Fixed effects for the auditor’s global network, country of domicile, the year-

quarter of the firm’s fiscal year-end, and interactions of these fixed effects with UE (as indicated

in the tables). The first two sets of fixed effects control for cross-sectional ERC differences across

auditors and countries. The year-quarter fixed effects flexibly account for ERC changes over time,

for instance, due to changes in market sentiment or macroeconomic cycles (e.g., a recession). We

truncate all continuous variables, with the exception of UE, at the 1% and 99% level. Unexpected

earnings are known to have large outliers, especially in the left tail (e.g., Beaver, Lambert, and

Morse 1980; Collins and Kothari 1989; Kothari 2001). Hence, we truncate UE at the 2.5% and

97.5% level. As a further control for extreme observations, we estimate a weighted least squares

(“robust”) regression that places less weight on estimates with large absolute residuals. 19 We rely

on the robust regression as our primary specification because we view it as an effective and

nondiscretionary way to reduce the influence of outliers. 20 Because the treatment coefficient of

interest includes UE and hence varies by firm, in all tests we cluster standard errors by firm. 21

Table B1 in Appendix B defines each variable.

         Table 3, panel A, presents the robust regression results of estimating Equation (1) using

each of the four alternative dates for the onset of the PCAOB regime: limited inspection fieldwork




19
   We perform robust regressions using Stata’s “rreg” procedure, which eliminates any observations with a Cook’s
distance greater than one and creates weights for the remaining observations based on the absolute residuals.
20
   Prior studies use a variety of approaches to deal with extreme UE observations, including deleting UE observations
that exceed a specified percentage of price (e.g., 100%) and deleting observations with large standardized residuals
(e.g., Collins and Kothari 1989; Teoh and Wong 1993; Francis and Ke 2006; Chen, Cheng, and Lo 2014). In IA§6,
we present scatterplots for untrimmed and truncated data across a variety of truncation levels and provide several
additional analyses to assess the sensitivity of our results to extreme UE observations. These analyses suggest that the
method for handling extreme UE observations can affect the strength of our inferences.
21
   We calculate robust, firm-level clustered standard errors using a WLS regression with weights generated by the
robust regression. In our setting, clustering (i.e., by auditor or year) is problematic given few large auditors and the
short time series (e.g., Petersen 2009; Conley, Goncalves, and Hansen 2018). However, our inferences are very similar
when we double cluster by firm (or industry) and earnings announcement month (untabulated).

                                                          23
(Column 1), limited inspection report release (Column 2), full inspection fieldwork (Column 3),

and full inspection report release (Column 4). Because there is significant overlap in the sample

windows, the estimated effects for each date cannot be interpreted cumulatively (or incrementally);

they simply provide alternative estimates for the effect of the regime change. In Column 1, which

uses the end of the limited inspection fieldwork, UE×Post×Treated is positive but statistically

insignificant. In Column 2, the treatment effect based on the limited inspection report release is

significant at the 10% level. In Columns 3 and 4, where Post is based on the full inspection

fieldwork end and the full inspection report release, respectively, UE×Post×Treated is positive

and significant at the 5% level (at least) and ranges in magnitude from 1.149 to 1.600. Overall,

these results indicate that ERCs increase significantly after the release of the limited inspection

reports and become even more pronounced after the first full inspections.

       In Table 3, panel B, we present results from an alternative design that reduces potential

contamination effects from the overlap in the pre- and post-periods when using alternative cutoff

dates (e.g., in the primary design, the pre-period for the report release overlaps with the post-period

for fieldwork). In this design, we exclude pre-period fiscal year-ends that occur during fieldwork

and prior to the release of the inspection report. To reduce sample attrition, we extend the sample

window to maintain pre and post periods that are of similar length to the main analyses. Figures

A1 and A2 in Appendix A illustrate the limited and full inspection designs without this overlap

(which we call the “dropped observations” design). Results with this design are stronger,

particularly in Column 4, which is where the contamination effects from overlap are likely the

most severe. As expected, the described overlap biases against our results. To be conservative, we

use the design without the dropped observations as our primary specification.

       Table 4, panel A, presents results when stacking the samples for the limited and full



                                                  24
inspections and the fieldwork end and inspection report release dates (hereafter, the “combined”

sample), which effectively provides the average change in ERC across the four alternative sample

windows. This presentation is parsimonious without favoring a particular date, and it also exploits

the variation in firms’ fiscal year-ends more effectively, which is why we use it for the subsequent

analyses. In this specification, UE×Post×Treated is positive and significant at the 1% level

(Column 1). 22 This specification should deliver a conservative estimate of the treatment effect

because it pools the relatively small response to the limited inspections with the larger response to

the full inspections. We report results for the combined sample using the dropped observation

design in Column 2; the coefficient magnitude is similar and is also significant at the 1% level.

         The key assumption underlying our identification strategy is that the treatment and control

firms would have had similar trends in their ERCs absent the introduction of public audit oversight

(i.e., the parallel trends assumption). To assess the reasonableness of this assumption, in Figure 1,

we replace the single Post×Treated×UE interaction term with separate interactions for each of the

years in our sample, except for the year immediately before the introduction of the PCAOB regime,

and map out the treatment effect in event time. In the pre-period, the coefficients for the

incremental ERC are small and statistically insignificant, which supports the parallel trends

assumption. 23 The treatment effect is positive but statistically insignificant in period T and

becomes economically and statistically significant in periods T+1 and T+2, consistent with the

coefficient pattern in Table 3 that shows stronger results after the first full inspections.

         Although the evidence regarding the parallel trends assumption is reassuring, recall that

our treatment and control firms differ along two observable dimensions, Size and Beta. For this


22
   For completeness, in IA§7, we report a full tabulation of all the coefficient estimates, excluding the coefficient
estimates for the fixed effects and fixed effects interacted with UE.
23
   In IA§4, we examine past trends in ERCs for our treatment and control firms over an extended period and again
find no evidence that calls into question the validity of the parallel trends assumption.

                                                         25
reason, we also conduct an analysis using coarsened exact matching (CEM) (see Blackwell et al.

2009) based on both these firm characteristics. CEM relies on covariate weighting to construct a

synthetic control sample, allowing us to preserve sample size. We coarsen our sample into 20 CEM

bins (per matching variable), which reflects a trade-off between preserving observations and the

ex post similarity of the matching variables for the treatment and control groups. We then use the

weights from this coarsening in estimations of Equation (1). After applying the CEM weights,

average Size and Beta are very similar for the treatment and the control samples (see Table 2, panel

C). Table 4, Column 3, presents the regression results with the CEM weights. They are consistent

with the results in Column 1, which do not use the CEM weights.

           Next, we introduce a cross-sectional split which further tightens our analysis in two ways.

First, we exploit the fact that the market response to the earnings surprises of loss firms (i.e., firms

with negative earnings, as distinct from negative surprises) is muted because of the transitory

nature of losses (Hayn 1995). 24 Given the low ERCs for loss firms, the treatment effect of the new

regime is expected to be concentrated in profitable firms. Thus, this differential prediction provides

a way to gauge whether the treatment effects behave sensibly. Second, while the inclusion of Loss

and its interaction with UE already accounts for the differential response to losses, it is possible

that the proportion of firms with losses happens to change around the introduction of the new

regime, which could affect our estimates. By separately estimating the effects of the regime change

for profit and loss firms, we control for composition changes through time and further insulate our

analysis from macroeconomic changes. We include the interactions of Loss with the treatment

indicators in all subsequent analyses.

           In Table 4, Column 4, when we separately estimate the treatment effect for profit and loss



24
     In untabulated results, we confirm that the ERC for firms with losses (i.e., negative earnings) is close to zero.

                                                             26
firms, we find that the results are stronger and that the credibility effects of the new regime are

concentrated in profitable firms, which is consistent with our expectations and corroborates our

interpretation (i.e., the UE×Post×Treated coefficient is 0.942). 25

         To assess the economic magnitude of the observed effects, we estimate the ERC for the

treatment group in the pre-period (using our full baseline model to calculate the pre-period average

UE for the treatment group). Next, we interpret the magnitude of the estimated treatment effects

in terms of the pre-Enron “baseline” ERC (see IA§10 for details). For treated firms in the pre-

period, an earnings surprise of 1% leads to a price change of 3.7%. The estimated treatment effect

in our most conservative specification (i.e., our primary design with coarsened exact matching in

Column 3 of Table 4) implies that ERCs increase by 0.719 (or roughly 19.5%). Thus, after the

introduction of public audit oversight, the total ERC for treated firms equals 4.4, which implies

that in the post-period, an earnings surprise of 1% translates into a price change of about 4.4%, as

compared to 3.7% in the pre-period. This effect is sensible and economically meaningful.

         Next, we present several additional tests to gauge the influence of firm-level heterogeneity

on our results. To address this concern, it is common to include firm fixed effects in a generalized

difference-in-differences estimation. However, this approach poses several issues in our analyses.

First, our main analysis is based on a short 4-year window, centered on the onset of the regime.

This means that we typically have only two firm-year observations before and after an inspection,

which makes the estimation of firm fixed effects quite demanding and noisy. Second, including

firm fixed effects in an ERC regression is different from a standard difference-in-differences

setting where the left-hand-side variable is the outcome of interest. In an ERC regression, the



25
  Similar arguments apply to extreme realizations of UE, which essentially make the ERC nonlinear. We therefore
perform several tests in IA§8 to gauge the influence of extreme observations and the effect on our results of allowing
for nonlinearities in the relationship between CAR and UE.

                                                         27
outcome of interest is an interaction on the right-hand side of the model. Therefore, including firm

fixed effects (without interacting them with UE) does not control for firm-level differences in the

ERC. It controls for a firm’s average CAR at the earnings announcement (and hence can help with

sample composition changes over time of firms with different CARs). But in order to have a

within-firm ERC analysis, it is necessary to interact UE with firm fixed effects. However, such a

fully interacted model is not feasible with only four observations per firm. Given these issues, we

use three alternative approaches to assess the impact of firm-level heterogeneity on our results.

         First, in Table 4, panel B, Column 1, we introduce firm fixed effects as main effects in our

primary (4-year) design, and in Column 3 use the same specification for a sample period of 6 years.

Despite the limited number of observations per firm, the results are very similar in magnitude and

statistical significance to those in our primary specification (panel A). 26 Second, in Table 4, panel

B, Columns 2 and 4, we present results using “firm-group fixed effects,” which are included as

main effects and interacted with UE using a 4- and 6-year sample period, respectively. Specifically,

we create firm groups by forming 100 portfolios (10-by-10) matched on Size and Beta in the first

year that a firm enters the sample; we then introduce fixed effects for these firm groups. We choose

Size and Beta to form firm groups because the treatment and control firms exhibit statistically

significant differences along these two dimensions (see Table 2, panel C), which are important

determinants of firms’ ERCs. These results are similar to those in our primary analyses. 27

         Third, instead of estimating the ERC in a regression, we define it as CAR divided by UE



26
   In additional untabulated analyses, we assess the impact of including firm fixed effects as main effects for each of
the specifications in Table 4, panel A. In some of these specifications, the treatment effect is insignificant and/or
substantially attenuated. However, this appears to be driven by a reduction in the number of observations that
contribute to the estimation of the treatment effect. Once we extend the sample period to include up to 6 years per
firm, the results are again positive and statistically significant, and the coefficients of interest are similar in magnitude
to those in our primary analyses without firm fixed effects.
27
   In IA§9, we present results for additional analyses that confirm our results are robust to the inclusion of fixed effects
for the Fama and French 12 industries as well as alternative portfolio sizes for the firm-group fixed effects analyses.

                                                            28
and then use this proxy as the dependent variable. With this specification, we can control for time-

invariant firm-level heterogeneity with firm fixed effects without using interactions. However, our

sample period is still short, so the downside of this approach is that the “ERC” proxy is quite noisy.

Nevertheless, using this approach, we obtain similar results and draw essentially the same

inferences as in our primary analyses (see IA§9). Thus, based on all three approaches, we conclude

that firm-level heterogeneity is unlikely to drive our results.

4.2    Sensitivity analyses: Changes in information environment and concurrent events

       In this section, we conduct four sets of sensitivity analyses. First, we explore whether other

contemporaneous changes in firms’ information environments or in the properties of reported

earnings affect our prior results. For instance, it is conceivable that the new regime itself affects

elements used in the construction of ERCs (e.g., analysts’ forecasts). To investigate this possibility,

we examine changes in seven separate proxies for changes in firms’ information environments or

earnings properties after the introduction of the PCAOB, including (1) unexpected earnings (UE);

(2) analysts’ earnings forecasts (Forecast); (3) the timeliness with which information is

incorporated into prices (Timeliness); (4) the relative amount of information that firms disclose

prior to the earnings announcement as a proportion of the total information released during the

year, including the earnings announcement (Relative information); (5) accruals (Scaled raw

accruals); (6) the presence of management earnings guidance (Earnings guidance); and (7) the

bundling of the earnings announcement with management guidance (Guidance bundle). Table B1

in Appendix B describes each of these measures in detail. We present descriptive statistics for each

of the proxies in panels A and B of Table 2 separately for our treatment and control firms.

       To examine whether there are systematic (and potentially confounding) changes in these

proxies around the regime change, we use the same difference-in-differences design as in our



                                                  29
primary analyses, successively replacing CAR in Equation (1) with each proxy. The coefficient on

Post×Treated indicates whether there is a change in the proxy after the onset of the PCAOB regime

relative to the control group. In each specification, we include the same set of control variables

and auditor-, country-, and year-quarter fixed effects. Table 5 presents the regression results.

Across all seven information environment proxies, the coefficient on Post×Treated is

economically small, suggesting that these proxies are not much affected. 28 The effects are not

significant, except for UE in Column 1 and Relative information in Column 4. The documented

decrease in UE suggests that analyst forecast bias slightly decreases for treated firms in the post-

period. However, in addition to being small in magnitude, any potential impact of this change is

mitigated, because we control for UE in Equation (1) when estimating the ERC for a given level

of earnings surprise.

           The observed increase in Relative information suggests that in the new regime, treated

firms release more of the year’s total information before the earnings announcement. The increase

of 0.026 is about 18% of 1 standard deviation (0.144). Again, this effect is relatively small. More

importantly, if firms release more of the year’s total information before the earnings

announcement, this should decrease the relative importance of the earnings announcement. Thus,

the change in Relative information likely works against finding an increase in the ERC. In an

untabulated test, we confirm that our results are essentially unchanged when we include Relative

information as an additional control variable (interacted with UE). Consistent with a decrease in

Relative information biasing against our results, the treatment effect for UE×Post×Treated

increases slightly (0.860) and is still significant at the 1% level. We also confirm that results do

not change materially if we simultaneously include all seven information environment proxies as



28
     Each of these results is similar when including firm fixed effects (untabulated).

                                                             30
controls (untabulated). Overall, there is no evidence that our findings are explained by significant

changes in pre-earnings-announcement disclosures, management guidance, earnings’ properties,

and/or analyst forecast behavior. 29

        In our second set of sensitivity analyses, we address the possibility that the observed ERC

change is attributable to firms’ voluntary efforts to improve their financial disclosures in response

to the 2001–2002 accounting scandals. Although our use of cross-listed, non-U.S. firms as a

control group mitigates this concern, it is possible that U.S. firms respond more strongly to these

scandals, affecting our analysis. To test this, we separately examine firms audited by Arthur

Andersen (“AA”) in 2000 and 2001. Leuz and Schrand (2009) show that former AA clients

responded more strongly (i.e., with a larger increase in disclosure) to the revelations at Enron than

did firms with other auditors. Thus, if our results are driven by these market responses rather than

the PCAOB regime, we would expect to see larger ERC changes for former AA clients. Columns

1 and 2 of Table 6 present the results. Excluding former AA clients, the treatment effect is still

positive, significant, and larger in magnitude than the treatment coefficient for former AA clients.

While the coefficients are not statistically different from each other, the relative magnitudes

suggest smaller effects for former AA clients, which is inconsistent with the explanation that a

scandal-induced shift in reporting incentives drives our findings.

        In the third set of analyses, we address the possibility that the observed ERC increase could

reflect other SOX provisions. Three provisions stand out as possibilities: (1) rules regarding audit

committee independence, (2) Section 302 rules regarding executive certification of financial


29
   In untabulated analyses, we also examine the possibility that our results could be explained by the increase in
external monitoring that accompanies the raising of additional external capital following PCAOB inspections (as
documented in Shroff 2017). We find no evidence that our treatment firms experience an increase in capital raising or
capital expenditures around the onset of the PCAOB regime. Rather, it seems more plausible that the increase in
credibility we document is the mechanism that leads to subsequent increases in capital raising.


                                                        31
statements, and (3) Section 404[b] rules regarding the assessment of internal controls. 30 Rules on

audit committee independence became effective on April 25, 2003, for both domestic and foreign

issuers, thus affecting our treatment and control groups simultaneously (SEC Release Nos. 33-

8220; 34-47654). Similarly, Section 302 came into effect on August 29, 2002, for all domestic and

foreign issuers (SEC Release No. 33-8124).

        In contrast, the adoption of Section 404[b] was staggered based on issuer size and domicile.

For U.S. accelerated filers (i.e., firms with market capitalizations greater than $75 million), Section

404[b] became effective for fiscal year-ends on or after November 15, 2004. The SEC deferred

implementation for nonaccelerated filers because of cost concerns. In 2010, the Dodd-Frank Act

made this exemption permanent. Foreign accelerated filers were not subject to Section 404[b] until

July 15, 2006 or July 15, 2007, depending on their size. Prior research documents that the market

responds negatively to the disclosure of 404[b] internal control weaknesses (e.g., Hammersley,

Myers, and Shakespeare 2008). Thus, if firms improve their internal controls, and if better controls

lead to more credible reporting, it is possible that the effects documented in Table 4 are attributable

to the implementation of SOX 404[b] rather than the new public oversight regime for auditors.

        We conduct two analyses to separate the PCAOB regime from other SOX provisions. First,

in an approach similar to Iliev (2010), we separately examine ERC changes for accelerated and

nonaccelerated filers. If the documented increase in credibility is attributable to the new oversight

regime (instead of 404[b]), we expect similar effects for accelerated and nonaccelerated filers.

Results in Columns 3 and 4 of Table 6 are consistent with this prediction. The treatment effect for

nonaccelerated filers is 1.139 as compared to 0.871 for accelerated filers. These coefficients are



30
  In addition, the PCAOB adopted several new auditing standards. However, we consider these changes part of the
PCAOB regime (and not confounds). In IA§1 Table IA6C, we provide details on the adoption timing of the new
PCAOB auditing standards. Given their timing, it is unlikely that they affect our analysis.

                                                      32
not significantly different and, if anything, indicate a larger ERC change for nonaccelerated

filers—a result that goes against the alternative explanation.

         Second, we separately examine ERC changes within treatment firms based on whether or

not a firm has an internal control opinion from its auditor—be it an effective, adverse, or disclaimer

opinion (i.e., we estimate our effects for firms outside and within the SOX 404[b] regime). If the

internal control opinions required under SOX 404[b] made earnings more credible, we would

expect a larger treatment effect for firms with such opinions. The results, presented in Columns 5

and 6 of Table 6, do not support this conjecture. The estimated treatment effect for firms without

a SOX 404[b] internal control opinion (0.923) is larger than for firms with an opinion (0.234); the

difference in the coefficients is statistically significant at the 10% level, suggesting that the effects

we document are distinct from the potential impact of SOX 404[b]. To be sure, in Column 7, we

simultaneously include both indicators in our model to control for the effects of SOX 404[b] and

SOX 302[a]. The estimated treatment effect is similar to that in Table 4, which again provides

assurance that the documented increase in reporting credibility is not attributable to other key SOX

provisions. 31 The next section provides further support for this conclusion.

4.3      Analysis of small, triennially inspected auditors

         Next, we examine the initial triennial inspections of U.S.-registered, small auditors,

beginning in 2004. We use generalized difference-in-differences tests to measure the effect of

triennial inspections, estimating the following equation:


                                                                                                                    (2)



31
   The negative coefficient for SOX 302[a] should be cautiously interpreted, because SOX 302[a] was effective for all
filers for fiscal years ending after August 29, 2002, which is early relative to the relevant PCAOB regime dates. Hence,
the indicator equals one for most (about 84%) firm-year observations.


                                                          33
CAR, Post, and UE are calculated as previously discussed. 32 We include controls as indicated in

the table. We also include auditor- and year-quarter Fixed effects as well as the interactions of

these fixed effects with UE. 33 With this fixed effect structure, the identification of the treatment

effect, UE×Post, comes solely from variation in the timing of inspections among triennially

inspected auditors. We include all available firm-year observations for firms with small auditors

from 2001 through 2007. We exclude fiscal year-ends after Q2 of 2008 to mitigate potential

confounding effects from the financial crisis. As in Table 3, we separately examine two alternative

cutoff dates: the completion of fieldwork and the inspection report release. 34

         Table 7 presents results for this analysis. In Column 1, we estimate a robust WLS

regression of Equation (2), where Post is based on the fieldwork end date. The estimated treatment

effect of 0.789 is positive and significant at the 5% level. In Column 2, Post is based on the report

release date. UE×Post is positive (1.063) and statistically significant at the 5% level. The larger

coefficient magnitude for the inspection report release is consistent with less publicized fieldwork

dates for triennial firms. In Column 3, we include additional controls for SOX 404[b] and 302[a]

and (using the report release date) find similar results, which indicates that the increase in reporting

credibility is not attributable to other SOX provisions. Column 4 reports results for the “dropped

observations” design, which excludes the post-fieldwork period from the sample to avoid overlap

and contamination. The treatment effect (1.022) is similar to the other specifications. Again,



32
   There are two exceptions. First, for triennially inspected auditors, fieldwork is shorter, and it is less clear that the
market is aware of its timing. Thus, we code the Post variable as equal to one for any earnings announcement occurring
30 days after the end of the PCAOB’s inspection fieldwork (or alternatively, the day following the inspection report
release). Second, because small firms have less analyst coverage, we extend our window for measuring the median
analyst forecast (from which UE is computed) from 95 to 360 days.
33
   As in the large auditor analysis, the degrees of freedom limit the number of fixed effects we can include and preclude
the use of firm fixed effects. However, in IA§9, we confirm that results are robust to the consideration of pseudo-firm
fixed effects based on firm characteristics and industry groupings.
34
   In IA§3, we provide specific examples of how we code the Post indicator for a variety of fiscal year-ends and
inspection years.

                                                           34
assuming a pre-period benchmark return response for a 1% earnings surprise of 3.7%, in the post-

PCAOB regime period, an earnings surprise of the same magnitude leads to a price change of

about 4.7%, an increase of about 28% for clients of triennially inspected auditors.

       In Table 7, Column 5, we report results including firm fixed effects as main effects in

Equation (2). The treatment effect is positive but statistically insignificant. One potential

explanation is that firm fixed effects reduce the number of firms that contribute to the identification

of the treatment effect. We have relatively few observations for triennially inspected auditors to

begin with (1,338 firm years), but even fewer (581) with at least one observation in both the pre-

and post-period. In Column 6, we include firm-group fixed effects as main effects and interacted

with UE, which allows us to control for firm-group-level heterogeneity in the estimated ERC.

These results are positive, statistically significant, of a very similar magnitude to those in Columns

1 and 2, and consistent with the result in Column 5 reflecting sample attrition.

       Overall, the results for small auditors are consistent with our earlier findings for large

auditors, which indicate a significant increase in reporting credibility following the introduction

of public audit oversight.

4.4    Abnormal trading volume around 10-K filings as an alternative credibility proxy

       In this section, we examine abnormal trading volume around the SEC filing of firms’

annual financial statements (10-Ks) as an alternative measure of reporting credibility. While prior

empirical studies generally interpret abnormal trading volume as a measure of the information

content of firm disclosures (e.g., Asthana and Balsam 2001; Asthana, Balsam, and

Sankaraguruswamy 2004; Leuz and Schrand 2009), it likely also reflects the credibility of the

information released. Kim and Verrecchia (1991) model the relation for abnormal trading volume

and show that the results for price reactions in Holthausen and Verrecchia (1988), on which the



                                                  35
ERCs rely, extend to trading volume even when investors are diversely informed. Thus, the

conceptual underpinnings discussed in Section 3.1 still apply. If the new audit oversight regime

increases reporting credibility, we predict a stronger volume reaction.

       The abnormal trading volume proxy also has some empirically desirable properties. Like

ERCs, abnormal trading volume around an information event is not anticipatory in nature and can

be measured over short intervals. Unlike the ERC, however, it does not have to be estimated from

an interaction and can be simply observed at the firm-year level, making it less noisy and allowing

us to introduce firm fixed effects. The drawback of this measure is that we cannot compute the

news component (or surprise) for the 10-K filing to standardize reactions, as we do for the ERC.

       Following prior literature (e.g., Asthana, Balsam, and Sankaraguruswamy 2004; Leuz and

Schrand 2009), we calculate abnormal volume, Abnormal 10-K Volume, using trading volume in

a window beginning 1 trading day prior to the filing and ending 3 trading days after. We normalize

raw trading volume by subtracting the mean trading volume in the 45 trading days beginning 5

trading days prior to the 10-K release and dividing by the standard deviation of trading volume

(calculated over the same window). We exclude any days in the 3-day earnings announcement

window and define Abnormal 10-K Volume as the mean of the normalized trading volume in the

5-day (from t-1 to t+3) window surrounding the 10-K.

       We conduct a difference-in-differences analysis of changes in Abnormal 10-K Volume

around the introduction of the PCAOB regime by estimating the following equation:


                                                                                                 (3)


       We combine the two alternative cutoff dates (completion of fieldwork and release of the

inspection report) and pool data across limited and full inspections in a single analysis. We use the



                                                 36
same treatment and control samples as in our primary analyses for large auditors. Following Leuz

and Schrand (2009), we include several controls from the ERC tests including Size, Market-to-

book, Leverage, Beta, and Loss. We control for the number of days between a firm’s fiscal year-

end and the 10-K release (Filing delay after FYE) and between the earnings announcement and the

10-K release (Filing delay after EA), following Asthana, Balsam, and Sankaraguruswamy (2004).

We also include Analyst following, since some sample firms do not have analyst coverage.

         We present descriptive statistics for the variables in IA§11. While the sample size is much

larger than for the ERC analysis (because we do not require analyst forecasts for these tests), the

majority of the sample observations (89%) are from the treatment group. On average, Abnormal

10-K Volume is positive, as expected. The median firm files its 10-K 83 days after the fiscal year-

end and 36 days after the earnings announcement.

         Table 8 presents the regression results. In Column 1, we estimate Equation (3) using

ordinary least squares (OLS) and include auditor-, country-, and year-quarter fixed effects. In

Column 2, we also include firm fixed effects. In both columns, the treatment effect, Post×Treated,

is positive and significant (at the 5% level or greater). In Column 3, we use a similar approach as

in Table 4 and employ CEM based on Size, Beta, and Loss. 35 In Column 3, the coefficient of

interest has a magnitude of 0.136, which translates into a 14.6% increase in abnormal trading

volume around the release of a firm’s 10-K.

         In Column 4, following Loughran and McDonald (2014), we include the log of the 10-K

file size (log(10-K file size)) as an additional control for information found in the 10-K and to

isolate credibility effects. In Column 5, we include additional controls for SOX provisions 404[b]



35
  We also match on Loss in this analysis because (in unreported analyses) we find that the proportion of loss firms
are significantly different between the treatment and control samples. In additional (untabulated) analyses, we confirm
that matching on Size and Beta alone does not affect our inferences.

                                                         37
and 302[a]. Although the magnitudes and standard errors differ slightly across specifications, the

results and inferences are robust and similar to those in Column 3.

       Overall, our results indicate that the abnormal trading volume around 10-K filings increases

after firms’ auditors are subject to PCAOB inspections. This result is consistent with an increase

in the reporting credibility of audited 10-Ks and corroborates our ERC-based analyses.

5.     Conclusion

       This paper examines the effects of financial reporting credibility in capital markets. To this

end, we analyze whether an increase in audit oversight by a quasi-public regulator increases capital

market responses to firms’ earnings surprises, as theory would suggest if the new oversight regime

enhances the credibility of reported earnings. We use a generalized difference-in-differences

research design that exploits the staggered introduction of the PCAOB regime that was established

by SOX to replace the prior self-regulatory regime. The introduction of the PCAOB regime affects

firms at different times depending on their fiscal year-ends, auditors, and the timing of PCAOB

inspections. Consistent with an increase in reporting credibility after the introduction of public

audit oversight, we find that capital market responses to earnings surprises increase significantly.

The effects are present for firms with Big Four auditors, other annually inspected auditors, and

triennially inspected auditors. SOX provisions unrelated to audit oversight do not appear to drive

the findings. Corroborating these results, we find that abnormal trading volume reactions to 10-K

filings increase after the introduction of the new oversight regime. Overall, our study provides

evidence on the capital market effects of the PCAOB regime and suggests that public audit

oversight can have capital market benefits by enhancing the credibility of financial reporting. It

also provides further support for the notion that reporting credibility is priced by investors in

capital markets.



                                                38
        Despite many sensitivity analyses, our results should be interpreted cautiously as our study

is subject to several limitations. First, although our analyses show sustained increases in reporting

credibility for at least 2 years, ERCs are based on investor perceptions and can change as more

information about the oversight regime (and reporting and audit quality) becomes publicly

available. Second, attributing the credibility effect to public audit oversight depends critically on

our ability to control for other concurrent changes in regulation and markets with our difference-

in-differences analyses. Third, because ERCs are noisy and difficult to measure, the magnitude of

our estimates should be interpreted carefully. Fourth, while we provide evidence that other SOX

provisions do not appear to drive our results, it is difficult to rule out the possibility that our results

reflect the joint effect of these provisions and public audit oversight. Fifth, our results are relative

to the prior peer review regime and do not rule out the possibility that a substantially reformed

peer review system could also have increased reporting credibility. Sixth, our study focuses on the

capital market benefits of public audit oversight, but does not examine the costs of the new regime.

Thus, we do not show net benefits. Seventh and finally, our analysis is limited to equity investors.

Given the role of auditing in debt contracting, it is conceivable that public audit oversight also

provides benefits to (and has costs for) other stakeholders (e.g., Costello and Wittenberg-Moerman

2011; Minnis 2011). We leave this question to future research.




                                                    39
References

Abernathy, J., M. Barnes, and C. Stefaniak. 2013. A summary of 10 years of PCAOB research: What have we
  learned? Journal of Accounting Literature 32:30–60.
Aobdia, D. 2018. The impact of the PCAOB individual engagement inspection process—preliminary evidence.
  Accounting Review 93:53–80.
Aobdia, D., and N. Shroff. 2017. Regulatory oversight and auditor market share. Journal of Accounting and
  Economics 63:262–87.
Asthana, S., and S. Balsam. 2001. The effect of EDGAR on the market reaction to 10-K filings. Journal of
   Accounting and Public Policy 20:349–72.
Asthana, S., S. Balsam, and S. Sankaraguruswamy. 2004. Differential response of small versus large investors
   to 10-K filings on EDGAR. Accounting Review 79:571–89.
Bailey, W., G. Karolyi, and C. Salva. 2006. The economic consequences of increased disclosure: Evidence
   from international cross-listings. Journal of Financial Economics 81:175–213.
Beaver, W., R. Lambert, and D. Morse. 1980. The information content of Security Prices. Journal of
  Accounting and Economics 2:3–28.
Blackwell, M., S. Iacus, G. King, and G. Porro. 2009. CEM: Coarsened exact matching in Stata. Stata Journal
   9:524–46.
Boone, J., I. Khurana, and K. Raman. 2015. Did the 2007 PCAOB disciplinary order against Deloitte impose
  actual costs on the firm or improve its audit quality? Accounting Review 90:405–41.
Chen, X., Q. Cheng, and A. Lo. 2014. Is the decline in the information content of earnings following
  restatements short-lived? Accounting Review 89:177–207.
Chhaochharia, V., and Y. Grinstein. 2007. Corporate governance and firm value: The impact of the 2002
  governance rules. Journal of Finance 62:1789–825.
Coates, J., and S. Srinivasan. 2014. SOX after ten years: A multidisciplinary review. Accounting Horizons
  28:627–71.
Collins, D., and S. Kothari. 1989. An analysis of intertemporal and cross-sectional determinants of earnings
   response coefficients. Journal of Accounting and Economics 11:143–81.
Conley, T., S. Goncalves, and C. Hansen. 2018. Inference with dependent data in accounting and finance
  applications. Journal of Accounting Research 56:1139–203.
Costello, A., and R. Wittenberg-Moerman. 2011. The impact of financial reporting quality on debt contracting:
  Evidence from internal control weakness reports. Journal of Accounting Research 49:97-–136.
Dechow, P., W. Ge, and C. Schrand. 2010. Understanding earnings quality: A review of the proxies, their
  determinants and their consequences. Journal of Accounting and Economics 50:344–401.
Dee, C., A. Lulseged, and T. Zhang. 2011. Client stock market reaction to PCAOB sanctions against a Big 4
  auditor. Contemporary Accounting Research 28:263–91.
DeFond, M. 2010. How should the auditors be audited? Comparing the PCAOB inspections with the AICPA
  peer reviews. Journal of Accounting and Economics 49:104–8.
———. 2012. The consequences of protecting audit partners’ personal assets from the threat of liability: A
 discussion. Journal of Accounting and Economics 54:175–9.
DeFond, M., and C. Lennox. 2011. The effect of SOX on small auditor exits and audit quality. Journal of
  Accounting and Economics 52:21–40.

                                                      40
———. 2017. Do PCAOB inspections improve the quality of internal control audits? Journal of Accounting
 Research 55:591–627.
DeFond, M., and J. Zhang. 2014. A review of archival auditing research. Journal of Accounting and Economics
  58:275–326.
Demsetz, H. 1968. Why regulate utilities? Journal of Law and Economics 11:55–65.
Dhaliwal, D., K. Lee, and N. Fargher. 1991. The association between unexpected earnings and abnormal
  security returns in the presence of financial leverage. Contemporary Accounting Review 8:20–41.
Diamond, D., and R. Verrecchia. 1991. Disclosure, liquidity, and the cost of capital. Journal of Finance
   46:1325–59.
Doty, J. 2011. The relevance, role and reliability of audits in the global economy. Texas Law Review 90:1891–
  911.
Duflo, E., M. Greenstone, R. Pande, and N. Ryan. 2013. Truth-telling by third-party auditors and the response
  of polluting firms: Experimental evidence from India. Quarterly Journal of Economics 128:1499–545.
Duro, M., J. Heese, and G. Ormazabal. 2018. Does the public disclosure of the SEC’s oversight actions matter?
  Working Paper, Harvard Business School and IESE Business School.
Easton, P., and M. Zmijewski. 1989. Cross-sectional variation in the stock market response to accounting
   earnings announcements. Journal of Accounting and Economics 11:117–41.
Economist. 2014. The dozy watchdogs. December 13. https://www.economist.com/briefing/2014/12/11/the-
   dozy-watchdogs.
Fogarty, T. 1996. The imagery and reality of peer review in the U.S.: Insights from institutional theory.
  Accounting, Organizations and Society 21:243–67.
Francis, J., and B. Ke. 2006. Disclosure of fees paid to auditors and the market valuation of earnings surprises.
   Review of Accounting Studies 11:455–523.
Fung, S., K. Raman, and X. Zhu. 2014. Does the PCAOB’s international inspection program provide spillover
  audit quality benefits for investors abroad? Working Paper, Hong Kong Polytechnic University.
Glover, S., D. Prawitt, and M. Taylor. 2009. Audit standard setting and inspection for U.S. public companies:
   A critical assessment and recommendations for fundamental change. Accounting Horizons 23:221–37.
Gunny, K., and T. Zhang. 2013. PCAOB inspection reports and audit quality. Journal of Accounting and Public
  Policy 32:136–60.
Hail, L., A. Tahoun, and C. Wang. 2018. Corporate scandals and regulation. Journal of Accounting Research
   56:617–71.
Hackenbrack, K., and C. Hogan. 2002. Market responses to earnings surprises conditional on reasons for an
  auditor change. Contemporary Accounting Research 19:195–223.
Hammersley, J., L. Myers, and C. Shakespeare. 2008. Market reactions to the disclosure of internal control
  weaknesses and to the characteristics of those weaknesses under section 302 of the Sarbanes Oxley Act of
  2002. Review of Accounting Studies 13:141–65.
Hayn, C. 1995. The information content of losses. Journal of Accounting and Economics 20:125–53.
Hilary, G., and C. Lennox. 2005. The credibility of self-regulation: Evidence from the accounting profession’s
   peer review program. Journal of Accounting and Economics 40:211–29.
Hilzenrath, D. 2010. Critics question effectiveness of auditing oversight board. Washington Post, July 11.
   http://www.washingtonpost.com/wp-dyn/content/article/2010/07/10/AR2010071000074.html.

                                                        41
Holthausen, R., and R. Verrecchia. 1988. The effect of sequential information releases on the variance of price
  changes in an intertemporal multi-asset market. Journal of Accounting Research 26:82–106.
Iliev, P. 2010. The effect of SOX Section 404: Costs, earnings quality, and stock prices. Journal of Finance
    65:1163–96.
Jackson, H., and M. Roe. 2009. Public and private enforcement of securities laws: Resource-based evidence.
   Journal of Financial Economics 93:207–38.
Kim, O., and R. Verrecchia. 1991. Trading volume and price reactions to public announcements. Journal of
  Accounting Research 29:302–31.
Kothari, S. 2001. Capital markets research in accounting. Journal of Accounting and Economics 31:105–231.
Krishnan, J., J. Krishnan, and H. Song. 2016. PCAOB international inspections and audit quality. Accounting
   Review 92:143–66.
La Porta, R., F. Lopez-De-Silanes, and A. Shleifer. 2006. What works in securities laws? Journal of Finance
   61:1–32.
Lamoreaux, P. 2016. Does PCAOB inspection access improve auditor quality? An examination of foreign
  firms listed in the United States. Journal of Accounting and Economics 61:313–37.
Lennox, C., and J. Pittman. 2010. Auditing the auditors: Evidence on the recent reforms to the external
   monitoring of audit firms. Journal of Accounting and Economics 49:84–103.
Leuz, C., and C. Schrand. 2009. Disclosure and the cost of capital: Evidence from firms’ responses to the
   Enron shock. NBER. Available at http://www.nber.org/papers/w14897.
Leuz, C., and P. Wysocki. 2016. The economics of disclosure and financial reporting regulation: Evidence and
   suggestions for future research. Journal of Accounting Research 54:525–622.
Li, H., M. Pincus, and S. Rego. 2008. Market reaction to events surrounding the Sarbanes-Oxley Act of 2002
    and earnings management. Journal of Law and Economics 51:111–34.
Loughran, T., and B. McDonald. 2014. Measuring readability in financial disclosures. Journal of Finance
  69:1643–71.
Marshall, N. T., J. H. Schroeder, and T. L. Yohn. 2018. An incomplete audit at the earnings announcement:
  Implications for financial reporting quality and the market’s response to earnings. Contemporary
  Accounting Research. Advance Access published online November 27, 2018, 10.1111/1911-3846.12472.
Minnis, M. 2011. The value of financial statement verification in debt financing: Evidence from private U.S.
  firms. Journal of Accounting Research 49:457–506.
Moreland, K. 1995. Criticisms of auditors and the association between earnings and returns of client firms.
  Auditing: A Journal of Practice & Theory 14:94–104.
PCAOB. 2004a. Section 4. Inspections: Rule 4000. General. SEC Release No. 34-49787 and File No. PCAOB-
  2003-08 (June 1, 2004).
———. 2004b. Statement Concerning the Issuance of Inspection Reports. PCAOB release No. 104-2004-001.
———. 2014. Public Accounting Oversight Board 2015 Budget by Program Area 2013-2015.
 http://pcaobus.org/About/Ops/Documents/Fiscal%20Year%20Budgets/2015.pdf.
Petersen, M. 2009. Estimating standard errors in finance panel data sets: Comparing approaches. Review of
   Financial Studies 22:435–80.




                                                       42
Riley, R., J. Jenkins, P. Roush, and J. Thibodeau. 2008. Audit quality in the post-SOX audit environment:
   What your accounting students must know about the PCAOB inspection process. Current Issues in Auditing
   2:A17–A25.
Shroff, N. 2019. Real Effects of PCAOB International Inspections. Forthcoming at Accounting Review.
Stigler, G. 1971. The theory of economic regulation. Bell Journal of Economics and Management Science 2:3–
   21.
Summers, L. 1999. Distinguished lecture on economics in government: Reflections on managing global
  integration. Journal of Economic Perspectives 13:3–18.
Teoh, S., and T. Wong. 1993. Perceived auditor quality and the earnings response coefficient. Accounting
   Review 68:346–66.
US House of Representatives. 2002. Sarbanes-Oxley Act of 2002. Public Law 107-204 [H.R. 3763]
  Washington, DC: Government Printing Office.
Wall Street Journal. 2010. A missed opportunity to kill Sarbox.                         July   3,     2010.
  https://www.wsj.com/articles/SB10001424052748703571704575341100384702596
Watts, R., and J. Zimmerman. 1983. Agency problems, auditing, and the theory of the firm: Some evidence.
  Journal of Law and Economics 26:613–33.
Wilson, W. 2008. An empirical analysis of the decline in the information content of earnings following
  restatements. Accounting Review 83:519–48.




                                                     43
Appendix A. Details on the Timing of the Introduction of the PCAOB Regime and
Identification Strategy
This appendix provides details on the timing of the introduction of the PCAOB audit oversight regime.

Table A1. Annually inspected auditor fieldwork and inspection report release dates

            Auditor                              Fieldwork                                    Report date
                                         Commences         Concludes
 Limited inspections
 Big Four auditors
 Deloitte & Touche                               June 2003          December 2003             August 26, 2004
 Ernst & Young                                   June 2003          December 2003             August 26, 2004
 KPMG                                            June 2003          December 2003             August 26, 2004
 PricewaterhouseCoopers                          June 2003            January 2004            August 26, 2004
 Full inspections
 Big Four auditors
 Deloitte & Touche                               May 2004           November 2004           October 06, 2005
 Ernst & Young                                   July 2004          December 2004         November 17, 2005
 KPMG                                            June 2004            October 2004        September 29, 2005
 PricewaterhouseCoopers                          May 2004             January 2005        November 17, 2005
 Tier-Two auditors
 BDO                                          May 2004                   July 2004        November 17, 2005
 Crowe Chizek                            November 2004              December 2004           January 19, 2006
 Grant Thornton                               May 2004                 March 2005           January 19, 2006
 McGladrey & Pullen                        October 2004             December 2004         November 30, 2005
This table provides the beginning and end dates for PCAOB fieldwork and the inspection report release dates for both
limited and full inspections by auditor. We use these dates to define the sample window for each of the respective
analyses. Whether a firm’s fiscal year-end falls within a given sample window determines which earnings
announcement observations are included. However, in setting the pre- and post-period windows, we also consider the
earnings announcement timeline of a typical firm in determining which fiscal year-end months to include. We do not
use the timing of earnings announcements to determine the sample window because the timing is not fixed, and thus
a firm could enter or exit the sample for endogenous reasons related to that timing. Instead, we use fiscal year-end
dates, which are fixed. See also Section 3.3 and Figures A1 and A2 for further details on the sample windows.




                                                        44
Figure A1. Limited inspections: Treatment timing (specific dates from Deloitte & Touche are presented as an example)


                                     Fieldwork begins (6/2003)
                                           Fieldwork concludes (12/2003)
                                                    Reports released (8/2004)

06/01 12/01 06/02 12/02 06/03 12/03 06/04 12/04 06/05 12/05 06/06


Primary:
                   Fieldwork pre                       Fieldwork post

                          Inspection report pre               Inspection report post

Dropped observations:
          Fieldwork pre               Drop             Fieldwork post

      Inspection report pre                 Drop              Inspection report post


This figure describes the coding of the Post variable around the limited inspections. We use two different designs. In the primary design, we use the end of fieldwork
across audit firms and the release of the inspection report as alternative cutoff dates to define the sample window. For the limited inspections, using the fieldwork
(inspection report) cutoff date, the sample window is defined between December 2001 and November 2005 (June 2002 and May 2006). The sample includes firms
whose fiscal year-ends fall into this window. For analyses using the end of fieldwork date, Post equals one if a firm’s fiscal year ends in the final month of the
fieldwork or later. For analyses using the inspection report date, Post equals one if a firm’s fourth-quarter earnings announcement falls on or after the release of
the inspection report. Typically, there are two firm-year observations before and after the relevant cutoff date. In the dropped observations design, to avoid
overlapping pre and post periods, we exclude fiscal year-ends occurring during PCAOB fieldwork when the fieldwork end is the cutoff date and exclude fiscal
year-ends occurring between the start of fieldwork and the release of the inspection report when the inspection report release is the cutoff date. To reduce sample
attrition, we extend the sample window to maintain pre and post periods that are of similar length to the main analyses. Time line dates are presented in the following
format: MM/YY.




                                                                                 45
Figure A2. Full inspections: Treatment timing (specific dates from Deloitte & Touche are presented as an example)

                                                      Fieldwork begins (5/2004)
                                                            Fieldwork concludes (11/2004)
                                                                           Report released (10/2005)

06/01 12/01 06/02 12/02 06/03 12/03 06/04 12/04 06/05 12/05 06/06 12/06 06/07 12/07


Primary:
                                Fieldwork pre                             Fieldwork post

                                                Inspection report pre                  Inspection report post

Dropped observations:
                            Fieldwork pre              Drop               Fieldwork post

                        Inspection report pre                   Drop                   Inspection report post


This figure describes the coding of the Post variable around the full inspections. We use two different designs. In the primary design, we use the end of fieldwork
across audit firms and the release of the inspection report as alternative cutoff dates to define the sample window. For the full inspections, using the fieldwork
(inspection-report) cutoff date, the sample window is defined between June 2002 and December 2006 (July 2003 and November 2007). The sample includes firms
whose fiscal year-ends fall into this window. For analyses using the end of fieldwork date, Post equals one if a firm’s fiscal year ends in the final month of the
fieldwork or later. For analyses using the inspection report date, Post equals one if a firm’s fourth-quarter earnings announcement falls on or after the release of
the inspection report. Typically, there are two firm-year observations before and after the relevant cutoff date. In the dropped observations design, to avoid
overlapping pre and post periods, we exclude fiscal year-ends occurring during PCAOB fieldwork when the fieldwork end is the cutoff date and exclude fiscal
year-ends occurring between the start of fieldwork and the release of the inspection report when the inspection report release is the cutoff date. To reduce sample
attrition, we extend the sample window to maintain pre and post periods that are of similar length to the main analyses. Time line dates are presented in the following
format: MM/YY.




                                                                                 46
Appendix B

Table B1. Variable definitions
Variables used in calculating earnings response coefficients
 CAR i,t          A firm’s 3 trading day return, centered on the earnings announcement date, less the CRSP
                  market return over the same period. The earnings announcement date is the earliest date
                  available on Compustat or I/B/E/S
 UE i,t           The difference between the I/B/E/S annual EPS and the median I/B/E/S forecast of annual
                  EPS from each analyst’s most recent forecast in the window starting 95 calendar days before
                  and ending 3 days before the earnings announcement, scaled by the CRSP price 2 days
                  before the earnings announcement. We supplement the triennially inspected auditor analysis
                  forecasts by including the difference between the I/B/E/S actual, annual EPS, and the median
                  I/B/E/S forecast of annual EPS from each analyst’s most recent forecast in the window
                  starting 360 calendar days before and ending 3 days before the earnings announcement when
                  the shorter window, detailed above, does not contain a forecast

PCAOB inspection indicators
 Post i,t      An indicator variable (based on an auditor’s global network) that equals one for all firm-
               years after a firm’s auditor’s U.S. affiliate’s treatment through the PCAOB inspection
               process, defined for each event as follows: (1) Big Four limited and full inspection fieldwork
               and Tier-Two full inspection fieldwork: Post equals one if a firm’s fiscal year-ends in the
               same month as the final month of fieldwork (as indicated in Table A1 in Appendix A) or
               later, and zero otherwise; (2) triennially inspected auditor full inspection fieldwork: Post
               equals one if a firm’s fiscal year-ends after the auditor-specific fieldwork end date plus 30
               days, and zero otherwise; and (3) Big Four limited and full inspection report release,
               triennially inspected auditors’ inspection report release, and Tier-Two full inspection report
               release: Post equals one if a firm’s fourth-quarter earnings announcement falls on or after
               the release date of the inspection report (as indicated in Table A1 in Appendix A), and zero
               otherwise
 Treated i,t   An indicator variable coded as one if a firm is audited by an auditor subject to a (limited or
               full) PCAOB inspection, and zero otherwise

Control variables
 Analyst          The number of unique analysts who issue at least one forecast on I/B/E/S in a window
 following i,t    starting 360 calendar days before and ending 3 days before the earnings announcement.
                  When no forecasts are observed, we set this count to zero
 Beta i,t         The coefficient from regressing excess daily returns for firm i on excess market returns over
                  one calendar year, ending on the fiscal year-end date. The risk-free rate is collected from
                  Kenneth French’s data library
 Filing delay     The number of days between the earnings announcement date (the earliest date available on
 after EA i,t     Compustat or I/B/E/S) and the filing date of the 10-K (the earliest date reported by Audit
                  Analytics or WRDS SEC Analytics). We use many variations of 10-K filings (e.g., 10-K405,
                  10-KSB, 20-F)
 Filing delay     The number of days between the firm’s fiscal year-end (from Compustat) and the filing of
 after FYE i,t    the 10-K (based on the earliest date reported by Audit Analytics or WRDS SEC Analytics).
                  We use many variations of 10-K filings (e.g., 10-K405, 10-KSB, 20-F)
 Leverage i,t     The ratio of total liabilities to total equity, measured at the fiscal year-end, from Compustat
 log(10-K file    The natural log of the file size of the firm’s 10-K SEC filing, from WRDS SEC Analytics.
 size)            We use many variations of 10-K filings (e.g., 10-K405, 10-KSB, 20-F)


                                                    47
 Loss i,t           An indicator variable coded as one when basic earnings per share excluding extraordinary
                    items from Compustat (epspx) is less than zero, and zero otherwise
 Market-to-         The ratio of the market value of equity to the book value of equity, measured at the fiscal
 book i,t           year-end, from Compustat
 Persistence i,t    The coefficient from regressing basic EPS excluding extraordinary items from Compustat
                    on lagged EPS using (where available) up to 10 years of data
 Size i,t           The natural log of the market value of equity measured at fiscal year-end, from Compustat
 SOX302a i,t        An indicator variable coded as one when the “IS EFFECTIVE” variable in the Audit
                    Analytics SOX 302 data set is coded as a “0,” “1,” or “2,” and zero otherwise. This variable
                    is coded 1 only for domestic firms
 SOX404b i,t        An indicator variable coded as one when the auditor internal control opinion (AUOPIC)
                    variable in Compustat shows an adverse, qualified, or unqualified indicator, and zero
                    otherwise. This variable is only coded 1 for domestic firms

Alternative dependent variables
 Abnormal        The mean abnormal trading volume in a window starting 1 day before the 10-K filing date
 10-K volume i,t and ending 3 days after. Abnormal trading volume is defined as raw volume less mean daily
                 volume over a window starting 49 days before and ending 5 days before the annual financial
                 statement report release (excluding any 3-day earnings announcement window days) divided
                 by the standard deviation of daily volume over the same window. All volume data is from
                 CRSP. The 10-K filing date is defined as the earlier of the date reported by Audit Analytics
                 (as long as it is after the earnings announcement date) and the first observable 10-K date
                 from WRDS SEC Analytics in a 180-calendar-day window beginning on the earnings
                 announcement date
 Earnings        An indicator variable coded as one when a guidance observation (quarterly or annual) is
 guidance i,t    available for the fiscal year-end date on either First Call or I\B\E\S, and zero otherwise
 Forecast i,t    The median I/B/E/S forecast of annual EPS, using each analyst’s most recent forecast in a
                 window beginning 95 days before and ending 3 days before the earnings announcement,
                 scaled by the CRSP price from 2 days before the earnings announcement
 Guidance        An indicator variable coded as one when management provides earnings guidance for any
 bundle i,t      fiscal period (quarterly or annual) within one calendar day of the earnings announcement on
                 either First Call or I\B\E\S, and zero otherwise
 Relative        This variable captures the share of information arriving prior to the earnings announcement
 information i,t relative to the total amount of information reflected in equity prices over a firm’s fiscal year,
                 calculated as the sum of the absolute value of daily market-adjusted CRSP returns starting
                 345 calendar days before and ending the day before the earnings announcement window,
                 divided by the same value plus predicted returns (based on the implied return to a given level
                 of earnings surprise using the firm’s estimated ERCs) for the 3-day earnings announcement
                 window, scaled by 100
                                                                 0

                                                                ∑        ri ,d − rM ,d
                    100 ⋅                                      d =−345
                                                                                                                               .
                                                                                     
                                                                                                       0
                            α             
                             lag 2 + UEi ⋅ ERClag 2 + Lossi ⋅ β lag 2 + UEi ⋅ Lossi ⋅ β lag 2
                                                                 Loss                    LossERC
                                                                                                 +    ∑        ri ,d − rM ,d
                                                                                                     d =−345
                   Returns are from CRSP, and d represents the number of calendar days relative to 2 trading
                   days prior to the earnings announcement. To increase the precision of the measurement, we
                   allow separate ERC coefficients for profits and losses estimated from cross-sectional
                   regressions 2 years prior to t
 Scaled raw        The difference between net income and cash flow from operations scaled by average total
 accruals i,t      assets, from Compustat

                                                         48
 Timeliness i,t    This variable captures how quickly market prices impound the information reflected in price
                   at p d=0 , calculated following Beekes and Brown (2006) and given by the equation:


                                                                                .


                  We multiply by -1 so that the measure is increasing in timeliness. Prices are from CRSP,
                  and d represents the number of calendar days relative to 2 trading days before the earnings
                  announcement. The indicator function in the denominator turns on when d is a trading day
Throughout the table, subscripts i and t refer to a particular firm and fiscal year, respectively.




                                                   49
Figure 1. Mapping the estimated treatment effect by event time

                                        1.6

                                        1.4

                                        1.2

                                          1

                                        0.8
                      Incremental ERC




                                        0.6

                                        0.4                                                                               Incremental U.S. ERC

                                        0.2

                                          0
                                               T-3    T-2          T-1            T           T+1          T+2
                                        -0.2

                                        -0.4

                                        -0.6
                                                     Event time indicators (T-1 is base time period)


Figure 1 presents simultaneously estimated trends in earnings response coefficients (ERCs) for the combined sample using profit firms only (i.e., Loss = 0), which
stacks the limited and full inspections analyses for each cutoff date (i.e., the end of fieldwork and report release) using the dropped observation design (see Figures
A1 and A2 in Appendix A). We use the sample from our primary analyses (i.e., Table 3, panel A of the manuscript) plus years “T-3” and “T+2” to better map out
the pretreatment period and treatment response. Each unshaded (shaded) dot on the graph represents an insignificant (significantly positive) regression coefficient
for U.S. firms in event time (i.e., UE× Treated interacted with event time dummies) from a robust regression estimation of Equation (1). We include auditor and
country fixed effects interacted with UE. Each line bar represents 2 standard errors on either side of the coefficient. We calculate robust, firm-level clustered
standard errors using a weighted least squares regression based on the weights (and coefficients) from the robust regression. Table B1 in Appendix B defines each
variable in detail.



                                                                                   50
Table 1. Sample composition
A. Number of unique issuers by auditor, inspection type, and sample window cutoff date
                                               Unique firms                            Firm-
                                                                                       years
                       Limited inspections           Full inspections         Combined
                          (1)           (2)          (3)           (4)      (5)         (6)
 Treatment sample Fieldwork Reports Fieldwork Reports
 Big Four auditors
 Deloitte & Touche            679          714           768          728      825       7,456
 Ernst & Young                986        1,028         1,122        1,044    1,198     10,878
 KPMG                         772          787           830          760      881       8,066
 PwC                          888          873           920          844      999       9,249
 Tier-two auditors
 BDO Seidman                    –            –           118          117      124         464
 Crowe Chizek                   –            –             46          43        46        185
 Grant Thornton                 –            –           166          167      179         566
 McGladrey &                    –            –
 Pullen                                                    33          36        37        137
    Subtotal                3,325        3,402         4,003        3,739    4,289     37,001
 Control sample
 Big Four auditors
 Deloitte & Touche             95          109             63          59      126         746
 Ernst & Young                108          123             89          81      137         953
 KPMG                         122          125             67          61      138         891
 PwC                          156          158             95          76      176       1,169
 Tier-Two auditor
 Grant Thornton                 –            –              2           2         2          6
    Subtotal                  481          515           316          279      579       3,765
    Total                   3,806        3,917         4,319        4,018    4,868     40,766
Table 1 provides details on the sample composition for our limited, full, and triennial inspection analyses. Panel A
describes the sample composition for the limited and full inspections by auditor, inspection type, and sample window
cutoff date. Columns 1 through 4 report the count of unique firms with available data for each of the four separate
sample windows (limited inspection fieldwork end, limited inspection report release, full inspection fieldwork end,
and full inspection report release). We provide the dates (month and year) of these four events for annually inspected
auditors in Table A1 in Appendix A. In Column 5, we report the number of unique firms in the combined analysis in
which we stack all inspections and sample windows. Thus, the combined analysis includes the same firm up to 4 times.
In Column 6, we report the number of firm-years for the combined analysis. We include any firm fiscal year-end that
falls into a sample window defined for the respective cutoff date (see Section 3.4 and Figures A1 and A2 in Appendix
A for details). We require that a firm have available data on Audit Analytics, Compustat, CRSP, and I/B/E/S.




                                                         51
Table 1. Sample composition (continued)
B. Number of newly treated, triennially inspected auditors and firm-years
                                       Fieldwork                      Inspection reports
                                Newly                               Newly
                                                 Unique                             Unique
                              inspected                          reported-on
                                                  firms                              firms
                               auditors                            auditors
 Calendar year                   (1)                (2)              (3)               (4)
 2004                             24                 98                –                 –
 2005                             54                 98               36                68
 2006                             73               297                44              131
 2007                             14                 32               56              179
 Other                             4                  4               32              150
 Total                           169               529               169              529
 Total firm-years                                1,338                              1,338
Panel B provides a sample breakdown of the number of newly treated, triennially inspected auditors and the number
of their unique client firms and firm-years. We include all firm-years on Compustat with fiscal years ending between
Q2 2001 and Q2 2008 that meet the following requirements: (1) the firm has available data on Audit Analytics,
Compustat, CRSP, and I/B/E/S and (2) the auditor has registered with the PCAOB. At the end of the sample period,
all but 4 auditors in our sample have been inspected; 32 had not yet had an inspection report released. Column 1 (2)
reports the number of newly treated auditors by calendar year, using the inspection fieldwork (report release) as the
cutoff date. Column 3 (4) reports the number of unique client firms associated with the newly inspected auditors. In
the last row, we report the number of firm-years contributed by these firms.




                                                         52
Table 2. Descriptive statistics for the limited, full, and triennial inspection samples

A. Annually inspected U.S. auditors (treatment group)
         Variable             N         Mean        SD                             P25         Median            P75
  CAR                        37,001        0.002      0.064                        -0.030        0.001            0.034
  UE                         37,001            0      0.008                        -0.001            0            0.002
  Loss                       37,001        0.182      0.386                             0            0                0
  Size                       37,001        7.018      1.518                         5.948        6.926            7.990
  Market-to-book             37,001        2.973      2.639                         1.594        2.254            3.487
  Leverage                   37,001        2.654      3.991                         0.506        1.153            2.643
  Persistence                37,001        0.282      0.446                             0        0.285            0.553
  Beta                       37,001        1.092      0.548                         0.708        1.033            1.436
  Forecast                   36,659        0.032      0.074                         0.025        0.046            0.063
  Timeliness                 36,596       -0.201      0.157                        -0.256       -0.155           -0.093
  Relative information       36,586        99.81      0.144                         99.74        99.84            99.92
  Scaled raw accruals        34,855       -0.055      0.076                        -0.084       -0.046           -0.014
  Earnings guidance          37,001        0.530      0.499                             0            1                1
  Guidance bundle            37,001        0.394      0.489                             0            0                1
  Post                       37,001        0.504      0.500                             0            1                1
  Timing: Treatment to
                             12,436        241.0      193.3                             88            165            386
  first EA (in days)
Table 2 presents descriptive statistics for the variables used in the limited, full, and triennial inspection analyses. Table
B1 in Appendix B defines each variable in detail. We include observations from limited and full inspections for
annually inspected auditors using both the end of fieldwork and the inspection report release as cutoff dates (i.e., the
combined sample), so the same firm enters multiple times (see Table 1). We truncate all continuous variables (except
UE) at 1% and 99% by fiscal year. UE is truncated at 2.5% and 97.5% by fiscal year. Panel A presents descriptive
statistics for firms with U.S. annually inspected Big Four or Tier-Two auditors (i.e., the treatment group in the limited
and full inspection analyses). The sample includes 37,001 firm-year observations. The last row in the panel provides
the average number of days from the respective cutoff date (end of fieldwork or inspection report release) to the
(treated) firm’s first earnings announcement.




                                                            53
Table 2. Descriptive statistics for the limited, full, and triennial inspection samples
(continued)

B. Non-U.S. auditors of U.S. cross-listed firms (control group)
         Variable              N         Mean         SD                      P25        Median           P75
  CAR                          3,765       -0.001      0.058                  -0.031      -0.001           0.030
  UE                           3,765       -0.001      0.012                  -0.003           0           0.003
  Loss                         3,765        0.171      0.376                       0           0               0
  Size                         3,765        8.102      1.848                   6.733       8.243           9.580
  Market-to-book               3,765        2.914      2.414                   1.510       2.299           3.597
  Leverage                     3,765        2.711      5.045                   0.470       1.118           2.198
  Persistence                  3,765        0.257      0.529                  -0.001       0.260           0.544
  Beta                         3,765        0.939      0.566                   0.529       0.833           1.292
  Forecast                     3,694        0.042      0.064                   0.026       0.050           0.074
  Timeliness                   3,733       -0.218      0.160                  -0.279      -0.177          -0.106
  Relative information         3,714        99.83      0.125                   99.75       99.85           99.92
  Scaled raw accruals          3,625       -0.063      0.078                  -0.097      -0.055          -0.020
  Earnings guidance            3,765        0.148      0.355                       0           0               0
  Guidance bundle              3,765        0.098      0.297                       0           0               0
  Post                         3,765        0.538      0.499                       0           1               1
Panel B presents descriptive statistics for U.S. cross-listed firms with non-U.S. Big Four or Grant Thornton auditors
that have annually inspected global network affiliates (i.e., the control group in the limited and full inspection
analyses). The sample includes 3,765 firm-year observations.




                                                         54
Table 2. Descriptive statistics for the limited, full, and triennial inspection samples
(continued)

C. U.S. and Non-U.S. auditors control variable balance
                                                    Unweighted                                CEM-weighted
                        U.S.      Non-U.S.
                                                                                                  Size, Beta
         N=                   37,001          3,765                  40,766                         39,843
       Variable               Mean            Mean             Diff.        t-stat            Diff.        t-stat
 Loss                            0.182          0.171            0.011          0.76                 –
 Size                            7.018          8.102           -1.084        -11.50           -0.014         -0.18
 Market-to-book                  2.973          2.914            0.060          0.55                 –
 Leverage                        2.654          2.711           -0.056         -0.22                 –
 Persistence                     0.282          0.257            0.025          1.13                 –
 Beta                            1.092          0.939            0.154          6.11           -0.002         -0.07
 Dropped obs. from
  U.S. sample                                                            0                             895
  Non-U.S. sample                                                        0                              28
Panel C presents differences in means for firms with U.S. versus non-U.S. auditors (i.e., the treatment versus control
group in the limited and full inspection analyses). We show unweighted and, where the unweighted differences are
statistically different from zero, weighted differences. Weights are calculated using coarsened exact matching (CEM),
with 20 bins for the control variables listed in the table header. The matching procedure drops observations when the
bins only contain U.S. or non-U.S. subsamples. All t-statistics are based on standard errors clustered at the firm level.
*p < .1; **p < .05; ***p < .01 (two sided).




                                                          55
Table 2. Descriptive statistics for the limited, full, and triennial inspection samples
(continued)

D. Triennially inspected auditors
         Variable              N                 Mean            SD           P25         Median           P75
  CAR                          1,338              -0.005          0.070       -0.036       -0.003           0.027
  UE                           1,338              -0.009          0.033       -0.006            0           0.001
  Loss                         1,338               0.254          0.436            0            0               1
  Size                         1,338               4.800          0.890        4.309        4.831           5.405
  Market-to-book               1,338               2.862          4.167        1.374        1.890           3.046
  Leverage                     1,338               4.983          5.133        0.431        2.167           9.576
  Persistence                  1,338               0.648          0.605        0.156        0.491           1.083
  Beta                         1,338               0.316          0.587            0        0.328           0.643
  Fieldwork timing:
  Post                         1,338               0.528         0.499               0             1             1
  Timing: Treatment to
                                 706               543.3         343.8            245         505.5           677
  first EA (in days)
  Report release
  timing:
  Post                         1,338               0.297         0.457               0             0             1
  Timing: Treatment to
                                 397               387.1         288.2            130           335           581
  first EA (in days)
  Dropped observation
  timing:
  Post                         1,013               0.392         0.488               0             0             1
Panel D presents descriptive statistics for firms with triennially inspected auditors. The sample includes 1,338 firm-
year observations. We provide descriptive information about the timing assigned to Post for the fieldwork, report
release, and dropped observation designs. In the dropped observation design, we lose 325 earnings announcements
that are between the beginning of fieldwork and the report release (24.3% of the sample). Timing: Treatment to first
EA (in days) is the average number of days from the respective cutoff date (the end of fieldwork date plus 30 days or
inspection report release) to the (treated) firm’s first earnings announcement.




                                                         56
Table 3. Changes in reporting credibility around the introduction of the PCAOB regime for
limited and full inspections
A. Analyses using the primary design
                                              (1)          (2)          (3)           (4)
                                            Limited inspections         Full inspections
  Dependent variable: CAR                 Fieldwork     Reports    Fieldwork       Reports
  UE×Post×Treated                            0.336       0.566*     1.600***       1.149**
                                            (1.094)      (1.881)      (4.978)       (2.141)
  UE×Loss                                 -0.369*** -0.627*** -0.899*** -1.745***
                                           (-2.617)     (-4.645)     (-6.547)      (-8.008)
  UE×Size                                   -0.008       -0.008        0.012      -0.230***
                                           (-0.188)     (-0.200)      (0.272)      (-3.202)
  UE×Market-to-book                          0.031      0.064**      0.047**       0.085**
                                            (1.136)      (2.447)      (2.051)       (2.561)
  UE×Leverage                               -0.011     -0.029**     -0.026**        -0.022
                                           (-0.972)     (-2.559)     (-2.435)      (-1.101)
  UE×Persistence                            -0.038       -0.045       -0.081        -0.019
                                           (-0.330)     (-0.560)     (-0.724)      (-0.092)
  UE×Beta                                  0.289**     0.334***      0.224**         0.227
                                            (2.211)      (2.711)      (2.055)       (1.426)
  Firm characteristics                        Yes          Yes          Yes           Yes
  Treatment indicators                        Yes          Yes          Yes           Yes
  UE×Treatment indicators                     Yes          Yes          Yes           Yes
                                                         Auditor,         Auditor,         Auditor,          Auditor,
                                                        country, &       country, &       country, &        country, &
 Fixed effects                                             year-            year-            year-             year-
                                                          quarter          quarter          quarter           quarter
 UE×Fixed effects                                          Yes               Yes             Yes               Yes
 Observations                                             9,308             9,799           11,833            9,826
 Adjusted R-squared                                        .048              .037            .041              .067
Table 3 presents separate analyses for each inspection event (limited and full) and each sample window cutoff date
(end of fieldwork and report release). Panel A reports results for our analysis using the primary design as described in
Figures A1 and A2 in Appendix A. Following Equation (1), we regress cumulative abnormal returns (CAR) on
unexpected earnings (UE), indicators for PCAOB inspection (i.e., Post and Treated), control variables, fixed effects,
the interactions of UE with control variables and fixed effects, and the interactions of the treatment indicators with
UE (as noted in the table footer). For brevity, we do not report coefficients for the control variables, fixed effects,
treatment indicator main effects, or most of the interactions among these variables. Controls include Loss, Size, M2B,
Leverage, Persistence, and Beta. Table B1 in Appendix B defines each variable in detail. We include fixed effects for
the auditor (defined at the global network level), the auditor’s country of domicile, and the respective fiscal year-end,
as well as the interactions of these fixed effects with UE. In all columns, we estimate a robust regression. In Column
1, we examine the changes in ERCs following fieldwork completion for limited inspections. In Column 2, we examine
the changes in ERCs following inspection report releases for limited inspections. In Column 3, we examine the
changes in ERCs following fieldwork completion for full inspections. In Column 4, we examine the changes in ERCs
following inspection report releases for full inspections. All t-statistics (in parentheses) are based on standard errors
clustered at the firm level. For all robust regressions, we calculate firm-level clustered standard errors using a weighted
least squares regression based on the weights (and coefficients) generated by the rreg command. *p < .1; **p < .05;
***p < .01 (two sided).




                                                           57
Table 3. Changes in reporting credibility around the introduction of the PCAOB regime for
limited and full inspections (continued)
B. Analyses for the dropped observations design
                                                (1)          (2)        (3)           (4)
                                              Limited inspections       Full inspections
  Dependent variable: CAR                  Fieldwork      Reports  Fieldwork      Reports
  UE×Post×Treated                              0.414       0.513*   1.620***      2.145***
                                              (1.310)      (1.691)    (4.965)       (4.940)
  UE×Loss                                  -0.541*** -0.544*** -0.809*** -1.076***
                                             (-4.033)     (-4.285)   (-5.760)      (-5.881)
  UE×Size                                      0.012        0.039      0.010         0.019
                                              (0.321)      (1.055)    (0.229)       (0.303)
  UE×Market-to-book                            0.030      0.060**    0.048**       0.076**
                                              (1.184)      (2.270)    (2.080)       (2.400)
  UE×Leverage                                 -0.014     -0.028**   -0.025**      -0.035**
                                             (-1.163)     (-2.457)   (-2.355)      (-2.348)
  UE×Persistence                               0.006        0.026     -0.109        -0.038
                                              (0.078)      (0.337)   (-0.968)      (-0.233)
  UE×Beta                                   0.363***      0.255**    0.227**        0.290*
                                              (3.108)      (2.352)    (2.031)       (1.675)
  Firm characteristics                          Yes          Yes        Yes           Yes
  Treatment indicators                          Yes          Yes        Yes           Yes
  UE×Treatment indicators                       Yes          Yes        Yes           Yes
                                                         Auditor,          Auditor,         Auditor,         Auditor,
                                                        country, &        country, &       country, &       country, &
 Fixed effects                                             year-             year-            year-            year-
                                                          quarter           quarter          quarter          quarter
 UE×Fixed effects                                           Yes              Yes              Yes               Yes
 Observations                                              8,775            9,191            11,017            9,528
 Adjusted R-squared                                         .041             .034             .043              .060
Panel B reports results for our analysis using the dropped observations design as described in Figures A1 and A2 in
Appendix A. Following Equation (1), we regress cumulative abnormal returns (CAR) on unexpected earnings (UE),
indicators for PCAOB inspection (i.e., Post and Treated), control variables, fixed effects, the interactions of UE with
control variables and fixed effects, and the interactions of the treatment indicators with UE (as noted in the table
footer). For brevity, we do not report coefficients for the control variables, fixed effects, treatment indicator main
effects, or most of the interactions among these variables. Controls include Loss, Size, M2B, Leverage, Persistence,
and Beta. Table B1 in Appendix B defines each variable in detail. We include fixed effects for the auditor (defined at
the global network level), the auditor’s country of domicile, and the respective fiscal year-end, as well as the
interactions of these fixed effects with UE. In all columns, we estimate a robust regression. In Column 1, we examine
the changes in ERCs following fieldwork completion for limited inspections. In Column 2, we examine the changes
in ERCs following inspection report releases for limited inspections. In Column 3, we examine the changes in ERCs
following fieldwork completion for full inspections. In Column 4, we examine the changes in ERCs following
inspection report releases for full inspections. All t-statistics (in parentheses) are based on standard errors clustered at
the firm level. For all robust regressions, we calculate firm-level clustered standard errors using a weighted least
squares regression based on the weights (and coefficients) from the robust regression. *p < .1; **p < .05; ***p < .01
(two sided).




                                                            58
Table 4. Changes in reporting credibility around the introduction of the PCAOB regime in
the combined analyses
A. Main results combining inspection events and cutoff dates
                                       (1)             (2)          (3)            (4)
                                    Primary        Dropped      Primary       Primary
 Dependent variable: CAR
                                     design       obs. design     design        design
                                                                                  loss
                                                                   CEM
                                                                            interactions
 UE×Post×Treated                   0.788***        0.874***      0.719**      0.942***
                                     (3.473)         (3.543)      (2.230)       (3.589)
 UE×Loss                           -0.761***       -0.699***   -0.755***        -0.093
                                    (-6.226)        (-5.857)     (-5.787)      (-0.378)
 UE×Size                             -0.023           0.016       -0.033        -0.022
                                    (-0.610)         (0.441)     (-0.777)      (-0.604)
 UE×Market-to-Book                  0.054**         0.050**      0.061**      0.064***
                                     (2.384)         (2.335)      (2.557)       (2.845)
 UE×Leverage                        -0.024**        -0.025**   -0.032***      -0.024**
                                    (-2.294)        (-2.371)     (-3.028)      (-2.271)
 UE×Persistence                      -0.034          -0.009       -0.090        -0.043
                                    (-0.405)        (-0.124)     (-1.028)      (-0.501)
 UE×Beta                           0.301***        0.284***     0.378***       0.247**
                                     (2.955)         (2.901)      (3.243)       (2.396)
 UE×Loss×Post×Treated                   –               –            –          -0.803
                                                                               (-1.520)
 Firm characteristics                  Yes             Yes          Yes           Yes
 Treatment indicators                  Yes             Yes          Yes           Yes
 UE×Treatment indicators               Yes             Yes          Yes           Yes
                                 Auditor,            Auditor,       Auditor,       Auditor,
 Fixed effects                  country, &          country, &     country, &     country, &
                               year-quarter        year-quarter   year-quarter   year-quarter
 UE×Fixed effects                  Yes                Yes            Yes            Yes
 Loss & UE×Loss interacted
                                   No                  No             No            Yes
 with treatment indicators
 Observations                    40,766              38,511         39,843         40,766
 Adjusted R-squared               .051                .049           .058           .052




                                              59
Table 4. Changes in reporting credibility around the introduction of the PCAOB regime in
the combined analyses
B. Main results, including additional firm-level fixed effects
                                          (1)              (2)       (3)             (4)
 Dependent variable: CAR                   Primary design              6-year design
                                                      Interacted                Interacted
                                         Firm                       Firm
                                                     firm-group                firm-group
                                        effects                    effects
                                                         effects                   effects
 UE×Post×Treated                       0.674**         0.784***  0.783***        0.791***
                                        (2.278)         (2.959)   (2.760)         (3.101)
 UE×Loss×Post×Treated                -2.162***           -0.136   -0.950*          -0.105
                                       (-3.237)         (-0.249)  (-1.672)        (-0.234)
 Firm characteristics                     Yes             Yes        Yes            Yes
 UE×Firm characteristics                  Yes             Yes        Yes            Yes
 Treatment indicators                     Yes             Yes        Yes            Yes
 UE×Treatment indicators                  Yes             Yes        Yes            Yes
 Firm-level main effects only            Firm              No       Firm             No
                                                 Firm-group,                   Firm-group,
 Interacted (and main)             Auditor,        auditor,       Auditor,       auditor,
  effects                         country, &      country, &     country, &     country, &
                                 year-quarter    year-quarter   year-quarter   year-quarter
 UE×Interacted Effects               Yes            Yes            Yes            Yes
 Loss & UE×Loss interacted
                                     Yes            Yes            Yes            Yes
 with treatment indicators
 Observations                      40,766          40,766         58,554         58,554
 Adjusted R-squared                 .272            .084           .236           .077
 Within R-squared                   .013              –            .010             –




                                            60
Table 4 presents analyses combining inspection events (limited and full) and the cutoff dates (end of fieldwork and
report release). Following Equation (1), we regress cumulative abnormal returns (CAR) on unexpected earnings (UE),
indicators for PCAOB inspection (i.e., Post and Treated), control variables, fixed effects, the interactions of UE with
control variables and fixed effects, and the interactions of the treatment indicators with UE (as noted in the table
footer). For brevity, we do not report coefficients for the control variables, fixed effects, treatment indicator main
effects, or most of the interactions among these variables. Controls include Loss, Size, M2B, Leverage, Persistence,
and Beta. Table B1 in Appendix B defines each variable in detail. We include fixed effects for the auditor (defined at
the global network level), the auditor’s country of domicile, and the respective fiscal year-end, as well as the
interactions of these fixed effects with UE. In all columns, we estimate a robust regression. All t-statistics (in
parentheses) are based on standard errors clustered at the firm level. For all robust regressions, we calculate firm-level
clustered standard errors using a weighted least squares regression based on the weights (and coefficients) from the
robust regression. In panel A of Column 1, we estimate the primary design using the combined sample. In Column 2,
we estimate the dropped observations design using the combined sample. We describe these designs in Figures A1
and A2 in Appendix A. In Column 3, we estimate the primary design using a CEM sample with 20 bins for the control
variables Size and Beta; unmatched bins result in 923 fewer observations. In Column 4, we allow for heterogeneous
treatment among profit and loss firms by interacting the treatment indicators with the Loss control variable. In all other
ways, Column 4 is consistent with Column 1. In panel B of Columns 1 and 2, we use our primary design and combined
sample (i.e., up to four firm-year observations around each of the inspection events and cutoff dates). In Columns 3
and 4, we use the combined sample, but add 1 year before and after the respective event date, resulting in a 6-year
series (as opposed to a 4-year series). Columns 1 and 3 otherwise follow the design of panel A, Column 4, except for
the inclusion of firm fixed effects that are introduced as main effects only. That is, firm-level main effects are not
interacted with UE. In Columns 2 and 4, we follow the design of panel A, Column 4, and include firm-group fixed
effects, which are generated by forming 100 portfolios (10-by-10) using the controls Size and Beta from the first year
that a firm enters the sample (see Internet Appendix §9 for more details on groups). The firm-group fixed effects are
included in the model as main effects and with respective interactions, including UE. *p < .1; **p < .05; ***p < .01
(two sided).




                                                           61
Table 5. Tests for other concurrent changes in the information environment around the introduction of the PCAOB
                              (1)            (2)           (3)          (4)            (5)           (6)        (7)
                                                                                                Relative          Scaled raw           Earnings           Guidance
  Dependent variable:                   UE              Forecast           Timeliness
                                                                                              information          accruals            guidance            bundle

  Post×Treated                      -0.001**              0.000               0.003            0.026***              0.003              -0.021              -0.010
                                    (-2.285)             (0.227)             (0.366)            (5.253)             (0.876)            (-1.234)            (-0.705)

  Firm characteristics                  Yes                Yes                 Yes                Yes                 Yes                 Yes                Yes
  Treatment indicators                  Yes                Yes                 Yes                Yes                 Yes                 Yes                Yes
                                     Auditor,            Auditor,           Auditor,            Auditor,           Auditor,            Auditor,            Auditor,
  Fixed effects                     country, &          country, &         country, &          country, &         country, &          country, &          country, &
                                   year-quarter        year-quarter       year-quarter        year-quarter       year-quarter        year-quarter        year-quarter
  Loss interacted with
                                        Yes                Yes                 Yes                Yes                 Yes                 Yes                Yes
  treatment indicators
  Observations                        40,766             40,353              40,329              40,298             38,480              40,766             40,766
  Adjusted R-squared                   0.032              0.410               0.249               0.494              0.147               0.137              0.114
Table 5 presents tests for other concurrent changes in the information environment around the introduction of the PCAOB inspection regime. We estimate the
treatment effects separately for profit and loss firms, but only report the effects for profit firms. In Columns 1 (2, 3, 4, 5, 6, 7), we regress UE (Forecast, Timeliness,
Relative information, Scaled raw accruals, Earnings guidance, and Guidance bundle) on indicators for PCAOB inspection (i.e., Post and Treated), controls, and
fixed effects. In all columns, for brevity, we do not report coefficients for the control variables, fixed effects, and treatment indicator main effects. Controls include
Loss, Size, M2B, Leverage, Persistence, and Beta. Table B1 in Appendix B defines each variable in detail. We include fixed effects for the auditor (at the global
network level), the firm’s country of domicile, and the year-quarter of the respective fiscal year-end. In all columns, we report OLS regressions. All t-statistics (in
parentheses) are based on standard errors clustered at the firm level. *p < .1; **p < .05; ***p < .01 (two sided).




                                                                                   62
Table 6. Are results driven by changes in reporting incentives or by other provisions of the Sarbanes-Oxley Act?
                                 (1)           (2)           (3)            (4)            (5)           (6)          (7)
                              Reporting Incentives                                Sarbanes-Oxley Act
 Dependent variable:         Non-AA         Only AA     Nonaccelerat       Only        Excluding        Only     Controlling
 CAR                           clients       clients          ed        accelerated       404[b]       404[b]     for SOX
 UE×Post×Treated             1.030***        0.492        1.139**        0.871***      0.923***       0.234+      0.921***
                              (3.662)       (1.415)        (2.570)        (3.102)        (3.153)      (0.632)      (3.306)
 UE×SOX404b                       –             –              –             –              –             –         0.275
                                                                                                                   (1.375)
 UE×SOX302a                       –             –              –             –              –             –      -0.900***
                                                                                                                   (-3.276)
 Firm characteristics           Yes           Yes            Yes            Yes            Yes          Yes          Yes
 UE×Firm characteristics        Yes           Yes            Yes            Yes            Yes          Yes          Yes
 Treatment indicators           Yes           Yes            Yes            Yes            Yes          Yes          Yes
 UE×Treatment
                                Yes           Yes            Yes            Yes            Yes          Yes          Yes
 indicators
                             Auditor,       Auditor,       Auditor,       Auditor,       Auditor,       Auditor,       Auditor,
 Fixed effects              country, &     country, &     country, &     country, &     country, &     country, &     country, &
                           year-quarter   year-quarter   year-quarter   year-quarter   year-quarter   year-quarter   year-quarter
 UE×Fixed effects              Yes           Yes            Yes            Yes            Yes            Yes            Yes
 Loss & UE×Loss
 interacted with               Yes           Yes            Yes            Yes            Yes            Yes            Yes
 Treatment indicators
 Observations                34,736         9,795          9,684          34,847         24,867         19,664         40,766
 Adjusted R-squared           .054           .075           .091           .050           .057           .062           .053




                                                               63
Table 6 presents sensitivity analyses that examine the role of changes in market-based reporting incentives and other provisions of SOX. We separately estimate
the treatment effects for loss and profit firms, though we only report the effects for profit firms. Following Equation (1), we regress cumulative abnormal returns
(CAR) on UE, indicators for PCAOB inspection (i.e., Post and Treated), control variables, fixed effects, the interactions of UE with control variables and fixed
effects, and the interactions of the treatment indicators with UE (as noted in the table footer). In all columns, for brevity, we do not report coefficients for the
control variables, fixed effects, treatment indicator main effects, or the interactions among these variables. Controls include Loss, Size, M2B, Leverage, Persistence,
and Beta. Table B1 in Appendix B defines each variable in detail. We include fixed effects for the auditor (at the global network level), the firm’s country of
domicile, and the year-quarter of the respective fiscal year-end. In all columns, we estimate a robust regression. In Columns 1 and 2, we partition the treatment
sample based on whether the firm was audited by Arthur Andersen in 2000 or 2001 (as indicated by the column headings). In Columns 3 and 4, we partition the
treatment sample based on whether a firm-year observation is classified as an accelerated filer in Audit Analytics (as indicated by the column headings). In Columns
5 and 6, we partition the treatment sample based on whether a firm-year has an auditor internal-control opinion (effective, adverse, or disclaimer) in Compustat (as
indicated by the column headings). As additional controls, in Column 7, we include the indicator variables SOX404b and SOX302a and their interactions with UE.
All t-statistics (in parentheses) are based on standard errors clustered at the firm level. + indicates significance (two-sided) at the 10% level for tests of the coefficient
magnitudes, relative to the adjacent column on the left. For all robust regressions, we calculate firm-level clustered standard errors using a weighted least squares
regression based on the weights (and coefficients) from the robust regression. *p < .1; **p < .05; ***p < .01 (two sided).




                                                                                     64
Table 7. Changes in reporting credibility around the introduction of PCAOB triennial inspections
                                     (1)              (2)             (3)           (4)            (5)                (6)
                                                   Report          Report       Dropped           Firm            Interacted
 Dependent variable: CAR         Fieldwork
                                                   release      release-SOX    observation       effects         firm-groups
 UE×Post                          0.789**          1.063**         0.915**       1.022**          0.531            1.077***
                                   (2.125)         (2.387)          (2.231)      (2.247)         (0.566)            (2.380)
 UE×SOX404b                           –                –            -0.566           –              –                  –
                                                                   (-1.595)
 UE×SOX302a                           –                –            -0.120           –              –                 –
                                                                   (-0.604)
 Firm characteristics                Yes             Yes              Yes          Yes             Yes              Yes
 UE×Firm characteristics             Yes             Yes              Yes          Yes             Yes              Yes
 Treatment indicator (Post)          Yes             Yes              Yes          Yes             Yes              Yes
 Firm-level main effects only        No               No              No            No            Firm              No
                                                                                                                 Firm-group,
 Interacted (and main)
                                 Auditor &       Auditor &           Auditor &      Auditor &      Auditor &      auditor, &
  effects                       year-quarter    year-quarter        year-quarter   year-quarter   year-quarter   year-quarter
 UE×Interacted effects              Yes            Yes                 Yes            Yes            Yes            Yes
 Loss & UE×Loss interacted
                                    Yes            Yes                 Yes            Yes            Yes            Yes
 with treatment indicator
 Observations                      1,338           1,338              1,338          1,013          1,338           1,338
 Adjusted R-squared                 .682            .681               .681           .823           .699            .694




                                                               65
Table 7 presents results for the analysis of the change in reporting credibility around the introduction of triennial PCAOB inspections. Following Equation (2), we
regress cumulative abnormal returns (CAR) on UE, an indicator for PCAOB inspections (i.e., Post), control variables, fixed effects, the interactions of UE with the
control variables, the interacted fixed effects, and the treatment indicator (as shown in the table footer). Controls include Loss, Size, M2B, Leverage, Persistence,
and Beta. Table B1 in Appendix B defines each variable in detail. In all columns, we include fixed effects for the auditor and the year-quarter of the respective
fiscal year-end. We estimate robust regressions. We separately estimate the treatment effect for profit and loss firms by including additional interactions. We report
the coefficient of interest for profit firms only. In Column 1, we examine changes in ERCs using the fieldwork cutoff date (i.e., Post equals 1 if the firm’s fiscal
year-end is at least 30 days after fieldwork completion). In Column 2, we examine changes in ERCs using the report release as the cutoff date (i.e., Post equals 1
if the firm’s earnings announcement is after the report release date). In Columns 3 through 6, we perform tests similar to the specifications for annually inspected
auditors. In Columns 3, 5, and 6, we use the report release design from Column 2. As additional controls, in Column 3, we add the indicator variables SOX404b
and SOX302a and their interactions with UE. In Column 4, we examine the dropped observation design for triennially inspected auditors. In Column 5, we include
firm-level main effects that are not interacted with UE. In Column 6, we include firm-group fixed effects interacted with UE; these are generated by forming 16
portfolios (4-by-4) using Size and Beta from the first year that a firm enters the sample (see Internet Appendix §9 for more details on groups). The firm-group fixed
effects are included in the model as main effects and with their respective interactions, including UE. All t-statistics (in parentheses) are based on standard errors
clustered at the firm level. We calculate firm-level clustered standard errors using a weighted least squares regression based on the weights (and coefficients) from
the robust regression. *p < .1; **p < .05; ***p < .01 (two sided).




                                                                                 66
Table 8. Changes in abnormal trading volume around 10-K filings after the introduction of
the PCAOB regime
                                 (1)         (2)        (3)          (4)           (5)
 Dependent variable:                                  CEM:         CEM:          CEM:
                                OLS         OLS
 Abnormal 10-K volume                                  WLS          WLS           WLS
 Post×Treated                 0.088**    0.097***   0.136***      0.126**       0.100**
                              (2.552)      (2.748)    (2.973)      (2.551)       (2.146)
 Size                         0.016**      -0.024     -0.018       -0.016        -0.017
                              (2.476)     (-0.990)   (-0.710)     (-0.638)      (-0.685)
 M2B                        -0.009***      -0.002      0.000       -0.000         0.000
                              (-3.457)    (-0.359)    (0.013)     (-0.016)       (0.034)
 Leverage                    0.009***     0.012**      0.009        0.009         0.009
                              (5.256)      (2.089)    (1.575)      (1.525)       (1.592)
 Beta                        0.076***    0.077***    0.058**      0.057**       0.054**
                              (5.460)      (3.679)    (2.534)      (2.463)       (2.347)
 Loss                       -0.075***    -0.061**    -0.051*     -0.057**       -0.051*
                              (-4.126)    (-2.219)   (-1.783)     (-1.961)      (-1.780)
 Filing delay after FYE      0.004***    0.003***   0.004***     0.003***      0.004***
                              (7.920)      (5.065)    (5.076)      (3.888)       (5.074)
 Filing delay after EA      -0.006*** -0.005*** -0.005*** -0.006*** -0.005***
                             (-15.081)    (-7.570)   (-7.284)     (-7.954)      (-7.227)
 Analyst following            -0.002*       0.000      0.000        0.001        -0.000
                              (-1.862)     (0.020)    (0.085)      (0.299)      (-0.063)
 log(10-K file size)              –           –          –          0.016           –
                                                                   (1.159)
 SOX404b                          –           –          –            –           0.051
                                                                                 (1.631)
 SOX302a                          –           –          –            –           0.076
                                                                                 (1.345)
 Treatment indicators           Yes          Yes        Yes          Yes           Yes
                              Auditor,
                                           Firm &      Firm &      Firm &      Firm &
                             country, &
 Fixed effects                              year-       year-       year-       year-
                                year-
                                           quarter     quarter     quarter     quarter
                               quarter
 Observations                 68,830       68,830      67,178      65,051      67,178
 Adjusted R-squared            .038         .244        .259        .260        .259




                                           67
Table 8 presents results for the analysis of changes in abnormal trading volume around 10-K filings after the
introduction of the PCAOB regime. Following Equation (3), we regress Abnormal 10-K volume on indicators for
PCAOB inspections (i.e., Post and Treated), control variables, and fixed effects (as indicated in the table footer).
Table B1 in Appendix B defines each variable in detail. We include fixed effects for the auditor (at the global network
level), the firm’s country of domicile, the year-quarter of the respective fiscal year-end, and the firm (as indicated in
the table footer). In Column 1, we report the baseline specification estimated using OLS. We repeat this in Column 2,
but substitute firm fixed effects for auditor and country fixed effects. In Column 3, we report the primary design with
weighted least squares (WLS) using weights from a coarsened exact matching (CEM) procedure that uses 20 bins for
the control variables Size, Beta, and Loss; unmatched bins result in 1,652 fewer observations. In Column 4, we use
WLS with the CEM weights from Column 3 and include continuous variable log(10-K file size). In Column 5, we use
WLS with the CEM weights from Column 3 and include the indicator variables SOX404b and SOX302a. All t-statistics
(in parentheses) are based on standard errors clustered at the firm level. *p < .1; **p < .05; ***p < .01 (two sided).




                                                          68
