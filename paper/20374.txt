                                NBER WORKING PAPER SERIES




                    SPATIAL ERRORS IN COUNT DATA REGRESSIONS

                                          Marinho Bertanha
                                            Petra Moser

                                        Working Paper 20374
                                http://www.nber.org/papers/w20374


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     August 2014




We thank Han Hong, Guido Imbens, Aprajit Mahajan, and Scott Stern for helpful conversations and
comments. Moser gratefully acknowledges financial support through NSF CAREER grant 1151180.
The views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2014 by Marinho Bertanha and Petra Moser. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice,
is given to the source.
Spatial Errors in Count Data Regressions
Marinho Bertanha and Petra Moser
NBER Working Paper No. 20374
August 2014
JEL No. C23,C33,O3

                                                ABSTRACT

Count data regressions are an important tool for empirical analyses ranging from analyses of patent
counts to measures of health and unemployment. Along with negative binomial, Poisson panel regressions
are a preferred method of analysis because the Poisson conditional fixed effects maximum likelihood
estimator (PCFE) and its sandwich variance estimator are consistent even if the data are not Poisson-distributed,
or if the data are correlated over time. Analyses of counts may be affected by correlation in the cross-section.
For example, patent counts or publications may increase across related research fields in response
to common shocks. This paper shows that the PCFE and its sandwich variance estimator are consistent
in the presence of such dependence in the cross-section - as long as spatial dependence is time-invariant.
In addition to the PCFE, this result also applies to the commonly used Logit model of panel data with
fixed effects. We develop a test for time-invariant spatial dependence and provide code in STATA
and MATLAB to implement the test.


Marinho Bertanha
Department of Economics
Stanford University
579 Serra Mall
Stanford, CA 94305-6072
bertanha@stanford.edu

Petra Moser
Department of Economics
Stanford University
579 Serra Mall
Stanford, CA 94305-6072
and NBER
pmoser@stanford.edu




Online supplements STATA and MATLAB commands to implement estimation procedures
described in the paper are available at:
www.stanford.com/~bertanha/xtpsse_stata.zip www.stanford.com/~bertanha/xtpsse_matlab.zip
1     Introduction

    Empirical analyses in economics and other disciplines rely heavily on regressions of count
data, such as patents, citations, publications, and counts of accidents or unemployed workers.
Along with the negative binomial estimator, the Poisson Conditional Fixed Effects Maximum
Likelihood Estimator (PCFE) has become the standard approach to analyze count data. A
key advantage is that the PCFE is robust to misspecifications of the underlying distribution
as long as the conditional mean is correctly specified (Wooldridge (1999), and Gourieroux,
Monfort and Trognon (1984)). For example, the PCFE is robust even if the variance of the
distribution is different from the mean (violating the assumption of equidispersion), or if the
data includes an excessive number of zeros. Another key benefit is that the PCFE is robust
to dependence over time. For example, counts of patents or unemployed workers may be
correlated over time and the PCFE is robust to such correlation.
    Count data can, however, also be affected by cross-sectional dependence. For example,
Jaffe, Trajtenberg and Henderson (1993) show that knowledge spillovers are geographically
localized. Patent data analyzed by Hall, Griliches and Hausman (1986) show evidence of
spatial dependence. Figure 1 depicts patterns of spatial dependence for patents by firms
with more than 100 patents per year. These firms may benefit from localized knowledge
spillovers (as described by Jaffe, Trajtenberg and Henderson (1993)) or from shared access
to human capital and other inputs to invention (Marshall (1890)).
    Counts of patents, publications, and other measures for innovation may also be corre-
lated in idea space - in addition to geographic space - if knowledge spillovers and scientific
breakthroughs encourage innovation across related fields. This type of spatial dependence
in idea space is likely to affect a growing literature (e.g. Azoulay, Zivin and Wang (2010),
Furman and Stern (2011), Moser and Voena (2012), Borjas and Doran (2012), Williams
(2013), Kogan, Papanikolaou, Seru and Stoffman (2012), and Moser, Voena and Waldinger
(2014)).


                                              2
       This paper investigates whether whether spatial dependence (or correlation in the cross-
section) threatens statistical inference from Poisson estimates of count data. To account
for spatial dependence, we specify the likelihood scores of the PCFE as moment conditions
in Conley (1999)’s spatial estimation framework. We find that the PCFE is consistent
and asymptotically normal. The asymptotic variance of the PCFE is generally different
from the variance that assumes spatial independence. To address this issue, we present a
consistent spatial variance estimator for the case of spatial dependence. In comparison with
clustering as a standard approach to address cross-sectional dependence, the spatial variance
estimator is more general than clustering because it allows for dependence between any pair
of individuals while clustering only allows for dependence within groups.1

            Figure 1: Patents per Firm Conditional on Patents by Neighboring Firms

                    0.5                                             0.5

                    0.4                                             0.4

                    0.3                                             0.3

                    0.2                                             0.2

                    0.1                                             0.1

                     0                                               0
                          200     400     600      800                    200     400     600     800
                       (A) Sum of neighboring patents is               (B) Sum of neighboring patents is
                      between 0 and 30 (0-25th percentile)          between 30 and 190 (25-50th percentile)


                    0.5                                             0.5

                    0.4                                             0.4

                    0.3                                             0.3

                    0.2                                             0.2

                    0.1                                             0.1

                     0                                               0
                          200     400     600      800                    200     400     600     800
                      (C) Sum of neighboring patents is              (D) Sum of neighboring patents is
                    between 190 and 639 (50-75th percentile)       between 639 and 4198 (75-100th percentile)
Notes: Firm A is defined to be a neighbor of firm B if its distance in terms of latitude and longitude is less
or equal to the 10th quantile of distances in the sample; results are robust to using the 25th or 50th quantile
as a cutoff to define neighbors. Dots plot the unconditional distribution of patents per year by firms with
more than 100 patents per year. Bars plot the distribution of patents per year for firms whose neighbors
produce few patents (sum of neighboring patents is between 0 and the 25th quantile, Panel A), medium level
of patents (25-50th and 50-75th quantiles, Panels B and C) and many patents (75-100th quantile, Panel D).

   1
       For a discussion of clustering see Cameron and Trivedi (2005), section 24.5.6, or STATA 13 User’s
Guide, section 20.21.2.


                                                               3
   Allowing for spatial dependence changes the variance of the PCFE if covariances of the
likelihood score function between observations in the cross-section are nonzero. We also show
that covariances of the likelihood scores are zero - and the standard sandwich estimator of
the PCFE is consistent - as long as spatial dependence is time-invariant.For example, firm
patent applications may be spatially correlated because of unobservable shocks that affect
the local supply of high-skilled workers such as cultural goods, high-quality restaurants or
schools. If access to these amenities is constant during the sample period, then the structure
of spatial dependence is time-invariant.
   More formally, spatial dependence is time-invariant if unobservable shocks can be fac-
tored into a time-variant and a time-invariant component, and only the time-invariant com-
ponent generates spatial dependence. Time-invariant spatial dependence does not affect the
asymptotic variance of the PCFE because the source of spatial dependence are unobservable
time-invariant components that are not separately identified from the unobservable fixed
effects of the PCFE model.
   The fixed effects of the PCFE model are modified to absorb time-invariant components
of unobservable shocks that cause spatial dependence. With this modification, covariances of
the likelihood score between different observations in the cross-section are zero. As a result,
the asymptotic variance of the PCFE under time-invariant spatial dependence is equal to
the variance under spatial independence, and the standard sandwich variance estimator is
consistent. In addition to the PCFE, this result also applies to the commonly used Logit
model of panel data with fixed effects.
   To detect spatial dependence that is not time-invariant, a test-statistic is constructed
based on the coefficients of a regression of the likelihood score of each individual on an
average of the likelihood scores of neighboring individuals. Under the null hypothesis of
time-invariance, the estimated parameters of this regression should be close to zero, because
the covariance of the likelihood scores between different individuals is zero. The test-statistic
is a Wald test for the restriction that these parameters are jointly equal to zero.


                                               4
        We illustrate the PCFE, its variance estimators, and the test statistic by applying them
to Hall, Griliches and Hausman (1986)’s analysis of the link between firms’ expenditures on
research and patent counts, as a measure of research output. We also apply our approach to
Furman and Stern (2011)’s analysis of the effects of a biological research center on cumulative
research output, measured by count data on scientific citations. We provide new commands
in STATA and MATLAB that compute the PCFE, its variance estimators, and the test
statistic.2
        The remainder of this paper is organized as follows. In Section 2, we summarize existing
robustness results for the PCFE that rely on the assumption of spatial independence. Section
3 derives the asymptotic distribution of the PCFE under spatial dependence, and provides
a consistent spatial estimator for the variance of the PCFE. We show that the sandwich
variance estimator is consistent for the variance of the PCFE if spatial dependence is time-
invariant. Section 4 constructs a test-statistic and derive its distribution under the null
hypothesis of time-invariance. Section 5 illustrates the estimator with the examples of Hall,
Griliches and Hausman (1986) as well as Furman and Stern (2011). An appendix presents
proofs for the results in this paper and provides additional details about the code in MATLAB
and STATA.




2         PCFE under Spatial Independence

        This section introduces the PCFE model of Hausman, Hall and Griliches (1984) (HHG)
and summarizes existing robustness results that rely on the assumption of spatial indepen-
dence. We revisit these results in the next section where the assumption of spatial inde-
pendence is relaxed. For i = 1, . . . N (cross-sectional units), and t = 1, . . . T (time periods),
denote the random variables: yi = [yi1 . . . yiT ]0 a T × 1 vector of count dependent variables;
xi = [xi1 . . . xiT ]0 a T × K matrix of explanatory variables; φ = [φ1 . . . φN ]0 a N × 1 vector of
    2
        Available at www.stanford.com/˜bertanha/xtpsse stata.zip; and www.stanford.com/˜bertanha/xtpsse matlab.zip


                                                      5
strictly positive individual fixed effects that are unobserved.3 To compute asymptotic distri-
butions, we let N → ∞ while T remains fixed. The likelihood function is derived assuming
observations are independent across i and t, and yit |xi , φi ∼ iid Poisson (φi exp (x0it β0 )). Un-
like the Poisson random effects model, here individual fixed effects and explanatory variables
can be dependent or independent.
   Using the argument of Andersen (1972), HHG conditions the Poisson distribution above
                                  PT
on the sum across t of yit , ni =  t=1 yit . This leads to a likelihood function that does

not depend on the unobserved φ. Following Wooldridge (1999), the pseudo log-likelihood
function is LN (β) = N1 N
                             P                             PT
                                i=1 `i (β), where `i (β) =  t=1 yit log [pt (xi , β)], and pt (xi , β) =

exp (x0it β)/ Tk=1 exp (x0ik β). The maximum likelihood estimator is the zero of the score
             P

function4 SN (β) = N1 N
                        P
                             i=1 Si (β) where




                                   Si (β) = ∇β p (xi , β)0 W (xi , β) ui (β)

                                  p (xi , β) = [p1 (xi , β) , . . . , pT (xi , β)]0

                                       W (xi , β) = [diag {pt (xi , β)}t ]−1

                                                   ui (β) = yi − p (xi , β) ni




       Using standard results for the asymptotics of maximum likelihood estimators,
   3
       Despite being random, the φi ’s are called fixed effects because the Poisson distribution assumption is
made conditionally on the φi ’s.
  4
    HHG shows global concavity of this likelihood function for a compact parameter space. Note that we
cannot compute β̂ if there exist explanatory variables that are constant over time, or any linear combination
of the explanatory variables that is constant over time.




                                                         6
                              √           
                                             d
                                  N β̂ − β0 → N 0; A−1    −1
                                                             
                                                    0 B0 A0


                                                 where                                       (1)

                                        A0 = E [∇β Si (β0 )]

                                        B0 = V AR [Si (β0 )]


   If the model is correctly specified, then A0 = −B0 , and the variance in the sandwich form
simplifies to B0−1 or −A−1
                        0 . An important reason for the widespread use of PCFE to analyze

count data lies in its robustness to misspecification of the Poisson distribution. Empirically,
the main concern is that count data typically do not satisfy the Poisson’s assumption of
equidispersion, i.e. the variance of the distribution is equal to the mean. Another issue is
that count data typically include a larger number of zeros than the best fitted Poisson model
would predict.
   There are two important robustness results in the literature for the Poisson model that as-
sume spatial independence. In the case of cross-sectional data with no fixed effects, Gourier-
oux, Monfort and Trognon (1984) show that consistency and asymptotic normality only
relies on the correct specification of the conditional mean. Wooldridge (1999) extends this
robustness result for the case of panel data with fixed effects, where the conditional mean is
assumed to be correctly specified as


                                   E[yit |xi , φi ] = φi exp (x0it β0 )                      (2)


   In other words, Wooldridge (1999) proves that the PCFE proposed by HHG is consistent
and asymptotically N 0; A−1      −1
                                    
                          0 B0 A0     under misspecification of the Poisson distribution as
long as the conditional mean is correctly specified. If the Poisson distribution is misspecified,
A0 may be different than −B0 , and we cannot simplify the sandwich form of the variance



                                                    7
A−1     −1                                                                   −1     −1
  0 B0 A0 . This is the reason why current applied research estimates A0 B0 A0 instead B0
                                                                                                −1

                         PN                           PN
or −A−1
      0 . Using Â = N
                      1                             1
                           i=1 ∇β Si (β̂), and B̂ = N
                                                                         0
                                                       i=1 Si (β̂)Si (β̂) as consistent estimators

for A0 and B0 , the so called ‘sandwich variance estimator’ is consistent for the asymptotic
variance of PCFE under misspecification of the Poisson distribution:


                                           Â−1 B̂ Â−1                                       (3)


    This paper relaxes the assumption of independence across individuals in the cross-section
of the PCFE model. Many types of count-data regressions are affected by spatial dependence,
for example, in geographic or idea space. For example, counts of patent applications by a
firm may be correlated to patent applications by neighboring firms if knowledge spillovers
are geographically localized (Jaffe, Trajtenberg and Henderson (1993)). Knowledge spillovers
can also influence patent counts of similar research fields, generating spatial dependence in
idea space. In the next section, we show that spatial dependence changes the distribution
of β̂ given in (1) above. Standard-errors that are computed based on the distribution in (1)
may lead to invalid inferences in the presence of spatial dependence.



3     PCFE under Spatial Dependence

    In this section we apply Conley (1999)’s results to derive the asymptotic distribution
of the PCFE under spatial dependence. We show that this asymptotic distribution is the
same as the asymptotic distribution that assumes spatial independence (1) as long as spatial
dependence is time-invariant. This is a new robustness result for the PCFE. In the next
section, we construct a test-statistic and derive its distribution under the null hypothesis of
time-invariant spatial dependence.
    Using the PCFE score function as a moment condition, consistency and asymptotic
normality follow from Conley (1999)’s spatial GMM estimator. In the following paragraph,
we introduce definitions that are central to our current analysis; see Conley (1999) for a

                                                8
more detailed discussion.5
       From now on, we substitute the i index in any random variable by si ∈ R2 , which means
that each unit in the cross-section has an Euclidean coordinate locating it in the R2 space
(this can also be generalized to Rk ). We assume that these coordinates are observed for all
units in the sample. The subscript s represents a coordinate in R2 , and p, a coordinate in
Z2 .
       It is assumed that observations are at least d0 > 0 apart from each other. To better
index observations, the R2 is covered by a regular lattice. Construct a grid with d∗ × d∗
identical squares with a diagonal that is less than d0 . This implies that there is always at
most one point in each square. Let D1 and D2 denote the number of lines and columns,
respectively, of the largest rectangular grid with d∗ × d∗ squares that contains the observed
sample. Label the grid lines using integers and label each square by its southwest corner
coordinate, a vector p ∈ Z2 . Not every square in this grid necessarily has an observation, that
is, N ≤ D1 D2 . The probability of observing a realization in any square is given by λ, and
this event is independent of everything else and across different squares. Let Yp (β) = Ss (β)
if s is observed in square p, but Yp (β) = 0 otherwise. Using Conley (1999)’s central limit
theorem, if the conditional mean (eq. 2) is correctly specified, then:



                                  √           
                                                 d
                                      N β̂ − β0 → N 0, A−1     −1
                                                                  
                                                        0 C 0 A0                                      (4)
   5
       Lemma 2 in the appendix shows that the PCFE score function satisfies Conley (1999)’s identification
assumption; that is, β0 is the unique solution to E[Si (β)] = 0.




                                                      9
where


                                      A0 = λ−1 E[∇β Yp (β0 )]
                                          X
               V0 =     lim    (D1 D2 )−1   COV [Yp (β0 ) , Yq (β0 )] non-singular
                      D1 ,D2 →∞
                                             p,q

                                               C0 = λ−1 V0


   In this setting, Â = N −1
                                  P
                                   i   ∇β Ssi (β̂) is a consistent estimator for the Hessian matrix
A0 . The consistent estimator Ĉ for C0 is an weighted average of sample spatial covariances
which is generally different than B̂. Like other covariance estimators, we need to cut off the
number of maximum lags we use when computing covariances between all possible pairs of
individuals. We denote the vertical and horizontal bandwidths as LD1 and LD2 . These are
assumed to go to infinity more slowly than the sample size.
   Define

                                                   LD1 −1    LD2 −1
                                           1        X         X
                                      Ĉ =
                                           N   j=−LD1 +1    k=−LD2 +1
                   D1
                   X               D2
                                   X                                      0 
                                             KD1 ,D2 (j, k) Ym,n β̂ Ym+j,n+k β̂
                    m=1             n=1
               st 1≤m+j≤D1     st 1≤n+k≤D2



   where we used the notation p = (m, n) ∈ Z2 and


                           
                            (1 − |j| /LD ) (1 − |k| /LD ) , for |j| < LD , |k| < LD
                           
                                         1              2                1          2
        KD1 ,D2 (j, k) =
                           
                                              0                 , o.w.

                                                                          p
   Under additional assumptions, Conley (1999) shows that Ĉ → C0 . Therefore, a consistent




                                                      10
estimator for the asymptotic variance of the PCFE under spatial dependence is given by


                                              Â−1 Ĉ Â−1                                            (5)


We call this estimator the ‘spatial variance estimator’.
   Our approach allows for spatial dependence, whereas HHG and Wooldridge (1999) assume
spatial independence. The only restrictions that Conley (1999) imposes on the nature of
spatial dependence are stationarity and mixing conditions. Although accounting for spatial
dependence preserves the consistency and asymptotic normality of the PCFE, estimates
of the variance may be affected by spatial dependence, such that inference based on the
sandwich variance estimator may be misleading.
   Comparing the distribution of β̂ under spatial dependence (4) to the distribution of β̂
under spatial independence (1), the difference arises in the expression for the variance of the
sum of the individual score functions (C0 vs B0 ). Under spatial dependence, this variance
contains covariances between scores of different individuals. If the covariance of the score
function of any two different individuals is zero, then C0 = λ−1 E[Yp (β0 )Yp (β0 )0 ] = B0 , and
B̂ = N −1 i ∇β Ssi (β̂)∇β Ssi (β̂)0 is a consistent estimator for B0 = C0 . The asymptotic
          P

results for the PCFE given in (1) along with its sandwich variance estimator continue to be
valid under spatial dependence if C0 = B0 . If the covariance of the score function is not zero
for some pairs of individuals, then C0 can be different than B0 , and the sandwich variance
estimator can be inconsistent for the variance of the PCFE.
   We define the unobserved shock vector εs = [εs,1 , · · · , εs,T ]0 such that εs,t ≡ ys,t / φs exp(x0s,t β0 )
                                                                                                               

for s ∈ R2 and t = 1, . . . , T . Given the observed data {ys , xs }s and the conditional mean
assumption (eq. 2), we can identify β0 and the joint distribution of {ys , xs , φs εs }s but we
cannot identify the distribution of φs and εs separately. There can be different εes,t and
φes such that φes εes,t = φs εs and the conditional mean equation holds for β0 and φes . It is
important to emphasize that the spatial dependence of unobserved shocks conditional on



                                                  11
explanatory variables xs and fixed effects φs is what makes C0 and B0 different. However, if
there is spatial dependence on εs,t conditional on (xs , φs ), but no spatial dependence on εes,t
conditional on (xs , φes ), then C0 and B0 will be the same. This is the case when the spatial
dependence on {εs }s is time-invariant.

Definition 1. The spatial dependence on {εs }s is said to be ‘time-invariant’ if there exists
c > 0 and {{us,t }t , ηs }s strictly positive scalar random variables such that


                                                    εs,t = ηs us,t


with us ⊥(us0 , xs0 , φs0 ηs0 )|xs , φs ηs for every s 6= s0 , where us = [us,1 , · · · , us,T ]0 , and E[us,t |xs , φs ηs ] =
c for every s, t .

    Intuitively, time-invariant spatial dependence means that εs,t can be decomposed in a
time-invariant component ηs , and a time-variant component us,t , and that the spatial de-
pendence in εs,t is generated by the time-invariant component ηs . Note that time-invariance
only restricts the spatial dependence on the unobserved variable εs,t to be constant over
time. It does not say that variables shouldn’t be correlated at all. For example, we can have
spatial and time dependence in ys,t , xs,t , εs,t , and spatial dependence in φs and still have
time-invariant spatial dependence on εs,t .
    If the spatial dependence on {εs }s is time-invariant, then the covariance of the score
function between any two different individuals is zero. Therefore, the asymptotic results
for the PCFE given in (1) along with its sandwich variance estimator are robust to spatial
dependence under time-invariance. Theorem 1 states the result; we present the complete
proof in the appendix.

Theorem 1. Under correct specification of the conditional mean function (eq. 2), if the
spatial dependence on {εs }s is ‘time-invariant’, then


                               COV [Ss (β0 ), Ss0 (β0 )] = 0, for every s 6= s0


                                                          12
                √           
                               d
                    N βb − β0 → N 0, A−1    −1
                                               
Consequently,                         0 B0 A0    , and the sandwich estimator given in
equation 3 is consistent for the variance of the PCFE.

    Time-invariance on the spatial dependence of εs,t does not affect the asymptotic variance
of the PCFE because the source of spatial dependence is ηs . This time-invariant component of
εs,t is not separately identified from the fixed effects φs that we control for in the PCFE model.
In other words, we can write an indistinguishable model with fixed effects φ̃s that absorb
the time-invariant components ηs leaving no spatial dependence on the unobserved shocks.
For example, firm patent applications may be spatially correlated because of unobservable
factors that affect the local supply of high-skilled workers such as cultural goods, high-quality
restaurants or schools. If access to these amenities is constant during the sample period,
then the structure of spatial dependence is time-invariant.



4     Testing for Time-invariant Spatial Dependence

    In this section we construct a test-statistic and derive its distribution under the null
hypothesis of time-invariant spatial dependence on the unobservable shocks {εs }s . The idea
is to detect if the asymptotic variance of β̂ changes from A−1    −1    −1    −1
                                                            0 B0 A0 to A0 C0 A0 when there

is spatial dependence. Throughout this section, we maintain Conley (1999)’s assumptions of
spatial dependence (as in section 3). If the null hypothesis of time-invariance is false, then
A−1    −1
 0 B0 A0  is generally different than A−1    −1
                                       0 C0 A0 , and we should use the spatial variance

formula (eq. 5) to estimate the variance of β̂ consistently. If the null hypothesis is true, then
A−1    −1   −1    −1
 0 B0 A0 = A0 C0 A0 , and the simpler sandwich variance estimator is consistent for the

variance of β̂. The spatial variance estimator is also consistent if the null hypothesis is true,
and the difference between sandwich and spatial estimates is small in large samples.
    To compute the test statistic, we regress each of the K elements of the vector Ss (β̂) on
averages of the spatial lags of the elements of the vector Ss (β̂). Under the null hypothesis of
time-invariance, the covariance of the score function between different cross-sectional units


                                               13
is zero (Theorem 1). This leads to estimated regression coefficients that are close to zero in
large samples. We use the Wald test statistic to test the restriction that all parameters are
zero.
   For a given observation located in p = (m, n), we define the non-random set of neighbors
up to the l = (l1 , l2 ) spatial lag to be N (p, l) = {p0 = (m0 , n0 ) ∈ Z2 : p0 6= p, |m0 − m| ≤
l1 , |n0 − n| ≤ l2 }. The number of elements in N (p, l) does not depend on p, and we call it
Nl . Remember that Yp (β) = Ss (β) if s ∈ R2 is in the grid cell p ∈ Z2 , and zero otherwise.
The average of the l-th spatial lags of the vector Yp is defined as Ȳp,l = Nl−1 q∈N (p,l) Yq .
                                                                                 P

                                                                                              (k)
For a given choice of spatial lag l = (l1 , l2 ), and for each k = 1, . . . , K, we regress Yp (β̂) on
                             (1)              (k)
k explanatory variables Ȳp,l (β̂), · · · , Ȳp,l (β̂) to obtain the k × 1 vector of estimates θ̂k . We
have a total of K ∗ = K(K + 1)/2 estimated parameters that are stacked in Θ
                                                                          b = [θb10 . . . θb0 ]0 .
                                                                                            K

We define the test statistic Tb as:




                                            T̂ = N Θ̂0 Ŵ −1 Θ̂


   where


                                                               !−1
                                     X                               X
                           Θ
                           b=              Zp (β)Z  b0
                                               b p (β)                      Zp (β)Y
                                                                                b p (β)
                                                                                     b
                                       p                              p
                                                        n          oK
                                                            (1:k)
                                   Zp (β)K ∗ ×K   = diag Ȳp,l (β)
                                                                                 k=1




                                                    h                                    i0
                                 (1:k)                     (1)                  (k)
                              Ȳp,l (β)k×1    =         Ȳp,l (β), · · ·   , Ȳp,l (β)

                                          W           b−1 Ω
                                          cK ∗ ×K ∗ = Γ   bΓb−1

                                    bK ∗ ×K ∗ = − 1
                                                     X
                                    Γ                   Zp (β)Z  b0
                                                            b p (β)
                                                 N p



                                                          14
                                                        LD1 −1      LD2 −1
                                                   1        X        X
                                    Ω
                                    b K ∗ ×K ∗   =
                                                   N   j=−LD1 +1   k=−LD2 +1
              D1
              X             D2
                            X                                                          0 
                                                                                0
                                      KD1 ,D2 (j, k) Zm,n (β)Y
                                                           b m,n (β)Y
                                                                  b m+j,n+k (β)
                                                                             b Zm+j,n+k βb
               m=1           n=1
          st 1≤m+j≤D1   st 1≤n+k≤D2


        Under the null hypothesis of time-invariant spatial dependence, this test-statistic is
asymptotically Chi-square distributed (Theorem 2, for a proof see Appendix, 7.4).6

Theorem 2. Under the null hypothesis of time-invariant spatial dependence,


                                                        d
                                                   T̂ → χ2K ∗


        If the estimate of this test-statistic exceeds a critical value, the null hypothesis of time-
invariant spatial dependence is rejected, which indicates that the sandwich variance estimator
is inconsistent. Failing to reject the null hypothesis indicates both the sandwich and spatial
variance estimators are consistent. In that case, there is either no spatial dependence or
spatial dependence is time-invariant.



5         Applications

        In this section, we illustrate the estimates and test-statistic with the examples of Hall,
Griliches and Hausman (1986)’s analysis of patent counts, and Furman and Stern (2011)’s
analysis of journal citations. In these examples, the differences between the sandwich and the
spatial variance estimates are small; values of the test statistic fail to reject time-invariance
spatial dependence which is consistent with small differences between spatial and sandwich
variance estimates.
    6
        It is unfeasible to compute Θ
                                    b if Γ    c are not invertible. This may be the case when K ∗ is large
                                         b or W

compared to the sample size N . Choosing to regress a number smaller than K of elements of the score
vector Y does not affect the limiting distribution of T̂ except for the smaller number of degrees of freedom.



                                                        15
5.1     Application to Hall, Griliches and Hausman (1986)

   Hall, Griliches and Hausman (1986) use patent counts to investigate whether patenting
responds to contemporaneous investment in R&D or whether it responds with a lag. Their
analysis of patent counts and R&D expenditures for 642 U.S. firms between 1972 and 1979
indicates that patenting is most responsive to contemporaneous expenditures in R&D. A
plot of the spatial component of their data reveals evidence of spatial dependence for firms
with more than 100 patent applications per year (Figure 1). In this section, we replicate the
analysis of Hall, Griliches and Hausman (1986) to examine whether Poisson estimates are
compromised by spatial dependence. Specifically, we replicate Table 6 (on p. 279 of their
paper) as a PCFE with firm fixed effects:



                                                                 3
                                                                                             !
                                                                 X
                 E[pi,t |Ri,t , · · · , Ri,t−3 , φi ] = φi exp          βτ log Ri,t−τ + αt       (6)
                                                                 τ =0


where

   • pi,t is the number of patent applications by firm i in year t;

   • Ri,t measures R&D expenditures in millions of 1972 US dollars;

   • αt are year fixed effects;

   • φi are firm fixed effects.

   In these data, patent applications may be correlated across space, because the unobserv-
able factors that influence patenting, such as the supply of high-skilled labor, specialized
inputs, or knowledge spillovers, are correlated across space. Theorem 1 implies that the
sandwich variance estimator is consistent in the presence of such spatial dependence, as long
as the structure of spatial dependence is time-invariant. For example, the geographic loca-
tion of high-skilled workers may vary with the supply of amenities that attract them, such as


                                                      16
cultural goods, high-quality restaurants or schools. If access to these amenities is constant
during the sample period, then the structure of spatial dependence is time-invariant.
       To construct a measure for the geographic proximity between patent applications, we use
information from the CUSIP (Committee on Uniform Security Identification Procedures)
codes of firms who apply for patents to obtain information on their street addresses from
COMPUSTAT.7 Address data are available from COMPUSTAT for 460 of 642 firms. We
then convert addresses to latitude and longitude coordinates, and calculate distances between
coordinates.

             Figure 2: Location of Patentees in Hall, Griliches and Hausman (1986)
                  100


                   90


                   80


                   70


                   60


                   50


                   40


                   30


                   20


                   10


                    0
                   −180       −160      −140       −120      −100       −80        −60
Notes: Squares represent three bandwidth choices (the 10th, 25th, and 50th quantile of the distribution of
the distance computed along the latitude and longitude coordinates). These bandwidths define nearness
to the firms in the center of the three squares. For example, firms inside the largest square (for the 50th
quantile of the distance distribution) are located in Colorado(center), Kansas, and Nebraska.

   7
       Available at www.compustat.com, accessed on August, 2012. Figure 2 excludes one firm that is located
in Singapore.




                                                     17
Table 1: Sandwich and spatial standard errors based on Hall, Griliches and Hausman (1986),
Table 6-1


                         Log R&D investment in time t
                              β̂0                   0.2468
                         sandwich s.e.            0.0786***
                          spatial s.e. 0.0946*** 0.0887***               0.0899***
                          bandwidth        10th      25th                   50th
                         Log R&D investment in time t − 1
                              β̂1                  -0.0930
                         sandwich s.e.              0.0797
                          spatial s.e.   0.0792     0.0757                 0.0774
                                              th
                          bandwidth        10        25th                   50th
                         Log R&D investment in time t − 2
                              β̂2                   0.0687
                         sandwich s.e.              0.0630
                          spatial s.e.   0.0623     0.0601                 0.0548
                          bandwidth        10th      25th                   50th
                         Log R&D investment in time t − 3
                              β̂3                  -0.0224
                         sandwich s.e.              0.0704
                          spatial s.e.   0.0648     0.0622                 0.0676
                                              th
                          bandwidth        10        25th                   50th
                              T̂          17.85      10.7                   7.34
                            Firms                     413
                            Years                      5
                         Observations                2065
Notes: Poisson Conditional Fixed-Effect Maximum Likelihood estimates of equation 6 with sandwich stan-
dard errors (equation 3) and spatial standard errors (equation 5). The estimation excludes three years of
observations to allow for three lags in Ri,t , and 47 firms without patents during the sample period. There
are four year dummies for 1976-1979. The test-statistic T̂ has an asymptotic Chi-square distribution with
36 degrees of freedom under the null hypothesis of time-invariant spatial dependence. We compute the
spatial s.e. and the test-statistic for different bandwidth choices chosen to be the different quantiles of the
distribution of distances. Significance of 1%, 5%, 10% is indicated with ***, **, * respectively.




    Table 1 reports sandwich and spatial estimates for the variance of the PCFE. The sta-
tistically insignificant value of 10.7 for the test statistic (for the 25th quantile bandwidth)
indicates that variance estimates are robust to allowing for spatial dependence. Consistent
with time-invariant spatial dependence, the difference between the sandwich estimate and


                                                      18
the spatial estimate of the standard errors is small. This result suggests that the sandwich
estimator of the standard errors is consistent. As a kernel estimator, the estimated value of
the spatial standard error depends on the researcher’s choice of a bandwidth. Table 1 reports
estimates for spatial standard errors using different choices of the bandwidth, defined by the
10th, 25th, and 50th quantile of nearness along coordinates of latitude and longitude; results
are robust to these alternative choices of the bandwidth.


5.2    Application to Furman and Stern (2011)

   Furman and Stern use citation counts to investigate whether the creation of a biologi-
cal research center (BRC), which certified and catalogued information about biomaterials,
helped to amplify the cumulative impact of scientific discoveries. In the United States,
the “American Culture Collection” (ATCC) is the largest BRC; Furman and Stern exploit
exogenous transfers of biomaterials to the ATCC to investigate whether materials in the
ATCC became more heavily cited after they became certified and catalogued by the ATCC.
Baseline specifications compare changes in citations to publications that use materials that
were transferred to the ATCC with other materials that were not transferred to the ATCC
(Furman and Stern (2011), p. 1949, specification 2):




                                 FORWARD CITATIONSi,t

      = f (εi,t ; γi + βt + δt-pubyear + ψWINDOW BRC-ARTICLE × WINDOW PERIODi,t

                         +ψ BRC-ARTICLE × POST-DEPOSITi,t )                               (7)


where :


   • FORWARD CITATIONSi,t is the number of citations to article i in year t;

   • BRC-ARTICLE × WINDOW PERIODi,t is a dummy variable that equals 1 if article

                                             19
         i is referenced by a BRC deposit and year t is equal to the year of the deposit or the
         year of the deposit plus or minus 1;8

   • BRC-ARTICLE × POST-DEPOSITi,t is a dummy variable that equals 1 if article i is
         referenced by a BRC deposit and YEAR > DEPOSIT YEAR + 1 (i.e., deposit has
         already occurred and deposit WINDOW PERIOD already passed);

   • γi denote article fixed effects;

   • βt denote year fixed effects;

   • δt-pubyear are fixed effects for the age of articles.


       Under the assumption that - without the transfers - changes in citations would have been
identical for publications about materials that were transferred and other materials that
were not transferred, the coefficient ψ measures the impact of the transfers on citations, as
a measure of knowledge flows. Using a balanced panel of 99 articles and 23 periods between
1979 and 2001, with a total of 2,277 observations, we estimate equation 7 (Table 3, column
4 in Furman and Stern (2011), p. 1948).9
       Citations to articles may, however, be affected by unobservable factors, such as scientific
breakthroughs or the invention of new research tools, which increase research productivity
across related fields. Intuitively, scientific breakthroughs are more likely to increase the
speed of innovation in fields that are more closely related to the original field in which the
breakthrough occurred than in other distant fields. Similarly, research tools, which have
been developed for a specific field may encourage cumulative innovation in related fields but
are less likely to benefit fields that are more distant in knowledge space. Results in section 3
   8
       The authors allow for a one-year window after the deposit, because the exact length of the lag between
the date of the deposit and the date when materials become accessible is unknown.
   9
     Furman and Stern (2011) estimate specification (7) using the negative binomial model for an unbalanced
panel of 216 articles and 32 periods with a total of 4,857 observations. The difference between spatial and
sandwich standard errors is also small when we estimate the Poisson model using the unbalanced panel.



                                                      20
imply that the standard sandwich estimator is consistent - even in the presence of spatial de-
pendence in idea space - as long as this dependence remains substantially unchanged during
the sample period. For example, results in section 3 imply that the standard sandwich esti-
mator is consistent - even if research output is correlated across related fields - as long as the
way in which related fields are affected by common shocks (such as scientific breakthroughs
or research tools) does not change during the sample period.


                                      Table 2: Measures of Distance

 Variable       Definition                                  Measure of Distance
 pair num       id number for treatment-control pairs       difference in id numbers
 collectn       biological material’s collection            zero if same collection
 atcccode       ATCC code and collection of material        difference in codes
 price          price of the referenced biological material difference in price
 journ abb      journal where the article was published     zero if same value
 author         article’s author                            zero if same value
 authinst       author’s institution                        zero if same value
 country        country of institution                      zero if same value
 pub year       publication year of article                 difference in years
Notes: For the qualitative variables collectn, journ abb, author, authinst, country, each distance is zero if
two different articles have the same value for the corresponding variable, or one if different values. For the
numeric variables pair num, atcccode, price, pub year, each distance is equal to the absolute value of the
difference of the corresponding variable for two different articles. This difference is normalized to be at most
one. For a given pair of articles, if a variable has a missing value, this distance is dropped from the averaging.
The variable atcccode is considered missing if two different articles are from different collections. 126 of 216
articles have missing values for at least one of the nine variables, and all of the articles have observed values
for at least five variables.




    To illustrate these results, we create a new measure of distance in idea space based on the
analysis of journal citations in Furman and Stern (2011). Specifically, we create a proxy for
distance in knowledge space based on the average distance for nine variables that Furman
and Stern (2011) use to characterize articles (Table 2). This proxy allows us to generate
coordinates, which we use to illustrate distance in knowledge space (Figure 3).



                                                       21
              Figure 3: Dispersion of papers in idea space and bandwidth choices
                                      4
                                  x 10
                             7


                            6.5


                             6


                            5.5


                             5


                            4.5


                             4


                            3.5


                             3


                            2.5


                             2
                                  0       1   2    3        4     5      6           7
                                                                                 4
                                                                              x 10

Notes: Squares with dotted lines represent three bandwidth choices (the 10th, 25th, and 50th quantile of the
distribution of the distance computed along the x and y coordinates). These bandwidths define nearness to
the article in the center of the three squares. For example, two articles in the smallest square (for the 10th
quantile of the distance distribution) share the same collection and similar publication year with the article
that is at the center of that square.



    Table 3 reports estimation results for the PCFE and its variance by the standard sandwich
estimator (equation 3) and spatial estimator that accounts for spatial dependence (equation
5). Insignificant values for the test statistic in the range of 6.68 to 25.9 (for bandwidths
between the 10th and 50th quantile) indicate that variance estimates are robust to allowing
for spatial dependence. Consistent with time-invariant spatial dependence, the difference
between the sandwich estimate and the spatial estimate of the standard errors is small.
These results suggest that the sandwich estimator of the standard error is consistent.




                                                       22
Table 3: Sandwich and spatial standard errors based on Furman and Stern (2011), Table 3-4


                            BRC-ARTICLE × WINDOW PERIOD
                              ψ̂WINDOW              0.4089
                            sandwich s.e.          0.1657**
                             spatial s.e. 0.1728** 0.1873** 0.2260*
                             bandwidth       10th     25th    50th
                            BRC-ARTICLE × POST-DEPOSIT
                                  ψ̂                0.5959
                            sandwich s.e.          0.2802**
                             spatial s.e. 0.3058* 0.3110* 0.3418*
                             bandwidth       10th     25th    50th
                                  T̂        25.9     15.37    6.68
                              Articles                96
                                Years                 23
                            Observations             2208
Notes: Poisson Conditional Fixed-Effect Maximum Likelihood estimates of equation 7 with sandwich stan-
dard errors (equation 3) and spatial standard errors (equation 5). We exclude 3 articles that do not have
any citations from the sample. There are year dummies for every year except 1979 and 1990, and 30 age
dummies. The test-statistic T̂ has an asymptotic Chi-square distribution with 45 degrees of freedom under
the null hypothesis of time-invariant spatial dependence. We use the first nine elements of the score vector
to calculate the test-statistic because it is not possible to compute the test-statistic using all elements of
the score vector due to the large number of regressors in equation 7. We compute the spatial s.e. and
the test-statistic for different bandwidth choices chosen to be the different quantiles of the distribution of
distances. Significance of 1%, 5%, 10% is indicated with ***, **, * respectively.




6     Conclusion

    Count data, such as patents, unemployed workers, or hospital visits, play an important
role in empirical analyses across a broad range of research fields. Due to its robustness to
misspecification of the Poisson distribution and to time dependence, the Poisson (PCFE)
estimator has become a standard approach to analyze count data. Count data may, however,
also be affected by cross-sectional dependence. For example, changes in patent counts for
firms that are geographically close may be correlated if they are affected by geographically
localized unobservable factors, such as knowledge spillovers or changes in the supply of inputs
and skilled workers. Similarly, changes in research output may be correlated across related


                                                     23
research fields, if they benefit from the same scientific advances.
   This paper extends the robustness properties of the PCFE to the case of spatial de-
pendence in the cross-section. We show that the asymptotic distribution of the PCFE –
derived by Wooldridge (1999) under the assumption of cross-sectional independence – is ro-
bust to cross-sectional dependence, as long as cross-sectional dependence is time-invariant.
The sandwich variance estimator is consistent if spatial dependence is time invariant. We
construct a test statistic to detect time-variant spatial dependence, and provide a spatial
variance estimator for the PCFE that is consistent under time-invariant and time-variant
spatial dependence. We provide new commands for STATA and MATLAB that compute
the sandwich and spatial variance estimates for the PCFE, as well as the test statistic. We
illustrate the revised estimates through empirical examples based on Hall, Griliches and
Hausman (1986) and Furman and Stern (2011). In these applications, the test statistic
does not indicate time-variance spatial dependence suggesting that the sandwich variance
estimator is consistent.




                                              24
References

Andersen, Erling B (1972), ‘The numerical solution of a set of conditional estimation equa-
  tions’, Journal of the Royal Statistical Society. Series B (Methodological) 34(1), 42–54.

Azoulay, Pierre, Joshua Graff Zivin and Jialan Wang (2010), ‘Superstar extinction’, The
  Quarterly Journal of Economics 125(2), 549–589.

Borjas, George J and Kirk B Doran (2012), ‘The collapse of the soviet union and the produc-
  tivity of american mathematicians’, The Quarterly Journal of Economics 127(3), 1143–
  1203.

Cameron, A. Colin and Pravin K. Trivedi (2005), Microeconometrics: Methods and Applica-
  tions, Cambridge University Press.

Conley, Timothy G. (1999), ‘Gmm estimation with cross sectional dependence’, Journal of
  Econometrics 92(1), 1–45.

Furman, Jeffrey L. and Scott Stern (2011), ‘Climbing atop the shoulders of giants:
  The impact of institutions on cumulative research’, The American Economic Review
  101(5), 1933–1963.

Gourieroux, Christian, Alain Monfort and Alain Trognon (1984), ‘Pseudo maximum likeli-
  hood methods: Theory’, Econometrica 52(3), 681–700.

Hall, Bronwyn H., Zvi Griliches and Jerry Hausman (1986), ‘Patents and r&d: Is there a
  lag?’, International Economic Review 27(2), 265–283.

Hausman, Jerry, Bronwyn H. Hall and Zvi Griliches (1981), Econometric models for count
  data with an application to the patents-r&d relationship. NBER Technical Working Paper
  No. 17.

Hausman, Jerry, Bronwyn H. Hall and Zvi Griliches (1984), ‘Econometric models for count
  data with an application to the patents-r&d relationship’, Econometrica 52(4), 909–938.

                                             25
Jaffe, Adam B., Manuel Trajtenberg and Rebecca Henderson (1993), ‘Geographic localiza-
  tion of knowledge spillovers as evidenced by patent citations’, The Quarterly Journal of
  Economics 108(3), 577–598.

Kogan, Leonid, Dimitris Papanikolaou, Amit Seru and Noah Stoffman (2012), Technological
  innovation, resource allocation, and growth. NBER working paper 17769.

Marshall, Alfred (1890), Principles of Economics, MacMillan, London.

Moser, Petra and Alessandra Voena (2012), ‘Compulsory licensing: Evidence from the trad-
  ing with the enemy act’, The American Economic Review 102(1), 396–427.

Moser, Petra, Alessandra Voena and Fabian Waldinger (2014), German-Jewish Emigres and
  U.S. Invention. Forthcoming in the American Economic Review.

Williams, Heidi L. (2013), ‘Intellectual property rights and innovation: Evidence from the
  human genome’, Journal of Political Economy 121(1), 1–27.

Wooldridge, Jeffrey M. (1999), ‘Distribution-free estimation of some nonlinear panel data
  models’, Journal of Econometrics 90(1), 77–97.




                                           26
7       Appendix

7.1       Code for Estimation

     The command ‘xtpsse’ computes the PCFE, the sandwich and spatial variance estimator,
and the test statistic for the null hypothesis of time-invariant spatial dependence. Each
cross-sectional unit in the data must have coordinate information in R2 space. The files are
available online at:

     • www.stanford.com/˜bertanha/xtpsse stata.zip;

     • www.stanford.com/˜bertanha/xtpsse matlab.zip.

Instructions on how to use the command are available in ‘xtpsse help.txt’ inside each zip
file.



7.2       Proof of Robustness to Time-invariant Spatial Dependence

          (Theorem 1)

     We first prove the equivalence between time-invariance and the existence of a different
model with fixed effects φ̃s and no spatial dependence on its unobserved shocks.

Lemma 1. The following statements are equivalent:

    (i) there exists {φ̃s }s strictly positive such that ys ⊥(ys0 , xs0 , φ̃s0 )|xs , φ̃s for every s 6= s0 and
        E[ys,t |xs , φ̃s ] = φ̃s exp(x0s,t β0 ) for every s, t

 (ii) the spatial dependence structure of εs is ‘time-invariant’.

Proof. (i) ⇒ (ii) : Make us,t = ys,t /φ̃s exp(x0s,t β0 ), ηs = φ̃s /φs , and c = 1.
     Note that us,t = φs εs,t /φ̃s which leads to εs,t = ηs us,t . By assumption, ys ⊥(ys0 , xs0 , φ̃s0 )|xs , φ̃s
makes us ⊥(us0 , xs0 , ηs0 φs0 )|xs , φs ηs for ∀s 6= s0 . Also, the assumption that E[ys,t |xs , φ̃s ] =
φ̃s exp(x0s,t β0 ) makes E[us,t |xs , φs ηs ] = c = 1.

                                                         27
    (i) ⇐ (ii) : Make φ̃s = φs ηs c. We have ys,t = φs exp(x0s,t β0 )εs,t = φs ηs c exp(x0s,t β0 )us,t /c.
The assumption that E[us,t |xs , φs ηs ] = c makes E[ys,t |xs , φ̃s ] = φ̃s exp(x0s,t β0 ). Also, the
assumption that us ⊥(us0 , xs0 , φs0 ηs0 )|xs , φs ηs makes ys ⊥(ys0 , xs0 , φ̃s0 )|xs , φ̃s for ∀s 6= s0 .

    Now we show for every s 6= s0 that,


                             ys ⊥(ys0 , xs0 , φ̃s0 )|xs , φ̃s ⇒ ys ⊥ys0 |xs , φ̃s , xs0 , φ̃s0                (8)


    Let the vector Ws = (xs , φes ), and denote W and Y denote measurable events for Ws and
ys respectively.

                                                P (ys ∈ Y, ys0 ∈ Y 0 , Ws0 ∈ W 0 |Ws ∈ W)
      P (ys ∈ Y, ys0 ∈ Y 0 |Ws ∈ W, Ws0 ∈ W 0 ) =
                                                         P (Ws0 ∈ W 0 |Ws ∈ W)
                       P (ys ∈ Y|Ws ∈ W) P (ys0 ∈ Y , Ws0 ∈ W 0 |Ws ∈ W)
                                                     0
                    =
                                    P (Ws0 ∈ W 0 |Ws ∈ W)
                  P (ys ∈ Y|Ws ∈ W, Ws0 ∈ W 0 ) P (ys0 ∈ Y 0 , Ws0 ∈ W 0 |Ws ∈ W)
                =
                                    P (Ws0 ∈ W 0 |Ws ∈ W)
                = P (ys ∈ Y|Ws ∈ W, Ws0 ∈ W 0 ) P (ys0 ∈ Y 0 |Ws ∈ W, Ws0 ∈ W 0 , )


    Define zs,t,q = xs,t −xs,q . Following Hausman, Hall and Griliches (1981), the score function
can be written as:

                                              T         PT             0
                                              X            q=1   exp(−zs,t,q β)zs,t,q
                                 Ss (β) =           ys,t PT               0
                                              t=1             u=1   exp(−zs,t,u β)

                                                    = S(ys , xs , β)                                          (9)


    Now, we use Lemma 1, result (8) and equation (9) to prove that COV [Ss (β0 ), Ss0 (β0 )] = 0
for every s 6= s0 . If the conditional mean is correctly specified (eq. 2 holds), then E[Ss (β0 )] =
EE[Ss (β0 )|xs , φ̃s ] = 0, and we can write the covariance between the score function of two
different individuals as:




                                                           28
                                COV [Ss (β0 ), Ss0 (β0 )] = E [Ss (β0 )Ss0 (β0 )0 ]
                                        h                                        i
                                 = E E Ss (β0 ), Ss0 (β0 ) xs , φ̃s , xs0 , φ̃s0




                            h                                                         i
                 = E E S(ys , xs , β0 )S(ys0 , xs0 , β0 )0 | xs , φ̃s , xs0 , φ̃s0
             n h                                       i h                                            i o
          = E E S(ys , xs , β0 )| xs , φ̃s , xs0 , φ̃s0 E S(ys0 , xs0 , β0 )0 | xs , φ̃s , xs0 , φ̃s0




                          n h                           i h                               i o
                    =E      E S(ys , xs , β0 )| xs , φ̃s E S(ys0 , xs0 , β0 )| xs0 , φ̃s0
                             n h                      i h                    i o
                         = E E Ss (β0 )| xs , φ̃s E Ss0 (β0 )| xs0 , φ̃s0           =0


   Therefore, COV [Ss (β0 ), Ss0 (β0 )] = 0 for every s 6= s0 , which implies COV [Yp (β0 ), Yq (β0 )] =
0 for every p 6= q, and that C0 = B0 under spatial dependence. Using this in (4) gives
√          
               d
  N βb − β0 → N 0, A−1         −1
                                  
                         0 B0 A0    , and the sandwich estimator given in equation 3 is con-
sistent for the variance of the PCFE.
   It is useful for the proof of Theorem 2 to show that E[∇β 0 Ss (β0 )Ss0 (β0 )] = 0 for every
s 6= s0 holds under time-invariance. The expression for ∇β 0 Ss (β) is:



                                                                  T
                                                                  X
                                                ∇β 0 Ss (β) =           ys,t
                                                                  t=1
                                      P                                P                                0 
                      1                   T           0                        T           0
                                   2      q=1   exp(−zs,t,q β)zs,t,q           q=1   exp(−zs,t,q β)zs,t,q
            ( Tq=1 exp(−zs,t,q
                         0     β))
             P
                                                                                                             
                                                       PT                                                    
                                          1                          0               0
                              − PT     exp(−z 0          q=1   exp(−zs,t,q β)zs,t,q zs,t,q
                                   q=1       s,t,q β)


                                                   = H(ys , xs , β)


                                                             29
   Using the same results that led to E[Ss (β0 )Ss0 (β0 )0 ] = 0, we have that:




                       E[∇β 0 Ss (β0 )Ss0 (β0 )] = E[H(ys , xs , β0 )S(ys0 , xs0 , β0 )]

                           = EE[H(ys , xs , β0 )S(ys0 , xs0 , β0 )|xs , φes , xs0 , φes0 ]
                n                                                                                       o
             = E E[H(ys , xs , β0 )|xs , φes , xs0 , φes0 ] E[S(ys0 , xs0 , β0 )|xs , φes , xs0 , φes0 ]
                      n                                                           o
                  = E E[H(ys , xs , β0 )|xs , φes ] E[Ss0 (β0 )|xs0 , φes0 ] = 0



7.3    Proof of Identification: E[Ss (β)] = 0 ⇐⇒ β = β0

   We refer to Conley (1999) for the complete set of assumptions behind his results of
consistency and normality of β̂, and consistency of Ĉ. In this section, we demonstrate that
using the PCFE score function as a moment condition satisfies the identification assumption
in Conley (1999). It is straightforward to verify that this moment condition also satisfies his
other assumptions under standard regularity conditions.


Lemma 2. E [Ss (β)] = 0 ⇔ β = β0 , where β0 ∈ int (B) with B ⊆ RK compact.

Proof. Correct specification of the conditional mean, E [yst |xs , φs ] = φs exp (x0st β0 ), plus
uniqueness of a global maximum leads to this result. Hausman, Hall and Griliches (1981)
show global concavity of this log-likelihood function. We use the same arguments to show
global concavity of the expected value of the log-likelihood function and that β0 is the unique
zero of E [Ss (β)] = 0. The conditional expectation of the log-likelihood is:

                                               T
                                                                                                 !
                                               X                              exp(x0st β)
                   E[`s (β)|φs , xs ] = φs            exp(x0st β0 ) log   PT
                                               t=1                           q=1   exp(x0sq β)
                                     T                          T
                                                                                                 !
                                     X                          X
                           = −φs           exp(x0st β0 ) log           exp(−(xst − xsq )0 β)
                                     t=1                         q=1
                                               T                           T
                                                                                                 !
                                               X                           X
                                      = −φs           exp(x0st β0 ) log                0
                                                                                 exp(−zstq β)
                                                t=1                        s=1


                                                          30
where zstq = xst − xsq . Looking at the first and second derivatives:

                                                T                                     T
                ∂                         X      exp(x0st β0 )      X
                                                                              0
                  E[`s (β)|φs , xs ] = φs     PT             0
                                                                        exp(−zstq β)zstq
               ∂β                         t=1  q=1 exp(−z    stq β) q=1
                                                                  T
                              ∂2                                X
                                    E[`s (β)|φ s , x s ] =  φ s       exp(x0st β0 )
                             ∂β∂β 0                              t=1
                                P                               P                          0 
                       1             T               0                   T          0
                          0 β) 2     q=1  exp(−z    stq  β)z stq         q=1 exp(−z stq β)zstq
            (PTq=1 exp(−zstq )                                                                   
                                                                                                 
                                     1
                                               P    T               0           0
                            − PT exp(−z   0 β)      q=1   exp(−z    stq β)z   z
                                                                           stq stq
                                  q=1           stq




   In order to see that this second derivative is negative definite, for any given s, t, and
                                  0
                                         hPT            0
                                                              i
β, call vq = zstq and aq = exp(−zstq β) /     j=1 exp(−zstj β) . Note that aq ∈ (0, 1) and
PT
  q=1 aq = 1. Rewriting the term in square brackets above gives:


                                  T
                                                !     T
                                                                    !0       T
                                  X                   X                      X
                                        aq vq               aq vq        −         aq vq vq0
                                  q=1                 q=1                    q=1
                                    T
                                    X
                              =−           aq [vq − (Σaq vq )] [vq − (Σaq vq )]0
                                     q=1


which is simply the negative weighted sample variance of vq . This is negative definite be-
cause xs ’s are not constant across time which makes the vq vary across q. Therefore, since
φs exp(x0st β0 ) > 0, we conclude that the second derivative is negative definite, i.e. the func-
tion is strictly concave. This is true for any (xs , φs ), so it is true for the unconditional
expectation of the log-likelihood.
   Given that the domain B is compact, there is a unique maximum and critical point. If
the conditional mean is correctly specified, β0 makes the expected value of the score function




                                                            31
zero:


                  E [Ss (β) |xs , φs ] = ∇β p (xs , β)0 W (xs ; β) E [us (β) |xs , φs ]

                                                  where

                  E [ust (β) |xs , φs ] = E [yst |xs , φs ] − E [pt (xs , β) ns |xs , φs ]
                                                                      T
                                                     exp (x0st β0 )   X
                    =   φs exp (x0st β0 )   − φ s PT         0
                                                                          exp (x0sk β0 )
                                                   k=1 exp (xsk β) k=1
                                                 "          PT                #
                                                         exp (x0sk β0 )
                            = φs exp (x0st β0 ) 1 − Pk=1
                                                     T           0
                                                     k=1 exp (xsk β)


   If β = β0 , then E [us (β0 ) |xs , φs ] = 0, which implies that E [Ss (β0 )] = 0 using iterated
expectations.




7.4     Proof of the Asymptotic Distribution of the Test Statistic

        (Theorem 2)
                                                                    −1 P
  First, consider the unfeasible estimator Θ e = P Zp (β0 )Zp (β0 )0
                                                    p                     p Zp (β0 )Yp (β0 ),

where we use the following notation: p = (m, n), p = m,n , K ∗ = K(K + 1)/2, and:
                                                P   P


                                                   n          oK
                                                       (1:k)
                                Zp (β)K ∗ ×K = diag Ȳp,l (β)
                                                                       k=1



                                            h                             i0
                                 (1:k)          (1)                (k)
                              Ȳp,l (β)k×1 = Ȳp,l (β), · · · , Ȳp,l (β)


   For a fixed choice of spatial lags l = (l1 , l2 ), the set N (p, l) is non-random and remains
fixed as the sample size increases. Using the GMM framework of Conley (1999), we can find




                                                       32
the asymptotic distribution of Θ
                               e under the null hypothesis of time-invariance:


                        √
                                     e−1 √1                    d
                                            X
                  f −1/2 N Θ
                  W           f −1/2 Γ
                           e =W               Zp (β0 )Yp (β0 ) → N (0; IK ∗ )                            (10)
                                          N p

where


                                          W           e−1 Ω
                                          fK ∗ ×K ∗ = Γ   eΓe−1
                                                      LD1 −1        LD2 −1
                                                 1     X             X
                                  Ω
                                  e K ∗ ×K ∗   =
                                                 N   j=−LD1 +1    k=−LD2 +1
        D1
        X              D2
                       X
                                  KD1 ,D2 (j, k) Zm,n (β0 )Ym,n (β0 )Ym+j,n+k (β0 )0 Zm+j,n+k (β0 )0
                                                                                                    
         m=1             n=1
    st 1≤m+j≤D1     st 1≤n+k≤D2

                                  eK ∗ ×K ∗ = − 1
                                                       X
                                  Γ                         Zp (β0 )Zp (β0 )0
                                               N        p



   Our goal is to use (10) to show asymptotic normality of the feasible estimator Θ:
                                                                                  b


                        √
                                     b−1 √1                  d
                                            X
                  c −1/2 N Θ
                  W           c −1/2 Γ
                           b =W               Zp (β̂)Yp (β̂) → N (0; IK ∗ )
                                          N p

                                                                               p
where Γ
      b and W                                                              b−Γ
            c have been defined in the main text. It suffices to show that Γ e → 0,
         p                                                     p
           0, and N −1/2
 b −Ωe →                 P
 Ω                         p Zp (β̂)Yp (β̂) − Zp (β0 )Yp (β0 ) → 0.



   Step 1: Under the null hypothesis of time-invariance, the proof of Theorem 1 shows that




                                                      33
 h                   i
       (i)     (j)
E ∇β Yp (β0 )Yq (β0 ) = 0 for every p 6= q and i, j ∈ {1, . . . , K}. Hence,

                                                 h n                   oi
                                                        (i)
                                                E ∇β Ȳp,l Yp(j) (β0 )
                                                                                                          
                          X              (i)
                                                                                           X          (i)
       = E Nl−1                    ∇β Yq,l (β0 )Yp(j) (β0 ) + E ∇β Yp(j) (β0 )Nl−1               Yq,l (β0 )
                       q∈N (p,l)                                                        q∈N (p,l)
                      X          h                        i       X  h                        i
                                       (i)                                            (i)
        = Nl−1                  E ∇β Yq,l (β0 )Yp(j) (β0 ) + Nl−1   E ∇β Yp(j) (β0 )Yq,l (β0 )
                    q∈N (p,l)                                         q∈N (p,l)

                                                            =0

                      n              o
           −1
                P         (i) (j)
   and N          p ∇β Ȳp,l Yp (β0 )  = op (1). We can show that the same is true when we
                           p
replace β0 with β ∗ → β0 . Assuming bounded moments of the data, and using the facts
that Yp (β) has smooth derivatives, and that β ∗ belongs to a compact set with probability
approaching one, we arrive at:



                                        1 X   n
                                                  (i) (j) ∗
                                                            o
                                            ∇β Ȳp,l Yp (β )  = op (1)                                            (11)
                                        N p

                                        1 X   n
                                                  (i) (j)
                                                                 o
                                            ∇β Ȳp,l Ȳp,l (β ∗ )  = op (1)                                       (12)
                                        N p


   Similarly, we have that for any i0 , i1 , j0 , j1 ∈ {1, . . . , K}:



                                     LD1 −1        LD2 −1        D1               D2
                                1      X            X            X                X
                                N   j=−LD1 +1    k=−LD2 +1        m=1             n=1
                                                             st 1≤m+j≤D1     st 1≤n+k≤D2
                                 n                                             o
                                     (i0 )   (i1 ) (j1 )      (j0 )
                KD1 ,D2 (j, k) ∇β Ȳ(m,n),l Ym,n  Ym+j,n+k Ȳ(m+j,n+k),l (β ∗ )  = Op (1)                         (13)



                     p
   Step 2:       b−Γ
                 Γ e → 0

   Let (i, j) denote an arbitrary element of the K ∗ × K ∗ matrix Γ. Let i0 and j0 index the

                                                            34
elements in Ȳp,l that are used to compute Γi,j . Using (12) we can show that:




                          ei,j = 1
                                   X (i )        (j )          (i )       (j )
                   bi,j − Γ
                   Γ                 Ȳ 0 (β̂)Ȳp,l0 (β̂) − Ȳp,l0 (β̃)Ȳp,l0 (β0 )
                                 N p p,l

                                          1 X   n
                                                    (i0 ) (j0 ) ∗
                                                                  o
                             ≤ kβ̂ − β0 k     ∇β Ȳp,l Ȳp,l (β )
                                          N p

                                        = op (1)op (1) = op (1).



                p
           b −Ω
   Step 3: Ω  e → 0

   Let (i, j) denote an arbitrary element of the K ∗ × K ∗ matrix Ω. Let i0 and i1 index the
elements in Ȳp,l , and j0 and j1 index the elements in Yp that are used to compute Ωi,j . Using
(13) we can show that:




                                              b i,j − Ω
                                              Ω       e i,j
                                                   LD1 −1         LD2 −1
                                              1     X              X
                                 ≤ kβ̂ − β0 k
                                              N   j=−LD1 +1   k=−LD2 +1
         D1
         X              D2
                        X                          n                                           o
                                                       (i0 )   (i1 ) (j1 )     (j0 )        ∗
                                  KD1 ,D2 (j, k) ∇β Ȳ(m,n),l Ym,n Ym+j,n+k Ȳ(m+j,n+k),l (β )
          m=1            n=1
     st 1≤m+j≤D1    st 1≤n+k≤D2

                                        = op (1)Op (1) = op (1).



                                                              p
   Step 4: N −1/2
                     P
                        p   Zp (β̂)Yp (β̂) − Zp (β0 )Yp (β0 ) → 0

   Let i denote an arbitrary element of the K ∗ × 1 vector Zp Yp . Let i0 index the element in
Ȳp,l , and i1 index the element in Yp that are used to compute {Zp Yp }i . Using (11), we can
show that:



                                                   35
                                Xn                                 o
                     N −1/2       Zp (β̂)Yp (β̂) − Zp (β0 )Yp (β0 )
                                                                                    i
                                    p

                              X           (i )                       (i )
                 = N −1/2               Ȳp,l0 (β̂)Yp(i1 ) (β̂) − Ȳp,l0 (β0 )Yp(i1 ) (β0 )
                                p

                        √                        1 X   n
                                                           (i )
                                                                             o
                    ≤       N kβ̂ − β0 k             ∇β Ȳp,l0 Yp(i1 ) (β ∗ )
                                                 N p

                                         = Op (1)op (1) = op (1)

                 √    d                                    d
           c −1/2 N Θ
Therefore, W        b→                           b 0W
                        N (0; IK ∗ ), and Tb = N Θ  c −1 Θ
                                                         b→  χ2K ∗ .




                                                      36
