                                NBER WORKING PAPER SERIES




      LINEAR-QUADRATIC APPROXIMATION OF OPTIMAL POLICY PROBLEMS

                                         Pierpaolo Benigno
                                         Michael Woodford

                                        Working Paper 12672
                                http://www.nber.org/papers/w12672


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                    November 2006




An earlier version of this paper was presented as a Plenary Lecture at the 10th Annual Conference
on Computing in Economics and Finance, Amsterdam, July 2004. We would like to thank Filippo
Altissimo, Vasco Curdia, Wouter Den Haan, Ken Judd, Jinill Kim, Andy Levin, Paul Levine, Diego
Rodriguez Palenzuela, and Joseph Pearlman for comments, and the National Science Foundation for
research support through a grant to the NBER. The views expressed herein are those of the author(s)
and do not necessarily reflect the views of the National Bureau of Economic Research.

© 2006 by Pierpaolo Benigno and Michael Woodford. All rights reserved. Short sections of text, not
to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.
Linear-Quadratic Approximation of Optimal Policy Problems
Pierpaolo Benigno and Michael Woodford
NBER Working Paper No. 12672
November 2006, Revised August 2008
JEL No. C61,C63

                                              ABSTRACT

We consider a general class of nonlinear optimal policy problems involving forward-looking constraints
(such as the Euler equations that are typically present as structural equations in DSGE models), and
show that it is possible, under regularity conditions that are straightforward to check, to derive a problem
with linear constraints and a quadratic objective that approximates the exact problem. The LQ approximate
problem is computationally simple to solve, even in the case of moderately large state spaces and flexibly
parameterized disturbance processes, and its solution represents a local linear approximation to the
optimal policy for the exact model in the case that stochastic disturbances are small enough. We derive
the second-order conditions that must be satisfied in order for the LQ problem to have a solution, and
show that these are stronger, in general, than those required for LQ problems without forward-looking
constraints. We also show how the same linear approximations to the model structural equations and
quadratic approximation to the exact welfare measure can be used to correctly rank alternative simple
policy rules, again in the case of small enough shocks.


Pierpaolo Benigno
Dipartimento di Scienze Economiche e Aziendali
Luiss Guido Carli
Viale Romania 32
00197 Rome - Italy
and NBER
pbenigno@luiss.it

Michael Woodford
Department of Economics
Columbia University
420 W. 118th Street
New York, NY 10027
and NBER
michael.woodford@columbia.edu
    Linear-quadratic (LQ) optimal-control problems have been the subject of an ex-
tensive literature.1 General characterizations of their solutions and useful numerical
algorithms to compute them are now available, allowing models with fairly large state
spaces, complicated dynamic linkages, and a range of alternative informational as-
sumptions to be handled.2 And the extension of the classic results of the engineering
control literature to the case of forward-looking systems of the kind that naturally
arise in economic policy problems when one allows for rational expectations on the
part of the private sector has proven to be fairly straightforward.3
    An important question, however, is whether optimal policy problems of economic
interest should take this convenient form. It is easy enough to apply LQ methodology
if one specifies an ad hoc quadratic loss function on the basis of informal consider-
ation of the kinds of instability in the economy that one would like to reduce, and
posits linear structural relations that capture certain features of economic time series
without requiring these relations to have explicit choice-theoretic foundations, as in
early applications to problems of monetary policy.4 But it is highly unlikely that the
analysis of optimal policy in a DSGE model will involve either an exactly quadratic
utility function or exactly linear constraints.
    We shall nonetheless argue that LQ problems can usefully be employed as ap-
proximations to exact optimal policy problems in a fairly broad range of cases. Since
an LQ problem necessarily leads to an optimal decision rule that is linear, the most
that one could hope to obtain with any generality would be for the solution to the
LQ problem to represent a local linear approximation to the actual optimal policy
— that is, a first-order Taylor approximation to the true, nonlinear optimal policy
rule. In this paper we present conditions under which this will be the case, and show
how to derive an LQ approximate problem corresponding to any member of a general
class of optimal policy problems.
    The conditions under which the solution to an LQ approximate problem will yield
a correct local linear approximation to optimal policy are in fact more restrictive
  1
     Important references include Bertsekas (1976), Chow (1975), Hansen and Sargent (2004),
Kendrick (1981), Kwakernaak and Sivan (1972), and Sargent (1987). See Kendrick (2005) for an
overview of the use of LQ methods in economics.
   2
     For numerical algorithms see, among others, Amman (1996), Anderson et al. (1996), Amman
and Kendrick (1999), Diaz-Gimenez (1999), Gerali and Lippi (2005), Hansen and Sargent (2004),
and Söderlind (1999).
   3
     See, e.g., Backus and Driffill (1986) for a useful review.
   4
     Notable examples include Kalchbrenner and Tinsley (1975) and Leroy and Waud (1977).



                                            1
than might be expected, as noted for example by Judd (1996, pp. 536-539; 1998,
pp. 507-508). In particular, it does not suffice that the objective and constraints of
the exact problem be continuously differentiable a sufficient number of times, that
the solution to the LQ approximate problem imply a stationary evolution of the
endogenous variables, and that the exogenous disturbances be small enough (though
each of these conditions is obviously necessary, except in highly special cases). An
approach that simply computes a second-order Taylor-series approximation to the
utility function and a first-order Taylor-series approximation to the model structural
relations in order to define an approximate LQ problem — the approach criticized
by Judd (1996, 1998) that we have elsewhere (Benigno and Woodford, 2006a) called
“naive LQ approximation” — may yield a linear policy rule with coefficients very
different from those of a correct linear approximation to the optimal policy in the
case of small enough disturbances.5
    The discussion by Judd (1996, pp. 536-539) might seem to imply that LQ ap-
proximation is an inherently mistaken idea — that it cannot be expected, other than
in cases so special as to represent an essentially fortuitous result, to yield a correct
approximation to optimal policy at all. Nonetheless, it is quite generally possible to
construct an alternative quadratic objective function that will result in a correct local
LQ approximation, in the sense that the linear solution to the LQ problem is a correct
linear approximation to the solution to the exact problem. The correct method was
illustrated in the important paper of Magill (1977), that applied results of Fleming
(1971) from the optimal-control literature to derive a local LQ approximation to a
continuous-time multi-sector optimal growth model. Here we show how the method
of Magill can be used in the context of discrete-time dynamic optimization problems
where some of the structural relations are forward-looking, as is almost inevitably the
case in optimal monetary or fiscal policy problems.6
    Of course the problems that can arise as a result of “naive” LQ optimization
can also be avoided through the use of alternative perturbation techniques, as ex-
plained by Judd. Approaches that are widely used in the recent literature on policy
   5
     For an example illustrating this possibility, see Benigno and Woodford (2006a). The same
problem can also result in incorrect welfare rankings of alternative simple policies, as discussed by
Kim and Kim (2003, 2006).
   6
     See also Levine et al. (2007) for another application to a discrete-time problem, and additional
discussion of how our method relates to that of Magill.



                                                2
analysis in DSGE models include either (i) deriving the first-order conditions that
characterize optimal (Ramsey) policy using the exact (nonlinear) objective and con-
straints, and then log-linearizing these conditions in order to obtain an approximate
solution to them, rather than separately approximating the objective and constraints
before deriving the first-order conditions;7 or (ii) obtaining a higher-order (at least
second-order) perturbation solution for the equilibrium implied by a given policy by
solving a higher-order approximation to the constraints, and then evaluating welfare
under the policy using this approximate solution.8 These methods can also be used
to correctly calculate a linear approximation to the optimal policy rule, and when
applied to the problem considered here, provide alternative approaches to calculating
the same solution.9
    Despite the existence of these alternative perturbation approaches to the analysis
of optimal policy, we believe that it remains useful to show how a correct form of
LQ analysis is possible in the case of a fairly general class of problems. One reason
is that the ability to translate a policy problem into this form allows one to use
the extensive body of theoretical analysis and numerical techniques that have been
developed for LQ problems. Another is that casting optimal policy analysis in DSGE
models in this form can allow comparisons between welfare-based policy analysis and
analyses of optimal policy based on ad hoc stabilization objectives (which have often
been expressed as LQ problems). We also show that the LQ formulation of the
approximate policy problem makes it straightforward to analyze whether a solution
to first-order conditions for optimal policy also satisfies the relevant second-order
conditions for optimality, and to rank suboptimal policy rules by a criterion that is
consistent with the characterization given of optimal policy.
    We first explain the essential problem with naive LQ optimization in section 1,
in the context of a simple, finite-dimensional example, and also use this example to
   7
     Recent applications of this method to problems of optimal monetary and fiscal policy include
King and Wolman (1999), Khan et al. (2003) and Schmitt-Grohé and Uribe (2004b).
   8
     For discussions of methods for executing computations of this kind in general classes of forward-
looking equation systems see, among others, Jin and Judd (2002), Kim et al. (2003), and Schmitt-
Grohé and Uribe (2004a). These methods have been used in many recent numerical analyses of
optimal policy (e.g., Schmitt-Grohé and Uribe, 2007).
   9
     As shown in section 2.3 below, our method computes the same coefficients for a linear policy
rule as are obtained by linearization of the first-order conditions for the exact policy problem. The
general intuition for this result is discussed in section 1.



                                                3
explain why the approach used by Magill (1977) avoids the problem. In section 2,
we present a general class of dynamic optimization problems with forward-looking
constraints, and derive an LQ approximate problem associated with any problem in
this class. Section 3 discusses the general algebraic form of the first- and second-
order conditions for optimality in the LQ approximate problem. Section 4 shows
how the quadratic objective for stabilization policy derived in section 2 can also be
used to compute welfare comparisons between alternative sub-optimal policies, in the
case that the stochastic disturbances are small enough. Finally, section 5 discusses
applications of the method described here and concludes.


1     Naive and Correct LQ Approximations
Here we review the reason why naive LQ approximation is generally incorrect, as
noted by Judd (1996, 1998), in the context of a simple static optimization problem
that allows us to the explain the issues in terms of simple multivariate calculus.
We then illustrate how Magill’s (1977) approach solves the problem, in the context of
this static example, before turning in the next section to the additional complications
raised by dynamic problems.


1.1    A Static Example
Suppose that we wish to find the policy y(ξ) that maximizes an objective U (y; ξ),
where y is an n-vector of endogenous variables and ξ is a vector of exogenous distur-
bances; we assume that U is at least twice continuously differentiable with respect
to the arguments y. Suppose furthermore that the possible outcomes y that can be
achieved by policy in any state of the world ξ are those values consistent with the
structural equations
                                    F (y; ξ) = 0,                               (1.1)
where F is a vector of m functions (for some m < n), again each at least twice
continuously differentiable. We assume that m < n so that there is at least one
direction in which it is possible for the outcome y to be varied by policy. We might
suppose that y is determined by equations (1.1) together with an additional set of
n − m equations of the form
                                      G(y; i, ξ) = 0,                           (1.2)

                                         4
where i is a vector of n − m instrument settings (or control variables); but the nature
of the additional equations (1.2) does not matter for our conclusions below, as long
as the derivative matrices        "      #
                                    Dy F
                                           ,     Di G
                                    Dy G
are of full rank when the partial derivatives are evaluated at the point around which
we conduct our local analysis. We shall suppose that there exists a solution y opt (ξ)
to this problem for all ξ in some neighborhood of 0 (the case of “zero disturbances”).
     Now let ȳ be the outcome under an optimal policy in the case that ξ = 0; that
is, it maximizes U (y; 0) subject to the constraints F (y; 0) = 0.10 We wish to obtain
a local linear approximation to the function y opt (ξ) for values of ξ near enough to 0.
In the case that y opt (ξ) is differentiable at ξ = 0, such a linear approximation exists,
with coefficients of the linear rule given by the derivatives of y opt , since by Taylor’s
theorem,
                             y opt (ξ) = ȳ + Dy opt · ξ + O(||ξ||2 ),               (1.3)
where the partial derivatives are evaluated at ξ = 0.
    In many problems, differentiability can be established, and the derivatives (and
hence the coefficients of the linear approximation) calculated, using the implicit func-
tion theorem. We can write a Lagrangian for this problem

                               L(y; ξ; λ) ≡ U (y; ξ) + λ0 F (y; ξ)                            (1.4)

where λ is an m−vector of multipliers associated with the constraints (1.1); there must
exist a vector of multipliers for which the optimal policy minimizes the Lagrangian
for each possible value of ξ. It follows that the optimal policy y opt (ξ) must satisfy the
(exact, nonlinear) first-order conditions obtained by differentiating the Lagrangian,

                                Dy U (y; ξ) + λ0 Dy F (y; ξ) = 0,                             (1.5)

in addition to the structural relations. The system consisting of (1.1) together with
(1.5) is then a system of n + m nonlinear equations implicitly defining functions y(ξ)
and λ(ξ). A correct local approximation to the solution to these equations can be
  10
     Note that we must compute our local approximations to the objective and constraints around
this optimal point if there is to be any hope that consideration of these local approximations alone
can correctly identify the optimal policy rule even in the case that ξ is small.


                                               5
obtained (under the regularity condition stated below) by linearizing equations (1.1)
and (1.5) around the unperturbed solution y(0) = ȳ, λ(0) = λ̄, and solving these
linear equations for y and λ as linear functions of ξ.
    In this method, we replace the exact constraints (1.1) by their linearized form,

                                      Dy F · ỹ + Dξ F · ξ = 0,                                   (1.6)

where we use the notation ỹ ≡ y − ȳ, and partial derivatives are evaluated at ȳ.
Similarly, the linearization of the first-order conditions (1.5) is given by
                                        0       X
             ỹ 0 Dyy
                   2
                      U + ξ 0 Dξy
                               2
                                  U + λ̃ Dy F +   λ̄k [ỹ 0 Dyy
                                                             2
                                                                F k + ξ 0 Dξy
                                                                           2
                                                                              F k ] = 0, (1.7)
                                                     k


where λ̃ ≡ λ − λ̄, and k indexes the m individual constraints F k . The linear system
consisting of (1.6)–(1.7) has a unique solution if and only if
                          "         P                      #
                              2             2
                            Dyy U + k λ̄k Dyy F k (Dy F )0
                      det                                      6= 0.             (1.8)
                                    Dy F              0

This is also precisely the regularity condition under which the implicit function theo-
rem guarantees that there exists a differentiable solution y(ξ) to the system consisting
of (1.1) and (1.5), for values of ξ in a neighborhood of 0. Moreover, a local linear
approximation of the form (1.3) exists, equal precisely to the solution to the linear
system (1.6)–(1.7).
    We wish to compare this correct linear approximation with the linear solution
to an LQ optimization problem obtained by approximating the objective U and the
constraints (1.1). In the case of any policy y(ξ) such that ỹ = O(||ξ||),11 a second-
order Taylor series expansion of U yields
                                                     1
          U (y; ξ) = Ū + Dy U · ỹ + Dξ U · ξ + ỹ 0 Dyy    2
                                                               U · ỹ +
                                                     2
                     1 0 2
                       ξ Dξξ U · ξ + ỹ 0 Dyξ
                                           2
                                              U · ξ + O(||ξ||3 )
                     2
                                 1
                   = Dy U · ỹ + ỹ 0 Dyy2
                                           U · ỹ + ỹ 0 Dyξ
                                                          2
                                                             U · ξ + t.i.p. + O(||ξ||3 ),         (1.9)
                                 2
  11
      Note that in the case that (1.8) holds and a local characterization of optimal policy can be given
using the implicit function theorem, as discussed in the previous paragraph, the optimal policy
y opt (ξ) has this property. More generally, in our discussion below of the use of local approximations
to rank alternative policies, we shall restrict attention to policies with this property.

                                                 6
where the various matrices of partial derivatives are each evaluated at (ȳ; 0). The
expression “t.i.p.” refers to terms that are independent of the policy chosen (such as
the constant term and terms that depend only on the exogenous disturbances); the
form of these terms is irrelevant in obtaining a correct ranking of alternative policies.
   A naive LQ approximation of this problem can then be obtained by replacing the
exact objective U (y; ξ) by the quadratic objective
                                            1
                    U Q (y; ξ) ≡ Dy U · ỹ + ỹ 0 Dyy
                                                   2
                                                      U · ỹ + ỹ 0 Dyξ
                                                                     2
                                                                        U · ξ,      (1.10)
                                            2
and replacing the exact constraints (1.1) by their linearized form (1.6). We wish to
consider whether the policy that maximizes U Q (y; ξ) subject to the constraints (1.6)
represents a correct local linear approximation to the true optimal policy of the form
(1.3).
    In general, it does not. The policy that maximizes the naive quadratic objective
(1.10) subject to the linearized constraints (1.6) satisfies linear first-order conditions
                            Dy U + ỹ 0 Dyy
                                         2
                                            U + ξ 0 Dξy
                                                     2
                                                        U + λ0 Dy F = 0.                          (1.11)
The naive LQ-optimal policy is then obtained by solving the system of equations
consisting of (1.6) and (1.11) for y and λ as linear functions of ξ. Because the two
final terms on the left-hand side of (1.7) are missing in (1.11), the naive method will
generally yield incorrect coefficients for the linear policy rule.
    The fact that LQ analysis using the quadratic objective (1.10) yields an incorrect
linear approximation to optimal policy is related to the fact that a linear approxi-
mation to the equilibrium outcome under a given policy rule does not suffice for a
correct welfare ranking of alternative policies, even to second order. In the case of any
(sufficiently differentiable) policy y(ξ) that is optimal in the absence of disturbances
(i.e., when ξ = 0), a local linear approximation is given by12
                                        y L (ξ) ≡ ȳ + Dξ y · ξ.
But substituting y L (ξ) into U Q to obtain a quadratic function of ξ but does not in
general result in an approximation to U that is accurate to second order; instead,
                                      X
     U (y(ξ); ξ) = U Q (y L (ξ); ξ) +   Dj U [ξ 0 Dξξ
                                                   2 j
                                                      y · ξ] + t.i.p. + O(||ξ||3 ). (1.12)
                                            j

  12
    This linear approximation is the one that is given by solution of the linearized structural relations
(1.6) using a similar linear approximation to the policy rule, in the case in which these linear relations
have a determinate solution, again as a consequence of the implicit function theorem.

                                                  7
Here the second term on the right-hand side indicates omitted (policy-dependent)
second-order terms in a correct approximation to U that result from second-order
dependence of the equilibrium outcome y on the state ξ, omitted as a result of the
linearization of y(ξ). Such terms generally exist if the gradient of the welfare criterion
Dy U is non-zero when evaluated at the unperturbed optimal policy.13
     Both this problem and the incorrect outcome of LQ optimization can be solved,
however, by using an alternative quadratic approximation to U . In order to obtain
correct welfare rankings of alternative policies, it suffices that a quadratic function
U ∗ (y; ξ) be such that
                              U (y; ξ) = U ∗ (y; ξ) + O(||ξ||3 )                    (1.13)
in the case of any y(ξ) satisfying (1.1) and such that ỹ = O(||ξ||). If we find an alter-
native objective U ∗ that is also purely quadratic, in the sense of containing no linear
terms (Dy U ∗ = 0), then welfare can be evaluated to second order by Û (y L (ξ); ξ);14
and the error in LQ approximation of the optimal policy rule is eliminated as well.
This is why the approach of Magill (1977) yields a correct LQ approximation.
    In fact, an objective U ∗ of this form can quite generally be found. The key is to
use a second-order Taylor series approximation to the constraints (1.1) to replace the
linear terms in (1.9) with purely quadratic terms.15 A second-order approximation
to the structural relations (1.1), of the same form as the approximation (1.9), implies
that
                             1
              Dy F k · ỹ = − ỹ 0 Dyy
                                    2
                                       F k · ỹ − ỹ 0 Dyξ
                                                        2
                                                           F k · ξ + t.i.p. + O(||ξ||3 )
                             2
in the case of any (y; ξ) satisfying (1.1). The fact that ȳ is an optimal policy when
the disturbances are zero implies that
                                                       0
                                         Dy U = −λ̄ Dy F,                                       (1.14)
  13
     See Woodford (2002; 2003, sec. 6.1) and Sutherland (2002) for further discussion.
  14
     While this method (like the approach of simply computing a second-order approximation to y(ξ)
and substituting this into objective) relies upon computing a second-order approximation to the
model structural relations, the second-order approximation need be used only once, in determining
the coefficients of the quadratic objective U ∗ , rather than having to be used again each time one
seeks to evaluate the welfare associated with yet another candidate policy.
  15
     A similar method is used by Sutherland (2002) to compute correct second-order approximations
to welfare under alternative policies. However, his second-order approximation is computed for a
particular parametric class of policies, while we derive a quadratic loss function that yields a correct
welfare measure for any feasible policy.


                                                 8
where λ̄ is a vector of Lagrange multipliers associated with the constraints (1.1) in
the case of zero disturbances. It then follows that
                       X
      Dy U · ỹ = −       λ̄k Dy F k · ỹ
                            k
                      1X                          X
                    =     λ̄k ỹ 0 Dyy
                                    2
                                       F k · ỹ +   λ̄k ỹ 0 Dyξ
                                                              2
                                                                 F k · ξ + t.i.p. + O(||ξ||3 ).
                      2 k                         k

       We can then use this expression to substitute for the term Dy U · ỹ in (1.9), yielding
                   1 0 2
  U (y; ξ) =        ỹ [D U
                   2 X yy                                  X
                              2
                   +     λ̄k Dyy F k ] · ỹ + ỹ 0 [Dyξ
                                                     2
                                                        U+        2
                                                             λ̄k Dyξ F k ] · ξ + t.i.p. + O(||ξ||3 ).
                       k                                   k

This is an approximation of the form (1.13), where
                1             X                                   X
    U ∗ (y; ξ) ≡ ỹ 0 [Dyy
                        2
                           U+        2
                                λ̄k Dyy F k ] · ỹ + ỹ 0 [Dyξ
                                                            2
                                                               U+        2
                                                                    λ̄k Dyξ F k ] · ξ.            (1.15)
                2             k                                   k

    Use of the corrected quadratic objective (1.15) solves the problems associated
with the use of U Q discussed above. In particular, the LQ problem of maximizing
(1.15) subject to the linearized constraints (1.6) satisfies linear first-order conditions
of precisely the form (1.7). Hence this linear policy represents a correct linear approx-
imation to the optimal policy y opt (ξ). There is a simple reason for this; in the case
of any functions y(ξ), λ(ξ) such that ỹ, λ̃ are both of order O(||ξ||),16 a second-order
Taylor expansion of the Lagrangian (1.4) takes the form
                                       0
           L(y; ξ; λ) = U ∗ (y; ξ) + λ̃ [Dy F · ỹ + Dξ F · ξ] + t.i.p. + O(||ξ||3 ).             (1.16)

But this is just the Lagrangian for the correct LQ problem, and the first-order con-
ditions obtained by differentiating this approximate Lagrangian (which is the La-
grangian of the proposed approximate policy problem) agree, to first order, with
those obtained by differentiating the exact Lagrangian.
    The objective (1.15) can also be used to correctly rank alternative policies (none
of which need be fully optimal), as long as these policies imply that y(0) = ȳ. 17
  16
     Again, the implicit function theorem implies that in the case that (1.8) is satisfied, the functions
y(ξ), λ(ξ) that solve the exact Lagrangian problem have this property.
  17
     Kim and Kim (2006) illustrate how the method expounded here can be used, for example, to
correctly rank alternative policies with regard to international risk-sharing, in an example where
naive LQ analysis sometimes gives an incorrect ranking.

                                                  9
One can easily verify that in the case of any feasible differentiable policy with this
property,
                     U (y; ξ) = U ∗ (y L (ξ); ξ) + t.i.p. + O(||ξ||3 ),
where y L (ξ) is the linear approximation to the policy in question. Hence using this
criterion, welfare can be correctly evaluated to second order, using only a linear
approximation to equilibrium outcomes under the policy in question; the problem
resulting from “naive” linearization discussed by Kim and Kim (2003, 2006) is thus
avoided.


1.2     Special Cases
While “naive” LQ optimization yields an incorrect linear approximation to optimal
policy in general, as discussed above, it is an adequate approach under certain more
restrictive conditions. This means that it is possible to use the simpler approach
when it is used with sufficient care, as has often been the case in the literature.
Our exposition above also makes clear in which cases a “naive” LQ approximation is
possible. These are cases in which the additional terms present in (1.7) but not in
(1.11) necessarily vanish.
    One such case is when the constraints (1.1) are all exactly linear, in which case the
second derivatives of the functions F k vanish.18 Sometimes it is possible to arrange for
a problem to have constraints of this form, through some combination of restrictive
specification of one’s model and careful choice of the variables in terms of which the
problem is written, as in Kydland and Prescott (1982).19 But while ingenuity can
extend the range of applicability of naive LQ optimization, the class of models that
can be put in this form is likely to be fairly restrictive.
    Another such case is when the unperturbed optimum ȳ is also an unconstrained
optimum in the case of zero disturbances, so that the multipliers λ̄ vanish, even
though the constraints bind in general (and the associated Lagrange multipliers are
  18
      The importance of this condition for application of LQ approximation is stressed by Diaz-
Jimenez (1999).
   19
      Kydland and Prescott eliminate one nonlinear constraint by combining the production function
with the utility function of the representative household, to obtain an objective written as a function
of the paths of hours, capital and investment spending. The only remaining constraint is then a
linear relation between investment spending and the dynamics of the capital stock; the linearity of
this relation depends on their omission of an convex adjustment costs for the capital stock.


                                                10
non-zero) in the presence of small disturbances ξ.20 Again, sometimes it is possible
to arrange for a problem to have this form, through some combination of restrictive
model specification and an appropriate change of variables, as in Rotemberg and
Woodford (1997).21 But once again, the class of cases to which this result can be
applied are likely to be quite restrictive. And in any event, as Judd (1996) stresses,
it is undesirable for one’s computational approach to yield correct answers only when
the problem is expressed in terms of one set of variables rather than another. The
approach described in section 1.1 eliminates the need for restrictions of the kind
discussed in this section.


1.3     LQ Approximation in Models with Uncertainty
In the simple static example presented above, we have supposed that the value of
the complete vector of disturbances ξ is known before any policy decisions must be
made, and before any of the endogenous variables are determined; there is therefore
no issue of policy choice under uncertainty. However, similar reasoning applies in the
case of choice under uncertainty. Here we illustrate this through a reinterpretation
of the analysis presented above.
    Consider a problem in which there are two periods, and at least one dimension
of policy must be decided in period 1, while at least one dimension of uncertainty
about the exogenous disturbances is resolved only in period 2. Suppose that there
are k possible states (s = 1, 2, ..., k) in period 2, each with some probability π(s) of
occurring. The aim of policy is to maximize expected welfare
                                                 X
                  E[Û (y1 , y2 ; ξ 1 , ξ 2 )] ≡   π(s)Û (y1 , y2 (s); ξ 1 , ξ 2 (s)), (1.17)
                                               s

  20
      The importance of this condition for application of LQ approximation is stressed by Woodford
(2002).
   21
      Rotemberg and Woodford write their welfare objective in terms of the paths of sectoral output
levels, rather than the consumption or hours worked by households, by substituting the production
function and market-clearing condition into the objective. They then consider a model in which the
steady-state path for output represents an optimal allocation of resources, because the stickiness of
prices does not affect the equilibrium allocation of resources in the steady state. But the optimality
of the steady-state allocation depends both on restriction of attention to policy rules consistent with
zero steady-state inflation, and an assumption that subsidies offset the steady-state distortions that
would otherwise result from firms’ market power. The present method allows LQ approximation to
be applied without these restrictive assumptions, as shown in Benigno and Woodford (2005a)

                                                11
where Û is a smooth function of the n1 endogenous variables y1 that are determined
in period 1, the n2 endogenous variables y2 that are determined in period 2, as well
as the exogenous disturbances ξ 1 that are realized in period 1 and the exogenous
disturbances ξ 2 that are realized in period 2. The possible equilibrium outcomes that
can be achieved by policy are those consistent with the m1 structural equations

                                     E[fˆ1 (y1 , y2 ; ξ 1 , ξ 2 )] = 0,                       (1.18)

where each of the elements of fˆ1 is a smooth function of the same arguments as Û ,
and with the m2 structural equations

                                       fˆ2 (y1 , y2 ; ξ 1 , ξ 2 ) = 0,                        (1.19)

each of which must hold exactly, regardless of the state s that occurs in period 2.22
Equations (1.18), together with policy decisions in period 1, determine the endogenous
variables y1 ;23 we suppose that m1 < n1 , so that there is at least one dimension along
which policy can vary in period 1. Equations (1.19), together with policy decisions
in period 2 (if any) and the variables determined in period 1, then determine the
endogenous variables y2 in whichever state s happens to be realized; we suppose that
m2 ≤ n2 .
    Under regularity conditions of the same kind as are needed in the static case,
the method presented above can be used to derive a valid LQ approximation to this
kind of policy problem as well. In fact, the calculations presented in section 1.1 are
directly applicable. The right-hand side of (1.17) defines an objective U (y; ξ), where
the vectors y and ξ now specify all possible realizations of the random variables:
                                                             
                                y1                         ξ1
                                                             
                             y2 (1)                  ξ 2 (1) 
                            
                        y ≡  . ,              ξ≡ . 
                                                      
                                 .                              .
                             .                       .. 
                                  y2 (k)                                  ξ 2 (k)
The left-hand side of (1.18) can similarly be written as a vector of m1 functions of the
vectors y and ξ, while for each possible state s, the left-hand side of (1.19) is a vector
  22
     On the left-hand side of (1.17) and in equation (1.18), y2 and ξ 2 are random variables, whereas
in (1.19) these symbols refer to the values of those variables that are realized in period 2.
  23
     Note that these structural relations need not all involve expectations; we allow for the case in
which some elements of fˆ1 may not depend on either y2 or ξ 2 . The important feature of the relations
(1.18) is that they involve only information available in period 1.

                                                  12
of m2 functions of the vectors y and ξ.24 Hence the complete system of structural
relations, for both periods and for all possible states in period 2, can be written as a
system of the form (1.1), where now F is a vector of m = m1 + k · m2 functions of y
and ξ. (Under the assumptions made in the previous paragraph, m < n, as assumed
in section 1.1, where n = n1 + k · n2 is the length of the vector y.)
     If Û , fˆ1 , and fˆ2 are continuously differentiable functions (of whatever order) of
                          0
ŷ 0 ≡ (y1 , y2 )0 and ξ̂ ≡ (ξ 1 , ξ 2 )0 , then it follows that U and F will be correspond-
ingly differentiable functions of y and ξ. The results of section 1.1 are then directly
applicable. In the case that the implicit function theorem can be applied to derive
a local linear approximation to optimal policy,25 that correct linear approximation
corresponds to the linear policy that solves an LQ optimization problem.
     In the case that the uncertainty is small — i.e., in each state s, ξ 2 (s) is close to the
same value ξ̄ 2 (which we may denote as zero, without loss of generality) — there is
additional structure that we can exploit in writing the approximate LQ problem. Let
us suppose not only that this is true (i.e., that the unperturbed problem corresponds
to ξ = 0 in all elements), but also that the solution to the unperturbed problem is
  24
      Of course, these latter functions depend on only a subset of the elements of y and ξ, namely,
those corresponding to y1 , y2 (s), ξ 1 , and ξ 2 (s), where s is the particular state for which the structural
relations are written.
   25
      Here by “linear approximation” we mean that y opt (ξ) is approximated by a linear function of
ξ, which differs from the exact function by a residual that is at most of order O(||ξ||2 ), as in (1.3).
Note that this is a different sense than the one proposed by Judd (1996) for stochastic models. Judd
considers a perturbation of a dynamic optimization problem under certainty by varying a factor
that scales the amplitude of a mean-zero random disturbance to fundamentals; the disturbance is
                √
multiplied by ², so that the variance of the disturbance is proportional to ². Judd considers a
“linear approximation” to be a perturbation of the (deterministic) solution for the ² = 0 case that
includes all terms linear in ², including any non-zero derivatives of the average values of endogenous
variables with respect to the variance of the disturbance; as a consequence, Judd refers to the
approximation obtained by linearizing the first-order conditions for optimality as “at most a half-
                                                                                               √
linear approximation” (1996, p. 538). In the present approach, if we write ξ 2 (s) = ²ξ̄ 2 (s), where
                                                         √                                  √
the random variable ξ̄ 2 remains fixed as we vary ², then only terms of order O( ²) are considered
to be of “first order” (i.e., of order O(||ξ||)); terms linear in ², such as the terms indicating how the
average values of variables vary linearly with the variance of the disturbances, are treated as part
of the residual of order O(||ξ||2 ). Of course, this is in no way intended to deny that it may be of
interest to calculate such effects; however, in the case of small enough random disturbances (i.e., a
                        √
small enough value of ²), these effects should be small relative to the ones taken account of in the
linear approximation derived here.



                                                    13
deterministic (i.e., y2 (s) = ȳ2 for all s as well).26 In this case, the solution ȳ to the
unperturbed problem must correspond to the solution (ȳ1 , ȳ2 ) to the deterministic
problem
                            max Û (ŷ; 0)     s.t. F̂ (ŷ; 0) = 0,
                                         ŷ

where F̂ is the vector of n1 + n2 functions fˆ1 and fˆ2 . This latter solution must satisfy
first-order conditions of the form
                                                                   0
                                                    Dŷ Û = −λ̂ Dŷ F̂ ,                                          (1.20)

where all derivatives are evaluated at (ȳ1 , ȳ2 ; 0, 0). It follows that the solution to the
unperturbed problem (in which y2 is however allowed to be state-dependent) satisfies
first-order conditions of the form (1.14), in which the vector of Lagrange multipliers
is given by
                                0     0         0                 0
                              λ̄ = [λ̂1 , π(1)λ̂2 , . . . , π(k)λ̂2 ].
   Because the steady-state vector of Lagrange multipliers takes this form (and the
functions U and F are additively separable across states), the Lagrangean for the
stochastic policy problem can be written in the form
                                                                       0
                                              L = E[Û (ŷ; ξ̂) + λ̂ F̂ (ŷ; ξ̂)],

in the case in which the multipliers λ are set equal to λ̄. It follows that the correct
quadratic objective (1.15) for the LQ approximation is of the form

                                                 U ∗ (y; ξ) = E[Û ∗ (ŷ; ξ̂)],

where
                      1                  X                                             X
       Û ∗ (ŷ; ξ̂) ≡ ŷ˜0 [Dŷ2ŷ Û +   λ̂k Dŷ2ŷ F̂ k ] · ŷ˜ + ŷ˜0 [Dŷ2ξ̂ Û +   λ̂k Dŷ2ξ̂ F̂ k ] · ξ̂,   (1.21)
                      2                  k                                             k


and ŷ˜ denotes the difference between ŷ and the unperturbed optimal values. Note that
(1.21) is just the quadratic objective for the LQ approximation to the deterministic
  26
    This latter property necessarily follows from the assumption that ξ is deterministic in the case of
a strictly convex problem, but the implication need not follow for all problems of the more general
sort that we consider here, so an additional assumption is required. In section 3, we show how
to check whether the deterministic optimal steady state is indeed at least a local optimum of the
stochastic problem as well.

                                                            14
problem of maximizing Û (ŷ; ξ̂) subject to the constraints F̂ (ŷ; ξ̂) = 0, derived using
the method of section 1.1.
    So the correct quadratic objective for the LQ approximation of the stochastic
problem is just the expected value of the quadratic objective for the corresponding
deterministic problem. Similarly, the local linear approximation to the constraints
(1.18) is of the form

                         Φ1 ỹ1 + Φ2 E[ỹ2 ] + Ψ1 ξ 1 + Ψ2 E[ξ 2 ] = 0,             (1.22)

where the matrices of coefficients are the same as in the deterministic model, while
the local linear approximation to constraints (1.19) is of exactly the same form as
in the deterministic model. Thus all coefficients of both the quadratic objective and
the linear constraints are the same as in the LQ approximation to the deterministic
problem (and represent partial derivatives of the functions Û and F̂ , evaluated at the
optimum of the deterministic problem when ξ̂ = 0); the only difference in the form of
the two LQ problems is the fact that expected values are taken in (1.21) and (1.22).
    As is well known, the solution to a stochastic LQ problem of this kind exhibits the
property of certainty equivalence. In particular, the linear approximation to y opt (ξ)
is of the form

                                y1 = M ξ 1 + N E[ξ 2 ],
                                y2 = P y1 + Qξ 1 + Rξ 2 ,

where the matrices of coefficients are the same as in the linear approximation to
ŷ opt (ξ̂) in the corresponding deterministic (perfect foresight) problem,

                                y1 = M ξ 1 + N ξ 2 ,
                                y2 = P y1 + Qξ 1 + Rξ 2 .

Of course, this does not mean that the exact solution for optimal policy in the presence
of uncertainty generally possesses the property of certainty equivalence. However, de-
partures from certainty equivalence (for example, effects of a mean-preserving change
in the variance of ξ 2 on the optimal choice of y1 ) represent contributions to y opt (ξ)
that are at most of order O(||ξ||2 ).




                                            15
1.4     Qualifications
While the conditions under which a valid LQ approximation is possible are fairly
general, several qualifications are in order. First of all, the LQ approximation, when
valid, is purely local in character; it can only provide an approximate characterization
of optimal policy to the extent that disturbances are sufficiently small. Whether the
disturbances are small enough for this to be a useful approximation will depend upon
the application; and a judgment about how accurate the approximation is likely to
be is not possible on the basis of the coefficients of the LQ approximate problem
alone. And like all perturbation approaches, it depends on sufficient differentiability
of the problem;27 it cannot be applied, for example, to problems in which there are
inequality contraints that sometimes bind but at other times do not. Moreover, the
LQ approximation provides at best a linear approximation to optimal policy. More
general perturbation methods28 can instead be used to compute approximations of any
desired order, assuming sufficient differentiability of the objective and constraints. In
this respect, LQ approximation is hardly a substitute for an understanding of general
perturbation calculations, as stressed by Judd (1996).
    Second, a correct LQ approximation yields a correct linear approximation to the
optimal policy in the case that linearization of the first-order conditions (1.5) would
also yield a system of linear equations that can be solved to obtain a linear approxi-
mation to optimal policy. If the regularity condition (1.8) fails, the implicit function
theorem cannot be applied to obtain a linear approximation in this way, and the
LQ approach similarly fails to provide a correct linear approximation to optimal pol-
icy. This is a problem that can certainly arise in cases of economic interest, such as
the portfolio problem treated by Judd and Guu (2001), and more complex pertur-
bation methods (used to deal with singular perturbations) can still be employed in
  27
      Whether the objective and constraints are sufficiently differentiable in a given application may
depend on the choice of variables in terms of which one writes these functions. Kim et al. (2007)
provide an example of an optimal stabilization policy problem in which the first-order conditions
describing optimal policy cannot be linearized — so that the LQ methodology expounded here
would also not be applicable — when the state variables are assumed to include the square root of
a measure of price dispersion, rather than the measure of price dispersion itself. Linearization is
instead possible under the alternative choice of variables.
   28
      A generally useful approach to obtaining a higher-order Taylor series approximation to y opt (ξ)
is to solve a higher-order Taylor series approximation to the first-order conditions (1.5), using the
approach explained by Judd (1996, 1998).


                                               16
such cases, as Judd and Guu show. But it is a problem the existence of which can
be diagnosed within the LQ analysis itself: for when the condition (1.8) fails, the
first-order conditions of the LQ problem fail to determine a unique solution. Thus it
remains true that if the LQ analysis determines a unique linear policy, this will be
a correct linear approximation to optimal policy. But when the LQ analysis implies
that optimal policy is indeterminate, this need not be a correct conclusion; there
may instead be a unique optimal policy, a correct linear approximation to which de-
pends on higher-order derivatives than those considered in the LQ approximation.
An identical caveat applies to the method of linearization of the first-order conditions
characterizing optimal policy.
    Third, a correct LQ approximation yields a correct linear approximation to the
optimal policy only in the case that the perturbed solution to the first-order conditions
(1.5) characterized by the implicit function theorem is in fact an optimum. It cannot
be taken as obvious that the first-order conditions suffice for optimality, since in
applications of interest, the structural relations (1.1) often define a non-convex set.
The question of convexity can be addressed at least locally by evaluating the relevant
second-order conditions corresponding to a given solution to the first-order conditions.
This is straightforward within the LQ analysis itself: one simply needs to verify the
concavity of the quadratic objective U ∗ in ỹ, for vectors ỹ in the linear subspace such
that Dy F · ỹ = 0. This is an algebraic property of the coefficients of the LQ problem,
involving the signs of certain principal minors of the matrix appearing in (1.8), as
shown by Debreu (1952).29 But of course, verification of the second-order conditions
for optimality still only guarantees that the solution to the LQ problem approximates
a local welfare optimum. The question of global optimality of the solution cannot be
treated using purely local methods, and is often quite difficult in dynamic stochastic
models.
    We turn now to the additional complications that arise in applying this method to
dynamic, stochastic policy problems. Foremost among these complications are ones
that result from the presence of forward-looking constraints, indicating the way in
which equilibrium determination is affected by forward-looking optimizing decisions
on the part of the public.
 29
      We discuss the generalization of this characterization to the dynamic case in section 3.




                                                 17
2      LQ Approximation of a Problem with Forward-
       Looking Constraints
We wish to consider an abstract discrete-time dynamic optimal policy problem of the
following sort.30 Suppose that the policy authority wishes to determine the evolution
of an (endogenous) state vector {yt } for t ≥ t0 to maximize an objective of the form
                                             ∞
                                             X
                                 Vt0 ≡ Et0          β t−t0 π(yt , ξ t ),                    (2.1)
                                             t=t0


where 0 < β < 1 is a discount factor, the period objective π(y, ξ) is a concave function
of y, and ξ t is a vector of exogenous disturbances. The evolution of the endogenous
states must satisfy a system of backward-looking structural relations

                                       F (yt, ξ t ; yt−1 ) = 0                              (2.2)

and a system of forward-looking structural relations

                                     Et g(yt , ξ t ; yt+1 ) = 0,                            (2.3)

that both must hold for each t ≥ t0 , given the vector of initial conditions yt0 −1 .
    Conditions of the form (2.2) allow current endogenous variables to depend on
lagged states; for example, these relations could include a technological relation be-
tween the capital stock carried into the next period, current investment expenditure,
and the capital stock carried into the current period.31 Conditions of the form (2.3)
instead allow current endogenous variables to depend on current expectations regard-
ing future states; for example, these relations could include an Euler equation for the
optimal timing of consumer expenditure, relating current consumption to expected
consumption in the next period and the expected rate of return on saving.32 While
the most general notation would allow both leads and lags in all of the structural
  30
     Applications of the framework proposed here are discussed in section 5.
  31
     The next period’s capital stock and the current investment expenditure would both be elements
of yt ; the vector ξ t could include a random disturbance to investment adjustment costs.
  32
     Current consumption and the current period ex-post return on saving in the previous period
would both be elements of yt ; the vector ξ t could include a random disturbance to the impatience
to consume. Note that without loss of generality we may suppose that the vector ξ t includes all
information available in period t regarding future exogenous disturbances.


                                               18
equations, supposing that there are equations of these two types will make clearer
the different types of complications arising from the two distinct types of intertempo-
ral linkages. We shall suppose that the number nF of constraints of the first type each
period plus the number ng of constraints of the second type is less than the number
ny of endogenous state variables each period, so that there is at least one dimension
along which policy can continuously vary the outcome yt each period, given the past
and expected future evolution of the endogenous variables. A t0 −optimal commit-
ment (the standard Ramsey policy problem) is then the state-contingent evolution
{yt } consistent with equations (2.2)–(2.3) for all t ≥ t0 that maximizes (2.1).


2.1     A Recursive Policy Problem
As is well-known, the presence of the forward-looking constraints (2.3) implies that
a t0 −optimal commitment is not generally time-consistent. If, however, we suppose
that a policy to apply from period t0 onward must be chosen subject to an additional
set of constraints on the acceptable values of yt0 , it is possible for the resulting policy
problem to have a recursive structure.33 While this is not necessary for the method
of LQ approximation to be applicable,34 it is necessary in order for both our approx-
imate quadratic objective and approximate linear constraints to involve coefficients
that are time-invariant, and correspondingly for our derived linear approximation to
optimal policy to involve time-invariant coefficients. In the case of the unconstrained
(Ramsey) optimal policy problem, the t0 -optimal policy generally does not imply con-
stant values of the endogenous variables, even when there are no random disturbances
and the functions π, F and g are all time-invariant, as assumed above; correspond-
  33
     The fact that a recursive structure can be restored, allowing dynamic-programming methods to
be employed, through a suitable modification of the assumed objective and/or constraints has been
known since the seminal work of Kydland and Prescott (1980). Marcet and Marimon (1998) provide
a detailed analysis of an approach that modifies the policy objective by adding additional multiplier
terms; the additional terms in the objective of the modified problem of Marcet and Marimon lead to
the same additional terms in the Lagrangian for the policy problem as the additional constraints that
we introduce here. We prefer to introduce initial pre-commitments because of the more transparent
connection of the modified problem to the original policy problem under this exposition. The first-
order conditions for optimal policy in the recursive policy problem that we propose are the same as
those derived by Marcet and Marimon, except in the initial period.
  34
     This is illustrated by the treatment of a simple example with forward-looking constraints in
section 1.3 above.


                                               19
ingly, a local approximation to Ramsey policy in the case of small disturbances must
involve derivatives evaluated along this non-constant path, so that the coefficients
of the linear approximation are generally time-varying. The case considered here is
clearly more convenient computationally, and it is arguable that the solution to this
kind of problem represents a more appealing policy commitment as well.35
    As discussed in Benigno and Woodford (2003, 2005a), in order to obtain a problem
with a recursive structure (the solution to which can be described by a time-invariant
policy rule), we must choose initial pre-commitments regarding yt0 that are self-
consistent, in the sense that the policy that is chosen subject to these constraints
would also satisfy constraints of exactly the same form in all later periods as well.
The required initial pre-commitments are of the form

                                    g(yt0 −1 , ξ t0 −1 ; yt0 ) = ḡt0 ,                        (2.4)

where ḡt0 may depend on the exogenous state at date t0 . Note that we assume the
existence of a pre-commitment only about those aspects of yt0 the anticipation of
which back in period t0 − 1 should have been relevant to equilibrium determination
then; there is no need for any stronger form of commitment in order to render optimal
policy time-consistent.
    We are thus interested in characterizing the state-contingent policy {yt } for t ≥ t0
that maximizes (2.1) subject to constraints (2.2) – (2.4). Such a policy is optimal from
a timeless perspective if ḡt0 is chosen, as a function of predetermined or exogenous
states at t0 , according to a self-consistent rule.36 This means that the initial pre-
commitment is determined by past conditions through a function

                                       ḡt0 = ḡ(ξ t0 , yt0 −1 ),                              (2.5)

where yt is an extended state vector;37 this function has the property that under
optimal policy, given this initial pre-commitment, the state-contingent evolution of
the economy will satisfy

                                 g(yt−1 , ξ t−1 ; yt ) = ḡ(ξ t , yt−1 )                       (2.6)
  35
     See Giannoni and Woodford (2002) and Woodford (2003, chap. 7) for further discussion.
  36
     See Giannoni and Woodford (2002), Woodford (2003, chap. 7), or Benigno and Woodford
(2005a) for further discussion.
  37
     The extended state vector may include both endogenous and exogenous variables, the values of
which are realized in period t or earlier. More specific assumptions about the nature of the extended
state vector are made below; see the discussion of equation (2.8).

                                                 20
in each possible state of the world at each date t ≥ t0 as well. Thus the initial
constraint is of a form that one would optimally commit oneself to satisfy at all
(subsequent) dates.
    Let V (ḡt0 ; yt0 −1 , ξ t0 , ξ t0 −1 ) be the maximum achievable value of the objective (2.1)
in this problem.38 Then the infinite-horizon problem just defined is equivalent to a
sequence of one-period decision problems in which, in each period t ≥ t0 , a value of
yt is chosen and state-contingent one-period-ahead pre-commitments ḡt+1 (ξ t+1 ) (for
each of the possible states ξ t+1 in the following period) are chosen so as to maximize

                              π(yt , ξ t ) + βEt V (ḡt+1 ; yt , ξ t+1 , ξ t ),               (2.7)

subject to the constraints
                                         F (yt, ξ t ; yt−1 ) = 0,
                                       g(yt−1 , ξ t−1 ; yt ) = ḡt ,
                                              Et ḡt+1 = 0,
given the values of ḡt , yt−1 , ξ t−1 , and ξ t , all of which are predetermined and/or exoge-
nous in period t. It is this recursive policy problem that we wish to study; note that
it is only when we consider this problem (as opposed to the unconstrained Ramsey
problem) that it is possible, in general, to obtain a deterministic steady state as an
optimum in the case of suitable initial conditions, and hence only in this case that we
can hope to approximate the optimal policy problem around such a steady state.39
    The solution to the recursive policy problem just defined involves values for the
endogenous variables yt given by a policy function of the form

                                    yt = y ∗ (ḡt , yt−1 , ξ t , ξ t−1 ),
  38
     We assume, to economize on notation, that the exogenous state vector ξ t evolves in accor-
dance with a Markov process. Hence ξ t summarizes not only all of the disturbances that affect the
structural relations at date t, but all information at date t about the subsequent evolution of the
exogenous disturbances. This is important in order for a time-invariant value function to exist with
the arguments indicated.
  39
     In the literature on Ramsey policy, one sometimes sees approximate characterizations of optimal
policy computed by log-linearizing around a steady state that Ramsey policy approaches asymptot-
ically in the absence of random disturbances. But in such a case, there is no guarantee that the
approximate characterization would be accurate even in the case of arbitrarily small disturbances,
as Ramsey policy need not be near the steady state except asymptotically.


                                                  21
and a choice of the following period’s pre-commitment ḡt+1 of the form

                                       ḡt+1 = g ∗ (ξ t+1 ; ḡt , yt−1 , ξ t , ξ t−1 ),

where y ∗ and g ∗ are time-invariant functions. Let us suppose furthermore that the
evolution of the extended state vector depends only on the evolution of the two vectors
{yt , ξ t }, through a recursion of the form

                                                yt = ψ(ξ t , yt , yt−1 );                                              (2.8)

this system of identities defines the extended state vector, the elements of which
consist essentially of linear combinations of current and lagged elements of the vectors
yt and ξ t . (To simplify notation, we shall suppose that the current values yt and ξ t are
among the elements of yt .) The initial pre-commitment (2.5) is then self-consistent if

    g ∗ (ξ t+1 ; ḡ(ξ t , yt−1 ), yt−1 , ξ t , ξ t−1 ) = ḡ(ξ t+1 , ψ(ξ t , y ∗ (ḡt , yt−1 , ξ t , ξ t−1 ), yt−1 ))   (2.9)

for all possible values of ξ t+1 , ξ t , and yt−1 .40 Note that this implies that equation
(2.6) is satisfied at all times.


2.2      A Correct LQ Local Approximation
We now derive a corresponding LQ problem using local approximations to both the
objective and the constraints of the above problem. In order for these local approxi-
mations to involve coefficients that remain the same over time, we compute them near
the special case of an optimal policy that involves values of the state variables that
are constant over time. This special case involves both zero disturbances and suitably
chosen initial conditions; we then seek to approximately characterize optimal policy
for nearby problems in which the disturbances are small and the initial conditions
are close to satisfying the assumed special conditions. To be precise, we assume both
an initial state yt0 −1 and initial pre-commitments ḡt0 such that the optimal policy
in the case of zero disturbances is a steady state, i.e., such that yt = ȳ for all t, for
some vector ȳ. (Our subsequent calculations then assume that both yt0 −1 and ḡt0 −1
are close enough to being consistent with this steady state.) In order to define the
  40
    Both sides of this equation involve only the elements of ξ t+1 , ξ t , and yt−1 , on the understanding
that yt−1 and ξ t−1 are both elements of yt−1 .


                                                           22
steady state, we must consider the nature of optimal policy in the exact problem just
defined.
    The first-order conditions for the exact policy problem can obtained by differen-
tiating a Lagrangian of the form
                             ∞
                             X             £                                                           ¤
         Lt0 = Vt0 + Et0             β t−t0 λ0t F (yt , ξ t ; yt−1 ) + β −1 ϕ0t−1 g(yt−1 , ξ t−1 ; yt ) ,   (2.10)
                              t=t0

where λt and ϕt are Lagrange multipliers associated with constraints (2.2) and (2.3)
respectively, for any date t ≥ t0 , and we use the notation β −1 ϕt0 −1 for the Lagrange
multiplier associated with the additional constraint (2.4). This last notational choice
allows the first-order conditions to be expressed in the same way for all periods.
Optimality requires that the joint evolution of the processes {yt , ξ t , λt , ϕt } satisfy

         Dy π(yt , ξ t ) + λt 0 Dy F (yt , ξ t ; yt−1 ) + βEt λt+1 0 Dy̌ F (yt+1 , ξ t+1 ; yt )
                       +Et ϕt 0 Dy g(yt , ξ t ; yt+1 ) + β −1 ϕt−1 0 Dŷ g(yt−1 , ξ t−1 ; yt ) = 0          (2.11)

at each date t ≥ t0 , where Dy denotes the vector of partial derivatives of any of the
functions with respect to the elements of yt , while Dŷ means the vector of partial
derivatives with respect to the elements of yt+1 and Dy̌ means the vector of partial
derivatives with respect to the elements of yt−1 .
    An optimal steady state is then described by a collection of vectors (ȳ, λ̄, ϕ̄) sat-
isfying
                                            0                        0
                       Dy π(ȳ, 0) + λ̄ Dy F (ȳ, 0; ȳ) + β λ̄ Dy̌ F (ȳ, 0; ȳ)
                                      +ϕ̄0 Dy g(ȳ, 0; ȳ) + β −1 ϕ̄0 Dŷ g(ȳ, 0; ȳ) = 0,                 (2.12)

                                                   F (ȳ, 0; ȳ) = 0,                                       (2.13)
                                                    g(ȳ, 0; ȳ) = 0.                                       (2.14)
We shall suppose that such a steady state exists, and assume (in the policy problem
with random disturbances) an initial state yt0 −1 near ȳ — more precisely, such that
yt0 −1 − ȳ = O(||ξ||) — and an initial pre-commitment such that ḡt0 = O(||ξ||) as
well.41 Once the optimal steady state has been computed, we make no further use
of conditions (2.11); our proposed method does not require that we directly seek to
solve these equations.
  41
       Note that the steady-state value of ḡ is equal to g(ȳ, 0; ȳ) = 0.

                                                          23
   Instead, we now consider local approximations to the objective and constraints
near an optimal steady state. We can compute a second-order Taylor expansion of
the period objective function π, obtaining an expression of exactly the form (1.9).
Substituting this into (2.1), we obtain the approximate objective
             ∞
             X                 ·                                                 ¸
                        t−t0                   1 0 2
 Vt0 = Et0          β              Dy π · ỹt + ỹt Dyy π · ỹt + ỹt Dyξ π · ξ t + t.i.p. + O(||ξ||3 ). (2.15)
                                                                    0 2

             t=t0
                                               2

This would be used as the quadratic objective in what we have called the “naive” LQ
approximation.
    However, (2.15) is not the only valid quadratic approximation to (2.1). Taylor’s
theorem implies that it is the only quadratic function that correctly approximates
(2.1) in the case of arbitrary (small enough) variations in the state variables, but
there are others that will also correctly approximate (2.1) in the case of variations
that are consistent with the structural relations. We can obtain an infinite number
of alternative quadratic welfare measures by adding to (2.15) arbitrary multiples of
quadratic (Taylor series) approximations to functions that must equal zero in order
for the structural relations to be satisfied. Among these, we are able to find a welfare
measure that is purely quadratic, i.e., that contains no non-zero linear terms, as in
Benigno and Woodford (2003), so that a linear approximation to the equilibrium
evolution of the endogenous variables under a given policy rule suffices to allow the
welfare measure to be evaluated to second order. The key to this is using a second-
order approximation to the structural relations to substitute purely quadratic terms
for the linear terms Dy π · ỹt in the sum (2.15), as in Sutherland (2002).
    A similar second-order Taylor series approximation can be written for each of the




                                                         24
functions F k . It follows that
∞
X                                         ∞
                                          X            n
           t−t0 0                                         0
       β      λ̄ F (yt , ξ t ; yt−1 ) =          β t−t0 λ̄ [Dy F · ỹt + Dy̌ F · ỹt−1 ]
t=t0                                      t=t0
                                                  ·
                                             1 0 2 k
                                          +λ̄kỹ D F · ỹt + ỹt0 Dyξ2
                                                                       F k · ξ t + ỹt−1
                                                                                     0    2
                                                                                         Dy̌ξ F k · ξt
                                             2 t yy
                                                                                   ¸¾
                                        1 0       2   k           0 2     k
                                      + ỹt−1 Dy̌y̌ F · ỹt−1 + ỹt Dyy̌ F · ỹt−1
                                        2
                                      +t.i.p. + O(||ξ||3 )
                                      ∞
                                      X          n
                                                    0
                                    =     β t−t0 λ̄ [Dy F + βDy̌ F ] · ỹt
                                          t=t0
                                           1 £
                                          + λ̄k ỹt0 Dyy  2
                                                             F k · ỹt + 2ỹt0 Dyξ 2                      2
                                                                                     F k · ξ t + 2β ỹt0 Dy̌ξ F k · ξ t+1
                                           2                                                 ¤ª
                                          +β ỹt0 Dy̌2y̌ F k · ỹt + 2ỹt0 Dy2y̌ F k · ỹt−1
                                          +t.i.p. + O(||ξ||3 ).                                                   (2.16)

   Using a similar Taylor series approximation of each of the functions g i , we corre-
spondingly obtain
∞
X                                                ∞
                                                 X            ©
       β t−t0 −1 ϕ̄0 g(yt−1 , ξ t−1 ; yt ) =            β t−t0 ϕ̄0 [Dy g + β −1 Dŷ g] · ỹt
t=t0                                             t=t0
                                                  1 £
                                                 + ϕ̄i ỹt0 Dyy  2 i
                                                                    g · ỹt + 2ỹt0 Dyξ 2 i
                                                                                           g · ξ t + 2β −1 ỹt0 Dŷξ
                                                                                                                 2 i
                                                                                                                     g · ξ t−1
                                                  2                                                      ¤ª
                                                 +β −1 ỹt0 Dŷ2ŷ g i · ỹt + 2β −1 ỹt0 Dŷy
                                                                                            2 i
                                                                                               g · ỹt−1
                                                 +t.i.p. + O(||ξ||3 ).                                                (2.17)




                                                           25
It then follows from constraints (2.2)–(2.4) that in the case of any admissible policy,42
                                      ∞
                                      X
               −1                                          0
           β          0
                     ϕ̄ ḡt0 = Et0                β t−t0 [λ̄ F (yt , ξ t ; yt−1 ) + β −1 ϕ̄0 g(yt−1 , ξ t−1 ; yt )]
                                      t=t0
                                      X∞                n
                                                            0
                            = Et0                 β t−t0 [λ̄ (Dy F + βDy̌ F ) + ϕ̄0 (Dy g + β −1 Dŷ g)] · ỹt
                                      t=t0
                                  1 £
                                 + λ̄k ỹt0 Dyy   2
                                                     F k · ỹt + 2ỹt0 Dyξ2
                                                                            F k · ξ t + 2β ỹt0 Dy̌ξ
                                                                                                 2
                                                                                                     F k · ξ t+1
                                  2                                                 ¤
                                 +β ỹt0 Dy̌2y̌ F k · ỹt + 2ỹt0 Dy2y̌ F k · ỹt−1
                                  1 £
                                 + ϕ̄i ỹt0 Dyy   2 i
                                                    g · ỹt + 2ỹt0 Dyξ 2 i
                                                                           g · ξ t + 2β −1 ỹt0 Dŷξ
                                                                                                 2 i
                                                                                                     g · ξ t−1
                                  2                                                      ¤ª
                                 +β −1 ỹt0 Dŷ2ŷ g i · ỹt + 2β −1 ỹt0 Dŷy
                                                                            2 i
                                                                               g · ỹt−1
                                 +t.i.p. + O(||ξ||3 ),                                                                (2.18)

where we have used (2.16) and (2.17) to substitute for the F and g terms respectively.
We can write this more compactly in the form
                                   ∞
                                   X                  ½                                                       ¾
           −1    0                            t−t0              1£ 0              0             0
                                                                                                            ¤
       β        ϕ̄ ḡt0 = Et0             β            Φ · ỹt + ỹt H · ỹt + 2ỹt Rỹt−1 + 2ỹt Z(L)ξ t+1
                                   t=t0
                                                                2
                               +t.i.p. + O(||ξ||3 ),                                                                  (2.19)

where
                                              0
                                  Φ ≡ λ̄ [Dy F + βDy̌ F ] + ϕ̄0 [Dy g + β −1 Dŷ g],
                                       2
                             H ≡ λ̄k [Dyy F k + βDy̌2y̌ F k ] + ϕ̄i [Dyy
                                                                      2 i
                                                                         g + β −1 Dŷ2ŷ g i ],
                                                  R ≡ λ̄k Dy2y̌ F k + ϕ̄i β −1 Dŷy
                                                                                2 i
                                                                                    g,
                                   2
                     Z(L) ≡ β λ̄k Dy̌ξ F k + (λ̄k Dyξ
                                                   2
                                                      F k + ϕ̄i Dyξ
                                                                 2 i
                                                                    g ) · L + β −1 ϕ̄i Dŷξ
                                                                                        2 i
                                                                                            g · L2 .
       Using (2.12), we furthermore observe that43

                                                               Φ = −Dy π.
  42
      Note that we here include (2.4) among the constraints that a policy must satisfy. We shall
call any evolution that satisfies (2.2)–(2.3) a “feasible” policy. Under this weaker assumption, the
left-hand sides of (2.18) and (2.19) must instead be replaced by β −1 ϕ̄0 g(yt0 −1 , ξ t0 −1 ; yt0 ).
   43
      This is the point at which our calculations rely on the assumption that the steady state around
which we compute our local approximations is optimal.



                                                                   26
With this substitution in (2.19), we obtain an expression that can be solved for
                                               ∞
                                               X
                                         Et0          β t−t0 Dy π · ỹt ,
                                               t=t0


which can in turn be used to substitute for the linear terms in (2.15). We thus obtain
an alternative quadratic approximation to (2.1),44

            X∞
       1              £                                             ¤
  Vt0 = Et0     β t−t0 ỹt0 Q · ỹt + 2ỹt0 Rỹt−1 + 2ỹt0 B(L)ξ t+1 + t.i.p. + O(||ξ||3 ), (2.20)
       2    t=t     0


where now
                                                  2
                                             Q ≡ Dyy π + H,
                                                     2
                                      B(L) ≡ Z(L) + Dyξ π · L.                                         (2.21)
Since (2.20) involves no linear terms, it can be evaluated (up to a residual of order
O(||ξ||3 )) using only a linear approximation to the evolution of ỹt under a given policy
rule.
    It follows that a correct LQ approximation to the original problem is given by
the problem of choosing a state-contingent evolution {ỹt } for t ≥ t0 to maximize the
objective
                                        X∞
                                 1                £                               ¤
                   VtQ (ỹ; ξ) ≡   E t0     β t−t0 ỹt0 A(L)ỹt + 2ỹt0 B(L)ξ t+1   (2.22)
                     0
                                 2      t=t     0

subject to the constraints that
                                                C(L)ỹt = ft ,                                         (2.23)
                                            Et D(L)ỹt+1 = ht                                          (2.24)
for all t ≥ t0 , and the additional initial constraint that

                                               D(L)ỹt0 = h̃t0 ,                                       (2.25)

where now
                                          A(L) ≡ Q + 2R · L,                                           (2.26)
  44
    Here we include ḡt0 among the “terms independent of policy.” If we consider also policies
that are not necessarily consistent with the initial pre-commitment, the left-hand side of (2.20) is
more generally equal to Vt0 + β −1 ϕ̄0 g(yt0 −1 , ξ t0 −1 ; yt0 ). This generalization of (2.20) is used in the
derivation of equation (4.3) below.


                                                      27
                                      C(L) ≡ Dy F + Dy̌ F · L,                                          (2.27)
                                            ft ≡ −Dξ F · ξ t ,
                                      D(L) ≡ Dŷ g + Dy g · L,                                          (2.28)
                                            ht ≡ −Dξ g · ξ t ,                                          (2.29)
                                           h̃t0 ≡ ht0 −1 + ḡt0 .


2.3     An Equivalent Lagrangian Approach
In the case that the objective (2.22) is concave,45 the first-order conditions associated
with the LQ problem just defined characterize the solution to that problem. Here
we show that these linear equations also correspond to a local linear approximation
to the first-order conditions associated with the exact problem, i.e., the modified
Ramsey policy problem defined in section 2.1, and hence that the solution to the LQ
problem represents a local linear approximation to optimal policy from a timeless
perspective.46
    As already noted, the first-order conditions for the exact policy problem are ob-
tained by differentiating the Lagrangian Lt0 defined in (2.10). This yields the sys-
tem of first-order conditions (2.11). The linearization of these first-order conditions
around the optimal steady state is in turn the set of linear equations that would be
obtained by differentiating a quadratic approximation to Lt0 around that same steady
state. Hence we are interested in computing such a local approximation, for the case
in which yt − ȳ, λt − λ̄, and ϕt − ϕ̄ are each of order O(||ξ||) for all t. (Here the
steady-state values of the Lagrange multipliers λ̄, ϕ̄ are again given by the solution
to equations (2.12) – (2.14).)
    We may furthermore write the Lagrangian in the form

                                            Lt0 = L̄t0 + L̃t0 ,

where
                             ∞
                             X            h                                                        i
                                             0
          L̄t0 = Vt0 + Et0          β t−t0 λ̄ F (yt , ξ t ; yt−1 ) + β −1 ϕ̄0 g(yt−1 , ξ t−1 ; yt ) ,
                             t=t0

  45
    The algebraic conditions under which this is so are discussed in the next section.
  46
    See also Levine et al. (2007) for a similar discussion of the equivalence between our approach
and the Lagrangian approach.

                                                   28
                             ∞
                             X                 h 0                                                      i
                                        t−t0                                −1 0
             L̃t0 = Et0             β           λ̃t F (yt , ξ t ; yt−1 ) + β ϕ̃t−1 g(yt−1 , ξ t−1 ; yt ) ,
                             t=t0

                                          λ̃t ≡ λt − λ̄,             ϕ̃t ≡ ϕt − ϕ̄.
We can then use equations (2.15) and (2.18) to show that the local quadratic approx-
imation to L̄t0 is given by47

                                          L̄t0 = VtQ
                                                   0
                                                     + t.i.p. + O(||ξ||3 ).

In addition, the fact that λ̃t , ϕ̃t are both of order O(||ξ||) means that a local quadratic
approximation to the other term is given by
                    ∞
                    X            h 0                                                            i
       L̃t0 = Et0          β t−t0 λ̃t F̃ (yt , ξ t ; yt−1 ) + β −1 ϕ̃0t−1 g̃(yt−1 , ξ t−1 ; yt ) + O(||ξ||3 ),
                    t=t0


where F̃ and g̃ are local linear approximations to the functions F and g respectively.
   Hence the local quadratic approximation to the complete Lagrangian is given by
                                    ∞
                                    X                h 0                                                            i
        Lt0 = VtQ
                0
                  + Et0                        β t−t0 λ̃t F̃ (yt , ξ t ; yt−1 ) + β −1 ϕ̃0t−1 g̃(yt−1 , ξ t−1 ; yt )
                                    t=t0

                                    +t.i.p. + O(||ξ||3 ).                                                               (2.30)

But this is identical (up to terms independent of policy) to the Lagrangian for the LQ
problem of maximizing VtQ  0
                              subject to the linearized constraints. Hence the first-order
conditions obtained from this approximate Lagrangian (which coincide with the local
linear approximation to the first-order conditions for the exact problem) are identical
to the first-order conditions for the LQ problem, and their solutions are identical as
well.


3      Characterizing Optimal Policy
We now study necessary and sufficient conditions for a policy to solve the LQ problem
of maximizing (2.22) subject to constraints (2.23) – (2.25). Let H be the Hilbert space
  47
    It is worth noting that this equality holds in the case of all feasible policies, whether or not the
policy is consistent with the initial pre-commitment (2.4). This is important for our discussion of
the welfare evaluation of suboptimal policies in section 4.


                                                              29
of (real-valued) stochastic processes {ỹt } such that
                                          ∞
                                          X
                                    Et0          β t−t0 ỹt0 ỹt < ∞.                               (3.1)
                                          t=t0


We are interested in solutions to the LQ problem that satisfy the bound (3.1) because
it guarantees that the objective V Q is well-defined (and is generically required for it to
be so). Of course, our LQ approximation to the original problem is only guaranteed
to be accurate in the case that ỹt is always sufficiently small; hence a solution to the
LQ problem in which ỹt grows without bound, but at a slow enough rate for (3.1)
to be satisfied, need not correspond (even approximately) to any optimum (or local
optimum) of the exact problem. In this section, however, we take the LQ problem at
face value, and discuss the conditions under which it has a solution, despite the fact
that we should in general only be interested in bounded solutions.


3.1     A Lagrangian Approach
The Lagrangian for this problem is given by
             (
           1       X∞         h                                     0
     Q                   t−t0
   Lt0 =       Et0     β        ỹt0 A(L)ỹt + 2ỹt0 B(L)ξ t+1 + 2λ̃t C(L)ỹt
           2       t=t    0
                                                                                                    )
                                                                                                ¤
                                                                        +2β −1 ϕ̃0t−1 D(L)ỹt           .


(Note that this is just (2.30), omitting the terms independent of policy and those
of third or higher order.) Differentiation of the Lagrangian then yields a system of
linear first-order conditions
            1
              Et {[A(L) + A0 (βL−1 )]ỹt } + Et [B(L)ξ t+1 ]
            2
                               +Et [C 0 (βL−1 )λ̃t ] + β −1 D0 (βL−1 )ϕ̃t−1 = 0                     (3.2)

that must hold for each t ≥ t0 under an optimal policy. (Here we use the notation
M 0 for the transpose of a matrix M .) These conditions, together with (2.23) – (2.25),
form a linear system to be solved for the joint evolution of the processes {ỹt , λ̃t , ϕ̃t }
given the exogenous disturbance processes {ξ t } and the initial conditions ỹt0 −1 and the



                                                  30
initial pre-commitment ḡt0 (or ĥt0 ). This type of system of linear stochastic difference
equations is easy to solve using standard methods.48
    The first-order conditions (3.2) are easily shown to be necessary for optimality,
but they are not generally sufficient for optimality as well; one must also verify that
second-order conditions for optimality are satisfied. (In the case of an LQ problem,
satisfaction of the second-order conditions implies global, and not just local, optimal-
ity; so we need not check any further conditions. But because our LQ problem is
only a local approximation to the original policy problem, a global optimum of the
LQ problem still may only correspond to a local optimum of the exact problem.) We
next consider these additional conditions.
    Let us consider the subspace H1 ⊂ H of processes ŷ ∈ H that satisfy the additional
constraints
                                         C(L)ŷt = 0                                   (3.3)
                                        Et D(L)ŷt+1 = 0                                   (3.4)
for each date t ≥ t0 , along with the initial commitments

                                             D(L)ŷt0 = 0,                                 (3.5)

where we define ŷt0 −1 ≡ 0 in writing (3.3) for period t = t0 and in writing (3.5). This
subspace is of interest because if a process ỹ ∈ H satisfies constraints (2.23) – (2.25),
another process y ∈ H with yt0 −1 = ỹt0 −1 satisfies those constraints as well if and
only if y − ỹ ∈ H1 . We may now state our first main result.


Proposition 1 For {ỹt } ∈ H to maximize the quadratic form (2.22), subject to the
constraints (2.23) – (2.25) given initial conditions ỹt0 −1 and ḡt0 , it is necessary and
sufficient that (i) there exist Lagrange multiplier processes49 ϕ̃, λ̃ ∈ H such that the
processes {ỹt , ϕ̃t , λ̃t } satisfy (3.2) for each t ≥ t0 ; and (ii)

                                                   X∞
                                              1
                      Q
                    V (ŷ) ≡   VtQ (ŷ; 0)   = Et0     β t−t0 [ŷt0 A(L)ŷt ] ≤ 0          (3.6)
                                 0
                                              2    t=t   0

  48
     See, for example, Giannoni and Woodford (2002) for discussion of the solution of an equation
system of this form using an eigenvector-decomposition method.
  49
     Note that ϕ̃t is also assumed to be defined for t = t0 − 1.




                                                 31
for all processes ŷ ∈ H1 , where in evaluating (3.6) we define ŷt0 −1 ≡ 0. A process
{ỹt } with these properties is furthermore uniquely optimal if and only if

                                             V Q (ŷ) < 0                                        (3.7)

for all processes ŷ ∈ H1 that are non-zero almost surely.


    The proof is given in the Appendix. The case in which the stronger condition
(3.7) holds — i.e., the quadratic form V Q (ŷ) is negative definite on the subspace H1
— is the one of primary interest to us, since it is in this case that we know that
the process {ỹt } represents at least a local welfare maximum in the exact problem.
In this case we can also show that pure randomization of policy reduces the welfare
objective (2.22), and hence is locally welfare-reducing in the exact problem as well,
as is discussed further in Benigno and Woodford (2005a).


3.2     A Dynamic Programming Approach
We can furthermore establish a useful characterization of the algebraic conditions
under which the second-order conditions (3.7) are satisfied. These are most easily
developed by considering the recursive formulation of our optimal policy problem
presented in section 2.1.50 Let us suppose that the exogenous state vector ξ t evolves
according to a linear law of motion

                                        ξ t+1 = Γ ξ t + ²t+1 ,                                   (3.8)

where Γ is a matrix, all of the eigenvalues of which have modulus less than β −1/2 ,
and {²t } is an i.i.d. vector-valued random sequence, drawn each period from a dis-
tribution with mean zero and a variance-covariance matrix Σ.51 In this case, our LQ
  50
    This section has been improved by the suggestions of Paul Levine and Joe Pearlman.
  51
    These assumptions ensure that the process {ξ t } satisfies a bound of the form (3.1). If we further
wish to ensure that the disturbances are bounded, so that our local approximations can be expected
to be accurate in the event of small enough disturbances, we may assume further that all eigenvalues
of Γ have a modulus less than 1, and that ²t+1 is drawn from a distribution with bounded support.
We may assume that, like the other structural relations in this section, (3.8) is merely a local linear
approximation. Finally, note that the assumption of a law of motion of the form (3.8) allows for
disturbances with arbitrarily complex forms of serial correlation, simply by adding elements to the
vector ξ t reflecting past exogenous states.

                                                32
approximate policy problem has a recursive formulation, in which the continuation
problem from any period t forward depends on the extended state vector
                                             
                                        ỹt−1
                                       h̃ 
                                       t 
                                 zt ≡        .                            (3.9)
                                       ξt 
                                        ξ t−1

    Let V̄ Q (zt ) denote the maximum attainable value of the continuation objective
VtQ , if the process {ỹτ } from date t onward is chosen to satisfy constraints (2.23)–
(2.24) for all τ ≥ t, an initial precommitment of the form

                                      D(L)ỹt = h̃t ,                              (3.10)

and the bound (3.1). As usual in an LQ problem of this form, it can be shown that
the value function is a quadratic function of the extended state vector,
                                                  1
                                      V̄ Q (zt ) = z0t P zt ,                       (3.11)
                                                  2
where P is a symmetric matrix to be determined. In characterizing the solution to
the problem, it is useful to introduce notation for partitions of the matrix P . Let Pij
(for i, j = 1, 2, 3, 4) be the 16 blocks obtained when P is partitioned in both directions
conformably with the partition of zt in (3.9), and let

                                 Pi ≡ [Pi1 Pi2 Pi3 Pi4 ]

(for i = 1, 2, 3, 4) be the four blocks obtained when P is partitioned only vertically.
    In the recursive formulation of the approximate LQ problem, in each period t, ỹt
is chosen, and a precommitment h̃t+1 (ξ t+1 ) is chosen for each possible state in the
period t + 1 continuation, so as to maximize
                         1 0
                           ỹt A(L)ỹt + Et [ỹt0 B(L)ξ t+1 ] + βEt V̄ Q (zt+1 ), (3.12)
                         2
subject to the constraints that ỹt satisfy (2.23) and (3.10), and that the choices of
{h̃t+1 (ξ t+1 )} satisfy
                                             Et h̃t+1 = ht .                      (3.13)
   To simplify the discussion, we shall further assume that
                                   "      #
                                     C0
                             rank           = nF + ng ,                            (3.14)
                                     D0

                                          33
                                                                            P
where here and below we write lag polynomials in the form X(L) = j Xj Lj . This
condition implies that the constraints (2.23) and (3.10) include neither any redundant
constraints nor any constraints that are inconsistent in the case of a generic state zt .
    The first-order conditions for the optimal choice of ỹt in this single-period problem
are of the form

       [A0 + (1/2)A1 L]ỹt + Et [B(L)ξ t+1 ] + βP1 Et zt+1 + C00 λ̃t + D00 ψ̃ t = 0,               (3.15)

where λ̃t , ψ̃ t are the Lagrange multipliers associated with constraints (2.23) and (3.10)
respectively. Condition (3.15) together with the constraints (2.23) and (3.10) con-
stitute a system of n = ny + nF + ng linear equations to solve for ỹt , λ̃t , and ψ̃ t as
functions of zt . This system can be written in the matrix form M yt† = −G zt , where
                                                                       
                            A0 + βP11 C00 D00                        ỹt
                                                                       
                    M ≡       C0       0 0 ,               yt† ≡  λ̃t  ,         (3.16)
                               D0       0 0                          ψ̃ t

and G is a matrix of coefficients, the first two columns of which (of particular interest
here) are                                                  
                                (1/2)A1                     0
                                                           
                       G1 ≡        C1     ,      G2 ≡  0  .
                                    D1                    −I
This has a determinate solution if and only if M is non-singular. This is evidently a
necessary condition for strict concavity of the policy problem, and we shall assume
that it holds in the remainder of our discussion.52 Given this assumption, the unique
solution is
                                   yt† = −M −1 G zt .                           (3.17)
    The first-order conditions for the optimal choice of the precommitments {h̃t+1 (ξ t+1 )}
are that
                                     βP2 zt+1 = −ϕ̃t                             (3.18)
in each possible state ξ t+1 that can succeed the given state in period t, where ϕ̃t is
the Lagrange multiplier associated with constraint (3.13); note that the value of ϕ̃t
  52
     We are actually only interested in whether there exists a unique solution for ỹt . However, con-
dition (3.14) implies that there can be no vector y † 6= 0 such that M y † = 0, unless it involves ỹ 6= 0.
Thus if M is singular, there are necessary multiple solutions for ỹt if there are any solutions at all,
and not just multiple solutions for the Lagrange multipliers.

                                                  34
depends only on the state in period t. The fact that the left-hand side of (3.18) must
be the same in each state ξ t+1 implies that

                                   P22 [h̃t+1 − ht ] + P23 ²t+1 = 0

in each state. This allows a determinate solution for h̃t+1 if and only if P22 is non-
singular; this too is evidently a necessary condition for concavity, and is assumed
from here on.53 Under this assumption, (3.18) together with (3.10) implies that
                                                   −1
                                     h̃t+1 = ht − P22 P23 ²t+1 .                                  (3.19)

We can also solve uniquely for the Lagrange multiplier,

                        ϕ̃t = −βP2 Et zt+1
                             = −βP21 ỹt − βP22 ht − β[P23 Γ + P24 ] ξ t .                        (3.20)

    Equations (3.17) and (3.19) completely describe the optimal dynamics of the vari-
ables {ỹt , h̃t }, starting from some initial conditions (ỹt0 −1 , h̃t0 ), given the evolution
of the exogenous states {ξ t }. The system consisting of these solutions for ỹt and
h̃t+1 (ξ t+1 ), together with the law of motion (3.8), can be written in the form

                                        zt+1 = Φ zt + Ψ ²t+1 ,                                    (3.21)

for certain matrices Φ and Ψ. If we partition Φ in the same way as P, it follows from
the form of the solutions obtained above that Φij = 0 for all i ≥ 2, j ≤ 2. From
this (together with our assumption about the eigenvalues of Γ) it follows that all
eigenvalues of Φ have modulus less than β −1/2 if and only if all eigenvalues of

                                     Φ11 ≡ [−I 0 0] M −1 G1                                       (3.22)

have this property. Hence there exists a determinate solution to the first-order condi-
tions for optimal policy, i.e., a unique solution satisfying the bound (3.1), if and only
if M and P22 are non-singular matrices, and all eigenvalues of Φ11 have modulus less
than β −1/2 .
  53
    If P22 is singular, it is obvious that there are multiple solutions for h̃t+1 (ξ t+1 ) consistent with
the first-order conditions, but one might wonder if these correspond to multiple state-contingent
evolutions {ỹt }. In fact they do, for a single state-contingent evolution {ỹt } is consistent with only
one process {h̃t }, which can be determined from (3.10).

                                                 35
    Note that the solution (3.21) involves elements of the matrix P . We can solve for
those elements of P in the following way. It follows from the assumed representation
(3.11) for the value function that the vector of partial derivatives with respect to ỹt−1
will equal
                                      V̄1Q = P1 zt .
On the other hand, application of the envelope theorem to the problem (3.12) implies
that
                           V̄1Q = G01 yt† = −G01 M −1 G zt .                  (3.23)
Equating the corresponding coefficients in these two representations, we observe that

                                       P1j = −G01 M −1 Gj

for j = 1, 2, 3, 4. A similar argument implies that

                                       P2j = −G02 M −1 Gj                                     (3.24)

for j = 1, 2, 3, 4.
    These expressions involve the matrix M , which depends on P11 ; but the system

                                    P11 = −G01 M (P11 )−1 G1                                  (3.25)

is a set of n2y equations to solve for the n2y elements of P11 .54 Once we have solved for
P11 , we know the matrix M , and can solve for the other elements of P . In particular,
we can solve for
                                    P22 = −G02 M −1 G2 ,                            (3.26)
and check whether it is non-singular, as required in (3.19). The other elements of P
can be solved for using the same method.55
    Thus far, we have discussed only the implications of the first-order conditions for
the single-period optimization problem. Again, the question arises whether a solution
to the first-order conditions corresponds to a maximum of (3.12). The second-order
conditions for a finite-dimensional optimization problem are well-known. First, the
objective is strictly concave in ỹt if and only if the matrix A0 + βP11 is such that

                                       ỹ 0 [A0 + βP11 ] ỹ < 0
  54
     Actually, because P11 is symmetric, and the system (3.25) has the same symmetry, we need only
solve a system of n(n + 1)/2 equations for n(n + 1)/2 independent quantities.
  55
     Details of the algebra are provided in a note on computational issues available from the authors.

                                               36
for all ỹ 6= 0 such that
                                    C0 ỹ = 0,        D0 ỹ = 0.
Using a result of Debreu (1952),56 we can state algebraic conditions on these matrices
that are easily checked. For each r such that nF +ng +1 ≤ r ≤ ny , let Mr be the lower-
right square block of M of size nF + ng + r.57 Then the concavity condition stated
above holds if and only if det Mr has the same sign as (−1)r , for each nF + ng + 1 ≤
r ≤ ny . Note that in the case that policy is unidimensional — meaning that there is
a single instrument to set each period, which suffices to determine the evolution of
the endogenous variables, so that nF + ng = ny − 1 — then this requirement reduces
to the single condition that the determinant of M have the same sign as (−1)ny .
    Second, in each possible state ξ t+1 in the following period, the continuation ob-
jective V̄ Q (zt+1 ) is a concave function of h̃t+1 (ξ t+1 ) if and only if the submatrix P22
is negative definite, i.e., such that h̃0 P22 h̃ < 0 for all h̃ 6= 0. This condition is also
straightforward to check using the Debreu theorem: the principal minors of P22 must
have alternating signs.
    These two conditions are obviously necessary for strict concavity of the single-
period problem, and hence for strict concavity of the infinite-horizon optimal policy
problem. In fact, they are also sufficient, yielding the following result.


Proposition 2 Suppose that the exogenous disturbances have a law of motion of the
form (3.8), where Γ is a matrix the eigenvalues of which all have modulus less than
β −1/2 , and that the constraints satisfy the rank condition (3.14), where nF + ng < ny .
Then the LQ policy problem has a determinate solution, given by (3.21), if and only
if (i) there exists a solution P11 to equations (3.25) such that for each of the minors
of the matrix M defined in (3.16), det Mr has the same sign as (−1)r , for each
nF + ng + 1 ≤ r ≤ ny ; (ii) the eigenvalues of the matrix Φ11 defined in (3.22) all
have modulus less than β −1/2 ; and (iii) the matrix P22 defined in (3.26) is negative
definite, i.e., is such that its rth principle minor has the same sign as (−1)r , for each
1 ≤ r ≤ ng .
  56
    See also Theorem 1.E.17 of Takayama (1985).
  57
    Given (3.14), we can order the elements of ỹt so that the left (nF + ng ) × (nF + ng ) block of
the matrix in (3.14) is non-singular, and we assume that this has been done when forming these
submatrices.



                                                 37
The proof of this proposition is also given in the Appendix. Note that the conditions
stated in the proposition are necessary and sufficient both for the existence of a
determinate solution to the first-order conditions, and for the quadratic form V Q (ψ) to
satisfy the strict concavity condition (3.7). In the case that either condition (i) or (iii)
is violated, there may exist a determinate solution to the first-order conditions, but
it will not represent an optimum, owing to violation of the second-order conditions.
     The fact that condition (iii) is needed in addition to conditions (i)–(ii) in order to
ensure that we have a concave problem indicates an important respect in which the
theory of LQ optimization with forward-looking constraints is not a trivial generaliza-
tion of the standard theory for backward-looking problems, since conditions (i)–(ii)
are sufficient in a backward-looking problem of the kind treated by Magill (1977).
58
    It also shows that the second-order conditions for a stochastic problem are more
complex than they would be in the case of a deterministic policy problem (again,
unlike what is true of purely backward-looking LQ problems). For in a deterministic
version of our problem with forward-looking constraints, conditions (i)–(ii) would also
be sufficient for concavity, and thus for the solution to the first-order conditions to
represent an optimum.
     In a deterministic version of the problem — where we not only assume that ξ t = 0
each period, but we restrict our attention to policies under which the evolution of
the variables {ỹt } is purely deterministic (and hence perfectly forecastable), so that
we seek to characterize the optimal perfect foresight equilibrium, without addressing
the question whether this is also optimal among the larger set of possible rational-
expectations equilibria.59 — the constraints on possible equilibria are the purely
backward-looking constraints (2.23) and
                                           D(L)ỹt = h̃t                                     (3.27)
for each t ≥ t0 , where we specify h̃t = ht−1 = 0 for all t ≥ t0 + 1. This is a purely
  58
     See Levine et al. for a derivation of the second-order conditions for a backward-looking, deter-
ministic LQ problem, using what is essentially a discrete-time version of the approach of Magill. In
some cases, conditions (i)–(ii) are both necessary and sufficient for concavity, even in the presence
of forward-looking constraints. The problem treated in Benigno and Woodford (2005a) is an exam-
ple of this kind. Note that in that paper an alternative, frequency-domain characterization of the
conditions for concavity is used, that is discussed more generally in Benigno and Woodford (2006b).
  59
     Additional equilibria can be attained, by randomization of policy, even in the case that there
are no exogenous random disturbances. This may or may not allow an increase in welfare relative
to the optimal deterministic policy.

                                               38
backward-looking problem, so that the standard second-order conditions apply. And
it should be obvious that, as there is no longer a choice of h̃t+1 (ξ t+1 ) to be made each
period, our argument above for the necessity of condition (iii) would not apply.
    But conditions (i)–(ii) are not generally a sufficient condition to guarantee that
(3.7) is satisfied, in the presence of forward-looking constraints (2.24), if policy ran-
domization is allowed.60 Because constraints (2.24) need hold only in expected value,
random policy may be able to vary the paths of the endogenous variables (in some
states of the world) in directions that would not be possible in the corresponding de-
terministic problem, and this makes the algebraic conditions required for (3.7) to hold
more stringent. Specifically, the value function for the continuation problem must be
a strictly concave function of the state-contingent pre-commitment h̃t+1 made for
the following period, or it is possible to randomize h̃t+1 (requiring a corresponding
randomization of subsequent policy) without changing the fact that constraint (2.24)
is satisfied in period t. Hence condition (iii) is necessary in the stochastic case.61 It
can also easily be shown that condition (iii) is not implied in general by conditions
(i)–(ii).
    A simple example may clarify this point. Suppose that yt has two elements,
and that the only constraint on what policy can achieve is a single, forward-looking
constraint
                                   Et [δ ỹ1,t − ỹ1,t+1 ] = 0                       (3.28)
  60
       Our remarks here apply even in the case that the “fundamental” disturbances {ξ t } are purely de-
terministic; what matters is whether policy may be contingent upon random events. As is discussed
further in Benigno and Woodford (2005a), when the second-order conditions fail to hold, policy
randomization can be welfare-improving, even when the random variations in policy are unrelated
to any variation in fundamentals.
   61
       Levine et al. (2007) provide a different argument for a condition similar to our condition (iii)
as a necessary condition for optimality in a model with a forward-looking constraint, which does
not require a consideration of stochastic policy. They consider Ramsey-optimal policy rather than
optimality from a timeless perspective; that is, they assume no initial precommitment (2.25). In this
case, the deterministic optimal policy problem is like the one considered above, except that (3.27)
need hold only in periods t ≥ t0 + 1; the optimal policy is then the same as in the backward-looking
problem just discussed, except that instead of taking h̃t0 as given, one is free to choose h̃t0 so as
to maximize (2.22). This latter problem has a solution only if the value function V̄tQ        0
                                                                                                 is bounded
above, for a given vector ỹt0 −1 , and this is true in general only if it is a strictly concave function of
h̃t0 . The validity of this argument, however, depends on considering an exact LQ problem, rather
than an LQ local approximation to a problem that may have different global behavior.



                                                  39
for all t ≥ t0 , where δ < β −1/2 . (The path of {ỹ2,t } can be freely chosen, subject to
the bound (3.1).) An initial pre-commitment specifies the value that ỹ1,t0 must have.
In the corresponding deterministic problem, constraint (3.28) implies that one must
have
                                       ỹ1,t+1 = δ ỹ1,t
for each t ≥ t0 , and this, together with the pre-commitment, uniquely determines
the entire path of the sequence {ỹ1,t } that must be brought about by deterministic
policy. Hence the second-order condition for the deterministic problem requires only
that the objective be a concave function of the path of {ỹ2,t }. But if random policies
are considered, it is also possible for {ỹ1,t } to evolve in accordance with any law of
motion
                                  ỹ1,t+1 = δ ỹ1,t + ²t+1 ,
where {²t } is any martingale difference sequence with a suitable bound on its asymp-
totic variance; in this simple example, the set of possible evolutions {ỹ1,t } is indepen-
dent of the evolution chosen for {ỹ2,t }. Whether randomization of the path of {ỹ1,t }
can increase the value of the policy objective obviously depends on terms in the ob-
jective involving the path of {ỹ1,t } (including cross terms), and not just the terms
involving the path of {ỹ2,t }. Hence the conditions required for a concave optimization
problem are more stringent in this case.62


4        Welfare Evaluation of Alternative Policy Rules
We have argued that another advantage of our approach is that it can be used not
only to derive a linear approximation to a fully optimal policy commitment, but also
to compute approximate welfare comparisons between alternative rules (neither of
which may be fully optimal), that will correctly rank these rules in the case that
random disturbances are small enough. Because empirically realistic models are in-
evitably fairly complex, a fully optimal policy rule is likely to be too complex to
represent a realistic policy proposal; hence comparisons among alternative simple
(though suboptimal) rules are of considerable practical interest. Here we discuss how
this can be done.
  62
       In the Appendix, we illustrate the application of the conditions in Proposition 2 to this example.




                                                  40
    We do not propose to simply evaluate (a local approximation to) expected dis-
counted utility Vt0 under a candidate policy rule, because the optimal policy locally
characterized above (i.e., optimal policy “from a timeless perspective”) does not max-
imize this objective; hence ranking rules according to this criterion would lead to the
embarrassing conclusion that there exist policies better than the optimal policy. (We
could, of course, define “optimal policy” as the policy that maximizes Vt0 ; but this
would result in a time-inconsistent policy recommendation, as noted earlier.) Thus
we wish to use a criterion that ranks rules according to how close they come to solving
the recursive policy problem defined in section 2.1, rather than how close they come
to maximizing Vt0 .
    Of course, if we restrict our attention to policies that necessarily satisfy the initial
pre-commitment (2.4), there is no problem; our optimal rule will be the one that
maximizes Vt0 , or (in the case of small enough shocks) the one that maximizes VtQ        0
                                                                                            .
But simple policy rules are unlikely to precisely satisfy (2.4); thus in order to be able
to select the best rule from some simple class, we need an alternative criterion, one
that is defined for all policies that are close enough to being optimal, in a sense that
is to be defined. At the same time, we wish it to be a criterion the maximization of
which implies that one has solved the constrained optimization problem defined in
section 2.1.


4.1    A Lagrangian Approach
Our Lagrangian characterization of optimal policy suggests such a criterion. The
timelessly optimal policy from date t0 onward — that is, the policy that maximizes
Vt0 subject to the initial constraint (2.4) in addition to the feasibility constraints
(2.2)–(2.3) — is also the policy that maximizes the Lagrangian

                        Vtmod
                          0
                              ≡ Vt0 + β −1 ϕ0t0 −1 g(yt0 −1 , ξ t0 −1 ; yt0 ),         (4.1)

where ϕt0 −1 is the vector of Lagrange multipliers associated with the initial constraint
(2.4). This is a function that coincides (up to a constant) with the objective Vt0 in
the case of policies satisfying the constraint (2.4), but that is defined more generally,
and that is maximized over the broader class of feasible policies by the timelessly
optimal policy. Hence an appropriate criterion to use in ranking alternative policies
is the value of Vtmod
                  0
                       associated with each one. This criterion penalizes policies that


                                               41
fail to satisfy the initial pre-commitment (2.4), by exactly the amount by which a
previously anticipated deviation of that kind would have reduced the expected utility
of the representative household.
    In the case of any policy that satisfies the feasibility constraints (2.2)–(2.3) for all
t ≥ t0 , we observe that

             Vtmod
               0
                   = L̄t0 + β −1 ϕ̃0t0 −1 g(yt0 −1 , ξ t0 −1 ; yt0 )
                      = VtQ
                          0
                            + β −1 ϕ̃0t0 −1 g̃(yt0 −1 , ξ t0 −1 ; yt0 ) + t.i.p. + O(||ξ||3 )
                      = VtQ
                          0
                            + β −1 ϕ̃0t0 −1 Dŷ g · ỹt0 + t.i.p. + O(||ξ||3 ).

This suggests that in the case of small enough shocks, the ranking of alternative
policies in terms of Vtmod
                       0
                           will correspond to the ranking in terms of the welfare
measure
                           Wt0 ≡ VtQ
                                   0
                                     + β −1 ϕ̃0t0 −1 Dŷ g · ỹt0 .         (4.2)
Note that in this derivation we have assumed that ỹt = O(||ξ||). This will be true
in the equilibrium associated with any (sufficiently differentiable) policy rule that
is consistent with the optimal steady state in the absence of random disturbances.
We shall restrict attention to policy rules of this kind. Note that while this is an
important restriction, it does not preclude consideration of extremely simple rules;
and it is a property of the simple rules of greatest interest, i.e., those that come closest
to being optimal among rules of that degree of complexity.
    In expression (4.1), and hence in (4.2), ϕt0 −1 is the Lagrange multiplier associated
with constraint (2.4) under the optimal policy. However, in order to evaluate Wt0 to
second-order accuracy, it suffices to have a first-order approximation to this multiplier.
Such an approximation is given by the multiplier ϕ̃t0 −1 associated with the constraint
(2.25) of the LQ problem. Thus we need only solve the LQ problem, as discussed
in the previous section — obtaining a value for ϕ̃t0 −1 along with our solution for the
optimal evolution {yt } — in order to determine the value of Wt0 .
    Moreover, we observe that in the characterization given in the previous section
of the solution to the LQ problem, ϕ̃t0 −1 = O(||ξ||).63 Thus a solution for the equi-
librium evolution {ỹt } under a given policy that is accurate to first order suffices to
evaluate the second term in (4.2) to second-order accuracy. Hence Wt0 inherits this
  63
   This follows from solution (3.17) for the Lagrange multiplier associated with the initial pre-
commitment.


                                                 42
property of VtQ0
                 , and it suffices to compute a linear approximation to the equilibrium
dynamics {ỹt } under each candidate policy rule in order to evaluate Wt0 to second-
order accuracy. We can therefore obtain an approximation solution for {ỹt } under
a given policy by solving the linearized structural equations (2.23)–(2.24), together
with the policy rule, and use this solution in evaluating Wt0 . In this way welfare
comparisons among alternative policies are possible, to second-order accuracy, us-
ing linear approximations to the model structural relations and a quadratic welfare
objective.
    Moreover, we can evaluate Wt0 to second-order accuracy using only a linear ap-
proximation to the policy rule. This has important computational advantages. For
example, if we wish to find the optimal policy rule from among the family of simple
rules of the form it = φ(yt ), where it is a policy instrument, and we are content to
evaluate Vtmod
            0
                 to second-order accuracy, then it suffices to search over the family of
linear policy rules64
                                         ı̃t = f 0 ỹt ,
parameterized by the vector of coefficients f. There are no possible second-order (or
larger) welfare gains resulting from nonlinearities in the policy rule.
    It is important to note that these conclusions obtain only because we evaluate
welfare taking into account the welfare losses that would result from a violation of
the initial pre-commitment if it were to have been anticipated. Some would prefer
to evaluate alternative simple policy rules by computing the expected value of Vt0
(rather than Vtmod
                0
                   ) associated with each rule (e.g., Schmitt-Grohé and Uribe, 2007).
As noted above, this alternative criterion is one under which the optimal rule from
a timeless perspective can be dominated by other rules, a point stressed by Blake
(2001) and Jensen and McCallum (2002), among others. The alternative criterion is
also one that cannot be evaluated to second-order accuracy using only a first-order
solution for the equilibrium evolution under a given policy. For a general feasible
policy — consistent with the optimal steady state, but not necessarily consistent
  64
    Here we restrict attention to rules that are consistent with the optimal steady state, so that the
intercept term is zero when the rule is expressed in terms of deviations from steady-state values.
Note that a rule without this property will result in lower welfare, in the case of any small enough
disturbances.




                                               43
with the initial pre-commitment (2.4) — we can show that65

                       Vt0 = VtQ
                               0
                                 − β −1 ϕ̄0 Dŷ g · ỹt0 + t.i.p. + O(||ξ||3 ).                  (4.3)

The first term on the right-hand side of this expression is purely quadratic (has zero
linear terms), but this is not true of the second term, if the initial pre-commitment
is binding under the optimal policy. Evaluation of the second term to second-order
accuracy requires a second-order approximation to the evolution {yt } under the policy
of interest; there is thus no alternative to the use of higher-order perturbation solution
methods as illustrated by Schmitt-Grohé and Uribe, and nonlinear terms in the policy
rule generally matter for welfare.66
    In expression (4.2), the value of the multiplier ϕ̃t0 −1 depends on the economy’s
initial state and on the value of the initial pre-commitment ḡt0 . However, we wish to
be able to rank alternative rules for an economy in which no such commitment may
exist prior to the adoption of the policy rule. We can avoid having to make reference
to any historically given pre-commitment by assuming a self-consistent constraint of
the form (2.5).
    If we define a new extended state vector
                                                      
                                               ỹt−1
                                          ĥ(ξ , ξ ) 
                                               t t−1 
                                   ẑt ≡              ,
                                                ξt    
                                                     ξ t−1

where67
                                                      −1
                           ĥ(ξ t , ξ t−1 ) ≡ ht−1 − P22 P23 (ξ t − Γξ t−1 ),
  65
     Here we use the more general form of (2.20) mentioned in footnote 42.
  66
     Damjanovic et al. (2008) show that one can instead use an LQ approximation to evaluate time-
invariant policy rules under an alternative criterion, which computes the expected value of Vt0 under
a probability distribution for initial conditions that is independent of the policy rule considered, as
in the calculations here, but rather under the ergodic distribution for the endogenous variables
associated with the particular time-invariant policy that is to be evaluated. This criterion has the
unappealing feature of giving a rule that leads to different long-run average values of an endogenous
variable (e.g., the capital stock) “credit” for a higher initial average value of the variable as well.
It also cannot be applied to evaluate non-stationary policies, or even time-invariant policies that
imply non-stationary dynamics of endogenous variables, such as the optimal policy in Benigno and
Woodford (2003).
  67
     Here it should be recalled that ht−1 is a linear function of ξ t−1 , defined in (2.29).

                                                44
then it follows from (3.19) that under the solution to the recursive policy problem,
zt = ẑt for each t ≥ t0 + 1. (However, ẑt , unlike zt , is a function solely of ỹt−1 and the
history of the exogenous disturbances.) Hence

                                          h̃t0 = ĥ(ξ t , ξ t−1 )                                 (4.4)

is a self-consistent constraint of the form (2.5).
    If we assume an initial pre-commitment specified in this way, it also follows from
(3.17) that
                                ψ̃ t = [0 0 −I] M −1 G ẑt                        (4.5)
is the Lagrange multiplier associated with the pre-commitment each period in the
recursive problem. Moreover, because the only constraint on the way in which
h̃t+1 (ξ t+1 ) can be chosen for the following period is given by the expected-value con-
straint (3.13), the first-order conditions for optimal policy imply that ψ̃ t = Et−1 ψ̃ t
for each t ≥ t0 + 1,68 and hence that

                   ψ̃ t = [0 0 −I] M −1 G Et−1 ẑt
                                                                                  
                                                                          ỹt−1
                                                                         ht−1     
                                                                                  
                        = ψ̃(ỹt−1 , ξ t−1 ) ≡ [0 0 −I] M −1 G                    .
                                                                         Γξ t−1   
                                                                          ξ t−1

Consistency of this result with (4.5) implies that the right-hand-side of (4.5) must be
equivalent to ψ̃(ỹt−1 , ξ t−1 ); that is, that the coefficients multiplying ỹt−1 , ξ t , and ξ t−1
must be the same in both expressions. But since (4.5) must hold at t = t0 as well,
in the case of an initial pre-commitment (4.4), and not only for t ≥ t0 + 1, it follows
that under such a pre-commitment,

                                         ψ̃ t = ψ̃(ỹt−1 , ξ t−1 )

for all t ≥ t0 . In the case that t = t0 , the multiplier ψ̃ t0 associated with the initial
pre-commitment is the one that is denoted β −1 ϕ̃t0 −1 in (2.30) and in (4.2). Thus we
can write
                          ϕ̃t0 −1 = ϕ∗ (yt0 −1 ) ≡ β ψ̃(ỹt0 −1 , ξ t0 −1 ).         (4.6)
  68
     In fact, one can show that ψ̃ t = β −1 ϕ̃t−1 for each t ≥ t0 + 1. This follows from differentiation
of the value function V Q (zt+1 ) with respect to h̃t+1 using the envelope theorem, and comparison of
the result with (3.18).

                                                 45
Then we can write69

                  Wt0 = W (ỹ; ξ t0 , yt0 −1 ) ≡ VtQ
                                                   0
                                                     + β −1 ϕ∗ (yt0 −1 )0 Dŷ g · ỹt0 .            (4.7)

This gives us an expression for our welfare measure purely in terms of the history
and subsequent evolution of the extended state vector.70


4.2      A Time-Invariant Criterion for Ranking Alternative Rules
Let us suppose that we are interested in evaluating a policy rule r that implies an
equilibrium evolution of the endogenous variables of the form71

                                          yt = φr (ξ t , yt−1 ).

This (together with the law of motion for the exogenous disturbances) then implies
a law of motion for the complete extended state vector

                                          yt = ψ r (ξ t , yt−1 ).                                   (4.8)

Using this law of motion, we can evaluate (4.7), obtaining

                                       Wt0 = Wr (ξ t0 , yt0 −1 ).

We can do this for any rule r of the assumed type, and hence we can define an
optimization problem
                              max Wr (ξ t0 , yt0 −1 )                    (4.9)
                                         r∈R

in order to determine the optimal rule from among the members of some family of
rules R.
  69
      In writing the function W (·), and others that follow, we suppress the argument ξ, as the evolution
of the exogenous disturbances is the same in the case of each of the alternative policies under
consideration.
   70
      Note that it is possible to solve for the initial Lagrange multipliers ϕ∗ (yt0 −1 ) using only the
values of ỹt0 −1 and of ξ t0 −1 . It is not necessary to simulate the optimal equilibrium dynamics over a
lengthy “estimation period” prior to the date t0 at which the new policy is to commence, as proposed
by Juillard and Pelgrin (2006).
   71
      This assumption that yt depends only on the state variables indicated is without loss of gener-
ality, as we can extend the vector yt if necessary in order for this to be so.




                                                  46
    However, the solution to problem (4.9) may well depend on the initial conditions
yt0 −1 and ξ t0 for which Wt0 is evaluated.72 This leads to the possibility of an unap-
pealing degree of arbitrariness of the choice that would be recommended from within
some family of simple rules, as well as time inconsistency of the policy recommenda-
tion: a rule chosen at date t0 on the ground that it solves problem (4.9) need not be
found to also solve the corresponding problem at some later date, though the calcu-
lation at date t0 assumes that rule r is to be followed forever. One way of avoiding
this might be to assume that one should choose the rule that would be judged best
in the case of initial conditions consistent with the optimal steady state, whether the
economy’s actual initial state is that one or not;73 that is, one would choose the rule
that solves the problem
                                      max Wr (0, ȳ).
                                           r∈R
This choice would not be time-inconsistent, but the choice is still an arbitrary one.
In particular, the decision to evaluate Wr assuming initial conditions consistent with
the steady state — when in fact the state of the economy will fluctuate on both sides
of the steady-state position — favors rules r for which Wr is a less concave function
of the initial condition.
    The criterion that we find most appealing is accordingly to integrate over a dis-
tribution of possible initial conditions, rather than evaluating Wr at the economy’s
actual state at the time of the choice, or at any other single state (such as the opti-
mal steady state). Suppose that in the case of the optimal policy rule r∗ , the law of
motion (4.8) implies that the evolution of the extended state vector {yt } is station-
ary.74 In this case, there exists a well-defined invariant (or unconditional) probability
distribution µ for the possible values of yt under the optimal policy.75 Then we can
define the optimal policy rule within some class of simple rules R as the one that
solves the problem
                                     max Eµ [W̄r (yt )],                          (4.10)
                                         r∈R

  72
     This is not a problem if the family of rules R includes a fully optimal rule r∗ , since the same
rule r∗ solves the problem (2.7) for all possible values of the initial conditions. But the result can
easily depend on the initial conditions if we restrict attention to a family of suboptimal rules.
  73
     This approach is proposed by Schmitt-Grohé and Uribe (2007), though they use Vt0 rather than
Vtmod
  0
       as the criterion to be maximized.
  74
     Benigno and Woodford (2005a) provide an example of an optimal monetary stabilization policy
problem in which this is case.
  75
     We discuss the computation of the relevant properties of this invariant measure in the Appendix.

                                                 47
where76
                                  W̄r (yt ) ≡ Et Wr (ξ t+1 , yt ).                          (4.11)
Because of the linearity of our approximate characterization of optimal policy, the cal-
culations required in order to evaluate Eµ [Wr ] to second-order accuracy are straight-
forward; these are illustrated in Benigno and Woodford (2005a, sec. 5).
    The most important case in which the method just described cannot be applied is
when some of the elements of {yt } possess unit roots, though all elements are at least
difference-stationary (and some of the non-stationary elements may be cointegrated).
Note that it is possible for even the equilibrium under optimal policy to have this
property, consistent with our assumption of the bound (3.1).77 There is a question in
such a case whether our local approximation to the problem should remain an accurate
approximation, but this is not a problem in the case that random disturbances occur
in only a finite number of periods, so LQ problems of this kind may be of practical
interest.
    Let us suppose that those elements which possess unit roots are pure random
walks (i.e., with zero drift).78 We can in such a case decompose the extended state
vector as
                                   yt = yt tr + yt cyc ,
where
                                       yt tr ≡ lim Et yT
                                               T →∞

is the Beveridge-Nelson (1981) “trend” component, and the “cyclical” component
yt cyc will still be a stationary process. Moreover, the evolution of the cyclical com-
ponent as a function of the exogenous disturbances under the optimal policy will be
independent of the assumed initial value of the trend component (though not of the
  76
      Recall that we assume that the exogenous disturbance process {ξ t } is Markovian, and that
ξ t is included among the elements of yt . Hence yt contains all relevant elements of the period t
information set for the calculation of this conditional expectation.
   77
      Benigno and Woodford (2003) provide an example of an optimal stabilization policy problem in
which the LQ approximate problem has this property. In this example, the unit root is associated
with the dynamics of the level of real public debt, which display a unit root under optimal policy
for the same reason as in the classic analysis of optimal tax smoothing by Barro (1979) and Sargent
(1987, chap. XV).
   78
      We may suppose that any deterministic trend under optimal policy has been eliminated by local
expansion around a deterministic solution with constant trend growth, so that there is zero trend
in the state variables {ỹt } expressed as deviations from that deterministic solution.

                                              48
initial value of the cyclical component). It follows that we can define an invariant
distribution µ for the possible values of yt cyc under the optimal policy, that is inde-
pendent of the assumed value for the trend component. Then for any assumed initial
value for the trend component yt0 −1 tr , we can define the optimal policy rule within
the class R as the one that solves the problem

                              max Ωr (yt0 −1 tr ) ≡ Eµ [W̄r (yt0 −1 )],                        (4.12)
                               r∈R

a generalization of (4.10).79
    It might seem in this case that our criterion is again dependent on initial condi-
tions, just as with the criterion (4.9) proposed first. The following result shows that
this is not the case.

Lemma 3 Suppose that under optimal policy, the extended state vector yt consists
entirely of components that are either (i) stationary, or (ii) pure random walks. Sup-
pose also that the class of policy rules R is such that each rule in the class implies
convergence to the same long-run values of the state variables as under optimal pol-
icy, in the absence of stochastic disturbances, so that the initial value of the trend
component yttr0 −1 is the same regardless of the rule r that is considered. Then for any
rule r ∈ R, the objective Ωr (yt0 −1 tr ) defined in (4.12) can be decomposed into two
parts,
                             Ωr (yt0 −1 tr ) = Ω1 (yt0 −1 tr ) + Ω2r ,             (4.13)
where the first component is the same for all rules in this class, while the second
component is independent of the initial condition yt0 −1 tr .

Hence the criterion (4.12) establishes the same ranking of alternative rules, regardless
of the initial condition. The proof of this result is given in the Appendix.


5      Applications
The approach expounded here has already proven fruitful in a number of applications
to problems of optimal monetary and fiscal policy. Benigno and Woodford (2005a)
  79
    In the case that all elements of yt are stationary, yt tr is simply a constant, and all variations
in yt correspond to variations in yt cyc . In this case, (4.12) is equivalent to the previous criterion
(4.10).

                                                49
use this method to derive an LQ approximation to the problem of optimal monetary
stabilization policy in a DSGE model with monopolistic competition, Calvo-style
staggered price-setting, and a variety of exogenous disturbances to preferences, tech-
nology, and fiscal policy. Unlike the LQ method used by Rotemberg and Woodford
(1997) and Woodford (2002), the present method is applicable even in the case of
(possibly substantial) distortions even in the absence of shocks, owing to market
power or distorting taxes. The quadratic stabilization objective obtained is of the
form
                          1    X∞        h                           i
                        − Et0      β t−t0 qπ π 2t + qy (Ŷt − Ŷt∗ )2 ,          (5.1)
                          2    t=t      0


where π t is the inflation rate between periods t − 1 and t, Ŷt is the log deviation of
aggregate real output from trend, Ŷt∗ is a target level of output that depends purely on
the exogenous real disturbances, 0 < β < 1 is the representative household’s discount
factor, and the weights qπ , qy are functions of model parameters (both positive if
steady-state distortions are not severe). The single linear constraint corresponds to
the familiar “new Keynesian Phillips curve,”

                                 π t = κ[Ŷt − Ŷt∗ ] + βEt π t+1 + ut ,            (5.2)

where κ > 0 is a function of model parameters and the “cost-push” term ut is a linear
function of the various exogenous real disturbances.
    The resulting LQ problem is of a form that has already been extensively studied in
the literature on optimal monetary stabilization policy,80 and so the ways in which the
parameterization of the objective and constraint shape the character of optimal policy
is well understood once the problem is stated in this form. The analysis in Benigno
and Woodford (2005a), however, explains the microeconomic determinants of these
factors. For example, it provides an interpretation of the “cost-push” disturbances
that play a crucial role in familiar discussions of the tradeoffs between inflation and
output stabilization, and shows that the cost-push effects of most types of shocks are
larger the more distorted is the economy’s steady state; and it explains the relative
weight that should be assigned to the output-gap stabilization objective, showing that
this need not be positive in the case of a sufficiently distorted economy. (Indeed, if
distortions are severe, the quadratic objective can fail to be concave, so that a small
 80
      See, e.g., , Clarida et al. (1999) and Woodford (2003, chap. 7).



                                                 50
amount of policy randomization can be welfare-improving.) Benigno and Woodford
(2005b) extend the analysis to the case in which both wages and prices are sticky,
obtaining a generalization of (5.1) in which a third quadratic loss term appears,
proportional to squared deviations of nominal wage inflation from zero. This shows
that the analysis by Erceg et al. (2000) of the tradeoff between stabilization of wage
inflation and price inflation applies also to economies with distorted steady states,
though the policy tradeoffs are complicated by the presence of cost-push terms that
do not appear in those authors’ analysis of the case of an undistorted steady state.
Montoro (2007) extends the analysis to allow for real disturbances to the relative
supply price of oil.
    An important limitation of the LQ method of Rotemberg and Woodford (1997),
that restricts attention to cases in which the utility gradient is zero in the steady state,
is that it cannot easily be applied to analyses of optimal policy for open economies;
for in an open economy, domestic production and consumption cannot be equated,
and the marginal utility associated with a change in either individually will inevitably
be non-zero in any reasonable case. The method proposed here instead allows LQ
analyses of optimal policy also in the case of open economies.
    Benigno and Benigno (2006) analyze policy coordination between two national
monetary authorities which each seek to maximize the welfare of their own country’s
representative household, and show that it is possible to locally characterize each
authority’s aims by a quadratic stabilization objective. Previous LQ analyses of
policy coordination have often assumed an objective of the form (5.1) for each national
authority, but with the nation’s own inflation rate and output being the arguments
in each case. Benigno and Benigno instead show that household utility maximization
would correspond to a quadratic objective for each authority with terms penalizing
fluctuations in both domestic and foreign inflation (but with different weights on the
two terms for the distinct national authorities), and similarly with terms penalizing
fluctuations in both domestic and foreign output (again with different weights in
the case of the two authorities). They also show that each authority’s stabilization
objective should contain a term penalizing departures of the terms of trade from a
“target” level (that depends on exogenous disturbances), and show how both the
weight placed on this additional objective and the nature of variation in the terms
of trade “target” depend on underlying micro-foundations. De Paoli (2004) similarly
shows how the analysis of Benigno and Woodford (2005a) can be extended to a


                                           51
small open economy, requiring the addition of a terms-of-trade (or real-exchange-
rate) stabilization objective to the two terms shown in (5.1).
    Another advantage of the fact that the present method applies to economies with
a distorted steady state is that it can be used to analyze optimal tax smoothing when
only distorting taxes are available as sources of government revenue, after the fashion
of Barro (1979) and Sargent (1987, chap. XV), and allows the theory of tax smooth-
ing to be integrated with the theory of monetary stabilization policy. Benigno and
Woodford (2003) extend the analysis of Benigno and Woodford (2005a) to the case of
an economy with only distorting taxes, and show that the problem of choosing jointly
optimal monetary and fiscal policies can also be treated within an LQ framework that
nests standard analyses of tax smoothing (with flexible prices, so that real effects of
monetary policy are ignored) and of monetary policy (with lump-sum taxes, so that
fiscal effects of monetary policy can be ignored) as special cases. Notably, they find
that allowing for tax distortions introduces no additional stabilization goals into the
quadratic objective (5.1). Instead, the benefits of tax smoothing are represented by
the penalty on squared departures of equilibrium output from its “target” level; tax
variations can increase the average size of this term, because of the effects of the level
of distorting taxes on equilibrium output (which occur due to a “cost-push” effect of
tax rates in the generalized version of the constraint (5.2)). Benigno and De Paoli
(2005) extend this analysis to treat optimal monetary and fiscal policy in a small
open economy, while Ferrero (2005) analyzes optimal monetary and fiscal policy in
a monetary union with separate national fiscal authorities. Berriel and Sinigaglia
(2008) extend the analysis to the case of an economy with multiple sectors that differ
in the degree of stickiness of prices.
    All of the analyses just mentioned involve fairly simple DSGE models, in which it
is possible to derive the coefficients of the LQ approximate policy problem by hand.
In the case of larger (and more realistic) models of the kind that are now being esti-
mated for use in practical policy analysis, such calculations are likely to be tedious.
Nonetheless, it is an advantage of our method that it is straightforward to apply it
even to fairly complex models and fairly general specifications of disturbances. Al-
tissimo et al. (2005) describe computer code that executes the calculations explained
above, for a general nonlinear problem with an arbitrary number of state variables,
and demonstrate its application to two important extensions of the work described
above, an analysis of optimal monetary policy in the presence of non-trivial frictions


                                          52
of the kind that result in a transactions demand for money, and an analysis of optimal
monetary policy for the empirical model of Smets and Wouters. Cúrdia (2007) illus-
trates the application of the methods proposed here to another fairly complex model,
namely, a model of “sudden stops” in a small emerging-market economy; in partic-
ular, the method explained in section 4 is used to evaluate alternative simple policy
rules for such a setting. We believe that it should similarly be practical to apply these
methods to a wide variety of other models of interest to policy institutions.




                                         53
A         Appendix: Proofs and Derivations
A.1         Proposition 1
Recall that H is the Hilbert space of (real-valued) stochastic processes {ỹt } such that
                                              ∞
                                              X
                                        Et0          β t−t0 ỹt0 ỹt < ∞,             (A.1)
                                              t=t0

and H1 ⊂ H is the subspace of sequences ŷ ∈ H that satisfy the additional constraints

                                                C(L)ŷt = 0                           (A.2)

                                            Et D(L)ŷt+1 = 0                          (A.3)
for each date t ≥ t0 , along with the initial commitments

                                               D(L)ŷt0 = 0,                          (A.4)

where we define ŷt0 −1 ≡ 0 in writing (A.2) for period t = t0 and in writing (A.4).

Proposition 1 For {ỹt } ∈ H to maximize the quadratic form (2.22), subject to the
constraints (2.23) – (2.25) given initial conditions ỹt0 −1 and ḡt0 , it is necessary and
sufficient that (i) there exist Lagrange multiplier processes81 ϕ̃, λ̃ ∈ H such that the
processes {ỹt , ϕ̃t , λ̃t } satisfy (3.2) for each t ≥ t0 ; and (ii)
                                                      ∞
                                                      X
                                                 1
                        V Q (ŷ) ≡ VtQ (ŷ; 0) =   Et    β t−t0 [ŷt0 A(L)ŷt ] ≤ 0   (A.5)
                                     0
                                                 2 0 t=t
                                                               0


for all processes ŷ ∈ H1 , where in evaluating (A.5) we define ŷt0 −1 ≡ 0. A process
{ỹt } with these properties is furthermore uniquely optimal if and only if

                                                V Q (ŷ) < 0                          (A.6)

for all processes ŷ ∈ H1 that are non-zero almost surely.

    Proof: We have already remarked on the necessity of the first-order conditions
(i). To prove the necessity of the second-order condition (ii) as well, let {ỹt } ∈ H,
and consider the the perturbed process

                                                yt = ỹt + ŷt                        (A.7)
  81
       Note that ϕ̃t is also assumed to be defined for t = t0 − 1.

                                                      54
for all t ≥ t0 − 1, where {ŷt } belongs to H1 and we define ŷt0 −1 ≡ 0. This construction
guarantees that if the process {ỹt } satisfies the constraints (2.23) – (2.25), so does
the process {yt }.
    We note that
                                         X∞
                                    1
    VtQ (y; ξ)   =   VtQ (ỹ; ξ)   + Et0     β t−t0 [ŷt0 A(L)ỹt + ỹt0 A(L)ŷt + 2ŷt0 B(L)ξ t+1 ]
      0                0
                                    2    t=t   0
                              ∞
                              X
                      1
                     + Et0     β t−t0 [ŷt0 A(L)ŷt ].
                      2    t=t     0


The second term on the right-hand side is furthermore equal to
                           X∞
                     1                      ©                                    ª
                       Et0     β t−t0 ŷt0 · [A(L) + A0 (βL−1 )]ỹt + 2B(L)ξ t+1
                     2     t=t0
                           ∞
                           X                    n                                      o
                 = −Et0            β t−t0 ŷt0 · C 0 (βL−1 )λ̃t + β −1 D0 (βL−1 )ϕ̃t−1
                           t=t0
                           X∞            n 0                               o
                 = −Et0            β t−t0 λ̃t C(L)ŷt + β −1 ϕ̃0t−1 D(L)ŷt ,
                           t=t0


where we use the first-order conditions (3.2) to establish the first equality, and con-
ditions (3.3) – (3.5) to establish the final equality.
    Thus for any feasible process ỹ and any perturbation (A.7) defined by a process
ŷ belonging to H1 ,
                             VtQ0
                                  (y; ξ) = VtQ
                                             0
                                               (ỹ; ξ) + V Q (ŷ).                (A.8)
It follows that if there were to exist any ŷ ∈ H1 for which V Q (ŷ) > 0, the plan ỹ
could not be optimal. But as this is true regardless of what plan ỹ may be, (A.5) is
necessary for optimality. Furthermore, if there were to exist a non-zero ŷ for which
V Q (ŷ) = 0, it would be possible to construct a perturbation y (not equal to ỹ almost
surely at all dates) that would achieve an equally high level of welfare. Hence the
stronger version of the second-order conditions (A.6) must hold for all ŷ not equal to
zero almost surely, in order for {ỹt } to be a unique optimum.
    One easily sees from the same calculation that these conditions are also sufficient
for an optimum. Let {ỹt } be a process consistent with the constraints of the LQ
problem. Then any alternative process {yt } that is also consistent with those con-
straints can be written in the form (A.7), where ŷ is some element of H1 . If the

                                                   55
first-order conditions (3.2) are satisfied by the process {ỹt }, we can again establish
(A.8). Condition (A.5) then implies that no alternative process is preferable to {ỹt },
while (A.6) would imply that {ỹt } is superior to any alternative that is not equal to
ỹ almost surely.


A.2      Proposition 2
Proposition 2 Suppose that the exogenous disturbances have a law of motion of the
form (3.8), where Γ is a matrix the eigenvalues of which all have modulus less than
β −1/2 , and that the constraints satisfy the rank condition (3.14), where nF + ng < ny .
Then the LQ policy problem has a determinate solution, given by (3.21), if and only
if (i) there exists a solution P11 to equations (3.25) such that for each of the minors
of the matrix M defined in (3.16), det Mr has the same sign as (−1)r , for each
nF + ng + 1 ≤ r ≤ ny ; (ii) the eigenvalues of the matrix Φ11 defined in (3.22) all
have modulus less than β −1/2 ; and (iii) the matrix P22 defined in (3.26) is negative
definite, i.e., is such that its rth principle minor has the same sign as (−1)r , for each
1 ≤ r ≤ ng .



    Proof: (1) The discussion in the text has already established the necessity of
each of conditions (i)–(iii), so it remains only to show that they are also sufficient
for the solution (3.21) to represent a solution to the original infinite-horizon optimal
policy problem. We shall do this by establishing that conditions (i)–(iii) imply that
the sufficient conditions of Proposition 1 are satisfied by this solution.
    We begin by establishing that the processes {ỹt , λ̃t , ϕ̃t } associated with the solution
(3.21) satisfy the first-order conditions (3.2) for the infinite-horizon problem. We have
already shown in the text that under conditions (i)–(iii), there exists a determinate
solution (3.21) for the dynamics of {zt }, that it satisfies the bound (3.1) along with
the constraints (2.23)–(2.25), and that associated with it are a unique system of
Lagrange multipliers {λ̃t , ψ̃ t , ϕ̃t }, the solution for which has also been explained in
the text. We wish to show that these processes must satisfy (3.2) for each t ≥ t0 .
    By construction, the processes {yt† } satisfy the first-order conditions (3.15) for
each t ≥ t0 . Moreover, it follows from (3.23) that
                                                        †
                                   P1 Et zt+1 = G01 Et yt+1 .

                                             56
Substituting this into (3.15), we obtain
             1
               Et {[A(L) + A0 (βL−1 )]ỹt } + Et [B(L)ξ t+1 ]
             2
                                  +Et [C 0 (βL−1 )λ̃t ] + Et [D0 (βL−1 )ψ̃ t ] = 0            (A.9)

for each t ≥ t0 .
    Differentiating V̄ Q (zt ) with respect to h̃t , and using the envelope theorem as in
the derivation of (3.23), we obtain V̄2Q = −ψ̃ t , from which we conclude that

                                           P2 zt = −ψ̃ t

for each t ≥ t0 . Comparison with first-order condition (3.18) for the optimal choice
of h̃t+1 in the recursive policy problem indicates that

                                          ψ̃ t = β −1 ϕ̃t−1                                  (A.10)

for each t ≥ t0 + 1. We may assume (as a definition of ϕ̃t0 −1 82 ) that (A.10) holds when
t = t0 as well. Then use of (A.10) to substitute for the process {ψ̃ t } in (A.9) yields
(3.2), which accordingly must hold for each t ≥ t0 . Hence the processes constructed
to satisfy the first-order conditions of the recursive policy problem must satisfy the
first-order conditions for the infinite-horizon policy problem characterized in section
3.1 as well.

    (2) It remains to show that conditions (i)–(iii) also imply that the strict concav-
ity condition (A.6) is satisfied. Let us consider an arbitrary process ỹ ∈ H1 , and
associated with it define the process h̃ by

                                           h̃t = D(L)ỹt                                     (A.11)

for each t ≥ t0 + 1, and by the stipulation that h̃t0 = 0. We thus obtain a pair of
processes satisfying
                                    C(L)ỹt = 0,                            (A.12)
                                          D(L)ỹt = h̃t ,                                    (A.13)
                                            Et h̃t+1 = 0                                     (A.14)
  82
     Note that ϕ̃t0 −1 has no other meaning in the analysis of the recursive policy problem presented
in section 3.2.


                                               57
for all t ≥ t0 . These are furthermore an example of a process {zt } consistent with the
constraints of the recursive policy problem, in the case that ξ t = 0 at all times and
the initial precommitment is given by h̃t0 = 0.
    We note that the analysis given in the text of the single-period problem of maxi-
mizing (3.12), applied to the special case in which ξ t = 0 at all times,83 implies that
for any values of ỹt−1 and h̃t , the maximum possible attainable value of the objective
                             1 0            β
                               ỹt A(L)ỹt + Et [z0t+1 P zt+1 ]
                             2              2
consistent with constraints (A.12)–(A.14) is equal to
                                             1 0
                                              z P zt ;
                                             2 t
and this value is attained only if

                                           zt+1 = Φ zt

with certainty, which is to say, only if

                                     ỹt = Φ11 ỹt−1 + Φ12 h̃t                              (A.15)

and
                                             h̃t+1 = 0                                      (A.16)
in each possible state in period t + 1.
    Thus the fact that the processes {ỹt , h̃t } satisfy (A.12)–(A.14) for all t ≥ t0 implies
that
                            1 0              β                   1
                              ỹt A(L)ỹt + Et [z0t+1 P zt+1 ] ≤ z0t P zt
                            2                2                   2
for all t ≥ t0 , and that the inequality is strict unless (A.15)–(A.16) hold. Now if
conditions (A.15)–(A.16) hold for all t ≥ t0 , ỹt = 0 at all times. Thus in the case
that ỹt is not equal to zero almost surely for all t, there must be at least one date t1
such that at least one of these conditions is violated with positive probability when
t = t1 . In that case, there must be some k > 0 such that
                     ½                                   ¾
                       1 0                 β 0              1
                 Et0     ỹt1 A(L)ỹt1 + zt1 +1 P zt1 +1       ≤ Et0 z0t1 P zt1 − k.
                       2                   2                2
  83
    It follows from the usual principle of certainty equivalence for LQ problems that the matrices
characterizing the solution to this problem do not depend on the value of the variance-covariance
matrix Σ for the disturbances. In fact, it is easily observed that the derivations given in the text
would apply equally to a problem in which ξ t = 0 at all times.

                                               58
It then follows, by summing these inequalities (appropriately discounted) for succes-
sive periods, that
          T
          X            1               β T +1−t0                     1
    Et0          β t−t0 ỹt0 A(L)ỹt +           Et0 z0T +1 P zT +1 ≤ z0t0 P zt0 − k = −k,   (A.17)
          t=t0
                       2                   2                         2

for all T ≥ t1 .
    As we have stipulated that the process ỹ is an element of H1 , and thus satisfies
the bound (3.1), we necessarily have

                                     lim β T +1 Et0 z0T +1 P zT +1 = 0.
                                    T →∞


(Note that it follows from (A.11) that the elements of h̃ cannot grow asymptotically
at a faster rate than do the elements of ỹ.) It then follows from (A.17) that
                                              T
                                              X            1
                               lim sup Et0           β t−t0 ỹt0 A(L)ỹt ≤ −k.               (A.18)
                                   T →∞
                                              t=t0
                                                           2

But since it follows from the assumption that ỹ satisfies (3.1) that the series in (A.18)
has a limit, this limit must be no greater than −k. Hence ỹ satisfies (A.6), and all
of the sufficient conditions of Proposition 1 have been verified. This establishes the
proposition.

  Example: Suppose that yt has two elements, that the objective of policy is to
maximize                               ∞
                                 1     X
                      VtQ (ỹ) ≡   E t   β t−t0 ỹt0 Aỹt ,             (A.19)
                        0
                                 2 0 t=t
                                                            0

where A is a symmetric 2 × 2 matrix, and that the only constraint on what policy
can achieve is a single, forward-looking constraint

                                          Et [δ ỹ1,t − ỹ1,t+1 ] = 0                        (A.20)

for all t ≥ t0 , where |δ| < β −1/2 . There are no exogenous disturbances, but the expec-
tations appear because we wish to consider the possibility of (arbitrarily) randomized
policies. We assume an initial pre-commitment of the form

                                          ỹ1,t0 = δ ỹ1,t0 −1 + h̃t0 ,                      (A.21)

                                                     59
for some quantity h̃t0 .
    In the case that policy is restricted to be deterministic, the constraint completely
determines the path of {ỹ1t }; the only (perfect foresight) sequence consistent with
the initial pre-commitment and the forward-looking constraint is the one in which

                                 ỹ1,t = [δ ỹ1,t0 −1 + h̃t0 ]δ t−t0

for all t ≥ t0 . The problem then reduces to the choice of a sequence {ỹ2,t }, constrained
only by the bound (3.1), so as to maximize the objective. This is obviously a concave
problem if and only if ỹ 0 Aỹ is a concave function of ỹ2 for a given value of ỹ1 . This
in turn is true if and only if A22 < 0; the other elements of A are irrelevant.
    If instead we allow random policies, the condition just derived is no longer suffi-
cient for concavity (though still necessary). One can show that the problem is concave
if and only if A is a negative definite matrix. This is obviously a sufficient condition
(as it implies that (A.19) is concave for arbitrary sequences). To show that it is also
necessary, suppose instead that it is not true. Then there exists a vector v 6= 0 such
that v 0 Av ≥ 0. Now let {ȳt } be any process satisfying the constraints (3.1), (A.20),
and (A.21), and consider the alternative process {ỹt } generated by the law of motion

                               ỹt = ȳt + δ(ỹt−1 − ȳt−1 ) + v²t

for each t ≥ t0 + 1, starting from the initial condition (A.21), where {²t } is a (scalar-
valued) martingale-difference sequence satisfying the bound (3.1). One can easily
show that the process {ỹt } satisfies (3.1), (A.20), and (A.21) as well; moreover, the
value of the objective in the case of this process satisfies
                                                                        ∞
                                                                        X
                  VtQ
                    0
                      (ỹ) = VtQ
                               0
                                 (ȳ) + (1 − βδ 2 )−1 v 0 Av Et0                 β t ²2t
                                                                       t=t0 +1

                           ≥   VtQ
                                 0
                                   (ȳ).

Since we can construct an alternative policy that is at least as good in the case of
any policy, there is no uniquely optimal policy in such a case; and in addition, we
have shown that arbitrary randomization of policy is possible without welfare loss.
    Let us examine how these results compare with the conditions stated in Proposi-
tion 2. In this example, condition (3.25) states that
                                           "       #
                                             1 0
                                 P11 = α             ,
                                             0 0

                                               60
where
                                    α = −δ 2 [M −1 ]33 .
This form for P11 implies in turn that M is invertible as long as A22 6= 0, and that in
that case,
                                                  |A|
                               [M −1 ]33 = −αβ −      .
                                                  A22
Hence we obtain a unique solution,
                                            δ 2 |A|
                                    α=                .
                                         1 − βδ 2 A22
Since nF = 0, ng = 1, ny = 2, condition (i) of the proposition holds if and only if
det M2 = det M > 0, and under the above solution for P11 , det M = −A22 ; hence
condition (i) reduces to the requirement that A22 < 0.
    This solution for P11 , and hence for M, also implies that
                                     "                 #
                                            δ       0
                               Φ11 =                     .
                                        −δA21 /A22 0
Hence the eigenvalues of Φ11 are 0 and δ. Thus under our assumption about δ,
condition (ii) is necessarily satisfied, as long as A22 6= 0 (so that Φ11 exists). We
observe that both conditions (i) and (ii) hold if and only if A22 < 0, which is just the
concavity condition derived above for the deterministic policy problem.
   The solution for P11 similarly implies that
                                                              1    |A|
                    P22 = −G02 M −1 G2 = −[M −1 ]33 =            2     .
                                                           1 − βδ A22
Since the numerator in this last expression is positive, condition (iii) holds (in addition
to the other two conditions) if and only if we also have det A > 0. Since A is negative
definite if and only if A22 < 0 and det A > 0, we can alternatively state that condition
(iii) holds (in addition to the other two) if and only if A is also negative definite.
This is the additional condition derived above for concavity in the case of stochastic
policies.


A.3     Lemma 3
Lemma 3 Suppose that under optimal policy, the extended state vector yt consists
entirely of components that are either (i) stationary, or (ii) pure random walks. Sup-
pose also that the class of policy rules R is such that each rule in the class implies

                                           61
convergence to the same long-run values of the state variables as under optimal pol-
icy, in the absence of stochastic disturbances, so that the initial value of the trend
component yttr0 −1 is the same regardless of the rule r that is considered. Then for any
rule r ∈ R, the objective

                             Ωr (yt0 −1 tr ) ≡ Eµ [W̄r (yt0 −1 )],                (A.22)

can be decomposed into two parts,

                            Ωr (yt0 −1 tr ) = Ω1 (yt0 −1 tr ) + Ω2r ,             (A.23)

where the first component is the same for all rules in this class, while the second
component is independent of the initial condition yt0 −1 tr .


    Proof: We restrict attention to a class of rules R with the property that each rule
in the class implies convergence to the same long-run values of the state variables as
under optimal policy, in the absence of stochastic disturbances. Because we analyze
the dynamics under a given policy using a linearized version of the structural relations,
certainty-equivalence obtains, and it follows that the limiting behavior (as T → ∞)
of the long-run forecast Et0 [yT ] must also be the same under any rule r ∈ R, given
the initial conditions yt0 −1 . Thus given these initial conditions, the decomposition
of the initial extended state vector into components yt0 −1 tr and yt0 −1 cyc is the same
under any rule r ∈ R.
    Let us consider the decomposition

                                        ỹt = ȳt + ŷt ,

where {ȳt } is the deterministic sequence

                                        ȳt ≡ Et0 −1 ỹt

and ŷt is the component of ỹt that is unforecastable as of date t0 − 1. Then if we
evaluate
                      W̄ (ỹ; yt0 −1 ) ≡ Et0 −1 W (ỹ; ξ t0 , yt0 −1 ),
where W is the quadratic form defined in (4.7), under the evolution implied by any
rule r, we find that

                     W̄ (ỹ; yt0 −1 ) = W̄ (ȳ; yt0 −1 ) + W̄ (ŷ; yt0 −1 ).      (A.24)

                                             62
Here all the cross terms in the quadratic form have conditional expectation zero
because ȳ is deterministic while ŷ is unforecastable.
    Moreover, under any rule r, the value of ŷt is a linear function of the sequence of
unexpected shocks between periods t0 and t, that is independent of the initial state.
(This independence follows from the linearity of the law of motion (4.8), under the
linear approximation that we use to solve for the equilibrium dynamics under a given
policy rule.) Hence the second term on the right-hand side of (A.24),84

                                 W̄ (ŷ; yt0 −1 ) = Et0 −1 VtQ
                                                             0
                                                               (ŷ),

is independent of the initial state yt0 −1 as well. Let W̄r2 denote the value of this
expression associated with a given rule r.
    Instead, the value of ȳt will be a linear function of yt0 −1 , again as a result of
the linearity of (4.8). And in our LQ problem with a self-consistent initial pre-
commitment, the function (4.6) is linear as well. It follows that the first term on the
right-hand side of (A.24) is a quadratic function of yt0 −1 ,

                                W̄ (ȳ; yt0 −1 ) = yt0 0 −1 Ξr yt0 −1 ,

where the subscript r indicates that the matrix of coefficients Ξr can depend on the
policy rule that is chosen. Then substituting yttr0 −1 + ytcyc
                                                             0 −1
                                                                  for yt0 −1 in the above
expression, and integrating over possible initial values of the cyclical component, for
a given initial value of the trend component, we observe that

                    Eµ [W̄ (ȳ; yt0 −1 )] = yttr0  Ξ ytr + Eµ [ycyc0 Ξr ycyc ],
                                               0 −1 r t0 −1
                                                                                          (A.25)

using the fact that Eµ [ycyc ] = 0.
   Finally, we observe that under any rule r, the linearity of the law of motion (4.8)
implies that conditional forecasts of the evolution of the endogenous variables take
the form
                          Et0 −1 yT = yttr0 −1 + BT +1−t0 yt0 −1 cyc ,
where the sequence of matrices {Bj } may depend on the rule r, but the first term
on the right-hand side is the same for all rules in the class R. Using this solution for
the sequence ȳ to evaluate W̄ (ȳ; yt0 −1 ), we find that the first term in (A.25) must
  84
    Here the expected value of the second term on the right-hand side of (4.7) vanishes because of
the unforecastability of ŷt0 .

                                                63
be a quadratic function of yttr0 −1 that is the same for all rules r, that can be denoted
yttr0
   0 −1
        Ξ̄yttr0 −1 . Thus if we integrate (A.24) over the invariant distribution µ, we obtain

                  Eµ [W̄r (yt0 −1 )] = yttr0
                                          0 −1
                                               Ξ̄yttr0 −1 + Eµ [ycyc0 Ξr ycyc ] + W̄r2 ,

which is precisely a decomposition of the asserted form (A.23). This proves that the
criterion (A.22) establishes the same ranking of alternative rules, regardless of the
initial condition.


A.4      Computing the Invariant Measure µ
We need to know the invariant distribution µ over possible initial conditions under
optimal policy, in order to compute the proposed welfare criterion (4.12). Because
W̄r (·) is a quadratic function, we only need to compute the unconditional mean and
variance-covariance matrix of yt cyc under optimal policy.
    Substituting (3.19) for the pre-commitment h̃t+1 in the solution (3.17) for the
optimal choice of ỹt+1 , we observe that under the solution to the recursive policy
problem (and hence under the solution to the original problem as well), ỹt+1 is a
linear function of ỹt , ξ t+1 , and ξ t , for each t ≥ t0 . This solution together with the
process (3.8) for the exogenous disturbances imply a law of motion of the form

                                       yt+1 = Φ̄ yt + Ψ̄ ²t+1                                (A.26)

for the extended state vector                      "         #
                                                       ỹt
                                            yt ≡                 .                           (A.27)
                                                       ξt
   Under this law of motion, the trend component of the extended state vector is
given by yt tr = Πyt , where Π is the matrix85

                                            Π ≡ lim Φ̄j ,
                                                   j→∞

and the cyclical component is correspondingly given by yt cyc = [I − Π]yt . It then
follows that the law of motion for the cyclical component is

                              yt+1 cyc = Φ̄ yt cyc + [I − Π]Ψ̄ ²t+1 .                        (A.28)
  85
     Under the assumption (made in the text) that the extended state vector is difference-stationary,
this limit must be well-defined.

                                                 64
We note furthermore that (A.28) describes a jointly stationary set of processes, since
the matrix Φ̄ is stable on the subspace of vectors v of the form v = [I − Π]y for some
vector y.86 Hence there exist a well-defined vector of unconditional means E and an
unconditional variance-covariance matrix V. The unconditional means are all zero,
while the matrix V is given by the solution to the linear equation system

                             V = Φ̄VΦ̄0 + [I − Π]Ψ̄ΣΨ̄0 [I − Π0 ].

    In the case of some policy rules, it may be necessary to include additional lags of ỹt
or ξ t in the extended state vector yt , in order for the equilibrium dynamics under the
rule r to have a representation of the form (4.8). However, in this case, the additional
elements of ytcyc will all be lags of elements of the vector considered above. Hence
the law of motion (A.28) can be used to derive the relevant unconditional moments
in this case as well (though we omit the algebra).




  86
     When restricted to this subspace, the operator Φ̄ has eigenvalues consisting of those eigenvalues
of Φ̄ that are less than one in modulus; these are in turn a subset of the eigenvalues of Φ that are
less than one in modulus (some zero eigenvalues have been dropped).

                                               65
References
[1] Altissimo, Filippo, Vasco Cúrdia, and Diego Rodriguez Palenzuela (2005),
    “Linear-Quadratic Approximation to Optimal Policy: An Algorithm and Two
    Applications,” paper presented at the conference “Quantitative Analysis of Sta-
    bilization Policies,” Columbia University, September.

[2] Amman, Hans (1996), “Numerical Methods for Linear-Quadratic Models,” in
    H.M. Amman, D.A. Kendrick, and J. Rust, eds., Handbook of Computational
    Economics, Volume 1, Amsterdam: North-Holland.

[3] Amman, Hans M., and David A. Kendrick (1999), “The Duali/Dualpc Software
    for Optimal Control Models: User’s Guide,” Center for Applied Research in
    Economics, University of Texas.

[4] Anderson, Evan W., Lars Peter Hansen, Ellen R. McGrattan, and Thomas
    J. Sargent (1996), “Mechanics of Forming and Estimating Dynamic Linear
    Economies,” in H.M. Amman, D.A. Kendrick, and J. Rust, eds., Handbook
    of Computational Economics, Volume 1, Amsterdam: North-Holland.

[5] Backus, David, and John Driffill (1986), “The Consistency of Optimal Policy in
    Stochastic Rational Expectations Models,” CEPR Discussion Paper No. 124.

[6] Barro, Robert J. (1979), “On the Determination of Public Debt,” Journal of
    Political Economy 87: 940-971.

[7] Benigno, Gianluca, and Pierpaolo Benigno (2006), “Designing Targeting Rules
    for International Monetary Policy Cooperation,” Journal of Monetary Eco-
    nomics, 53(3), pages 473-506.

[8] Benigno, Gianluca and Bianca De Paoli (2005), “Optimal Monetary and Fiscal
    Policy for a Small Open Economy,” unpublished manuscript, London School of
    Economics.

[9] Benigno, Pierpaolo, and Michael Woodford (2003), “Optimal Monetary and Fis-
    cal Policy: A Linear-Quadratic Approach,” in M. Gertler and K. Rogoff, eds.,
    NBER Macroeconomics Annual 2003, Cambridge, MA: MIT Press.



                                      66
[10] Benigno, Pierpaolo, and Michael Woodford (2005a), “Inflation Stabilization And
     Welfare: The Case Of A Distorted Steady State,” Journal of the European
     Economic Association, vol. 3(6), pages 1185-1236, December.

[11] Benigno, Pierpaolo, and Michael Woodford (2005b), “Optimal Stabilization Pol-
     icy when Wages and Prices are Sticky: The Case of a Distorted Steady State,”
     in J. Faust, A. Orphanides, and D. Reifschneider (eds.) Models and Monetary
     Policy, Board of Governors of the Federal Reserve System: Washington, pp.
     127-180.

[12] Benigno, Pierpaolo, and Michael Woodford (2006a), “Optimal Taxation in an
     RBC Model: A Linear Quadratic Approach,” Journal of Economic Dynamics
     and Control, 30(9-10): 1445-1489.

[13] Benigno, Pierpaolo, and Michael Woodford (2006b), “Linear-Quadratic Approx-
     imation of Optimal Policy Problems,” NBER Working Paper no. 12672, Novem-
     ber.

[14] Berriel, Tiago, and Daniel Sinigaglia (2008), “Optimal Fiscal and Monetary
     Policy under Sectoral Heterogeneity,” unpublished, Princeton University, April.

[15] Bertsekas, Dimitri P. (1976), Dynamic Programming and Stochastic Control,
     New York: Academic Press.

[16] Blake, Andrew P. (2001), “A ‘Timeless Perspective’ on Optimality in Forward-
     Looking Rational Expectations Models,” NIESR Discussion Papers 188, National
     Institute of Economic and Social Research.

[17] Chow, Gregory C. (1975), Analysis and Control of Dynamic Economic Systems
     John Wiley & Sons, New York.

[18] Clarida, Richard, Jordi Gali and Mark Gertler (1999), “The Science of Monetary
     Policy: A New Keynesian Perspective,” Journal of Economic Literature 37: 1661-
     1707.

[19] Cúrdia, Vasco (2007), “Optimal Monetary Policy under Sudden Stops,” unpub-
     lished, Federal Reserve Bank of New York, April.



                                       67
[20] Damjanovic, Tatiana, Vladislav Damjanovic, and Charles Nolan (2008), “Linear-
     Quadratic Approximation to Unconditionally Optimal Policy: The Distorted
     Steady State,” unpublished, University of St. Andrews, February.

[21] Debreu, Gerard (1952), “Definite and Semidefinite Quadratic Forms,” Econo-
     metrica 20: 295-300.

[22] De Paoli, Bianca (2004), “Monetary Policy and Welfare in a Small Open Econ-
     omy,” unpublished manuscript, London School of Economics.

[23] Diaz-Gimenez, Javier (1999), “Linear-Quadratic Approximations: An Introduc-
     tion,” in Ramon Marimon and Andrew Scott, editors, Computational Methods
     for the Study of Dynamic Economies, Oxford: Oxford University Press.

[24] Erceg, Christopher J., Dale W. Henderson, and Andrew T. Levin (2000), “Op-
     timal Monetary Policy with Staggered Wage and Price Contracts,” Journal of
     Monetary Economics 46: 281-313.

[25] Ferrero, Andrea (2005), “Fiscal and Monetary Rules for a Currency Union,”
     unpublished manuscript, New York University.

[26] Fleming, Wendell H. (1971), “Stochastic Control for Small Noise Intensities,”
     SIAM Journal of Control 9: 473-517.

[27] Gerali, Andrea and Francesco Lippi (2005), “Solving Dynamic Linear-Quadratic
     Problems with Forward-Looking Variables and Imperfect Information using Mat-
     lab,” unpublished, Bank of Italy, November.

[28] Giannoni, Marc, and Michael Woodford (2002), “Optimal Interest-Rate Rules:
     I. General Theory,”NBER Working Paper no. 9419, December.

[29] Hansen, Lars P., and Thomas J. Sargent (2004), Recursive Models of Dynamic
     Linear Economies, unpublished, University of Chicago, August 2004.

[30] Jensen, Christian, and Bennet C. McCallum (2002), “The Non-Optimality of
     Proposed Monetary Policy Rules Under Timeless-Perspective Commitment,”
     NBER Working Paper No. 8882.



                                      68
[31] Jin, Hehui, and Kenneth L. Judd (2002), “Perturbation Methods for General
     Dynamic Stochastic Models,” unpublished, Stanford University.

[32] Judd, Kenneth L. (1996), “Approximation, Perturbation and Projection Meth-
     ods in Economic Analysis,” in H.M. Amman, D.A. Kendrick, and J. Rust, eds.,
     Handbook of Computational Economics, Volume 1, Amsterdam: North-Holland.

[33] Judd, Kenneth L. (1998), Numerical Methods In Economomics, Cambridge,
     Mass.: MIT Press.

[34] Judd, Kenneth L., and Sy-Ming Guu (2001), “Asymptotic Methods for Asset
     Market Equilibrium Analysis,” Economic Theory 18: 127-157.

[35] Juillard, Michel, and Florian Pelgrin (2006), “Computing Optimal Policy in a
     Timeless Perspective: An Application to a Small Open Economy,” unpublished,
     University of Paris VIII, September.

[36] Kalchbrenner, J.H., and Peter A. Tinsley (1975), “On the Use of Optimal Control
     in the Design of Monetary Policy,” Special Studies Paper No. 76, Federal Reserve
     Board.

[37] Kendrick, David A. (1981), Stochastic Control for Economic Models, New York:
     McGraw-Hill.

[38] Kendrick, David A. (2005), “Stochastic Control for Economic Models: Past,
     Present and the Paths Ahead,” Journal of Economic Dynamics and Control 29:
     3-30.

[39] Khan, Aubhik, Robert G. King, and Alexander L. Wolman (2003), “Optimal
     Monetary Policy,” Review of Economic Studies 70(4): 825-860.

[40] Kim, Jinill, and Sunghyun Kim (2003), “Spurious Welfare Reversal in Interna-
     tional Business Cycle Models”, Journal of International Economics, Volume 60,
     Issue 2, Pages 471-500 .

[41] Kim, Jinill, and Sunghyun Kim (2006), “Two Pitfalls of Linearization Methods,”
     unpublished, Federal Reserve Board, April. (Forthcoming, Journal of Money,
     Credit and Banking.)


                                       69
[42] Kim, Jinill, Sunghyun Kim, Ernst Schaumburg, and Christopher A. Sims (2003),
     “Calculating and Using Second Order Accurate Solutions of Discrete Time Dy-
     namic Equilibrium Models,” unpublished manuscript, University of Virginia,
     June. (Forthcoming, Journal of Economic Dynamics and Control.)

[43] Kim, Jinill, Andrew T. Levin, and Tack Yun (2007), “Diagnosing and Treat-
     ing Bifurcations in Perturbation Analysis of Dynamic Macro Models,” FEDS
     discussion paper no. 2007-14, March.

[44] King, Robert G., and Alexander L. Wolman (1999), “What Should the Monetary
     Authority Do When Prices are Sticky?” in J.B. Taylor, ed., Monetary Policy
     Rules, Chicago: University of Chicago Press.

[45] Kydland, Finn E., and Edward C. Prescott (1980), “Dynamic Optimal Taxation,
     Rational Expectations and Optimal Control,” Journal of Economic Dynamics
     and Control 2: 79-91.

[46] Kydland, Finn E., and Edward C. Prescott (1982), “Time to Build and Aggregate
     Fluctuations,” Econometrica, vol. 50(6), pages 1345-70, November.

[47] Kwakernaak, Huibert, and Raphael Sivan (1972), Linear Optimal Control Sys-
     tems, New York: Wiley.

[48] LeRoy, Stephen F., and Roger N. Waud (1977), “Applications of the Kalman
     Filter in Short-run Monetary Control,” International Economic Review 18, 195–
     207.

[49] Levine, Paul, Joseph Pearlman, and Richard Pierse (2007), “Linear-Quadratic
     Approximation, External Habit, and Targeting Rules,” ECB Working Paper no.
     759, June. (Forthcoming, Journal of Economic Dynamics and Control.)

[50] Magill, Michael J.P. (1977), “A Local Analysis of N-Sector Capital Accumulation
     under Uncertainty,” Journal of Economic Theory 15: 211-218.

[51] Marcet, Albert, and Ramon Marimon (1998), “Recursive Contracts,” Universitat
     Pompeu Fabra working paper no. 337, October.

[52] Montoro, Carlos (2007), “Oil Shocks and Optimal Monetary Policy,” unpub-
     lished, Banco Central de Reserva del Peru, June.

                                       70
[53] Rotemberg, Julio J., and Michael Woodford (1997), “An Optimization-Based
     Econometric Framework for the Evaluation of Monetary Policy,” NBER Macroe-
     conomics Annual 12: 297-346.

[54] Sargent, Thomas J. (1987), Macroeconomic Theory, 2d edition, New York: Aca-
     demic Press.

[55] Schmitt-Grohé, Stephanie, and Martin Uribe (2004a), “Solving Dynamic Gen-
     eral Equilibrium Models Using a Second-Order Approximation to the Policy
     Function,” Journal of Economic Dynamics and Control, vol. 28, pp. 755-775.

[56] Schmitt-Grohé, Stephanie, and Martin Uribe (2004b), “Optimal Fiscal and Mon-
     etary Policy under Sticky Prices,” Journal of Economic Theory vol. 114, pp.
     198-230.

[57] Schmitt-Grohé, Stephanie, and Martin Uribe (2007), Journal of Monetary Eco-
     nomics, 54: 17021725.

[58] Söderlind, Paul (1999), “Solution and estimation of RE macromodels with opti-
     mal policy,” European Economic Review, vol. 43(4-6), pages 813-823, April.

[59] Sutherland, Alan (2002), “A Simple Second-Order Solution Method for Dynamic
     General Equilibrium Models,” CEPR discussion paper no. 3554, July.

[60] Takayama, Akira (1985), Mathematical Economics, Cambridge: Cambridge Uni-
     versity Press, 2d ed.

[61] Woodford, Michael (2002), “Inflation Stabilization and Welfare,” Contributions
     to Macroeconomics 2(1), Article 1. [www.bepress.com]

[62] Woodford, Michael (2003), Interest and Prices: Foundations of a Theory of
     Monetary Policy, Princeton: Princeton University Press.




                                       71
