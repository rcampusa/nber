                                NBER WORKING PAPER SERIES




     PRICING MODEL PERFORMANCE AND THE TWO-PASS CROSS-SECTIONAL
                       REGRESSION METHODOLOGY

                                            Raymond Kan
                                            Cesare Robotti
                                             Jay Shanken

                                        Working Paper 15047
                                http://www.nber.org/papers/w15047


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                      June 2009




We thank Pierluigi Balduzzi, Christopher Baum, Tarun Chordia, Wayne Ferson, Nikolay Gospodinov,
Ravi Jagannathan, Ralitsa Petkova, Yaxuan Qi, Guofu Zhou, seminar participants at the Board of Governors
of the Federal Reserve System, Concordia University, Federal Reserve Bank of Atlanta, Federal Reserve
Bank of New York, University of Toronto, and participants at the 2009 Meetings of the Association
of Private Enterprise Education, the 2009 CIREQ-CIRANO Financial Econometrics Conference, and
the 2009 FIRS Conference for helpful discussions and comments. Kan gratefully acknowledges financial
support from the National Bank Financial of Canada. The views expressed herein are those of the author(s)
and do not necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2009 by Raymond Kan, Cesare Robotti, and Jay Shanken. All rights reserved. Short sections of
text, not to exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including © notice, is given to the source.
Pricing Model Performance and the Two-Pass Cross-Sectional Regression Methodology
Raymond Kan, Cesare Robotti, and Jay Shanken
NBER Working Paper No. 15047
June 2009
JEL No. C1,C12,C13,C4,C52,G12

                                               ABSTRACT

Since Black, Jensen, and Scholes (1972) and Fama and MacBeth (1973), the two-pass cross-sectional
regression (CSR) methodology has become the most popular approach for estimating and testing asset
pricing models. Statistical inference with this method is typically conducted under the assumption
that the models are correctly specified, i.e., expected returns are exactly linear in asset betas. This can be
a problem in practice since all models are, at best, approximations of reality and are likely to be subject
to a certain degree of misspecification. We propose a general methodology for computing misspecification-
robust asymptotic standard errors of the risk premia estimates. We also derive the asymptotic distribution
of the sample CSR R2 and develop a test of whether two competing beta pricing models have the same
population R2. This provides a formal alternative to the common heuristic of simply comparing the
R2 estimates in evaluating relative model performance. Finally, we provide an empirical application
which demonstrates the importance of our new results when applied to a variety of asset pricing models.


Raymond Kan                                           Jay Shanken
University of Toronto                                 Goizueta Business School
105 St. George Street                                 Emory University
Toronto, Ontario                                      1300 Clifton Road
Canada M5S 3E6                                        Atlanta, GA 30322
kan@chass.utoronto.ca                                 and NBER
                                                      jay_shanken@bus.emory.edu
Cesare Robotti
Federal Reserve Bank of Atlanta
Research Department
1000 Peachtree Street N.E.
Atlanta, Georgia 30309-4470
CRobotti@frbatlanta.org
I.         Introduction
In the empirical asset pricing literature, the popular two-pass cross-sectional regression (CSR)
methodology developed by Black, Jensen, and Scholes (1972) and Fama and MacBeth (1973) is
often used for estimating risk premia and testing pricing models that relate expected security
returns to security betas on economic factors (beta pricing models). Although there are many
variations of this two-pass methodology, the basic approach always involves two steps. In the
first pass, the betas of the test assets are estimated from ordinary least squares (OLS) time series
regressions of returns on some common factors. In the second pass, the returns on test assets
are regressed on the betas estimated from the first pass. By running this second-pass CSR on a
period-by-period basis, we obtain time series of the intercept and slope coefficients. The average
values of these coefficients are then used as estimates of the zero-beta rate and factor risk premia,
with standard errors computed from these time series as well.

         Since the betas are estimated with error in the first-pass time series regressions, an errors-in-
variables (EIV) problem is introduced in the second-pass CSR. Measurement errors in the betas
cause two problems. The first is that the estimated zero-beta rate and risk premia are biased,
though Shanken (1992) shows they are consistent as the length of the time series increases to
infinity. The second problem is that the usual Fama-MacBeth standard errors for the estimated
zero-beta rate and risk premia are inconsistent. Shanken (1992) addresses this by developing an
asymptotically valid EIV adjustment of the standard errors. Jagannathan and Wang (1998) extend
this asymptotic analysis by relaxing the assumption that returns are homoskedastic conditional on
the factors.1 Finally, the finite sample properties of these two-pass estimators have been studied
by Ahn and Gadarowski (2003), Chen and Kan (2003), and Shanken and Zhou (2007).

         Standard inference using the two-pass methodology implicitly assumes that expected returns are
exactly linear in the betas, i.e., the beta pricing model is correctly specified. It is difficult to justify
this assumption when estimating many different models because some (if not all) of the models
are bound to be misspecified. Moreover, since asset pricing models are, at best, approximations of
reality, it is inevitable that we will often, knowingly or unknowingly (because of limited power),
estimate an expected return relation that departs from exact linearity in the betas. The first
contribution of this paper is the development of misspecification-robust asymptotic standard errors

     1
         Jagannathan, Skoulakis and Wang (2008) provide a synthesis of the two-pass CSR methodology.


                                                           1
for the estimated zero-beta rate and risk premia. Our analysis generalizes the results of Hou and
Kimmel (2006) and Shanken and Zhou (2007), which are derived under a normality assumption.

    One nice feature of our robust standard errors is that they are applicable whether a model
is correctly specified or not. In addition, under a multivariate elliptical assumption, we provide
simple expressions for the asymptotic variances of the zero-beta rate and risk premia estimates.
In the case of the generalized least squares (GLS) CSR estimators, we prove that the variances
are always larger when the model is misspecified. The difference depends on the extent of model
misspecification as well as on the correlation between the factors and returns. We show that the
misspecification adjustment term can be very large when the underlying factor is poorly mimicked
by asset returns, a situation that typically arises when the factors are macroeconomic variables.

    Judgement about the empirical success of a beta pricing model is often based on its cross-
sectional R2 . A high value is usually considered evidence that the model does a good job of
explaining the cross-section of expected returns. Several papers have analyzed the properties of the
population values of the cross-sectional R2 measures. Although there is an exact linear relation be-
tween expected returns and betas when a market index (factor portfolio) is mean-variance efficient,
Roll and Ross (1994) show that there may be no relation at all, i.e., an OLS R2 of zero, even if an
index is nearly efficient. Kandel and Stambaugh (1995) document related limitations of the OLS
R2 and show that there is a direct relation between the GLS R2 and the relative efficiency of an
index. Lewellen, Nagel and Shanken (2009) provide a multifactor generalization of this result, with
mimicking portfolios substituted for non-traded factors. They also argue, as do Jagannathan and
Wang (1996), that the OLS R2 can still be economically meaningful if the objective is to model
the expected returns for a particular set of assets.

    Jagannathan, Kubota, and Takehara (1998), Kan and Zhang (1999), Jagannathan and Wang
(2007), and Lewellen, Nagel, and Shanken (2009) employ simulation methods to explore sampling
issues in estimating the cross-sectional R2 .2 However, to our knowledge no attempt has been made
to derive the asymptotic distribution of the sample cross-sectional R2 . Building on our analysis of
parameter estimation under potential model misspecification, the second contribution of this paper
is to characterize the asymptotic distribution of the sample R2, thereby filling a significant gap in
   2
     In contrast to our paper, Jagannathan, Kubota, and Takehara (1998), Kan and Zhang (1999), and Jagannathan
and Wang (2007) examine the sampling errors of the CSR R2 and risk premia estimates under the assumption that
one of the factors is useless (i.e., independent of returns).


                                                      2
the literature.

   Finally, although R2 s for competing models are routinely compared in empirical asset pricing
studies, no formal model comparison test has yet been proposed in this context. This is essential
since the R2 statistics are subject to considerable statistical variation. Consequently, a model with
a higher sample R2 may not truly outperform its competitor. The third contribution of this paper
is the introduction of a methodology to formally test whether two beta pricing models have the
same population R2. We find that the asymptotic distribution of the difference in sample R2s
of two models depends on whether the models are correctly specified or not, and on whether the
models are nested or non-nested.

   After developing the econometric methodology, we provide an in-depth empirical analysis that
demonstrates the relevance of our new tests. We examine the performance of a variety of uncon-
ditional and conditional beta pricing models that have been proposed as refinements of the static
capital asset pricing model (CAPM) and consumption CAPM (CCAPM). We start by investigat-
ing whether these models pass a specification test based on the sample cross-sectional R2 and find
that, in many instances, the models are rejected at conventional statistical levels. This provides
compelling motivation to explicitly account for model misspecification in the subsequent empirical
analysis of R2s.

   Next, we examine whether model misspecification substantially affects the standard errors of
the zero-beta rate and risk premia estimates. Consistent with our theoretical results, we find that
the t-ratios are about the same under correctly specified and potentially misspecified models when
the underlying factors are returns on well diversified portfolios. However, standard errors can differ
substantially when the underlying factors are not traded, e.g., macroeconomic factors.

   Finally, we analyze whether different beta pricing models have significantly different cross-
sectional R2 measures. It appears that the commonly used returns and factors are sometimes too
noisy to conclude that one model clearly outperforms the others. For example, using the commonly
employed 25 size and book-to-market ranked portfolios as test assets, there is not much statistical
evidence to establish that the five-factor intertemporal capital asset pricing model (ICAPM) of
Petkova (2006) outperforms even the simple unconditional CAPM in terms of cross-sectional R2 .
However, the advantage of the Fama and French (1993) three-factor model over the CAPM is
statistically significant for this metric.

                                                  3
         The rest of the paper is organized as follows. Section II presents an asymptotic analysis of the
zero-beta rate and risk premia estimates under potentially misspecified models. We also consider an
alternative CSR approach that uses covariances with the factors, rather than (multiple regression)
betas, as the regressors. In addition, we provide an asymptotic analysis of the sample cross-sectional
R2 s under correctly specified and misspecified models. Section III introduces tests of equality of
cross-sectional R2s for two competing models and provides the asymptotic distributions of the test
statistics for different scenarios. Section IV presents an empirical application. The final section
summarizes our findings and the Appendix contains proofs of all propositions.


II.         Asymptotic Analysis under Potentially Misspecified Models

A.        Population Measures of Pricing Errors and Cross-Sectional R2 s

Let f be a K-vector of factors and R a vector of returns on N test assets. We define Y = [f 0 , R0 ]0
and its mean and covariance matrix as
                                                          "        #
                                                              µ1
                                        µ = E[Y ] ≡                ,                                             (1)
                                                              µ2
                                                              "         #
                                                                V11 V12
                                       V    = Var[Y ] ≡                     ,                                    (2)
                                                               V21 V22

where V is assumed to be positive definite.3 The multiple regression betas of the N assets with
                                                 −1
respect to the K factors are defined as β = V21V11  . These are measures of systematic risk or the
sensitivity of returns to the factors. In addition, we denote the covariance matrix of the residuals
                                  −1
of the N assets by Σ = V22 − V21V11  V12.

         The proposed K-factor beta pricing model specifies that asset expected returns are linear in
the betas, i.e.,
                                                    µ2 = Xγ,                                                     (3)

where X = [1N , β] is assumed to be of full column rank, 1N is an N -vector of ones, and γ = [γ0, γ10 ]0
is a vector consisting of the zero-beta rate (γ0) and risk premia on the K factors (γ1).4 When the
     3
     For most of our analysis, we only need to assume V11 is nonsingular and V21 is of full column rank. For the case
of GLS CSR, we also need to assume V22 is nonsingular.
   4
     Note that constant portfolio characteristics can easily be accommodated in the CSR without creating any addi-
tional complication. The analysis that includes asset characteristics is available upon request.


                                                         4
model is misspecified, the pricing-error vector, µ2 − Xγ, will be nonzero for all values of γ. In that
case, it makes sense to choose γ to minimize some aggregation of pricing errors. Denoting by W
an N × N symmetric positive definite weighting matrix, we define the (pseudo) zero-beta rate and
risk premia as the choice of γ that minimizes the quadratic form of pricing errors:
                          
                     γW,0
             γW ≡            = argminγ (µ2 − Xγ)0W (µ2 − Xγ) = (X 0W X)−1 X 0W µ2 .               (4)
                     γW,1
The corresponding pricing errors of the N assets are then given by

                                          eW = µ2 − XγW .                                         (5)

   In addition to aggregating the pricing errors, researchers are often interested in a normalized
goodness-of-fit measure for a model. A popular measure is the cross-sectional R2 . Following Kandel
and Stambaugh (1995), this is defined as
                                                       Q
                                           ρ2W = 1 −      ,                                       (6)
                                                       Q0
where

        Q0 = min(µ2 − 1N γ0)0W (µ2 − 1N γ0 ) = µ02 W µ2 − µ02 W 1N (10N W 1N )−1 10N W µ2 ,       (7)
                   γ0

         Q = e0W W eW = µ02 W µ2 − µ02 W X(X 0W X)−1 X 0W µ2 .                                    (8)

In order for ρ2W to be well defined, we need to assume that µ2 is not proportional to 1N (the
expected returns are not all equal) so that Q0 > 0. Note that 0 ≤ ρ2W ≤ 1 and it is a decreasing
function of the aggregate pricing-error measure Q = e0W W eW . Thus, ρ2W is a natural measure of
goodness of fit.

   While the betas are typically used as the regressors in the second-pass CSR, there is a potential
issue with the use of multiple regression betas when K > 1: in general, the beta of an asset with
respect to a particular factor depends on what other factors are included in the first-pass time-
series OLS regression. As a consequence, the interpretation of the risk premia γ1 in the context
of model selection can be problematic (more discussion on this issue later in Section III.A). To
overcome this problem, we propose an alternative second-pass CSR that uses the covariances V21
as the regressors. Let C = [1N , V21] and λW be the choice of coefficients that minimizes the
quadratic form of pricing errors:
                           
                      λW,0
             λW ≡             = argminλ(µ2 − Cλ)0W (µ2 − Cλ) = (C 0 W C)−1 C 0 W µ2 .             (9)
                      λW,1

                                                  5
Given (4) and (9), there is a one-to-one correspondence between γW and λW :

                                                                          −1
                                       λW,0 = γW,0,              λW,1 = V11  γW,1 .                              (10)

It is easy to see that the pricing errors from this alternative second-pass CSR, eW = µ2 − CλW , are
the same as those in (5). It follows that the ρ2W for these two CSRs are also identical. However, it
is important to note that unless V11 is a diagonal matrix, λW,1i = 0 does not imply γW,1i = 0, and
vice versa.5

         It should be emphasized that unless the model is correctly specified, γW , λW , eW , and ρ2W
depend on the choice of W . Popular choices of W in the literature are W = IN (OLS CSR),
      −1
W = V22  (GLS CSR),6 and W = Σ−1
                              d  (weighted least squares (WLS) CSR), where Σd is a
diagonal matrix containing the diagonal elements of Σ. To simplify the notation, we suppress the
subscript W from γW , λW , eW , and ρ2W when the choice of W is clear from the context.


B.        Sample Measures of Pricing Errors and Cross-Sectional R2 s

Let Yt = [ft0, R0t]0 , where ft is the vector of K proposed factors at time t and Rt is a vector of
returns on N test assets at time t. Throughout the paper, we assume the time series Yt is jointly
stationary and ergodic, with finite fourth moment. Suppose we have T observations on Yt and
denote the sample moments of Yt by
                                        "          #           T
                                            µ̂1            1X
                               µ̂ =                    =          Yt ,                                           (11)
                                            µ̂2            T
                                                              t=1
                                        "                    #         T
                                            V̂11       V̂12       1X
                              V̂   =                           =         (Yt − µ̂)(Yt − µ̂)0.                    (12)
                                            V̂21       V̂22       T
                                                                    t=1

The popular two-pass method first estimates the betas of the N assets by running the following
multivariate regression:
                                       Rt = α + βft + t ,            t = 1, . . . , T.                          (13)
     5
     See Jagannathan and Wang (1998) and Cochrane (2005, Chapter 13.4) for a discussion of this issue. Another
solution to this problem is to use simple regression betas as the regressors in the second-pass CSR, as in Chen, Roll,
and Ross (1986) and Jagannathan and Wang (1996, 1998). Kan and Robotti (2009) provide asymptotic results for
the CSR with simple regression betas under potentially misspecified models.
   6
     As pointed out by Lewellen, Nagel, and Shanken (2009), γW and e0W W eW are the same regardless of whether we
            −1                                                                                  −1
use W = V22     or W = Σ−1 . However, it should be noted that the ρ2W are different for W = V22    and W = Σ−1 . For
                                                                                                                   −1
the purpose of model comparison, it makes sense to use a common W across models, so we prefer to use W = V22
for the case of GLS CSR.


                                                                6
                                                                                                    −1
The estimated betas from this first-pass time-series regression are given by the matrix β̂ = V̂21V̂11  .
We then run a single CSR of µ̂2 on X̂ = [1N , β̂] to estimate γW in the second pass.7 When the
weighting matrix W is known (say OLS CSR), we can estimate γW in (4) by

                                          γ̂ = (X̂ 0W X̂)−1X̂ 0W µ̂2 .                                      (14)

Similarly, letting Ĉ = [1N , V̂21], we estimate λW in (9) by

                                           λ̂ = (Ĉ 0 W Ĉ)−1 Ĉ 0 W µ̂2 .                                  (15)

In the GLS and WLS cases, the weighting matrix W involves unknown parameters and, therefore,
we need to substitute a consistent estimate of W , say Ŵ , in (14) and (15). This is typically the
                                                             −1
corresponding matrix of sample moments, for example, Ŵ = V̂22  for GLS and Ŵ = Σ̂−1
                                                                                   d for WLS.

     The sample measure of ρ2 is similarly defined as
                                                              Q̂
                                                 ρ̂2 = 1 −          ,                                       (16)
                                                              Q̂0
where Q̂0 and Q̂ are consistent estimators of Q0 and Q in (7) and (8), respectively. When W is
known, we estimate Q0 and Q using

                             Q̂0 = µ̂02 W µ̂2 − µ̂02 W 1N (10N W 1N )−1 10N W µ̂2 ,                         (17)

                              Q̂ = µ̂02 W µ̂2 − µ̂02 W X̂(X̂ 0W X̂)−1 X̂ 0W µ̂2 .                           (18)

When W is not known, we replace W with Ŵ in the formulas above.


C.    Asymptotic Distribution of γ̂ under Potentially Misspecified Models

When computing the standard error of γ̂, researchers typically rely on the asymptotic distribu-
tion of γ̂ under the assumption that the model is correctly specified. Shanken (1992) presents the
asymptotic distribution of γ̂ under the conditional homoskedasticity assumption on the residuals.
Jagannathan and Wang (1998) extend Shanken’s results by allowing for conditional heteroskedas-
ticity as well as autocorrelated errors.

     Two recent papers have investigated the asymptotic distribution of γ̂ under potentially mis-
specified models. Hou and Kimmel (2006) derive the asymptotic distribution of γ̂ for the case of
   7
     Some studies allow β̂ to change throughout the sample period. For example, in the original Fama and MacBeth
(1973) study, the betas used in the CSR for month t were estimated from data prior to that month. We do not study
this case here mainly because the estimator of γ from this alternative procedure is generally not consistent.


                                                         7
GLS CSR with a known value of γ0 , and Shanken and Zhou (2007) present asymptotic results for
the OLS, WLS, and GLS cases with γ0 unknown. However, both analyses are somewhat restrictive,
as they rely on the i.i.d. normality assumption. We now relax this assumption.8

    We first present the asymptotic distribution of γ̂ when W is known.


Proposition 1. Let H = (X 0W X)−1 , A = HX 0W , and γt ≡ [γ0t, γ1t
                                                                0 0
                                                                   ] = ARt. Under a poten-
tially misspecified model, the asymptotic distribution of γ̂ = (X̂ 0W X̂)−1 X̂ 0W µ̂2 is given by
                                          √              A
                                              T (γ̂ − γ) ∼ N (0K+1, V (γ̂)),                                        (19)

where
                                                         ∞
                                                         X
                                              V (γ̂) =           E[hth0t+j ],                                       (20)
                                                         j=−∞

with
                                      ht = (γt − γ) − (φt − φ)wt + Hzt ut ,                                         (21)
                                                                                     −1
φt = [γ0t, (γ1t − ft )0 ]0, φ = [γ0, (γ1 − µ1 )0]0, ut = e0 W (Rt − µ2 ), wt = γ10 V11  (ft − µ1 ), and
                       −1 0
zt = [0, (ft − µ1 )0 V11 ] . When the model is correctly specified, we have:

                                            ht = (γt − γ) − (φt − φ)wt.                                             (22)


    To conduct statistical tests, we need a consistent estimator of V (γ̂). This can be obtained by
replacing ht with
                                      ĥt = (γ̂t − γ̂) − (φ̂t − φ̂)ŵt + Ĥ ẑt ût ,                               (23)

                     0 ]0 = (X̂ 0 W X̂)−1 X̂ 0 W R , φ̂ = [γ̂ , (γ̂ − f )0 ]0 , φ̂ = [γ̂ , (γ̂ − µ̂ )0 ]0 , û =
where γ̂t ≡ [γ̂0t, γ̂1t                           t    t     0t    1t  t                0     1    1          t
                                                       −1                                                             −1 0
ê0 W (Rt − µ̂2 ) with ê = µ̂2 − X̂ γ̂, ŵt = γ̂10 V̂11  (ft − µ̂1 ), Ĥ = (X̂ 0W X̂)−1 and ẑt = [0, (ft − µ̂1 )0V̂11 ].
In particular, if ht is uncorrelated over time, then we have V (γ̂) = E[hth0t ], and its consistent
estimator is given by
                                                               T
                                                             1X
                                                 V̂ (γ̂) =       ĥt ĥ0t .                                         (24)
                                                             T
                                                                 t=1
   8
     For the case of misspecified GMM, White (1994) and Hall and Inoue (2003) provide an asymptotic analysis of the
parameter estimates. However, the two-pass CSR is not a standard GMM procedure that estimates β and γ jointly.
Instead, the two-pass CSR can be interpreted as a sequential GMM that first estimates β from one set of moment
conditions and then estimates γ using a different set of moment conditions by plugging in the estimated β (see Pagan
(1984) for an analysis of regressions with generated regressors and Newey (1984) for a discussion of sequential GMM).
As a result, the asymptotic analyses of White (1994) and Hall and Inoue (2003) cannot be directly applied to the
two-pass CSR estimator of γ.


                                                             8
When ht is autocorrelated, one can use Newey and West’s (1987) method to obtain a consistent
estimator of V (γ̂).

       An inspection of (21) reveals that there are three sources of asymptotic variance for γ̂. The first
term γt − γ measures the asymptotic variance of γ̂ when the true betas (β) are used in the CSR. For
example, if Rt is i.i.d., then γt is also i.i.d. and we can use the time series variance of γt to compute
the standard error of γ̂. This coincides with the popular Fama and MacBeth (1973) method.
However, since β̂ is used in place of β in the actual second-pass CSR, there is an EIV problem.
The second term (φt − φ)wt is the EIV adjustment term that accounts for the estimation errors
in β̂. The first two terms together give us the V (γ̂) under the correctly specified model.9 When
the model is misspecified (e 6= 0N ), there is a third term Hztut , which we call the misspecification
adjustment term. Traditionally, this term has been ignored by empirical researchers.

       To gain a better understanding of the relative importance of the misspecification adjustment
term, in the following lemma we derive an explicit expression for V (γ̂) under the assumption that
returns and factors are multivariate elliptically distributed.


Lemma 1. When the factors and returns are i.i.d. multivariate elliptically distributed with kurtosis
parameter κ,10 the asymptotic variance of γ̂ = (X̂ 0W X̂)−1 X̂ 0W µ̂2 is given by

                                       V (γ̂) = Υw + Υw1 + Υ0w1 + Υw2 ,                                        (25)

where

                                                              −1
                                   Υw = AV22A0 + (1 + κ)γ10 V11  γ1AΣA0 ,                                      (26)

                                   Υw1 = −(1 + κ)H[0, γ10 V11
                                                            −1 0 0
                                                              ] e W V22A0                                      (27)
                                                                −1
                                   Υw2 = (1 + κ)e0 W V22W eH Ṽ11  H,                                          (28)
                "             #
        −1
                    0   00K
with Ṽ11  =             −1
                               .
                    0K V11

       Note that when κ = 0, Lemma 1 collapses to the expression given by Shanken and Zhou (2007)
in their Proposition 1 under normality. For general W , the misspecification adjustment term
   9
     It can be verified that this expression coincides with the one given by Jagannathan and Wang (1998) in their
Theorem 1, except that our expression is easier to use in practice.
  10
     The kurtosis parameter for an elliptical distribution is defined as κ = µ4 /(3σ4 ) − 1, where σ2 and µ4 are its
second and fourth central moments, respectively.


                                                         9
                                                                                            −1
Υw1 + Υ0w1 + Υw2 is not necessarily positive semidefinite. However, for true GLS with W = V22
or W = Σ−1 , we have AV22W e = Ae = 0K+1 , so Υw1 vanishes, resulting in the following simple
expression for V (γ̂):


                        V (γ̂) = H + (1 + κ)γ10 V11
                                                  −1
                                                     γ1 (X 0Σ−1 X)−1 + (1 + κ)QH Ṽ11
                                                                                    −1
                                                                                       H,                (29)

                −1                   −1                                                      −1
where H = (X 0V22  X)−1 and Q = e0 V22  e. The misspecification adjustment term (1 + κ)QH Ṽ11  H
                                                                                             −1
is positive semidefinite in this case since 1 + κ > 0 (see Bentler and Berkane (1986)) and V11  is
positive definite. Note that the adjustment term is positively related to the aggregate pricing-error
measure Q and the kurtosis parameter κ.

       We now turn our attention to the asymptotic distribution of γ̂ when W must be estimated.
Under a correctly specified model, the use of Ŵ instead of W does not alter the asymptotic
distribution of γ̂ (proof is available upon request). However, the asymptotic distribution is affected
when the model is misspecified. In the following proposition, we present the distribution for the
GLS case.11


                             −1                 −1
Proposition 2. Let H = (X 0V22  X)−1, A = HX 0V22                    0 0
                                                   , and γt = [γ0t, γ1t ] = ARt . Under a
                                                                            −1              −1
potentially misspecified model, the asymptotic distribution of γ̂ = (X̂ 0V̂22  X̂)−1 X̂ 0V̂22  µ̂2 is given by

                                           √           A
                                            T (γ̂ − γ) ∼ N (0K+1, V (γ̂)),                               (30)


where
                                                         ∞
                                                         X
                                              V (γ̂) =          E[hth0t+j ],                             (31)
                                                         j=−∞

with


                              ht = (γt − γ) − (φt − φ)wt + Hzt ut − (γt − γ)ut,                          (32)

                                                              −1                        −1
φt = [γ0t, (γ1t − ft )0]0, φ = [γ0, (γ1 − µ1 )0]0 , ut = e0 V22  (Rt − µ2 ), wt = γ10 V11  (ft − µ1 ), zt =
                 −1 0
[0, (ft − µ1 )0V11 ] . When the model is correctly specified, we have:


                                            ht = (γt − γ) − (φt − φ)wt.                                  (33)
  11
       Various results for the WLS case are available upon request.


                                                           10
       Comparing (32) with the expression for ht in (21), we see that there is an extra term in ht
associated with the use of Ŵ instead of W . This fourth term vanishes only when the model is
correctly specified.

       In order to gain a more concrete understanding of the misspecification adjustment term, in the
following lemma we derive an explicit expression for V (γ̂) in the GLS case under the multivariate
elliptical assumption.


Lemma 2. When the factors and returns are i.i.d. multivariate elliptically distributed with kurtosis
                                                     −1              −1
parameter κ, the asymptotic variance of γ̂ = (X̂ 0V̂22  X̂)−1 X̂ 0V̂22  µ̂2 is given by


                                                   V (γ̂) = Υw + Υw2 ,                                               (34)


where


                  Υw = H + (1 + κ)γ10 V11
                                        −1
                                           γ1(X 0Σ−1 X)−1,                                                           (35)
                                h                                               i
                                                  −1
                  Υw2 = (1 + κ)Q (X 0Σ−1 X)−1Ṽ11    (X 0Σ−1 X)−1 + (X 0Σ−1 X)−1 ,                                   (36)

                                                                    "             #
                   −1                     −1               −1
                                                                        0   00K
with H =     (X 0V22  X)−1,    Q=    e0 V22  e,   and   Ṽ11    =            −1
                                                                                  .
                                                                        0K V11

       When Q > 0, the misspecification adjustment term Υw2 is positive definite since it is the sum
of two matrices, the first positive semidefinite and the second positive definite. In the proof of
Lemma 2, we show that the misspecification adjustment term crucially depends on the variance
of the residuals from projecting the factors on the returns. For factors that have very low corre-
lation with returns (e.g., macroeconomic factors), therefore, the impact of misspecification on the
asymptotic variance of γ̂1 can be very large.


D.      Asymptotic Distribution of λ̂ under Potentially Misspecified Models

In the following proposition, we present the asymptotic distribution of λ̂, the estimated parameters
in the covariance-based model, for various cases. Since the derivation is very similar to the derivation
for γ̂, we do not provide the proof.12
  12
     A proof of this proposition is available upon request. The asymptotic distribution of λ̂ under the i.i.d. multivariate
elliptical distributional assumption is also available upon request.


                                                                11
Proposition 3. Under a potentially misspecified model, the asymptotic distribution of λ̂ is given
by
                                         √               A
                                             T (λ̂ − λ) ∼ N (0K+1, V (λ̂)),                           (37)

where
                                                         ∞
                                                         X
                                              V (λ̂) =            E[h̃th̃0t+j ].                      (38)
                                                         j=−∞

To simplify the expressions for h̃t , we define G̃t = V21 − (Rt − µ2 )(ft − µ1 )0, z̃t = [0, (ft − µ1 )0]0,
H̃ = (C 0 W C)−1 , Ã = H̃C 0 W , λt = ÃRt , and ut = e0W (Rt − µ2 ).

(1) With a known weighting matrix W , λ̂ = (Ĉ 0 W Ĉ)−1 Ĉ 0 W µ̂2 and


                                        h̃t = (λt − λ) + ÃG̃tλ1 + H̃ z̃t ut .                        (39)


                           −1               −1
(2) For GLS, λ̂ = (Ĉ 0 V̂22  Ĉ)−1 Ĉ 0 V̂22  µ̂2 and


                                h̃t = (λt − λ) + ÃG̃t λ1 + H̃ z̃t ut − (λt − λ)ut.                   (40)


When the model is correctly specified, we have:


                                              h̃t = (λt − λ) + ÃG̃t λ1.                              (41)


E.    Asymptotic Distribution of the Sample Cross-Sectional R2

The sample R2 (ρ̂2) in the second-pass CSR is a popular measure of goodness of fit for a model.
A high ρ̂2 is viewed as evidence that the model under study does a good job of explaining the
cross-section of expected returns. Lewellen, Nagel, and Shanken (2009) point out several pitfalls in
this approach and explore simulation techniques to obtain approximate confidence intervals for ρ2 .
In this subsection, we provide the first formal statistical analysis of ρ̂2 .

     In the following proposition, we show that the asymptotic distribution of ρ̂2 crucially depends on
whether (1) the population ρ2 is 1 (i.e., a correctly specified model), (2) 0 < ρ2 < 1 (a misspecified
model that provides some explanatory power for the expected returns on the test assets), or (3)
ρ2 = 0 (a misspecified model that does not explain any of the cross-sectional variation in expected
returns for the test assets).

                                                             12
                                                  −1
Proposition 4. In the following, we set W to be V22  for the GLS case. (1) When ρ2 = 1,
                                                                       N −K−1
                                                                         X
                                           2          T Q̂     A                ξj
                                   T (ρ̂ − 1) = −              ∼−                  xj ,                          (42)
                                                      Q̂0                       Q0
                                                                        j=1

where the xj ’s are independent χ21 random variables, and the ξj ’s are the eigenvalues of

                                                           1       1
                                                  P 0 W 2 SW 2 P,                                                (43)

                                                                                                             1
where P is an N × (N − K − 1) orthonormal matrix with columns orthogonal to W 2 C, S is the
                                   P
asymptotic covariance matrix of √1T Tt=1 Rt yt , and yt = 1−λ01(ft −µ1 ) is the normalized stochastic
discount factor (SDF).

       (2) When 0 < ρ2 < 1,
                                                                                    
                                 √                                 ∞
                                                                   X
                                                  A
                                     T (ρ̂2 − ρ2) ∼ N 0,                E[ntnt+j ] ,                           (44)
                                                                 j=−∞

where
                                          
                nt = 2 −ut yt + (1 − ρ2)vt /Q0                                            for known W,           (45)
                                                       
                nt = u2t − 2ut yt + (1 − ρ2)(2vt − vt2 ) /Q0                                          −1
                                                                                          for Ŵ = V̂22  ,       (46)

with e0 = [IN − 1N (10N W 1N )−1 10N W ]µ2 , ut = e0 W (Rt − µ2 ), and vt = e00 W (Rt − µ2 ).

       (3) When ρ2 = 0,
                                                           K
                                                           X
                                                      A      ξj
                                                 T ρ̂2 ∼        xj ,                                             (47)
                                                             Q0
                                                           j=1

where the xj ’s are independent      χ21   random variables and the ξj ’s are the eigenvalues of

                                [β 0W β − β 0 W 1N (10N W 1N )−1 10N W β]V (γ̂1),                                (48)

where V (γ̂1) is given in Proposition 1 (for known weighting matrix W ) or Proposition 2 (for GLS).13


       The first asymptotic distribution in (42) allows us to perform a specification test of the beta
pricing model. This is an alternative to the various multivariate asset pricing tests that have been
  13
    In the proof of Proposition 4, we show that ρ2 = 0 if and only if γ1 = 0K . Therefore, another way to test
H0 : ρ2 = 0 is to test the equivalent hypothesis H0 : γ1 = 0K , which can be easily performed by using a Wald test.
When computing V (γ̂1 ) for the test of H0 : ρ2 = 0, we can impose the null hypothesis H0 : γ1 = 0K and drop the
EIV term (φt − φ)wt in the expressions for ht in Propositions 1 and 2.


                                                           13
developed in the literature.14 Whereas the earlier tests focus on an aggregate pricing-error measure,
the R2 -based test examines pricing errors in relation to the cross-sectional variation in expected
returns. In contrast to these tests, the asymptotic distribution in (47) permits a test of whether
the model has any explanatory power for expected returns, i.e., whether we can reject H0 : ρ2 = 0.

       When 0 < ρ2 < 1, the primary case of interest, Proposition 4 shows that asymptotically, ρ̂2
is normally distributed around its true value. From the results of the proposition, we see that nt
approaches zero when ρ2 → 0 or ρ2 → 1. Consequently, se(ρ̂2) tends to be lowest when ρ2 is close
to zero or one, and se(ρ̂2) is not monotonic in ρ2. Note that the asymptotic normal distribution of
ρ̂2 breaks down for the two extreme cases (ρ2 = 0 or 1).15 Intuitively, the normal distribution fails
because, by construction, ρ̂2 will always be above zero (even when ρ2 = 0) and below one (even
when ρ2 = 1).16



III.       Tests for Comparing Two Competing Models

One way to think about model comparison and selection is to ask whether two competing beta pric-
ing models have the same population cross-sectional R2 . In this section, we derive the asymptotic
distribution of the difference between the sample R2s of two models. We show that this distribution
depends on whether the two models are nested or non-nested and whether the models are correctly
specified or not. For model comparison, we focus on the R2 of the CSR with known weighting
                                                        −1
matrix W and on the R2 of the GLS CSR that uses Ŵ = V̂22  as the weighting matrix.

       Our analysis in this section is related to the model selection tests of Kan and Robotti (2008)
and Li, Xu, and Zhang (2009), which are based on the earlier work of Vuong (1989), Rivers and
Vuong (2002), and Golden (2003). Whereas Kan and Robotti (2008) and Li, Xu, and Zhang
(2009) conduct tests of equality of the Hansen-Jagannathan (1997) distances of two competing
asset pricing models, our objective is to test for equality of the cross-sectional R2s of two models.
The asymptotic distributions of the model selection tests developed here are derived under general

  14
       See Campbell, Lo, and MacKinlay (1997) or Cochrane (2005) and the included references.
  15
       This is because when ρ2 = 1, we have e = 0N and ut = 0, so nt in (45) and (46) becomes zero. Similarly, when
  2
ρ = 0, we have yt = 1, e = e0 and ut = vt, so again nt in (45) and (46) vanishes.
    16
       As a result, we need to use a weighted sum of independent chi-squared random variables with one degree of
freedom to characterize the sampling variation of ρ̂2 for these two extreme cases. The asymptotic distribution of ρ̂2
under the i.i.d. multivariate elliptical distributional assumption is available upon request.


                                                         14
distributional assumptions.17

       We consider two competing beta pricing models. Let f1 , f2 , and f3 be three sets of distinct
factors, where fi is of dimension Ki × 1, i = 1, 2, 3. Assume that model A uses f1 and f2 , while
Model B uses f1 and f3 as factors. Therefore, model A requires that the expected returns on the
test assets are linear in the betas or covariances with respect to f1 and f2 , i.e.,

                         µ2 = 1N λA,0 + Cov[R, f10 ]λA,1 + Cov[R, f20 ]λA,2 = CA λA ,                            (49)

where CA = [1N , Cov[R, f10 ], Cov[R, f20 ]] and λA = [λA,0, λ0A,1 , λ0A,2]0. Model B requires that
expected returns are linear in the betas or covariances with respect to f1 and f3 , i.e.,

                         µ2 = 1N λB,0 + Cov[R, f10 ]λB,1 + Cov[R, f30 ]λB,3 = CB λB ,                            (50)

where CB = [1N , Cov[R, f10 ], Cov[R, f30 ]] and λB = [λB,0, λ0B,1, λ0B,3]0.

       In general, both models can be misspecified. Following the development in Section II.A, given
a weighting matrix W , the λi that maximizes the ρ2 of model i is given by

                                          λi = (Ci0 W Ci )−1 Ci0 W µ2 ,                                          (51)

where Ci is assumed to have full column rank, i = A, B. For each model, the pricing-error vector
ei , the aggregate pricing-error measure Qi , and the corresponding goodness-of-fit measure ρ2i are
all defined as in Section II.

       When K2 = 0, model B nests model A as a special case. Similarly, when K3 = 0, model A nests
model B. When both K2 > 0 and K3 > 0, the two models are non-nested. We study the nested
models case in the next subsection and deal with non-nested models in Section III.B.


A.      Nested Models

Without loss of generality, we assume K3 = 0, so that model A nests model B. In this case, the
following lemma shows that ρ2A = ρ2B is equivalent to a restriction on the parameters of model A.


Lemma 3. ρ2A = ρ2B if and only if λA,2 = 0K2 .
  17
    The asymptotic distributions of our model selection tests under the multivariate elliptical distributional assump-
tion are available upon request.


                                                         15
   Note that Lemma 3 is applicable even when the models are misspecified. By this lemma, to
test whether the models have the same ρ2, one can simply perform a test of H0 : λA,2 = 0K2 . Let
                                                                  √
V̂ (λ̂A,2) be a consistent estimator of the asymptotic variance of T (λ̂A,2 − λA,2 ). Then, under the
null hypothesis,
                                                                   A
                                      T λ̂0A,2V̂ (λ̂A,2)−1 λ̂A,2 ∼ χ2K2 ,                              (52)

and this statistic can be used to test H0 : ρ2A = ρ2B . If K2 = 1, we can also use the t-ratio associated
with λ̂A,2 to perform the test. However, it is important to note that, in general, we cannot conduct
this test using the usual standard error of λ̂, which assumes that model A is correctly specified.
Instead, we need to rely on the misspecification-robust standard error of λ̂ given in Proposition 3.

   Alternatively, in keeping with the common practice of comparing cross-sectional R2s, we can
derive the asymptotic distribution of ρ̂2A − ρ̂2B and use this statistic to test H0 : ρ2A = ρ2B . The next
proposition presents the distribution.

                                 0 W C )−1 as
Proposition 5. Partition H̃A = (CA    A
                                       "               #
                                         H̃A,11 H̃A,12
                                 H̃A =                   ,                                             (53)
                                         H̃A,21 H̃A,22

where H̃A,22 is K2 × K2. Under the null hypothesis H0 : ρ2A = ρ2B ,
                                                             K2
                                                             X
                                                        A       ξj
                                        T (ρ̂2A − ρ̂2B ) ∼         xj ,                                (54)
                                                                Q0
                                                             j=1

                                                                                            −1
where the xj ’s are independent χ21 random variables and the ξj ’s are the eigenvalues of H̃A,22 V (λ̂A,2 ).


   Again, we emphasize that the misspecification-robust version of V (λ̂A,2) should be used to test
H0 : ρ2A = ρ2B . Model misspecification tends to create additional sampling variation in ρ̂2A − ρ̂2B .
Without taking this into account, one might mistakenly reject the null hypothesis when it is true.
In actual testing, we replace ξj with its sample counterpart ξˆj , where the ξˆj ’s are the eigenvalues
   ˆ −1 V̂ (λ̂ ), computed from the consistent estimators H̃
of H̃                                                       ˆ
      A,22    A,2                                             A,22 and V̂ (λ̂A,2 ).

   Before considering the more complicated case of non-nested models, it is worth clarifying a point
about risk premia, which we suspect is not widely understood. Lemma 3 implies that whether the
extra factors f2 improve the cross-sectional R2 depends on whether any of the prices of covariance
risk associated with f2 are nonzero. However, λ2 = 0K2 does not mean that the usual risk premia

                                                      16
(coefficients on the multiple-regression betas) associated with f2 are zero. To see this, let γ =
[γ0, γ10 , γ20 ]0 be the zero-beta rate and risk premia for f1 and f2 . Then, using the one-to-one
correspondence between λ and γ in (10), we have:
                        "    # "                                  #"    #
                          γ1          Var[f1 ]     Cov[f1 , f20 ]    λ1
                               =                                          .                                   (55)
                          γ2        Cov[f2 , f10 ]  Var[f2 ]         λ2
Hence, the risk premia associated with f2 are γ2 = Cov[f2 , f10 ]λ1 when λ2 is zero. As we see, γ2
can still be nonzero in this case unless f1 and f2 are uncorrelated.18 Similarly, we can show that
γ2 = 0K2 does not imply λ2 = 0K2 unless f1 and f2 are uncorrelated.

       In other words, finding a significant t-ratio on a factor risk premium — the case of a so-called
“priced” factor — need not imply that inclusion of that factor will add to the cross-sectional
explanatory power of a model. Similarly, finding that a factor is not “priced” in the usual sense
need not imply that the factor is unimportant in explaining cross-sectional differences in expected
returns. There is no problem if one simply wants to estimate the parameters of a given pricing
model, as is often the case. Indeed, in some contexts the multiple regression betas and corresponding
risk premia may be of great economic interest. But there is an issue if one is concerned with the
hypothesis of incremental explanatory power for expected returns. We provide some examples to
illustrate these points.

       In the first example, we consider two factors with
                                                "         #
                                                   15 −10
                                          V11 =             .                                                 (56)
                                                  −10 15
Suppose there are four assets and their expected returns and covariances with the two factors are
                                                       "            #
                                           0
                                                         1 2 3 4
                          µ2 = [2, 3, 4, 5] ,   V12 =                 .                      (57)
                                                         3 5 2 1
It is clear that the covariances (or simple regression betas) of the four assets with respect to the
first factor alone can fully explain µ2 because µ2 is exactly linear in the first row of V12. As a result,
the second factor is irrelevant from a cross-sectional expected return perspective. However, when
we compute the (multiple regression) beta matrix with respect to the two factors, we obtain:
                                         "                         #0
                                   −1
                                           0.36  0.64  0.52  0.56
                          β = V21V11   =                              .                      (58)
                                           0.44 0.76 0.48 0.44
  18
    When λ2 = 0K2 , we see that γ1 = Var[f1 ]λ1 . Consequently, the risk premia for f1 stay the same when we add f2
to the model.


                                                        17
Simple calculations give γ = [1, 15, −10]0 and γ2 is nonzero even though f2 is irrelevant.19

       In the second example, we change µ2 to [10, 17, 14, 15]0. In this case, the covariances (or
simple regression betas) with respect to f1 alone do not fully explain µ2 (in fact, the OLS ρ2 for
the model with just f1 is only 28%). However, it is easy to see that µ2 is linear in the first column
of the beta matrix, implying that the ρ2 of the full model is 100%. Simple calculations give us
γ = [1, 25, 0]0 and γ2 = 0, even though f2 is needed in the factor model, along with f1 , to explain
µ2 .


B.      Non-Nested Models

The test of H0 : ρ2A = ρ2B is more complicated for non-nested models. The reason is that under H0 ,
there are three possible asymptotic distributions for ρ̂2A − ρ̂2B , depending on why the two models
have the same cross-sectional R2 . To see this, first let us define the normalized SDFs for models A
and B as

 yA = 1−(f1 −E[f1])0λA,1 −(f2 −E[f2])0λA,2,          yB = 1−(f1 −E[f1])0λB,1 −(f3 −E[f3])0λB,3. (59)


       In the Appendix, we show that yA = yB implies that the two models have the same pricing
errors and hence ρ2A = ρ2B . If yA 6= yB , there are additional cases in which ρ2A = ρ2B . A second
possibility is that both models are correctly specified (i.e., ρ2A = ρ2B = 1). This occurs, for example,
if model A is correctly specified and the factors f3 in model B are given by f3 = f2 + , where 
is pure “noise” — a vector of measurement errors with mean zero, independent of returns. In this
case, we have CA = CB and both models produce zero pricing errors. A third possibility is that
the two models produce different pricing errors but the same overall goodness of fit. Intuitively,
one model might do a good job of pricing some assets that the other prices poorly and vice versa,
such that the aggregation of pricing errors is the same in each case (ρ2A = ρ2B < 1). As it turns out,
each of these three scenarios results in a different asymptotic distribution for ρ̂2A − ρ̂2B .


1. yA = yB Case

At first sight, it may appear that yA = yB is equivalent to the joint restriction λA,1 = λB,1,
λA,2 = 0K2 and λB,3 = 0K3 . The following lemma shows that the first equality is redundant since
  19
   This suggests that when the CAPM is true, it does not imply that the betas with respect to the other two
Fama-French factors should not be priced. See Grauer and Janmaat (2009) for a discussion of this point.


                                                    18
it is implied by the other two.

Lemma 4. For non-nested models, yA = yB if and only if λA,2 = 0K2 and λB,3 = 0K3 .

   Note that Lemma 4 is applicable even when the models are misspecified. It implies that we can
test H0 : yA = yB by testing the joint hypothesis H0 : λA,2 = 0K2 , λB,3 = 0K3 . Let ψ = [λ0A,2, λ0B,3]0
and ψ̂ = [λ̂0A,2 , λ̂0B,3]0. Arguing, as in the proof of Proposition 3, we can establish that under
H0 : yA = yB , the asymptotic distribution of ψ̂ is
                                  √                   A
                                      T (ψ̂ − ψ) ∼ N (0K2+K3 , V (ψ̂)),                            (60)

where
                                                          ∞
                                                          X
                                                                       0
                                        V (ψ̂) =                E[q̃tq̃t+j ],                      (61)
                                                      j=−∞

and q̃t is a K2 + K3 vector obtained by stacking up the last K2 and K3 elements of h̃t for models A
and B, respectively, where h̃t is given in Proposition 3.

   Let V̂ (ψ̂) be a consistent estimator of V (ψ̂). Then, under the null hypothesis H0 : ψ = 0K2 +K3 ,
                                                               A
                                        T ψ̂ 0V̂ (ψ̂)−1 ψ̂ ∼ χ2K2 +K3 ,                            (62)

and this statistic can be used to test H0 : yA = yB . As in the nested models case, it is important
to conduct this test using the misspecification-robust standard error of ψ̂.

   Alternatively, we can perform a test based on the popular ρ2 metric, the main focus of this
paper. The following proposition gives the asymptotic distribution of ρ̂2A − ρ̂2B given H0 : yA = yB .

                            0
Proposition 6. Let H̃A = (CA  W CA )−1 and H̃B = (CB
                                                   0
                                                     W CB )−1 , and partition them as
                        "                #            "                 #
                           H̃A,11 H̃A,12                H̃B,11 H̃B,13
                  H̃A =                    ,    H̃B =                     ,                        (63)
                           H̃A,21 H̃A,22                H̃B,31 H̃B,33

where H̃A,11 and H̃B,11 are (K1 + 1) × (K1 + 1). Under the null hypothesis H0 : yA = yB ,
                                                               KX
                                                                2 +K3
                                                           A            ξj
                                      T (ρ̂2A   −   ρ̂2B ) ∼               xj ,                    (64)
                                                                        Q0
                                                                j=1

where the xj ’s are independent χ21 random variables and the ξj ’s are the eigenvalues of
                                    "     −1
                                                       #
                                        H̃A,22 0K2 ×K3
                                                   −1
                                                         V (ψ̂).                                   (65)
                                       0K3 ×K2 −H̃B,33


                                                          19
    Note that we can think of the earlier nested models scenario as a special case of testing H0 :
yA = yB with K3 = 0. The only difference is that the ξj ’s in Proposition 5 are all positive whereas
some of the ξj ’s in Proposition 6 are negative. As a result, we need to perform a two-sided test
based on ρ̂2A − ρ̂2B in the non-nested model case.20

    If we fail to reject H0 : yA = yB , we are finished since equality of ρ2A and ρ2B is implied by this
hypothesis. Otherwise, we need to consider the case yA 6= yB .


2. yA 6= yB Case

As noted earlier, when yA 6= yB , the asymptotic distribution of ρ̂2A − ρ̂2B given H0 : ρ2A = ρ2B
depends on whether the models are correctly specified or not. The following proposition presents
a simple chi-squared statistic for testing whether models A and B are both correctly specified. As
this joint specification test focuses on the pricing errors, it can be viewed as a generalization of the
cross-sectional regression test (CSRT) of Shanken (1985), which tests the validity of the expected
return relation for a single pricing model.


Proposition 7. Let nA = N − K1 − K2 − 1 and nB = N − K1 − K3 − 1. Also let PA be an N × nA
                                                                  1
orthonormal matrix with columns orthogonal to W 2 CA and PB be an N × nB orthonormal matrix
                                     1
with columns orthogonal to W 2 CB . Define
                                       "           # "        #
                                         gAt (λA )     Rt yAt
                               gt(θ) =              =           ,                                                  (66)
                                         gBt(λB )      Rt yBt

where θ = (λ0A, λ0B )0, and
                                         "               #        ∞
                                             SAA   SAB            X
                                S≡                           =          E[gt(θ)gt+j (θ)0].                         (67)
                                             SBA SBB             j=−∞

If yA 6= yB and the null hypothesis H0 : ρ2A = ρ2B = 1 holds, then
       "          1     #0 "         1         1             1         1     #"         1     #
          P̂A0 Ŵ 2 êA      P̂A0 Ŵ 2 ŜAA Ŵ 2 P̂A P̂A0 Ŵ 2 ŜAB Ŵ 2 P̂B    P̂A0 Ŵ 2 êA A 2
    T             1                  1         1             1         1                1       ∼ χnA +nB ,        (68)
         P̂B0 Ŵ 2 êB       P̂B0 Ŵ 2 ŜBAŴ 2 P̂A P̂B0 Ŵ 2 ŜBB Ŵ 2 P̂B     P̂B0 Ŵ 2 êB

where êA and êB are the sample pricing errors of models A and B, and P̂A , P̂B , and Ŝ are consistent
estimators of PA , PB , and S, respectively.
  20
     Following Davidson and MacKinnon (2003, p. 174), the p-value associated with a realized statistic τ̂ based on
a possibly asymmetric distribution is computed as p = 2min[F (τ̂), 1 − F (τ̂ )], where F (τ̂ ) is the cumulative density
function of the statistic τ̂ .


                                                             20
       An alternative specification test makes use of the cross-sectional R2s. The relevant asymptotic
distribution is given in the following proposition.


Proposition 8. Using the notation in Proposition 7, if yA 6= yB and the null hypothesis H0 : ρ2A =
ρ2B = 1 holds, then
                                                                    nAX
                                                                      +nB
                                                                A               ξj
                                               T (ρ̂2A − ρ̂2B ) ∼                  xj ,                      (69)
                                                                                Q0
                                                                      j=1

where the xj ’s are independent χ21 random variables and the ξj ’s are the eigenvalues of
                                "              1            1                   1             1   #
                                    −PA0 W 2 SAA W 2 PA −PA0 W 2 SAB W 2 PB
                                           1            1                   1             1
                                                                                                      .      (70)
                                    PB0 W 2 SBAW 2 PA                PB0 W 2 SBB W 2 PB

       Note that the ξj ’s are not all positive because ρ̂2A − ρ̂2B can be negative. Thus, again, we need
to perform a two-sided test of H0 : ρ2A = ρ2B .

       If the hypothesis that both models are correctly specified is not rejected, we are finished, as the
data are consistent with H0 : ρ2A = ρ2B = 1. Otherwise, we need to determine whether ρ2A = ρ2B for
some value less than one. As in our earlier analysis for ρ̂2, the asymptotic distribution of ρ̂2A − ρ̂2B
changes when the models are misspecified. Proposition 9 presents the appropriate distribution for
this case.


Proposition 9. Suppose yA 6= yB and 0 < ρ2A = ρ2B < 1.21 We have:
                                                                         
                                    √                         ∞
                                                              X
                                                      A
                                     T (ρ̂2A − ρ̂2B ) ∼ N 0,   E[dtdt+j ] .                                (71)
                                                                      j=−∞


When the weighting matrix W is known,

                                           dt = 2Q−1
                                                  0 (uBt yBt − uAt yAt ),                                    (72)

                                                                                               −1
where uAt = e0A W (Rt − µ2 ) and uBt = e0B W (Rt − µ2 ). With the GLS weighting matrix Ŵ = V̂22  ,

                                    dt = Q−1  2                2
                                          0 (uAt − 2uAt yAt − uBt + 2uBtyBt ),                               (73)

                  −1                            −1
where uAt = e0A V22  (Rt − µ2 ) and uBt = e0B V22  (Rt − µ2 ).
  21
       Since ρ2A = ρ2B = 0 implies yA = yB = 1, this case is already covered by the test based on Lemma 4.


                                                                21
       Note that if yAt = yBt, then uAt = uBt, and hence dt = 0. Or, if yAt 6= yBt, but both models
are correctly specified (i.e., uAt = uBt = 0), then again dt = 0. Thus, the normal test cannot be
used in these cases, consistent with the maintained assumptions in the proposition.22


C.      Discussion

Given the three distinct cases encountered in testing H0 : ρ2A = ρ2B for non-nested models, the
approach we have described above entails a sequential test, as suggested by Vuong (1989). In our
context, this involves first testing H0 : yA = yB using (62) or (64). If we reject H0 : yA = yB , then
we use (68) or (69) to test H0 : ρ2A = ρ2B = 1. Finally, if this hypothesis is also rejected, we use the
normal test in Proposition 9 to test H0 : 0 < ρ2A = ρ2B < 1. Let α1, α2 , and α3 be the significance
levels employed in these three tests. Then the sequential test has an asymptotic significance level
that is bounded above by max[α1, α2, α3].23 Thus, if α1 = α2 = α3 = 0.05, the significance level of
this procedure for testing H0 : ρ2A = ρ2B is asymptotically no larger than 5%.

       Another approach is to simply perform the normal test in Proposition 9. This amounts to as-
suming that yA 6= yB and that both models are misspecified. The first assumption seems reasonable
since most of our models only have the constant term in common. Consequently, by Lemma 4,
yA = yB would imply that the models do not account for any cross-sectional variation in expected
returns, an unlikely scenario. The second assumption is sensible because asset pricing models are
approximations of reality and we do not expect them to be perfectly specified. In the following
empirical application, we conduct both the sequential test and the normal test when comparing
non-nested models.



IV.        Empirical Analysis

We apply our methodology to several models of interest in the asset pricing literature. First, we
describe the data used in the empirical analysis and outline the different specifications of the beta
  22
     Note that, depending on whether the asymptotic distribution is normal (Proposition 9) or a linear combination
                                                                                                        1
of independent chi-squared random variables (Propositions 6 and 8), ρ̂2A − ρ̂2B can be either OP (T − 2 ) or OP (T −1 ),
                          2     2
respectively, under H0 : ρA = ρB .
  23
     For the sequential test to reject ρ2A = ρ2B all three tests must reject. Consider the first scenario, yA = yB .
P(reject ρ2A = ρ2B | yA = yB ) ≤ P(test 1 rejects | yA = yB ) = α1 . Similarly, the probability that the sequential test
rejects under the second and third scenarios cannot exceed α2 and α3 , respectively. Under H0 : ρ2A = ρ2B , one of the
three scenarios must hold, so the true probability of rejection cannot exceed the maximum.


                                                          22
pricing models considered. Then we present our results.


A.      Data and Beta Pricing Models

The return data are from Kenneth French’s website and consist of the monthly returns on the 25
Fama-French size and book-to-market ranked portfolios. For most of our time series, the data are
from May 1953 to December 2006 (644 monthly observations). The beginning date of our sample
period is dictated by the bond yield data availability from the Board of Governors of the Federal
Reserve System.24

       We analyze six asset pricing models. The first model is the simple static CAPM. The cross-
sectional specification is
                                                  µ2 = γ0 + βvw γvw ,

where vw is the excess return (in excess of the one-month T-bill rate from Ibbotson Associates) on
the value-weighted stock market index (NYSE-AMEX-NASDAQ) from the Center for Research in
Security Prices (CRSP).

       The second model (CCAPM) is the unconditional consumption CAPM, which implies

                                                  µ2 = γ0 + βcg γcg ,

where cg is the growth rate in real nondurables consumption (from the Bureau of Economic Analy-
sis). For consumption growth, the monthly data start in February 1959 (575 monthly observations).

       The third model (FF3) is the Fama-French (1993) empirical three-factor model with

                                    µ2 = γ0 + βvw γvw + βsmb γsmb + βhml γhml ,

where vw is the stock market factor, smb is the return difference between portfolios of small and
large stocks and hml is the return difference between portfolios of high and low book-to-market
ratios (from Kenneth French’s website).

       The fourth model (C-LAB) is the conditional CAPM of Jagannathan and Wang (1996). The
cross-sectional specification is

                                    µ2 = γ0 + βvw γvw + βlab γlab + βprem γprem ,
  24
       All bond yield data are from this source unless noted otherwise.


                                                           23
where vw is the stock market factor, lab is the growth rate in per capita labor income and prem is
the lagged yield spread between BAA and AAA rated corporate bonds. Per capita labor income,
L, is defined as the difference between total personal income and dividend payments, divided by
the total population (from the Bureau of Economic Analysis). Following Jagannathan and Wang
(1996), we use a two-month moving average to construct the growth rate in per capita labor income,
labt = (Lt−1 + Lt−2 )/(Lt−2 + Lt−3 ) − 1, for the purpose of minimizing the influence of measurement
error.

    The fifth model (C-CCAPM) is a conditional CCAPM, with a cross-sectional specification of
the form
                                 µ2 = γ0 + βdy γdy + βcg γcg + βcg·dy γcg·dy ,

where dy, the conditioning variable, is the lagged dividend yield of the NYSE-AMEX-NASDAQ
value-weighted portfolio (from CRSP). This specification is obtained by scaling the constant term
and the cg factor of a linearized CCAPM by a constant and dy. Scaling factors by instruments
is one popular way of allowing factor risk premia and betas to vary over time. Examples of this
type of practice are found in Shanken (1990), Ferson and Schadt (1996), Cochrane (1996), and
Lettau and Ludvigson (2001), among others. We choose the lagged dividend yield as an instrument
because of its frequent use in the literature.

    The last model (ICAPM) is the five-factor intertemporal CAPM proposed by Petkova (2006),
which implies

                    µ2 = γ0 + βvw γvw + βterm γterm + βdef γdef + βdiv γdiv + βrf γrf ,

where vw is the stock market factor, term is the difference between the yields of ten-year and
one-year government bonds, def is the difference between the yields of long-term corporate Baa
bonds and long-term government bonds (from Ibbotson Associates), div is the dividend yield on the
CRSP value-weighted stock market portfolio, and rf is the one-month T-bill yield (from CRSP,
Fama Risk Free Rates). Following Petkova (2006), the factors for term, def , div, and rf are
actually their innovations from a VAR(1) system of seven state variables that also include vw, smb,
and hml.25
  25
     In contrast to Petkova (2006), we do not orthogonalize the innovations since the R2 of the model is the same
whether we orthogonalize or not. The results for the parameter estimates using the orthogonalized innovations are
available upon request.


                                                       24
B.      Results

We start by estimating the sample cross-sectional R2 s of the different pricing models considered.
Then we analyze the impact of potential model misspecification on the statistical properties of the
estimated γ and λ parameters. Finally, we present the results of our pairwise tests of equality of
the cross-sectional R2 s for different models.


1. Sample Cross-Sectional R2s of the Models

One of the main contributions of this paper is to provide the asymptotic distribution of the sample
cross-sectional R2. In Table 1, we report ρ̂2 for each model and use the results in Proposition 4 to
investigate whether the model can do a good job of explaining the cross-section of expected returns.
We denote the p-value of the specification test of H0 : ρ2 = 1 by p(ρ2 = 1), and the p-value of the
test of H0 : ρ2 = 0 by p(ρ2 = 0). The asymptotic standard error of the sample cross-sectional R2
computed under the assumption that 0 < ρ2 < 1 is se(ρ̂2).

       In addition, we report a generalized version of the CSRT of Shanken (1985), Q̂c = ê0 V̂ (ê)+ ê,
where V̂ (ê) is a consistent estimator of the asymptotic variance of the sample pricing errors and
V̂ (ê)+ stands for its pseudo-inverse. When the model is correctly specified (i.e., e = 0N or ρ2 = 1),
                  A
we have T Q̂c ∼ χ2N −K−1 .26 Following Shanken (1985), we also consider an approximate F -test
                      app.
                                   
which is given by Q̂c ∼ N      −K−1
                             T −N +1 FN −K−1,T −N +1 .
                                                       27 The two p-values associated with testing


H0 : Qc = 0 are p1 (Qc = 0), the asymptotic p-value, and p2 (Qc = 0), the p-value for the approximate
F -test.28 Finally, the number of parameters in each asset pricing model is No. of par.


                                               Table 1 about here


       In Panels A and B of Table 1, we provide results for the OLS and GLS CSRs, respectively.
First, we consider the specification tests based on R2s. It turns out that several models are rejected
at the 5% level: three out of six in the OLS case and four out of six using GLS. Consistent with
  26
     Our Q̂c is more general than the CSRT of Shanken (1985) because we can use sample pricing errors from any
CSR, not just the ones from the GLS CSR. In addition, we allow for conditional heteroskedasticity and autocorrelated
errors. Proofs of the results related to Q̂c are available upon request.
  27
     Simulation evidence suggests that this test has better size properties than the asymptotic test, especially when
N is large relative to T .
  28
     The p-values and standard errors in Table 1 are computed assuming no serial correlation. In a separate set of
results (available upon request), we implement the automatic lag selection procedure without prewhitening of Newey
and West (1994). Overall, accounting for serial correlation in the data has a fairly minor impact on the results.


                                                         25
the empirical findings of Petkova (2006), the ICAPM delivers the highest OLS and GLS R2s and
passes the corresponding specification tests.

       Interestingly, not all models with high cross-sectional R2s pass the specification test. For exam-
ple, the FF3 model has the second highest OLS R2 (0.769) but is rejected with p-value 0.000 (it is
also rejected using GLS). This rejection with a modestly smaller R2 may be due in part to greater
precision, as suggested by the smaller standard error estimates (especially GLS) for FF3 compared
to ICAPM. Thus, while the specification tests provide information about the validity of a given
model, they provide little information about model comparison. Formal tests will be needed to
determine whether the ICAPM outperforms the other models.

       We note that the C-CCAPM also passes the R2 specification test in the OLS and GLS cases,
while the unconditional CCAPM is strongly rejected. The true R2 s of the conditional model may
indeed be higher, and the pricing errors smaller, because the scaling variable dy allows the price
of risk and betas to vary with the business cycle. However, we must keep in mind that the use
of conditioning variables increases the number of factors and parameters, making the conditional
models better able to fit the average returns in any given sample. Again, we will need a formal test,
in this case to establish whether going from unconditional to conditional models truly improves the
cross-sectional R2 .

       In rows five through seven of Table 1, we report the generalized CSRT and corresponding p-
values. The asymptotic and approximate finite sample p-values of the CSRT are close to each other
and fully support the asymptotic findings based on the sample R2s. Out of 12 cases in Panels A
and B, all specification tests reject the same seven models at the 1% and 5% significance levels.

       Assuming that 0 < ρ2 < 1, se(ρ̂2) captures the sampling variability of ρ̂2. In Table 1, we observe
that the ρ̂2s of several models are quite volatile, with the C-CCAPM having a se(ρ̂2) of almost 0.45
in the OLS case. This suggests that some of the models pass the specification test simply because
of low power. In fact, for the C-CCAPM and using OLS, not only do we fail to reject H0 : ρ2 = 1,
but also H0 : ρ2 = 0, the hypothesis that the model cannot explain any of the cross-sectional
differences in expected returns on the 25 size and book-to-market ranked portfolios. We fail to
reject H0 : ρ2 = 0 at the 5% level for the CAPM and CCAPM as well in the OLS case and for the
CCAPM and C-LAB using GLS.29 We will see below that high volatility of the ρ2 estimates also
  29
       In computing the p-value of the test of H0 : ρ2 = 0, we impose the constraint of γ1 = 0K in the computation of


                                                          26
makes it hard to distinguish between models.

    To summarize, several observations emerge from the results in Table 1. First, there is strong
evidence of the need to incorporate model misspecification into our statistical analysis. Second,
there is considerable sampling variability in ρ̂2 and so it is not entirely clear whether one model
consistently outperforms the others. Finally, specification test results are sometimes sensitive to
the weighting matrix used, and it is not always the case that models with very high ρ̂2s pass the
specification test.


2. Properties of the γ and λ Estimates under Correctly Specified and Potentially Misspecified
    Models

Before turning to model comparison, we investigate whether model misspecification substantially
affects the properties of the γ and λ estimators. As far as we know, all previous empirical asset
pricing studies except the recent paper by Shanken and Zhou (2007) have used standard errors that
assume the model is correctly specified. As we argued in the introduction, it is difficult to justify
this practice because some (if not all) of the models are bound to be misspecified. In this subsection,
we see whether using an asymptotic standard error that is robust to model misspecification can
lead to different inferences.

    In Table 2, we focus on the zero-beta rate and risk premia estimates, γ̂, of the beta pricing
models. For each model, we report γ̂ and associated t-ratios under correctly specified and potentially
misspecified models.30 For correctly specified models, we give the t-ratios of Fama and MacBeth
(1973), followed by those of Shanken (1992) and Jagannathan and Wang (1998) which account for
estimation error in the betas. Last, are the t-ratios under potentially misspecified models, based
on our results in Propositions 1 and 2. The various t-ratios are identified by subscripts f m, s, jw,
and pm, respectively.


                                              Table 2 about here


    Consistent with our theoretical results, we find that the t-ratios under correctly specified and
V̂ (γ̂1 ). If we do not impose this constraint, then we fail to reject H0 : ρ2 = 0 for more models.
   30
      The t-ratios are computed by assuming that the errors have no serial correlation. In a separate set of results
(available upon request), we implement the automatic lag selection procedure without prewhitening of Newey and
West (1994). Overall, accounting for serial correlation in the data has a minor impact on the standard errors of γ̂.


                                                        27
potentially misspecified models are similar for traded factors, while they can differ substantially
for factors that have low correlations with asset returns. Included in the latter category are the
macroeconomic factors lab and cg, the financial factors term, def , prem, div, rf , as well as the
factors scaled by dy. Consider, for example, the OLS results for the FF3 model in Panel A. The t-
ratios on γ̂vw , γ̂smb and γ̂hml for correctly specified and potentially misspecified models are generally
very close, as the factors are all mimicked well by the returns on the test assets. For the vw factor,
the t-ratiof m = −2.96 and the t-ratiopm = −2.58 are not very different, while the t-ratios for smb
and hml hardly vary at all across methods. The GLS results in Panel B deliver a similar message.

   When we consider models with factors that are weakly correlated with asset returns, the picture
changes substantially. For example, for the dy factor of the C-CCAPM in the OLS case (Panel A),
we have t-ratiof m = −5.30, t-ratios = −2.71, t-ratiojw = −2.82, and t-ratiopm = −1.07, which
shows that the misspecification adjustment can make a real difference. Although not showing
as big a difference, the standard error of γ̂dy in the GLS case (Panel B) still increases by more
than 40% when we incorporate potential model misspecification. Finally, the ICAPM provides
another example of the different conclusions that one can reach by using misspecification-robust
standard errors. While the t-ratios under correctly specified models in Panel A suggest that γ̂term
is statistically significant (t-ratiof m = 3.97, t-ratios = 2.50 and t-ratiojw = 2.55), the t-ratio of 1.81
under potentially misspecified models provides much weaker evidence.

   To summarize, we find that for factors that are weakly correlated with the returns on the test
assets, all of the t-ratios under potentially misspecified models are smaller (in absolute value) than
the Fama and MacBeth (1973) t-ratios. In addition, most of the misspecification-robust t-ratios are
smaller (in absolute value) than the t-ratios of Shanken (1992) and Jagannathan and Wang (1998).
Finally, the latter two are close to each other and substantially smaller (in absolute value) than the
Fama-MacBeth t-ratios. Thus, both model misspecification and beta estimation error materially
affect inference about the expected return relation.

   As discussed in Section III.A, there are issues with testing whether an individual factor risk
premium is zero or not in a multi-factor model. Unless the factors are uncorrelated or simple
regression betas are used, only the price of covariance risk (elements of λ1) allows us to identify
factors that improve the explanatory power of the expected return model (the usual risk premium
for a given factor does not). To investigate whether the covariance risks of the factors are priced, in


                                                    28
Table 3 we present estimation results for λ. Similar to Table 2, we report λ̂ and associated t-ratios,
with the OLS results in Panel A and the GLS results in Panel B.31 First we have the t-ratios
of Fama-MacBeth (t-ratiof m), then t-ratios that account for estimation error in the covariances
with the model correctly specified (t-ratiocs), and finally the t-ratios under potentially misspecified
models (t-ratiopm). All are based on our results in Proposition 3.32


                                                 Table 3 about here


       To illustrate our point that risk premia and prices of covariance risk can deliver different mes-
sages, consider the FF3 model. In both Panels A and B, λ̂smb is statistically significant at the 1%
level, as all t-ratios are close to or greater than three. In contrast, γ̂smb in Table 2 is not significant
at the 5% level using either OLS or GLS, with all t-ratios smaller than 1.7. Hence, by focusing
on the risk premium, one might think that smb is not an important factor in the FF3 model.
However, results for the price of covariance risk, λ̂smb , imply that smb has explanatory power for
the cross-section of expected returns above and beyond the other factors in the FF3 model.33

       To summarize, accounting for model misspecification can often make a qualitative difference in
determining whether estimates of the risk premium or the price of covariance risk are statistically
significant, especially when the factor has low correlation with asset returns. This would typically
be the case with macroeconomic or scaled factors. Unless one is confident about a model, potential
model misspecification should be accounted for when computing standard errors. In addition,
focusing on the γ̂s, rather than λ̂s, can lead to erroneous conclusions as to whether or not a factor
is helpful in explaining the cross-section of expected returns.


3. Tests of Equality of the Cross-Sectional R2 s of Two Competing Models

Recall that a p-value is the probability, under the null hypothesis, of obtaining a test statistic at
least as extreme as the one observed. As such, the p-value provides no direct information about
  31
     The t-ratios are computed by assuming that the errors have no serial correlation. A separate set of results
(available upon request) considers the automatic lag selection procedure without prewhitening of Newey and West
(1994). Overall, accounting for serial correlation in the data has a modest impact on the standard errors of λ̂.
  32
     We also examined t-ratios for correctly specified models under the normality assumption. These t-ratios were
usually close to t-ratiocs , which is computed under general distributional assumptions.
  33
     There are also situations where the opposite happens — a risk premium is statistically significant in Table 2,
while the corresponding price of covariance risk is not in Table 3. As expected, for one-factor models, γ̂1 and λ̂1 result
in similar inferences. In this case, the t-ratios of the γ̂1 and λ̂1 would be identical if we imposed the null hypotheses
of γ1 = 0 and λ1 = 0, so that the EIV adjustment terms drop out of the analysis.


                                                           29
alternative hypotheses and the extent of deviations from the null. Therefore, p-values from the spec-
ification tests do not allow us to formally compare models. In this subsection, we explore relative
goodness of fit by empirically testing whether competing beta pricing models exhibit significantly
different sample cross-sectional R2 s.

    In Section III, we showed that the asymptotic distribution of the difference between the sample
cross-sectional R2 s depends on whether the two competing models are correctly specified or not
and whether they are nested or non-nested. For nested models, we use Proposition 5 to test for
equality of cross-sectional R2 s.34 For non-nested models, we use the normal test in Proposition 9
as well as the sequential test described in Section III.C. However, for ease of comparison, we only
present results for the normal test, which produces just one more rejection than the sequential
test.35

    In Table 4, we report pairwise tests of equality of cross-sectional R2s for different models, some
nested and others non-nested. Panel A is for the OLS CSR and Panel B is for the GLS CSR. Each
panel shows the differences between the sample cross-sectional R2 s for various pairs of models and
the associated p-values (in parentheses).36


                                                Table 4 about here


    The main findings can be summarized as follows. First, the results show that only the uncon-
ditional CAPM and CCAPM are often outperformed by other models at the 5% level. Specifically,
the CAPM is dominated by C-LAB and FF3 in Panel A, and by FF3 in Panel B, with R2 differences
around 50 percentage points in the OLS cases. In addition, the FF3 and ICAPM fare better relative
to the CCAPM in Panel A, while only the C-CCAPM outperforms the CCAPM in Panel B.37

    Second, there is no strong evidence that conditional models outperform unconditional models.
For example, there is no statistically significant evidence that the ICAPM of Petkova (2006) out-
  34
     When computing the misspecification-robust V̂ (λ̂A,2 ), we impose the null hypothesis H0 : λA,2 = 0K2 . However,
the p-values remain virtually unchanged when we do not impose the null hypothesis. Results obtained using the
Wald test in (52) (not reported in the paper) are consistent with the ones shown in Table 4.
  35
     The sequential test we implement is based on Lemma 4 and Propositions 7 and 9. We also experimented with a
sequential test based on Propositions 6, 8, and 9, and found that both tests reject the same models.
  36
     Note that in the case of non-nested models, the reported p-values are two-tailed p-values.
  37
     All the p-values in Table 4 are computed assuming no serial correlation. A separate set of results (available upon
request) considers the automatic lag selection procedure without prewhitening of Newey and West (1994). We find
that most of the p-values of the test statistics become slightly larger and differences between models even harder to
detect. Two of the four rejections of equality in Panel A of Table 4 are reversed at the 5% level.


                                                          30
performs the FF3 model in terms of OLS and GLS cross-sectional R2s. Surprisingly, we cannot
even strongly conclude that the ICAPM dominates the simple static CAPM, although the OLS p-
value of 0.064 is suggestive. In addition, out of eight comparisons involving C-LAB and C-CCAPM
and the unconditional models, CAPM and CCAPM, the C-LAB model of Jagannathan and Wang
(1996) dominates the CAPM only in the OLS case (p-value 0.020) and the C-CCAPM outperforms
the CCAPM only in the GLS case (p-value 0.025). Of course, failure to reject may, in some cases,
be due to low power; as we saw earlier, the precision of the C-CCAPM sample R2 is particularly
low.

       We also explored the effect of including the three Fama-French factors, along with the 25
portfolios, as test assets in the various model comparisons. For models with one or more of these
traded factors, inclusion requires that the estimated price of risk conform to the corresponding
model restriction (i.e., equal the expected market premium over the zero-beta rate or the expected
spread return for hml and smb) either exactly (GLS) or approximately (OLS), as discussed by
Lewellen, Nagel, and Shanken (2009). For the most part, our inferences are unchanged.38 We
do find, however, that the ICAPM specification can now be rejected (GLS R2 p-value 0.011),
with the price of covariance risk for the term factor no longer significant after allowing for model
misspecification (the GLS t-ratio declines from 2.03 to 1.03).

       Finally, since the population R2 depends on the choice of test assets when a model is misspec-
ified, we consider the robustness of our conclusions to an alternative set of asset portfolios — 25
size-beta sorted portfolios.39 The main differences in model comparison results are observed in the
OLS case, with the C-CCAPM and ICAPM both outperforming the CAPM and the CCAPM at
the 5% level. Moreover, we find that the ICAPM now outperforms the FF3 model as well, with a
spread in OLS R2 of 0.203 and a p-value of 0.033.




  38
     In this context, the vector 1N in the X matrix and in Equation (7) is modified to have entries of zero corresponding
to the hml and smb test assets. Adding five industry portfolios (from Kenneth French’s website) as test assets likewise
has little effect on our main conclusions. The results of the analyses with portfolio restrictions and industry portfolios
are available upon request.
  39
     The 25 portfolios are determined by first forming size quintiles based on market capitalization rankings of all
NYSE-AMEX-NASDAQ common stocks (from CRSP), and then by forming beta quintiles within each size quintile.
This is similar to the approach of Fama and French (1992). We use quintiles, rather than deciles, to mitigate
potential finite-sample issues related to the inversion of a large sample covariance matrix. The results of this analysis
are available upon request.


                                                           31
V.      Conclusion

We have provided a systematic analysis of the asymptotic statistical properties of the traditional
cross-sectional regression methodology and the associated R2 goodness-of-fit measure when an
underlying beta pricing model fails to hold exactly. Our misspecification-robust standard errors for
the zero-beta rate and factor risk premia are derived under very general distributional assumptions,
extending the previous results of Shanken and Zhou (2007) derived under normality. A nice feature
of these standard errors is that they can be used whether the model is correctly specified or not.

     When factors and returns are multivariate elliptically distributed, we show analytically that with
GLS cross-sectional regressions, the standard errors under model misspecification are always larger
than the standard errors that assume the model is correctly specified. We also show, in the GLS
case, that the misspecification adjustment depends, among other things, on the correlation between
the factor and the test asset returns. This adjustment can be very large when the underlying factor
is poorly mimicked by asset returns.

     We also provide a general asymptotic theory for the sample OLS and GLS cross-sectional R2 s.
In particular, we believe our study is the first to consider (in any manner) the important sampling
distribution of the difference between the sample R2 s of two competing models. As we show, the
asymptotic distribution of this difference depends on whether the models are correctly specified
and whether they are nested or non-nested.

     Our econometric results are used to analyze a variety of asset pricing models that have been
proposed in the literature, focusing mainly on the commonly employed 25 size and book-to-market
ranked portfolios as test assets. We find that the significance of risk premia for several non-traded
factors is substantially reduced once potential model misspecification is taken into account. For
example, the OLS t-ratio on the risk premium for the lagged dividend yield in a conditional version
of the consumption CAPM goes from −2.82 to −1.07, a reduction in magnitude of 60% (the
traditional Fama-MacBeth t-ratio is −5.30).

     Our empirical findings suggest that the sample cross-sectional R2 measure can be too noisy
to permit a conclusion that one model outperforms another, in that very large differences in R2
are sometimes statistically insignificant. The estimated standard errors for the sample OLS R2s
range from 0.099 for the Fama and French (1993) three-factor model to 0.447 for a conditional

                                                  32
version of the consumption CAPM. These findings imply that the common approach of informally
relying solely on the sample R2 and ignoring its sampling variability in comparing models can be
dangerous. In this respect, our work reinforces the simulation-based conclusion of Lewellen, Nagel,
and Shanken (2009), while providing a more formal framework to evaluate statistical precision and
conduct inference.

       Finally, the intertemporal CAPM of Petkova (2006) and the Fama and French (1993) three-
factor model perform best in our model comparison tests, while the CAPM and the unconditional
consumption CAPM are frequently dominated by other models. Furthermore, the intertemporal
CAPM of Petkova (2006), the conditional CAPM of Jagannathan and Wang (1996) and a condi-
tional version of the consumption CAPM are never outperformed at the 5% level.40

       Our analysis could be extended in a number of ways. For instance, since we find that the zero-
beta rate estimates of all models are unreasonably large, it would be interesting to perform model
comparison under the constraint that the zero-beta rate equals the risk-free rate. Other metrics
for comparing models besides the R2 measure could also be considered. Finally, although we have
made substantial progress in deriving asymptotic results, future research should also address the
small sample properties of the test statistics proposed in this paper.




  40
    This includes comparisons that employ the 25 size and book-to-market ranked portfolios and the 25 size and beta
ranked portfolios as test assets.


                                                        33
Appendix


Proof of Propositions 1 and 2: We only provide the proof of Proposition 2 here, as the proof of
Proposition 1 is very similar. The proof relies on the fact that γ̂ is a smooth function of µ̂ and V̂ .
Therefore, once we have the asymptotic distribution of µ̂ and V̂ , we can use the delta method to
obtain the asymptotic distribution of γ̂. Let
                                  "           #                            "              #
                                        µ                                         µ̂
                             ϕ=                 ,                   ϕ̂ =                      .                  (A1)
                                    vec(V )                                    vec(V̂ )

We first note that µ̂ and V̂ can be written as the GMM estimator that uses the moment conditions
E[rt(ϕ)] = 0(N +K)(N +K+1), where
                                              "                                           #
                                                                Yt − µ
                                   rt(ϕ) =                                                    .                  (A2)
                                                  vec((Yt − µ)(Yt − µ)0 − V )

Since this is an exactly identified system of moment conditions, it is straightforward to verify that
under the assumption that Yt is stationary and ergodic with finite fourth moment, we have:41

                                     √                 A
                                         T (ϕ̂ − ϕ) ∼ N (0(N +K)(N +K+1), S0),                                   (A3)

where
                                                      ∞
                                                      X
                                            S0 =             E[rt(ϕ)rt+j (ϕ)0].                                  (A4)
                                                      j=−∞

Using the delta method, the asymptotic distribution of γ̂ under the misspecified model is given by
                                                                  
                                                                     
                               √                  A      ∂γ      ∂γ 0
                                   T (γ̂ − γ) ∼ N 0K+1 ,      S0        .                                        (A5)
                                                         ∂ϕ0     ∂ϕ0

It is straightforward to obtain:

                                          ∂γ                               ∂γ
                                               = 0(K+1)×K ,                     = A.                             (A6)
                                          ∂µ01                             ∂µ02

For the derivative of γ with respect to vec(V ), we first need to show that

                                ∂x                 −1 0
                                                                 
                                       0
                                         = [0K , V11 ] , 0(K+1)×N ⊗ [−β, IN ],                                   (A7)
                              ∂vec(V )
  41
     Note that S0 is a singular matrix as V̂ is symmetric, so there are redundant elements in ϕ̂. We could have written
ϕ̂ as [µ̂0 , vech(V̂ )0 ]0 , but the results are the same under both specifications.


                                                               34
where x = vec(X). In order to prove this identity, we write:

                 V11 = [IK , 0K×N ]V [IK , 0K×N ]0,         V21 = [0N ×K , IN ]V [IK , 0K×N ]0        (A8)

to obtain
                                 ∂vec(V11)
                                               = [IK , 0K×N ] ⊗ [IK , 0K×N ],                         (A9)
                                 ∂vec(V )0
                                 ∂vec(V21)
                                               = [IK , 0K×N ] ⊗ [0N ×K , IN ].                        (A10)
                                 ∂vec(V )0
With the following identity
                             −1                −1
                      ∂vec(V11    )     ∂vec(V11  ) ∂vec(V11)
                                0
                                      =
                       ∂vec(V )         ∂vec(V11)0 ∂vec(V )0
                                            −1      −1
                                      = −(V11  ⊗ V11   ) ([IK , 0K×N ] ⊗ [IK , 0K×N ])
                                           −1                −1
                                      = [V11  , 0K×N ] ⊗ [−V11  , 0K×N ],                             (A11)

we can use the product rule to obtain
                                                                              −1
               ∂vec(β)            −1      ∂vec(V21)                    ∂vec(V11    )
                             = (V11  ⊗ IN )           + (I K ⊗  V 21 )
               ∂vec(V )0                  ∂vec(V )  0                   ∂vec(V ) 0
                                  −1                              −1
                             = [V11 , 0K×N ] ⊗ [0N ×K , IN ] + [V11 , 0K×N ] ⊗ [−β, 0N ×N ]
                                  −1
                             = [V11  , 0K×N ] ⊗ [−β, IN ].                                            (A12)

Finally, using the identity
                                            ∂x
                                                   = [0K , IK ]0 ⊗ IN ,                               (A13)
                                          ∂vec(β)0
we obtain:
                    ∂x          ∂x     ∂vec(β)             −1 0
                                                                         
                          0
                            =        0         0
                                                 = [0K , V11 ] , 0(K+1)×N ⊗ [−β, IN ].                (A14)
                 ∂vec(V )     ∂vec(β) ∂vec(V )
Let Km,n be a commutation matrix (see, e.g., Magnus and Neudecker (1999)) such that Km,n vec(A) =
vec(A0 ) where A is an m × n matrix. In addition, denote Kn,n by Kn . Then, using the product
rule, we obtain:
                                                                                         −1
    ∂γ          0 −1             ∂vec(H)        0 −1      ∂vec(X 0)      0      0 ∂vec(V22 )
           = (µ  V
                2 22 X ⊗ I K+1 )           + (µ  V
                                                2 22 ⊗ H)           + (µ 2 ⊗ HX  )           . (A15)
 ∂vec(V )0                       ∂vec(V )0                ∂vec(V )0                ∂vec(V )0
The last two terms are given by
                           ∂vec(X 0)                   
                                                      −1 0
            (µ02 V22
                   −1
                      ⊗ H)                = [H 0K , V11    , 0(K+1)×N ] ⊗ [−µ02 V22
                                                                                  −1
                                                                                     β, µ02 V22
                                                                                              −1
                                                                                                 ],   (A16)
                           ∂vec(V )0
                                −1
                         ∂vec(V22    )
            (µ02 ⊗ HX 0)           0
                                          = −[00K , µ02 V22
                                                          −1
                                                             ] ⊗ [0(K+1)×K , A].                      (A17)
                          ∂vec(V )

                                                       35
For the first term, we use the chain rule to obtain
                          −1           ∂vec(H)
                   (µ02 V22  X ⊗ IK+1 )
                                       ∂vec(V )0
                        −1              ∂vec(H) ∂vec(H −1 )
               = (µ02 V22  X ⊗ IK+1 )
                                       ∂vec(H −1)0 ∂vec(V )0
                                                  
                           −1                            −1                     ∂x
               = −(µ02 V22    X ⊗ IK+1 )(H ⊗ H) (X 0V22     ⊗ IK+1 )KN,K+1
                                                                             ∂vec(V )0
                                         −1                                
                         0      0 ∂vec(V22 )               0 −1      ∂x
                  + (X ⊗ X )                 + (IK+1 ⊗ X V22 )
                                   ∂vec(V )0                     ∂vec(V )0
                                                                              
               = −(γ 0 ⊗ H) [−X 0V22    −1
                                           β, X 0V22
                                                   −1             −1 0
                                                      ] ⊗ [0K , V11 ] , 0(K+1)×N KN +K

                  − [0(K+1)×K , X 0V22 −1
                                          ] ⊗ [0(K+1)×K , X 0V22
                                                               −1
                                                                  ]
                           −1 0
                                               
                  + [0K , V11   ] , 0(K+1)×N ⊗ [−X 0V22  −1
                                                            β, X 0V22
                                                                    −1
                                                                       ]
                          −1 0
                                             
               = H[0K , V11   ] , 0(K+1)×N ⊗ [γ 0X 0V22 −1
                                                           β, −γ 0X 0V22−1
                                                                           ]
                                    −1                             −1
                   + [00K , γ 0X 0V22  ] ⊗ [0(K+1)×K , A] − [γ10 V11  , 00N ] ⊗ [−Aβ, A].                            (A18)
                                                                    −1
Combining the three terms and using the first order condition β 0 V22  e = 0K , we have:
              ∂γ                      −1 0
                                                                     
                       =    H[0K , V11    ] , 0(K+1)×N ⊗ 00K , e0 V22
                                                                    −1
           ∂vec(V )0
                                   −1
                                                                    −1
                                                                                      
                            − γ10 V11  , 00N ⊗ [−Aβ, A] − 00K , e0 V22    ⊗ 0(K+1)×K , A .                           (A19)

   Using the expression for ∂γ/∂ϕ0, we can simplify the asymptotic variance of γ̂ to
                                                        ∞
                                                        X
                                  V (γ̂) =                    E[ht(ϕ)ht+j (ϕ)0],                                     (A20)
                                                       j=−∞

where
                ∂γ
    ht (ϕ) =        rt(ϕ)
                ∂ϕ0
                                                                                            "                   #!
                                                                                                        −1
                                                                                                [0K , V11  ]H
            = A(Rt − µ2 ) + vec      [00K ,   e   0     −1
                                                      V22  ][(Yt                  0
                                                                   − µ)(Yt − µ) − V ]
                                                                                                 0N ×(K+1)
                                                                        "              #!
                                                                              −1
                                                                            V11  γ1
                 − vec [−Aβ, A][(Yt − µ)(Yt − µ)0 − V ]
                                                                             0N
                                                                             "              #!
                                                                                      0K
                 − vec [0(K+1)×K , A][(Yt − µ)(Yt − µ)0 − V ]                       −1
                                                                                  V22  e
                                  −1 0
            = (γt − γ) + H[0K , V11 ] (ft − µ1 )ut − A[(Rt − µ2 ) − β(ft − µ1 )](ft − µ1 )0V11
                                                                                             −1
                                                                                                γ1
                                            −1 0     −1
                 − A(Rt − µ2 )ut − H[0K , V11 ] V12V22  e − Aβγ1 + Aβγ1 + Ae

            = (γt − γ) + Hztut − (φt − φ)wt − (γt − γ)ut.                                                            (A21)

                                                             36
                                                              −1                               −1
The last equality follows from the first order condition X 0V22  e = 0K+1 (which implies β 0 V22  e = 0K
and Ae = 0K+1 ) and the fact that Aβ = AX[0K , IK ]0 = [0K , IK ]0 gives us
                                                        "           #
                                                              0
                  A(Rt − µ2 ) − Aβ(ft − µ1 ) = γt − γ −               = φt − φ.                     (A22)
                                                          f t − µ1

   Note that when the model is correctly specified, we have e = 0N , ut = 0, and ht (ϕ) can be
simplified to
                                     ht (ϕ) = (γt − γ) − (φt − φ)wt.                                (A23)

This completes the proof.

Proof of Lemma 1: In our proof, we rely on the mixed moments of multivariate elliptical distribu-
tions. Lemma 2 of Maruyama and Seo (2003) shows that if (Xi, Xj , Xk , Xl) are jointly multivariate
elliptically distributed and with mean zero, we have:

                           E[XiXj Xk ] = 0,                                                         (A24)

                        E[XiXj Xk Xl ] = (1 + κ)(σij σkl + σik σjl + σil σjk ),                     (A25)

where σij = Cov[Xi, Xj ]. We first note that since γt , φt , zt , wt, and ut are all linear functions of Rt
and ft , they are also jointly elliptically distributed. In addition, using (A22), we have φt − φ = At ,
where t = Rt − µ2 − β(ft − µ1 ), which is uncorrelated with ft . Using this result, we can easily
show that

                                      Var[γt] = AV22A0,                                             (A26)

                                     Var[φt ] = AΣA0,                                               (A27)
                                                    −1
                                      Var[zt ] = Ṽ11  ,                                            (A28)
                                                     −1
                                     Var[wt] = γ10 V11  γ1 ,                                        (A29)

                                     Var[ut ] = e0W V22 W e,                                        (A30)

                                  Cov[φt, zt0 ] = 0(K+1)×(K+1),                                     (A31)

                                 Cov[φt, wt] = 0K+1 ,                                               (A32)

                                  Cov[φt , ut] = AΣW e = AV22W e,                                   (A33)

                                  Cov[wt, zt0 ] = [0, γ10 V11
                                                            −1
                                                               ],                                   (A34)

                                  Cov[zt , ut] = 0K+1 ,                                             (A35)

                                 Cov[wt, ut] = 0.                                                   (A36)

                                                    37
   Using these second moments, we can then apply (A24) and (A25) to obtain

                      E[(γt − γ)(φt − φ)0wt] = 0(K+1)×(K+1) ,                                    (A37)

                              E[(γt − γ)zt0 ut] = 0(K+1)×(K+1) ,                                 (A38)
                                                                         −1
                                    E[ztzt0 u2t ] = (1 + κ)e0 W V22W eṼ11  ,                    (A39)

                            E[(φt − φ)zt0 wt ut] = (1 + κ)AV22W e[0, γ10 V11
                                                                           −1
                                                                              ],                 (A40)
                                                            −1
                     E[(φt − φ)(φt − φ)0wt2] = (1 + κ)γ10 V11  γ1 AΣA0.                          (A41)

Using these results and the i.i.d. assumption, we can now write:

       V (γ̂) = E[hth0t ]

              = Var[γt] − E[(γt − γ)(φt − φ)0wt ] + E[(γt − γ)zt0 ut ]H

                   + E[(φt − φ)(φt − φ)0wt2 ] − E[(φt − φ)(γt − γ)0wt] − E[(φt − φ)zt0 wtut ]H

                   + HE[ztzt0 u2t ]H + HE[zt(γt − γ)0ut ] − HE[zt(φt − φ)0 ut wt]

              = AV22A0 + (1 + κ)(γ10 V11
                                       −1
                                          γ1 )AΣA0 + (1 + κ)e0 W V22W eH Ṽ11
                                                                            −1
                                                                               H
                                             −1                        −1 0 0
                   − (1 + κ)AV22W e[0, γ10 V11  ]H − (1 + κ)H[0, γ10 V11 ] e W V22A0 .           (A42)

This completes the proof.

Proof of Lemma 2: Under the i.i.d. assumption, the expression for V (γ̂) is given by

    E[hth0t ] = Var[γt] − E[(γt − γ)(φt − φ)0 wt] + E[(γt − γ)zt0 ut ]H − E[(γt − γ)(γt − γ)0ut ]

                  + E[(φt − φ)(φt − φ)0 wt2] − E[(φt − φ)(γt − γ)0wt] − E[(φt − φ)zt0 wt ut]H

                  + E[(φt − φ)(γt − γ)0wtut ] + HE[ztzt0 u2t ]H + HE[zt(γt − γ)0ut ]

                  − HE[zt(φt − φ)0ut wt] − HE[zt(γt − γ)0u2t ] + E[(γt − γ)(γt − γ)0u2t ]

                  − E[(γt − γ)(γt − γ)0ut] + E[(γt − γ)(φt − φ)0wt ut] − E[(γt − γ)zt0 u2t ]H.   (A43)

Following the proof of Lemma 1, we have:

                                      Var[γt] = H,                                               (A44)

                     E[(γt − γ)(φt − φ)0 wt] = 0(K+1)×(K+1) ,                                    (A45)

                              E[(γt − γ)zt0ut ] = 0(K+1)×(K+1) ,                                 (A46)

                                    E[ztzt0 u2t ] = (1 + κ)QṼ11
                                                               −1
                                                                  ,                              (A47)

                                                  38
                               E[(φt − φ)zt0 wtut ] = 0(K+1)×(K+1) ,                                             (A48)

                         E[(φt − φ)(φt − φ)0 wt2] = (1 + κ)γ10 V11
                                                                 −1
                                                                    γ1(X 0Σ−1 X)−1,                              (A49)

                           E[(γt − γ)(γt − γ)0ut ] = 0(K+1)×(K+1) ,                                              (A50)

                       E[(φt − φ)(γt − γ)0wtut ] = 0(K+1)×(K+1) ,                                                (A51)

                          E[(γt − γ)(γt − γ)0u2t ] = (1 + κ)QH,                                                  (A52)
                                                             "                           #
                                                                              0    00K
                                  E[zt(γt − γ)0u2t ] = (1 + κ)Q                              .                   (A53)
                                                                              0K   IK

By partitioning H as                                  "               #
                                                          H11 H12
                                               H=                         ,                                      (A54)
                                                          H21 H22
where H11 is the (1, 1) element of H, and using (A44)–(A53), we can write:

                                     −1                                −1
        E[hth0t ] = H + (1 + κ)γ10 V11  γ1(X 0Σ−1 X)−1 + (1 + κ)QH Ṽ11   H
                                   "            #                            "         #
                                       0 00K                                    0 00K
                      − (1 + κ)QH                 + (1 + κ)QH − (1 + κ)Q                 H
                                     0K IK                                     0K IK
                                                   "             #!
                                                              0
                                           −1         H 11  0 K
                  = Υw + (1 + κ)Q H Ṽ11      H+
                                                      0K −H22
                                    "                                             #
                                              −1                     −1
                                       H12 V11   H21 + H11      H12V11  H22
                  = Υw + (1 + κ)Q                 −1             −1
                                                                                    .         (A55)
                                          H22V11     H21    H22V11  H22 − H22
                                                                 "             #
                                                                           0
                                                                    0    0 K
By applying the identity (X 0Σ−1 X)−1 = H − Ṽ11, where Ṽ11 =                  , we can verify that
                                                                   0K V11
the expression of Υw2 in Lemma 2 is the same as the second term in (A55) as follows:42

       (X 0Σ−1 X)−1Ṽ11
                      −1
                         (X 0Σ−1 X)−1 + (X 0Σ−1 X)−1 = (H − Ṽ11)Ṽ11
                                                                    −1
                                                                       (H − Ṽ11) + H − Ṽ11
                                                                   "               #
                                                                      H      0 0
                                                            −1          11     K
                                                     = H Ṽ11  H+                    .       (A56)
                                                                       0K −H22

In particular, the misspecification adjustment term for V (γ̂1) is

                           −1
             (1 + κ)Q(H22V11  H22 − H22)
                       −1            −1       −1
        = (1 + κ)QH22V11  (V11 − V11H22 V11)V11  H22
                       −1             −1            −1
        = (1 + κ)QH22V11  [V11 − V12V22  V21 + V12V22  1N (10N V22
                                                                 −1
                                                                    1N )−1 10N V22
                                                                                 −1       −1
                                                                                    V21]V11  H22, (A57)
  42
     By comparing V (γ̂) for the estimated GLS case with the V (γ̂) for the true GLS case in (29), it is easy to see that
              −1               −1
the use of V̂22   instead of V22  as weighting matrix increases the asymptotic variance of γ̂0 but reduces the asymptotic
variance of γ̂1 .


                                                           39
                                                −1
where the last equality is obtained by writing H22 as

                            −1         −1          −1           −1             −1
                           H22 = β 0 V22  β − β 0V22  1N (10N V22  1N )−110N V22  β.               (A58)

This completes the proof.

Proof of Proposition 4: (1) ρ2 = 1: We first derive the asymptotic distribution of

                             T Q̂ = T (µ̂02 Ŵ µ̂2 − µ̂02 Ŵ X̂(X̂ 0Ŵ X̂)−1 X̂ 0Ŵ µ̂2 )          (A59)

                                  a.s.
under H0 : ρ2 = 1, where Ŵ −→ W (this includes the known weighting matrix case as a special
case). This can be accomplished by using the GMM results of Hansen (1982). Let θ = (θ10 , θ20 )0 ,
where θ1 = (α0 , vec(β)0)0 and θ2 = γ. Define
                                         "          # "           #
                                           g1t(θ1 )      l t ⊗ t
                                gt (θ) ≡             =              ,                              (A60)
                                           g2t(θ)       Rt − Xγ

where lt = [1, ft0 ]0 and t = Rt − α − βft . When the model is correctly specified, we have
E[gt(θ)] = 0p+N , where p = N (K + 1). The sample moments of gt (θ) are given by
                                           " PT               #
                                            1
                                            T   t=1 g1t (θ1 )
                                 ḡT (θ) =   1
                                               PT               .                                  (A61)
                                             T   t=1 g 2t (θ)

Let θ̂ = (θ̂10 , θ̂20 )0 , where θ̂1 = (α̂0, vec(β̂)0)0 is the OLS estimator of α and β, and

                                         θ̂2 = γ̂ = (X̂ 0Ŵ X̂)−1 X̂ 0Ŵ µ̂2                       (A62)

is the second-pass CSR estimator of γ. Note that θ̂ is the solution to the following first order
condition
                                              BT ḡT (θ) = 0p+K+1 ,                                (A63)

where                        "                        #          "                      #
                                    Ip        0p×N        a.s.         Ip       0p×N
                      BT =                                −→                                ≡ B.   (A64)
                                 0(K+1)×p X̂ 0Ŵ                     0(K+1)×p X 0W
Writing

                              lt ⊗ t = vec(t lt0 ) = (lt ⊗ IN )vec(t ),                         (A65)

                                   t = Rt − α − βft = Rt − (lt0 ⊗ IN )θ1 ,                        (A66)

                                 βγ1 = (γ10 ⊗ IN )vec(β),                                          (A67)

                                                          40
we have:

                                         ∂g1t(θ1 )
                                                          = −ltlt0 ⊗ IN ,                                                (A68)
                                           ∂θ10
                                         ∂g1t(θ1 )
                                                          = 0p×(K+1),                                                    (A69)
                                           ∂θ20
                                          ∂g2t(θ)
                                                          = [0, −γ10 ] ⊗ IN ,                                            (A70)
                                           ∂θ10
                                          ∂g2t(θ)
                                                          = −X.                                                          (A71)
                                           ∂θ20

Let

                                          ∂ḡT (θ)
                             DT    =            0
                                          " ∂θ         PT                                  #
                                                    1             0
                                              −     T     t=1 lt lt ⊗ IN       0p×(K+1)
                                   =
                                                    [0,   −γ10 ] ⊗ IN              −X
                                          "                                        #
                                  a.s.         −E[ltlt0 ] ⊗ IN       0p×(K+1)
                                  −→                                                 ≡ D.                                (A72)
                                              [0,   −γ10 ]   ⊗ IN         −X

Hansen (1982, Lemma 4.1) shows that when the model is correctly specified, we have:
                  √          A
                      T ḡT (θ̂) ∼ N (0p+N , [Ip+N − D(BD)−1 B]S[Ip+N − D(BD)−1 B]0 ),                                   (A73)

where
                                                    ∞
                                                    X
                                          S=               E[gt(θ)gt+j (θ)0 ].                                           (A74)
                                                  j=−∞

Using the partitioned matrix inverse formula, it is easy to verify that
                                        "           −1           −1
                                                                     #
                                 0 −1
                                          1 + µ01 V11  µ1 −µ01 V11
                            E[ltlt] =            −1            −1
                                                                       .                                                 (A75)
                                            −V11    µ1       V11

It follows that
                                         "                                           #
                                               −E[ltlt0 ] ⊗ IN            0p×(K+1)
                             BD =                                                        ,                               (A76)
                                              [0, −γ10 ] ⊗ X 0W            −H −1
                                         "                                                       #
                                                    −E[ltlt0 ]−1 ⊗ IN              0p×(K+1)
                         (BD)−1 =                     −1            −1
                                                                                                     ,                   (A77)
                                              [−γ10 V11  µ1 , γ10 V11  ]⊗A           −H
                                         "                                                               #
                                                                     Ip                          0p×N
                  D(BD)−1 B =                         −1            −1
                                                                                                             ,           (A78)
                                              [−γ10 V11  µ1 , γ10 V11  ] ⊗ (IN − XA) −XA
                                         "                                                                       #
                                                                    0p×p                             0p×N
            IN − D(BD)−1 B =                         −1             −1
                                                                                                                     .   (A79)
                                              [γ10 V11  µ1 , −γ10 V11  ] ⊗ (IN − XA) IN − XA

                                                             41
We now provide a simplification of the asymptotic distribution of ḡ2T (θ̂). From (A73), we have:
                                             √                A
                                                 T ḡ2T (θ̂) ∼ N (0N , Vq ),                                                   (A80)

where
                                                     ∞
                                                     X
                                        Vq =                 E[qt(θ)qt+j (θ)0 ],                                               (A81)
                                                     j=−∞

and

                  qt (θ) = [0N ×p, IN ](IN − D(BD)−1 B)gt (θ)
                                              −1
                         = −(IN − XA)t γ10 V11  (ft − µ1 ) + (IN − XA)(Rt − Xγ)

                         = (IN − XA)[Rt − Rt γ10 V11
                                                   −1
                                                      (ft − µ1 )]

                         = [IN − X(X 0W X)−1X 0W ]Rtyt
                                  1                  1                                         1        1
                         = W − 2 [IN − W 2 X(X 0W X)−1X 0W 2 ]W 2 Rtyt
                                  1                  1                                     1        1
                         = W − 2 [IN − W 2 C(C 0 W C)−1 C 0 W 2 ]W 2 Rtyt
                                  1              1
                         = W − 2 P P 0 W 2 R t yt ,                                                                            (A82)

                   −1
where yt = 1−γ10 V11  (ft −µ1 ) = 1−λ01(ft −µ1 ) follows from (10). The second equality holds because
α = µ2 − βµ1 = 1N γ0 + β(γ1 − µ1 ) = Xφ when the model is correctly specified and β = X[0K , IK ].
Therefore, α + βft vanishes when premultiplied by IN − XA and we have

                     (IN − XA)t = (IN − XA)(Rt − α − βft ) = (IN − XA)Rt.                                                     (A83)

With this expression of qt , we can write Vq as

                                                     1            1             1                  1
                                   Vq = W − 2 P P 0 W 2 SW 2 P P 0 W − 2 ,                                                     (A84)

                                                                            PT
where S is the asymptotic covariance matrix of                        √1
                                                                        T           t=1 Rt yt .         Having derived the asymptotic
distribution of ḡ2T (θ̂), the asymptotic distribution of Q̂ is given by
                                                                                    N −K−1
                                                                                      X
                                                                                A
                                T Q̂ = T ḡ2T (θ̂)0Ŵ ḡ2T (θ) ∼                                   ξj x j ,                    (A85)
                                                                                      j=1

where the xj ’s are independent χ21 random variables, and the ξj ’s are the N − K − 1 nonzero
eigenvalues of
                                         1               1                  1          1
                                      W 2 Vq W 2 = P P 0 W 2 SW 2 P P 0 .                                                      (A86)

                                                              42
                                                        1     1               a.s.
Equivalently, the ξj ’s are the eigenvalues of P 0 W 2 SW 2 P . Since Q̂0 −→ Q0 > 0, we have:
                                                             N −K−1
                                                               X ξj
                                                     T Q̂ A
                                   T (ρ̂2 − 1) = −        ∼−           xj .                          (A87)
                                                     Q̂0            Q0
                                                               j=1


(2) 0 < ρ2 < 1: The proof uses the same notation and delta method employed in Propositions 1
and 2 to obtain the asymptotic distribution of ρ̂2 as
                                                                 
                           √                         X∞
                                          A
                             T (ρ̂2 − ρ2) ∼ N 0,       E[ntnt+j ] ,                                (A88)
                                                            j=−∞

where
                                                      ∂ρ2
                                               nt =       rt(ϕ).                                     (A89)
                                                      ∂ϕ0

   Obtaining an explicit expression for nt requires computing ∂ρ2/∂ϕ0. For both the known weight-
ing matrix case and the estimated GLS case, we have:
                                     ∂ρ2
                                            = 0K ,                                                   (A90)
                                     ∂µ1
                                     ∂ρ2
                                            = 2Q−1         2
                                                0 W [(1 − ρ )e0 − e].                                (A91)
                                     ∂µ2
Equation (A90) follows because ρ2 does not depend on µ1 . For (A91), using the first order conditions
10N W e0 = 0 and X 0W e = 0K+1 and letting Q0 = e00 W e0 , we have:
                                      ∂Q0                    ∂Q
                                          = 2W e0,               = 2W e.                             (A92)
                                      ∂µ2                    ∂µ2
It follows that
   ∂ρ2        ∂Q         ∂Q0
       = −Q−1
           0      + Q−2
                     0 Q     = −2Q−1         −2         −1         2
                                  0 W e + 2QQ0 W e0 = 2Q0 W [(1 − ρ )e0 − e].                        (A93)
   ∂µ2        ∂µ2        ∂µ2
The expression for ∂ρ2/∂vec(V )0 , however, depends on whether we use a known W or an estimate
of W , say Ŵ , as the weighting matrix. We start with the known weighting matrix W case.
Differentiating Q = e0 W e with respect to vec(V ), we obtain:
                                                                                  
            ∂Q         0   ∂(µ2 − Xγ)         0      0         ∂x           ∂γ
                   = 2e W              = −2e W (γ ⊗ IN )              +X             .               (A94)
         ∂vec(V )0          ∂vec(V )0                       ∂vec(V )0    ∂vec(V )0
Note that the second term vanishes because of the first order condition X 0W e = 0K+1 . Using (A7)
for the first term and the fact that β 0 W e = 0K gives
          ∂Q                                                                                   
                 0
                   = −2e0 W [γ10 V11
                                   −1
                                      , 00N ] ⊗ [−β, IN ] = −2 [γ10 V11
                                                                      −1
                                                                         , 00N ] ⊗ [00K , e0 W ] .   (A95)
        ∂vec(V )

                                                       43
Since Q0 = e00 W e0 does not depend on V , we have:

                       ∂ρ2               ∂Q               0 −1 0   0        
                              0
                                = −Q−1
                                    0           0
                                                  = 2Q−1
                                                      0   γ1V11 , 0N ⊗ 0K , e0W .                  (A96)
                     ∂vec(V )          ∂vec(V )

Therefore, for the known weighting matrix W case, nt is given by

                  ∂ρ2
          nt =        rt(ϕ)
                  ∂ϕ0
                = 2Q−1       2 0     0                  −1 0                      0 −1
                    0 [(1 − ρ )e0 − e ]W (Rt − µ2 ) + 2Q0 e W (Rt − µ2 )(ft − µ1 ) V11 γ1

                = 2Q−1                2
                    0 [−ut yt + (1 − ρ )vt ].                                                      (A97)


                              −1                               −1
   We now turn to the Ŵ = V̂22  case. Differentiating Q = e0V22  e with respect to vec(V ), we
obtain:
                                                              −1
      ∂Q                   ∂(µ2 − Xγ)                0 ∂vec(V22 )
                   = 2e0 V22
                           −1
                                         +  (e 0
                                                 ⊗ e  )
    ∂vec(V )0               ∂vec(V )0                   ∂vec(V )0
                                                                                                   
                   = −2 [γ1V11 , 0N ] ⊗ [0K , e V22 ] − (e0 ⊗ e0) [0N ×K , V22
                          0 −1    0       0      0 −1                        −1                −1
                                                                                ] ⊗ [0N ×K , V22  ]

                   = −[2γ10 V11
                              −1
                                 , e0V22
                                       −1
                                          ] ⊗ [00K , e0 V22
                                                          −1
                                                             ].                                    (A98)


Similarly, we have:

                                  ∂Q0                     −1                  −1
                                          = −[00K , e00 V22  ] ⊗ [00K , e00 V22  ].                (A99)
                                ∂vec(V )0

It follows that

                         ∂ρ2                    ∂Q                 ∂Q0
                                     = −Q−1
                                          0             + Q−2
                                                            0 Q
                       ∂vec(V )0              ∂vec(V )0         ∂vec(V )0
                                             0 −1 0 −1   0                
                                     = Q−1
                                        0    2γ1V11 , e V22 ⊗ 0K , e0 V22 −1

                                                         0          0            
                                       − Q−1        2         0 −1
                                            0 (1 − ρ ) 0K , e0 V22  ⊗ 0K , e00 V22
                                                                                 −1
                                                                                      .           (A100)


Therefore, we have:

            ∂ρ2
      nt =      rt(ϕ)
            ∂ϕ0
          = 2Q−1       2 0     0   −1              −1 0 −1              0 −1
              0 [(1 − ρ )e0 − e ]V22 (Rt − µ2 ) + Q0 e V22 (Rt − µ2 )[2γ1 V11 (ft − µ1 )
                         −1
                  + e0 V22  (Rt − µ2 )] − Q−1      2   0 −1             2   −1     −1      2
                                           0 (1 − ρ )[e0 V22 (Rt − µ2 )] − Q0 Q + Q0 (1 − ρ )Q0

          = Q−1  2                  2         2
             0 [ut − 2ut yt + (1 − ρ )(2vt − vt )].                                               (A101)

                                                          44
(3) ρ2 = 0: We start by rewriting Q0 − Q as

        Q0 − Q = µ02 W X(X 0W X)−1 X 0W µ2 − µ02 W 1N (10N W 1N )−1 10N W µ2
                                                     "                          #
                                                           0         −1     0
                                                        (1 N W 1 N )      0 K
               = µ02 W X(X 0W X)−1 X 0W µ2 − µ02 W X                              X 0 W µ2
                                                              0K         0K×K
                                           "                          #
                   0   0        0   0
                                             (10N W 1N )−1     00K
               = γ (X W X)γ − γ (X W X)                                 (X 0W X)γ
                                                   0K         0K×K
                                  "                                           #
                   0   0        0
                                    10N W 1N              10N W β
               = γ (X W X)γ − γ                                                 γ
                                    β 0 W 1N β 0 W 1N (10N W 1N )−1 10N W β
                    = γ10 [β 0W β − β 0 W 1N (10N W 1N )−1 10N W β]γ1.                                       (A102)

The matrix in the middle is positive definite because X is assumed to be of full column rank, so
the necessary and sufficient condition for Q0 = Q (i.e., ρ2 = 0) is γ1 = 0K . Note that (A102) also
holds for its sample counterpart, so we can write ρ̂2 as

                               Q̂   Q̂0 − Q̂  γ̂ 0 [β̂ 0 Ŵ β̂ − β̂ 0 Ŵ 1N (10N Ŵ 1N )−1 10N Ŵ β̂]γ̂1
                  ρ̂2 = 1 −       =          = 1                                                         .   (A103)
                              Q̂0      Q̂0                                  Q̂0

Under the null hypothesis H0 : γ1 = 0K , we have:
                                               √      A
                                                T γ̂1 ∼ N (0K , V (γ̂1)),                                    (A104)

                                                                                                                a.s.
where V (γ̂1) is the asymptotic variance of γ̂1 obtained under the misspecified model. As Q̂0 −→
Q0 > 0 and

                                                       a.s.
        β̂ 0Ŵ β̂ − β̂ 0 Ŵ 1N (10N Ŵ 1N )−1 10N Ŵ β̂ −→ β 0 W β − β 0 W 1N (10N W 1N )−1 10N W β,         (A105)

it follows that
                                                          K
                                                          X
                                                      2 A   ξj
                                                   T ρ̂ ∼      xj ,                                          (A106)
                                                            Q0
                                                              j=1

where the xj ’s are independent χ21 random variables and the ξj ’s are the eigenvalues of

                                  [β 0W β − β 0 W 1N (10N W 1N )−1 10N W β]V (γ̂1).                          (A107)

This completes the proof.

Proof of Lemma 3: Partition CA = [CAa , CAb ], where CAa is the first K1 + 1 columns of CA and
CAb is the last K2 columns of CA . Using the fact that CAa = CB , we can write the difference

                                                              45
between QB and QA as

 QB − QA = µ02 W CA (CA
                      0
                        W CA )−1 CA
                                  0
                                    W µ2 − µ02 W CB (CB0
                                                         W CB )−1 CB0
                                                                      W µ2
                                                    "                −1
                                                                                     #
                                                          0
             0        0       −1 0           0         (CAa W CAa )      0(K1 +1)×K2    0
         = µ2 W CA (CA W CA ) CA W µ2 − µ2 W CA                                        CA W µ2
                                                         0K2 ×(K1 +1)      0K2×K2
                                            "                                 #
                                                  0
             0   0             0    0
                                               (CAa W CAa )−1 0(K1+1)×K2          0
         = λA (CA W CA )λA − λA (CA W CA )                                      (CA W CA )λA
                                                 0K2 ×(K1 +1)      0K2 ×K2
             = λ0A,2 [CAb
                       0           0
                          W CAb − CAb         0
                                      W CAa (CAa W CAa )−1 (CAa
                                                             0
                                                                W CAb )]λA,2

             = λ0A,2 H̃A,22
                       −1
                            λA,2 ,                                                               (A108)

where H̃A,22 is the lower right K2 × K2 submatrix of H̃A . Since CA is assumed to be of full column
        −1
rank, H̃A,22 is a positive definite matrix. It follows that QA = QB if and only if λA,2 = 0K2 . This
completes the proof.

Proof that yA = yB implies eA = eB : Using the first order conditions for model A, we obtain:

    0 = 10N W eA = 10N W µ2 − 10N W 1N λA,0 − 10N W Cov[R, f10 ]λA,1 − 10N W Cov[R, f20 ]λA,2.   (A109)

This implies that the (pseudo) zero-beta rate of model A is

   λA,0 = (10N W 1N )−1 10N W (µ2 − Cov[R, f10 ]λA,1 − Cov[R, f20 ]λA,2) = (10N W 1N )−110N W E[RyA],
                                                                                                 (A110)
and the pricing errors of model A can be written as

                               eA = [IN − 1N (10N W 1N )−1 10N W ]E[RyA].                        (A111)

Similarly, the pricing errors of model B can be written as

                               eB = [IN − 1N (10N W 1N )−1 10N W ]E[RyB ].                       (A112)

Therefore, when yA = yB , we have eA = eB . This completes the proof.

Proof of Lemma 4: Given that yA = yB if and only if λA,1 = λB,1, λA,2 = 0K2 , and λB,3 = 0K3 , it
suffices to show that λA,2 = 0K2 and λB,3 = 0K3 imply λA,1 = λB,1. For model A, premultiplying
                       0 W C , we obtain:
both sides of (51) by CA    A
                                                                 
                       "                           #       λA,0       "              #
                            0 WC
                           CAa          0 WC
                                       CAa                                 0 Wµ
                                                                          CAa
                                  Aa          Ab                              2
                            0           0               λA,1  =          0
                                                                                         .       (A113)
                           CAb W CAa   CAb W CAb                          CAb W µ2
                                                         λA,2

                                                   46
When λA,2 = 0K2 , the first block of this equation gives us
                               "       #
                                  λA,0        0
                                          = (CAa W CAa )−1 CAa
                                                            0
                                                               W µ2 .                                         (A114)
                                  λA,1

Similarly for model B, when λB,3 = 0K3 , we have:
                             "       #
                                λB,0         0
                                        = (CBa W CBa )−1 CBa
                                                          0
                                                             W µ2 ,                                           (A115)
                                λB,1
                                                                                                0 ]],
where CBa is the first K1 +1 columns of CB . Since CAa and CBa are both equal to [1N , Cov[Rt, f1t
we have λA,0 = λB,0 and λA,1 = λB,1. This completes the proof.

Proof of Propositions 5 and 6: Since Proposition 5 is a special case of Proposition 6 when K3 = 0,
we only provide the proof of Proposition 6 here. We first derive a simplified expression for QB −QA .
The aggregate pricing-error measure for model A is given by

                       QA = e0A W eA = µ02 W µ2 − µ02 W CA (CA
                                                             0
                                                               W CA )−1 CA
                                                                         0
                                                                           W µ2 .                             (A116)

We now introduce a model M that uses only f1 as factors. The aggregate pricing-error measure for
model M is given by

                      QM = e0M W eM = µ02 W µ2 − µ02 W CM (CM
                                                            0
                                                              W CM )−1 CM
                                                                        0
                                                                          W µ2 ,                              (A117)

where CM = [1N , Cov[R, f10 ]]. Using the fact that the CAa = CBa = CM and (A108), we can write
the difference between QM and QA as

                                            QM − QA = λ0A,2H̃A,22
                                                             −1
                                                                  λA,2.                                       (A118)

Similarly, we have:
                                                         −1
                                        QM − QB = λ0B,3H̃B,33 λB,3.                                           (A119)

Subtracting (A119) from (A118), we obtain:
                                                                             "      −1
                                                                                                     #
                                −1                     −1
                                                                                  H̃A,22   0K2 ×K3
         Q B − QA =     λ0A,2 H̃A,22 λA,2   −   λ0B,3H̃B,33 λB,3   =ψ    0
                                                                                              −1
                                                                                                         ψ,   (A120)
                                                                                 0K3 ×K2   −H̃B,33

where ψ = [λ0A,2, λ0B,3]0. This equation also holds for its sample counterpart, and under the null
                                       √         1   A
hypothesis H0 : ψ = 0K2 +K3 , we have T V (ψ̂)− 2 ψ̂ ∼ N (0K2+K3 , IK2+K3 ). It follows that
                                                                KX
                                                                 2 +K3
                                                            A
                                            T (Q̂B − Q̂A ) ∼                 ξj x j ,                         (A121)
                                                                   j=1


                                                           47
where the xj ’s are independent χ21 random variables and the ξj ’s are the eigenvalues of
                                    "    −1
                                                       #
                                       H̃A,22  0K2 ×K3
                                                   −1
                                                         V (ψ̂).                                                        (A122)
                                      0K3 ×K2 −H̃B,33
                                                   a.s.
Since ρ̂2A − ρ̂2B = (Q̂B − Q̂A )/Q̂0 and Q̂0 −→ Q0 > 0, we have
                                                                      KX
                                                                       2 +K3
                                                                  A               ξj
                                         T (ρ̂2A − ρ̂2B ) ∼                          xj .                               (A123)
                                                                                  Q0
                                                                          j=1

This completes the proof.

Proof of Propositions 7 and 8: In the proof of Proposition 4, we show that when model A is correctly
specified,
                                              √               A
                                                  T êA ∼ N (0N , VqA ),                                                (A124)

where
                                                          ∞
                                                          X
                                                                         0
                                          VqA =                    E[qAtqA,t+j ],                                       (A125)
                                                      j=−∞

with
                                      1                   1                         1               1
                         qAt = W − 2 PA PA0 W 2 RtyAt = W − 2 PA PA0 W 2 gAt .                                          (A126)

A similar result holds for model B. Stacking up the pricing errors of the two models, we have:
                                        "      #
                                    √      êA A
                                      T          ∼ N (02N , Vq ),                          (A127)
                                           êB

where
                                                          ∞
                                                          X
                                                                           0
                                              Vq =                    E[qtqt+j ],                                       (A128)
                                                          j=−∞

and                                  "            #       "               1             1       #
                                          qAt                     W − 2 PA PA0 W 2 gAt
                              qt =                    =                   1             1
                                                                                                    .                   (A129)
                                          qBt                     W − 2 PB PB0 W 2 gBt
We can simplify Vq as
         "      1         1       1            1                              1             1           1   1   #
           W − 2 PA PA0 W 2 SAA W 2 PA PA0 W − 2                   W − 2 PA PA0 W 2 SAB W 2 PB PB0 W − 2
    Vq =        1         1       1            1                              1             1           1   1       .   (A130)
           W − 2 PB PB0 W 2 SBA W 2 PA PA0 W − 2                   W − 2 PB PB0 W 2 SBB W 2 PB PB0 W − 2

It follows that                           "               1           #
                                  √             P̂A0 Ŵ 2 êA             A
                             z=       T                   1               ∼ N (0nA +nB , Vz ),                          (A131)
                                                P̂B0 Ŵ êB
                                                          2



                                                                  48
where                            "          1              1                1        1   #
                                     PA0 W 2 SAA W 2 PA             PA0 W 2 SAB W 2 PB
                          Vz =              1              1                1        1       .       (A132)
                                     PB0 W 2 SBA W 2 PA PB0 W 2 SBB W 2 PB
Then, we have:
                                                               A
                                                z 0V̂z−1 z ∼ χ2nA +nB .                              (A133)

This completes the proof of Proposition 7.
                                     0 Ŵ 0 ê = 0
   Using the first order condition ĈA        A    K1 +K2 +1 , we can write:

                                        1                      1                         1       1
                   T Q̂A = T ê0A Ŵ 2 [P̂A P̂A0 + Ŵ 2 ĈA (ĈA
                                                               0
                                                                 Ŵ ĈA )−1 ĈA
                                                                              0
                                                                                Ŵ 2 ]Ŵ 2 êA
                                        1                1
                           = T ê0A Ŵ 2 P̂A P̂A0 Ŵ 2 êA
                              0
                           = zA zA ,                                                                 (A134)

                                                            0
where zA is the first nA elements of z. Similarly, T Q̂B = zB zB , where zB is the last nB elements
of z. Let QΞQ0 be the eigenvalue decomposition of
                                     "                     #
                                   1    −I n A
                                                0 n A ×n B
                                                               1
                                 Vz2                         Vz2 ,                                   (A135)
                                       0nB ×nA     In B

where Ξ = Diag(ξ1, · · · , ξnA +nB ) is a diagonal matrix of the eigenvalues of (A135) or, equivalently,
                                                      −1       A
of the eigenvalues of (70). Writing z̃ = Q0 Vz 2 z ∼ N (0nA+nB , InA+nB ), we have:
                         "                    #                                nAX+nB
                       0
                            −I n A
                                   0 n A ×n B        0 −2
                                                         1
                                                             0 −2
                                                                  1
                                                                         0
    T (Q̂B − Q̂A ) = z                          z = z Vz QΞQ Vz z = z̃ Ξz̃ =          ξj x j ,       (A136)
                           0nB ×nA    In B                                       j=1

               A
where xj = z̃j2 ∼ χ21 , j = 1, . . ., nA + nB , and they are asymptotically independent of each other.
                                                        a.s.
   Since ρ̂2A − ρ̂2B = (Q̂B − Q̂A )/Q̂0 and Q̂0 −→ Q0 > 0, we have:
                                                                   nAX
                                                                     +nB
                                                             A             ξj
                                        T (ρ̂2A   −   ρ̂2B ) ∼                xj .                   (A137)
                                                                           Q0
                                                                    j=1

This completes the proof of Proposition 8.

Proof of Proposition 9: We start from the known weighting matrix case. Using the results of
Proposition 4, we obtain the following expressions for models A and B:
                                   2 0
                                   ∂ρA
                    nAt (ϕ) =            rt(ϕ) = 2Q−1                   2
                                                    0 [−uAt yAt + (1 − ρA )vt ],                     (A138)
                                   ∂ϕ
                                   2 0
                                   ∂ρB
                    nBt(ϕ) =             rt(ϕ) = 2Q−1                   2
                                                    0 [−uBt yBt + (1 − ρB )vt ].                     (A139)
                                   ∂ϕ

                                                               49
Now, using the delta method and equations (A1)–(A4), the asymptotic distribution of ρ̂2A − ρ̂2B
when both models are misspecified is given by
                                                                          0                           !
            √                               A              ∂(ρ2A − ρ2B )                 ∂(ρ2A − ρ2B )
             T (ρ̂2A − ρ̂2B − (ρ2A − ρ2B )) ∼ N         0,                      S0                            .    (A140)
                                                                ∂ϕ                            ∂ϕ
                                                                                                     √
With the analytical expressions of nAt (ϕ) and nBt(ϕ), the asymptotic variance of                        T (ρ̂2A − ρ̂2B ) can
be written as
                                          ∞
                                          X
                                                E[dt(ϕ)dt+j (ϕ)],                                                  (A141)
                                         j=−∞

where                                             0
                                       ∂ρ2A ∂ρ2B
                         dt(ϕ) =           −            rt (ϕ) = nAt (ϕ) − nBt(ϕ).                                 (A142)
                                       ∂ϕ    ∂ϕ
Under H0 : ρ2A = ρ2B , we have:

                                   dt(ϕ) = 2Q−1
                                             0 (uBt yBt − uAt yAt ).                                               (A143)

                                                           −1
Using the same type of proof for the GLS case with Ŵ = V̂22  , we obtain:

                            dt(ϕ) = Q−1  2                2
                                     0 (uAt − 2uAt yAt − uBt + 2uBt yBt ).                                         (A144)

This completes the proof.




                                                    50
References

Ahn, Seung C., and Christopher Gadarowski. 2003. “Two-Pass Cross-Sectional Regression of
    Factor Pricing Models: Minimum Distance Approach.” Working Paper, Arizona State Uni-
    versity.

Bentler, Peter M., and Maia Berkane. 1986. “Greatest Lower Bound to the Elliptical Theory
    Kurtosis Parameter.” Biometrika 73: 240–241.

Black, Fischer, Michael C. Jensen, and Myron Scholes. 1972. “The Capital Asset Pricing Model:
    Some Empirical Findings.” In Jensen, M.C. (Ed.), Studies in the Theory of Capital Markets.
    Praeger, New York.

Campbell, John Y., Andrew W. Lo, and A. Craig MacKinlay. 1997. The Econometrics of Finan-
    cial Markets. Princeton University Press, Princeton.

Chen, Nai-Fu, Richard Roll, and Stephen A. Ross. 1986. “Economic Forces and the Stock
    Market.” Journal of Business 59: 383–404.

Chen, Robert, and Raymond Kan. 2003. “Finite Sample Analysis of Two-Pass Cross-Sectional
    Regressions.” Working Paper, University of Toronto.

Cochrane, John H. 1996. “A Cross-Sectional Test of an Investment-Based Asset Pricing Model.”
    Journal of Political Economy 104: 572-621.

Cochrane, John H. 2005. Asset Pricing. Princeton University Press, Princeton.

Davidson, Russell, and James D. MacKinnon. 2003. Econometric Theory and Methods. Oxford
    University Press, New York.

Fama, Eugene F., and James D. MacBeth. 1973. “Risk, Return and Equilibrium: Empirical
    Tests.” Journal of Political Economy 71: 607-636.

Fama, Eugene. F., and Kenneth R. French. 1992. “The Cross-Section of Expected Stock Returns.”
    Journal of Finance 47: 427–466.

Fama, Eugene. F., and Kenneth R. French. 1993. “Common Risk Factors in the Returns on
    Stocks and Bonds.” Journal of Financial Economics 33: 3–56.

                                             51
Ferson, Wayne E., and Rudi W. Schadt. 1996. “Measuring Fund Strategy and Performance in
    Changing Economic Conditions.” Journal of Finance 51: 425–461.

Golden, Richard M. 2003. “Discrepancy Risk Model Selection Test Theory for Comparing Possibly
    Misspecified or Nonnested Models.” Psychometrika 68: 229–249.

Grauer, Robert R., and Johannus A. Janmaat. 2009. “On the Power of Cross-Sectional and
    Multivariate Tests of the CAPM.” Journal of Banking and Finance, forthcoming.

Hall, Alastair R., and Atsushi Inoue. 2003. “The Large Sample Behaviour of the Generalized
    Method of Moments Estimator in Misspecified Models.” Journal of Econometrics 114: 361–
    394.

Hansen, Lars P. 1982. “Large Sample Properties of Generalized Method of Moments Estimators.”
    Econometrica 50: 1029–1054.

Hansen, Lars P., and Ravi Jagannathan. 1997. “Assessing Specification Errors in Stochastic
    Discount Factor Models.” Journal of Finance 52: 557–590.

Hou, Kewei, and Robert Kimmel. 2006. “On the Estimation of Risk Premia in Linear Factor
    Models.” Working Paper, Ohio State University.

Jagannathan, Ravi, and Zhenyu Wang. 1996. “The Conditional CAPM and the Cross-section of
    Expected Returns.” Journal of Finance 51: 3–53.

Jagannathan, Ravi, and Zhenyu Wang. 1998. “An Asymptotic Theory for Estimating Beta-
    Pricing Models Using Cross-Sectional Regression.” Journal of Finance 53: 1285–1309.

Jagannathan, Ravi, Keiichi Kubota, and Hitoshi Takehara. 1998. “Relationship Between Labor-
    Income Risk and Average Return: Empirical Evidence From the Japanese Stock Market.”
    Journal of Business 71: 319–348.

Jagannathan, Ravi, and Yong Wang. 2007. “Lazy Investors, Discretionary Consumption, and the
    Cross-Section of Stock Returns.” Journal of Finance 62: 1623–1661.

Jagannathan, Ravi, Georgios Skoulakis, and Zhenyu Wang. 2008. “The Analysis of the Cross
    Section of Security Returns.” Handbook of Financial Econometrics, forthcoming.

                                            52
Kan, Raymond, and Cesare Robotti. 2008. “Model Comparison Using the Hansen-Jagannathan
    Distance.” Review of Financial Studies, forthcoming.

Kan, Raymond, and Cesare Robotti. 2009. “A Note on the Estimation of Asset Pricing Models
    Using Simple Regression Betas.” Working Paper, University of Toronto.

Kan, Raymond, and Chu Zhang. 1999. “Two-Pass Tests of Asset Pricing Models with Useless
    Factors.” Journal of Finance 54: 203–235.

Kandel, Shmuel, and Robert F. Stambaugh. 1995. “Portfolio Inefficiency and the Cross-Section
    of Expected Returns.” Journal of Finance 50: 157–184.

Lettau, Martin, and Sydney C. Ludvigson. 2001. “Resurrecting the (C)CAPM: A Cross-Sectional
    Test when Risk Premia are Time-Varying.” Journal of Political Economy 109: 1238–1287.

Lewellen, Jonathan W., Stefan Nagel, and Jay Shanken. 2009. “A Skeptical Appraisal of Asset-
    Pricing Tests.” Journal of Financial Economics, forthcoming.

Li, Haitao, Yuewu Xu, and Xiaoyan Zhang. 2009. “Evaluating Asset Pricing Models Using the
    Second Hansen-Jagannathan Distance.” Journal of Financial Economics, forthcoming.

Magnus, Jan R., and Heinz Neudecker. 1999. Matrix Differential Calculus with Applications in
    Statistics and Econometrics. Wiley, New York.

Maruyama, Yosihito, and Takashi Seo. 2003. “Estimation of Moment Parameter in Elliptical
    Distributions.” Journal of the Japan Statistical Society 33: 215–229.

Newey, Whitney K. 1984. “A Method of Moments Interpretation of Sequential Estimators.”
    Economics Letters 14: 201–206.

Newey, Whitney K., and Kenneth D. West. 1987. “A Simple Positive Definite Heteroskedasticity
    and Autocorrelation Consistent Covariance Matrix.” Econometrica 55: 703–708.

Newey, Whitney K., and Kenneth D. West. 1994. “Automatic Lag Selection in Covariance Matrix
    Estimation.” Review of Economic Studies 61: 631–653.

Pagan, Adrian. 1984. “Econometric Issues in the Analysis of Regressions with Generated Regres-
    sors.” International Economic Review 25: 221–247.

                                              53
Petkova, Ralitsa. 2006. “Do the Fama-French Factors Proxy for Innovations in Predictive Vari-
    ables?” Journal of Finance 61: 581–612.

Rivers, Douglas, and Quang H. Vuong. 2002. “Model Selection Tests for Nonlinear Dynamic
    Models.” Econometrics Journal 5: 1–39.

Roll, Richard, and Stephen A. Ross. 1994. “On the Cross-sectional Relation between Expected
    Returns and Betas.” Journal of Finance 49: 101–121.

Shanken, Jay. 1985. “Multivariate Tests of the Zero-Beta CAPM.” Journal of Financial Eco-
    nomics 14: 327–348.

Shanken, Jay. 1990. “Intertemporal Asset Pricing: An Empirical Investigation.” Journal of
    Econometrics 45: 99–120.

Shanken, Jay. 1992. “On the Estimation of Beta-Pricing Models.” Review of Financial Studies
    5: 1–33.

Shanken, Jay, and Guofu Zhou. 2007. “Estimating and Testing Beta Pricing Models: Alternative
    Methods and their Performance in Simulations.” Journal of Financial Economics 84: 40–86.

Vuong, Quang H. 1989. “Likelihood Ratio Tests for Model Selection and Non-Nested Hypotheses.”
    Econometrica 57: 307–333.

White, Halbert L. 1994. Estimation, Inference and Specification Analysis. Cambridge, New York.




                                              54
                                   TABLE 1
      Sample Cross-Sectional R2 s and Specification Tests of the Models


                                              Panel A: OLS


                        CAPM       CCAPM           FF3        C-LAB       C-CCAPM         ICAPM
           2
          ρ̂             0.213       0.036        0.769        0.691         0.526         0.793
          p(ρ2 = 1)      0.000       0.000        0.000        0.102         0.211         0.209
          se(ρ̂2)        0.236       0.118        0.099        0.156         0.447         0.115
          p(ρ2 = 0)      0.099       0.545        0.004        0.007         0.367         0.004
          Q̂c            0.091       0.113        0.070        0.036         0.021         0.029
          p1 (Qc = 0)    0.000       0.000        0.002        0.327         0.935         0.480
          p2 (Qc = 0)    0.000       0.000        0.004        0.378         0.947         0.527
          No. of par.      2           2            4            4             4             6


                                              Panel B: GLS


                        CAPM       CCAPM           FF3        C-LAB       C-CCAPM         ICAPM
          ρ̂2            0.127       0.045        0.336        0.158         0.388         0.389
          p(ρ2 = 1)      0.000       0.000        0.001        0.000         0.423         0.226
          se(ρ̂2)        0.085       0.076        0.114        0.106         0.229         0.189
          p(ρ2 = 0)      0.004       0.228        0.000        0.244         0.004         0.030
          Q̂c            0.089       0.108        0.071        0.084         0.037         0.039
          p1 (Qc = 0)    0.000       0.000        0.001        0.000         0.445         0.156
          p2 (Qc = 0)    0.000       0.000        0.003        0.000         0.501         0.194
          No. of par.      2           2            4            4             4             6




  Note.–The table presents the sample cross-sectional R2 (ρ̂2 ) and the generalized CSRT (Q̂c ) of six beta
pricing models. The models include the unconditional CAPM (CAPM), the consumption CAPM (CCAPM),
the Fama and French (1993) three-factor model (FF3), the conditional CAPM (C-LAB) of Jagannathan and
Wang (1996), the conditional CCAPM (C-CCAPM), and the intertemporal CAPM (ICAPM) of Petkova
(2006). The models are estimated using monthly returns on the 25 Fama-French size and book-to-market
ranked portfolios. Most of the data are from May 1953 to December 2006 (644 observations), but the data
for the CCAPM and C-CCAPM start in February 1959 (575 observations). p(ρ2 = 1) is the p-value for the
test of H0 : ρ2 = 1. se(ρ̂2 ) is the standard error of ρ̂2 under the assumption that 0 < ρ2 < 1. p(ρ2 = 0) is
the p-value for the test of H0 : ρ2 = 0. p1(Qc = 0) is the p-value for the asymptotic test of H0 : Qc = 0.
p2 (Qc = 0) is the p-value for the approximate F -test of H0 : Qc = 0. No. of par. is the number of parameters
in the model.




                                                     55
                                TABLE 2
    Estimates and t-ratios of Zero-Beta Rate and Risk Premia under
             Correctly Specified and Misspecified Models

                                                    Panel A: OLS

                                                      CAPM              CCAPM
                                                    γ̂0     γ̂vw        γ̂0    γ̂cg
                                   Estimate       1.90     −0.66       1.00   0.15
                                   t-ratiof m     5.53     −1.72       4.85   0.70
                                   t-ratios       5.47     −1.70       4.75   0.69
                                   t-ratiojw      5.28     −1.67       4.80   0.70
                                   t-ratiopm      4.97     −1.60       3.86   0.58


                                              FF3                                C-LAB
                             γ̂0         γ̂vw     γ̂smb    γ̂hml       γ̂0     γ̂vw    γ̂lab    γ̂prem
             Estimate       2.01       −0.99        0.15   0.43        1.95   −1.08    0.11      0.54
             t-ratiof m     6.94       −2.96        1.22   3.86        5.79   −2.96    0.94      4.31
             t-ratios       6.69       −2.87        1.22   3.86        3.44   −1.89    0.56      2.58
             t-ratiojw      6.72       −2.85        1.22   3.87        3.46   −1.94    0.58      2.78
             t-ratiopm      5.91       −2.58        1.23   3.86        3.48   −1.97    0.52      3.21


                           C-CCAPM                                               ICAPM
                γ̂0        γ̂dy        γ̂cg     γ̂cg·dy         γ̂0    γ̂vw   γ̂term    γ̂def      γ̂div    γ̂rf
Estimate       1.33       −1.61       0.50      0.01        1.21      −0.16   0.26     −0.11     −0.01     −0.48
t-ratiof m     6.82       −5.30       2.94      2.47        3.91      −0.47   3.97     −2.37     −0.54     −3.77
t-ratios       3.47       −2.71       1.51      1.27        2.44      −0.32   2.50     −1.50     −0.35     −2.38
t-ratiojw      3.56       −2.82       1.47      1.26        2.06      −0.28   2.55     −1.29     −0.26     −2.19
t-ratiopm      3.13       −1.07       0.53      0.65        1.73      −0.25   1.81     −1.18     −0.20     −1.96




                                                           56
                              TABLE 2 (Continued)
       Estimates and t-ratios of Zero-Beta Rate and Risk Premia under
                Correctly Specified and Misspecified Models

                                                    Panel B: GLS

                                                      CAPM               CCAPM
                                                    γ̂0      γ̂vw        γ̂0     γ̂cg
                                  Estimate         1.90    −0.85        1.27    0.21
                                  t-ratiof m       8.98    −3.17        8.93    1.92
                                  t-ratios         8.80    −3.14        8.56    1.85
                                  t-ratiojw        8.63    −3.10        8.49    1.85
                                  t-ratiopm        7.51    −2.84        7.61    1.19


                                             FF3                                   C-LAB
                            γ̂0        γ̂vw        γ̂smb   γ̂hml       γ̂0      γ̂vw     γ̂lab    γ̂prem
             Estimate      1.88      −0.84         0.20    0.40        1.82    −0.78     −0.07    0.06
             t-ratiof m    7.40      −2.77         1.68    3.61        8.41    −2.84     −0.93    0.83
             t-ratios      7.17      −2.71         1.68    3.61        8.00    −2.75     −0.89    0.80
             t-ratiojw     7.22      −2.70         1.69    3.62        7.64    −2.67     −0.89    0.76
             t-ratiopm     6.11      −2.37         1.69    3.61        6.57    −2.32     −0.44    0.40


                           C-CCAPM                                                 ICAPM
                  γ̂0      γ̂dy       γ̂cg     γ̂cg·dy           γ̂0    γ̂vw    γ̂term    γ̂def    γ̂div    γ̂rf
   Estimate     1.18      −0.97      0.50      0.02           1.61     −0.52    0.21     −0.08     0.01    −0.22
   t-ratiof m   8.18      −5.02      4.03      3.98           5.94     −1.67    3.99     −2.10     0.53    −2.06
   t-ratios     5.29      −3.30      2.66      2.62           4.33     −1.31    2.94     −1.55     0.39    −1.52
   t-ratiojw    4.89      −3.85      2.61      2.52           3.90     −1.23    2.97     −1.47     0.34    −1.46
   t-ratiopm    4.69      −2.64      2.08      2.06           3.08     −1.01    2.01     −1.09     0.25    −1.10

  Note.–The table presents the estimation results of six beta pricing models. The models include the uncon-
ditional CAPM (CAPM), the consumption CAPM (CCAPM), the Fama and French (1993) three-factor
model (FF3), the conditional CAPM (C-LAB) of Jagannathan and Wang (1996), the conditional CCAPM
(C-CCAPM), and the intertemporal CAPM (ICAPM) of Petkova (2006). The models are estimated using
monthly returns on the 25 Fama-French size and book-to-market ranked portfolios. Most of the data are
from May 1953 to December 2006 (644 observations), but the data for the CCAPM and C-CCAPM start
in February 1959 (575 observations). We report parameter estimates γ̂ (multiplied by 100), the Fama
and MacBeth (1973) t-ratios under correctly specified models (t-ratiof m ), the Shanken (1992) and the
Jagannathan and Wang (1998) t-ratios under correctly specified models that account for the EIV problem
(t-ratios and t-ratiojw, respectively), and our model misspecification-robust t-ratios (t-ratiopm ).



                                                            57
                                TABLE 3
Estimates and t-ratios of Zero-Beta Rate and Prices of Covariance Risk
          under Correctly Specified and Misspecified Models

                                                Panel A: OLS

                                                  CAPM                    CCAPM
                                                λ̂0        λ̂vw          λ̂0       λ̂cg
                                 Estimate      1.90    −3.66             1.00     28.96
                                 t-ratiof m    5.53    −1.72             4.85     0.70
                                 t-ratiocs     5.28    −1.69             4.80     0.70
                                 t-ratiopm     4.97    −1.61             3.86     0.58


                                         FF3                                           C-LAB
                           λ̂0        λ̂vw    λ̂smb    λ̂hml            λ̂0        λ̂vw      λ̂lab    λ̂prem
             Estimate     2.01      −5.43      4.66    3.96         1.95         −7.70      31.48     318.91
             t-ratiof m   6.94      −2.49      3.09    2.12         5.79         −3.83       0.44      4.50
             t-ratiocs    6.72      −2.39      2.95    2.02         3.46         −2.41       0.26      2.84
             t-ratiopm    5.91      −2.13      2.90    1.92         3.48         −2.46       0.23      3.29


                           C-CCAPM                                                                 ICAPM
               λ̂0        λ̂dy         λ̂cg      λ̂cg·dy          λ̂0           λ̂vw      λ̂term       λ̂def     λ̂div     λ̂rf
Estimate      1.33    −156.29       −58.35      4471.67           1.21        −9.87       286.90     −278.89   −275.39   −91.95
t-ratiof m    6.82     −5.38        −0.71        1.65             3.91        −1.13        2.60       −3.05     −0.90    −2.22
t-ratiocs     3.56     −2.74        −0.33        0.77             2.06        −0.54        1.80       −1.56     −0.42    −1.22
t-ratiopm     3.13     −1.35        −0.11        0.35             1.73        −0.38        1.15       −1.41     −0.28    −1.17




                                                           58
                            TABLE 3 (Continued)
 Estimates and t-ratios of Zero-Beta Rate and Prices of Covariance Risk
           under Correctly Specified and Misspecified Models

                                                 Panel B: GLS

                                                   CAPM                          CCAPM
                                                 λ̂0         λ̂vw            λ̂0           λ̂cg
                                  Estimate      1.90       −4.73            1.27      40.53
                                  t-ratiof m    8.98       −3.17            8.93      1.92
                                  t-ratiocs     8.63       −3.15            8.49      1.83
                                  t-ratiopm     7.51       −2.81            7.61      1.18


                                          FF3                                                C-LAB
                            λ̂0       λ̂vw      λ̂smb      λ̂hml           λ̂0            λ̂vw        λ̂lab      λ̂prem
              Estimate     1.88     −4.66      4.95        4.04            1.82      −4.98          −55.12        43.60
              t-ratiof m   7.40     −2.36      3.41        2.24            8.41      −3.30          −1.12         1.04
              t-ratiocs    7.22     −2.28      3.26        2.20            7.64      −3.19          −1.07         0.96
              t-ratiopm    6.11     −1.97      3.21        2.08            6.57      −2.77          −0.54         0.52


                            C-CCAPM                                                                  ICAPM
                λ̂0        λ̂dy        λ̂cg      λ̂cg·dy             λ̂0           λ̂vw          λ̂term         λ̂def      λ̂div   λ̂rf
 Estimate      1.18    −96.74       −49.83      4369.36             1.61         −4.58       345.64           −155.28     −9.08    4.51
 t-ratiof m    8.18    −5.24        −0.72        2.03               5.94         −0.59        3.81             −2.16      −0.03    0.14
 t-ratiocs     4.89    −3.76        −0.49        1.34               3.90         −0.38        2.83             −1.45      −0.02    0.09
 t-ratiopm     4.69    −2.72        −0.36        1.02               3.08         −0.27        2.03             −1.10      −0.01    0.07

 Note.–The table presents the estimation results of six beta pricing models. The models include the unconditional
CAPM (CAPM), the consumption CAPM (CCAPM), the Fama and French (1993) three-factor model (FF3),
the conditional CAPM (C-LAB) of Jagannathan and Wang (1996), the conditional CCAPM (C-CCAPM), and
the intertemporal CAPM (ICAPM) of Petkova (2006). The models are estimated using monthly returns on the
25 Fama-French size and book-to-market ranked portfolios. Most of the data are from May 1953 to December
2006 (644 observations), but the data for the CCAPM and C-CCAPM start in February 1959 (575 observations).
We report parameter estimates λ̂ (with λ̂0 multiplied by 100), the Fama and MacBeth (1973) t-ratios under
correctly specified models (t-ratiof m ), the t-ratios under correctly specified models that account for the EIV
problem (t-ratiocs), and model misspecification-robust t-ratios (t-ratiopm ).




                                                            59
                                TABLE 4
                Tests of Equality of Cross-Sectional R2 s

                                       Panel A: OLS
                         CCAPM          FF3         C-LAB     C-CCAPM         ICAPM
           CAPM            0.135      −0.555        −0.478      −0.355        −0.580
                          (0.686)     (0.000)       (0.020)     (0.457)       (0.064)
          CCAPM                       −0.747        −0.585      −0.490        −0.803
                                      (0.029)       (0.129)     (0.321)       (0.023)
             FF3                                     0.078       0.256        −0.024
                                                    (0.608)     (0.558)       (0.792)
           C-LAB                                                 0.095        −0.102
                                                                (0.849)       (0.543)
         C-CCAPM                                                              −0.313
                                                                              (0.470)
                                       Panel B: GLS
                         CCAPM          FF3         C-LAB     C-CCAPM         ICAPM
           CAPM            0.067      −0.209        −0.031      −0.275        −0.261
                          (0.588)     (0.001)       (0.735)     (0.256)       (0.256)
          CCAPM                       −0.283        −0.092      −0.342        −0.296
                                      (0.058)       (0.502)     (0.025)       (0.151)
             FF3                                     0.178      −0.059        −0.053
                                                    (0.163)     (0.802)       (0.778)
           C-LAB                                                −0.250        −0.230
                                                                (0.318)       (0.268)
         C-CCAPM                                                               0.047
                                                                              (0.871)

  Note.–The table presents pairwise tests of equality of the OLS and GLS cross-sectional
R2 s of six beta pricing models. The models include the unconditional CAPM (CAPM), the
consumption CAPM (CCAPM), the Fama and French (1993) three-factor model (FF3), the
conditional CAPM (C-LAB) of Jagannathan and Wang (1996), the conditional CCAPM
(C-CCAPM), and the intertemporal CAPM (ICAPM) of Petkova (2006). The models are
estimated using monthly returns on the 25 Fama-French size and book-to-market ranked
portfolios. Most of the data are from May 1953 to December 2006 (644 observations), but the
data for the CCAPM and C-CCAPM start in February 1959 (575 observations). We report
the difference between the sample cross-sectional R2s of the models in row i and column
j, ρ̂2i − ρ̂2j , and the associated p-value (in parentheses) for the test of H0 : ρ2i = ρ2j . The
p-values are computed under the assumption that the models are potentially misspecified.




                                               60
