                                 NBER WORKING PAPER SERIES




                                 THE IMPACT OF U.S. NEWS &
                             WORLD REPORT COLLEGE RANKINGS
                              ON ADMISSIONS OUTCOMES AND
                                    PRICING POLICIES AT
                              SELECTIVE PRIVATE INSTITUTIONS

                                            James Monks
                                         Ronald G. Ehrenberg

                                          Working Paper 7227
                                  http://www.nber.org/papers/w7227


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                        July 1999




The Cornell Higher Education Research Institute is supported by the Andrew W. Mellon foundation and other
donors. All opinions expressed are those of the authors and not those of the National Bureau of Economic
Research, the Consortium on Financing Higher Education, Cornell University, or the Andrew W. Mellon
Foundation.

© 1999 by James Monks and Ronald G. Ehrenberg. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice, is given
to the source.
The Impact of U.S News & World Report College
Rankings On Admission Outcomes and Pricing
Decisions at Selective Private Institutions
James Monks and Ronald G. Ehrenberg
NBER Working Paper No. 7227
July 1999
JEL No. I2

                                                 ABSTRACT

        Despite the widespread popularity of the U.S. News & World Report College rankings there has
been no empirical analysis of the impact of these rankings on applications, admissions, and enrollment
decisions, as well as on institutions’ pricing policies. Our analyses indicate that a less favorable rank leads
an institution to accept a greater percentage of its applicants, a smaller percentage of its admitted applicants
matriculate, and the resulting entering class is of lower quality, as measured by its average SAT scores.
While tuition levels are not responsive to less favorable rankings, institutions offer less visible price discounts
in the form of slightly lower levels of expected self-help (loans and employment opportunities) and
significantly more generous levels of grant aid. These decreases in net tuition are an attempt to attract
additional students from their declining applicant pool.


James Monks                                                  Ronald G. Ehrenberg
Consortium on Financing Higher Education                     Cornell Higher Education Research Institute
238 Main Street (Suite 307)                                  256 Ives Hall
Cambridge, MA 02142                                          Ithaca, NY 14853-3901
Jmonks@mit.edu                                               and NBER
                                                             Rge2@cornell.edu
I. Introduction

       Each fall the U.S. News & World Report (henceforth USNWR) publishes an issue that

ranks the colleges and universities throughout the country. Many higher education

administrators abhor this form of detailed numerical ordering of the institutions. Stanford

University has gone so far as to have the data underlying their ranking audited by outside

consultants, and the Association of American Universities is investigating the possibility of

constructing its own ranking scheme in response to the popularity of the USNWR ranking

(imitation being the highest form of flattery). At the same time, many institutions use their

standing in the rankings as a selling point in their admissions brochures. Ehrenberg

(forthcoming, chapter 4) outlines actions taken by Cornell University to improve its relative

position in the rankings, that had no effect on the institution’s underlying academic quality. He

also illustrates how minor changes in the methodology used by USNWR can result in substantial

changes in the rank ordering of the top-ranked national universities.

       The widespread popularity of the rankings among students and families, as evidenced by

the sales of the USNWR issue that contains the rankings and of their expanded special college

ranking supplementary publication, as well as the increasing angst and attention that these

rankings cause higher education administrators, warrant an analysis of the impact of these

rankings on the higher education admissions processes. Machung (1998) chronicles the efforts

sometimes taken by institutions to ensure or improve their position in the rankings. She also

points out that a recent study by the Art and Science Group, a market research firm, found that

two-thirds of parents of high-achieving, college-bound seniors felt the USNWR rankings to be

“very helpful” in evaluating a college’s quality. Hansmann (1998) also provides anecdotal
evidence that Yale’s achieving the top position in the USNWR ranking of law schools resulted in

a precipitous increase in the yield at the Yale Law School, the following year.

     Despite these convincing examples and casual observations concerning the influence of the

USNWR rankings of colleges and programs, there has been no thorough empirical investigation

into the impact of these rankings on potential students’ or academic institutions’ behavior. Our

paper fills this void by examining the effects of changes in USNWR rankings on the admissions

outcomes and pricing policies of a set of institutions that are at the very top of the undergraduate

rankings. In particular, we investigate the impact of changes in highly ranked national

universities’ and liberal arts colleges’ USNWR rankings on the fraction of their applicants that

they admit (their admit rates), the fraction of their accepted applicants that enroll (their yield

rates) and the average SAT scores of their resulting freshman classes. We also examine the

impact of changes in these institutions’ rankings on the tuition levels they charge, the self-help

levels they include in their financial aid packages, their aid-adjusted tuition levels (the average

price actually paid by students on need-based financial aid), and their net tuition levels (the

average price actually paid by all students).



II. Data

       We focus on the set of national universities and liberal arts colleges that are ranked at the

top of the rankings because these institutions and their rankings receive a disproportionate share

of public attention. 1 The institutions in our sample include 16 of the top 25 national universities,


1
 Our set of institutions is drawn from the Consortium on Financing Higher Education and
includes: Amherst, Barnard, Brown, Bryn Mawr, Carleton, Columbia, Cornell, Dartmouth,
Duke, Georgetown, Harvard, Johns Hopkins, MIT, Mount Holyoke, Northwestern, Oberlin,
Pomona, Princeton, Smith, Stanford, Swarthmore, Trinity (CT), University of Chicago,
University of Pennsylvania, University of Rochester, Washington University, Wellesley,
Wesleyan, Williams, and Yale.


2
one university ranked between 26th and 50th and 13 of the top 25 national liberal arts colleges in

the USNWR 1998 rankings. We restrict our attention to these institutions because we were able

to obtain detailed information for them on the typical expected self-help and the financial aid-

adjusted tuition levels for incoming freshmen. The availability of freshmen aid-adjusted prices

permits us to more fully capture the impact of annual changes in the institutions’ rankings on

their pricing decisions than we could have done if we were forced to rely only on posted tuition

levels.

          The institutions in our sample are all members in the Consortium on Financing Higher

Education (COFHE), which was established in 1974, before the beginning of the USNWR

rankings in 1983. 2 Because all of the institutions in our sample are privately controlled, no

inferences about the impact of changes in rank on admissions outcomes and pricing policies in

public higher education institutions should be drawn from the results that follow.

          We limit our sample years to the admissions outcomes and pricing policies for the

entering classes of the 1988/89 to 1998/99 academic years, and to the prior year’s fall USNWR

rankings (the fall of 1987 to the fall of 1997). The first year of our sample is the first year that

USNWR reported rankings for at least the top 25 liberal arts colleges and the top 25 national

universities. Prior to 1987, USNWR reported only the top 10 or so ranked institutions in each

category. The fall 1997 ranking is the final ranking used because it is hypothesized to influence

the admissions’ outcomes and pricing behavior for the 1998/99 academic year, the last year for

which we had admissions and pricing information, at the time we wrote the paper. The resulting

sample consists of 30 institutions across 11 years, for a panel of 330 observations. For some




2
 Oberlin is the exception. Oberlin joined COFHE in 1988. All other institutions in our sample
joined COFHE before USNWR began ranking colleges and universities


3
institution-years, the level of self-help or net tuition was not reported and those observations

were dropped from the statistical analyses that used these variables.

       USNWR determines an institution’s rank among national universities and liberal arts

colleges by taking a weighted average of the institution’s scores on 7 broad categories of

academic input and outcome measures. In its 1997 rankings, the categories and their weights

were academic reputation (25 percent), retention rate (20 percent), faculty resources (20 percent),

student selectivity (15 percent), financial resources (10 percent), alumni giving (5 percent), and

graduation rate performance (5 percent). These 7 categories were further divided and 16

different variables were used to capture their dimensions. These 16 variables were: academic

reputation, as measured by a survey of college presidents; the fraction of freshman applicants

that were admitted (the admit rate): the fraction of accepted applicants that enrolled (the yield

rate); the percentage of incoming freshman in the top 10 percent of their high school class; the

average SAT or ACT scores or entering freshmen; average faculty compensation; the percentage

of faculty with a Ph.D. or the highest degree possible in the field; the percentage of faculty who

were full-time; the student/faculty ratio; the percentage of classes with 1 to 19 students; the

percentage of classes with 50 or more students; the 6 year graduation rate; the freshman

retention rate; average education expenditures per student; the alumni giving rate; and the

institution’s graduation rate performance relative to its predicted graduation rate measure.

       Periodically, USNWR alters the methodology it uses to determine the rankings. So

changes in an institution’s rank do not necessarily indicate true changes in the underlying

“quality” of the institution. In fact, some institutions have changed their positions in the ordering

by as much as 18 places in a single year. For example, Bryn Mawr dropped from 5th position in

1989, to 23rd position in 1990. The hypotheses we are testing here is thus whether a change in an




4
institution’s USNWR ranking, which is not necessarily equal to a change in the “true” academic

quality of the institution, influences its admissions outcomes and its pricing behavior.

III. Empirical Results

        Our methodological approach is to statistically relate the admissions outcomes and

pricing variables described above for an institution in an academic year to its lagged (previous

year’s) USNWR ranking. Some institutions in our sample did not receive a specific numerical

rank in some years because USNWR only reported the numerical ranks of the top 25 institutions

in each category from 1987 to 1994. After 1994 they listed the top 50 national universities and

top 40 national liberal arts colleges. For those institution-years for which an institution dropped

out of the top 25 and its numerical rank was not reported, we assigned the institution a rank of

25. We also included in the model a dichotomous variable that was set equal to one for these

institution-years and zero otherwise. It is straightforward to show that the coefficient on this

variable indicates whether an institution that fell below a rank of 25 in those years experienced

admissions or pricing outcomes that were significantly different from those of the 25th ranked

institution.

       We include average endowment per student at an institution among the explanatory

variables in order to control for differences across institutions and over time in the ability to fund

operations from revenue sources other than tuition. Institutional dichotomous variables are also

included to capture time-invariant institution specific reputation and policy effects. Finally, year

dichotomous variables are included to control for changes in the potential applicant pool and

pricing environment that are consistent across this set of institutions.

        Table 1 presents the results of our analyses of the impact of USNWR rank on admissions

outcomes. In the first column, the admit rate (the number of students admitted/the number of




5
applicants) is specified to be linearly related to the institution’s lagged USNWR rank, the

dichotomous variable for the institution’s lagged rank being greater than 25 and not specifically

reported, average endowment per student, and institution and year effects. An increase in rank of

one (an increase in rank reflects a less favorable position in the ordering; for example, moving

from being ranked 2nd to 3rd) is associated with a positive and statistically significant increase in

the institution’s admit rate of 0.399. In other words, a change in rank, from say 4th to 5th ,

coincides with an increase in an institution’s admit rate of almost one half of a percentage point.

An institution whose rank is increasing must admit a greater percentage of its shrinking applicant

pool in order to fill its incoming class, thus becoming less selective in its admissions.

Conversely, an institution whose rank improves (becomes lower) can accept a smaller percentage

of its applicants and increase its selectivity.

        As column 2 indicates, an increase in rank not only decreases the selectivity of an

institution, but lowers its yield (number of matriculants/number of admitted students), as well. A

less favorable rank results in a smaller percentage of an institution’s admitted applicants

accepting positions in the entering class. This provides an additional reason why institutions that

are losing ground in the rankings must admit a larger percentage of their applicants, while

institutions that improving in the rankings can accept a smaller percentage of their applicants.

While the impact on yield is statistically significant, the magnitude of the effect of a change in

rank on yield is rather small. It takes an improvement in rank of 6 places to increase an

institution’s yield by 1 percentage point. 3

        An increase in average endowment per student also increases an institution’s yield. In

particular, a $10,000 increase in endowment per student increases an institution’s yield by 0.56


3
   We also estimated models in which the admit rate and yield rate were specified as log-odds
ratios. The results were very similar and are not presented here.


6
percentage points. As will be discussed in the following section, an increase in endowment leads

to pricing policies that lower the financial aid adjusted cost of attendance, thus increasing yield.

       The net effect of an increase in rank on admit rates and yields is a decline in the average

SAT score of the institution’s incoming freshmen class. 4 The largest reductions in SAT scores

are felt at the top of the rankings, with the impact declining further down the ordering of

institutions. Thus the increased selectivity and yield that accompany an improvement in rank

leads to a modest increase in the quality of the institution’s incoming freshmen class, as

measured by its average SAT scores. 5

       Table 2 presents our estimates of the impact of changes in an institution’s USNWR rank

on its pricing policies and on the tuition revenue it actually nets per student. All outcome

variables in this table are specified in logarithmic form, so that the estimated coefficients for

each explanatory variable represent the approximate percentage changes in the outcome

associated with a one-unit change in the explanatory variable.

       The first column presents estimates of the impact of rank and endowment per student on

tuition. An increase in rank has no statistically significant impact on tuition. Similarly, an

increase in endowment has no significant impact on tuition. “Sticker prices” appear not to be

influenced by changes in the overall rank and wealth of an institution, conditional on institution

and year-specific effects. This may be because gross tuition levels act, in part, as a signal of

academic quality (Breneman (1994), p. 32), so that an institution does not want to reveal its

declining position by lowering its published price.



4
  The pre-1996/97 average composite SAT scores have been recentered to correct for the
“recentering” of SAT scores that took place in that year.
5
   We experimented with including the square of rank in each of the regressions reported in
tables 1 and 2. However, it proved to be statistically significant and improved the fit of the model
only for the SAT score equation.


7
        As column 2 indicates, however, an increase in rank is associated with a decrease in the

typical expected freshmen self-help contribution from students. Institutions that experience a

declining position (increasing rank) in the USNWR ordering appear to lower their self-help levels

in an attempt to attract additional students, although this result is only significantly different

from zero at the 10 percent level.

        Consistent with the impact of rank on self-help, an increase in rank significantly lowers

average financial-aid-adjusted tuition. An increase in rank (less favorable ranking) of 10 places

leads to a reduction in aid adjusted tuition of approximately 4 percent. Because an increase in

rank was shown in column 1 not to significantly reduce tuition levels, this reduction in aid-

adjusted tuition implies that a less favorable ranking prompts institutions to provide more

generous financial aid. 6 Likewise, an improvement in rank raises aid-adjusted tuition, as higher

ranked institutions do not have to offer deep discounts to attract matriculants.

        An increase in endowment per student also is associated with lower aid-adjusted tuition.

This implies that institutions pass on at least some of their increases in wealth to their students in

the form of more generous financial aid packages. A $100,000 increase in endowment per

student reduces aid-adjusted tuition by approximately 4 percent.

        Finally, an increase in rank leads to a decrease in net tuition (average aid-adjusted tuition

across all students, both aided and non-aided). The decrease in net tuition is smaller than the

decrease in aid-adjusted tuition. This result is consistent with the statistically insignificant effect

of rank on tuition and the significant decrease in aid-adjusted tuition found in columns 1 and 3,

respectively.

6
 Aid-adjusted tuition is defined as tuition minus average grant aid per student, for those students
on aid. It does not include self-help and merit aid. Although merit aid is becoming increasingly
popular, it still constituted only 2.5 percent of all grant aid awarded in 1998/99 at the COFHE



8
Conclusion

       Our analyses suggest that an increase in a selective private institution’s USNWR rank (a

less favorable ranking) leads the institution to accept a greater percentage of its applicants (an

increase its admit rate), that a smaller percentage of its admitted pool of applicants matriculates

(a decrease in its yield), and that its resulting entering class is of lower quality, as measured by

average SAT scores. In addition, we find that institutions’ tuition levels are not responsive to

less favorable rankings. This may be because lower tuition relative to one’s competitors may be

perceived of as an additional signal of lower quality. As a result, institutions that have declined

in the ratings offer less visible price discounts in the form of lower levels of expected self-help

and more generous levels of grant aid, in an attempt to attract additional students from their

declining applicant pool.

       Cornell University, the home institution of one of us, provides a case study and test of the

predictive power of our results. Cornell jumped in rank from 14th in the fall of 1997 (the last

year used in our study) to 6th in the fall of 1998. Our estimates imply that this 8 place

improvement in rank should have led to approximately a 3 percentage point reduction in the

institution’s admit rate, a one percentage point increase in its yield, and approximately an 8 point

increase in its entering freshmen’s average SAT scores. While data on these outcomes for the

freshmen class entering in the fall of 1999 have not yet been publicly released by Cornell, a

senior administrator confirmed for us that the reduction in the university’s admit rate and the

increases in its yield and average freshmen SAT scores were at least as large as our predictions.

Moreover, completed freshman applications to the university rose by over 10 percentage points.


institutions, and was granted to less than 2 percent of the total COFHE enrollment. Its exclusion
from the aid-adjusted tuition levels should not significantly influence the results.


9
        A change in rank does have a significant influence on admissions outcomes and

institutional pricing decisions for liberal arts colleges and national universities that are at the very

top of the USNWR ranking lists. These in turn, through the methodology that USNWR uses, will

have an impact on the institutions’ future rank. 7 The growing popularity and influence of these

rankings may also lead the institutions to try to influence them. Institutions may attempt to

improve their position in the rankings by lobbying USNWR to change the methodology in a way

that might favor an institution or group of institutions, by “correcting” their data in a way that

leads to an improvement in their ranking, or by devoting resources to activities related to

improving their rank that do not directly enhance educational quality. An example of the latter

might be to increase the size of their development offices in order to increase their alumni giving

rates, even if the marginal return to the university in terms of dollars raised from doing so

doesn’t exceed the cost of the additional staff.

        The factor that receives the largest weight in the USNWR rankings is the survey of higher

education administrators. Hence an improvement (or decline) in an institution’s rank may lead to

future movements in its rank in the same direction because administrators are increasingly aware

of how other institutions fare in the rankings. The heightened awareness, and perhaps even

animosity, among higher education administrators concerning their institutions’ relative positions

in the USNWR rankings appears to be warranted, as changes in rank have a significant influence

on the applications and enrollment decisions of students and the pricing behavior of the

institutions.


7
 This mechanical relationship may lead to an endogeneity problem in our analyses, if current
rank is correlated with future rank, which in turn is determined in part by current admission
outcomes. Our inability to specify adequate exogenous variables for an institution’s rank prevent
us from conducting formal statistical tests of whether rank should be treated as endogenous in
our models. However, our use of lagged rank and of institutions specific effects is intended to
minimize this problem.


10
                                            References



Breneman, David W. (1994). Liberal Arts Colleges: Thriving, Surviving, or Endangered?
      Brookings Institution, Washington, D.C.

Ehrenberg, Ronald G. (forthcoming). Adam Smith Goes to College…..and learns why they can’t
      hold down their costs”.. Harvard University Press, Cambridge, MA

Hansmann, Henry (1998). “Higher Education as an Associative Good.” Yale Law School
     mimeo.

Machung, Anne. (1998). “Playing the Rankings Game.” Change. July/August 1998, pp. 12-16.

U.S. News and World Report, various issues 1983 to 1998.

</ref_section>




11
                     Table 1 US News and World Report Rankings and Admissions Outcomes
                                      Academic Years 1988/89-1998/99

                                                 Dependent Variable

                                              Admit
                                               Rate                       Yield       Average SAT

Constant                                    19.543***                   44.083***     1402.628***
                                            (4.121)                     (1.988)        (11.848)

Lagged US News Rank                           0.399***                   -0.171***       -2.777***
                                             (0.098)                     (0.047)         (0.773)

Lagged US News Rank Squared                   -------                     -------         0.086***
                                                                                         (0.025)

Dummy of Lagged Rank > 25                     0.473                       1.073          -3.009
                                             (1.527)                     (0.737)         (4.357)

Average Endowment/student                    -0.013                       0.056***        0.045
(thousands 98/99 $)                          (0.015)                     (0.007)         (0.041)

Institutional Dummy Variables                  Yes                         Yes            Yes

Year Dummy Variables                           Yes                         Yes            Yes

Adjusted R-square                              0.93                        0.97           0.96

Number of Institutions                           30                         30             30
Number of Institution-Years                     330                        330            330

Notes:
(* ,**, ***) statistically significantly different from zero at 10% (5%, 1%) level.
Average endowment is 3 year moving average of lagged endowment levels.




12
                              Table 2 US News and World Report Ranking and Pricing
                                        Academic Years 1988/89-1998/99

                                          Dependent Variable (in log form)

                                                                  Self-               Aid Adjusted
                                          Tuition                 Help                   Tuition     Net Tuition

Constant                                  10.102***              8.577***                9.461***      9.915***
                                          (0.012)               (0.080)                 (0.069)       (0.036)

Lagged US News Rank:                       -0.0001              -0.004*                 -0.004**      -0.003***
                                           (0.0003)             (0.002)                 (0.002)       (0.001)

Dummy of Lagged Rank > 25                   0.0020              -0.031                  -0.013        -0.022*
                                           (0.0044)             (0.028)                 (0.026)       (0.013)

Average Endowment/student                  -0.00001              0.0000                 -0.0004*      -0.0001
(thousands 98/99 $)                        (0.00004)            (0.0003)                (0.0002)      (0.0001)

Institutional Dummy Variables               Yes                   Yes                     Yes           Yes

Year Dummy Variables                        Yes                   Yes                     Yes           Yes

Adjusted R-square                           0.98                  0.78                    0.61          0.85

Number of Institutions                      30                     30                     30            30
Number of Institution-Years                 330                    325                    330           326

Notes:
 (*,**, ***) statistically significantly different from zero at 10% (5%, 1%) level.
  Average endowment is 3 year moving average of lagged endowment levels.




13
