                              NBER WORKING PAPER SERIES




                    NEIGHBORHOOD-BASED INFORMATION COSTS

                                     Benjamin M. Hébert
                                     Michael Woodford

                                      Working Paper 26743
                              http://www.nber.org/papers/w26743


                    NATIONAL BUREAU OF ECONOMIC RESEARCH
                             1050 Massachusetts Avenue
                               Cambridge, MA 02138
                                   February 2020




The authors would like to thank Mark Dean, Sebastian Di Tella, Mira Frick, Xavier Gabaix,
Matthew Gentzkow, Emir Kamenica, Divya Kirti, Jacob Leshno, Stephen Morris, Pietro
Ortoleva,José Scheinkman, Ilya Segal, Ran Shorrer, Joel Sobel, Harald Uhlig, Miguel Villas-
Boas, Ming Yang, and seminar and conference participants at the Cowles Theory conference, the
16th SAET Conference, Barcelona GSE Summer Conference on Stochastic Choice, Stanford
GSB research lunch, the 2018 ASSA meetings, UC San Diego, and UC Berkeley for helpful
discussions on this topic, and the NSF for research support. We would particularly like to thank
Doron Ravid and Philipp Strack for discussing an earlier version of the paper. Portions of this
paper circulated previously as the working papers "Rational Inattention with Sequential
Information Sampling" and "Information Costs and Sequential Information Sampling," and
appeared in Benjamin Hébert's Ph.D. dissertation at Harvard University. All remaining errors are
our own. The views expressed herein are those of the authors and do not necessarily reflect the
views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2020 by Benjamin M. Hébert and Michael Woodford. All rights reserved. Short sections of
text, not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.
Neighborhood-Based Information Costs
Benjamin M. Hébert and Michael Woodford
NBER Working Paper No. 26743
February 2020
JEL No. D83,G41

                                         ABSTRACT

We propose a new measure of the cost of information structures in rational inattention problems,
the "neighborhood-based" cost functions, given that many applications involve states with a
topological structure. These cost functions summarize the results of a sequential information
sampling problem, and also capture a notion of perceptual distance. This second property allows
neighborhood-based cost functions, unlike mutual information, to make accurate predictions
about behavior in perceptual experiments. We compare the implications of our neighborhood-
based cost functions with those of a mutual-information cost function in a series of applications:
security design, global games, modeling perceptual judgments, and linear-quadratic-Gaussian
problems.


Benjamin M. Hébert
Graduate School of Business
Stanford University
655 Knight Way
Stanford, CA 94305
and NBER
bhebert@stanford.edu

Michael Woodford
Department of Economics
Columbia University
420 W. 118th Street
New York, NY 10027
and NBER
mw2230@columbia.edu




A data appendix is available at http://www.nber.org/data-appendix/w26743
1      Introduction
In models of rational inattention (proposed by Christopher Sims and surveyed in
Sims (2010)), a decision maker (DM) chooses her action based on a signal that
provides only an imperfect indication of the true state. The information structure
that generates this signal is optimal, in the sense of allowing the best possible state-
contingent action choice, net of a cost of information. In Sims' theory, the cost
of any information structure is proportional to the mutual information between the
true state of the world and the signals generated by that information structure.
    It is not obvious, though, that the theorems that justify the use of mutual in-
formation in communications engineering (Cover and Thomas (2012)) provide a
warrant for using it as a cost function in a theory of attention allocation, either
in the case of economic decisions or that of perceptual judgments.1 Moreover,
the mutual-information cost function has implications that are unappealing on their
face, and that seem inconsistent with evidence on the nature of sensory processing,
as discussed, for example, in Woodford (2012), Caplin and Dean (2013), Dewan
and Neligh (2017), and Caplin et al. (2018b).
    We propose an alternative family of information costs, which we call neighborhood-
based cost functions. These information costs have two particular properties (in ad-
dition to the standard ones described in, e.g., De Oliveira et al. (2017)) that we view
as desirable. First, they can be viewed as summarizing the results of a process of
sequential evidence accumulation. Second, these information costs can capture the
idea that certain pairs of states are easy to distinguish, whereas others are difficult
to distinguish. Our interest in both of these properties is motivated by empirical ev-
idence about the nature of sensory processing, discussed further below. The second
property, in particular, allows the neighborhood-based cost functions avoid some
of the problematic implications of the mutual-information cost function. The two
properties are connected by an object we call the "information-cost matrix func-
    1 Asexplained in Cover and Thomas (2012), these theorems rely upon the possibility of "block
coding" of a large number of independent instances of a given type of message, that can be jointly
transmitted before any of the messages have to be decoded by the recipient. In our situation, an
action must be taken in an individual decision problem, without waiting to learn about a large number
of problems of the same form.



                                                 1
tion," which encodes the difficulty of distinguishing between pairs of states and
summarizes the cost of a small amount of information.
    The neighborhood-based cost functions differ from mutual information because
mutual information imposes a type of symmetry across different states of nature,
so that it is equally difficult to distinguish between any two states that are equally
probable ex ante. This implies that under an optimal information structure, actions
differ across states only to the extent that the associated payoffs differ across those
states, and action probabilities jump discontinuously when payoffs jump. An ex-
tensive experimental literature in psychophysics finds that subjects' probabilities of
making perceptual judgments (the action) vary continuously with changes in the
stimulus magnitude (the state), even when subjects are rewarded based on whether
the magnitude is greater or smaller than some threshold (generating a discrete jump
in payoffs). Such behavior can be optimal only if it is costly to receive very differ-
ent signals in similar states, but less costly to distinguish states that are dissimilar.
That is, the information cost must capture some notion of "perceptual distance."
    Motivated by these issues, we consider the properties that a plausible cost func-
tion should satisfy. As discussed in Fehr and Rangel (2011) and Woodford (2014), a
large literature in psychology and neuroscience has argued that data on both the fre-
quency of perceptual errors and the frequency distribution of response times can be
explained by models of sequential sampling. More recently, some authors have pro-
posed that data on stochastic choice and response time in economic contexts can be
similarly modeled.2 Consequently, one property we desire in a cost function is that
it should summarize the results of a sequential information sampling process. In
Hébert and Woodford (2018), we demonstrate that static rational inattention prob-
lems with any uniformly posterior-separable (UPS) cost functions can be derived
from a sequential information sampling model.3 Motivated by this result, and the
experimental evidence of Dean and Neligh (2018) that is consistent with UPS cost
functions, we restrict attention to UPS cost functions.
   2 Additional  recent examples include Krajbich et al. (2014) and Clithero (2018). Shadlen and
Shohamy (2016) provide a neural-process interpretation of sequential-sampling models of choice.
    3 For more on this class of cost functions, see Caplin et al. (2018b). Morris and Strack (2017)

provide a related foundation for this class, in the special case in which there are only two possible
states and signals are exogenous.



                                                 2
    The key "parameter" of the dynamic model of Hébert and Woodford (2018) is
a matrix-valued function that describes the local cost of information acquisition.
This matrix-valued function is closely related to the Hessian of the information
cost in the corresponding static rational inattention model. This matrix encodes,
on its diagonal, how difficult each state is to learn about, and on its off-diagonal,
how difficult it is to discriminate between states. Mutual information generates
problematic predictions because its corresponding information-cost matrix function
has a kind of symmetry that implies that equally likely states are equally difficult
to discriminate. More generally, the comparative statics of the joint distribution of
states and actions with respect to changes in payoffs are governed by the Hessian
of the cost function. Intuitively, if it very costly to discriminate between some pair
of states, the DM will not do so even if her payoff jumps across those states. As a
result, there are UPS cost functions that are both consistent with sequential evidence
accumulation and able to capture the idea of perceptual distance.
    We introduce a specific family of such cost functions, the neighborhood-based
cost functions. With these cost functions, information structures are more costly the
greater the extent to which they allow intrinsically similar states of the world (states
that share a "neighborhood") to be discriminated. The dependence on a concept
of intrinsic similarity between states (the "neighborhood structure") distinguishes
these cost functions from mutual information. Neighborhood structures are closely
related to the idea that the state space is equipped with a topology; that is, states of
nature are not unordered sets.
    We derive the neighborhood-based cost function from a set of three assumptions
that connect the topology of the state space to the cost function, attempting to cap-
ture the idea that it is difficult to discriminate between nearby states. We show that,
given a set of neighborhoods that cover the state space, these three assumptions plus
uniform posterior separability uniquely determine a neighborhood-based cost func-
tion (up to a set of constants). We then relax one of our assumptions, introducing
a generalized version of the neighborhood-based cost functions that builds on work
by Dean and Neligh (2018). Dean and Neligh (2018) study these neighborhood-
based cost functions in an experimental setting, and find that these costs fit observed
behavior better than several other alternatives, including mutual information. We


                                           3
also show that these cost functions can explain the continuous variation of response
frequencies in the perceptual experiments discussed previously.
    We also specialize the neighborhood-based cost functions to a particularly use-
ful case, in which the states can be ordered on a line. Throughout the paper, we
use as a running example the case of a potential buyer of a security whose payoff
depends on the value of some assets (an example based on Yang (2017)). In this
case, it is natural to suppose that the states of the world are the asset values, and that
it may be difficult for the DM to discriminate between nearby asset values even as
the DM is more easily able to acquire information about whether the asset values
will be very high or very low. We extend our analysis of this case to a continuum
of states (in the rest of the paper, we use a discrete state space) and show that the
limit of the neighborhood-based cost function for this neighborhood structure is the
average Fisher information. This is the average value over the state space of a lo-
cal measure of the discriminability of nearby states. Like mutual information, this
measure is uniquely defined up to a scale parameter, and it can be used instead of
mutual information in almost any context in which the states can be ordered on a
line or a circle. We further extend this result to multi-dimensional state spaces, such
as when states correspond to a vector of real numbers.
    We next discuss four applications that illustrate how these cost functions are
both different from and similar to mutual information in various respects. We study
perceptual experiments, global games (building on Morris and Yang (2016)), se-
curity design (building on Yang (2017)), and a linear-quadratic-Gaussian setting of
the kind treated in Sims (2010). In the first three of these, the neighborhood-based
cost functions generate different predictions than mutual information.
    In the popular linear-quadratic-Gaussian case, we find that the average Fisher
information cost function shares a convenient prediction with mutual information:
optimal signals will have a Gaussian structure. However, even in this case, inter-
esting differences exist between the implications of the two cost functions. With
a single-dimensional state space, the Fisher information leads to a cost that is lin-
ear in the precision of a Gaussian signal; such costs have previously been used in
the literature (e.g. Van Nieuwerburgh and Veldkamp (2010); Myatt and Wallace
(2011)) and our results provide a justification for this functional form. In contrast,


                                            4
mutual information generates a cost proportional to the log of the precision, which
generates different predictions in the applications discussed by those authors.
    With a multi-dimensional state space, additional differences emerge. In a setting
where only one dimension of the state space is payoff-relevant, we show that with
mutual information, the DM receives a signal only about that dimension, whereas
with Fisher information, the DM receives a signal that maximally covaries with the
payoff-relevant dimension. Hébert and La'O (2019) demonstrate that this distinc-
tion leads to different predictions about efficiency and non-fundamental volatility
in games with rationally inattentive agents.
    Several other papers in the literature propose alternatives to the mutual infor-
mation cost function. Caplin et al. (2018b) analyze the class of UPS cost functions,
and direct particular attention to a class of UPS cost functions based on Tsallis en-
tropy. These cost functions lack a notion of distance between states, but deviate
from mutual information in other respects. Pomatto et al. (2018) are motivated by
concerns similar to ours, and derive a different family of cost functions from axioms
related to the cost of repeated experiments. These cost functions are not UPS, but
are similar to our neighborhood-based cost functions in that they can also capture a
notion of distance between states. The axioms of Pomatto et al. (2018) relate to the
cost of performing multiple, independent experiments and to "diluted" versions of
an experiment, whereas our axioms describe the relationship between the topology
of the state space and information costs.
    In section 2, we begin by defining a general class of static rational inattention
problems, that can be understood as reduced-form versions of the kind of dynamic
evidence accumulation problem treated in Hébert and Woodford (2018). In section
3, we then state the additional assumptions that define the class of neighborhood-
based cost functions. We apply the neighborhood-based cost functions to a series
of applications in section 4. In section 5 we conclude.


2    Static Rational Inattention Problems
We begin by describing static rational inattention problems. Let x  X be the under-
lying state of the nature, and a  A be the action taken by the decision maker (DM).

                                         5
A and X are finite sets, and the number of states is weakly larger than the number of
actions, |X |  |A|. The DM's utility from taking action a in state x at time t is ua,x .
    The DM does not know the state x  X , but can learn about which states are more
or less likely. The DM begin with prior beliefs q0  P (X ), where P (·) denote the
probability simplex on a set. The DM then chooses a "signal structure," consisting
of a signal alphabet S (a finite set) and a conditional probability, for each state x, of
each signal, p = { px  P (S)}xX . The signal structure p generates, under the prior
beliefs q0 , an unconditional probability of each signal, s ( p, q0 ). After receiving a
signal s  S, the DM will hold posterior beliefs qs ( p, q0 ), defined by Bayes' rule.
    Based on her posterior beliefs, the DM chooses an action a  A. Define u            ^:
P (X )  R as the utility when taking an optimal action given posteriors beliefs q,

                                   ^(q) = max  ua,x qx ,
                                   u
                                             aA xX


where qx is the probability under q of state x  X . In what follows, we will treat the
beliefs q  P (X ) as vectors in R|X | .
    Signal structures are costly in utility terms. Let C( p, q0 ; S) : P (S)|X | × P (X ) 
R be the cost of choosing a signal structure p and alphabet S, given initial prior q0 .
The standard static rational inattention problem, given the signal alphabet S,4 is

                      max                  ^(qs ( p, q0 )) -  C( p, q0 ; S),
                                  s( p, q0)u                                                  (1)
                  { px P (S)}xX sS


where  > 0 parameterizes the cost of information. Note that the problem can be
rewritten as a choice of the signal probabilities s and posteriors qs , instead of the
signal structure p; for any s and qs such that sS s qs = q0 , there is a unique
signal structure p such that s = s ( p, q0 ) and qs = qs ( p, q0 ).

Example. Suppose the DM is considering buying a security whose payoff is a func-
tion of the value of some assets. In this case, X is a set of possible values for
the assets, and the actions are to either accept (L, "like") or reject (R) the offer,
A = {L, R}. The utility of rejecting the offer is normalized to zero (uR,x = 0), and
   4 The  full problem includes a choice over the signal alphabet S. A standard result, which will
hold for all of the cost functions we study, is that |S| = |A| is sufficient.


                                                6
the utility of accepting the offer is uL,x = sx - K , where sx is the security payoff and
K is the price. The stopping payoff u     ^(·) involves deciding, under the current be-
liefs, whether to accept or reject: u ^(q ) = max{qT   · s - K , 0}, where s is the vector
of security payoffs.

    In the classic formulation of Sims, a problem of the form of (1) is considered, in
which the cost function C( p, q; S) is given by the mutual information between the
signal and the state. Mutual information can be defined using Shannon's entropy,

                            H Shannon (q)  -  qx ln(qx ).                               (2)
                                                 xX

Shannon's entropy can be used to define a measure of the degree to which each
posterior qs differs from the prior q0 , the Kullback-Leibler (KL) divergence,

      DKL (qs ||q0 )  H Shannon (q0 ) - H Shannon (qs ) + (qs - q0 )T Hq
                                                                       Shannon
                                                                               (q0 ),   (3)

where HqShannon denotes the gradient of Shannon's entropy. Mutual information is

the expected value of the KL divergence over possible signals,

                  CMI ( p, q0 ; S)      s( p, q0)DKL (qs( p, q0)||q0).                  (4)
                                       sS

Mutual information provides a measure of the degree to which the signal changes
what the DM believes about the state, on average. Mutual information is not, how-
ever, the only possible measure of the informativeness of an information structure,
or the only plausible cost function for a static rational inattention problem.
    A more general class of cost functions, which includes mutual information, are
the UPS cost functions. These cost functions can all be written as

                  CUPS ( p, q0 ; S)      s( p, q0)DH (qs( p, q0)||q0),
                                       sS

where DH is a Bregman divergence, itself defined by a convex function H ,

                    DH (qs ||q) = H (qs ) - H (q) - (qs - q)T Hq (q).                   (5)


                                             7
The Kullback-Leibler divergence, for example, is a Bregman divergence (see (3)),
with a entropy function equal to the negative of Shannon's entropy.
    Any differentiable convex function H defines a Bregman divergence. For no-
                                      |X |
tational purposes, we define H on R+ instead of P (X ). That is, we work with
non-negative vectors that may not sum to one. Given a function defined on P (X ),
                  |X |
we extend it to R+ by assuming that the function is homogenous of degree one.
    Assuming the H function is twice-differentiable, we can define a transformed
version of its Hessian matrix Hqq ,

                            k(q) = Diag(q)Hqq (q)Diag(q),                                (6)

where Diag(q) is an |X | × |X | diagonal matrix with qx on its diagonal. By the
convexity and homogeneity of degree one of H , k(q) is positive-definite and any
vector z that is constant in the support of q satisfies k(q) · z = 0.
     In Hébert and Woodford (2018), we call this matrix the "information cost matrix
function." We show that any static rational inattention problem (1) with a UPS
cost function be justified from a continuous time problem in which the matrix-
valued function k(q) describes the cost of acquiring a small amount of information
given current beliefs q. In particular, the diagonal elements of k(q) determine the
difficulty of learning about a particular state, whereas the off-diagonal elements
determine the ease or difficult of distinguishing between particular pairs of states.
     One possible k(q) is the "inverse Fisher information matrix,"
                                                                                         
                                q1 (1 - q1 )   -q1 q2                ...  -q1 q|X |
                                                                                         
                                 -q1 q2      q2 (1 - q2 )            ...  -q2 q|X | 
k(q) = g+ (q) = Diag(q) - qqT =                                                          .
                                                                                         
                                      .
                                      .            .
                                                   .                 ..         .
                                                                                .
                                
                                      .            .                    .       .        
                                                                                         
                                 -q1 q|X |    -q2 q|X |          . . . q|X | (1 - q|X | )
                                                                                          (7)
This k(q) matrix corresponds to the H function that is the negative of Shannon's
entropy. In this case, the off-diagonal element kxx (q) is equal to -q(x)q(x ) for any
pair of states x, x ; thus it depends only on the prior probabilities of the two states,
and is otherwise the same regardless of the states selected. Consequently, all pairs


                                             8
of distinct states with identical probabilities are equally easy or difficult to tell apart.
While this kind of symmetry might seem appealing on a priori grounds for some
applications, we view it as implausible for many cases of economic relevance.

Example. Continuing the example of a buyer considering a security, suppose the
buyer's current beliefs q are uniformly distributed over the various asset values
x  X . If k(q) is the inverse Fisher information matrix, the buyer finds it equally
costly to discriminate between any pair of asset values x, x , regardless of how close
or far apart those asset values are.

    In many applications, we have a notion of some pairs of states x, x being closer
together than others. In the case of payoffs, quantities, or other economic variables
that can be summarized by a single number, we usually think that it is harder to
sharply discriminate between values that are close together than values that are far
apart. Perceptual experiments, in which subjects classify stimuli that differ from
one another in intensity or magnitude along a single dimension, are another exam-
ple. A k(q) that captures a notion of distance between states is
                                                                                                                      
            q1 q2
           q1 +q2      - qq 1 q2
                          1 +q2
                                               0                            ...                            0
                                                                            ..                             .
                                                                                                                      
        q1 q2
       - q +q        q1 q2
                             +      q2 q3
                                            - qq 2 q3                          .                           .
                                                                                                           .
                                                                                                                      
                    q1 +q2         q2 +q3      2 +q3
                                                                                                                      
        1 2                                                                                                           
                                               ..                           ..                                        
k(q) =  0              - qq 2 q3
                          2 +q3
                                                    .                          .                            0         
                                                                                                                      .
        .                ..                    ..                                                                     
        .                                                    q|X |-1 q|X |-2        q|X | q|X |-1      q|X |-1 q|X | 
        .                    .                      .       q|X |-2 +q|X |-1 + q|X |-1 +q|X |       - q +q            
                                                                                                       |X |    |X |-1 
                                                                          q | q|X |-1                q        q
       
          0                  ...               0                     - q |X+                           |X |-1 |X |
                                                                                                     q|X | +q|X |-1
                                                                           |X | q|X |-1
                                                                                    (8)
Here, the only non-zero off-diagonal elements kxx (q) are negative elements when x
directly follows x in the ordering of states (or vice versa). This form of matrix k(q)
implies that an information structure is costly only to the extent that there are pairs
of "neighboring" states x, x for which the distributions of signals conditional on
those states are different. This example information cost matrix function is closely
related to the neighborhood-based cost functions we introduce in Section 3.

Example. Continuing the example of a buyer considering a security, if k(q) is the
function described in equation (8) above, the buyer finds discriminating between

                                                        9
adjacent asset values costly, and the total information cost depends on how rapidly
the signals the buyer receives change as a function of the asset value.

    Aside from its a priori appeal, this alternative information-cost matrix function
has different implications for the behavior of the DM. Intuitively, the Hessian of the
cost function determines the comparative statics of how the DM responds to chang-
ing incentives. The recoverability result of Caplin et al. (2018b) also demonstrates
that the cost function matters for behavior­ if the cost function can be uniquely
recovered from data on the likelihood of the DM's action in each state, then that
likelihood must be influenced by the cost function. Our applications in section 4
provide additional examples of how information costs influence behavior.
    At this point, we have defined the static rational inattention problem and the
UPS cost functions. Our next section proposes a specific class of UPS cost func-
tions, the neighborhood-based cost functions, that we will argue are superior in
certain respects to the standard mutual information cost function.


3    Neighborhood-Based Cost Functions
In this section, we define the neighborhood-based cost functions. For this section
only, we treat the state space X as part of the definition of the cost function, and
focus on how cost functions defined on different state spaces can be related to each
other. That is, in this section only, we write C( p, q0 ; S, X ) instead of C( p, q0 ; S).
    Motivated by the theoretical results of Hébert and Woodford (2018) and Caplin
et al. (2018b), and the experimental evidence of Dean and Neligh (2018), we restrict
attention to cost functions in the UPS family:

Assumption 1. The cost function C( p, q0 ; S, X ) is uniformly posterior-separable,
and the associated H function is continuously twice-differentiable.

    As the discussion in the previous section emphasized, there are many UPS cost
functions, and they will make different predictions about behavior. Our goal is to
justify particular choices within the UPS family. To make progress, we begin by
observing that, in many problems, the state space X has a structure. That is, some
states are similar in a way that others are not.

                                           10
     To capture this idea, we will assume that X is a finite subset of a metric space
(X , d ), and suppose that the cardinality of X is at least as great at the cardinality
of the real numbers.5 Now suppose we are given with a point finite open cover of X
(i.e. a finite set of open neighborhoods that cover X ). Let us denote this collection
of neighborhoods by N , and let these neighborhoods be indexed by i  I . We will
think of these neighborhoods as regions in which it is difficult to discriminate. Each
neighborhood Ni  N is a subset of X , and we will use the notation Xi  X  Ni to
denote that set of states in neighborhood Ni . Except where it would cause confusion,
we will also refer the sets Xi as neighborhoods.
     The question is how to connect these neighborhoods with the cost function C(·).
Intuitively, the neighborhoods define the sets of points that are difficult to distin-
guish. If there is no neighborhood in N that contains some x, x  X , it should be
easy for the DM to distinguish between x and x , whereas if those states do share a
neighborhood, it should be costly to distinguish them. In the context of the static ra-
tional inattention problem, the DM is distinguishing between x and x if she receives
a different distribution of signals conditional on x than conditional on x .
     To operationalize this idea, consider three different signal structures, p, p , and
p . The signal structure p discriminates between a state x and all other states,
meaning that the conditional distributions of signals conditional on any state except
x are identical under p. Formally,
                                          
                                          r         x =x
                                     px =                                                     (9)
                                          r         x = x,

for some r, r  P (S). Similarly, suppose that p discriminates between x and all
other states, that is, let px = r for x = x and px = r .
    Define p as the signal structure that discriminates between (x, x ) and all other
   5 The  metric d will play no role in our analysis. What we really assume is a second-countable
regular Hausdorff space. But since all such spaces are metrizable (Urysohn's metrization theorem),
it is equivalent to just assume a metric space. We would like to thank Harald Uhlig for a helpful
discussion on this point.




                                               11
states, that is,                        
                                        r          x / {x, x }
                                   px =                                                         (10)
                                        r          x  {x, x }.

The key difference between p and the signal structures p and p is that the former
does not discriminate between x and x , whereas the latter structures do.
     By the logic above, if x and x share a neighborhood in N , the structures p
and p should be costlier than p , because they discriminate between nearby states
whereas p does not. Conversely, if x and x do not share a neighborhood in N ,
it is easy to distinguish between them, and p should be as costly as p and p .
Intuitively, what is costly is distinguishing x from its neighboring states and x from
its neighboring states, and since p does both these things it should be as costly as
if they were done separately. We apply this logic in the assumption below.

Assumption 2. Let x, x  X be distinct states in the support of q0  P (X ), and let
p, p , and p be defined as in equations (9) and (10), with r = r . If there exists a
neighborhood Ni  N with {x, x }  Ni , then

                     C( p , q0 ; S, X ) < C( p, q0 ; S, X ) + C( p , q0 ; S, X ).

If no such neighborhood exists, then

                     C( p , q0 ; S, X ) = C( p, q0 ; S, X ) + C( p , q0 ; S, X ).

    Figure 1 contains a diagram with an example neighborhood structure that sum-
marizes this assumption. To ease exposition, we have made this assumption is
stronger than necessary for our results; we only require that it holds for values of
r close to r. Note also that distinguishing states within a neighborhood is relevant
only when the neighborhood contains states that occur with positive probability
under q0 . One implication of using a UPS cost function is that the conditional
distributions for zero-probability (under the prior q0 ) states are irrelevant.6
    In general, a single state x will be contained in multiple neighborhoods in N .
   6 Tosee this, observe that these conditional distributions change neither the unconditional signal
probabilities  ( p, q0 ) nor the posteriors qs ( p, q0 ) associated with positive probability signals.


                                                 12
We interpret this situation as one in which discriminating between x and all other
states is difficult both because it discriminates between x and the other states in (for
example) the neighborhood N1 and because it discriminates between x and a (pos-
sibly overlapping) different set of states in neighborhood N2 . Our next assumption
states that this situation is equivalent to one in which x is split into two states, x1
and x2 , with x1  N1 and x2  N2 , but x1    / N2 and x2 / N2 .
    Let X be the split space, X = (X \ {x})  {x1 , x2 }  X . Define, for some
distinct r, r  P (S), the signal structure p1 on X that discriminates between x1
and all other states, p1                              1                    2
                         x = r for all x = x1 and px1 = r , and define p in similar
fashion. Likewise, define p as the signal structure that discriminates between x and
all other states on the original state space, (9).
    Let q  P (X ) be some prior on X , and define q1  P (X ) by
                                    
                                    q
                                                x / {x1 , x2 }
                                     x
                                    
                               q1
                                x = qx          x = x1
                                    0           x = x2 .

Define q2 in analogous fashion.
    Our assumption is that discriminating between x and all other states requires
both differentiating x from all states in N1 and all states in N2 , and therefore is as
costly as doing these things separately.

Assumption 3. Fix a prior q  P (X ) and distinct signals r, r  P (S). Suppose
that some state x  X is contained in at least two neighborhoods in N , with none
of these neighborhoods entirely contained in another, and let x1 , x2 , X , q1 , q2 , p,
p1 , and p2 be defined as above. Then

                  C( p, q; S, X ) = C( p1 , q1 ; S, X ) + C( p2 , q2 ; S, X ).

    Figure 2 contains a diagram with an example neighborhood structure that sum-
marizes this assumption. The key implication of this assumption is that it is without
loss of generality to suppose that the neighborhoods are disjoint. This implication
allows us to invoke standard results on additive separability. Combining our first

                                              13
three assumptions, we derive an additive separability result. We present this re-
sult below, but first introduce some notation. For each neighborhood Xi , we define
the probability that some state belonging to neighborhood Xi (and Ni ) occurs under
beliefs q  P (X ), q  ¯i (q)  xXi qx . For neighborhoods with positive probability
 ¯i (q) > 0), we define qi (q)  P (Xi ) as the conditional distribution over Xi under
(q
q, and adopt the convention that qi (q) is uniform if q
                                                      ¯i (q) = 0.

Proposition 1. Under Assumptions 1, 2, and 3, the H function can be written as

                         H (q; X , N ) =   ¯i (q)H i (qi ; Xi ),
                                           q
                                           iI


where H i (·; Xi ) : P (Xi )  R is a twice-differentiable convex function for all i  I .

Proof. See the appendix, section B.1.

    To pin down the specific H i functions, we require an additional assumption.
We will assume that the cost function is monotonically decreasing with respect to
"garblings" of states that preserve the neighborhood structure. That is, if we create
an random mapping from X to X that maps each x  X only to states in X that are
in the exact same subset of neighborhoods in N as x, then this mapping only reduce
the cost function, because it can only reduce the difference between the prior and
posteriors within each neighborhood. Intuitively, by "merging" states, the priors
and posteriors become closer in some sense. This kind of invariance is closely
related to the "invariance under compression" axiom of Caplin et al. (2018b), and
allows us to conclude that each H i function is proportional to Shannon's entropy.
    Formally, let X  X be another set covered by the neighborhood covering.
Define a stochastic (Markov) matrix mx ,x , and suppose it has the following prop-
erty: mx ,x > 0 only if the subsets of N containing x and x are identical. In effect,
this matrix stochastically "garbles" each state x  X into one or more x  X , while
maintaining the neighborhood structure. We define the corresponding mapping of
measures on X to measures on X , M : P (X )  P (X ) by, for all x  X ,

                                M (q)x =     mx ,x qx .                            (11)
                                           xX


                                           14
    Take as given a signal structure p defined on X , and let qs ( p, q0 ) be the associ-
ated posteriors. Now define a new set of posteriors, {qs  P (X )}sS by

                                   qs = M (qs ( p, q0 ))

and observe that sS s ( p, q0 )qs = M (q0 ), meaning that these posteriors are con-
sistent with the prior M (q0 ). It follows that there exists a signal structure p such
that qs = qs ( p , M (q0 )) and s ( p, q0 ) = s ( p , M (q0 )). That is, there exists a sig-
nal structure that generates the garbled posteriors. Because this signal structure has
posteriors and priors that are garbled within each neighborhood, and hence closer
to each other, we assume that it costs weakly less than the original signal structure.

Assumption 4. Let m be a stochastic matrix that maps measures on X  X to
measures on X  X , and suppose that mx ,x > 0 only if, for all i  I , x  Ni 
x  Ni . Then for all such m, all q0  P (X ), and all signal structures p,

                         C( p, q0 ; S, X )  C( p , M (q0 ); S, X ),

where M is the mapping corresponding to m defined by (11) and the signal structure
p : X  P (S) is the signal structure that satisfies M (qs ( p, q0 )) = qs ( p , M (q0 ))
and s ( p, q0 ) = s ( p , M (q0 )).

    Figure 3 contains a diagram with an example neighborhood structure that sum-
marizes this assumption, using an invertible mapping m. In this case, equality must
hold, since the inequality of this assumption applies in both directions. This form of
invariance pins down, up to a scalar, a unique H i function for each neighborhood.
We call the resulting UPS cost function a neighborhood-based cost function.

Proposition 2. Under Assumptions 1, 2, 3, and 4, the H function can be written as

                       H (q; X , N ) = -      ¯i (q)H Shannon (qi ),
                                            ciq
                                           iI

where {ci  R+ }iI are positive constants.

Proof. See the appendix, section B.2.

                                            15
    These neighborhood-based cost functions are unique given the neighborhoods
N and constants c. These neighborhoods and constants determine the difficulty of
discriminating between nearby states. We consider them as part of the economic
environment, observing that problems with similar payoffs can nevertheless differ
in terms of the DM's ability to distinguish between exogenous states. This is exactly
the kind of variation that occurs, for example, in perceptual experiments.
    Define the selection matrices Ei as the |Xi | × |X | matrices that select each of the
elements of Xi from a vector of length |X |. The information cost matrix function
associated with our neighborhood-based cost function is

                            kN (q) =        ¯i EiT g+ (qi )Ei ,
                                          ciq
                                         iI


where g+ (qi ) = Diag(qi ) - qi qT
                                 i is the inverse Fisher information matrix defined
on measures over the neighborhood Xi . We have already seen an example of this
matrix, given a particular neighborhood structure, in (8).


3.1    Neighborhood with Generalized Entropy
We next introduce a generalization of the neighborhood cost function that replaces
Shannon's entropy with the generalized entropy index of Shorrocks (1980). This
generalization, which nests Shannon's entropy as a special case, satisfies Assump-
tions 1, 2, and 3, and hence Proposition 1 holds, but does not satisfy Assumption
4. The original version of this paper studied only the Shannon entropy case; our
use of the generalized entropy index follows Dean and Neligh (2018), who provide
experimental evidence consistent with the neighborhood-based cost function, but
find that generalized entropy indices provide a better fit to their experimental data.
    We start from a generalized kN function, defined for all full-support q as
                      
                             ¯i |Xi |1- EiT (g+ (qi ))2- Ei
                       iI ci q                                             = 2,
          kN (q;  ) =
                          cq ¯ |X |-1 E T (I - q  T )(I -  qT )E
                           iI i i    i        i       i           i   i    = 2,

where g+ (·) is the inverse Fisher information matrix,  is a vector of ones,  is


                                              16
a constant, and the constants ci are strictly positive. Within each neighborhood,
we have assumed that the cost of information is proportional to the inverse Fisher
information to some power, nesting our axiomatically derived cost function as the
 = 1 case. Using (6), we derive the corresponding entropy function, HN (q;  ).

Lemma 1. Let H Gen (qi ;  ) be the generalized entropy index of Shorrocks (1980) on
the neighborhood i  I , defined for any interior qi as
                         
                           1          1
                                                     {(|Xi |eT     2- - 1}    / {1, 2}
                          |Xi | ( -2)( -1) xXi               x qi )
                         
         H Gen (qi ;  ) = - |X 1
                                    xXi ln(eT x qi )                           =2
                                 i|
                         
                                    eT q ln(eT q )
                         
                               xXi x i        x i                              = 1.

The entropy function HN (q;  ) associated with the neighborhood-based information-
cost matrix function kN (q;  ) is, for any q in the relative interior of the simplex,

                               HN (q;  ) =       ¯i H Gen (qi ;  ),
                                               ciq
                                             iI

and is defined on the boundary by continuity for  < 2 and as infinity for   2.

Proof. See the Appendix, Section B.3.

    As mentioned above, the special case of  = 1 corresponds to (the negative of)
Shannon's entropy within each neighborhood. The exponent  controls the curva-
ture of the entropy function (Dean and Neligh (2018) use the following analogy:
H Gen (qi ;  ) is to Shannon's entropy as CRRA utility is to log utility). Using the
our generalized entropy function HN (q;  ), we can define a Bregman divergence,
DN (qs ||q;  ), as in (5), and a static rational inattention problem,7

   VN (q) =              max
                P (A),{qa P (X )}aA aA
                                          (a)(uT
                                               a · qa ) -    (a)DN (qa ||q;  ).              (12)
                                                                aA

    It is sometimes more convenient to work with cost functions defined over signals
{ px  P (S)}xX , as opposed to posteriors qa and unconditional probabilities  (as
in (1)). We rewrite the using Bayes' rule below.
  7 To   deal with the boundaries in the   2 case, we assume q has full support in this problem.

                                                17
Lemma 2. The static rational inattention problem in (12) can be written as

             VN (q) =       max       s( p, q0)u
                                               ^(qs ( p, q))
                        { px P (S)}xX sS
                                            -1
                    -      ci|Xi|1- q
                                    ¯i            (eT
                                                    x q)
                                                        2-
                                                           D ( px || pEiT qi ),
                         iI                      xXi

where
                     
                          1                  px,s 2-
                      ( -2)( -1) sS:s >0 s (( s )
                                                     - 1)  = {1, 2}
                     
        D ( px || ) = sS:s >0 s ln( p s
                                           )               =2
                                       x,s
                                        px,s
                     
                       sS:s >0 px,s ln( s )                = 1.
                     

Proof. See the Appendix, Section B.4.

    The divergences D are known as the -divergences (under a different param-
eterization) and are a transformed version of the Renyi divergences (Amari and
Nagaoka (2007)). In the special case of  = 1, D is the Kullback-Leibler diver-
gence. If  = 1 and there is only a single neighborhood, this is the standard rational
inattention problem with mutual information. The relevance of alternative neigh-
borhood structures is illustrated by the following observation.

Corollary 1. Consider a rational inattention problem with a neighborhood-based
information-cost function (Lemma 2), and let x, x be two states with the property
that (i) ua,x = ua,x for all actions a  A, (ii) qx = qx , and (iii) the set of neighbor-
hoods {Xi } such that x  Xi is the same as the set such that x  Xi . Then under the
optimal policy, p       
                   x = px . If  = 1, this result holds even if qx = qx .

Proof. The result follows directly from the problem in Lemma 2.

    The significance of Corollary 1 can be seen if we consider the predictions of
rational inattention for a standard form of perceptual discrimination experiment. In
these experiments, payments are based on correct and incorrect responses. As a
result, two states in which the correct response and ex-ante likelihoods are identical
will (for a single-neighborhood cost function) have the same likelihood of a correct


                                             18
response. Experimental evidence (intuitively) shows that in some states it is more
difficult to determine the correct response than in other states.


3.2       A Specific Proposal: The Fisher Information Cost Function
Our neighborhood-based framework is flexible enough to accommodate a wide
range of structures on the state space. However, in practice, there is a particular
structure that is relevant for many economic models: states ordered on a line. We
first discuss the case of a discrete set of states, as above, and then extend our results
to allow for a continuum of states, which is useful in many applications.
     Suppose that there are M + 1 ordered states, X M = {0, 1, . . . , M }, and that each
pair of adjacent states forms a neighborhood, Xi = {i, i + 1}, for all i  {0, 1, . . . , M -
1}. Thus two states belong to a common neighborhood if and only if one comes
immediately after the other in the sequence. This captures the idea that the readily
available measurement technologies respond similarly in states that are "similar," in
the sense of being at nearby positions in the sequence. Suppose further that ci = 1
for all i, implying that it is equally difficult to distinguish two neighboring states at
all points in the sequence.8 Under these assumptions, for any full-support q,

                                 1    1 M-1 1 T
            HN (q;  , M ) =                  ( (e j + eT
                                                       j+1 )q)×
                                 - 2  - 1 j=0 2
                                        eT
                                         jq         2-
                                                                  eT
                                                                   j+1 q
                            {( 1   T
                                                    )    +( 1                     )2- - 2}.         (13)
                               2 (e j   + eT
                                           j+1 )q
                                                                 T
                                                             2 (e j   + eT
                                                                         j+1 )q
   8 If ci is the same for all i, we can without loss of generality set it equal to one, as the multiplier
 can still be used to scale the overall magnitude of information costs. Note also that if we regard
our discrete model as a discrete approximation to a model in which the state is actually a continuous
variable, the assumption that ci is the same for all neighborhoods requires that we choose the spacing
between discrete "states" in such a way that any two adjacent states in the sequence are equally
difficult to distinguish. The construction of numerical scales with which to measure physical stimuli
so that equal distances along the scale imply equal difficulty of discrimination is a familiar exercise
in psychophysics; it often requires that the scale be a nonlinear function of measurable physical
properties of the stimuli (Gescheider, 1988).




                                                    19
                                     1   1 2-
Defining the function g(x;  ) =      -2  -1 x ,       we can rewrite this expression as

                M -1                      1 T           T                1 T           T
                    1 T    T              2 (e j+1 - e j )q              2 (e j+1 - e j )q
HN (q;  , M ) =  ( (e j + e j+1 )q){g(1 - 1 T       T )q
                                                            ;  )+ g (1 + 1 T       T )q
                                                                                           ;  ) - 2g(1;  )}.
                j=0 2                     2 (e j + e j +1                2 (e j + e j +1


This function penalizes differences in the function g(·;  ) between states i and i + 1
and their average. Because the g(·;  ) function is convex, any changes in probability
are penalized. As a result, it will be optimal in the static rational inattention problem
for the DM to smooth posterior probabilities across states of the world.
    If qi and qi+1 are close to each other for all i, a second-order Taylor approxima-
tion of the function g(u;  ) around u = 1 clarifies this point:

                                                    T        T    2
                                          1 M -1 ((e j+1 - e j )q)
                         HN (q;  , M )                              .                   (14)
                                          4 j     1 T
                                             =0 2 j(e   + eT )q
                                                            j+1

Note that this approximation is exact in the  = 0 case, and that the approximation
is the same for all values of  . Intuitively, all of the H Gen (qi ;  ) resemble each
other in the neighborhood of the uniform distribution, and hence when applied to a
neighborhood with two states with similar probabilities are approximately identical.
    For many applications, it is convenient to work with a continuous state space.
Based on this approximation result, it is tempting to suppose that, in the limit as
M  , if the discrete distributions qM converge to differentiable function q,
                                                  ^
                                             1           (q (x))2
                       lim HN (qM ;  , M ) =                      dx,
                       M                     4    supp(q) q(x)


where supp(q) denotes the support of q. Based on this intuition, we can define a
continuous-state rational inattention problem:
                                                       ^
         VN (q) =            sup             (a)                  ua (x)qa (x)dx
                     P (A),{qa PLipG }aA aA             supp(q)
                                ^                             ^
                                          (qa (x))2                      (q (x))2
                -  { (a)                            dx} +                         dx,   (15)
                 4 aA              supp(q) qa (x)         4       supp(q) q(x)




                                             20
subject to the constraint that, for all x,

                                       (a)qa(x) = q(x).
                                    aA

In this expression, the real number x is the exogenous state, ua (x) is the utility of
action a  A in state x, q(x) is the prior over the states, and qa (x) is the posterior be-
lief conditional on taking action a. The notation PLipG refers to a set of probability
measures on the support of q that we describe below.
     This problem can alternatively be formulated as a choice of the signal structure:
                             ^                                         ^
                                                                                  ( pa (x))2
VN (q) =         sup                   q(x)  pa (x)ua (x)dx -             q(x)               dx,
         { pa }aA PLipG (A)    supp(q)     aA                 4   supp(q)     aA pa (x)
                                                                                      (16)
where PLipG (A) is the set of mappings { pa : supp(q)  R+ }aA such that for
each x, aA pa (x) = 1, and for each action a, the function pa (x) is a differentiable
function of x with a Lipschitz-continuous derivative.
    This alternative formulation shows that our proposed static information-cost
function is a weighted average of the Fisher information (Cover and Thomas (2012),
sec. 11.10), a real number for each point in the state space that provides a measure
of the local discriminability of states.9 It is for this reason that we refer to our pro-
posal as the "Fisher-information cost function." Like the mutual-information cost
function, the Fisher-information cost function is a single-parameter cost function,
and it can also be applied in almost any context, as long as the state space is contin-
uous.10 Unlike the mutual-information cost function, the Fisher-information cost
function depends on the topological structure of the state space.
    We prove the convergence of the static problem described in section §2 to this
    9 The equivalence of the two formulations is shown in the Technical Appendix, section C.2, where

we also provide further discussion of the connection with Fisher information.
   10 The fact that we have a single free parameter depends on having chosen a coordinate x for the

state space with the property that the difficulty of discriminating nearby states increases with the
distance x between two states in a similar way at all points in the state space. This means that the
formula that we give here for the cost function does not remain appropriate under arbitrary smooth
re-parameterizations of the state space. The formula can easily be generalized, however, to apply to
cases in which the local degree of discriminability of nearby states is a smooth nonlinear function
of x, rather than constant.


                                                21
problem formally in the Technical Appendix, Section C.1, under some regularity
assumptions on the prior q (differentiability, with a Lipschitz-continuous derivative,
and support on a compact set), for the specific case of  = 1.11 In the proof, we
show that the limiting optimal posteriors qa are also differentiable and have the
same support as q (so the Fisher information integrals make sense) and that their
derivatives are also Lipschitz-continuous (which helps prove convergence). We
refer to the set of full-support, differentiable probability distribution functions with
Lipschitz-continuous derivatives as PLipG . The proof is quite technical, and the
relevant economics are summarized by the approximation (14).
    The key challenge of the proof is to demonstrate that the DM will optimally
choose a signal structure such that the posteriors are in PLipG . However, if we are
willing to simply assume this, it is straightforward to extend our results to the  = 1
case by observing that for all values of  , the approximation in (14) holds. We
can then immediately observe that all values of  lead to the same continuous-state
limit. Consequently, the distinctions Dean and Neligh (2018) reach with regards to
the value of  must rely on the way the state space they study is discretized.
    Moreover, provided we are willing to assume posteriors in PLipG , it is straight-
forward to extend our results to a multi-dimensional state space. Suppose that,
instead of being ordered on a line, the state space consists of an L-dimensional grid,
with each edge consisting of M states ordered on a line, and the neighborhoods are
all pairs of states that are adjacent in one of the L dimensions. In this case, by
arguments almost identical to those in the technical appendix, one can show that
                                                      ^
                                             1                |q(x)|2
                       lim HN (qM ;  , M ) =                          dx,
                       M                     4         supp(q) q(x)


where q(x) denotes the gradient. In effect, this simply adds up the one-dimensional
Fisher information costs in each dimension.12 We can also write the multi-dimensional
  11 We also assume bounded utilities. We think the result holds for other values of  , and without
some of our regularity assumptions, but generalizing our quite technical proof is difficult.
  12 Again, the fact that these are added with equal weights on the Fisher information for the various

dimensions depends on assumption that the units in which distance is measured along the various
dimensions are equivalent, in the sense that a given size distance along any dimension has the same
consequence for the degree of discriminability of nearby states.



                                                 22
problem in terms of the signal structure using the cost function
                                          ^
                                                          | pa (x)|2
                 CFisher ( p, q; A) =               q(x)             dx.         (17)
                                      4   supp(q)      aA  pa (x)

    Thus, our proposed Fisher-information cost function can be readily applied to
multi-dimensional settings with a continuous state space. We now turn to applica-
tions, to illustrate the effects of using our proposed alternative in the place of the
standard rational inattention cost function.


4     Applications of Neighborhood-Based Cost Functions
In this section, we discuss several applications of our results. Our first applica-
tion considers a linear-quadratic-Gaussian environment, and the next three study
two-action environments. These two environments cover a wide range of existing
applications of rational inattention (for a survey, see Mackowiak et al. (2018)).


4.1    Linear-Quadratic Gaussian Environments
In this application, we consider the classic "Linear-Quadratic-Gaussian" (LQG)
tracking problem, which is a major application of the standard theory of rational
inattention (see, e.g., Sims (2010)). The mutual-information cost function proposed
by Sims is known to be quite convenient in this case, as it leads to a very tractable
solution. Here we show that our Fisher-information cost function is equally tractable,
while leading to interestingly different conclusions in some cases.
    For this application, we extend the continuous-state version of our model, with
the multi-dimensional Fisher-information cost function, to the case of a continuous
action space as well (though we do not formally prove convergence). An important
conclusion is that, as with the mutual-information cost function, the optimal sig-
nal given a linear-quadratic payoff and a Gaussian prior will be a Gaussian signal.
However, the precision of this Gaussian signal and (in the multi-dimensional case)
the nature of the information it conveys will differ from the mutual-information
case. In particular, we will find that the Fisher-information cost function implies in-


                                              23
formation costs that are linear in precision. Our approach thus provides foundations
for a cost that has already been found to be convenient in practical applications (e.g.
Myatt and Wallace (2011) and Van Nieuwerburgh and Veldkamp (2010)).
    Let the state space X be RL , with L  1, and let the space of possible actions A
be the real line R. The DM's task is to estimate the value of the state (i.e., to "track"
variation in the state), with a reward given by ua (x) = -( T x - a)2 . In other words,
the goal is to minimize the mean squared error of the DM's estimate of  T x, where
 is a non-zero vector that defines the payoff-relevant dimension of the state space.
    We assume that the prior distribution over the state space X is a Gaussian distri-
bution, with mean vector µ0 and variance-covariance matrix 0 . Information costs
are given by the multi-dimensional Fisher-information cost function, as in (17). Our
problem is to choose the functions { pa (x)}aA  PLipG (A) so as to minimize
                       ^          ^
                                                               |x pa (x)|2
             V (q) =       q(x)       [ pa (x)(a -  T x)2 +                ]dadx.   (18)
                       X          A                           4 pa (x)

    This is a problem in the calculus of variations. Our next proposition demon-
strates that, if  < 4|0  |2 , the optimal information structure is equivalent to ob-
serving a one-dimensional signal about some dimension of the state space. The fact
that the optimal signal can be one-dimensional is a consequence of the usual result
that it is without loss of generality to equate signals with recommended actions.

Proposition 3. In the linear-quadratic-Gaussian tracking problem defined in (18),
if  < 4|0  |2 , then the optimal choice of pa (x) satisfies

                             2
              pa (x) =  exp(- (a -  T µ0 -  -2  T (x - µ0 ))2 ),
                       2     2

where  > 0 is a constant satisfying

                                   4 -2 -1 2 
                              |(-1
                                0 +  I)  | =
                                             4




                                                24
                                             1
and  is a vector of length | | = 2 - 2 and direction

                                        ^ T (-1 +  -2   T )-1  .
                           arg max           0                                              (19)
                      | |     ^ :|
                                  ^ |=1


This pa (x) is identical to conditional distribution of actions of a DM who observes
a signal s =  T x +  ,   N (0,  2 ), and then chooses her action optimally.

Proof. See the appendix, section B.5.

    If the DM observes the signal described in this proposition, her expectation of
the payoff-relevant state  T x (and hence optimal action) is

                                      T 0                         -2
     E [ T x|s] =  T µ0 +                                                   (s -  T µ0 ),
                                      T 0                  ( T 0  )-1 +  -2
                  prior
                            "beta" between  T x and  T x            update on  T x


which given the particular optimal values of  and  simplifies to

                          E [ T x|s] =  T µ0 +  -2 (s -  T µ0 ).

As a result, the action taken conditional on x is normally distributed, with mean

                            E [a|x] =  T µ0 +  -2  T (x - µ0 ),

the variance is V [a|x] =  -2 , as implied by our solution for pa (x).
    The critical property of  T x that enables this simplification is that it maximally
covaries with the payoff-relevant state  T x under the DM's posterior after receiving
the signal s. That is, after receiving the signal s, the DM's posterior variance-
covariance matrix on x is

                              V [x|s] = (-1 -2 T -1
                                         0 +  ) ,


and by (19) the vector  maximizes covariance with  under this posterior. An




                                                 25
explicit formula for  given  is

                                     1
                                 = ( -  +  -2 I )-1  ,
                                    4 0

where I is the identity matrix.
    This result is subtly different from what happens in the case of the mutual-
information cost function. With a mutual-information cost function, the DM will
choose to learn only about the payoff-relevant dimension of the state ( will be
a multiple of  ), and ignore all other information even when that information is
correlated with the payoff-relevant state. In contrast, with the Fisher-information
cost function, the DM chooses to receive a signal about a dimension of the state
space that maximally covaries with the payoff-relevant dimension, and as a result
will choose to receive information about dimensions of the state space that are cor-
related with the payoff-relevant dimension even when they are not directly payoff-
relevant themselves. Hébert and La'O (2019) interpret this difference in the context
of public signals, and demonstrate that this distinction leads to significantly differ-
ent outcomes in coordination games ("beauty contests").
    Armed with the knowledge that the optimal signal is conditionally Gaussian
and that its variance does not depend on the state, we can rewrite the problem as a
choice of the posterior variance-covariance matrix s .

Corollary 2. Let ML be the set of L × L real symmetric positive-definite matrices.
The value function V (q) described in (18) can be written as

                                                   
                       V (q) = inf  T s  - tr[-1        -1
                                              s ] + tr [0 ],
                              s ML        4        4
                 subject to s     0 ,

                                               -1
and the optimal policy in this problem is          -2 T -1
                                          s = (0 +    ) , where  and 
are described as in Proposition 3.

Proof. See the appendix, section B.6.

   That is, the DM chooses the variance-covariance matrix of her posterior to mini-
mize errors subject to a cost that is proportional to the trace of the posterior precision

                                           26
matrix (and a "no-forgetting" constraint). This problem is the multi-dimensional
analog of a problem in which costs are linear in precision. A similar result holds
with mutual information, in which the trace in the above equation is replaced with
the log determinant. Consequently, in the one-dimensional case, the two problems
are almost identical, up to the functional form of the precision cost. Even this differ-
ence can generate different predictions, as both Van Nieuwerburgh and Veldkamp
(2010) and Myatt and Wallace (2011) discuss. In the multi-dimensional case, the
two cost functions make more divergent predictions (Hébert and La'O (2019)).
    In the solution described by Proposition 3, as  approaches 4|0  |2 from below,
the optimal choice of  diverges to infinity. That is, the DM's signal converges to
something uninformative. Our next corollary shows that, as one might expect, if
  4|0  |2 , it is optimal for the information structure to be purely uninformative,
and for the DM to choose an action a =  T µ0 regardless of the state.

Corollary 3. In the linear-quadratic-Gaussian tracking problem defined in (18), if
  4|0  |2 , the optimal policy for the DM is to gather no information and choose
a =  T µ0 with probability one.

Proof. See the appendix, section B.7.

    The Fisher information cost function, like mutual information, allows for the
possibility of a corner solution in which no attention at all is paid to some features
of the environment, despite the fact that tracking them would allow the DM to
achieve a higher level of welfare, and despite a finite information cost parameter  .
    The main features of our results are similar to but subtly different from those
of the LQG tracking problem with a mutual-information cost function. We include
these results to show that, if one considers the tractability of the LQG problem
an appealing feature of mutual information, the problem remains tractable (and
the results equally sensible) with the Fisher-information cost function. However,
even though both cost functions result in Gaussian signals, Fisher-information and
mutual-information cost functions imply different conclusions in interesting appli-
cations. Our next application, to psychometric functions, shows that neighborhood-
based cost functions (and their Fisher-information limit) can match experimental
evidence that cannot be reconciled with a mutual-information cost function.

                                          27
4.2    Psychometric Functions
We next discuss neighborhood-based cost functions in the context of perceptual ex-
periments (for example, Shadlen et al. (2007) or Dean and Neligh (2018)). Suppose
that the different states X = {0, 1, 2, . . . , M }, where M is an odd integer, represent
different stimuli that may be presented to the subject, and that the subject is asked
to classify the stimulus as one of two types (L or R); R is the correct answer if and
only if x > M /2. For example, the stimuli might be visual images with different
orientations relative to the vertical, with increasing values of x corresponding to
increasingly clockwise orientations; the subject is asked whether the image is tilted
clockwise or counter-clockwise relative to the vertical. The subject's goal is to give
as many correct responses as possible; hence we suppose that ux,a = 1 if a = R and
x > M /2 or if a = L and x < M /2, while ux,a = 0 in all other cases. We assume that
each of the possible stimuli is presented with equal prior probability, and hence that
both responses have equal ex ante probability of being correct.
     Both the mutual-information cost function and generalizations of it based on
a generalized entropy index represent special cases of a neighborhood-based cost
function, in which all states belong to the unique neighborhood. Hence condition
(iii) of Lemma 1 holds for any pair of states, and by assumption conditions (i) and
(ii) hold as well. In the problem just posed, Lemma 1 implies that the probability of
response R must be the same for all states x < M /2, and also the same (but higher)
for all states x > M /2. Changing the severity of the information constraint changes
the degree to which the probability of responding R is higher when x > M /2, but
the response probabilities still will depend only on whether x is greater or less than
M /2. This is illustrated in Figure 4, which plots the optimal response frequencies
as a function of x, for alternative  , under mutual information.
     Alternatively, consider a neighborhood-based cost function in which the neigh-
borhoods are given by Xi = {i, i + 1} for i = 1, 2, . . . , M - 1, and the constants ci are
equal to one for all neighborhoods, as in Section 3.2. Suppose further that  = 1.
     With this alternative cost function, Corollary 1 no longer requires that the re-
sponse frequencies be identical for any two states. Moreover, because the cost
function penalizes large differences in signal frequencies (and hence in response
frequencies) in the case of neighboring states, in this case an optimal policy involves

                                            28
a gradual increase in the probability of response R as x increases, even though the
payoffs associated with the different actions jump abruptly at a particular value of
x. This is illustrated in Figure 5, which again shows the optimal response frequen-
cies as a function of x, for alternative  , with the cost function just described. The
sigmoid functions predicted with this cost function -- with the property that re-
sponse frequencies differ only modestly from 50 percent when the stimuli are near
the threshold of being correctly classified one way or the other, and yet approach
zero or one in the case of stimuli that are sufficiently extreme -- are characteristic
of measured "psychometric functions" in perceptual experiments of this kind.13


4.3     Global Games and The Fisher-Information Cost Function
The continuity of choice probabilities despite discrete changes in payoffs is also an
important issue for the "global games" literature (Morris and Yang (2016)). This
literature typically assumes a continuum of states, so for this application we will
discuss the continuous-state limit described in (15). We will compare the implica-
tions of the Fisher-information cost function proposed in Section 3.2 with those of
the more standard mutual-information cost function.
     This application is motivated by the work of Yang (2015) and Morris and Yang
(2016), who study global games (e.g. Morris and Shin (1998)) with endogenous in-
formation acquisition. In the well-known analysis of Morris and Shin (1998), with
exogenous private information, there is a unique equilibrium despite the incentives
for coordination across DMs (subject to some caveats and details that are not rel-
evant for our discussion). In contrast, Yang (2015) demonstrates that allowing for
endogenous information acquisition, with mutual information as the information
cost, restores a multiplicity of equilibria.
  13 For the general concept of a psychometric function,  see, for example, Gabbiani and Cox (2010),
chap. 25, especially Figures 25.1 and 25.2, and discussion on p. 360; or Gold and Heekeren (2014),
p. 356. For an example of an empirical psychometric function for the kind of task discussed in
the text (classification of the dominant direction of motion for a field of moving dots), see Shadlen
et al. (2007), Figure 10.1A. Note not only that the curve is monotonically increasing, with many
data points corresponding to different response probabilities between zero and one, but also that the
subject's reward function is clearly of the kind assumed in the text: only two possible reward levels
(for correct vs. incorrect responses), with a discontinuous change in the reward where the sign of
the "motion strength" changes from negative to positive.


                                                29
    The key to Yang's result is that DMs can tailor the signals they receive to sharply
discriminate between nearby states of the world. As a result, they can all coordinate
their decision (say, to invest or not) on a particular threshold, and there are many
such thresholds that can represent equilibria if coordinated upon. But this result de-
pends on the fact that the mutual-information cost function does not make it costly
to have abrupt changes in signal probabilities as the state of the world changes con-
tinuously. Morris and Yang (2016) develop the complementary result, showing that
even in the case of an endogenous information structure, if signal probabilities must
vary continuously with the state, there is again a unique equilibrium.
    Here we show that a neighborhood-based cost function can provide a justifica-
tion for the kind of continuity condition that the result of Morris and Yang (2016)
requires. Those authors study a global game with two possible actions, "invest"
and "not-invest," with equilibrium behavior characterized by a probability s(x) of
investing when the state is x. Their equilibrium uniqueness result depends on an
assumption of continuous choice, meaning that for all information costs  > 0 and
all parameterizations of the relevant utility function, s(x) is absolutely continuous
on a compact interval for which q(x) has full support.
    In our continuous state problem, (15), agents always choose posteriors that are
differentiable, with a Lipschitz-continuous derivative. By assumption, the prior is
also differentiable with a Lipschitz-continuous derivative. Therefore the function

                                         qinvest (x)
                                s(x) =               invest
                                            q(x)

is differentiable with respect to x in the support of q. By the Lipschitz-continuity of
qinvest (x) and q (x), and the fact that q(x) has full support over the relevant compact
interval, the derivative of s(x) is bounded, and hence s(x) is absolutely continuous.
    Thus, our proposal provides a micro-foundation for the continuous choice as-
sumption of Morris and Yang (2016), and hence for uniqueness in global games.




                                            30
4.4    Security Design
Our last application considers the security design model with adverse selection in
Yang (2017),14 which builds on the buyer's decision problem that we have used
as an example. The purpose of this example is to show that neighborhood-based
cost functions remain tractable (at least computationally) in this application, and to
demonstrate an interesting implication of contracting in the presence of a buyer who
will always choose continuous choice probabilities. We will briefly summarize the
environment, and encourage readers to refer to Yang (2017) for a richer exposition.
                                     |X |
    A seller offers a security s  R+ , whose payoffs are contingent on the realized
value of the assets backing the security, x  X  R+ , to a buyer at a price K . The
buyer's problem (our example earlier in the paper) is to gather information about
which asset values x  X are most likely and then accept ("like," L) or reject (R)
this take-it-or-leave it offer. Both parties are risk-neutral, and the seller discounts
the cashflows by a factor  < 1, relative to the buyer. The security is constrained
by limited liability, 0  eT x s  x. The seller designs the security and offers a price,


                            max L (s, K )qL (s, K )T (K  -  s)·
                            s,K 0

subject to the limited liability constraint, where  is a vector of ones. In this ex-
pression, L (s, K ) and qL (s, K ) are the optimal policies of the buyer who solves the
rational inattention problem of (1), with A = {L, R},

                V (q0 ; s, K ) =          max              L qT
                                                              L (s - K  )
                                   L [0,1],qL ,qR P (X )

                             -  L DH (qL ||q0 ) -  (1 - L )DH (qR ||q0 ),

subject to the constraint that L qL + (1 - L )qR = q0 .
    Yang (2017) shows that, with the standard rational inattention cost function (DH
is the Kullback-Leibler divergence), the optimal security design is a debt contract,
s(x) = min{v(x), v¯} for some positive constant v ¯. The analysis involves two dif-
ferent cases, depending on whether the seller attempts to ensure acceptance with
  14 Our  neighborhood cost function could also be applied in the same fashion to the model of
security design with moral hazard in attention described in the appendix of Hébert (2018).


                                                 31
certainty (L = 1) or not, but the form of the optimal security is the same in both
cases. To simplify our exposition, we focus on the case with some possibility of
rejection (L < 1), and discuss acceptance with certainty in appendix section §C.2.
    We explore, numerically, how the result of Yang (2017) changes with alternative
H (·) functions. We consider three alternatives, our neighborhood-based function
HN with our pairwise neighborhood structure (equation (13)), a generalized entropy
index cost function (the neighborhood cost function with only one neighborhood),
and a "weighted" Shannon's entropy. Weighted Shannon's entropy is

                                                         eT
                                                          xq
                         Hw (q) =    (eT     T
                                       x w)(ex q) ln(     T
                                                          q
                                                             ),
                                    xX

where w is a vector of weights. Constant weights correspond to Shannon's entropy.
    Summarizing our results, we replicate numerically the proof of Yang (2017)
that, with mutual information, the optimal security design is always a debt. In
contrast, for weighted mutual information and the generalized entropy index, the
shape of the security design depends on the weights and the prior, respectively. The
neighborhood cost function, on the other hand, appears to always generate the same
shape irrespective of the prior, a result we speculate could be proven analytically in
the continuous-state version of the model.
    Below, we describe our calculation procedure, and the parameters we use to
generate figures 6 and 7. Our choice of parameters is guided by a desire to illustrate
the differences between the cost functions, and to ensure that acceptance is not
certain (L < 1). Our numerical calculation uses the "first-order approach," solving

                                 max              L qT
                                                     L (K  -  s)
                        s,K 0,L [0,1],qL P (X )


subject to the buyer's first order condition and that beliefs remain in the simplex,

                      s - K  +  Hq (q0 - L qL ) =  Hq (L qL ),
                                 eT
                                  x (q0 - L qL )  0, x  X ,




                                          32
and the limited liability constraints.15 Combining the first-order conditions of this
security design problem and the constraints,

             (1 -  )s =  Hq (q - L
                                                
                                   qL ) -  Hq (L qL )+
                                                              
                         +  [Hqq (q - L qL ) + Hqq (L qL )]( L qL -  +  ),

where  and  are the multipliers on the limited liability constraints. This illustrates
that the optimal security design is determined by the entropy function, and hence
the information cost matrix function, subject to the caveat that L  q is endogenous.
                                                                     L
    Our numerical experiment uses an X with twenty-one states, with values of x
evenly spaced from 0 to 10. We use a seller  of 0.5, and prior q that is an equal-
weighted mixture of a uniform and binomial (21 outcomes of a 50-50 coin flip)
distribution. We have chosen these parameters to help illustrate the differences
between the cost functions.16
    For the generalized entropy and neighborhood-based cost functions, we use  =
13. This value is close to the estimated parameter of Dean and Neligh (2018) for
these two cost functions, although there is no particular reason to apply parameters
estimated for perceptual experiments to security design. The various cost functions
are not of the same "scale," so the same values of  do not necessarily result in the
securities of the same scale. We have chosen  = 1    2 for Shannon's entropy,  = 1
                                                                                     1
for weighted Shannon's entropy and the neighborhood cost function, and  = 50
for the generalized entropy function, which results in securities that are of the same
scale but distinct in our graphs. For our weighted Shannon's entropy, we use

                                                   3  x
                                         w(x) =      + .
                                                   2 10

This linear weight structure assumes that it is more costly for the buyer to learn
  15 We  conjecture, but have not proven, that the first-order approach is valid in this context.
  16 In particular, the effects of weighted vs. standard Shannon's entropy are proportional to ln( ),
so we choose a value of  significantly different from one. The differences between the generalized
entropy index and Shannon's entropy disappear with a uniform prior, so we use the binomial part
of the prior to highlight those differences. At the same time, it is helpful for numerical purposes to
ensure the prior is significantly different from zero in each state, which is why we have the uniform
part of the prior.



                                                 33
about good states than about bad states. We will see that this induces the seller
to offer the buyer more in good states, and hence makes the buyer's security more
equity-like. The more general point is that almost any security design could be
reverse-engineered as optimal given some weight matrix. This reinforces the need
to consider what kinds of information costs are reasonable.
     Our numerical results are shown in figures 6 and 7. The first of these shows the
optimal security designs, the second the optimal monotone (in x) security designs.
Our numerical calculations recover the result of Yang (2017) for the case of Shan-
non's entropy. They also illustrate our point that, with upward-sloping weights, the
result for weighted Shannon's entropy is equity-like. The "inverse hump-shape"
of the optimal security with the generalized entropy index cost function is caused
by the "hump-shape" of the prior.17 The optimal securities for mutual information
and weighted mutual information are monotone, and hence do not differ between
the two graphs, whereas the optimal securities for the neighborhood based cost
function and (imperceptibly) the generalized entropy index are non-monotone, and
hence do differ. For weighted mutual information and the generalized entropy in-
dex, monotonicity or a lack thereof is not guaranteed, as the shape of the optimal
security depends on the weights and prior, respectively.
     Our results for the neighborhood cost function appear, regardless of parameters,
to result in the same "debt-like," but non-monotone, optimal security. This security
is non-monotone and rapidly changing in one area. Rapid changes in security values
would cause rapid changes in buyer behavior with Shannon's entropy, and hence be
sub-optimal, but this is not the case with neighborhood cost functions. As a result,
it is possible for the optimal security to have rapid changes. However, when we
restrict the security to be monotone, the optimal security is a debt, suggesting that
the result of Yang (2017) is robust to using neighborhood cost functions (but not
the other two alternatives) under this additional restriction. We conjecture that it is
possible to prove the optimality of debt among monotone securities with a Fisher
information cost, in the continuous state case.18
  17 With  a uniform prior, the optimal security with the generalized entropy index cost is also a debt.
  18 Sharp-eyed   readers might notice a second feature of the optimal security for neighborhood-
based cost functions: the "flat" part isn't exactly flat. This feature arises from the "tri-diagonal"
nature of the information cost matrix function k(q), which leads to a difference equation describing


                                                  34
5     Conclusion
In many applications of rational inattention, the space of exogenous states has a
structure­ for example, that of numbers ordered on line. Imposing assumptions
on the structure of the state space, and assuming a uniformly posterior separable
cost function, we have derived the neighborhood-based cost functions. These cost
functions capture the idea that certain states are easier or harder to discriminate than
others, and as a result are able to match the results of perceptual experiments. In
contrast, the standard rational inattention cost function, mutual information, cannot
match the results of these experiments.
    Moreover, we have shown that the neighborhood-based cost functions and their
continuous state limit, the Fisher information cost function, make predictions that
differ from those of mutual information in important settings: linear-quadratic Gaus-
sian problems, global games, and security design. The Fisher information cost func-
tion, in particular, is a one-free-parameter family of cost functions that can be used
in place of mutual information in any application in which states are continuous and
described by a vector of real numbers.


References
Shun-ichi Amari and Hiroshi Nagaoka. Methods of information geometry, volume 191.
  American Mathematical Soc., 2007.
Andrew Caplin and Mark Dean. The behavioral implications of rational inattention with
  Shannon entropy. Unpublished manuscript, August 2013.
Andrew Caplin, Mark Dean, and John Leahy. Rationally inattentive behavior: Characteriz-
  ing and generalizing Shannon entropy. Unpublished manuscript, 2018b.
John A Clithero. Improving out-of-sample predictions using response times and a model
  of the decision process. Journal of Economic Behavior & Organization, 148:344­375,
  2018.
Thomas M Cover and Joy A Thomas. Elements of information theory. John Wiley & Sons,
  2012.
Henrique De Oliveira, Tommaso Denti, Maximilian Mihm, and Kemal Ozbek. Rationally
the optimal security. As the number of states increases, the "flat" part of the security becomes in-
creasingly flat. In the continuous state case, the difference equation becomes a differential equation,
and we conjecture that the flat part is truly flat.



                                                 35
  inattentive preferences and hidden information costs. Theoretical Economics, 12:621­
  624, 2017.
Mark Dean and Nathaniel Neligh. Experimental tests of rational inattention. Technical
  report, Working Paper, Columbia University, 2018.
Ambuj Dewan and Nate Neligh. Estimating information cost functions in models of rational
  inattention. Unpublished manuscript, January 2017.
Ernst Fehr and Antonio Rangel. Neuroeconomic foundations of economic choice -- recent
  advances. Journal of Economic Perspectives, 25(4):3­30, 2011.
Fabrizio Gabbiani and Steven J. Cox. Mathematics for Neuroscientists. Academic Press,
  2010.
Joshua I. Gold and Hauke R. Heekeren. Neural mechanisms for perceptual decision making.
  In Paul W. Glimcher and Ernst Fehr, editors, Neuroeconomics: Decision Making and the
  Brain, 2d ed. Academic Press, 2014.
Benjamin Hébert. Moral hazard and the optimality of debt. The Review of Economic
  Studies, 85(4):2214­2252, 2018.
Benjamin Hébert and Jennifer La'O. Information acquisition, efficiency, and non-
  fundamental volatility. 2019.
Benjamin Hébert and Michael Woodford. Rational inattention in continuous time. Unpub-
  lished manuscript, September 2018.
Ian Krajbich, Bastiaan Oud, and Ernst Fehr. Benefits of neuroeconomics modeling: New
  policy interventions and predictors of preference. American Economic Review, 104(5):
  501­506, 2014.
Bartosz Mackowiak, Filip Matejka, and Mirko Wiederholt. Rational inattention: A disci-
  plined behavioral model. 2018.
Stephen Morris and Hyun Song Shin. Unique equilibrium in a model of self-fulfilling
  currency attacks. American Economic Review, pages 587­597, 1998.
Stephen Morris and Philipp Strack. The Wald problem and the equivalence of sequential
  sampling and static information costs. Unpublished manuscript, June 2017.
Stephen Morris and Ming Yang. Coordination and the relative cost of distinguishing nearby
  states. Unpublished manuscript, 2016.
David P Myatt and Chris Wallace. Endogenous information acquisition in coordination
  games. The Review of Economic Studies, 79(1):340­374, 2011.
Luciano Pomatto, Philipp Strack, and Omer Tamuz. The cost of information. arXiv preprint
  arXiv:1812.04211, 2018.
Michael Shadlen and Daphna Shohamy. Decision making and sequential sampling from
  memory. Neuron, 90(5):927­939, 2016.
Michael N. Shadlen et al. The speed and accuracy of a perceptual decision: A mathematical
  primer. In K. Doya et al., editors, Bayesian Brain: Probabilistic Approaches to Neural
  Coding. M.I.T. Press, 2007.
Anthony F Shorrocks. The class of additively decomposable inequality measures. Econo-
  metrica: Journal of the Econometric Society, pages 613­625, 1980.


                                           36
Christopher A Sims. Rational inattention and monetary economics. Handbook of Monetary
  Economics, 3:155­181, 2010.
Stijn Van Nieuwerburgh and Laura Veldkamp. Information acquisition and under-
  diversification. The Review of Economic Studies, 77(2):779­805, 2010.
Michael Woodford. Inattentive valuation and reference-dependent choice. Unpublished
  manuscript, May 2012.
Michael Woodford. An optimizing neuroeconomic model of discrete choice. Technical
  report, National Bureau of Economic Research, February 2014.
Ming Yang. Coordination with flexible information acquisition. Journal of Economic The-
  ory, 158:721­738, 2015.
Ming Yang. Optimality of debt under flexible information acquisition. 2017.



A      Figures

                           Figure 1: Diagram for Assumption 2




Notes: X = {X 1, X 2, X 3, X 4} in this diagram. Each circle denotes a neighborhood, N =
{N 1, N 2, N 3}. Under the signal structure p, red/gray colored states have signal distribution r ,
whereas black-colored states have signal distribution r. The left-hand side describes a situation
in which the x and x of Assumption 2 share a neighborhood, while the right-hand side describes a
situation in x and x do not share a neighborhood.



                                                37
                            Figure 2: Diagram for Assumption 3




Notes: X = {X 1, X 2, X 3, X 4} and X = {X 1, X 2, X 3_1, X 3_2, X 4} in this diagram. Each circle de-
notes a neighborhood, N = {N 1, N 2, N 3}. Under the signal structure p, red/gray colored states have
signal distribution r , whereas black-colored states have signal distribution r. The arrows describe
how the probability of q  P (X ) is assigned to q1 , q2  P (X ).



                            Figure 3: Diagram for Assumption 4




Notes: X = {X 1, X 2, X 3, X 4} and X = {X 1, X 2, X 3, X 3, X 4_1, X 4_2} in this diagram. Each cir-
cle denotes a neighborhood, N = {N 1, N 2, N 3}. Under the signal structure p, red/gray colored
states have signal distribution r , whereas black-colored states have signal distribution r. The arrows
describe how the probability of q  P (X ) is assigned to q  P (X ).


                                                 38
                       1
                      0.9
                      0.8
                      0.7
                      0.6
           Prob(R)



                      0.5
                      0.4
                      0.3
                                                           3 =.5
                      0.2                                  3 =1
                      0.1                                  3 =2
                                                           3 =4
                       0
                            5          10           15             20
                                         x

Figure 4: Predicted response probabilities with a mutual-information cost function,
for alternative values of the cost parameter  .


                        1
                      0.9
                      0.8
                      0.7
                      0.6
            Prob(R)




                      0.5
                      0.4
                      0.3
                                                          3 =2.5
                      0.2                                 3 =10
                      0.1                                 3 =25
                                                          3 =50
                        0
                            5          10          15              20
                                         x

Figure 5: Predicted response probabilities with a neighborhood-based cost function,
in which each neighborhood consists only of two adjacent states.




                                        39
     Figure 6: Optimal Security Designs by Entropy Function




Figure 7: Optimal Monotone Security Designs by Entropy Function




                              40
Online Appendix
B     Proofs

B.1    Proof of Proposition 1
This proof will refer to a few results in Hébert and Woodford (2018).
   Observe that all continuously twice-differentiable UPS cost functions satisfy
conditions 1-4 of Hébert and Woodford (2018) (see Lemma 8 and its proof). Sup-
pose that
                                      r = r + v

for some  > 0 and non-zero v  R|S| , and that r has full support on S. Then by
Lemma 11 of Hébert and Woodford (2018),

                                   1
                    C( p, q0 ; S) =  2 kx,x (q0 ) T · g(r) ·  + o( 2 )
                                   2
where g(r) = Diag(r)-1 -  T and k(·) is the information cost matrix function.
Similarly,
                                1
                C( p , q0 ; S) =  2 kx ,x (q0 ) T · g(r) ·  + o( 2 )
                                2
and

                                    1
                   C( p , q0 ; S) =  2 kx,x (q0 ) T · g(r) ·  + o( 2 )
                                    2
                                    1 2
                                  +  kx ,x (q0 ) T · g(r) ·  + o( 2 )
                                    2
                                  +  2 kx,x (q0 ) T · g(r) ·  + o( 2 ).

Consequently, by Assumption 2, if x and x do not share a neighborhood in N ,
kx,x (q0 ) = 0, and if they do, kx,x (q0 ) < 0.
     Observe also that if q0,x = 0, we must have kxx (q0 ) = 0 by the fact that p is
costless under these circumstances, which follows from Assumption 1 as discussed
in the text.
     By the definition of the information cost matrix (equation (6)), this property also

                                           41
applies to the Hessian matrix of H . That is, if x and x share a neighborhood in N ,
then
                                    2
                                         H (q) < 0,
                                  qx  qx
and otherwise
                                      2
                                            H (q) = 0.
                                     qx  qx
   It follows that if x and x do not share a neighborhood, then

                                              
                                      H (q) =     H (q )
                                   qx          qx

for all measures q, q that differ only in the mass on x .
    We next take a detour to argue that it is without loss of generality to suppose
neighborhoods are disjoint. Observe first that if one neighborhood is entirely con-
tained in another, the existence of the smaller neighborhood imposes no additional
restrictions under our assumptions. Consequently, it is without loss of generality to
assume no neighborhood is contained in another neighborhood.
    Under these circumstances, if there is an x  X contained in multiple neighbor-
hoods, we can split it by Assumption 3. In the context of that assumption, define
        |X |
q  R+ by                            
                                    q
                                       x    x  / {x1 , x2 }
                             qx =
                                    q
                                       x    x  {x1 , x2 }.

It follows immediately that, because q differs from q1 only on the mass x2 ,

                           C( p1 , q1 ; S, X ) = C( p1 , q ; S, X ),

and likewise C( p2 , q2 ; S, X ) = C( p2 , q ; S, X ). Defining the signal structure p by
px = r1(x   / {x1 , x2 }) + r 1(x  {x1 , x2 }), by Assumption 2,

                  C( p , q ; S, X ) = C( p1 , q ; S, X ) + C( p2 , q ; S, X )
                                   = C( p, q; S, X ).




                                              42
Consequently, it is without loss of generality to write the problem on the split space,
and repeating this argument implies it is without loss of generality to assume neigh-
borhoods are disjoint on X , provided that we do not impose the requirement that
q  P (X ). However, the costs when q         / P (X ) are determined by Assumption 1
and the homogeneity of degree one of H .
    Observe, by the strict positivity and homogeneity of degree one of H , that at
least one partial derivative must be positive. Consequently, by the General Theorem
on Functional Dependence (see Leontief (1947) and Gorman (1968)), separability
holds:
              H (q; X , N ) = f (H
                                 ^ 1 (q1 (q), q        ^ 2 (q2 (q), q
                                              ¯1 (q)), H            ¯2 (q)), ...),

where the H ^ i are continuously differentiable functions only of the values of qx
within the neighborhood Xi (and hence of qi and q  ¯i ), and f is a continuously differ-
entiable function.
    By the condition
                                2
                                      H (q; X , N ) = 0
                              qx  qx
for x, x that do not share a neighborhood, the function f must be linear in its ar-
guments. The constant term in f is irrelevant for cost function under Assumption
1, and hence without loss of generality we assume it is zero. We have concluded
                                                                                   ^i
that f (x) =  x for some constant  , and without loss of generality to rescale the H
functions and assume  = 1. Therefore, we can write

                             H (q; X , N ) =   ^ i (qi , q
                                               H         ¯i ; Xi ).
                                               iI

Under Assumption 1, the level of the cost functions H        ^ i (qi , q
                                                                       ¯i ; Xi ) has no impact
on the cost functions. We can therefore assume without loss of generality that
H^ i (qi , 0; Xi ) = 0, consistent with the assumption of homogeneity of degree one for
H (q; X , N ). Considering distributions that place all support within a single neigh-
borhood, it follows that the H       ^ i are homogenous of degree one in q        ¯i and twice-
differentiable in qi . We can therefore write

                            H (q; X , N ) =    ¯i H
                                               q  ^ i (qi , 1; Xi ).
                                              iI

                                               43
which is the result.


B.2    Proof of Proposition 2
As argued in the proof of section B.1, it is without loss of generality to suppose
that the neighborhoods are disjoint. It follows immediately by Assumption 4 that
the Hessian matrix of H i is invariant to all embeddings in the sense of Chentsov
(1982) (see also Amari and Nagaoka (2007) or Hébert and Woodford (2018) for a
discussion of this invariance). Consequently, by Theorem 11.1 in Chentsov (1982),
the Hessian matrix is proportional to the Fisher matrix. Let ci denote the constant
of proportionality, and note by the convexity of H i that it is weakly positive. Inte-
grating the Hessian of H i , it follows that H i must be proportional to the negative of
Shannon's entropy.


B.3    Proof of Lemma 1
We have, for any interior q,

           HN (q;  ) = -      ¯i H Gen (qi ;  )
                            ciq
                           iI
                                 1         1             eT q
                       =  ci q
                             ¯i                       {( 1x )2- - 1}.
                         iI     |Xi | ( - 2)( - 1) xXi |X | q
                                                            ¯i  i


Differentiating,

              HN (q;  )                  1  -1 T 1-
                        = -  ci |Xi |1-      ¯i (ex q)
                                             q
                qx         iI : x X
                                         - 1
                                            i
                                                        1  -2
                          +               ci |Xi |1-       ¯
                                                           q     (eT
                                                                   x q)
                                                                       2-
                              iI : x Xi
                                                        - 2 i xX    i
                                     1         1
                          -  ci                        .
                           iI : x X
                                    |Xi | ( - 2)( - 1)
                                      i




                                                44
Differentiating again,

                   2 HN (q;  )                                        -1 -
                               = x ,x                    ci |Xi |1- q
                                                                    ¯i  qx
                   qx  qx                   iI : x Xi
                                                                  -2 1-
                                  -                  ci |Xi |1- q
                                                                ¯i  qx
                                      iI : x ,x Xi
                                                                  -2 1-
                                  -                  ci |Xi |1- q
                                                                ¯i  qx
                                      iI : x ,x Xi
                                                                  -3             2-
                                  +                  ci |Xi |1- q
                                                                ¯i              qx    .
                                      iI : x ,x Xi                       x Xi

Thus,

        2 HN (q;  )                                             q
qx (                )qx =              ci |Xi |1- q ¯i {x ,x ( x )2-
        qx  qx            iI : x ,x Xi
                                                                q¯i
                           q        q           q           q       q   q       q
                        - ( x )2- ( x ) - ( x )2- ( x ) + ( x )( x )(  ( x )2- )}.
                           q¯i       q¯i         ¯i
                                                 q          q¯i     q¯i q¯i x X q¯i
                                                                                          i


Note that this equation also holds in the  = 2 and  = 1 cases. We can write this
as
                     2 HN (q;  )
               qx (              )qx =  ci |Xi |1- q
                                                   ¯i eT  T
                                                       x Ei m(qi )Ei ex ,
                     qx  qx            iI

where

m(qi ) = Diag(qi )2- - Diag(qi )2-  qT      T
                                     i - qi  Diag(qi )
                                                      2-
                                                         + qi  T Diag(qi )2-  qT
                                                                               i
                               2-
         = (I -  qT  T
                  i ) Diag(qi )   (I -  qT
                                         i ).


The result immediately follows in the  = 2 case. For any  = 2,
                              1
                       m(qi ) 2- = (I - qi  T )Diag(qi )(I -  qT
                                                               i )

                                  = Diag(q) - qi qT       T       T
                                                  i - qi qi + qi qi

                                  = g+ (qi ).

If  < 2, HN (q;  ) is a bounded convex function on the relative interior of the sim-
plex, and hence by theorem 10.3 of Rockafellar (1970) there is a unique extension

                                                45
to the simplex.


B.4     Proof of Lemma 2
First, note that if   2 and qs does not have full support, then px will not have full
support for the state x such that eT                                            T
                                      x qs = 0, and we will have D ( px || pEi qi ) = 
for any i with x  Xi , as required. For  < 2, continuity holds, and therefore both
boundary cases are satisfied, provided the result holds for interior qs .
    To prove this claim, it is sufficient to show that, if all qs are interior,

                -1
 ci|Xi|1- q
          ¯i            (eT
                          x q)
                              2-
                                 D ( pex || pEiT qi ) = -HN (q)+  (eT         T
                                                                    s pq)HN (es pDiag(q)).
iI                   xXi                                                  sS

Using Lemma 1,

                                                   1         1              eT
                                                                             x qs 2-
    sHN (qs) =                 s           ¯i,s
                                        ci q                            { ( 1
                                                                                    ) - 1}.
  sS                 sS:s >0       iI             |Xi | ( - 2)( - 1) xXi |X | q¯i,s
                                                                               i


                     ¯i,s = q
Using Bayes' rule, s q      ¯i p            ¯i,s = pEiT qi , and therefore
                               ¯i,s , where p

                                    -1        1                              -1
 sHN (qs) =  ci|Xi|1- q
                      ¯i
                                         ( - 2)( - 1) x
                                                          (eT
                                                            x q)
                                                                2-
                                                                      p    ¯i,s (eT
                                                                                  s pex )
                                                                                         2-
sS                iI                                   Xi          sS:s >0
                                   1
              -      ¯i
                   ciq               .
                  iI    ( - 2)( - 1)

Therefore,

                                                          -1
      -HN (q) +  s HN (qs ) =           ci|Xi|1- q
                                                 ¯i             (eT
                                                                  x q)
                                                                      2-
                                                                         D ( px || pEiT qi ),
                  sS                   iI                      xXi

as required. The proof is essentially identical in the  = 1 and  = 2 cases.




                                                    46
B.5     Proof of Proposition 3
Here we solve the multi-variate problem in the calculus of variations stated in Sec-
tion 4.1,
                             ^            ^
                                                                         |x pa (x)|2
                inf                q(x)        [ pa (x)(a -  T x)2 +                 ]dadx
        { pa (x)}aA PLipG (A) X            A                            4 pa (x)

where under the prior q(x) x  N (µ0 , 0 ), X = RL , and A = R.
   We can write this as
                     ^       ^
                        q(x) F (a, pa (x), x pa (x); x) da dx,
                        X           A

where for each pair (x, a), the function

                                                                       |g|2
                       F (a, f , g; x)  f · (a -  T x)2 +
                                                                      4 f

is a convex function of the arguments ( f , g) everywhere on its domain (the half-
plane on which f > 0). To prove convexity, observe that

                             Fgg Ff g       fI
                                                        1
                                                              - fg2
                                       =       T                 T      .
                             Fg f Ff f   4 -g2                2 gf 3g
                                             f

The upper left block is positive definite, and the determinant of the matrix is strictly
positive, and consequently the matrix is strictly positive-definite.
    Given the convexity of the objective, the first-order conditions are both neces-
sary and sufficient for an optimum. The relevant first-order conditions are further-
more the same as those for minimization of the Lagrangian
                       ^           ^
                            q(x)        L (a, pa (x),  pa (x); x) da dx,
                        X           A

where
                  L (a, f , g; x) = F (a, f , g; x) +  (x) f + a (x) f .                     (20)



                                                   47
Here  (x) is the Lagrange multiplier associated with the constraint
                                     ^
                                          pa (x)da = 1                             (21)
                                      A

for each x  X , as is required in order for pa (x) to be a probability density function,
and a (x) is the multiplier on the constraint that pa (x) be weakly positive.
    For given Lagrange multipliers, the problem of minimizing the Lagrangian can
further be expressed as a separate minimization problem for each possible action
a. Then if we can find a function  (x) and a function pa (x) for each a  A, with
pa (x) > 0 for all x, such that (i) for each a  A, the function pa (x) minimizes
                         ^
                               q(x)L (a, pa (x), x pa (x); x) dx,                  (22)
                           X

and (ii) condition (21) holds for all x  X , then we will have derived an optimal
information structure.
    For the problem of choosing a function pa (x) to minimize (22), the first-order
conditions are given by the Euler-Lagrange equations

           L                             L
                                             d L
    q(x)     (a, pa (x), x pa (x); x) =  k q(x) k (a, pa (x), x pa (x); x) ,
           f                            k=1 dx g

or equivalently,

L
  (a, pa (x), x pa (x); x) = g L (a, pa (x), x pa (x); x) · x [log q(x)] + x · g L (a, pa (x), pa (x); x) .
f

   In the case of the objective function (20), we have

                 L                
                   = (a -  T x)2 - |x va (x)|2 +  (x) + a (x),
                 f                4

                                              
                                   g L =        x va (x),
                                              2




                                             48
where va (x)  log pa (x). Under our assumption of a Gaussian prior, we also have

                           x [log q(x)] = -1
                                          0 ( µ0 - x).


Substituting these expressions, the Euler-Lagrange equations take the form

                                                                
(a -  T x)2 +  (x)+ a (x) - |x va (x)|2 = (µ0 - x)T -1
                                                    0 x va (x) + x · x va (x)
                           4             2                      2

for all x and a.
    In the case that 4|0  |2 >  , we conjecture and verify that these equations have
a solution given by
                                     a (x) = 0,

                    x va (x) =  [a -  T µ0 -  -2  T (x - µ0 )],                (23)

for some values of   R,   RL and some  (x). Note that this conjecture can be
integrated, with

                                    2
      exp(a (x)) = pa (x) = -  exp(- (a -  T µ -  -2  T (x - µ ))2 ).
                              2     2

   Plugging in this conjecture,

                                 T
          (x) = -(a -  T x)2 +   (a -  T x + ( -  -2  )T (x - µ0 ))2
                                4
                             -1
              + (µ0 - x)T 0      (a -  T x)
                2
                             -1
              + (µ0 - x)T 0      ( -  -2  )T (x - µ0 )
                2
                 -2 T
              +   .
                2

By variation of parameters in a, we must have (as in the proposition)

                                      T        4
                                      =
                                               




                                          49
and, for all x,
                               -1
                    (x - µ0 )T 0   =  T  (x - µ0 )T ( -  -2  ).

Hence we require
                                 -1
                                    =  -  -2  ,
                                4 0
which implies (as stated in the text) that

                                   1
                               = ( -    -2 -1
                                    0 +  I)  ,                                   (24)
                                  4

and
                                1            4
                             |( -    -2 -1 2
                                 0 +  I)  | = ,                                  (25)
                               4             
which is feasible for  > 0 under the assumption that |0  |2 >       4 . Note that this
formula is a rescaled version of the one stated in the proposition.
   Observe that we can rewrite this equations as

                             -1       4
                             0  =        -  -2   T  ,
                                      

and hence that
                                  4 -1
                             =     (0 +  -2   T ) .                              (26)
                                  
    Now suppose the DM receives a Gaussian signal s =  T x +  , where the "ob-
servation error"  is normally distributed, with mean zero and a variance  2 , and
independent of the value of x. Here,  and  are the solutions to (24) and (25)
above.
    With such a signal, and given the Gaussian prior beliefs, the DM's posterior
beliefs are Gaussian. The posterior precision of the DM's belief about  T x is

                                 ( T 0  )-1 +  -2 ,

and the posterior mean is

                  (( T 0  )-1 +  -2 )-1 (( T 0  )-1  T µ0 +  -2 s),



                                         50
while the posterior mean and precision about any zT x with zT 0  = 0 is unchanged.
An orthogonal basis of these z vectors and  form an orthogonal basis, and let

                                  = b0  + b1 z1 + . . . ,

observing that
                                              T 0 
                                     b0 =          .
                                              T 0 
   The posterior variance-covariance matrix is

                           0   T 0     1
                 s = 0 +           ( T           -  T 0  ),
                           ( 0  ) ( 0  )-1 +  -2
                            T    2


which simplifies to

                               0   T 0         1
                       s = 0 +         (     -
                                                       - 1)
                               ( 0  ) 1 +  2  T 0 
                                 T

                                             -2
                         = 0 - 0   T 0               ,
                                       1 +  -2  T 0 

and therefore by the Sherman-Morrison lemma,

                               -1  -1  -2 T
                               s = 0 +    .


   The posterior mean of  T x (and hence optimal action a(s)) is

                 T 0 
 E [ T x|s] =         [(( T 0  )-1 +  -2 )-1 (( T 0  )-1  T µ0 +  -2 s) -  T µ0 ]
                 T 0 
           +  T µ0 ,

which simplifies to (as given in the text)

                                     T 0     -2
             E [ T x|s] =  T µ0 +    T    T   -1  -2
                                                     (s -  T µ ).
                                     0  ( 0  ) + 




                                             51
Observe by the definitions of  and  that

                               1 =  T 0  -  -2  T 0 

and therefore (as stated in the text)

                         E [ T x|s] =  T µ0 +  -2 (s -  T µ0 ).

Consequently, a is normally distributed conditional on x, with conditional mean

                         E [a(s)|x] =  T µ0 +  -2  T (x - µ0 )

and conditional variance
                                  Var[a(s)|x] =  -2 .

      That is,

                                2
                 pa (x) =  exp(- (a -  T µ0 -  -2  T (x - µ0 ))2 ,
                          2     2

and
                    x ln( pa (x)) =  (a -  T µ0 -  -2  T (x - µ0 )),

which is the conjectured and verified functional form in (23).
   Now consider the problem

                        z  arg min zT (-1  -2 T -1
                                       0 +    ) .
                                z:|z|2 =1


The first-order condition is
                                     s  -  z = 0,

where  is the multiplier on zT z = 1, and therefore by (26)

                                            z   ,

concluding the proof.


                                             52
B.6    Proof of Corollary 2
In this corollary we rewrite the problem in terms of a choice of a normally dis-
tributed signal s  RL with conditional mean µx and positive-semidefinite variance
matrix . Given such a signal, the posterior is normally distributed with mean µs
and posterior variance
                               s = (-  1    -1 -1
                                      0 + ) .

Observe by Proposition 3 that the optimal signal structure falls into this class.
   Now consider the original problem in posterior form (as in the multi-dimensional
generalization of equation (15)). Because the posteriors of this problem are nor-
mally distributed, we have


                            ^
                                  |x qs (x)|2
                                              dx = E [|-1          2
                                                       s (x - µs )| |s]
                             Rk    qs (x)

and therefore
          ^             ^
                            |x qs (x)|2
                  (s)                   dxds = E [tr[-1                  T -1
                                                     s (x - µs )(x - µs ) s ]]
            Rk          X    qs (x)
                                                  = tr[-1
                                                       s ].


By the same argument, for the prior q,
                                      ^
                                            |x q(x)|2
                                                      dx = tr[-1
                                                              0 ].
                                        X    q(x)

Given such a signal structure, the optimal action is

                                              a (s) =  T µs ,

and therefore
                 ^           ^
                      q(x)           ps (x)(a (s) -  T x)2 dsdx = E [Var[ T x|s]]
                  X             Rk
                                                                =  T s  .


                                                    53
Let Mk be the set of k × k real symmetric positive-definite matrices. We can write
the posterior-based problem as

                                                 
                             inf  T s  - tr[-1        -1
                                            s ] + tr [0 ]
                            s Mk        4        4

subject to the constraint
                                          -
                                          s
                                            1
                                                 -1
                                                 0 ,

which equivalent to s          0 . By Proposition 3, the optimal solution to this problem
is
                                       -1  -2 T -1
                                  s = (0 +    ) .



B.7        Proof of Corollary 3
In the case that   4|0  |2 , instead, there is no solution to the Euler-Lagrange
equations from the proof of Proposition 3, and we can show that there is no interior
solution to the optimization problem. Instead it is optimal to choose a completely
uninformative information structure, and to choose the estimate a = µ at all times.
This is because in this case, one can show that any information structure and esti-
mation rule implies that

                                       
             V  E[(a -  T x)2 ] +        E[I (x)]  E[( T (x - µ ))T ] =  T 0  ,
                                       4

where I (x) is the Fisher information, with the lower bound achieved only in the case
that a = µ with probability 1.
    Consider some hypothetical policy pa (x). We begin by observing that the Cramï¿oer-
Rao bound for a biased estimator19 implies that

                                     ¯(x))T · I (x; p)-1 · x a
            E p [(a -  T x)2 |x]  (x a                               ¯(x) -  T x)2 .
                                                             ¯(x) + (a

where a¯(x)  E p [a|x] under the measure pa (x), and I (x; p) is the Fisher information
of x under pa (x).
  19 See   Cover and Thomas (2006), p. 396.



                                                54
   Thus,


                                                                      
E p [(a -  T x)2 |x] + tr[I (x)]  (x a¯(x))T · I (x; p)-1 · x a                       ¯(x) -  T x)2
                                                               ¯(x) + tr[I (x; p)] + (a
                      4                                               4
                                                                    
                                  inf{x a¯(x))T · I -1 · x a¯(x) + tr[I ]} + (a¯(x) -  T x)2
                                   I                                4

where the minimization is taken over the set of positive-definite matrices.
   In the technical appendix, we prove the following lemma:

Lemma 3. Let 0 be a k × k real symmetric positive-semidefinite matrix, let Mk be
the set of k × k real symmetric positive-definite matrices, and let v  Rk be a vector.
Then

                               2|v| = inf vT -1 v + tr[]
                                      Mk


Proof. See the technical appendix, C.6.

   By this lemma,

                   4                                         1
                      ¯(x))T · I -1 · x a
               inf{ x a                 ¯(x) + tr[I ]} = 4 - 2 |x a
                                                                  ¯(x)|.
                I 

Therefore,

                              
        E p [(a -  T x)2 |x] + tr[I (x)]   1/2 |x a        ¯(x) -  T x)2
                                                  ¯(x)| + (a
                              4
                                          2|0  | |x a        ¯(x) -  T x)2
                                                    ¯(x)| + (a
                                           2 T 0 x a       ¯(x) -  T x)2 ,
                                                   ¯(x) + (a

where the next-to-last inequality follows from the assumption that   4|0  |2 and
the last from the Cauchy-Schwarz inequality. Taking the expected value under the
prior q(x), it then follows that
                         ^
                  V           q(x) [2 T 0 x a       ¯(x) -  T x)2 ] dx.
                                            ¯(x) + (a                                (27)
                          X




                                            55
    We wish to obtain a lower bound for the integral on the right-hand side of (27).
To do this, we solve for the function a   ¯(x) that minimizes this integral, using the
calculus of variations. Once again, we note that the integrand is a convex function
of a
   ¯ and x a¯, so that the first-order conditions are both necessary and sufficient for
a minimum. The first-order conditions are given by the Euler-Lagrange equations

                             ¯(x) -  T x) = 2 T 0 x q(x)
                       2q(x)(a
                                           = 2q(x) T (x - µ0 )

which have a unique solution a¯(x) =  T µ0 for all x.
   Substituting this solution into the integral (27), we obtain the tighter lower
bound                      ^
                    V        q(x)( T (x - µ0 ))2 dx =  T 0  .                 (28)
                             X

But this lower bound is achievable by choosing a =  T µ0 with probability 1, regard-
less of the value of x (the optimal estimate in the case of a perfectly uninformative
information structure). Hence a perfectly uninformative information structure is
optimal for all   4|0  |2 .
    This solution is not only one way of achieving the lower bound, it is the only
way. It follows from the reasoning used to derive the lower bound for V that the
lower bound can be achieved only if each of the weak inequalities holds as an
equality. But the bound in (28) is equal to the bound in (27) only if a  ¯(x) =  T µ0
almost surely; thus optimality requires this. And the restriction that E[a|x] =  T µ0
for a set of x with full measure implies that we must have

                    E[(a -  T x)2 |x] = ( T (x - µ0 ))2 + Var[a|x].

This in turn implies that

    E[(a -  T x)2 ] = E[( T (x - µ0 ))2 ] + E[Var[a|x]] =  T 0  + E[Var[a|x]].

Hence the lower bound can be achieved only if E[Var[a|x]] = 0.
   Given that the variance is necessarily non-negative, this requires that Var[a|x] =


                                          56
0 almost surely. This together with the requirement that E[a|x] =  T µ0 almost surely
implies that a =  T µ0 almost surely. Hence optimality requires that a =  T µ0 with
probability 1, whenever   4| |2 .




                                         57
