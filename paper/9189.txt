                                 NBER WORKING PAPER SERIES




                                          STORABLE VOTES


                                           Alessandra Casella


                                          Working Paper 9189
                                  http://www.nber.org/papers/w9189


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                     September 2002




I thank Avinash Dixit, Prajit Dutta, Jean-Jacques Laffont, Philippe Michel, Tom Palfrey, Ray Riezman, Jean
Tirole, Robert Townsend, Charles Wyplosz and the participants to numerous seminars and conferences for
very useful comments. Nobuyuki Hanaki and Alex Peterhansl wrote most of the computer programs required
for the numerical exercises, with enthusiasm and persistence. The views expressed herein are those of the
author and not necessarily those of the National Bureau of Economic Research.

© 2002 by Alessandra Casella. All rights reserved. Short sections of text, not to exceed two paragraphs, may
be quoted without explicit permission provided that full credit, including © notice, is given to the source.
Storable Votes
Alessandra Casella
NBER Working Paper No. 9189
September 2002
JEL No. D72, F15

                                            ABSTRACT

       Motivated by the need for more flexible decision-making mechanisms in the European
Union, the paper proposes a simple but novel voting scheme for binary decisions taken by
committees that meet regularly over time. At each meeting, committee members are allowed to store
their vote for future use; the decision is then taken according to the majority of votes cast. The
possibility of shifting votes intertemporally allows agents to concentrate their votes when
preferences are more intense, and although the scheme will not in general achieve full efficiency,
making votes storable typically leads to ex ante welfare gains. The analysis in the paper suggests
that the result will hold if one of the following conditions is satisfied: (i) the number of voters is
above a minimum threshold; (ii) preferences are not too polarized; (iii) the horizon is long enough.




Alessandra Casella
Department of Economics
Columbia University
420 West 118 Street
New York, NY 10027
and NBER
ac186@columbia.edu
                                                                                                      1


                                        I. INTRODUCTION


        Consider a committee that meets regularly over time to vote up or down proposals that
affect all of its members. The committee members are heterogenous and have different
preferences over the policy to be enacted. Decisions are taken by majority vote, and as always a
majority with weak preferences will win over a minority with more strongly held opinions.
Think of this simple alternative: although each member continues to accrue one new vote at each
meeting, he now has the option of storing his vote for future use. If a member abstains at the
first meeting, he will be able to cast either 0, 1 or 2 votes at the second; were he to abstain again,
he would have up to 3 votes available for the next meeting. In other words, suppose votes are
storable. Would this plausible procedural change improve the efficiency of the committee? If
asked at some preliminary constitutional stage, would committee members prefer a system of
storable votes? The purpose of this paper is to propose such a mechanism and begin addressing
the questions it raises.
        Its main results, in the simplified setting the paper studies, are promising. By allowing
voters to shift their votes intertemporally, storable votes lead them to concentrate their votes on
times when preferences are more intense, and therefore increase the probability of obtaining the
desired decision when it is more important. Under plausible assumptions, ex ante welfare is
higher than with non-storable votes. In addition, storable votes appear to behave well even if
voters follow plausible rules-of-thumb, as opposed to fully rational strategies. Finally, at least in
the examples analyzed in the paper, storable votes have better welfare properties than tradable
votes, besides being more transparent and procedurally simpler and thus less objectionable both
ethically and practically.
        The research project was motivated by concerns with the mechanisms through which the
European Union coordinates (or attempts to coordinate) the policies of its members. The
problem of achieving a unified policy while respecting the sovereignty of heterogeneous
countries is very difficult, and all reforms of European Union’s institutions are caught between
the need for faster decision-making that majority voting provides and the importance of
                                                                                                                   2

respecting each country’s priorities lest the whole process of integration comes to an end.1
Intuitively, a country should be able to weigh more heavily when a fundamental interest is
threatened, but at a price: as in the case of money, the choice to obtain control over one item
should come at the cost of smaller disposable resources available in the future. Storable votes
fulfill this function. Other mechanisms may do so too, but storable votes have the advantage of
being extremely simple: the mechanism is very natural, can be explained in few words and
induces very intuitive behavior.
         In line with this motivation, and notwithstanding the theoretical interest of the dynamic
game induced by storable votes, the goal of this research remains very applied. The final
ambition is to study the conditions under which a system of storable votes would be a desirable
and feasible procedural reform over current practice, or equivalently to learn that such a reform
would be unwise. The questions asked and the model designed reflect strongly these practical
concerns. Thus, for example, the paper does not investigate how an optimal decentralized
mechanism could be designed in the setting it studies. Storable votes share with other market-
type systems of voting a fundamental weakness: a voter who chooses to exploit the mechanism
alters the probability that all other votes be pivotal, and hence the value of those votes. The
externality implies that the final outcome will fall short of full efficiency and that there is scope
for a superior mechanism. But the externality does not imply that storable votes cannot
dominate non-storable votes, and it is this more modest question that the current paper
addresses.2 In the same spirit, the paper does not allow for monetary side-payments. In practical
applications, credit constraints and unequal wealth distribution would lead to uneven political
influence, an inequitable - and in general inefficient - outcome that would be politically
unacceptable.
         Of course the importance of preserving strongly felt minority preferences extends much
beyond the immediate challenges of the European Union, to the design of most democratic
institutions. The paper refers to the specific example of the European Central Bank because it

         1
          See for example the surprising defense of veto power in The Economist (12, 8th-14th, 2001, p.34)
         2
         Both observations - the inefficiency brought about by the externality and the welfare gain that may
nonetheless remain relative to standard majority voting - have been made also in reference to tradable votes. See for
example Philipson and Snyder (1996) and Piketty (1994).
                                                                                                                 3

provides a concrete example of a repeated binary voting game with fixed agenda, and it is this
simple setting that this first model studies. But it should be clear that there is no reason why
storable votes should not be studied eventually for potential applications to generic committees.
        The idea of using more resources, here more votes, when a decision is valued more is
very natural, but storable votes have no clear precedent in the literature. The two closest
relations are vote trading (see for example Buchanan and Tullock, 1962, Coleman, 1966, Brams
and Riker, 1973, Ferejohn 1974, Philipson and Snyder, 1996 and Piketty, 1994) and cumulative
voting (Dodgson, 1884, Sawyer and MacRae, 1962, Brams, 1975, Cox, 1990, Guinier, 1994,
Gerber, Morton and Rietz, 1998, among others). But storable votes are different from both.
        Without recurring to monetary exchanges, trading votes by exchanging support for each
others’ favorite policies is common practice, and although a practice just as frequently decried
and almost never granted institutional support3, it has long been studied as a natural and
potentially beneficent way of expressing voters’ intensity of preferences. In a system of storable
votes, votes are traded intertemporally, not interpersonally, but the two mechanisms seem
similar, and it is interesting to compare them. They differ on two main grounds. First, because
they rely on individuals acting alone, storable votes are a simpler and more transparent
institution. When votes are exchanged interpersonally, traders must find each other, competitors
must outbid one another and future promises must be enforced. How these steps take place
depends on auxiliary, but essential, institutions;4 different alternatives are possible and affect the
outcome, creating potential sources of manipulation that contribute to the public’s instinctive
suspicion of tradable votes. These complications do not exist in the case of storable votes.
Second, with both mechanisms individuals’ decisions impose an externality on other voters, but
the problem is different in the two cases. Vote trading results in coalitions, and individuals
uninterested or unable to trade votes find their influence reduced both today and in the future.
With storable votes, on the other hand, when an individual chooses to cast more than 1 vote in
any period, the other committee members are automatically compensated by their increased

        3
          An interesting exception is “pairing” in the US Congress: two members who will be absent for a vote can
choose to “pair” in a couple whose votes would cancel each other out. Their pairing is recorded and transmitted to
the leadership. See Oleszek (2001).
        4
         See for example the discussion in Philipson and Snyder, 1996.
                                                                                                                      4

influence in the other periods. At least in the simple example studied in the paper, storable votes
are not only less tainted ethically, but welfare superior.5
         Cumulative voting, on the other hand, is a system where voters elect a subset of
candidates in a given election and are free to allocate a given stock of votes among them as they
see fit. It is a static mechanism, where all voters choose simultaneously how to cast all their
votes in a single election. Storable votes on the contrary are a dynamic mechanism, where votes
are kept over time and over multiple binary decisions. As time passes, uncertainty is resolved
both with respect to the voters’ evolving preferences, and the stock of votes still available to
one’s opponents. The presence and the partial resolution of uncertainty lend importance to time
and differentiate the two mechanisms.
         Other voting schemes have some of the flavor of storable votes, but again all are
different. Voting by successive veto (Mueller,1978, Moulin,1982) and voting by successive
pair-wise elimination (Moulin,1979) are schemes where one of several possible alternatives is
selected through a dynamic process of elimination. All information is known at the beginning,
and the dynamic aspect allows to select subgame perfect equilibria (and hence restrict the set of
possible outcomes). The main concern is the theoretical design of desirable schemes when
voters must choose among more than two alternatives. Here instead, information is acquired
over time, and the decision is binary each period. The observation that introducing a cost to
voting selects voters with more intense preferences and thus may be efficiency-enhancing has
been made before (for example, Börgers, 2001). But storable votes make that cost endogenous
by allowing voters to choose how much future influence to renounce.
         The dynamic nature of storable votes calls to mind the economic theory of optimal
dynamic contracting (Townsend, 1982, Phelan and Townsend, 1991, Atkeson and Lucas, 1992).
The problem addressed in these works is the design of the optimal incentive-compatible
insurance mechanism when agents are subject to random shocks that are private information.
The literature has found that such a mechanism must be dynamic: agents are effectively given a
stock of claims to transfers; their use at any time reduces, according to an optimal formula, the


         5
          Notice that analyses of vote markets fall in the realm of second-best theory, and restricting some trades
need not lead to worse outcomes.
                                                                                                                    5

amount of claims available for the future.6 It seems plausible that the optimal mechanism for
the problem studied in this paper will similarly be dynamic, and share some features of storable
votes. Storable votes fulfill a function similar to that of simple borrowing and lending schemes
in Townsend (1982), not optimal, but superior to one-period agreements.
         The paper proceeds as follows. Section II describes the assumptions of the model.
Section III discusses why storable votes lead to welfare gains in the simplest setting, when there
are only 2 voters. Section IV extends the analysis to N voters and considers in detail the case of
3 voters. Section V compares storable and tradable votes, and section VI concludes. The
Appendix presents the longer proofs.


                                             II. A SIMPLE GAME


         A committee of n individuals meets regularly to take a common decision d that can
assume two values: d 0 {0,1}. We can think of d = 0 as maintaining the status quo, and d = 1 as
change. Each member’s preferences are indexed by a parameter F : in period t, individual i’s
utility equals Fi,t dt . The parameter Fi,t is drawn from a continuous distribution F(F), defined
over the support [-1, 1] and symmetric around zero. Thus whenever the realization of Fi,t is
negative, i prefers dt = 0; when Fi,t is positive, i prefers dt = 1, and the absolute value of Fi,t
measures the intensity of i’s preferences. The distribution F(F) is common across all committee
members and all periods, and Fi,t is independently distributed both across individuals and across
time. The committee takes the decision every period for a total of T periods, where T is finite.
         For concreteness, we can think of the committee as the Executive Council of the
European Central Bank, meeting each month to decide whether to maintain current interest rates
(d = 0), or to change them (d = 1), under the assumption that both the direction of the possible
change and, more controversially, its size are known before the meeting. Each member of the
Council has preferences over European monetary policy and these preferences need not be

         6
          Athey and Bagwell, 1999, study the optimal intertemporal contract supporting collusion in a cartel with
private information about cost shocks. The question is different, but the logic, and the answer, are very similar.
Dixit, Grossman and Gul, 2000, analyze the efficient equilibrium of a sharing game where two political parties have
varying political strength over time. Again the result relies on dynamic ties: the efficient allocation is non-Markov,
and parties’ shares must reflect the history of the game.
                                                                                                                      6

homogenous, reflecting different needs of the national economies, possibly different objectives
or different individual perceptions of Europe-wide conditions. Each member’s preferences are
summarized by Fi,t. The assumption of i.i.d. shocks is not ideal in this context, but simplifies the
analysis greatly without being fundamental to the logic of the scheme proposed.
         Every period each committee member is given one vote. He can cast it in favor of the
option he prefers, or store it for use at a later time. Thus in period 1, a member can cast either 0
or 1 votes; if he decides to save his vote, in period 2 he will have a total of 2 votes at his disposal
and will decide how many of these, if any, to use; and so on in all successive periods until time T
when the game ends. We assume that votes can be stored but not borrowed to avoid the difficult
problems that could arise in practice if one member were to run out of votes, but we will show
later that the assumption is unimportant.7 Subject to the budget constraint that the votes cast
cannot exceed the number of votes available, each member is asked to indicate his preferred
decision and the number of votes he is willing to spend to support his choice. When individuals
vote, they know the realization of their current Fi,t and the probability distribution F, but cannot
observe the preferences of the other members. On the other hand, because the initial allocation
of votes and the history of the game are known, the number of votes that each player has at his
disposal is common knowledge.
         The committee selects d according to which of the two alternatives has received more
votes. If the votes are equal, the preferences of members who have cast zero votes are
considered; if the tie is still not broken, the decision is taken with a coin toss. The tie-breaking
mechanism seems plausible and has some advantages in deriving analytical solutions, but does
not affect the substance of the results.8

         7
           The constraint on borrowing is common to policy mechanisms that rely on market-type behavior (for
example environmental regulation through tradable pollution licences), because it reduces the costs of mistakes and
inexperience, and increases the credibility of the rules. In addition, when members are subject to appointments or
elections, the inability to borrow from the future limits the extent to which current members can expropriate the
power of their successors. In our model too, the constraint is imposed for purely pragmatic considerations.
         8
          Other tie-break rules - no weight on zero voters; status quo wins when votes are tied (with or without
considering zero voters) - always yielded the same qualitative results. In the application of the game to the
European Central Bank, an alternative model is also possible: we could assume that the decision is between a cut
(d=-1) or an increase (d=1) in interest rates, with the status quo (d=0) prevailing in case of ties. However this set-
up would minimize the role of the status quo, while in fact maintaining the status quo is often the preferred option
for most central bankers. In any case, the results of the two models are identical up to a factor of proportionality in
                                                                                                           7

        The individuals’ objective is to announce a policy preference and choose a number of
votes each period so as to maximize the expected flow of utility over the whole time horizon.
Given a common discount factor *, the problem amounts to maximizing EU i = E(3 t *t Fi t dt),
where E is the expectations operator, subject to the constraint that for each committee member
the stock of available votes ki t equals the votes stored the previous period plus the allocation of 1
new vote (ki t = ki t-1 - vi t-1 + 1, where vi t-1 are votes cast by i at t-1). The state of the game is
given by the distribution of available votes among all members and calendar time; if we call Kt
the vector of votes held by players at time t, we can write the expected value of the game to
individual i when all players follow optimal strategies as EVt i (Kt , t).
        The goal of the paper is to compare the storable votes scheme to the more traditional case
where votes are not transferable over time, and thus each individual always casts one vote in
favor of his preferred alternative. The two games are obviously identical if the time horizon
reduces to a single period, but differ otherwise. The storable votes game requires some thought:
the choice of how many votes to cast reflects not only the current intensity of preferences,
relative to expected future preferences, but also the probability that a vote be pivotal, today or in
the future, and thus the expectation of the other players’ voting behavior over time. It is a non-
stationary dynamic game, where each individual’s optimal strategy will be conditioned on the
realization of his preference shock, on the distribution of available votes among all players and
on calendar time. To build intuition for the results that will follow, it is good to begin with the
simplest case.


                                           III. TWO VOTERS.
III. A. Two Periods.

        Two players i and j must take decision d. At period T-1, they are endowed with 1 vote
each; they will both receive an additional vote at period T, but the game will then end. At T they
will both spend all available votes on their preferred alternative; thus the only problem each
player must solve is what preference to announce and whether to cast 1 or 0 votes in its support
at T -1. Because preferences and votes are announced simultaneously and preferences shocks


expected payoffs.
                                                                                                                            8

are i.i.d., a voter will always announce preferences truthfully: he cannot manipulate his
opponent’s strategy. The choice reduces to the number of votes to cast.
        Consider individual i, and suppose for now that the realization of his preference shock
FiT-1 is positive. Thus i prefers d = 1. If i saves his vote, his expected utility is given by:

                                                                    (
         Eui T −1 (vi = 0) = σi T −1 (3 / 4 p j 0 + p j1 / 2) + δ p j 0 EV i T (2,2) + p j1 EV i T (2,1)      )       (1)


where pj v is the probability that j casts v votes at T-1, and EV iT (s,k) is i’s expected value of the
game in the next and final period, given stocks of available votes s (for player i) and k (for player
j). With Fi T-1 positive, i’s expected current return is Fi T-1, times the probability of obtaining the
desired decision d = 1 when casting 0 votes. If j casts 0 votes too, with probability ½ d = 1 is
chosen because it is both individuals’ desired option (given the symmetry of the distribution
function F(F), and even if neither player is willing to spend any votes); with probability ½ j
prefers d = 0, but even in that case i has a fifty percent chance of winning the coin toss. Hence if
j casts 0 votes, the probability that d = 1 equals 3/4. If instead j casts 1 vote, then d = 1 is
chosen only if it is j’s preferred option, which occurs with probability ½. Thus i’s expected
current return must equal Fi T-1 (3/4 pjo + 1/2 pj1), the first term in equation (1). As for next
period, if i casts 0 votes today, he will then have 2 votes available, while j’s votes will depend on
j’s current strategy.
        Similarly, if individual i casts his vote at T-1, his expected utility is:

                                                                        (
           Eui T −1 (vi = 1) = σi T −1 ( p j 0 + 3 / 4 p j1 ) + δ p j 0 EV i T (1,2) + p j1 EV i T (11
                                                                                                     ,)           )   (2)


taking into account that i always obtains his preferred option at T-1 if j casts 0 votes, or with
probability 3/4 if j casts 1 vote. Comparing (1) and (2), we obtain that i will cast 1 vote at T-1 if
and only if:


                                    (
       σi T −1 ( p j 0 + p j1 ) / 4 ≥ δ p j 0 ( EV i T (2,2) − EV i T (1,2)) + p j1 (EV i T (2,1) − EV i T (11
                                                                                                             , )) )   (3)


Solving next period’s expected values, we can obtain an explicit solution to the optimal strategy.
                                                                                                                9

In period T, both players cast all votes they have, and the one with most votes wins with
probability 1. Thus:
                                            0                1                        1

                       EV i T (2,1) = ∫ σdF (σ )(0) + ∫ σdF (σ )(1) = ∫ σdF (σ )                          (4)
                                            −1               0                        0



since whenever FiT is negative, i will be able to impose d = 0, and whenever FiT is positive, d will
equal 1. The player with fewer votes will not be able to influence the choice of d, but half of the
times his opponent’s preferred choice matches his own. Hence:
                                                 0                1

                       EV i T (1,2) = 1 / 2 ∫ σdF (σ ) + 1 / 2 ∫ σdF (σ ) = 0                            (5)
                                                 −1               0



Finally, when the two players have the same number of votes, the value of the game at period T
is identical to the value of the one-period non-storable votes game (with equal votes). Call the
value of this latter game W, noticing that it is time independent and that any number of equal
votes is equivalent. For any realization of FiT, player i expects to obtain his preferred value of d
three quarters of the times, either because j has the same preference (fifty percent of the times),
or because when they do disagree, the coin toss is in i’s favor (twenty five percent of the times).
That is:
                                       0                                          1
         i
             , ) = EV T (2,2) = ∫ σ dF (σ )(3 / 4(0) + 1 / 4 (1)) + ∫ σ dF (σ )(3 / 4 (1) + 1 / 4 (0))
      EV T (11          i

                                       −1                                         0

or:                                                                1

                                       , ) = EV i T (2,2) = 1 / 2 ∫ σdF (σ ) = W
                              EV i T (11                                                                  (6)
                                                                   0

Substituting (4), (5) and (6) in (3), we obtain:

                             σi T −1 ( p j 0 + p j1 ) / 4 ≥ δ ( p j 0 + p j1 )W
or:
                            σi T −1 ≥ 4δ W                             if σi T −1>0                      (7)

         It is easy to verify that if Fi T-1 is negative the same logic leads voter i to cast his vote if
                                                                                                                       10

and only if -Fi T-1 $4*W. 9             Thus i’s optimal strategy is to identify a threshold value " / 4*W
> 0 and cast 1 vote whenever *Fi T-1* is larger or equal to ", and cast 0 votes whenever*Fi T-1* is
smaller than ". Not surprisingly, the threshold " equals the average intensity of preferences
(discounted), and is strictly smaller than 1 as long as there is any probability mass outside the
extreme values -1 and 1. In the simple case where F(F) is Uniform and * = 1, " = 1/2.
          The conclusion was expected: if i’s policy preference is particularly strong today, he will
be willing to sacrifice some of his possible future power to increase his chances of obtaining the
desired outcome; vice versa, if his policy preference is weak, he will prefer to abstain today and
increase his influence tomorrow. It was this intuition that motivated the paper. We can now
verify whether it leads indeed to desirable welfare properties (at least in this simple example).
          Before the preference shock is realized, the expected value of the game for player i
equals:

                           α                                       0

                 , ) = ∫ σdF (σ )(3 / 4 p j 0 + 1 / 2 p j1 ) + ∫ σdF (σ )(1 − 3 / 4 p j 0 − 1 / 2 p j1 ) +
        EVT −1 (11
                            0                                      −α
                                                               1

                                              (            )
                         + (2 F (α) − 1)δW p j 0 + 2 p j1 + ∫ σdF (σ )( p j 0 + 3 / 4 p j1 ) +
                                                               α
                                                                                                                      (8)
                            −α

                          + ∫ σdF (σ )(1 − p j 0 − 3 / 4 p j1 ) + 2(1 − F (α))δWp j1
                            −1



The expression seems unwieldy, but is easily simplified. Voter j faces an identical problem and
conditions his voting behavior on the same threshold " : he will vote 0 with probability 2[F(")-
1/2], and 1 with probability 2[1-F(")] (using, as in (8), the symmetry of the probability
distribution).10 Substituting these values for pj0 and pj1, the expected value of the two-period
game for either player becomes:



          9
           If Fi T-1 is negative, i’s expected utility from playing 1 or 0 is analogous to equations (1) and (2) above, but
the negative preference shock now multiplies the corresponding probability of losing, as opposed to winning (since
instantaneous utility is then different from zero only if i does not succeed in imposing his preference for d = 0). The
probability of losing when casting 1 or 0 votes is the complement to 1 of the probability of winning we derived
earlier, and the two expressions for expected utility are then immediately calculated.
          10
               Notice that the equilibrium strategy is unique; in fact in this two-period example it is dominant.
                                                                                                                     11
                                α                                 1

                        , ) = ∫ σdF (σ )( F (α ) − 1 / 2) + ∫ σdF (σ ) F (α ) + δW
               EVT −1 (11                                                                                        (9)
                                0                                 α


        We can now establish the first result of the paper. If W is the value of the one-shot non-
storable votes game, call WT-1 the value of the two-period non-storable votes game (where the
finite horizon yields the unique equilibrium value WT-1 = W(1+*)). Then we can state:


Proposition 1. For any distribution F(F), EVT-1(1,1) > WT-1 .


Proof. Notice first that when " = 0, F(") = ½, and when " = 1, F(") = 1. In both cases,
EVT-1(1,1) = WT-1. To understand the behavior of EVT-1(1,1) in the interval " 0 (0,1), differentiate
EVT-1(1,1) with respect to ":

                           ∂EVT −1         1                  
                                   = f (α ) ∫ σdF (σ ) − α / 2                                              (10)
                            ∂α             0                  

where f(") is the density f(F) evaluated at ", and thus is positive. (10) is positive at " = 0 and has
a single root; since we know EVT-1(1,1) = WT-1 at " = 0 and at " = 1, it follows that EVT-1(1,1) >
WT-1 for all " 0 (0,1). And since we know that " is strictly positive and smaller than 1, the
conclusion follows. #


        Proposition 1 states that the two-period game with two players has higher expected value
when the votes can be stored. The result is not surprising and is clearly visible in expression (9):
the possibility to store votes increases the likelihood that a player will win when his preference is
stronger. The positive threshold " shifts probability mass from payoffs with relatively low value
(when *F* is smaller than ") to payoffs with relatively higher value (when *F* is larger than "),
and thus increases ex ante welfare. The analysis is simplified by assuming i.i.d. shocks and a
symmetrical probability distribution, but intuitively it seems unlikely that the conclusion would
be sensitive to these aspects of the problem.11

         11
           Correlation in players’ preferences will reduce the incentive to vote, but seems unlikely to affect the
nature of the result. Autocorrelation of each player’s preferences over time creates a more difficult problem: it
could induce non-truthful voting in an effort to manipulate future voting decisions by one’s opponent.
                                                                                                                              12

          Notice that the proof of Proposition 1 does not rely on the equilibrium value of " - any
threshold strictly between 0 and 1 would lead to welfare gains. This is potentially important - if
practical applications of the mechanism are considered, its robustness to mistakes should be
investigated further. Threshold strategies are very intuitive rules of thumb, and if they are
followed, we can say something more. When the two thresholds are equal (as they must be in
equilibrium), the result always holds. When they differ, call " voter i’s threshold, and $ voter j’s.
Then:

                             α                                   1

     EV   i
              T −1   (11                                                                (
                       , ) = ∫ σdF (σ )( F ( β) − 1 / 2) + ∫ σdF (σ ) F ( β) + δW 1 + 2( F (α) − F ( β))         )      (11)
                             0                                   α



It is not difficult to verify that if *=1, EV iT-1(1,1) > WT-1 for all " 0 (0,1), independently of $ (and
EV iT-1(1,1) = WT-1 at " = 0 or 1).12 If the second period is discounted, limits begin to appear as to
how different the thresholds can be, but even for very small * there is a sizable range of
acceptable thresholds values, i.e. values consistent with welfare gains. In Figure 1, the area
between two curves labeled with the same * value corresponds to the acceptable area at that *
when F(F) is Uniform.


III.B. T Periods.


          Although the logic of the problem is unchanged, the analysis becomes quickly more
complicated as the number of periods increases because the number of states to be considered
increases very rapidly with the length of the horizon. Starting from state (k i, s j ) at t, we need to
evaluate (k i+1)(s j+1) possible states at time t+1, and of course the expected value of each of
these states must be solved backwards from all the possible options it itself can give rise to, and
so on at all times, using as anchor the expected values of all possible different states in the
terminal periods. It is clear that the only possible solution method must be recursive. But here


                                                             1             1
              12
                   When *=1, EV iT-1(1,1) $ WT-1 if 1 / 2   ∫ σdF (σ ) ≥ ∫ σdF (σ )[ F (α) − 1] , a condition that does not
                                                            α              0
 depend on $ and is readily satisfied.
                                                                                                                     13

we encounter another problem: the game is non-stationary, and the equilibrium strategies depend
both on the current state and on calendar time. To calculate the expected values of future states,
we need to weigh them by their probability of realization, and hence by the probabilities of the
players’ alternative strategies in equilibrium. And these change over time, even for given states.
It is then a welcome surprise to be able to obtain analytical results.
        Call vt the vector of strategies (vt i,vt j), i.e. the number of votes cast by the 2 voters at time
t. After the realization of the preference shock Fi t , player i’s expected value of the game at state
Kt is given by:


                                      t
                                          {
     EU t (vt ; σit , Kt ) = maxv i E ui (vt ; σit , Kt ) + δE [ Eσ t +1 Vt +1 ( Kt +1 , σt +1 )]
          i
                                               j
                                              vt
                                                                           j
                                                                          vt
                                                                                          i
                                                                                                        }         (12)


The first expectation inside the curly brackets is taken over vt j, j’s strategy; The second
expectation is taken both over vt j, because j’s current strategy affects the state of the game next
period. and Ft+1 (the vector (Fi t+1, Fj t+1)), because next period preferences affect both strategies
and payoffs next period. Given the possible existence of multiple equilibria, we restrict our
analysis to Markov strategies - i.e. strategies that depend on past history only to the extent that it
is reflected in the current state. It is possible to show that the following results must hold:

Proposition 2: (i) At any t, there exist pure Markov strategies vt* such that:

                      EU t i (vt i* , vt j* ;σit , Kt ) ≥ EU t i (vt i , vt j* ;σit , Kt )     ∀ vt i ≠ vt i*
                      EU t i (vt i* , vt j* ;σ jt , Kt ) ≥ EU t i (vt i* , vt j ;σ jt , Kt )   ∀ vt j ≠ vt j* .
               (ii) vti* is monotonically increasing in *Fi t*, the player’s intensity of preferences.

(The proofs are in the Appendix).

In addition to establishing that an equilibrium exists, and that it exists in pure strategies,
Proposition 2 states that in equilibrium a voter will never casts fewer votes when the intensity of
his preferences is higher than when it is lower. This simple conclusion allows us to characterize
equilibrium strategies a bit more precisely. Notice that the number of votes that a player has at
his disposal is always finite, while the support of *Fi t*, the segment [0,1], is continuous. Thus at
any state of the game and time t, each voter must identify a series of thresholds that divide the
                                                                                                                                                    14

segment [0,1] into a finite number of intervals. For all realizations of *Fi t* in a given interval, i
casts the same number of votes, but higher intervals must correspond to a larger number of votes.
The thresholds are functions of the state of the game, calendar time and the opponent’s
equilibrium strategies, and although their number cannot be larger than the number of votes the
player has available, it can well be smaller - some feasible number of votes may never be cast in
equilibrium.
            Proposition 2 does not state that the equilibrium is unique, and uniqueness is not required
for what follows.13 The important point is that Proposition 2 allows us to characterize each
player’s expected instantaneous utility in equilibrium. Consider for example the symmetrical
state (kt ,kt ), where both voters enter the period with identical stocks of votes. Call Egt i(kt ,kt ) i’s
expected one period equilibrium utility (or payoff) before the realization of the preference shock
when both players play optimal strategies, and "v-1(K,t) # "v(K,t) the equilibrium thresholds such
that i will cast v-1 votes for all *Fi t* 0 ["v-1(K,t), "v(K,t)). Then in a symmetrical equilibrium:

                          α1 ( t , k )                                          α2 ( t , k )

                                ∫ σdF (σ)(F (α (t , k )) − 1 / 2) + α ∫ σdF (σ)(F (α (t , k )) + F (α (t , k )) − 1)+....
     i
Eg t (k t , k t ) =                                     1                                                   1                    2
                                0                                                 1 ( t ,k )

                       α k ( t ,k )                                                                        1
                                                                                                                                                 (13 )
         .........+         ∫            σdF (σ )(F (αk (t , k )) + F (αk −1 (t , k )) − 1) +             ∫ σdF (σ) F (α     k       (t , k ))
                      α k −1 ( t , k )                                                                α k ( t ,k )



where 0 # "v (k,t) # "v+1 (k,t) # 1, œ t, œ v 0{1,..,k-1}.14 A more cumbersome but analogous
expression describes expected one-period equilibrium payoffs in asymmetrical states.
            Player i’s expected value of the game at state (kt i, kt j) before the realization of the
preference shock, is given by:


                          EVt i ( st i , k t j ) =
                                                                                                                                                 (14)
                                                    Egt i ( st i , k t j ) + δEVt +1i ( st i − vt i * + 1, k t j − vt j * + 1)


             13
                  All numerical exercises with 2 voters we studied did however have a unique equilibrium.
             14
            Equation (13) is analogous to (8) above. When i casts vi votes, he obtains the decision he prefers with
 probability 1* prob(vj < vi )+3/4 * prob(vj = vi )+1/2 * prob(vj > vi ), or, exploiting Proposition 2, ½ [F("i ) + F("i+1
 )]. For each interval of Fi values corresponding to a given strategy, i’s expected return is weighted by the
 probability of the decision he prefers minus the probability of the decision he opposes (to account for negative
 realizations of Fi - see (8)), or F("i) + F("i+1 ) - 1.
                                                                                                        15

where, with abuse of notation, we use a single expectations operator although EVt+1 must be
calculated by taking expectations over both Ft (which determines j’s current strategy) and Ft+1.
(See the Appendix for a more detailed description of how to proceed).
        Expressions (13), and its analogue in asymmetrical states, and (14) allow us to establish
the main result of this section. Define as symmetrical any equilibrium where i and j play the
same strategies if there are at the same state at the same calendar time. Then:

Proposition 3. For any distribution F(F) and any t < T, in any symmetrical equilibrium EVt (1,1)
> Wt .

Proof. Intuitively, the objective is to reduce the expected value of the game at the initial period t
to the sum of the expected one-period equilibrium payoffs corresponding to each possible state in
all future periods. Exactly as in the 2-period case, when the state is symmetric, the possibility of
storing votes when preferences are weak makes expected one-period payoffs higher than in the
game with non-storable votes. The problem comes in non-symmetrical states: it is the prospect of
being the weaker player in these states, possibly protracted over time and absent by assumption
from the game with non storable votes, that creates concerns. But notice that in any symmetrical
equilibrium and from any symmetrical state (kt ,kt), the probability of reaching state (st+J i, kt+J j) is
identical to the probability of reaching state (kt+J i, st+J j). Thus when evaluating possible future
states, a player will give the same weight to the two opposite asymmetrical states and in effect
consider their mean expected payoff. All we require then is that this mean payoff be higher, or at
least not smaller, than the expected payoff with non-storable votes. It is this observation that
allows us to establish the Proposition.
        The intuition is formalized in the following two results:

Lemma 1.       i)    Egt i ( kt , k t ) ≥ W ∀ t , with strict inequality at T -1.
               ii ) Egt i ( st i , k t j ) + Egt i ( k t i , st j ) ≥ 2W ∀ t .


Lemma 2. Suppose the following inequalities hold at t+1:
                                                                                                        16


                i ) EVt +1i ( kt +1 , k t +1 ) > Wt +1
                ii ) EVt +1i ( st +1i , k t +1 j ) + EVt +1i ( k t +1i , st +1 j ) ≥ 2Wt +1
Then they must hold at t.

The proofs of the two lemmas amount to manipulating expected equilibrium payoffs (expression
(13) and its counterpart in asymmetrical states) and the dynamic programming equation (14).
They can be found in the Appendix.
        Once the two lemmas are established, Proposition 2 follows immediately. Because all
votes are cast at T, EVT (sTi, kTj) + EVT (kTi, sTj) =2W ; in addition in all symmetrical equilibria at
T-1, EVT-1 (kT, kT) = EgT-1 (kT, kT) + *W > WT-1 by Lemma 1. By induction, the inequalities hold at
all previous times t, and in particular EVt (1,1) > Wt at any t < T. #


        The result confirms that the intuition highlighted so clearly in the 2-period example
extends to a longer horizon. Indeed we would expect the ratio EVt (1,1)/Wt to be higher the
smaller is t, or the larger is (T-t), the horizon remaining before the end of the game, a property
that is not implied directly by the two lemmas but that was satisfied by all numerical simulations
we investigated.
        Notice that once again the proof of Proposition 3 makes no use of the exact values of the
equilibrium thresholds, but holds for all monotone symmetrical thresholds. For example, some
positive welfare gains would still be realized if a voter holding k votes followed this simple rule
of thumb: at any t, divide the interval [0,1] in k+1 subintervals of equal size, and once Fi is
realized cast vi votes, where vi satisfies: vi /(k+1) # |Fi|< (vi+1)/(k+1), vi 0 {0,1,..,k}. If instead off
equilibrium voters’ strategies are not symmetric, we can use the proof of Lemma 2 (ii) to show
that the average expected one-period payoff (averaged over the two voters) cannot be inferior to
the expected payoff under nonstorable votes. By induction this will hold for the average ex ante
value of the full game (although not necessarily for each individual player).
        Finally, we have assumed so far that votes accrue to voters over time and future
allocations cannot be borrowed. Relaxing this constraint would increase the set of possible states,
but at any state equilibrium strategies would still take the form of monotone thresholds (see the
                                                                                                                     17

proof of Proposition 2). Because this is all is needed in Proposition 3, both the proof and the
Proposition would remain identical.15


                                                  IV. N PLAYERS.


        Because the voting mechanism proposed here is new, it is important to study its properties
in the reasonably transparent case of 2 voters. Still, most applications of the scheme should be to
situations involving larger groups. There are two reasons to anticipate complications. First, as
mentioned earlier, there is an externality built into the scheme that must prevent the achievement
of the first-best,16 and welfare properties will be hard to characterize. Second, the logic of the
mechanism exploits the value of casting more votes than one’s opponents, i.e. the resulting
increase in the probability of being pivotal. But such an increase depends on the number of votes,
on the number of voters and, not surprisingly, on whether the committee is of even or odd size.


As a simple illustration, Figure 2 reports the percentage increase in the ex ante probability of
obtaining one’s desired outcome from holding 2 votes when everybody else has a single one, in
the one period game where all votes are cast.17 As expected, the marginal impact of an extra vote
(typically) diminishes with the size of the committee. However, when the size is small enough
the extra vote is much more valuable if the number of voters is even rather than odd, and,
unexpectedly, the impact increases, instead of falling, when the size of the committee goes from 3
to 5 voters.
        These effects depend on the discreteness of the number of votes and voters and are
independent of any potential inefficiency. In other words, even if voters chose their voting


          15
            Of course this does not mean that the welfare gain would remain identical. But notice that the second
 best nature of the problem implies that borrowing need not increase the expected value of the game.
          16
             It is easy to see for example how diffuse but weak preferences might lose against a determined minority
 even in those cases where a static utilitarian concept (the sum of utilities) would dictate otherwise. The correct
 efficient yardstick is more complex because it involves the full intertemporal problem, but the principle is
 unchanged.
          17
               The figure holds for any F(F) symmetrical around zero. The relevant formulas are in the Appendix. .
                                                                                                                        18

strategies cooperatively - ie even if the externality were taken into account and the thresholds set
optimally - the expected welfare gains would still depend on n. Since in addition the severity of
the externality itself changes with n, the number of voters affects the final welfare properties of
the scheme through two separate channels which are not easy to disentangle and characterize
systematically. Figure 3 provides a clear summary of these observations. It depicts the ratio EVT-
1   (1,1,1,...,1)/ WT-1(n) in the next to last period of the game when F(F) is Uniform and *=1, as
function of the number of voters. Three features are particularly noticeable: First, the ratio is
larger than 1, i.e. the welfare gains are positive, for all n different from 3 or 5. Second, the ratio
behaves differently for n odd and n even: especially when the number of players is small, the
welfare gains from the scheme are much higher for n even than for n-1 or n+1. However, and this
is the third feature, the ratio increases with the number of players if n is odd and decreases if n is
even, finally converging to a value larger than 1 for all n large enough. If F(F) is unimodal with a
peak at 0, the graph shifts upward (the more so the larger the probability mass around 0), and
eventually welfare gains become positive for all n, but the qualitative results are otherwise
unchanged.18
            All considered, we are lead to conjecture that the argument for storable votes may be
weakest when the number of voters is small and odd. To understand why, in the remainder of the
paper we concentrate on the case of n=3, and begin by deriving one-period equilibrium payoffs.
We must proceed in three steps. First, we verify that a voter’s equilibrium strategy continues to
be a non-decreasing function of his intensity of preferences.

Lemma 3. At any t and for any number of voters n, voter i’s equilibrium strategy vti* (Kt, t, n, Fit)
is monotonically increasing in *Fit*.

The reasoning is identical to that exploited in the case of 2 voters (see the proof of Proposition 2
in the Appendix). The generalization to n voters results simply from noticing that the probability
of obtaining one’ preferred outcome must be monotonically (if possibly weakly) increasing in the
number of votes cast, for any n, and the proof is not repeated here. Notice that, as in the case of 2


             18
               The relevant formulas are in the Appendix. It can be shown analytically that the ratio EVT-1 (1,1,1,...,1)/
    WT-1(n) converges to a number higher than 1 as the number of players becomes arbitrarily large, for any distribution
    F(F) (Casella and Gelman, in progress).
                                                                                                        19

voters, monotonicity implies that at any t each voter divides the segment [0,1] into a finite
number of intervals, identified by optimal thresholds "v i. The thresholds remain a function of the
state K and of calendar time t.
        Second, we derive the probability of obtaining the desired outcome di* for player i casting
v votes in an arbitrary state K at time t when facing two potential opponents j and z. For any K
and for any v, there are only three alternatives that are relevant to i: either his vote is decisive on
its own, regardless of the others’ preferences; or i obtains the outcome he prefers if and only if he
has at least 1 ally; or his vote is irrelevant to the final decision. When i needs at least 1 ally, with
i.i.d shocks and symmetrical F(F), the probability of obtaining di* equals 3/4 (1 minus the
probability that both opponents agree against i, or 1/4); as in the case of two voters this is the
relevant reference point because it corresponds to the case of non-storable votes. When i’s vote is
decisive on its own, he obtains his favorite outcome with probability 1; this occurs if the sum of
i’s opponents’ votes is smaller than v, or if it is equal to v and i wins the coin toss. Finally, i’s
vote is irrelevant when one of the other players is sure to determine alone the final decision, i.e.
when the difference between i’s opponents votes is larger than v, or when it is equal to v but the
player casting the largest number of votes wins the coin toss. In the special case where v = 0,
player i is never decisive on its own, but the tie-break rule states that he will always be consulted
in case of ties among his opponents. We can then conclude:

Lemma 4. Consider an arbitrary state K. If player i, facing two potential opponents j and z,
casts v votes, the probability that he obtains his preferred decision di* equals:
                      3/ 4 - 1/ 4 prob( v − v > v ) − 1 / 8 prob( v − v = v ) +                
                                            j     z                       j     z
                                                                                                
                      + 1 / 4 prob( v j + vz < v ) + 1 / 8 prob( v j + vz = v )     if v ≠ 0 
        prob(d=di* )=                                                                          
                                                                                               
                                                                                               
                       3/ 4 - 1/ 4 prob( v j − vz > v )                            if v = 0 

where vj and vz are the number of votes cast be j and z respectively.

        Given Lemmas 3 and 4, constructing expected one-period equilibrium payoffs is not
difficult. Consider for example symmetrical state (k,k,k) at time t. Then:
                                                                                                                           20

                                                     k α v +1
                          Eg ( kt , kt , kt ) =     ∑ ∫ σdF (σ)[2 prob(d
                                                    v =0 αv
                                                                                 i
                                                                                  *
                                                                                                 ]
                                                                                      vi = v ) − 1                      (15)



An equivalent equation holds for asymmetrical states, and we can write generally:

 Eg ( k t , yt , zt ) =
                 α1                                 k               α v +1
                        1                                                                 1
        W + ∫ σdF (σ )  − prob( v j − v z > 0)  + ∑                ∫       σdF (σ )[ −      prob( v j − v z > v ) −    (16)
            0           2                       v =1               αv
                                                                                            2
               1                        1                      1
          −      prob( v j − v z = v ) + prob(v j + v z < v ) + prob(v j + v z ) = v ]
               4                        2                      4

                      1

where W = 1 / 2 ∫ σdF (σ ) , the expected payoff with non-storable votes (and "k+1/1).19
                      0
         As in the case of 2 voters, relative to non-storable votes, storable votes shift the
probability of obtaining one’s desired outcome away from low and towards high realizations of
the preference parameter - away from instances where preferences are weaker and towards
instances where they are more intense. This is clearly visible in (16): the negative terms are
larger the closer to zero are the intervals over which the preference parameter is integrated, while
the opposite is true for the positive terms. The fundamental mechanism that delivered welfare
gains in the case of 2 voters (and that supports intuitively the idea of storable votes) remains
unchanged.
         What does change however is the extent of this shift - i.e. the change in the probability of
being pivotal. With 3 voters, gains and losses - relative to non-storable votes - require more
extreme asymmetry than with 2 voters: while before a voter controlled the final outcome
whenever he cast more votes than his opponent, now he must cast more votes than both his
opponents combined; while before he had no say if he cast less votes than his opponent, now this
only occurs if his votes and those of one of his opponent, combined, are less than the votes cast



          19
               Notice that W is unchanged for n=3 and n=2. For arbitrary n:
                1                          n−1 
                                                      
    W (n) = ∫ σdF (σ )(1 / 2)      n −1
                                           n − 2 + In         .
                0                              2      
                                                                                                                    21

by the third voter. Two remarks follow immediately. First, the probability of these more extreme
events will in general be lower than the corresponding critical probabilities in the case of 2 voters.
And since it is the shift in the probability of being pivotal that underlies potential welfare gains,
we should expect these gains to be lower than with 2 voters. Second, there is an asymmetry built
into the critical probabilities - relative to non-storable votes, a voter increases his chances of
being pivotal only when he casts at least as many votes as his two opponents combined, but has
no say if either one of his two opponents is decisive on his own. In symmetrical states, the ex
ante probability of the latter event must then be twice as large than the probability of the former,
implying that the negative terms in (16) are larger than the positive terms. But because the
number of votes a player chooses to cast depends on the strength of his preferences, in
equilibrium the negative terms multiply smaller integrals than the positive ones, and it does not
follow that Eg(kt,kt,kt) is smaller than W - indeed typically it is larger.20 More problematic are
asymmetrical states, where the dominant voting behavior of a single voter is not necessarily
compensated by correspondingly stronger preferences.
       Consider a specific example - the two-period horizon game where all voters start out with
a single vote. In the first period, each player votes 0 if his draw of *F* is less than a threshold "1,
and 1 otherwise (by Lemma 3). Following (16), the first period expected payoff is::
                         α1                                            1

            , , ) = W − ∫ σdF (σ )4[1 − F (α1 )][ F (α1 ) − 1 / 2] + ∫ σdF (σ )2[ F (α1 ) − 1 / 2]2
   EgT −1 (111                                                                                                 (17)
                         0                                             α1



which can be shown to be larger than W for any "1 0 (0,1) if for instance F(F) is Uniform. But
now evaluate expected payoffs in the last period. The possible states at T are: (1,1,1), (2,2,2),
(1,2,2) and its permutations, and (1,1,2) and its permutations. In the last period, players always
cast all their available votes. Thus the expected payoffs associated with symmetrical states at T
must equal W : EgT (1,1,1) = EgT (2,2,2) = W. If the state is (1,2,2), each voter obtains his
preferred outcome if at least one of the other voters agrees, an event that occurs with probability
3/4, exactly as in the case of symmetrical states. Thus EgT (1,2,2) = EgT (2,1,2) = EgT (2,2,1) = W.


         20
             In all numerical exercises, modeling F(F) as a Beta distribution with curvature parameter b we found
Eg(kt,kt,kt) $W as long as b$1 i.e. unless F(F) is convex and bi-modal, with maxima at the two extremes.
                                                                                                                          22

If the state is (1,1,2), however, players with a single vote only obtain their preferred choice with
probability 5/8 (if the player with 2 votes agrees - with probability ½ - or if he disagrees, but the
two smaller players agree with each other and win the coin toss - with probability 1/4 (1/2) =
1/8), and the player with 2 votes with probability 7/8 (he wins unless the 2 smaller voters agree
with each other and not with him and win the coin toss, with probability 1/4 (1/2)=1/8). It
follows that EgT (1,1,2) = ½ W and EgT (2,1,1) = 3/2 W. This is important. In the case of 2
voters it was possible to show that average expected payoffs in asymmetrical states are never
lower than W (where, starting at time 0, each player rationally assigns the same probability to
being the weaker or the stronger player). This very strong result does not hold with 3 voters:
1/3(2 EgT (1,1,2)+ EgT (2,1,1)) = 5/6 W < W.
        The strong welfare result, and the simple proof, obtained with 2 voters will not carry over
now. Whether or not it remains true that storable votes deliver ex ante welfare gains must depend
on the exact value of the equilibrium thresholds, a much more difficult result to establish with any
generality. In the simple two-period case we are considering here, the question is whether the
higher expected payoff at T-1 is sufficient to compensate for the possibility of a welfare loss at T.
If F(F) is Uniform, for example, and *=1, the ratio EVT-1 (1,1,1)/WT-1 is reproduced in Figure 4, as
function of the threshold "1. As the figure shows, the ratio is larger than 1 if "1 is larger than .5.
But, following the same procedure described in the case of 2 players, it is easy to calculate that
the equilibrium threshold in this case equals .364, yielding a EVT-1 (1,1,1)/WT-1 ratio of .99 (the
same value shown in Figure 3 for n=3).21
        However it should be clear from our discussion that the negative conclusion does not hold
generally - because it depends on the exact value of the threshold, it must depend on the
parameters of the model. Possible welfare losses, relative to non-storable votes, arise from those
states where asymmetrical strategies that result in one player’s dominant power occur with large
probabilities, and are not compensated by sufficient differences in strength of preferences. But



         21
              EVT −1 (111                , , ) + δW (1 − 4[ F (α 1 ) − 1 / 2][1 − F (α 1 )]2 ) where EgT-1 (1,1,1) is given
                       , , ) = Eg T −1 (111
by (17). If the 3 players chose the threshold cooperatively, they would set "1=.695 and realize positive expected
welfare gains: by reducing the ex ante probability of casting a vote at T-1, they would reduce the likelihood of state
(1,1,2) at T. Notice that "1=.695 is not an equilibrium.
                                                                                                                     23

the probability of reaching those states, as well as the probability of very asymmetrical strategies
given the state, are crucially influenced by the variance of the intensity of preferences and the
length of the horizon. The lower the variance, the less likely it is that very asymmetrical states
will be reached; and the longer the horizon the higher the option value of a vote, and the less
likely that asymmetrical states will translate into very asymmetrical strategies.
         To evaluate this intuition, numerical exercises were run with different time horizons and
different F(F). F(F) was modeled as a Beta distribution, with the parameter b summarizing its
curvature: b=1 corresponds to the Uniform; as b increases, the relative probability mass around
zero increases and the variance falls. The results are in Figure 5, where the expected value of the
storable votes game at time 0, relative to the value with non-storable votes, is plotted for different
horizons and different distributions. Two regularities emerge. First, at any horizon, an increase
in b is associated with better ex ante welfare properties for storable relative to non-storable votes.
As expected, the larger frequence of weak preferences leads players to expect higher vote savings
and a lower likelihood of states dominated by a single voter. The final consequence is the
improved expected performance of storable votes. Indeed, although the figure does not show it,
for b high enough, the ratio EV0/W0 is larger than 1 for all T. Second, for b>1 storable votes are

associated with ex ante welfare gains if the horizon T is longer than a critical value T (b) , where

T is lower the larger is b. For b=1, the conclusion might still hold - for T > 3 the ratio EV0/W0 is
monotonically increasing in T, as in the case of higher b’s - but the simulated horizon is not long
enough to reflect it.22
         Better welfare properties for longer time horizons pose a commitment problem - as time
passes and the end of the game approaches voters may wish to renegotiate. We ignore this aspect

          22
             Three further comments. First, reducing * (increasing future discounting) raises EV0/W0, presumably
 because the more asymmetrical states are expected to arise at the end of the horizon and are then discounted more.
 But the effect is not large because it is countered in part by the reduction in vote saving, and hence the higher
 likelihood of these same states. Second, as the figure shows, EV0/W0 reaches a minimum at T = 3 for all b’s.
 Although a higher T implies more vote saving, it also multiplies possible asymmetrical states - according to the
 numerical exercises, the second effect dominates for T=3, but becomes relatively less important as T increases
 further. Finally, multiple equilibria are possible, but only in one case did we in fact find two equilibria: b=1 and
 state (5,4,3) at T-1 (which requires T=6). In one equilibrium, voter i never plays 1 and player j never plays 1 or 2.
 In the other equilibrium, player j never plays 3 and player z never plays 1 or 2. Although the first equilibrium leads
 to slightly better welfare properties, the effect washes out almost completely in the calculation of EV0/W0. The
 figure uses the second equilibrium.
                                                                                                     24

here - storable votes are evaluated ex ante at some constitutional stage, and we take the possibility
of commitment as granted. This said, the conclusion is pleasing - the very idea of storable votes
relies on the possibility of intertemporal trades and we should expect it to yield its potential
benefits only if there is enough time for these trades to be possible. The lack of welfare gains
with a 2-period horizon is much less of a concern if longer horizons improve the performance of
the mechanism.
                             V. STORABLE V/S TRADABLE VOTES


        As discussed in the Introduction, storable votes inevitably bring to mind vote trading.
How related are the two mechanisms? Having ruled out monetary side-payments, the natural
comparison is to log-rolling: exchanges of current for future votes. To study the two schemes
side by side we make them comparable through two assumptions: first, we ignore the problem of
enforcement posed by vote trading in our finite horizon setting - debtors would be sure to renege
in the last period, with the usual cascading effect. We posit instead the existence of credible
outside enforcement. Second, with vote trading players who buy votes are effectively borrowing
against their future voting allocation. It seems appropriate then to allow borrowing also in the
case of storable votes. We simply assume that when votes are storable the entire stock of votes is
allocated to each player at time 0, for him to distribute over future decisions as he sees fit.
        Begin with the simplest case: 2 voters and 2 periods. With storable votes, each player
enters the game with 2 votes. Following the usual steps, it is easy to establish that voter i will
choose to cast 2 votes if *Fi* $ 4*W and 0 votes otherwise. Although the initial number of votes
is different, the outcome is identical to the case studied earlier where each voter was endowed
with 1 new vote each period. The expected value of the game is again given by equation (9).
         Suppose now that votes are tradable, but not storable. At time 1, each voter has 1 vote
and three options: he can offer to sell his vote now (S) (and have 2 votes next period, when his
opponent will have 0, if the trade takes place); do nothing (N) (and have 1 vote each period, just
like his opponent), or offer to buy a vote (B) (and have 0 votes next period, when his opponent
will have 2). Call pB the probability that a player offers to buy, pS the probability that he offers to
sell, and pN = 1-pB-pS the probability that he does nothing. Given Fi , positive for simplicity, the
three alternatives lead to expected utilities:
                                                                                                                       25

                     Eui S = pB (σi 1 / 2 + δ 2W ) + (1 − pB )(σi 3 / 4 + δW )
                     Eui N = σi 3 / 4 + δW                                                                        (18)
                     Eui B = pS σi + (1 − pS )(σi 3 / 4 + δW )

It is possible of course that both voters would want to buy, or both would want to sell. With a
longer number of periods, prices would emerge, but in this simple example no voter can offer
more (or less) than a 1-to-1 exchange between a vote today and a vote tomorrow. Thus if both
voters find themselves on the same side of the trade no exchange can be concluded, and this is
reflected in (18). Given these equations, it is easy to see that the optimal strategy is to offer to
buy a vote whenever *Fi* $ 4*W, and offer to sell otherwise. It follows that there is a deviation
from the reference case of no-trade only when at time 1 one voter’s preference intensities are
above the threshold, and the other’s below. But this is exactly what happens with storable votes
(in all other cases, the players’ strategies cancel each other). And because the threshold is the
same, it is not surprising then that the expected value of the game is given once again by equation
(9). With 2 players and 2 periods, the two voting mechanisms are identical.23 Indeed, one can
conjecture that with 2 voters the result should continue to hold for any arbitrary time horizon T.
        Will this be true with 3 voters? The question is interesting because it is with more than 2
voters that the inefficiency built into vote trading comes into being. If the severity of the
externality differs between tradable and storable votes, it is then that such a difference will
appear. Consider a 3-voters, 2-period game. With storable votes each player again enters the
game with 2 votes. The optimal strategy in the first period is to abstain if *Fi* < "SV and cast 2
votes otherwise, where "SV / 4*W(1-p02 )/(1-p22 ), and p0=1-p2 = 2[F("SV)-1/2] (the superscript
SV stands for “storable votes”). The expected payoff at T-1 and the expected value of the game
are given by:




         23
           One important caveat. For consistency with the rest of the paper, we are maintaining the information
assumption made all along: a voter makes decisions knowing his preferences but not his opponent’s. In the case of
tradable votes, this can result in trades between voters on the same side of an issue, albeit with different intensities.
Whether a voter would want to reveal his true position is an interesting question not pursued here (see for example
the discussion in Mueller, 1989).
                                                                                                       26
                                                                 SV
                                        1                    α
                                               p02
                  Eg   SV
                       T −1   = W + ∫ σdF (σ )     −           ∫ σdF (σ ) p p
                                                                          0   2
                                   α SV
                                               2                 0
                                                                                                    (19)
                  EV    SV
                       T −1   = Eg   SV
                                     T −1   + δW (1 − p0 p )
                                                         2
                                                         2


with the probabilities defined above.
        Consider now the case of tradable votes. The horizon continues to be 2 periods, implying
that again each player can buy or sell at most 1 vote at T-1. As in the case of 2 voters, there are
three possible alternatives: each player can offer to sell, offer to buy, or do nothing. When a
transaction is proposed, it is concluded only if there is at least another voter who has made the
complementary proposal. But now a new difficulty emerges: a voter willing to transact may be
shut out of the market because his 2 opponents trade among themselves. Ruling out side-
payments, no price and no bargaining can emerge in the 2-period game, and we assume that if 2
willing buyers, for example, face a single seller, the successful one will be chosen with a coin
toss. Taking this into account, expected utilities from any of the three actions can be calculated as
usual. Consider for example voter i, offering to sell his vote. He succeeds in selling if: (i) both
other voters offer to buy (with probability pB 2 ); (ii) one offers to buy and one does nothing (with
probability 2pB pN ); or (iii) one offers to buy, one offers to sell and the coin toss is favorable to i
(with probability pB pS). If i succeeds, then he is left with 0 votes today in exchange for 2
tomorrow, while his opponents have 2 and 1 votes today and 0 and 1 tomorrow. In both period,
the voter who controls 2 votes alone determines the outcome; thus i’s expected utility, conditional
on succeeding in selling, equals Fi/2+2*W (with Fi positive for simplicity). If i’s offer is not
accepted, that may be either because no-one is interested in buying (with probability (1-pB )2 ), in
which case no transaction takes place and i’s expected utility equals Fi 3/4+*W , or because the
other 2 voters trade among themselves (with probability pB pS), in which case i carries no weight
either this period or the next and his expected utility equals Fi /2. Thus we can write:

         Eui S = ( pB2 + 2 pB pN + pB pS )(σi / 2 + 2δW ) + (1 − pB ) 2 (σi 3 / 4 + δW ) +
                                                                                                   (20)
                       + pB pSσi / 2


The expected utilities associates with the two remaining alternatives are calculated analogously:
                                                                                                                    27

       Eui B = ( pS2 + 2 pS p N + pB pS )σi + (1 − ps ) 2 (σi 3 / 4 + δW ) + pB pSσi / 2
                                                                                                             (20)’
       Eui N = pB pSσi + (1 − 2 pB pS )(σi 3 / 4 + δW )

Given these equations it is easy to establish that it is never optimal to do nothing. There is a
single relevant threshold "M such that voter i offers to sell his vote if *Fi* < "M, and offers to buy
otherwise (the superscript M stands for “market”), where once again "M = 4*W. Expected payoff
at T-1 and the expected value of the game are given by:

                                    1                  αM
                                           pS2                         (1 + pS )
              Eg   M
                   T −1   = W + ∫ σdF (σ )     −        ∫   σdF (σ )             pB
                               αM
                                           2                               2
                                                        0
                                                                                                             (21)
              EV    M
                   T −1   = Eg   M
                                 T −1   + δW (1 − pS pB )


where pS =1-pB =2[F("M)-1/2].
       Comparing equations (19) and (21) is very instructive. It is particularly easy when F(F) is
Uniform, because in that case "SV = "M = .5, and p0 = pS, p2 = pB. The expected value of the
game is unequivocally lower with tradable than with storable votes, a result that arises because
expected payoffs are lower in both periods. And the reason is simple: tradable votes require two
sides for a trade: with 3 voters, the buyer guarantees himself control over the public decision in
the first period, and the seller in the second. The third voter, excluded from the transaction, has
no voice in either periods. With storable votes, on the other hand, each voter decides his
allocation of votes on his own. If a voter decides to abstain in the first period, neither one of his
opponents experiences a decline in the probability of obtaining the desired outcome in that
period; nor can the abstaining voter be sure of controlling the public decision in period 2. In other
words, the externality is less severe with storable than with tradable votes. The intuition seems
robust: the welfare results are unchanged for all F(F) we have tried.24 The probability of being
rationed when votes are tradable remains positive for all finite number of players, and although
the game will be more complicated, the logic seems unchanged. Similarly, the emergence of
prices when trading occurs over a longer horizon should be matched by an equivalent flexibility


         24
           As b increases, "M becomes larger than "SV, implying that the ex ante probability of putting one’s vote up
for sale when votes are tradable increases more than the probability of abstaining.
                                                                                                     28

in the intertemporal program with storable votes. We cannot draw general conclusions at this
point, but there is no obvious reason why the welfare results should be reversed.


                                       VI. CONCLUSIONS


       We have discussed a very simple - indeed natural - voting mechanism for committees that
meet repeatedly over time: voters are allowed to store their votes and shift them intertemporally.
As a result, voters cast more votes when their preferences are more intense, and the probability of
obtaining their preferred decision shifts from times when preferences are weaker to times when
they are stronger. Relative to non-storable votes, ex ante welfare rises.
       This transparent intuition appears clearly, and can be proven rigorously, in the case of 2
voters. When the number of voters is larger, some complications arise but the analysis of the
paper suggests that the conclusion should continue to hold if one of the following conditions is
satisfied: (i) the number of voters is above a minimum threshold; (ii) preferences are not too
polarized; (iii) the horizon is long enough.
       The model studied here is very simple, and some of its restrictive assumptions will have to
be relaxed before the promise of the voting scheme can be confirmed. Some needed extensions
are immediate generalizations of this initial model. The importance of the horizon length
suggests allowing for infinite horizon, keeping the analysis tractable, for example, by having
votes expire after a fixed number of periods, or by studying overlapping generations of committee
members with fixed terms. Different information assumptions should be studied - what if
opponents’ preferences are known? What if at least their signs, if not their intensities, are
known? In most applications, correlation among preferences should be allowed, either over time
or across voters.
       Other extensions require introducing new issues. How robust are the results to
endogenous agenda? Because storable votes derive their value from intertemporal planning,
influencing the order in which votes will be called ought to be very important. An individual or a
group controlling the agenda might be able, for example, to exhaust opponents’ votes before an
issue he considers crucial is decided. But the opposite could be argued too - the ability to shift
votes intertemporally provides everybody with more flexibility and might in fact neutralize the
                                                                                                    29

advantage enjoyed by those who set the agenda.
       A related if different question is the impact of storable votes on minorities. Advocates of
cumulative voting, the static counterpart of storable votes, have stressed their potential for
increasing the power of minorities (Guinier, 1994), an observation confirmed at least partially by
formal and experimental analyses (Cox, 1990, Gerber, Morton and Rietz, 1998). Others have
expressed concern that when voting is costly the voters most likely to express their votes might be
those with most extreme preferences (Campbell, 1999, Osborne, Rosenthal and Turner, 2000).
Would decisions be dominated by extremists? What would the welfare implications be then?
Notice that the outcome is not obvious: when votes are storable, the cost of voting is endogenous
and the majority can control a small minority at relatively low cost, if the coordination problem is
not too severe.
       Finally, we have maintained the assumption that aggregating voters’ preferences is made
difficult by their divergence. Alternatively, we could model the voting problem as a common
value problem: voters have the same preferences but receive different signals about the optimal
choice (for example Feddersen and Pesendorfer, 1997, Piketty, 1999). Piketty (1994) has argued
that in this case market-type mechanisms applied to voting, in particular spot markets for votes,
are less efficient than simple majority voting, because they induce abstentions and thus reduce the
amount of information transmitted through voting. To what extent would this argument apply to
storable votes? What if both private and common values are present?
       These questions are important and difficult, and will need to be addressed. For now, we
can only conclude by stating once more that storable votes are not the most efficient mechanism
theoretically possible. But they are very simple, could realistically be implemented and appear to
take us part of the way towards efficiency without violating our ethical priors. They deserve
more study.
                                                                                                        30

                                             APPENDIX


Proof of Proposition 2. i) Existence. Formally, we are looking for a perfect Bayesian
equilibrium of a multi-stage game. An important simplification is that players’ types are i.i.d.
across different periods: the game has no updating of information on players’ types, and if we
restrict our focus to Markov strategies the only intertemporal link across periods is the evolution
of the state variable - the accumulation or depletion of the votes’ stock (which is common
knowledge). It follows that we can find a perfect equilibrium by backward induction. In period
T, the dominant strategy is to cast all remaining votes. In period T-1, given the state KT-1 the
continuation value of the game depends only on the strategies at T-1 (and on the expected value
of |FT | / 2W, an exogenous parameter); the one-period payoff depends on the realization of one’s
own type Fi,T-1 , and on the strategies at T-1; thus, given the state, the total payoff of the game at T-
1, EUT-1 (vT-1; Fi,T-1 ,KT-1 ), depends only on current strategies. We can study the game at T-1 as a
one-stage simultaneous move game. Notice that the game satisfies a number of conditions: (i) j’s
type does not enter i’s payoff directly (j’s strategy does); (ii) players’ types are independently
distributed; (iii) F(F) is assumed to be continuous and atomless; (iv) for each player, the
strategies’ space is finite. By using the notion of distributional strategies - joint distributions on
actions and types - Milgrom and Weber (1985) have shown that these conditions guarantee that
an equilibrium exists, and that all equilibrium strategies are empirically indistinguishable from
pure strategies. (See also Fudenberg and Tirole, 1992, section 6.8). But if the game at T-1 has an
equilibrium, then equilibrium strategies at T-1 can be anticipated, as function of the types’
realizations and the state at T-1. Again, expected types’ realizations are exogenous and KT-1 is
determined completely by state and strategies at T-2. Hence, given Fi,T-2 and KT-2, we can study
the game at T-2 as a one-stage game and rely once more on Milgrom and Weber’s result. With a
finite horizon T, the complete game has a finite number of stages and states, and using backward
induction we can replicate the procedure for each of them. #


ii) Monotonicity. Suppose Fi t > 0. When casting v votes, player i’s expected utility at t is given
by: Fi t prob(dt=1*vti =v)+*EVt+1 (kti -v +1,ktj -vtj +1), where prob(dt=1*vti =v) = [prob(vtj<v) +
3/4 prob(vtj=v) + ½ prob(vtj >v)]. Notice that prob(dt=1*vti =v+1) - prob(dt=1*vti =v) = 1/4
                                                                                                          31

[prob(vtj=v)+prob(vtj=v+1)]$0: as expected prob(dt=1*vti =v) is monotonically increasing in v.
Call v’ (v”) the equilibrium number of votes cast by player i when Fi t = F’ (F”) (with F’>F” >0
). By definition of equilibrium, the following two inequalities must hold:

       σ ' prob(d t = 1 v ') + δEVt +1 ( kti − v '+ 1, k t j − v j + 1) ≥
                                   σ ' prob(d t = 1 v ' ') + δEVt +1 ( k ti − v ' '+ 1, kt j − v j + 1)


       σ" prob(d t = 1 v") + δEVt +1 ( kti − v"+ 1, kt j − v j + 1) ≥
                                   σ" prob(d t = 1 v ') + δEVt +1 ( kti − v '+ 1, k t j − v j + 1)
Adding the two inequalities, we obtain:

      (σ '− σ ' ' )[ prob(d t = 1 v ' ) − prob( d t = 1 v ' ' )] ≥ 0

But with F’ > F” and prob(dt=1*v) monotonically increasing in v, this implies v’ $v”,
establishing the result. The logic is identical, with the appropriate sign changes, for Fi t < 0
Notice that the proof holds for any strategy chosen by j, implying that all best response functions
must be monotonically increasing, a stronger result than stated in the Proposition. #


Proof of Lemma 1. Begin by proving part i) for symmetrical states. Recall that expected one-
period equilibrium payoff is given by (13), reflecting the optimal thresholds chosen by the voters.
Define a function Q("v, ....., "k), representing (fictional) expected payoff when thresholds "1
,...,"v-1 are set to zero, and all other thresholds are kept at their equilibrium values (and where to
simplify notation we ignore the time subscript). By construction Q("1, ....., "k) = Eg(k,k). We
can show that the following two conditions hold:

     a ) Ψ (αk ) ≥ W
     b) Ψ (αv ,...., αk ) ≥ Ψ (αv +1 ,...., αk )
To establish a), notice that given (12) and the definition of Q("k ), we can write:
                                    αk                                    1

                        Ψ (αk ) ≡    ∫ σdF (σ)(F (α ) − 1 / 2) + ∫ σdF (σ) F (α )
                                     0
                                                         k
                                                                         ak
                                                                                             k




where "k 0 [0,1]. At "k = 0 or "k = 1, Q("k ) = W; in addition it is easy to verify that MQ("k )/M"k
is positive at "k = 0 and has a single root in the interval "k 0 (0,1]. Hence Q("k ) > W œ "k 0 (0,1)
                                                                                                                   32

and Q("k ) = W if "k = 0 or 1. But from (12) we also know:

Ψ (αv ,..., αk ) ≥ Ψ (αv +1 ,..., αk ) ⇔
αv                             α v +1                                         α v +1
                                                                                                                 (A1)
 ∫ σdF (σ )(F (α ) − 1 / 2) + α∫ σdF (σ )(F (α ) + F (α
 0
                  v                               v         v +1   ) − 1) ≥    ∫ σdF (σ )(F (α
                                                                                0
                                                                                             v +1   ) − 1 / 2)
                                  v



The left-hand side of (A1) is identical to the right-hand side if "v = 0 or "v = "v+1. At "v = 0, the
left-hand side is increasing in "v and again it can easily be shown that the derivative has a single
root. Hence Q("v, ....., "k) > Q("v+1, ....., "k) œ "v 0 (0,"v+1) and Q("v, ....., "k) = Q("v+1, ....., "k)
for "v = 0 or "v = "v+1, and b) is established.
        Finally, it follows that a) and b) can both hold with equality only if all thresholds are
either 0 or 1 or if there exist an "v and "v+1 such that "1 = ...= "v = 0 and "v+1 =...= "k = 1, with v
0{1,...,k-1}, i.e. only if the same strategy is followed for all realizations of Fi. If at least one
threshold is strictly between 0 and 1, then the inequality in part i) of Lemma 1 is strict. We
expect that to be the case in all symmetrical states, but it is particularly easy, and sufficient for
our purposes, to show that this must be true at T-1. Suppose both players are endowed with k
votes at T-1. We show that casting v votes for all realizations of Fi cannot be an equilibrium.
Given FiT-1, which we suppose positive for simplicity, the expected utility of voter i casting v
votes is given by: EU iT-1(v)=FiT-1 [prob(vtj<v)+3/4 prob(vtj=v) + ½ prob(vtj >v)] + *W
[prob(vtj=v)+2prob(vtj >v)]. It is easy to establish then that:


         EU iT-1(v’+1)-EU iT-1(v’)=(FiT-1 /4 - *W) [prob(vtj=v’+1) + prob(vtj =v’)]
          EU iT-1(v’)-EU iT-1(v’-1)=(FiT-1 /4 - *W) [prob(vtj=v’) + prob(vtj =v’-1)]


Recall that 4*W 0 (0,1). Take any v’ such that prob(vtj=v’)>0. It is immediate to show that if Fi
< 4*W, then player i must prefer v’-1 to v’, and if Fi > 4*W he must prefer v’+1 to v. If v’ equals
0 or k only one direction of deviation is feasible, but in all cases no v can be the equilibrium
strategy for all Fi. Part i) of lemma 1 is established.#
        ii) To establish part ii) of the lemma for asymmetrical states, we follow the same logic.
Suppose s > k, and denote {(1 ,(2 ,...,(k+1 } the equilibrium thresholds for the player holding s
votes at t, and {$1 ,$2 , ...,$k} the equilibrium thresholds for the player holding k votes (where,
                                                                                                                                       33

again, to simplify notation time subscripts are omitted). Notice that the player holding s votes
will never cast more than k+1. We can write:
                                            β1                              β2

Eg ( k , s ) + Eg ( s , k ) = ∫ σdF (σ )( F (γ 1 ) − 1 / 2) + ∫ σdF (σ )( F (γ 1 ) + F (γ 2 ) − 1)+ ..
    i            i     j       i   i   j

                                             0                              β1
            1                                           γ1                                  γ2

 ...+ ∫ σdF (σ )( F (γ k ) + F (γ k +1 ) − 1) + ∫ σdF (σ )( F ( β1 ) − 1 / 2) + ∫ σdF (σ )( F ( β1 ) + F ( β2 ) − 1)+ ....
        βk                                               0                                  γ1
        γ v +1                                                γ k +1                        1

 ...+ ∫ σdF (σ )( F ( βv ) + F ( βv +1 ) − 1)+ .....+ ∫ σdF (σ )( F ( βk )) +              ∫ σdF (σ)                          (A2)
            γv                                                 γk                         γ k +1



Define a function Q($1,...,$v ,(1,..,(v+1 ), representing the (fictional) sum of expected payoffs in
(A2) when thresholds $v+1,...,$k-1,(v+2,..,(k+1 are set to 1 (which is now more convenient than
setting the omitted thresholds to 0), and all other thresholds are kept at their equilibrium values.
By construction, Q($1,..,$k ,(1,..,(k+1) / Egi (si,k j)+Egi (ki,s j). As in the symmetrical case, we
proceed by first evaluating the function Q at the smallest threshold and then adding successively
higher ones. We can show that the following three conditions hold:

        a)            Ψ (γ 1 ) ≥ 2W ; Ψ ( β1 ) ≥ 2W
        b)            Ψ (γ 1 , β1 ) ≥ Ψ (γ 1 ); Ψ (γ 1 , β1 ) ≥ Ψ ( β1 )
        c) (i) Ψ ( β1 ,..., βv +1 , γ 1 ,...,γ m ) ≥ Ψ ( β1 ,..., βv , γ 1 ,..., γ m ) where either βv +1 > γ m or γ m = 1
                     (ii) Ψ ( β1 ,..., βv , γ 1 ,..., γ m+1 ) ≥ Ψ ( β1 , ..., βv , γ 1 ,..., γ m ) where either γ m+1 > βv or βv = 1
        .
To verify a), notice that given (A2) we can write:
                               1                             γ1                  1

                     Ψ (γ 1 ) ≡ ∫ σdF (σ )( F (γ 1 ) − 1 / 2) + ∫ σdF (σ )1 / 2 + ∫ σdF (σ )
                               0                              0                  γ1




Differentiating Q((1) with respect to (1, it is easy to see that Q((1) > 2W œ(1 0 (0,1) and Q((1) =
2W if (1 = 0 or 1. The same reasoning, and a corresponding equation, establish Q($1)$ 2W.
To verify b), notice that from (A2) we also know:

                                                 1                                   β1

                     Ψ ( β1 , γ 1 ) ≥ Ψ (γ 1 ) ⇔ ∫ σdF (σ )(F ( β1 ) − 1 / 2) ≥ ∫ σdF (σ )1 / 2
                                                 01                                   0


an inequality that holds strictly for all $1 0 (0,1), and weakly at $1 = 0 or1. Again an equivalent
                                                                                                                                            34

condition establishes Q($1,(1) $Q($1).
Finally, to verify c), consider case (i) first. We can derive from (A2):

           Ψ( β1 ,..., βv +1 , γ 1 ,..., γ m ) ≥ Ψ( β1 ,..., βv , γ 1 ,..., γ m ) ⇔
                                        1                                             γ v +2
                                                                                                                                     (A3)
                                        ∫      σdF (σ )(F (γ v+2 ) − F (γ v )) + ∫ σdF (σ )(F ( βv +1 ) − 1) ≥ 0
                                       βv +1                                           γv

where (v+2 # (m and hence either (v+2 # $v+1 or (v+2 =1 (and similarly either (v # $v+1 or (v =1,
where (v # (v+2 ). At (v+2 =1, the inequality in (A3) becomes:
               1                                         1

              ∫      σdF (σ )(1 − F (γ v )) − ∫ σdF (σ )(1 − F ( βv +1 )) ≥ 0
             βv +1                                       γv
a condition that is satisfied for all (v # $v+1 or at (v =1. If (v+2 …1, notice that (A3) holds with
equality at (v+2 = (v and becomes:
                1                                                    βv +1

               ∫ σdF (σ)(F (β
              βv +1
                                            v +1   ) − F (γ v )) −    ∫ σdF (σ)(1 − F (β )) ≥ 0
                                                                     γv
                                                                                               v +1




at (v+2 = $v+1, an inequality that is satisfied for all $v+1 $(v. But differentiating (A3) with respect
to (v+2, we can easily establish that for all $v+1 < 1 the derivative has a unique root which must be
a maximum. Hence if the inequality is satisfied at (v+2 = (v and at (v+2 = $v+1 , it must be satisfied
everywhere. For $v+1 = 1, (A3) equals 0 for any (v+2 , (v. We conclude that condition b) (i) is
established. The proof of condition b) (ii) proceeds identically, and we leave it to the reader. #


Proof of Lemma 2. Once again, we proceed in two steps. First, we consider symmetrical states
and show that if the conditions in Lemma 2 hold, then EVt i(kt ,kt ) > Wt i(k,k). Then we prove the
corresponding result for asymmetrical states. What follows could be written in matrix form, but
the expanded notation, though cumbersome, is more transparent and is maintained here.
       Consider state (kt , kt ). We can write:
   EVt ( kt , kt ) = Egt i ( kt , k t ) + δ
      i



                         (
                   [ pi 0 p j 0 EVt +1i ( k t + 1, kt + 1) + p j1 EVt +1i ( k t + 1, kt ) + ....+ p jk EVt +1i ( k t + 11
                                                                                                                        ,) +     )
                             (                                                                                     )
                     + pi1 p j 0 EVt +1i ( k t , kt + 1) + p j1 EVt +1i ( kt , k t ) + ....+ p jk EVt +1i ( k t ,1) + ... ....

                                                   (
                     ..................+ pik p j 0 EVt +1i (1, kt + 1) + p j1 EVt +1i (1, k t ) + ....+ p jk EVt +1i (11
                                                                                                                       ,)]       )
                                                                                                                                                     35

or, more compactly:

                                                   k        k                                               
   EVt i ( k t , k t ) = Eg t i ( k t , k t ) + δ  ∑ pivi  ∑ p jv j EVt +1i ( k t − v i + 1, k t − v j + 1                              (A4)
                                                   vi = 0  v j =0                                           


where pjv is the probability that *Fj t* falls into the interval that corresponds to j’s optimal strategy
v. But the game is symmetric, and starting from the symmetrical state (kt , kt ), piv = pjv for all v.
We can thus collect terms and rewrite (A4) as:


   EVt i ( k t i , k t j ) = Eg t i ( k t , k t ) + δ
                k −1
                          k
                                                                                                    
               [ ∑  piv ∑ p jr ( EVt +1i ( k − v + 1, k − r + 1) + EVt +1i ( k − r + 1, k − v + 1)) +
                 v =0  r = v +1                                                                                                              (A5)
                 k
              + ∑ piv p jv EVt +1i ( k − v + 1, k − v + 1)]
                v =0

Substituting the conditions stated in Lemma 2, we then obtain:
                                                      k −1 k            k
                                                                                  
    EVt ( k t , k t ) > Eg t ( k t , k t ) + δ Wt +1  2∑ ∑ piv p jr + ∑ piv p jv 
          i                       i

                                                      v =0 r =v +1    v =0       

Once again using piv pjr = pir pjv, it is not difficult to verify that the probabilities, which span all
possible equilibrium strategies, sum up to 1. Hence :

                       EVt i ( k t , k t ) > Eg t i ( k t , k t ) + δ Wt +1

But we know by Lemma 1 that Egt i(kt ,kt ) $ W. Hence EVt i (kt , kt ) > Wt (k, k), and the first part of
Lemma 2 is established.
         The logic of the proof is identical in the asymmetrical state (st i, kt j). We can write:




    EVt i ( st i , k t j ) + EVt i ( k t i , st j ) = Eg t i ( st i , k t j ) + Eg t i ( k t i , st j ) + δ
                        (
    [ pi 0 ( st i , k t j ) p j 0 ( st i , k t j ) EVt +1i ( st i + 1, k t j + 1) + ....+ p jk ( st i , k t j ) EVt +1i ( st i + 11  )
                                                                                                                                  , ) + ..

                            (                                                                                           )
                                                                                                                    , ) ]+ δ
    ...+ pis ( st i , k t j ) p j 0 ( st i , k t j ) EVt +1i (1, k t j + 1) + ....+ p jk ( st i , k t j ) EVt +1i (11                         (A6)

                        (
    [ pi 0 ( k t i , st j ) p j 0 ( k t i , st j ) EVt +1i ( k t i + 1, st j + 1) + ....+ p js ( k t i , st j ) EVt +1i ( k t i + 11 )
                                                                                                                                   , ) + ..

                            (
    ...+ pik ( k t i , st j ) p j 0 ( k t i , st j ) EVt +1i (1, st j + 1) + ....+ p js ( k t i , st j ) EVt +1i (11
                                                                                                                   ,)]  )
                                                                                                                                               36




          As always, the probability that a given strategy is chosen by either player is a function of
the state; and since we are considering two different states this dependence is recognized
explicitly. Using piv (st i, kt j) = pjv (kt i, st j) œv,s,k,t, we can simplify (A6):


EVt i ( st i , k t j ) + EVt i ( k t i , st j ) = Eg t i ( st i , k t j ) + Eg t i ( k t i , st j ) + δ
                        k
[ pi 0 ( st , k t ) ∑ p jv ( st i , k t j )( EVt +1i ( st i + 1, k t j − v + 1) + EVt +1i ( k ti − v + 1, st j + 1))+ ..
          i       j

                       v =0
                                                                                                                                        (A7)
                              k
...+ pis ( st i , k t j ) ∑ p jv ( st i , k t j )( EVt +1i (1, k t j − v + 1) + EVt +1i ( k ti − v + 11
                                                                                                      , ))]
                            v =0



More compactly, we can write:

          EVt i ( st i , kt j ) + EVt i ( kt i , st j ) = Egt i ( st i , kt j ) + Egt i ( kt i , st j ) + δ
              s         k

          ∑ p ∑ p (EV                          ( st i − r + 1, k t j − v + 1) + EVt +1i ( k ti − v + 1, st j − r + 1))
                                           i                                                                                            (A8)
                  ir              jv   t +1
          r =0         v =0




(All probabilities are now conditional on the same state, and in absence of ambiguity the notation
is simplified). Substituting the conditions in Lemma 2, we then derive:
                                                                                                               s      k
    EVt i ( st i , kt j ) + EVt i ( kt i , st j ) ≥ Egt i ( st i , kt j ) + Egt i ( kt i , st j ) + 2δWt +1 ∑        ∑p     ir   p jv
                                                                                                              r =0   v =0

It is easy to verify that the probabilities sum up to 1. Hence:

      EVt i ( st i , k t j ) + EVt i ( k t i , st j ) ≥ ( Eg t i ( st i , k t j ) + δWt +1 ) +
                                                                           + ( Eg t i ( k t i , st j ) + δWt +1 )

But by Lemma 1, the second part of Lemma 2 is then established.#
Derivation of Figure 2: When every voter casts 1 vote, the probability of obtaining one’s
preferred decision equals the probability that at least (n-1)/2 other members agree, if n is odd; and
the probability that either n/2 other members agree, or that exactly (n/2)-1 do and the tie-break is
favorable, if n is even. Or:
                                                                                                                                        37
                                                      n−1 
                                                 n −1          
                               1 / 2 1 + (1 / 2)  n − 2 + I n  
                                                                             In/1 for n odd, and 0 for n even.
                                                      2       

When voter i alone controls 2 votes, he needs the agreement of at least (n/2)+1 others if n is even,
and of at least (n-1)/2 or exactly (n-3)/2 plus a favorable tie-break, if n is odd. The probability of
i’s preferred outcome is then:
                                         n−1                                                          n−1      
                    1 / 2 + (1 / 2) n −1                                                          n −1     2n 
                                           n − 2        for n even;              1 / 2 1 + (1 / 2)  n − 3            for n odd.
                                                                                                               n − 1
                                         2                                                          2       


It is not difficult to see that the probability of winning goes from 3/4 to 7/8 when n is3, a
percentage increase of 1/6; and from 11/16 to 13/16 when n is 5, a percentage increase of 2/11.


Derivation of Figure 3: When votes are storable and all players can either cast 1 vote or abstain,
the probability of obtaining one’s preferred outcome when voting equals:

                                                                 x 
             n −1
                                      n − 1                  x         
             ∑p      x
                     1   pn − x −1
                          0          
                                      x 
                                             1 / 2 1 + (1 / 2)  x − I x   
                                                    
                                                                                         Ix/1 for x odd, and 0 for x even.
             x =0
                                                                2   

The corresponding probability when abstaining equals:
                                                                  x  n − x − 1 
  n −1
                         n − 1                            n −1                  
  ∑p     x
         1
             n − x −1
             p
             0          
                         x 
                                1 / 2 1 + (1 − I x )(1 / 2)  x   n − x − 2 + I n   
                                       
                                                                                                       In/1 for n odd, and 0 for n even.
  x =0
                                                                 2      2          

As stated in Lemma 3, the probabilities p1 (n) and p0(n) continue to depend on a threshold "(n)
such that p1(n) = 2[1-F("(n))] and p0(n) = 2[F("(n))-1/2]. On the basis of these equations, it is
possible to derive expected payoffs and the expected value of the game.
                                                                                               38

                                         REFERENCES


Athey, Susan and Kyle Bagwell, 1999, “Optimal Collusion with Private Information”, mimeo,
Columbia University.

Atkeson, Andrew and Robert E. Lucas, 1992, “On Efficient Distribution with Private
Information”, The Review of Economic Studies, 59, 427-453.

Börgers, Tilman, 2001, “Costly Voting”, mimeo, University College London.

Brams, Steven, 1975, Game Theory and Politics, New York: Free Press.

Brams, Steven and William H. Riker, 1973, “The Paradox of Vote Trading”, American Political
Science Review, 67, 1235-1247.

Buchanan, James M. and Gordon Tullock, 1962, The Calculus of Consent, Ann Arbor: University
of Michigan Press.

Campbell, Colin, M., 1999, “Large Electorates and Decisive Majorities”, Journal of Political
Economy, 107, 1199-1217.

Casella, Alessandra and Andrew Gelman, in progress, “Storable Votes for Referenda”, mimeo,
Columbia University.

Coleman, James, 1966, “The Possibility of a Social Welfare Function”, American Economic
Review, 56, 1105-1122.

Cox, Gary W., 1990, “Centripetal and Centrifugal Incentives in Electoral Systems”, American
Journal of Political Science, 34, 903-935.

Dixit, Avinash, Gene M. Grossman and Faruk Gul, 2000, “A Theory of Political Compromise”,
Journal of Political Economy, 108, 531-568.

Dodgson, Charles,1884, The Principles of Parliamentary Representation, London: Harrison
and Sons (Supplement, 1885).

Feddersen, Timothy and Wolfgang Pesendorfer, 1997, “Voting Behavior and Information
Aggregation in Elections with Private Information”, Econometrica, 65, 1029-1058.

Ferejohn, John, 1974, “Sour Notes on the Theory of Vote Trading”, mimeo, California Institute of
Technology.

Fudenberg, Drew and Jean Tirole, 1992, Game Theory, Cambridge, Ma: The MIT Press.
                                                                                            39

Gerber, Elizabeth, Morton, Rebecca and Thomas Rietz, 1998, “Minority Representation in
Multimember Districts”, American Political Science Review, 92, 127-144.

Guinier, Lani, 1994, The Tyranny of the Majority, NewYork: Free Press.

Milgrom, Paul R. and Robert J. Weber, 1985, “Distributional Strategies for Games with
Incomplete Information”, Mathematics of Operations Research, 10, 619-632.

Moulin, Hervé, 1979, “Dominance Solvable Voting Schemes”, Econometrica, 47, 1337-1352

Moulin, Hervé, 1982, “Voting with Proportional Veto Power”, Econometrica, 50, 145-162.

Mueller, Dennis C., 1978, “Voting by Veto”, Journal of Public Economics, 10, 57-75.

Mueller, Dennis C., 1989, Public Choice II, Cambridge: Cambridge University Press.

Oleszek, Walter, 2001, Congressional Procedures and the Policy Process, Washington: CQ Press,
Fifth edition.

Osborne, Martin, Rosenthal, Jeffrey and Matthew Turner, 2000, “Meetings with Costly
Participation”, American Economic Review, 90, 927-943.

Phelan, Christopher and Robert M. Townsend, 1991, “Computing Multi-Period, Information-
Constrained Optima”, Review of Economic Studies, 58, 853-881.

Philipson, Tomas and James Snyder, 1996, “Equilibrium and Efficiency in an Organized Vote
Market”, Public Choice, 89, 245-265.

Piketty, Thomas, 1994, “Information Aggregation through Voting and Vote-Trading, mimeo,
MIT, April.

Piketty, Thomas, 1999, “The Information Aggregation Approach to Political Institutions”,
European Economic Review, 43, 791-800.

Sawyer, Jack and Duncan MacRae, 1962, “Game Theory and Cumulative Voting in Illinois: 1902-
1954", American Political Science Review, 56, 936-946.

Townsend, Robert M., 1982, “Optimal Multi-period Contracts and the Gain from Enduring
Relationships under Private Information”, Journal of Political Economy, 90, 1166-1186.
            Figure 1



        2 players, 2 periods
    Acceptable thresholds range
           F(F) Uniform




"




                                  $
                                            Figure 2



                                     One period game.
                              The marginal value of an extra vote




Percentage increase in the probability of obtaining the desired outcome from holding 2 votes when
everybody else has a single one, as function of the total number of voters.
     Figure 3



2 periods, n players
F(F )Uniform; *=1
                  Figure 4



             3 players, 2 periods.
             F(F )Uniform; *=1




EVT-1/WT-1
                        Figure 5


                   3 players, T periods
                     F(F) Beta; *=1


EV0/W0




                                       1
  Beta distribution: f (σ ) =   1                   (1 − σ 2 )b−1
                                ∫ (1 − σ
                                −1
                                           2 b −1
                                            ) dσ
