                   NBER WORKING PAPERS SERIES




                    DYNAMIC (S,s) ECONOMIES




                      Ricardo J. Caballero

                      Eduardo M.R.A. Engel




                    Working Paper No. 3734




              NATIONAL BUREAU OF ECONOMIC RESEARCH
                    1050 Massachusetts Avenue
                       Cambridge, MA 02138
                            June 1991




This paper is part of NEER's research program in Economic
Fluctuations. Any opinions expressed are those of the authors
and not those of the National Bureau of Economic Research.
                                       NBER Working Paper #3734
                                       June 1991



                    DYNAMIC (S,s) ECONOMIES



                            ABSTRACT

    In  this paper we provide a framework to study the aggregate
dynamic behavior of an economy where individual units follow (S.
s) policies. We characterize structural and stochastic
heterogeneities that ensure convergence of the economy's
aggregate to that of its frictionless counterpart, determine the
speed at which convergence takes place, and describe the
transitional dynamics of this economy. In particular, we
consider a dynamic economy where agents differ in their initial
positions within their bands and face both stochastic and
structural heterogeneity; where the former refers to the presence
of (unit specific) idiosyncratic shocks, and the latter to
differences in the widths of units' (S,s) bands and their
response to aggregate shocks. We study the evolution of the
economy's aggregate and the evolution of the difference between
this aggregate and that of an economy without macroeconomic
friction, where the latter pertains to a situation where
individual units adjust with no delay to all shocks. We also
examine the sensitivity of this difference to conmion shocks. For
example, in the retail inventory problem the aggregate deviation
and sensitivity to common shocks correspond to the aggregate
inventory level and its sensitivity to aggregate demand shocks,
respectively.


Ricardo J. Caballero                    Eduardo.M.R.A. Engel
Department of Economics                 Department of Economics
Columbia University                     M.I.T.
New York, NY 10027                      Cambridge, MA 02139
     and
NEER
                                     1 INTRODUCTION

     In recent years there has been a surge in the application of formal microecononhic
 models of discontinuous and lumpy adjustment —originally developed in the early 50's
 for retail inventories— to a variety of topics in economics, such as cash balances, labor
 demand, investment, entry and exit, prices, durable goods and technology upgrade. Yet the
 possibility of explaining aggregate economic phenomena based on these models has remained
 largely unexplored, primarily because of the technical difficulties involved. Since aggregate
 data do not look as discontinuous and lumpy as their microeconomic counterparts, in order
 to apply these models to macroeconomic data aggregation has to be modeled explicitly.
This is hard to do when shocks are not purely idiosyncratic but also have a common (or,
equivalently, aggregate) component. The few results existent in the literature have provided
important insights, but have been limited either to numerical simulations (Blinder 1981)
or to steady state analysis (Caplin 1985, Caplin and Spulber 1987).2 This paper's main
contribution is to provide a framework within which the out—of—steady—state aggregate
dynamics of an economy with lumpy adjustment at the microeconomic level can be studied
analytically.
    We simplify the mathematics substantially by only considering a particular, but widely
used, adjustment policy: the one sided (S,s) rule. In the last section we argue that many
of this paper's insights either carry over directly to more general forms of adjustment rules
or provide the natural foundation for their study.
    One of the appealing characteristics of (S, i) rules is their simplicity: an individual agent
allows his state variable (e.g. inventories) to fall freely until it reaches a certain critical level
s; at this point abrupt action takes place and the state variable is reset to an upper value S
from where the cycle starts again. Examples where the optiinality of fixed (S,s) rules has
been established go back to the problem of inventories management (Scarf, 1959); a more
recent example is price setting in the presence of menu—costs (Sheshinski and Weiss, 1983;
Caplin and Sheshinski, 1987). Moreover, the fixed (S,s) model has also been extensively
used in the Operations Research and Economics literatures as an approximation for more
complex optimal rules (e.g. Arrow, harris and Marschal, 1951; Karlin and Fabens, 1959;

                                                 I
 Blinder, 1981; Ehrhardt, Schultz and Wagner, 1981; Blanchard and Fischer, 1989, p.405).
     Whenever microeconomic units adjust discretely and by large amounts, the issue of het-
 erogeneity acquires high priority. The similarity between the economy's aggregate patti and
 the discontinuous and lumpy path of microeconomic units grows with the degree of synchro-
 nization of units' actions. In the limit, when all units are identical and act simultaneously
 (the symmetric equilibria assumption), the aggregate path is indistinguishable from that
 of an individual unit. On the other hand, if units' actions exhibit little synchronization,
 the aggregate may depart substantially from the behavior of any single (representative)
 unit. The framework developed in this paper addresses precisely the process of endogenous
 synchronization and staggering of individual units, and studies the aggregate implications
 of such phenomena.
    We consider a dynamic economy where agents differ in their initial positions within their
 bands and face both stochastic and struclural heterogeneity; where the former refers to the
presence of (unit specific) idiosyncratic shocks, and the latter to differences in the widths
of units' (5, s) bands and their response to aggregate shocks. We study the evolution of the
economy's aggregate and the evolution of the difference between this aggregate and that of
an economy without microeconomic friction, where the latter pertains to a situation where
individual units adjust with no delay to all shocks. We also examine the sensitivity of this
difference to common shocks. For example, in the retail inventory problem the aggregate
deviation and sensitivity to common shocks correspond to the aggregate inventory level and
its sensitivity to aggregate demand shocks, respectively.
   In Section 2 we determine conditions under which the inicroeconomic effect of lumpy
adjustment rules has no aggregate impact. Section 3 begins the study of the economy's
aggregate (out—of--steady--state) dynamics by discussing the summary variables we use to
describe the economy over time. In Section 4 we consider the effect of stochastic het-
erogeneity on the economy's dynamic aggregate behavior when no structural differences
are present. We show that the economy's aggregate converges to that of its counterpart
without friction when idiosyncratic shocks spread out without bound over time, and that
the speed of convergence increases with the rate at which dispersion occurs; we also show
that common shocks play no role in aiding convergence. Structural heterogeneity is incor-
porated into the analysis in Section 5; we show that it can lead to convergence by itself,
that the speed ofconvergence grows with the degree of structural heterogeneity, and that
common shocks aid convergence when structural differences are present. Section 6 shows


                                             2
that, paradoxically, the interaction between both krms of heterogeneity may actually slow
down convergence. Section 7 presents final remarks. An extensive appendix follows.


                      2 BASIC MODEL AND STEADY STATE

      We consider an economy composed of a large number of units, and approximate this
large number by a continuum, indexed by i E [0, 1]. We let z) denote the difference
between x(i), the actual value of unit I'S state variable at time i when an (S, s) policy is
followed, and x(t), the value of the same variable if there was no friction. For example,
consider the retail inventory problem, where firms decide on their optimal inventory holding
in the presence of uncertain demand and fixed replenishment costs. In this case z'(t) and
        are accumulated sales and accumulated inventory orders, and z1() is the level of
inventories.
      We express every frictionless (optimal) variable, x(t), as the sum of an idiosyncratic
component, v(t), and the unit's response to an aggregate shock a(t) fx(t)di:

(1)                                 x(t) = Oa() + v,(t),

where 9 is unit i's sensitivity to the common shock.3 For example, in the retail inventory
problem da(t) denotes aggregate demand shocks and 6 the sensitivity of sector i's demand
to these shocks. We normalize the sensitivity parameters so that f 9 di = 1; this implies
that by construction f v,(i) di = 0 for all t.
      We assume that, for each unit i, z(t) decreases monotonically and continuously until
it reaches the unit specific trigger barrier, sj; at this point finite control is exerted on x to
bring zj back to the unit specific target barrier S1.4

ASSUMPTION 1 . SationariLy, symmeirij, monotonicity and continuity.

   1. The variable zj(t) is controlled according to a stationary, fixed band, one sided, unit
       specific (5, a) policy.

   2. The (S,s) rules are symmetric: S1 =

  3. The variable z1(t) decreases monotonically during time periods where no control is
       exerted.6

   4. The sample paths of v(t) are continuous and those of a(t) are continuous, increasing

                                                 3
         and unbounded.

       This framework can accommodate many well known problems, apart from the retail
 inventory problem mentioned above. A few of them are:

       • The Pricing Problem, where firms pay a menu—cost when they adjust their nominal
         prices. In this case x(t) is the frictionless optimal price and x() the actual price
         charged.

       • The Cash—Balance Problem, where consumers decide on the optimal level of cash
         holdings when adjusting their cash—balances is costly. In this case, x(t) and z,()
         are accumulated expenditures and accumulated withdrawals, and z-(t) is the current
         cash balance.

      • The Technology Update Problem, where firms decide on whether to scrap their current
        machines and update them or not. In this case, x(i) and x1(i) are desired and actual
        state of technology, and z1(t) is the gap between them.

      • The Durable Goods Problem, where consumers decide when to buy a durable good
        and adjusting the stock they have is costly. In this case, z(t) and x(i) are desired
        and actual levels of the stock of durable goods, and z1(i) is the gap between them. In
        this problem, the sensitivity parameters could correspond to the marginal propensities
        to consume.

      • The Capital Stock Adjustment Problem, where firms decide when to adjust their
        capital stock when there are non—convex costs of adjustment. In this case, x(i) and
             are desired and actual levels of the stock of capital, and z1(t) is the gap between
        themY

      The main goal of this paper is to examine the behavior of the variable we call "the
aggregate," defined as the integral of the z,()'s over all i's and denoted by X(i). Using
the definition of the z)'s, and letting Z() fJ z,() di, leads to the following expression
for X(i):


(2)                                   X(t) = a(s) + Z(t).
      When there isno microeconomic friction, all the z's are identically zero, thus X() =

X(i) = a(s).        As we are interested the effects of microeconomic (S,s) policies on the

                                               4
departure of X(t) from X(t),      we   focus on the mean of the cross—section distribution of
individual departures, Z(t).8 The entire analysis carried out in this paper —in particular the
computation of the latter mean— is conditional on the actual path of the aggregate shock
a(t). It turns out that the results we derive do not depend on any particular features of
this path, as long as a(t) is continuous, increasing and tends to infinity (see Assumption 1).
We therefore do not need to specify the stochastic mechanism underlying common shocks.
The fact that we consider the dynamic path of the actual cross—section distribution —and
not that of the joint distribution of all units— in spite of the presence of aggregate shocks,
is one of the building blocks of the methodology we develop in this paper. Its usefulness
is best appreciated when we consider convergence issues in Sections 4 and 5. We therefore
postpone discussing its importance until the final section.
      Instead of working directly with z(t), it is notationally convenient to describe the
problem in terms of the fraction unit i has covered of its (S,s) band at time t, c,(t). We
therefore define:
(3)                                    c(i)—,
where A,      S — 8 denotes unit i's bandwith. The variable 4(t) takes values in [0, 1); it
starts its cycle when cQ) = 0 (i.e. when z1(t) = S) and ends it when c,(t) reaches one (i.e.
when zj(t) reaches s,). Substituting z1(t) — x'(t) for z,(t) in (3) yields:

                                       =   (!   —   x5(t) — z(1)
                                                         A1



Substituting x(t) by (1), adding and subtracting cj(0), and noting that (x1(t) — x1(0))/A,
is always an integer, yields:


(4)                        4(t) = (c(o) + 01a(t)+ vi(i)) (mod 1),

where z (mod 1) denotes the difference between the real number x and its integer part and
we set a(0) and v1(O) equal to zero without loss of generality.
      We let Ct, Vj, 0 and A denote random variables with a joint probability distribution
identical to that of the joint cross—section distribution of the c1(i)'s, the v,(t)'s, the O,'s and
the A1's.9 Thus, we have that:


(5)                               =(    + e(t)-1- V) (mod 1).
                                                    5
  An expression for the aggregate deviation, Z(t), can be obtained directly in terms of the
  variables we defined above. All that is needed to determine Z(t) is the value of the current
  aggregate shock, a(t), and the cross—section distribution of the random vector (co,vj,A,O).

  PRoPosITIoN 1       Suppose assumption 1 holds. Then Z(i) = g(a(t),i) and X(t) = a(t) +
 g(a(t),t), where

                      g(a,t)     E(A)—E[A{(co+ °)(mod1)}]
 Paoop: Follows directly from equations (3), (4) and (5). •

    The intermittent and lumpy microeconoinic behavior is irrelevant at the aggregate level

 when —for any realization of the stochastic mechanism underlying aggregate and idiosyn-
 cratic shocks— Z(t) remains constant over time. Without loss of generality we suppose
 that the constant aggregate deviation is equal to zero in what follows.

 DEFINITION 1   The aggregate deviation of an economy satisfying Assumption 1 is at its
 steady state at time I = 0 if g(a,t) = 0 for all a a(0) 0 and all I 0, with g(a,t)
defined in Proposition 1.

    Whether the economy's aggregate deviation is at its steady state or not depends on
the stochastic mechanism underlying the model. There are various sets of conditions under
which the aggregate deviation remains equal to zero as time passes. In this paper we
consider conditions that can be expressed only in terms of the cross—section distributions
defined above. In the following proposition —which is an extension of Proposition 1 in
Caballero and Engel (1989b)— we show that when units' initial positions within their
cycle are distributed uniformly on [0, 1) and independent from the remaining sources of
heterogeneity, the economy's aggregate deviation is at its steady state.


PRoposiTioN 2 (Caballero and Engel, 1989b) Given Assumption I, the economy's aggre-
gate deviation is at its steady state at time I = 0 if c0 is uniform on [0,1) and independent
from A, 0 and vg for all 1> 0. Furthermore, cg is uniform on [0,1) for all t > 0.


   This result shows that when units' positions within their cycle are independent from the
sources of structural and stochastic heterogeneity, there exists a cross—section (or empirical)
distribution of the c's that is invariant under continuous, monotone, aggregate shocks.

                                              6
 This distribution is uniform. It follows —from equation (3)— that there also exists a
 cross—section distribution of the z's that is invariant under the same class of shocks. This
 distribution is determined by the probability distribution of A; it is uniform only when
 bandwidths do not vary across units.
     Proposition 2 presents an economy with strong forms of microeconomic rigidity that has
an aggregate behavior indistinguishable from that of an economy without friction. This is a
generalization of the insightful result in Caplin and Spulber (1987). They consider the case
where all units have the same bandwidth, no idiosyncratic shocks are present, and common
shocks have the same impact on all units' z7(t)'s. None of these conditions are required for
Proposition 2 to hold. In addition, the scenario described in Proposition 2 has a realistic
feature that is absent in an economy without structural or stochastic heterogeneity: the
relative positions of units within their cycle changes over time. The order in which units
adjust their state variable does not repeat itself from one cycle to another.
     Proposition 2 assumes that the initial cross—section distribution of the 4's is independent
from the joint distribution of idiosyncratic shocks, bandwidths and sensitivity parameters.
If this is not the case, the cross-section distribution of the 4's generally does not remain
uniform on [0,1) and the aggregate deviation, Z(t), does not remain constant. This hap-
pens, for example, when units with smaller bandwidths —or larger sensitivity parameters—
are initially concentrated at the beginning of their cyde, as is further illustrated in Section
5.


         3     DESCRIPTION OF NON—STEADY—STATE DYNAMICS

     There are many reasons why Assumption 1 may be momentarily violated and the (5, s)
economy's aggregate deviation be forced away from the steady state described in Proposi-
tion 2. For example, in the case of the pricing problem, a finite (discrete) change in a(i),
like an oil shock or a large monetary shock, bunches a fraction of units at the beginning of
their cycle. Alternatively, a widening of units' bands —due, for example, to an increase in
the rate of core inflation in an economy where bands are set optimally— leaves a fraction
of the new state space initially with no units. In the time period following any one of these
"structural changes," the aggregate deviation ypicaUy does not remain constant and the
economy therefore is not at its steady state anymore.
     In the following three sections we study the dynamic behavior of the economy outside of
its steady state. We consider idiosyncratic shocks and structural heterogeneity as possible

                                               7
  sources of convergence; the latter meaning differences in bandwidths and sensitivity pa-
  rameters. For expository simplicity, we study the effects of these factors separately before
  considering their interaction.

      Proposition 1 characterizes the dynamic path of the difference of the aggregates from
 economies with and without frictions. For example, it can he used to determine the evolu-
 tion of the average level of inventories after an oil shock. Yet we may not only be interested
 in the level of aggregate inventories at a given point in time, but also in the potential im-
 pact of a small aggregate demand shock on this aggregate. This impact on Z(t) is equal
 to the (partial) derivative of the function g —defined in Proposition 1— with respect. to a,
 evaluated at (a(i), t). We denote this derivative by J(t)    Og/i9a.
      The relation between J(t) and the cross—section distribution of firms' positions within
 their cycle is best understood if we look at the effect of a small common shock, 1a, on the
 aggregate deviation, Z(t), when sensitivity parameters do not vary across units (0        1).
 We begin with the units that are forced to start a new cyde. The common shock forces
 a unit with bandwidth A to adjust only if it has covered a fraction larger or equal than
 1—   (Aa/A) of its cycle before the shock. The fraction of units with bandwidth A that
 reach their trigger point is proportional to Aa f(IA,A)(1)/A + O((ia)2),1° where fx(A)
 denotes the density of the random variable X. Other things equal, this fraction is smaller
 the larger the common bandwidth. This effect is exactly offset by the fact that Z(t) grows
more when a unit with a larger bandwidth restarts its cyde. Thus, the contribution to the
• aggregate deviation of those units that a.djust and have bandwidth equal to A is proportional
to 4a.f(C4A=A)(1 )fA(A); the total increase in Z(i) due to units reaching their trigger point
is then equal to a.ff(C11A)(1)fA(A)dA =           a.f4(r). Next we consider those units that
do not start a new cycle alter the aggregate shock. Every unit that does not adjust decreases
its contribution to Z(i) by ia; their total contribution is equal to La (minus a term of
order (ia)2 that accounts for the fact that not all units belong to the group that does not
start a new cycle). We have therefore shown that g/a is equal to f(1) — 1 + O(ta).
Letting a approach zero we conclude that J(t) = f1(1j — 1.
    It is apparent from the previous paragraph and Proposition 1 that both J(t) and Z(t)
may be equal to zero even when the economy's aggregate deviation is "far away" from its
steady state. On the one hand, J() is equal to zero every time f(1) is equal to one;1' on
the other hand, Proposition 1 implies that Z(t) = 0 every time fA E(c A = A)fA(A) dA = 0.
Therefore Z(t) = 0 whenever the weighted average of the "sectoral" aggregates is equal to

                                              8
zero; where the latter are defined as the aggregates conditional on a common bandwidth.
Since these sectoral aggregates may evolve in rather arbitrary ways, there is no reason why
their average should remain equal to zero in the future.
      It is tempting to argue, based on Proposition 2, that the economy's aggregate deviation
is at its steady state every time the cr061—section distribution of units within their cycle,
c, is uniform on [0,1). This intuition is supported by the fact that Z(t) = E{A( — c)}
is equal to zero when c is uniform on [0,1) and independent form A. Yet this argument is
not correct, since c is generally not independent from A. For example, consider the case
where a fraction of units is bunched at the beginning of their cycle after the economy is
perturbed away from its steady state. Other things equal, units with larger bandwidths
move a smaller fraction of their cyde in a given period of time, so that the correlation
between A and c is negative in the time period following the perturbation. We conclude
that although Z(t), J(t) and the shape of the cross—section distribution of units positions
within their cycle are interesting summary variables of the economy's aggregate deviation
at any particular instant in time, neither of them has the property of capturing how much
the economy's aggregate behavior differs from that of its counterpart without frictions.
Next we consider two indices that do have this property:


                                     E SUP(a>a(t),a>f} g(a,s)

and

                              J(t) E
The definition of these indices is now illustrated by describing how one of them, Z(t), is
evaluated at a given instant in time, to. Suppose that accumulated common shocks at time
to are equal to o• Consider all possible future paths of the aggregate shock, {a(s), s
that satisfy Assumption 1 and have a(io) = ao, and calculate the maximum (absolute)
aggregate deviation for every one of them. The index Z(t) then is equal to the largest
among these maxima. The aggregate deviation and its sensitivity to small aggregate shocks
have (absolute) values that are bounded from above by Z(i) and J) for any future
trajectory of the common shock that satisfies Assumption j•12
   Once  the economy's aggregate deviation departs from the steady state, it typically
never exactly retuTas there. There usually is no instant in time at which the economy's
aggregate deviation has actually reached its steady state again (in the sense of Definition 1).


                                              9
  This implies that there always exists the possibility that the aggregate deviation's sensitivity
  to common shocks, J(t), be relatively large at some instants in time, even if Z(i) converges
  to zero. The aggregate effect of microeconomic frictions is not being washed away in this
  case. This justifies requiring that J"(i) also tends to zero for microeconomic frictions
  to become irrelevant at the macroeconomic level. Motivated by the discussion above we
  define "convergence of the economy     aggregate to that of its cotAnterpart with no friction"
  as follows:

  DEFINITIoN 2 The aggregate of an economy that satisfies Assumption 1 convergc8 to that
 of its frictionless counterpart if Z(t) and J(*) tend to zero as t tends to infinity.13

     In sum, we describe the dynamic behavior of an (S,s) economy using four summary
 variables. We look at the economy's aggregate deviation from the frictionless counterpart,
 at the sensitivity of this index to common shocks, and at the suprema of these indices over
 all possible realizations of the underlying stochastic mechanism.


                4   CONVERGENCE AND IDIOSYNCRATIC SHOCKS

                                   4.1    CONVERGENCE

    In this section we isolate stochastic heterogeneity as the only source of convergence
by assuming that all uiijts have the same bandwidth )j            )) and   the same sensitivity
parameters (e E 1).
    There are many ways in which the economy's aggregate may converge to that of its
frictionless counterpart. For example, convergence takes place if idiosyncratic shocks are
correlated with Co in such a way that they exactly ll in the gaps between the density of c
and a density uniform on [0,1) in finite time and, after this happens, become independent
of units' positions within their cyde so that ct remains uniform on [0,1) (see Proposition 2).
This way of achieving convergence is rather far—fetched; there exist other scenarios where
convergence takes place that are even more arbitrary. In this section we consider conditions
that ensure convergence when there is no systematic relation between CO and the realizations
of the idiosyncratic shocks.

ASSUMPTION 2      Independence. The random variables c0 and Vt are independent for all
t > 0, or, equivalently, dv is independent from c, for all a


                                              10
 Under the independence assumption, convergence is not achieved by filling in the gaps in
 finite time, but by making initial conditions irrelevant as time passes. This happens when
the cross—section distribution of idiosyncratic shocks, V, folded back into the unit interval,
converges to a distribution uniform on [0,1) and thereby "washes away" the initial cross—
section distribution of units' positions within their cycle. An example is useful at this
point. Suppose that the process generating any unit's idiosyncratic shocks, (v1(t), t 0), is
Gaussian with variance ti2(t) growing as time passes. Since these processes are independent
across units, the cross—section distribution of idiosyncratic shocks, vt, also is normal and has
the same variance. This follows from the Glivenko—Cantelli Theorem, see e.g. Billlngsley
(1986). Figure la illustrates how the cross—section density of idiosyncratic shocks flattens
out; the corresponding evolution of the density of Cg is illustrated in Figure lb —where we
have abstracted from the value of the common shock a(t)— for the case where Co is a spike
at 0.5. Since the expected value of c approaches one half, Z(t) tends to zero, and since the
cross—section density of Cj is approaching one, J(t) = f(P)—1 tends to zero. Furthermore,
since bandwidths and sensitivity parameters are the same across units, aggregate shocks do
not act as a unit separating mechanism, all they do is move units around their cycle. Figure
lc illustrates this by showing how the density of ct varies for different values of the common
shock at a fixed instant in time (t=1.0). It follows that Z(t) and J(t) both tend to zero.
Thus Figure 1 suggests that all summary variables converge to zero when the cross—section
density of idiosyncratic shocks flattens out as time passes. This assumes that densities are
unirnodal, or at least that they do not oscillate too much. The following assumption makes
these intuitive conditions on the density of the vg's precise.

ASSUMPTION 3 Flattening out of densities. The total variation of the density of Vt tends
to zero as t tends to infinity.'4

   Assumption 3 holds when the density of Vt IS uthmodal and its largest value tends to
zero as i tends to infinity. Two situations where this happens are when the Vt'S are normal
and their variance tends to infinity, and when the Vt'S are absolutely continuous and have
independent increments or, more generally, are an integrated process. "l'he proposition that
follows provides general conditions under which convergence occurs.


PROPOSITION 3        Suppose idiosyncratic shocks and differences in units' initial positions
within their cycle are the only sourtes of heterogeneity and Assumptions 1- 3 hold. Then the


                                              11
economy's aggregate converges to that of its counterpart without friction and Cg converges
to a distribution uniform on [0,1).


PROOF: See the appendix. I

    The assumptions of Proposition 3 are on the cross—section distribution of idiosyncratic
shocks, not on the processes generating individual units' shocks. Since we have a contin-
uum of units, the Glivenko'—Cantelli Theorem (see Billingsley, 1986) provides a link between
assumptions on the v(i)'s and assumptions on vj. For example, if idiosyncratic shocks are
i.i.d. across units, then the cross—section distribution of idiosyncratic shocks is equal to the
probability distribution generating individual shocks. Another example is when the v,(t)'s
are of the form 7w,(t), with the w,(t)'s ii.d. across units and y a fixed, unit specific param-
eter (that could depend on Oj and A,). In this case Vg has the same probability distribution
as the product of the independent random variables F and Wt,where F corresponds to the
cross—section distribution 7,'S, and tv to the common distribution of w,(t)'s.


                            4.2 SPEED OF CONVERGENCE

    Figure 1 suggests that convergence is faster when the variance of idiosyncratic shocks,
relative to the common bandwidth, is larger. It also shows that the speed at which the
economy's aggregate behavior approaches that of an economy with no friction —as mea-
sured by Z(t) and J(t)— does not depend on the sample path of the common shock a(t).
We illustrate these issues with an example.
   Suppose the economy's aggregate deviation is at its steady state, when an increase in
the variance of shocks leads all units to increase their bandwidths by 50%, and that the new
idiosyncratic shocks follow a Brownian motion with instantaneous standard deviation equal
to 5%. From the symmetry assumption it follows that Co is uniform on [1/4,3/4). Figure
2a shows the resulting paths of the aggregate deviation Z(t) for two economies which only
differ in the realizations of the common shock, a(t). The explicit dependence of g(a(t), t) on
t (via v) is reflected in the dampening of the oscillations of the sample paths of Z(t). The
dependence of g on a(t) determines the speed at which the actual sample paths oscillate; the
number of oscillations grows with the speed at which common shocks accumulate. Figure
2b illustrates the corresponding paths of J(i).
   The convergence mechanism we consider in this section ensures that the cross—section
distribution of units' positions within their cycle converges to a distribution U uniform

                                              12
on [0, 1). It is therefore not surprising that the summary variables Z() and J(t) are
closely related to particular notions of distance between c and U. Since the corresponding
relation for J) can be derived intuitively, we only consider this case. From our discussion
in Section 3, we have that J(t) is equal to f,(1) —       1.   The index J() is obtained by
maximizing Og/8a over all values of a a(t) and all values of s 1. Modifying the value of
a for a. fixed instant in time s rotates the density of c1 without affecting its shape; for this
see Figure ic and imagine joining both ends of the z-axis to form a circular diagram, as in
Caplin and Spulber (1987). It follows that sup I(a,s)I is equal to supa f,(a) — i. The
latter expression is the sup—distance between the densities of c and U, which we denote by
R(C., U). It is equal to the largest relative error made when approximating the distribution
of c by a distribution uniform on [0, i).' We therefore have that J(t) = 6Pa> R(c, U).
Figure lb indicates that it is quite likely that lt(c., U) decreases monotonically over time.
This is indeed true when the Vt'S have independent increments, as is shown in Proposition A4
in the Appendix. It then follows that J'(t) = R.(cg, U), that is, that the largest (percentage)
error made when approximating the probability of an event under c by the corresponding
probability under U is equal to the largest sensitivity of the aggregate deviation to small
common shocks over all possible future sample paths of a(t).
   Figures 2c and 2d show the trajectories of Z) and J(t) that correspond to Figures
2a and 2b. These do not depend on the particular paths of a(t). It follows from the
formulas we derive for the summary statistics in the appendix that the speed of convergence
increases with the relative importance of idiosyncratic shocks compared with the common
bandwidth. For example, if in the experiment of Figure 2 x1() and z(i) are the logarithms
of economically meaningful variables and time is measured in years, then it takes about 18
years before J(t) is below 5 percent when c/A is equal to 0.1; if a/A is equal to 0.5 it takes
only about 9 months.16
   In Proposition Al in the Appendix, we provide general expressions for the indices used
to construct these figures. They are all expressed in terms of the Fourier coefficients of Vj,
and show that, loosely speaking, the smaller the Fourier coefficients, the faster all indices
converge to zero. This can be understood in terms of the example given in Figure 1 above,
since Fourier coefficients measure how fast vt spreads out.17 Moreover, in the particular
case where idiosyncratic shocks have independent increments, all the indices converge to
zero at the same rate as Ikit, where k denotes the first non-trivial Fourier coefficient of
v1/A that differs from zero.38 Hence speed of convergence is faster, the smaller the first


                                              13
 non-trivial Fourier coefficient of v1/A. For example, when idiosyncratic shocks follow a
 Brownian motion with instantaneous variance a2, we have that Ik = exp(—2r2c2/X2).
 Since the variance of the random variable that is folded back into the unit interval (see
 equation (4)) is (o-/A)2, it       is   not surprising that convergence is faster when this ratio is
 larger.


             5      CONVERGENCE AND STRUCTURAL HETEROGENEITY

       Structural heterogeneity —namely, differences in bandwidths and sensitivity parameters—

 is   a second source of convergence. It ensures convergence by itself, even if no idiosyncratic
 uncertainty is present. It also adds various new features to the analysis of convergence and
 speed of convergence. Most prominently, aggregate shocks stop being irrelevant —as was
 the case in Section 4— and become the driving force behind convergence.
       In this section we isolate structural heterogeneity as a source of convergence, by as-
suming that there are no idiosyncratic shocks. We consider both sources of convergence
simultaneously in Section 6. We find it convenient to study separately the cases where
differences in bandwidths and differences in sensitivity parameters are the only sources of
convergence. We begin with the former case.


                                5.1 HETEROGENEOUS BANDWIDTHS

      When structural heterogeneity due to different bandwidths is present, equation (3) may
be used      to show that:

(6)                                 Z() =     J AIA(.A) { -. c(IA)} d),
where fAr') denotes the probability density of bandwidths and C(tIA) the average position

within their cycle of the "sector" of the economy formed by units with bandwidths equal
to X.
      Equation      (6) shows that, as mentioned in Section 3, units with a larger bandwidth
have a larger weight when determining the deviation of the aggregate from its frictionless
counterpart.        The weight is proportional to both the size    of the bandwidth and the size of
the sector.      This equation also shows that the aggregate path of the economy may converge
to    that of its   frictionless counterpart in one of two ways. First, convergence takes place
if   units   within   each   sector approach a distribution uniform on their common bandwidth.
Each sector then behaves as in a frictionless economy, and adding over all sectors shows that

                                                     14
 the economy's aggregate mimics that of its frictionless counterpart Convergence occurs in
 this way when the density of idiosyncratic shocks spread out without limit as time passes
 (see Section 4). Yet convergence may take place even when the aggregate deviation of
 units with the same bandwidth does not converge at all, but synchronization among the
aggregate deviations of different bandwidths breaks down over time. This is the case with
sufficient differences in bandwidths.

                                    6.1.1    CONVERGENCE


    We start our discussion of convergence by presenting an example where differences

in bandwidths are the only source of convergence. All Os's are the same, there are no
idiosyncratic shocks, and all units start off at the beginning of their cycle. We consider
a cross—section distribution of the inverse-bandwidths —the 1/.X's— that is uniform on
[10,20] and assume that the z's and x's are the logarithms of economically meaningful
variables. Bandwidths therefore vary between 5 and 10 percentage points. Since there
are no idiosyncratic shocks, and all units start off at the beginning of their cycle, we may
imagine that there is only one unit in each sector. The deviation of any given sector does
not approach zero; it exhibits cycles that do not dampen out over time.
    As common shocks begin to accumulate, units with different bands move in a fully
synchronized manner within their bandwidths until they start completing their first cycle
(at t = 0.05). The times at which units complete their cycles vary because bandwidths
differ across units; this is the source of convergence in this example.
    From equation (5) we have that c = (a(t)/A)(mod 1), therefore the distribution of cj is
uniform on 10,1) every time accumulated common shocks are equal to a multiple of 0.1. It
departs from this distribution after every visit, yet every time by less. A visit to the uniform
distribution is characterized by the fact that the correlation between units' positions within
their cycle and their bandwidths decreases when compared to the previous visit. Figures
3a and 3b show the paths of Z(t) and J(i). The discontinuities in J(i) are due to the fact
that the density of 1/A is not continuous at its endpoints. Modifying this density slightly
at these points would lead to the same qualitative behavior without jumps. The Figure
shows that the aggregate deviation, Z(), and its sensitivity to small common shocks, J(),
oscillate on their way to zero.
   When there is no stochastic heterogeneity, both Z(t) and J(t) only depend on time
through the current value of c(s); g(a, t)     g(a) remains constant as t varies (see Propo-

                                               15
 sition 1). Hence the path of Z(t) = SUP,>) jg(a) and        J(t) = SUP>() Ig'(a) are both
 equal to the envelopes of the sample path of Z(t) and J(t). Figures 3c and 3d show how
 Z(t) and J(t) evolve over time. This example also serves to show that convergence may
 take place even if units' initial positions within their cycles are highly correlated with their
 bandwidths. Structural heterogeneity achieves convergence by breaking down the correla-
 tion between the aggregates of different sectors.

    Consider any cross—section distribution of 1/A that has a sufficiently smooth density.
 Partition the set of possible bandwidths into a finite number of intervals, and approximate
 the cross—section distribution of bandwidths within each interval by a uniform distribution.
 The argument given above applies to the sector composed of units with bandwidths in
any one interval; these units' aggregate deviation therefore converges. It follows that the
behavior of the entire economy's aggregate converges to that of its counterpart without
friction. This argument explains why, when differences in bandwidths is the only source of
heterogeneity, convergence takes place when the inverse of units' bandwidths have a smooth
density. Since our model has a continuum of units, this is a relatively weak assumption.
    The previous argument is based on assuming that c0 is constant; it can be extended to
the case where c0 and A are not "perfectly" correlated by requiring that the density of 1/A,
conditional on any value of c0, be sufficiently smooth.

ASSUMPTION 4 . Smoothness       (1). The random variable A has finite expectation and the
density of 1/A, conditional on any value of c0, has bounded variation V(A co) such that
EV(A' Ico) is finite.

    Below we provide a proposition generalizing and formalizing the insights of this example.


PROPoSITION 4 Suppose that differences in bandwidths and units' initial positions within
their cycle are the only source of heterogeneity, and that Assumptions I and 4 hold. Then
the economy's aggregate behavior converges to that of its counterpart with no friction and
ct converges to a distribution uniform on the interval [0, 1).

Paoor: See the Appendix. I

                             5.1.2   SPEED OF CONVERGENCE

   The example above shows that the rate at which the common shock a(t) grows —which
is irrelevant in the case of only stochastic heterogeneity— is crucial when heterogeneity in

                                              16
 bandwidths is the only source of convergence. The mechanism that leads to convergence
 in this case is not based upon spreading units out, but on having them move around their
 cycles   at different speeds. This mixing effect grows with a(t).
       The example above also shows that the distance between the cross—section distribu-
 tion of units' positions within their cycle anda distribution uniform on     [0, 1) does not
 decrease monotonically over time. Even though the distribution of units within their cycle
 approaches a distribution uniform on 10,1), there are periods when units "catch up" with
each other and the distance between Cg and its limiting distribution increases. This differs
from what we saw in Section 4; since the distance between ct and a distribution uniform on
[0,1) decreases monotonically over time when stochastic heterogeneity is the only source of
convergence and idiosyncratic shocks have independent increments.
      When there is no stochastic heterogeneity, Z*(t) and    J(t) depend on t only through
the value of a(t); it follows that the speed of convergence grows with the rate at which
aggregate shocks accumulate. It is shown in the Appendix that, under the assumptions of
Proposition 4, J(t) is bounded from above by k/a(t) for some constant k that depends
on how smooth the corresponding densities are. This bound cannot be improved upon,
it is sharp when the cross—section distribution of units' bandwidths within their cycle is
uniform.


                   5.2 HETEROGENEOUS SENSITIVITY PARAMETERS

      When different sensitivity parameters are the only source of convergence, equation (3)
may be used to show that:


(7)                            Z() = ) J   { — C(iO)} fe(8)dO,
where fe(8) denotes the probability density of sensitivity parameters and C(iIO) the average
position within their cycle of the "sector" of the economy formed by units with sensitiv-
ity parameter equal to 0. As in the case with different bandwidths, when differences in
sensitivity parameters are the only source of heterogeneity, aggregate shocks achieve con-

vergence by gradually eliminating the synchronization between sectoral aggregates instead
of by having every sectoral aggregate deviation converge.
      When all bandwidths are the same (without loss of generality A     1) and there are no

idiosyncratic shocks, equation (5) implies that c = (c0 + a(i)e)(mod 1); hence cg converges


                                               17
 to a distribution uniform on [0,1) because a(L)O flattens out without bound as aggregate
 shocks accumulate. The correlation between the position within their cycle of units with
 different sensitivity parameters decreases over time, since common shocks affect them dif-
 ferently and these differences accumulate.'9 As long as 0 has a sufficiently smooth density,
 conditional on any value of cO, the economy's aggregate deviation converges to that of its
 frictionless counterpart.

 ASSUMPTION 5 Smoothness (2). The random variable 0 has a density fe(8) such that
 fo(O) and 9f(9), conditional on any value of CO, have bounded variation V(fe(O) I ce) and
 V(Ofe(9) co); and E,V(f9(8) co) and E,V(9f0(O) co) are both finite.

 PROPOSITION 5 Suppose that differences in sensitivity parameters and units' initial posi-
 tions within their cyck are the only source of heterogeneity, and that Assumptions I and 5
hold. Then the economy's aggregate behavior converges to that of its counterpart with no
friction and cg converges to a distribution uniform on the interval [0,1).

PROOF: See the Appendix. I
    The speed at which the economy's aggregate converges to that of its frictionless coun-
terpart increases with the rate at which a(t) grows; it is shown in the Appendix that Z(t)
and J(t) are both bounded from above by k/a(L), where k depends on how smooth the cor-
responding densities are. This bound is sharp when sensitivity parameters have a uniform
distribution.
    The mechanism that leads to convergence in this case combines those present when
either idiosyncratic shocks or differences in bandwidths are the sole source of heterogeneity.
On the one hand, aggregate shocks are the main determinant of convergence, on the other,
these shocks achieve convergence by spreading out indefinitely the x(t)'s, as idiosyncratic
shock8 did in Section 4.


                                 6 INTERACTIONS

   We have found conditions under which stochastic and structural heterogeneity yield
convergence separately. It follows that convergence is more likely to occur when both
sources of heterogeneity are present. We formalize this intuition at the end of Section A2
in the Appendix.
   The results on the speed of convergence are, however, far less transparent. There is a

                                             18
 broad set of parameters for which the intuitive assertion that when a second mechanism is
 added, convergence speeds up, is valid; surprisingly, however, this is not universally true.
      Figure 4 presents an example of this paradox. It shows that adding structural hetero.-
geneity to stochastic heterogeneity may slow down the speed of convergence. In this exam-
ple, idiosyncratic shocks follow a Brownian motion (with instantaneous variance equal to
0.4 and 1/A is normal with mean 0.4 and variance t2). All units have the same sensitivity
parameters and their initial distribution within their cycle is uniform on [0,0.2]. Figure 4
shows the path of 1(t) for three values of the parameter ,. It is apparent that —beyond
a certain time threshold— convergence is faster when stochastic heterogeneity is the only
source of convergence (q = 0) than when structural heterogeneity is also present (q> 0).20
      Figure 4 is best understood by comparing the aggregate deviation without structural
heterogeneity, Z(t), with the aggregate deviation of a sector composed of units with a
common bandwidth larger than average after structural heterogeneity is added. When
structural heterogeneity is added to idiosyncratic uncertainty, the sectoral aggregates cor-
responding to larger bandwidths converge slower than Z(t), since structural heterogeneity
reduces the variance of their idiosyncratic shocks relative to their bandwidths and it is this
ratio that determines the speed of convergence (see Section 4). For the same reason the
sectoral aggregates corresponding to smaller bandwidths converge faster than Z(t). Figure
4 shows an example where the slowdown of units with bandwidths larger than average
dominates over the combined effect of the acceleration of units with bandwidths smaller
than average and the decrease in synchronization between sectoral aggregates (see Section
5).
      Perverse interactions may also be present when we add stochastic heterogeneity to an
economy where structural heterogeneity —in the form of differences in bandwidths— leads
to convergence by itself. This is best understood when we consider the case where there
are no differences in sensitivity parameters and we group units into sectors according to the
value of their idiosyncratic shock at time t, v,(i). Since the effect of v1(i) on units within a
sector is the same as the effect of having a common shock equal to a(t) + v1(t) instead of
a(t), the discussion in Section 5 shows that sectors with positive v(t)'s are typically nearer
to their steady state than they would be if there were no idiosyncratic shocks, while sectors
with negative realizations are farther away. When adding sectoral aggregate deviations,
structural heterogeneity decreases the degree of synchronization, yet it may happen that
units with negative shocks determine the overall speed of convergence. We have constructed


                                              19
 examples where this is the case.21
     Finally, we consider the case where idiosyncratic shocks interact with differences in
 sensitivity parameters. For simplicity we suppose that bandwidths are the same across
 units. If the v,(t)'s are i.i.d. across units and independent from 0, then adding idiosyncratic
 shocks speeds up convergence (this follows form Proposition A4 in the Appendix). Yet when
 v,(t) depends on 0, there are cases where adding structural heterogeneity —in the form
 of differences in sensitivity parameters— slows down the speed at which an economy with
 stochastic heterogeneity converges.


                                 7     FINAL REMARKS
    In this paper we study the dynamic behavior of an (S,s) economy where units face
idiosyncratic shocks and differ in both their bandwidths and their responses to aggregate
shocks. We develop a framework that provides a meaningful characterization of the out—
of—steady state dynamics of an (S, s) economy, and study its convergence properties and
the speed at which this occurs.
    The major building block in our approach is to work with the cross—section distribution
of units' positions within their cycle, conditional on the 8ample path of the aggregate 8hock.
This distribution, combined with that of structural differences and sensitivity parameters,
describes the actual state of the economy at a given instant in time and —if the number of
units is sufficiently large— does not depend on the value taken by every particular agent's
idiosyncratic shock but only on the common distribution function originating them. This
insight follows from the Clivenko—Cantelli Theorem (see Billingsley, 1986); it allows us to
apply results from probability theory when studying convergence and speed of convergence.
Although we work with (S,s) rules, the summary variables Z(t), J(t), Z(t) and J(t)
should be applicable to a much broader set of circumstances where m.icroeconomic frictions
influence aggregate dynamics.
   An important methodological contribution of our approach is that it substantially re-
duces the dimensiona.lity of the problem. An alternative approach would be to characterize
the joint behavior of n units, in terms of the joint distribution function describing units' po-
sitions at time t based upon information available at time I = 0 (e.g. Caplin, 1985). Within
this approach, however, convergence means that given information available at time I = 0,
our best forecast of the n-dimensional random vector describing agents' positions within
their cycle at time I approaches a distribution uniform on the unit hypercube, tO, l]'. In

                                              20
 this case speed of convergence slows down as the number of agents grows, since demanding
 that all agents be within a given distance from their uniform distribution becomes more
stringent. This differs from the steady state we consider in this paper, where the cross—
section distribution of units' positions within their cycle is uniform on the interval [0,1].
Considering statistics derived from the cross—section distribution —such as its mean and
sensitivity to common shocks— and realizing that it does not depend on the actual realiza-
tion of every agents' idiosyncratic shock simplifies the analysis considerably and provides
ground for optimism about future research in this area.
    We have implicitly assumed in our analysis that the redefinition of initial conditions —
i.e. whatever moves the economy away from its steady state— occurs infrequently enough
so that the economy has time to converge back to its steady state; the insights developed
here, however, apply even when this is not the case (see Caballero and Engel 1989a, and the
working paper version of this paper). In general, there is a permanent tension between the
natural tendency for the economy's aggregate deviation to converge back to the steady state
and the impact of repeated large (finite) aggregate shocks. Given any process generating
the latter, the average distance of the economy from the steady state decreases with an
increase in the importance of stochastic and structural heterogeneity (with the caveats of
Section 6).
   The techniques developed here have already found applications beyond the framework
of this paper. For example, Caplin and Leahy (1989) use them to prove convergence (up
to a location parameter) in the context of a fully symmetric two sided (S, s) economy
where heterogeneity is negligible; and Caballero and Engel (1989b) have used the concept
of synchronization developed here to show that when strategic interactions are present,
multiple equilibria can be ruled out once the cross—section distribution is sufficiently close
to its steady state.
   To conclude, we stress that the principle of conditioning on the aggregate in order
to keep track of the evolution of the cross—section distribution is far more general than
the framework of this paper. This may be one of the building blocks of future work on
aggregation of heterogeneous units in the presence of non—vanishing correlation across units.


Department of Economics, Columbia University, New York, NY 10025, U.S.A.

 Department of Economics, MiT (Cieplan and Universidad de Chile), Cambridge, MA
02139, U.S.A.


                                             21
                                         APPENDIX



               Al. EXACT FORMULAS FOR TIlE SUMMARY VARIABLES

DEFINITION     Al Given non—negative real numbers a and t, we define the random variables
C(a,t) and Y(a,t) as follows:

                                                   aO+
(8)                             C(a, )       (+          Vt)
(9)                             Y(a,) =     [C(a,)] (mod 1);

with c0, Vt, 0 and A as in Section 2. We then have that the function g(a,i) defined in
Section 2 is equal to EA — E{AY(a,i)}.

      The following three propositions provide expressions to calculate g(a,i) and Og/Oa
when only one of the three sources of heterogeneity considered in this paper —idiosyncratic
shocks, differences in bandwidths and differences in sensitivity parameters— is present, and
all units have the same initial position within their cycle. Following these results we show
how a simple conditioning argument extends them to the case where more than one source
of convergence is present and units differ in their initial positions within their cyde.

LEMMA Al Let X be a random variable whose density 1(z) has bounded variation. Then
X(mod 1) also has a density, f1(z), and f1(x) = Ekf(z + k).

Prtoor: This is a well known result in probability theory, for a proof under the assumptions
made above see Proposition 3.1 in Engel (1991). I

LEMMA A2 Let X denote a random variable whose characteristic function J(z) satisfies
Ek>1 IJ(27k)i <+00. Then:

(10)                     E [X(mod 1)] =     —
                                                  E>i [J(2rk)],
where [z] denotes the imaginary part of the complex number rand x(mod 1) the difference
between x and the largest integer less than or equal than z.

Paoor: The Fourier coefficients of X and X(mod 1) are the same (see e.g. Lemma 3.1
in Engel, 1991); hence the Fourier coefficients of X(inod 1) are summable and X(mod 1)

                                             22
 has a continuous density, f1(x), with bounded variation. Applying Poisson's Summation
 Formula (see Butzer and Nessel, 1971, p.202, for the version being used here) we then have
that fj(x) = EkJ(2rk)e_i2. Substituting this expression for fi(z) in E[X(modl)] =
f xf(z) dx, interchanging the order of integration and summation,22 and integrating the
resulting terms, leads to equation (10). I

PROPOSITION Al Suppose that CO           C, A        1,23 and 0 1 in equation (10), and assume
that the density of Vg has a characteristic function, J(z) that satisfies Ek>1 If(2wk)l < +.
Then:


(11)                     g(a,t) =
                                         k> 1

(12)                             =   2         3 [j(2rkei21(c+a)]
                                         k>1

where [z] and E[z] denote the real and imaginary parts of the complex number z.


Paoo:        The expression for g(a,i) follows directly from equation (10) in Lemma Al,
letting c + a + v play the role of X.
   The expression for Og/Da can be derived formally by differentiating the sum in (11)
term by term. The change in the order of summation and differentiation is made rigorous
by applying Lebesgue's Dominated Convergence Theorem (see e.g. Billlngsley, 1986) and
using the assumption that the the Fourier coefficients of v are summable. I


PROPOSITION A2 Suppose that c0        c with c E [0,1), Vg        0 and 0 E 1, that EA is finite,
and that AfA(X) has finite total variation, where fA(A) denotes the density of A. Then:

                                                              a/(k-.c)
(13)              g(a,t) = (._c)EA — a +
                                                             0


(14)             (a,t) = —1+>J(k)21/t(k).
PROOF: The expression for g(a, t) follows from:


  E(AY(a,t)] = J.\ [(÷ ) (modl)} fA(A)dA

                       a/(k+I—c) A(c.1-_k)fA(A)dA
                      ja/(k.c)        A           + J+OO
                                                     a/(1—c) A(c+)fA(A)dA
                                                                 A



                                                23
                = cEA + a —
                                   k1       a/(k+1—c)

                = cEA + a      —
                                   ja/(kc)
                                   k>1 0

The expression for Og/ôa is obtained by differentiating the latter expression. The assump-
tion that AIA(.A) has bounded variation is used when interchanging the order of differenti-
ation and summation. •

PRoPosITIoN A3 Suppose that co             c with c in [0,1), Vt   0, and A 1, and that 9f(8)
has bounded variation, where fe(9) denote8 the density of 0. Then:


                g(a,i) =       —a        + Ek(k—c){Fe (k+:_c)       _F0()},
              !(a,t) =      —1   +

where Fe(O) denotes the cumulative distribution function of 0.

PRooF: The expression for g(a,t) is obtained using Lemma Al as follows:

                                                         +k—
        E[(c+ aO)(modl)] =
                                   J0x1e (X
                             =                           —k   + c)fe(u)du
                                     k    (k—c)/a

                             = aEO         —
                                               Eck —(h—c)/
                                                      c)J"          fe(u) du
                                               k
                             =a—                              _____            ___

The expression for Og/Oa is obtained by differentiating the latter expression; the assumption
that Ofe(9) has bounded variation is used when interchanging the order of summation and
differentiation. I


                                     GENERALIZATIONS

   When more than one source of convergence is present, we obtain expressions for g(a, *)
and Og/Oa by calculating E[AY(a,t)IX = z] —and the corresponding derivative— for an
appropriately chosen random vector X using one of the above propositions, and then taking
expected value with respect to X. This argument is based on the fact that ELJ(X,Y)] =

                                                    24
 Ex[f(X,Y)IX = z)J. It requires that the corresponding proposition's regularity conditions
 hold conditional on X = x for any x, and, when calculating Og/Oa, that they hold uniformly
in x. Next we show explicitly how to apply this argument for every one of the propositions
derived above.

   I. If we want to apply Proposition Al we let           (co = ?,A = A,O = 0) play the role of
       Vt   and   + (aB/A) the role of c. This leads to the following expressions:


                            g(a,t)   =E    k> 1
                                                       [EA {Ae12   (a,t)A = A}]

                                     =2           [E6 {Oei2C()IO = o}]
                                          k> 1


       with C(a,) defined in (8).

   2. If we want to apply Proposition A2 we let (A Ic0 = ,         0 = 0, v = v) play the role of
       A, aO + v that of a and that of c.

   3. If we want to apply Proposition A3 we let (0 I c = , A = A, Vt = v) play the role of
       0, ? + (v/A) that of c, and (a/A) that of a.


                                     A2 CONVERGENCE

LEMMA A3      Let X denote a random variable that has a density, 1(z), with finite total
variation equal to V(f). Denote the density of X(mod 1) by f1(z), and the sup—distance
between X(mod 1) and a distribution uniform on [0,11 by R(X(mod 1), U). Then:


(15)                      JE[X(modl)1 —                 R(X(mod1), U),
(16)                        R(X(mod 1), U) V(f).

PitooF: Equation (15) follows from:


                       IE[A'(mochl)l —             J(f() 1) zdz
                                                    I Ifi(z)—1)lzdz
                                                   Jo

                                                 I R(X(modl),U)xdz
                                                   Jo
                                             = R(X(mod1),U).

                                                  25
 For a proof of equation (16), which s due to Kemperman, see Proposition 3.3.c) in Engel
(1991). •

LEMMA A4           1. Suppose that X and Y are random variables such that (X Y = y) has
        a density with finite total variation V(XIY = y) for all values of y and EyV(X I Y =
        y) is finite. Then X has a density with finite total variation V(X) and V(X)
        EyV(X I ' =
   2.   Let 1(x), fa(x) and f(x) denote the densities of the random variables X, aX and
        X + c, with a > 0, and suppose that 1(x) has finite total variation V(f). Then f(x)
        and   f(x) also have finite total variation and V(fg) = V(f)/a; V(f) = V(f).

Paoop: The proof of the first statement is analogous to that of Proposition 4.3 in Engel
(1991). The proof of the second statement is trivial. I


                                 PROOF OF PRoPosITIoN 3

    Let R(c, U) denote the sup—distance between Ct and a distribution uniform on the unit
interval, and V(X) denote the total variation of the density of the random variable X.
From Lemma A3 it follows that R(cg, U) V(co + (vt/A)); Lemma A4 and Assumption
2 then imply that R(ct, U) <      V(v/A) = V(v).         Assumption 3 now implies that Ct
converges —in the sup—distance— to U. Since J'(i) = 8P,>t R(c,, U) (see Section 4), this
is equivalent to having J(t) converge to zero. That Z(t) also tends to zero follows from
the fact that, due to Lemma A3, it is bounded by           R(c,, U).   I

                                PROOF OF PRoPosmoN 4

   We begin by noting that, since in this case Cg only depends on t through the value of
a(t), convergence of Z() and J(g) to zero is equivalent to convergence of Z() and J(t)
to zero. The same holds for Proposition 5.
   Let 1t(c, U) denote the sup—distance between c and a distribution uniform on the unit
interval and V(X) denote the total variation of the density of the random variable X. From
Lemma A3 it follows that R(ct, U)         V(co + (a(t)/A)). Using Lemma A4 we then have
that R(c, U) EV(A1 co)/2a(t); therefore c converges to U and J(i) converges to
zero at least as fast as

                                              26
    Theorem 4.2 —due to HopI— in Engel (1991) shows that (cg,A) converges in the weak—
star topology to (U,A), with A independent from U. It follows that E(cgA) converges to
 SEA, and therefore Z(t) converges to zero. I

                               PRooF OF PRoPosITIoN 5


    It follows from Lemmas A3 and A4 that R(cg, U) k/a(t), with k = E0V(fe I co)/2;
therefore ct converges to a distribution uniform on [0,1) and Z(t) converges to zero.
    To show that J(t) converges to zero, we first consider the case where c0        c. That
J(t) converges to zero in this case follows from the expression we derived for Og/Oa in
Proposition A3 and the fact that Ek fe (-) converges to f 0f0(9)dO E because
Ofe(O) is Riemann—integrable. Ftirthermore, since EO =     1   we have:


                 IJ(t)I   = >I:k_cf (k-c) — Ej'Ofe(O)dO
                          1jk_cf(k;c)Of(O)1
with (k — c)/a    9 (k + 1 — c)/a. It follows that J(t) V(Ofe(6))/a(t); therefore the
speed of convergence of J*(g) —and, due to Lemma A3 that of Z'(t) too— is bounded from
above by 1/a(t).
   The case where c0 is not equal to a spike follows from the previous argument by condi-
tioning on the value of c0 and using the hypotheses according to which EV(ef0(O) I c0) is
finite. I

                                   GENERALIZATIONS


   Propositions 3, 4 and 5 can be extended easily to the case where more than one source
of heterogeneity is present using a conditioning argument analogous to the one we used at
the end of Section Al. I

PR.0pOSITI0N A4 Suppose that X and Y are independent random variables such that the
density of X has bounded variation. Then the sup-distance between (X + Y)(mod 1) and a
distribution U uniform on 10, 1] is less than or equal than the sup—distance between (Xmod 1)
and U.


                                            27
Paoor: Let fx(tz) and fx+v(u) denote the densities of X(mod 1) and (X + Y)(mod 1),
and Fy(u) the cumulative distribution function of Y(mod 1). From Lemma Al and the
independence assumption it follows that fx+y(u) = I fx(u — v)dFy(v). Hence:

                               —
                    Ifx+y(u)        = ILfx(u_v)dFv(v) — iJ
                                    = I! (fx(ts—v)     —
                                                           1)dFy(v)I
                                      I Jo
                                             Ifx(u—v) — ljdFy(v)I

                                     jR(X(modl),U).
The desired conclusion follows by taking the supremum over all u in [0,1]. I




                                             28
                                    REFERENCES


AKERLOF, G.A.: "Irving Fisher on his Head: The Consequences of Constant Threshold-
Target Monitoring of Money Holdings," The Quarterly Journal of Economics, 93-2 (1979),
169—187.

ARROW, K.J., T.HARRIs, AND J.MARSIIACK: "Optimal Inventory Policy," Econometrica,
19 (1951), 250-272.

BENABOU, R.: "Optima! Price Dynamics and Speculation with a Storable Good," Econo-
met rica 57-1 (1989), 41—81.

BILLINGSLEY, P.: Probability and Measure, 2 Ed. John Wiley, New York, 1986.

BLANCRARD, O.J., AND S.FIscRER: Lectures on Macroeconomics, Mass.: MIT Press,
1989.

BLINDER, A.S.: "Retail Inventory Investment and Business Fluctuations," Brookings Pa-
pet-s on Economic Activity, 2 (1981), 443—505.

BUTZER., P.L., AND R.J.NEssEL: Fourier Analysis and Approzimation Vol. .1 One-
Dimensional Theory, Academic Press, New York, 1971.

CABALLERO, R.J. AND E.M.R.A. ENGEL: "The S-s Economy: Aggregation, Speed of
Convergence and Monetary Policy Effectiveness," Columbia Univ. Working Paper #420,
(1989a).
CABALLERO, RJ. AND E.M.R.A. ENGEL: "Heterogeneity and Output Fluctuations in a
Dynamic Menu Cost Economy," Columbia Univ. Working Paper #453, (1989b).

CABALLERO, R.J. AND E.M.R.A. ENGEL: "Dynamic (S,s) Economies: Aggregation,
Heterogeneity and Coordination," Columbia Univ. Working Paper #476, (1990).

CAPLIN, A.S.: "The Variability of Aggregate Demand with (S,s) Inventory Policies,"
Econometrica, 53 (1985), 1395—1410.

CAPLIN, A.S., AND E. SHESRINSKI: "Optimality of S,s Pricing Policies," inimeo (1987).

CAPLIN, A.S., AND D. SPULBER: "Menu Costs and the Neutrality of Money," Quarterly
Journal of Economics, 102-4 (1987), 703—726.

CAPLIN, A.S., AND J. LEAIIY: "State-Dependent Pricing and the Dynamics of Money and
Output" Columbia WP # 448, October (1989).

                                           29
ENGEL, E.M.R.A.: A Road to Randomness in Physical Systems, Lecture Notes in Statis-
tics, Springer Verlag, New York, 1991.

EHRHARDT, R.A., C.SCHULZ, AND H.WAGNER: "(s,S) Policies for a Wholesale Inven-
tory System," in Schwartz, L.B. (ed.), Multi-Level Production/Inventory Control Systems:
Theory and Practice. Amsterdam: North Holland, 1981, 145—161.

KARLIri, S., AND A.FABENs: "A Stationary Inventory Model with Markovian Demand,"
Chapter 11 in Mathematical Methods in the Social Sciences, ed. by K.J.Arrow, S.Kazlin
and P.Suppes. Stanford: Stanford University Press, 1959.

SCARF, H.E.: "The Optimality of (S,s) Policies in the Dynamic Inventory Problem" Chap-
ter 13 in Mathematical Methods in the Social Sciences, ed. by K..LArrow, S.Karlin and
P.Suppes. Stanford: Stanford University Press, 1959.

SHESI1INSKI, E., AND Y.Wniss: "Inflation and Costs of Price Adjustment," Review of
Economic Studies, 44 (1977), 287—303.

SHESHINSKI, E., AND Y.WEIss: "Optimum Pricing Policy under Stochastic Inflation,"
Review of &onomic Studies, 50 (1983), 513—529.

TsIDD0N, D.: "The (Mis)Behavior of the Aggregate Price Level," mimeo (1989).




                                          30
                                  FOOTNOTES
 1. We thank Roland Benabou, Olivier Blanchard, Andrew Caplin, Peter Diamond, Mo-
    hainmad Hammour, Esteban Jadresic, Keith Head, Robert Porter, four anonymous
    referees and seminar participants at Columbia, MIT and Princeton for very use-
    ful comments. Ricardo Caballero acknowledges financial support from NSF through
    Grant SES-9010443.

 2. Others have performed comparative statics experiments in models with no aggregate
    (continuous) shocks (e.g. Akerlof, 1979; Tsiddon, 1989).

 3. Of course, studying the determination of the x(t)'s themselves can be, and has been,
    a topic in itself.

4. We assume that the (S,s) rules followed by units are given exogenously. This has two
   consequences. First, we do not consider the relation between the economy's aggregate
   behavior and the determinants of the (S, s) policies' optimal target and trigger points.
   This can be done easily, yet doing so is beyond the scope of this paper. Second, the
   results we derive also apply in a broader class of problems, where (S, s) rules are not
   optimal but can be justified as either simple rules that approximate more complex
   first best rules or, perhaps equivalently, as arising from near rational behavior.

5. The only reason for having this assumption is that it simplifies some of the algebraic
   expressions. It is easy to work without it, as we did in preliminary versions of this
   paper. For example, this implies that in the retail inventory problem z1 represents
   the inventory level in deviation from its long run average.

6. This assumption requires that the sum of changes in aggregate and idiosyncratic
  components always be positive: O1da(i) +     dv,() 0. We assume that a(t) grows
  sufficiently fast —compared to the rate at which idiosyncratic shocks disperse— for
  this assumption to hold. On some occasions, however, calculations are simpler if we
  consider distributions generating idiosyncratic shocks that have infinite tails. Our
  model is appropriate in this case if the fraction of units violating the monotonicity
  assumption is small.

7. The monotonicity assumption is appropriate in the inventory problem when returns
  are dominated by new sales and the holding cost does not vary much; in the pricing

                                         31
    problem, when core inflation is sufficiently large; in the cash balance problem, when
   expenditures dominate the interest rate variability; and in the technology, consumer
    durables, and investment problems, when the obsolescence and depreciation rates
   dominate the uncertainty faced by firms and consumers.

 8. To reconstruct X(t) based on Z(t) we need to know the value of a(t). This is usually
   obtained front a theoretical model for the frictionless economy.

 9. Note that 0 and A do not have time subindices, indicating that units' sensitivity
   parameters and bandwidths do not change over time.

10. The 1 is used in place of 1 to remind us that there are no units with c(i) = 1, since
   this is a trigger point. Strictly speaking, this notation is unnecessary since the density
   of an absolutely continuous random variable is determined up to a set of Lebesgue
   measure zero. What we have in mind is a continuous version of this density.

11. This assumes that all sensitivity parameters are the same across units. The expression
   for 1(t) is extended to the general case as follows. We apply the argument given in
   the text with the density of ct conditional on the value of e instead of     f, and take
   expectation with respect to 0, concluding that J(t) = Ee [9f(c,e=s)(1j1 — 1. The
   assertion that 1(to) = 0 does not imply that /(t) remains equal to zero is still valid.

12. Considering suprema in the definitions above is just one possible choice. We could
   work with a weighted average —over all possible values of a a(t) and $ t— where
   the weights reflect the likelihood of different sample paths of the common shock and
   the time discount rate.

13. Strictly speaking, we should consider higher derivatives of Z(t) with respect to a(t);
   we do not see any economic motivation for doing this.

14. The total variation of a function 1(x) is equal to sup Ek If(zk+1) — f(zk)I, where
   the supremum is taken over all finite increasing sequences z1 < x2 < X3 <         .... It
   follows directly from this definition (see e.g. Proposition 3.4 in Engel, 1991) that the
   total variation of a unimodal function is equal to twice the maximum value it attains.
   More generally, if f(z) is piecewise continuously differentiable, with jumps of absolute
   magnitude 61,62,..., then its total variation is equal to E6k + I If'(x)ldz.



                                            32
 15. Formally:
                                R(c.,tJ) = SUPA Pr{c. E A)     — 1
                                                   Pr{U   A}
       where the supremum is taken over all l3orel sets with positive Lebesgue measure. The
       proof may be found in Caballero and Engel (1989a).

 16. We have limited our attention to cases where the economy converges to the steady
      state, but the same approach can be used when this does not happen. In Caballero and
      Engel (1989b) we show that when the v,(1)'s are stationary, the synchronizing features
      of large aggregate shocks can only be partially undone by stationary idiosyncratic
      shocks.

17. Given a random variable X, the real and imaginary parts of its first Fourier coefficient
      are equal to the expected value of co€(2wX) and sin(2xX). Since the sine and co-
      sine functions are periodic, these expectations are equal to those of cos(2rX(mod 1))
      and sin(2TX(mod 1)) and therefore measure how near to a uniform distribution the
      random variable X is after being folded back onto the unit interval.

18. When we say that g() converges to zero at the same rate as a positive decreasing
      function h(t), we mean that


                              0 < lim (lim sup Ig(u)I/h(i)) < +oo.
                                 —•+O        u>t


19.   Looking at a particular example —say, c0      0, A 1 and 0 uniform on [1/2,3/2]—
      helps building the intuition behind how convergence takes place in this case. Since
      such an analysis is entirely analogous to the one we made in Section 5.1, we omit it.

20. A similar phenomenon takes place for Z(i).

21. The argument given above assumes that units' idiosyncratic shocks are independent
      from their bandwidths. If v and A are correlated, the perverse effect described above
      may still happen. One exception, though, is when the v,(t)'s are identically distributed
      except for a scale parameter that is proportional Aj;in this case adding idiosyncratic
      shocks to differences in bandwidths always speeds up convergence. This follows from
      Proposition A4 and the Glivenko—Cantelli Theorem.

22. This step is based on Fubini's Theorem. It is here where we use the assumption that
      the Fourier coefficients of X are summable.

                                             33
23. If A A we let vs/A play the role of v.




                                         34
                           la
                           C
                           (V




                    2
              ——

-1.6   —1.2   -OS   —0.4        —0.0    0.4   0.0   1.2   1.6




                           lb




                    FIGURE             lc
                                         2[a]
      rq            I       __
                                 I   -I-
4-)   Cu                                                      a(t]=0 05t
NJ                                                      - - - aCt)=0.lOt
                                                              zero
      LI)
      D




                                         2[b]
      CD
      0




      0
      Cc?


            0           2        3   4    b     6   7        8       9     10
                                          t
                1




                                         2[c]
      CD
      c
      0
      m
      0
      0
      0
      q
      00        1       2        3   4     5    S   7        8       9     10
                                           t
                                         2Cd]
      0?
      0
      CD
      0
      0
      p
                        2        3   4     5    6   7         8      9      10
                1

                                           t
                                     3[aJ
      0
      ci
      ('4
      Q
4.)
      0
N     C




      0
      C\J

      0     0.05   0.10   0.15   0.20 0.25 0.30 0.35 0.40 0.45 0.50
                                       a

                                     3[b]
      c:i
      0
      C',
4-)   0
—)



      0
      I-
            0.05 0.10     0.15   0.20 0.25 0.30 0.35 0.40 0.45 0.50
                                       a

                                     3(c)
      (1
      0



*1          0.05   0.10   0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50
                                      a

                                    3(d)
      0)
      0
      CD
      0
      0
      0
      ci
            0.05 0.10     0.15   0.20 0.25 0.30 0.35 0.40 0.45 0.50
                             4
    a


    a


    0


    .4
    0
*
    •1
    0


    a

                                           I            11=0.0
    0                                               —


    0
    0
         0   2   4   8   S                                       20
                             t
                                 12   14       16        15
