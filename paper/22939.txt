                             NBER WORKING PAPER SERIES




      ASYMMETRIC EFFECTS OF NON-PECUNIARY SIGNALS ON SEARCH AND
        PURCHASE BEHAVIOR FOR ENERGY-EFFICIENT DURABLE GOODS

                                     J. Scott Holladay
                                      Jacob LaRiviere
                                   David M. Novgorodsky
                                       Michael Price

                                     Working Paper 22939
                             http://www.nber.org/papers/w22939


                    NATIONAL BUREAU OF ECONOMIC RESEARCH
                             1050 Massachusetts Avenue
                               Cambridge, MA 02138
                                  December 2016




We thank the Baker Center at University of Tennessee and Becker Center at University of
Chicago for funding support and help in executing the experiment. Wooju Lee provided excellent
research assistance. We thank our private and public sector partners for their support. Ben
Gilbert, Michael Greenstone, Grant Jacobsen, Steven Levitt, John List, Preston McAfee, Justin
Rao, and Dmitry Taubinksy and seminar participants at the 2014 EEE NBER Summer Institute,
2014 ERE World Congress, 2014 Camp Resources, 2015 AEA meetings, 2015 Fall APPAM
Conference, University of Wyoming and UC Davis all provided important feedback that greatly
improved this paper. Any mistakes are ours. The views expressed herein are those of the authors
and do not necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2016 by J. Scott Holladay, Jacob LaRiviere, David M. Novgorodsky, and Michael Price. All
rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without
explicit permission provided that full credit, including © notice, is given to the source.
Asymmetric Effects of Non-Pecuniary Signals on Search and Purchase Behavior for Energy-Efficient
Durable Goods
J. Scott Holladay, Jacob LaRiviere, David M. Novgorodsky, and Michael Price
NBER Working Paper No. 22939
December 2016
JEL No. C93,D01,D83,Q41

                                         ABSTRACT

We report the results of a field experiment where we exogenously vary the use of social
comparisons "nudges" and subsidies for participation in an in-home energy audit program, and
follow subjects through to the subsequent purchase of durable goods. We therefore can compare
the causal effect of financial incentives and nudges along two margins, audits, which we liken to
search, and purchase of durables. Using data on nearly 100,000 households, we document an
asymmetry; nudges increase audits, but lead to lower rates of purchase. We find no evidence of a
differential response for those offered a financial incentive. These differences suggest
heterogeneity in the motives of the marginal consumer induced by nudges versus prices.


J. Scott Holladay                               David M. Novgorodsky
The University of Tennessee                     University of Chicago
515 Stokely Management Center                   Saieh Hall for Economics
Knoxville, TN 37996                             1126 E. 59th St.
jhollad3@utk.edu                                Chicago IL, 60637
                                                davidnov@uchicago.edu
Jacob LaRiviere
Microsoft                                       Michael Price
Department of Economics                         Experimental Economics Center
University of Tennessee                         Andrew Young School of Policy Studies
525 Stokely Management Center                   Georgia State University
Knoxville, TN 37996-0550                        P.O. Box 3992
jlariv@microsoft.com                            Atlanta, GA 30302-3992
                                                and NBER
                                                mprice25@gsu.edu
1        Introduction

There is a growing body of literature documenting that individuals respond to social comparisons

that provide informative signals about the actions or beliefs of reference groups. Specifically, such

messages have been shown to influence a wide array of activities from residential electricity and

water use (Allcott, 2011; Brent et al., 2015; Costa and Kahn, 2013; Ferraro and Price, 2013; Gromet

et al., 2013; Ito et al., 2013; Schutlz et al., 2007) to charitable giving (Chen et al., 2010; Frey and

Meier, 2004; Shang and Croson, 2009) and retirement savings (Beshears et al., 2015; Esther Duflo,

2003). To date, this literature has focused predominantly on decisions along an intensive margin

(e.g., changes in electricity use, changes in water use, or average contribution levels). A less studied

question is the impact of such signals on patterns of information acquisition and subsequent decisions

along an extensive margin (e.g., the purchase of energy-saving technologies).

        In this paper, we report the results of a natural field experiment designed to link the content of a

targeted advertisement to search intensity and search to subsequent purchase decisions. Our context

is participation in a utility-sponsored in-home energy audit program (IHEA) and the resulting

purchase of energy-efficient durable goods.1 We compare the relative impact of pecuniary incentives,

in the form of randomly-varied subsidies2 , with the effects of informative nudges in the form of social

comparisons that vary the unit of comparison (e.g., monthly kWh of use, monthly expenditures

for energy, or CO2 emissions due to energy use) on the likelihood a household signs up for an

IHEA (e.g., search for information about energy savings) and subsequently purchases a range of

energy-efficient durable goods.


    1
     We view participation in an IHEA as an act akin to costly search behavior: a household must pay a cost (in both
money and time) to reduce uncertainty in the expected monetary benefit of a durable good investment. In doing so,
we build upon prior work showing that many individuals systematically underestimate the relative energy intensity of
many durables in the home (Attari et al., 2010) and a related body of work showing that individuals have difficulty
calculating the long-run cost savings from purchasing energy efficient durable goods (Allcott and Greenstone, 2012).
   2
     We use the terms “subsidy” and “rebate” interchangeably throughout.




                                                         2
       In the field experiment, we partnered with a utility and electricity wholesaler to send letters

encouraging the household to sign-up for an in-home energy audit. Our experiment was conducted in

a medium-sized metropolitan statistical area (MSA) in the southeastern United States and includes

information on IHEA participation for a large control group that did not receive any letter or

encouragement to schedule such. During the experiment, we mailed letters to approximately 51,000

residential consumers over five waves. All letters stated that any durable good purchases by the

household that satisfied a broad range of criteria would be eligible for a rebate that provided a

dollar-for-dollar subsidy on the first $1000 spent on eligible durables (i.e., households that completed

an IHEA would be eligible for a $500 rebate on durable good purchases).3

       Our experiment includes 12 different treatments arranged in a four-by-three design. Each

household in the treatment group received a letter with one of four possible signals of historical

electricity use and one of three possible rebate levels offered for scheduling an IHEA. The signals

can broadly be delineated by: a) whether or not a household’s own use was presented together with

average historical use in their nine-digit zip code (No Comparison vs. Comparison), and b) the

unit used to convey historical use (monthly kWHs, monthly expenditures on electricity, or CO2

emissions).4 Households receiving the No Comparison letter were provided information on their

average monthly consumption in kWhs over the prior twelve month period. Households receiving

one of the Comparison letters were provided this same information along with information on the

average monthly use of counterparts in their local area. Information in the Comparison treatments

was conveyed in one of three forms; (i) monthly kWhs consumed, (ii) monthly expenditures in

dollars, or (iii) pounds of CO2 attributable to their monthly electricity consumption. We cross the

comparison types with treatments that offer the recipient a $20 or $50 gift card that can be used to


   3
    Eligible durable goods include new energy-saving windows, insulation, duct sealing, etc.
   4
    We use nine-digit zip code averages for the local areas with 10 or more households. For smaller nine-digit zip
areas we use five-digit zip averages. Throughout, wherever we refer to nine-digit zip codes, this caveat applies.



                                                        3
offset the cost of the IHEA which was $50 over the entirety of the study period. In this regard, our

subsidy treatment introduced random variation in the price of the audit.

       Our design and context allow us to overcome several challenges faced in prior work exploring

the role of targeted messages (advertisements) on the economic behaviors we study. First, our

design permits us to separately estimate the effect of the informational content of a message (i.e.,

a description of the program or information about a household’s average electricity use) and the

marginal effect of augmenting such messages to include a social comparison (i.e., information that

compares one’s own actions to the actions of like others) on search behavior. Second, we are able to

place a monetary value on social comparisons by comparing the effects of these treatments to the

effect of changing the price of the IHEA in our No Comparison treatment. Third, households in our

subsidy treatment were required to schedule the IHEA within thirty days of receiving our letter to

qualify for the gift card. By design, our program places a time limit on potential treatment effects

which allows us to circumvent the challenge of open-ended search (Lewis and Rao, 2015). Finally,

while the regional wholesaler schedules initial audits and provides a list of approved contractors, they

do not follow up with households to encourage them to complete the recommended installations; it is

the household’s responsibility to qualify for the $500 rebate. Our context is thus an ideal setting to

observe the impact of our treatments on both search intensity and subsequent purchase decisions.5

       We find three main results for treatment’s impact on IHEA uptake. First, receiving a letter

that provided information on the IHEA program and a household’s average consumption, but no

nudge or subsidy, had no significant impact on IHEA uptake. Second, “nudges” in the form of

social comparisons are an effective strategy for promoting IHEAs. Households that receive either

a kWh or expenditure comparison were more than twice as likely to schedule an IHEA than are


   5
    In this regard, our approach differs from the IHEA program studied in Allcott and Greenstone (2015) which
provides more support for households following the initial audit as a way to increase both participation in the IHEA
and subsequent purchases.



                                                         4
counterparts in the control group. Finally, consistent with the literature we find demand for IHEAs

is somewhat inelastic: subsidizing audits led to statistically significant increases in IHEA rates,

but even when audits were costless in monetary terms ($50 subsidy) rates were still low. We can,

though, price out a kWh and expenditure comparison to be $35-$50 in subsidies based upon our

point estimates in terms of IHEA uptake.

   With respect to durable good purchases, we find that households in the both the kWh and

expenditure treatments were less likely to make an installation than were counterparts in the control.

Importantly, these differences hold whether we examine installations conditioned on completing

an IHEA or examine the unconditional effect of treatment on the purchase decision. Conversely,

purchase rates for households in our subsidy treatments are statistically indistinguishable from those

observed amongst the control group. Taken jointly, these differences suggest heterogeneity in the

motives of the marginal consumer that is induced to take the audit across treatments. We find

evidence that nudges were less effective at inducing installations than subsidies but more effective

at leading to additional audits.

   The findings highlight that what motivates the marginal auditor (e.g., search behavior) versus

the marginal durable goods installer (e.g., purchase behavior) can vary as a function of pecuniary

and non-pecuniary signals. For example, in our experiment a $50 subsidy and kWh comparison had

similar impacts on IHEAs but different impacts on durable good purchase. Our finding is consistent

with there not being a one-to-one mapping between social comparisons and price signals across

all microeconomic behavior. We don’t view this finding as particularly surprising however as the

literature remains unsettled as to all the precise mechanisms through which social comparisons

operate despite recent advances (Allcott and Kessler, 2015).

   The next section motivates IHEAs as a form of search and describes the field experiment. Section

3 presents data. Section 4 presents results and offers discussion. Section 5 briefly concludes.



                                                  5
2        Audits as Search

We follow Gilbert et al. (2015) and argue that IHEAs are a form of search. The canonical search

literature motivates search in the context of a consumer acquiring product information via brick and

mortar shopping before making a purchase (Rothschild, 1974). However, brick and mortar shopping

is not the only way an individual can engage in search. Seeking expert advice can also be modeled

as a form of search (e.g., Pitchik and Schotter (1987) and Edo and Szentes (2007)). In such models,

the agent seeking advice is uncertain about the state of the world but can learn about it by paying

for an informative signal from an expert. As a result, the agent undertakes a costly action – paying

an expert – as a way to acquire information before making a purchase decision.

        When a consumer signs up for an IHEA, they are seeking expert advice about the benefits of

making an investment in an energy-efficient durable good. During an IHEA, a paid professional

enters a home and uses specialized equipment to identify a range of durable good investments that,

if made, would allow the household to save electricity and get the greatest possible return on their

investment.6 However, many individuals may incorrectly perceive the relative energy intensity

of many actions within the home (Attari et al., 2010) or have difficulty calculating the long-run

cost savings from purchasing energy efficient durables (Allcott and Greenstone, 2012; Palmer and

Walls, 2015). An important function of an IHEA is that the auditor helps resolve such uncertainty

and, in doing so, better anchors a household’s expectations about the net present value (NPV) of

investments in various durable goods.7

        Our experimental treatments are designed to introduce variation in the expected net benefits of

scheduling an audit and/or introduce new motives for search (social norms). In the Appendix, we


    6
     Auditors may also provide advice on ways to reduce electricity consumption without changing the stock of durable
goods in the home - e.g., by setting thermostats at a higher temperature during summer months.
   7
     While McKinsey (2009) documents large variability in the implied rate of return across the spectrum of durable
good investments that may be suggested to a household during an IHEA, auditors in our study area limit suggested
installs and recommend 3 to 5 items that are ordered based on the implicit rate of return.


                                                         6
walk through a simple theoretical model of audits as a form of search in line with Gilbert et al. (2015).

We also discuss our ability to parse between the various channels through which our treatments

shift expected audit benefits in greater detail below. For example, variation in the framing of the

social comparison allow us to measure whether households weigh information differently when it

highlights expected private benefits (expenditures) as opposed to public benefits (carbon emissions)

on search and associated changes in consumption.

   There are direct links between our study and measuring the returns from advertising. In general,

there are two key challenges to measuring returns to advertising. The first is the data challenge of

linking exogenous variation in advertising to revealed preference data on search and subsequently

revealed preference sales data. The second is the nature of search and purchase: especially for high

cost items like durable goods there is a significant amount of search so that even after an advertising

campaign, a household may delay their purchase of a good while gathering information. Our field

experiment, described in the next section, allows us to overcome both of these problems for three

reasons. First, we randomly vary both the price of search and non-price signals (e.g., nudges) and

are able to use administrative records to link treatment to a particular customer. This allows us to

identify and directly compare the effect of the various messages on search intensity and subsequent

purchase decisions. Second, we exploit a key feature of the IHEA program to track both search (e.g.,

audit uptake) and purchase (e.g., home durable good upgrades) for the same user over time. In

our study region, households were required to have a third party auditor verify installations if they

wished to claim the available rebates on purchase. We are thus able to identify treatment’s impact

on search and purchase behavior using administrative records. Third, our pecuniary treatment,

audit cost subsidies, sets a bound on the maximum length of time available to subjects to redeem

the subsidy. From a design perspective, then, we are well-suited to address time lag challenges

noted in the literature and identify the effects of our treatments on both search intensity and the



                                                   7
resulting purchase decisions (Lewis and Rao, 2015).

    It is also important to place our paper in the context of the larger literature on nudges and

economic behavior. There is a growing body of literature showing that social norms and specifically

“nudges” in the form of social comparisons can be used to change patterns of electricity and water

consumption (Allcott, 2011; Costa and Kahn, 2013; Brent et al., 2015; Ferraro and Price, 2013; Ito

et al., 2013; Wichman et al., 2016). Moreover, given results from Ferraro et al. (2011), Bernedo et al.

(2014), Allcott and Rodgers (2014) and Dolan and Metcalfe (2015) showing that social comparisons

can have persistent effects on patterns of electricity and water use, it is reasonable to posit that

such signals may influence patterns of search and subsequent purchase of more efficient durable

goods rather than exclusively working through long-run changes in behavior. We investigate this

directly in our paper by focusing on energy-efficient durable good upgrades.

    We investigate nudges’ ability to cause households to invest in the energy efficiency of their

home, and in doing so add to the nudge and social norm literature in several novel ways. First,

we investigate IHEAs and durable good investment decisions available to all households- not just

low income households as in Fowlie et al. (2015). Second, our treatments exogenously vary the use

of nudges, the form of nudges (private versus social frames) and the price of IHEAs providing an

apples-to-apples comparison of nudges in terms of dollars. Third, because we follow subjects through

the audit process to purchase, we can determine if subjects “nudged” into audits behave similarly

in purchase space as subjects “priced” in through subsidies. Fourth, because we use comparisons

highlighting both private aspects ($ and kWh) and public aspects (CO2 ) of electricity consumption

we are able to identify how framing of nudges impacts their effectiveness in the context of IHEAs.




                                                  8
3        The IHEA Program and Experimental Design

IHEAs are widely-available programs in which a trained expert with specialized equipment examines

a home and recommends the most cost-effective investments a household could make to save money

on electricity bills. Local utilities and policymakers across the U.S. have implemented a range of

programs designed to increase the rate of IHEAs as a means to stimulate the purchase of energy-

efficient durables (e.g., NYSERDA, TVA Energy Right, New Jersey Clean Energy Program, and

Mass Save, among others) to reduce demand for electricity and mitigate externalities associated

with its consumption. Our study area is reflective of this national trend. Like other areas, our area

exhibits annual rates of IHEAs that are low (less than 1 percent), which has prompted the regional

wholesaler to pursue a variety of ways to increase participation including the ideas tested in our

experiment (Palmer and Walls, 2015).

        Our field experiment was conducted with the support of an electric utility and their primary

wholesaler which funds and administers the IHEA program. The program is branded and passively

advertised on the utility’s website.8 At the time of our experiment, the only way to schedule an

audit was for a customer to call a hotline managed by the regional wholesaler and arrange for an

auditor to come to their home at a predetermined time. At the end of the experiment, we were

provided the universe of call logs for our sample area. This allows us to observe and record all

audits scheduled in our sample area during the course of our experiment.

        During an audit, a professionally trained auditor comes to the customer’s home and performs a

visual inspection.9 The auditor typically inspects the home’s attic, basement and HVAC system.

At the time of our experiment, the audit took approximately half an hour to complete and the


    8
     Over the course of our experiment, there was no change in the marketing of the program by either our partner
utility or the wholesaler.
   9
     Some IHEA programs use trained engineers and infrared cameras or blower door tests to find sources of energy
leakage. The program we investigate is intended to be a low cost, less time-intensive audit and provides more general
information.


                                                         9
homeowner was required to be present during this time. The audit cost $50 but the amount was

refunded if the customer made a recommended investment.

       At the end of the audit, the auditor presented the customer with a list of suggested investments

that could include improved insulation in the attic, replacing windows or sealing HVAC system

ducts. Each customer was presented with the same list of potential investments and provided

informal suggestions about which investments were likely to provide the greatest return for them

specifically. In addition, customers were provided a list of approved contractors who could perform

the work and informed that they would receive a dollar-for-dollar subsidy of up to $500 for any

investment on the list.

       To receive the durable good subsidy, households were required to schedule a follow-up audit and

provide confirmation from the auditor that the installation was done properly. The follow-up audits

were scheduled by phone and noted in the log book as a verification appointment. As a result, we

have administrative records on both audits and subsequent purchases in the audit program.


3.1       Experimental Design

As noted above, our field experiment was conducted with the support of an electric utility and their

primary wholesaler. Our sample area was a medium-sized MSA in the U.S. served almost entirely

by the same utility.10 The goal of the field experiment is to identify how subsidies and different

forms of comparative information affect the 1) probability of signing up for an IHEA and 2) the

probability of subsequently making an installation. Importantly, we worked with the utility and the

wholesaler in designing the experiment so as to maintain consistency with their project goals.

       Figure 1 provides a graphical depiction of the timing of subjects’ decisions in our field experiment.


  10
    In this area, the utility provides electricity to all residential customers via average cost pricing; there is no block
structure for residential consumers. During the study period, the retail price of electricity for households was constant.




                                                            10
As noted in the figure, households were first randomized into either a control group or one of twelve

treatment groups that received a letter inviting them to sign up for an in-home audit. Households

then determined whether or not they wished to sign up for the IHEA and call the auditing agency

to schedule the audit.11 Conditional on completing an audit, households had the opportunity to

purchase and install a range of energy-efficient technologies that were eligible for a rebate from the

auditing agency. To receive the rebate, the household had to schedule a follow-up audit to verify

the installation.

       Our research design compares the relative impact of pecuniary incentives (subsidies that lower

the cost of the IHEA) with the effects of social comparisons that convey relative consumption

from three different frames; (i) average monthly kWh, (ii) average monthly expenditures, and (iii)

CO2 emissions related to average monthly use. The various treatment letters were designed in

collaboration with the regional wholesaler. Because we cannot observe whether letters are opened

or not we estimate intent-to-treat effects (ITTs) in all but one case (probability of installation

conditional on audit).

       Table 1 depicts the four-by-three treatment design utilized in our natural field experiment.

Cell entries reflect a unique treatment letter (described below) and the corresponding number of

households that received the given letter type. For example, the upper left corner of the table

corresponds to our baseline - “No Comparison, No Subsidy” - treatment letter which was mailed to

3,923 distinct households. This treatment compared to the large control group allows us to estimate

the informative effects of the letter on audits and installs. In total, we sent out over 50,000 letters

and observe decisions for a large control group who did not receive a letter during the course of

the experiment. Table 1 also shows statistically insignificant differences in average pre-treatment


  11
    Households in the control group did not receive a letter encouraging them to sign up for an IHEA but had the
same opportunity to participate in the program. Moreover, the procedure for scheduling an audit and the nature of
the audits themselves were identical for households in the treatment and control groups.



                                                       11
electricity usage by subject.

   Treatment letters were printed on the electricity wholesaler’s official letterhead (e.g., the entity

overseeing IHEAs in the area) and sent via first-class mail in envelopes from the wholesaler to

maximize the likelihood that they would be opened by the household and associated with the IHEA

program. Letters were mailed across five waves starting in December 2012 through August 2013.

Our utility partners required the waves to be spread over time to avoid exceeding the capacity of

the existing staff of auditors. Figure 2 shows the wave-by-wave timing in a Gantt chart. While

the figure describes the period of study for subjects getting audits attributable to treatment, for

experimental design reasons discussed below, we observe all installations through mid-December

2013. We provide evidence below that this is sufficient coverage for our experiment.

   Table 2 describes the samples sizes and date of mailing for each treatment wave. It also reports

the number of households in each treatment type in each wave. Each pilot wave has around four

thousand households and the three main waves varied between fifteen and twenty thousand treated

households. In all, approximately 51,000 households are in one of twelve treatment groups in

addition to a large control group of roughly 50,000 households (roughly 10,000 of which are held as

explicitly within-wave control units).

   The sample sizes are nonlinear across subsidy levels to improve power to detect nonlinear

response to subsidy levels; in particular, we employed a weighted design over the various subsidy

levels (25%-50%-25%) which allows us to identify non-linear effects of price on likelihood of signing

up for an IHEA and is the optimal sample arrangement if we believe that the underlying demand

function is quadratic. Waves 1 and 2 did not include CO2 treatment types of any subsidy amount

because of low uptake during the pilots.




                                                 12
3.1.1    No Comparison Letter


Our baseline letter provided households an “information-only” message designed to encourage the

recipient to sign-up for an IHEA (see Appendix). The letter included a brief description of the

IHEA program along with a phone number and web address that the household could use to get

more information about the program. Specifically, the letter describes the IHEA program as follows:

            There’s no place like home, and there’s no time like now to make your home

            more energy efficient. You can conserve energy, save on utility bills, and get

            cash rebates by participating in....

                If you sign up for an IHEA, a ... Certified Energy Advisor will visit your

            home at a time convenient for you. The advisor will recommend cost-effective

           ways to increase your home’s energy efficiency and will install free CFLs and

            low-flow water saving measures if you choose.

                ...evaluation fee is $150 (currently with an instant rebate of $100). And

           you will receive the remaining $50 fee back if you spend $150 or more on

            qualifying improvements. You will also receive matching rebates of up to $500

            for installing eligible improvements....

    In addition to information on the IHEA program, our baseline letter included information on

the household’s average monthly consumption during the preceding year. Such information was

conveyed using a bar chart12 which was a statement reading “...Your average energy consumption

over the past year: XXX kWh...” We calculated average monthly consumption using billing records

shared with us by our partner utility. Specifically, we used monthly billing data for the period July


   12
      This bar chart and those corresponding to our three other content-related treatments are depicted in Figure 3
side-by-side.




                                                        13
2011 through July 2012 to calculate a household-specific measure of average monthly consumption.13


3.1.2      The Social Comparison Letters


We build upon the social comparison and “nudge” literature by augmenting our baseline letter to

include a comparison of the household’s average electricity use to the average use of other households

in their nine-digit zip code.14

       Information in the social comparison treatments were conveyed in one of three forms; (i) monthly

kWhs consumed, (ii) monthly expenditures in dollars, or (iii) pounds of CO2 attributable to

their monthly electricity consumption.15 We chose these three frames to identify if households

respond to nudges which make different aspects of electrity consumption more or less salient: use

(kWh), expenditures ($) or a public bad associated with electricity consumption (CO2 emissions).

Differential responses for search and purchase due to different frames would provide information

about what aspects of a nudge induce subjects into changing their behavior. We included a bar

chart to illustrate the comparison graphically. Below the bar chart, we included a statement reading:

             Your Average Energy Consumption                              XXXkWh

             Local Area Homes’ Average Energy Consumption                  XXXkWh


             You used XX percent more (less) energy than other area homes

       Our choice of nine-digit zip rather than a higher level of aggregation as the comparison group

was informed by a large body of work in social psychology showing that comparative signals are


  13
     Households in our sample area receive bills from our partner utility on a monthly basis. While monthly bills
display consumption for each of the previous 12 months, they do not provide information on average consumption
over the period.
  14
     Recall that for subjects with fewer than 10 households in a nine-digit zip, we used five-digit zip code averages.
  15
     To our knowledge, ours is the first paper to explore how varying the way in which comparative information is
framed impacts subsequent behavior. While Allcott and Greenstone (2015) present results from a field experiment
that uses a variety of “nudges” to induce participation in an IHEA program, the aim of their paper is to quantify
the welfare implications of such programs rather than explore whether and how such strategies influence patterns of
search and subsequent purchase decisions.




                                                         14
most effective when the reference group is more proximate to the individual receiving the signal (e.g.,

Trope and Liberman (2010).) We framed the percentile text depending on whether a household

used more or less electricity than their local area. We interpret such framing as a way to emphasize

how many people do or do not engage in the targeted behavior (e.g., Cialdini et al. (2006) and

Schultz et al. (2007))


3.1.3      The Subsidy Letters


Our final treatment dimension is designed to introduce experimental variation in the expected net

benefit of an in-home audit. To do so, we augment the baseline and social comparison letters to

include a rebate for households that sign-up for an IHEA. Specifically, our subsidy treatments offered

the recipient a $20 or $50 gift card that could be used to offset the cost of the IHEA. Information

about the subsidy was included in the final sentence of the third paragraph which in part reads:

             As an additional thank you for participating, if you have an In-Home Energy

             Evaluation within 30 days from the date of this letter you will receive a $XX

             gift card.

       Before proceeding to the results section, a few key features of our experimental design should

be highlighted. First, within each wave of the experiment, treatment letters were mailed on the

same day.16 Second, there were around 3,000 letters that were returned to sender and thus not

delivered. We dropped these households from our empirical analysis. Third, households that moved

or had their electricity service cut off due to delinquent bills during the course of our experiment

were dropped from the analysis. Finally, all treatment letters included a unique code located at the

bottom left corner. The call center recorded this code when scheduling an IHEA which allowed us


  16
    One minor exeption occurred during the first pilot during which letters were sent across two days - December
18,2012 and December 21, 2012.




                                                      15
to match households that scheduled an IHEA to their respective treatment group.



4     Data and Experimental Results

Each treatment letter had a unique identifier that matched the specific letter (and therefore treatment

group) to an address. We entered into a data sharing agreement with the auditing agency and

wholesaler in order to measure how treatment affected audits and installations. To do so, we first

matched the universe of scheduled IHEAs to the randomized treatment and control assignments

based on the address of the household.17 We next linked audit scheduling with subsequent purchase

decisions, using data from the follow-up audits and the installations verified during this audit.

    Letters in the subsidy treatment contained a clause noting that to guarantee the subsidy the

household had to call and schedule an IHEA within 30 days of receiving the letter.18 Due to a

small number of scheduling conflicts and at the suggestion of the auditor, we honored the subsidies

for up to sixty days of sending the letter. For each household, we thus limit the post-intervention

period to a fixed period of sixty days following the mailing of any treatment letter to estimate upper

bounds for audit uptake treatment effects. All households in the area to whom this utility provides

electricity (approximately 100,000 total) were subject to randomized treatment assignment.

    There are two sets of results from the IHEA field experiment. The first identifies the effect of

treatment on IHEA participation. The second set of results identifies the effect of treatment on

installations. There are two parts to the installation results: how treatment impacts the likelihood

of a purchase and how treatment impacts the timing of installs relative to control households.


  17
     Our randomization was a block randomization on a household’s mean electricity use in the preceding year with
approximate blocking on which decile a household’s mean use in the preceding year falls into among households in its
local area. We summarize the results of this block randomization with the mean pre-treatment use in Table 1 as well
as the distribution of treatment assignment in Figure A5 in the Appendix.
  18
     Importantly, this allows us to verify the effect of advertisements (treatment) on search. Other studies note that
not being able to place time limits on search complicates the problem of estimating the effects of advertisements on
purchase (Lewis and Rao, 2015).



                                                         16
    We performed power tests before implementing our experiment to gauge the likelihood of finding

significant results. The results of those power tests are presented in the Appendix. Due to the stated

experience of the audit providers with advertising campaigns, we designed the experiment to detect

treatment effects which double baseline audit and installation rates. Those results suggest that our

sample size is sufficient to detect effects of treatment when all treatment groups are aggregated

into one group (least granular), as well as when social comparison treatment effects are additively

separable in price treatment effects and vice versa (more granular). We therefore use an empirical

specification which allows a unique estimate for each comparison treatment and each subsidy level

by using indicators for each type of comparison and each level of subsidy (but not the interaction).19


4.1    Search: Treatment on IHEA Uptake

The primary goal of the field experiment is to provide an apples-to-apples comparison of pecuniary

incentives and informative “nudges” on search (e.g., IHEA uptake) and purchase behavior (e.g.,

durable good installation). Given the explicit time limitation built into our pecuniary treatments,

we focus on IHEA uptake rates in the two months following treatment.20 As a result the two month

audit uptake rate is the primary statistic of interest. As a benchmark, the two month audit uptake

rate for households in the meta-control group, the right counterfactual for our analysis, is .0011.

    In Table 3 we report raw 60 day IHEA uptake rates across treatments over the experimental

window.21 Columns show different subsidy treatments and rows show different comparison treatments.

There are several important points regarding Table 3. First, overall effects across all treatments were


  19
     We lack power to estimate 12 unique comparison-subsidy treatment effects to gauge the impacts of the interaction
of comparison and price effects but report those results in the Appendix for completeness; they are consistent with
the main results presented here and statistically significant in several cases.
  20
     Recall that, by design, households in our subsidy treatments had to schedule an IHEA within 30 days of receiving
the letter to be eligible for the gift card.
  21
     Note that Table 3 (as well as 4) drops eight IHEAs unmatched because they either occurred during a break in the
billing time series or occurred precisely on the last day of a household’s final bill in the time series.




                                                         17
modest, not quite doubling two month uptake rates (.0019 relative to .0011). This is consistent with

the larger literature on audit uptake which finds inducing additional audits is challenging (Fowlie et

al., 2015; Palmer and Walls, 2015). Second, the “No Comparison-No Subsidy” treatment, which

only included information on the audit itself, did nothing to increase uptake and potentially even

decreased audit uptake (.0008 versus .0011). We don’t view this as strong evidence on a significant

decrease, though, given the relatively small size of the “No Comparison-No Subsidy” treatment

cell. Third, expenditure and kWh comparisons both have a positive impact on IHEA uptake and

those impacts are identical. CO2 comparisons look to have a no impact on IHEA uptake. This

is consistent with findings from the larger literature that social comparisons can induce economic

action (Allcott, 2011; Ferraro and Price, 2013) but that different frames can asymmetrically impact

behavior (Chen and Li, 2009; Chen et al., 2010). Fourth, subsidies increased IHEA uptake but not

by as much as comparisons, and there is no consistent evidence for an impact of moving from the

$20 to $50 subsidy. This third and fourth point taken together imply that some social norms can be

more valuable than either a $20 or $50 subsidy.

       To examine the statistical significance of these findings and control for seasonality/differences

in IHEA participation across waves of the experiment, we proceed from the suggestive results in

Table 3 to regression-adjusted results. In such models, we separately estimate the average ITT

effect of receiving any letter (which we typically associate with a variable called Any Letter) and

the marginal ITT effect of different content framings (which we typically associate with a set of

variables called kWh Comparison, $ Comparison, and CO2 Comparison).22

       In the estimation we collapse the panel data series to a cross sectional data series with wave-level


  22
    While our interest is in analyzing search, we are evaluating a relevant policy instrument at the same time. In
this vein, note that with any mailing, no amount of targeting on the part of policymaker solves the unobservable
opening of mail, so the ITT effect is also a policy relevant treatment effect. Nonetheless, our coefficients inevitably
underestimate the average treatment effect on the treated.




                                                          18
treatment and control audit uptake indicators defined to give an apples-to-apples comparison

between treatment and control groups given both multiple treatment waves and limited treatment

windows to schedule an audit (e.g., 60 days). We’ve estimated the same specification at the month

level and all results are similar but we view this as conceptually easier to interpret. We also use

the entire set of super-control households randomly assigned to different waves. This gives roughly

99,000 subject households in the full estimating sample. In sum, we perform our main estimating

specification via a cross-sectional OLS regression:




                                                                  X
      1{IHEAi } = α + ωw + νtz + 1{Any Letteri }γ +                             1{f Comparisoni }βf
                                                            f ∈{kWh, $, CO2 }

                   + 1{$20 subsidyi }δ1 + 1{$50 subsidyi }δ2 + i .                                   (1)



1{IHEAi } is an indicator which denotes whether household i conducted an IHEA with two months of

being treated. 1{Any Letteri } is an indicator variable that takes the value of one if a household was

randomized to receive any letter. A similar definition applies for each framing f in 1{f Comparisoni }

which allows for estimation of the marginal effect of each comparison on IHEA uptake. To explain

wave-specific variation in IHEA rates, we include wave fixed effects ωw . To explain some time-series

and spatial variation in IHEA rates and improve the precision of the estimated treatment effects, we

also include fixed effects νtz capturing features of the particular month in which the audit occurred

(t) and the particular five-digit zip code (z) where the household is located. This technique assures

proper weighting of control households and that treated households are never grouped as control

households (e.g., in the 61st day after a letter).

   Given our baseline specification, the coefficient γ is the “pure information” effect of receiving any

letter (e.g., without a social comparison) on bi-monthly IHEA rate. βf describes the marginal effect



                                                     19
for each framing f ∈ {kWh, $, CO2 } - i.e., it captures the effect of the given framing in addition to

the pure information effect associated with receipt of a letter. Looking beyond non-pecuniary effects,

our baseline specification also allows us to estimate the causal effect of subsidies on IHEA uptake by

an indicator variable for each subsidy level (e.g., 1{$20 subsidyi }). Importantly, this specification

will allow us to identify the dollar-equivalent of a comparison (i.e., a “nudge”) by comparing the

marginal effect of a subsidy to each βf .

   Table 4 shows the coefficient estimates from estimating equation (1). We estimate the ITT effect

for the full sample in columns 1 and 2. Column 1 does not include controls for waves (ωw ) or for

audit month-of-year by 5-digit-zip (νtz ) fixed effects whereas column 2 does. Differences in sample

sizes are driven by singleton households within the fixed effects. We report results for specifications

that parse the sample above and below median electricity use within a local area (columns 3 and 4)

and above and below median electricity use for the sample area as a whole (columns 5 and 6). Such

specifications allow us to explore whether the effects of our treatments differ across high and low

user groups. We note, though, that parsing the sample in this way greatly reduces statistical power

so we consider those results to be suggestive only. In each specification we use heteroskedasticity

robust standard errors.

   For the full sample without controls (column 1) and with controls (column 2) we find that the

pure information treatment effect γ is an imprecisely estimated zero. Moving to marginal effects,

we find positive and significant effects of both the kWh and expenditure comparisons. The point

estimate of both kWh or expenditure comparisons are more than double that of the control group

in Column 1. Moreover, as in the raw data, we find no effect of a CO2 comparison on uptake. We

emphasize that these impacts are the marginal impact of a comparison relative to the exact same

information, including a subject’s own average energy usage, in the treatment letter. Parsing the

sample by above and below local (nine-digit zip) and MSA medians the effect of dollar comparisons



                                                  20
remains significant but only for energy users below the median. Subsidies had an impact for above

MSA-median households, though. While suggestive, due to lack of statistical power we don’t claim

strong inference from this result.

   The impact of subsidies is positive but somewhat less consistent than the impact of social

comparisons. A $20 subsidy has a positive and statistically significant impact on IHEA uptake in

the regression without controls but becomes insignificant in the specification with controls. The

opposite is true for the $50 subsidy: it has an insignificant impact on IHEAs without controls and

significant with controls. We favor the regression with controls (column 2) since fixed effects increase

the signal to noise ratio in treatment.

   The subsidy results in column 2 are consistent with economic intuition on subsidies and the

effectiveness of nudges. First, the point estimate for a $20 subsidy is less than a $50 subsidy.

However the two coefficients are not statistically different from each other. Second, we find that

point estimates for the statistically significant results in columns 1 and 2 put to dollar value of

either a kWh or expenditure ($) comparison at between $35 (column 1) and $50 (column 2). This

dollar value of a nudge is consistent with what we observe when we estimate this regression as a

panel (results available upon request and presented in earlier versions of this paper).

   In sum, we find that non-pecuniary signals (expenditure and use comparisons) significantly

increase search intensity (audit uptake) in our experiment. Further, our results suggest that the

framing of the non-pecuniary signals mattered; only privately framed comparisons increased audit

uptake. CO2 comparisons have no statistically significant impact on IHEA uptake. We note that

we are somewhat less confident in this CO2 comparison result given there were only half as many

households in the CO2 treatment. We view this as important, though, because there is evidence

that the type of framing matters and our result is consistent with that (Chen and Li, 2009; Chen et

al., 2010; Costa and Kahn, 2013).



                                                  21
       We acknowledge that monthly IHEA uptake is small in both our study area and the nation

(Palmer and Walls, 2015). Hence, even though our field experiment increased IHEA rates by over

100%, we still have few households conducting IHEAs. To place these effect sizes in context, our

IHEA uptake rates are actually similar to click-through rates for online banner advertisements

(Lewis and Rao, 2015). Even with over 50,000 households in the treatment, treatment induced 80

additional IHEAs. This is no surprise: even when fully subsidized, IHEAs impose a time cost on

households. For example, DellaVigna et al. (2016) find that households’ time costs to be surveyed in

their homes are on the order of $35/hour. IHEAs must be scheduled in advance and, as mentioned

earlier, take roughly half an hour to complete. Thus, even when there is no expenditure for an

IHEA, there is still a non-trivial price for this kind of search. Taken at face value, our estimates

suggest that subsidies would need to be on the order of $67.50 in the location of our field experiment

in order to make IHEAs “free” for households (e.g., $67.50 = $50 IHEA price + $17.50 time cost).

       These results allow us to perform a back-of-the-envelope calculation (assuming out point estimates

are externally valid) to determine the implied cost of this policy if it were widely implemented.23

We sent out out roughly 50,000 letters at 45 cents per letter (in 2012) for a total cost of $22,500.

Each audit therefore had an implicit cost of roughly $281. There are two ways to reduce this cost.

First, sending the letters by bulk would halve costs. Assuming bulk mail is opened at the same rate

and by the same types of households as first class mail, the costs drop to roughly $140/audit. Now

assume that instead of sending each treatment, only the most effective treatments were sent: either

kWh or expenditure comparisons and a $50 subsidy. Recalling that roughly 60% of households got

either a kWh or expenditure comparison, and only a small fraction both the $50 subsidy and a kWh

or expenditure comparison (e.g., .60*.25 = .15), the implied cost of using an optimized version of


  23
    Note that this back-of-the-envelope is not necessarily of scientific interest given that we care about installations
and not audits per se.




                                                          22
this policy is roughly $85 per audit. Paying the $50 subsidy increases the price of an audit using

this policy back to $135 per audit.


4.2    Purchase: Treatment on Installs

Next we test for treatment’s impact on installing a new durable good. Juxtaposing treatment’s effect

on durable good purchases with treatment’s effect on search in a unified field experiment is the main

contribution of the paper. Our context is also important for policy - if households in the treatment

group are more likely to sign up for an IHEA but less unlikely to actually make an installation, it

would suggest that both non-pecuniary signals (“nudges” in our case) and pecuniary incentives for

IHEA participation are cost-ineffective ways to induce households to make large energy-efficient

durable good upgrades. As a result, we focus on the behavior of “nudged in” subjects versus “priced

in” subjects versus control subjects in terms of installation behavior.

   As a first step we investigate the timing decision of treated versus control households who make

installations relative to when they schedule an audit. This provides a view of not just total effects

on installations but also to possible differences in those mechanisms. This is also important to

verify the internal validity of the experiment: our installation data are through Dec 15, 2013 and

the final wave of letters was sent on August 12, 2013. If there is a significant time gap between

audits and installations we may not have complete coverage and thus underestimate the likelihood

of installations. We investigate the impact of treatment on installations in great detail below, but

note that the likelihood of an installation conditional on an audit in control households is roughly

66%.

   Figure 4 is a histogram illustrating the number of days between an initial IHEA and an

installation for all households in the experimental sample making an installation. The figure shows

two important characteristics of installation behavior: first, almost 50% of installations occur on



                                                 23
the same day as the audit. Second, almost all installations occur within three months of the initial

audit. This is reassuring given our data only runs for 120 days after the final wave of letters was

sent and the letters stated audits must be scheduled within 30 days of treatment.

   Table 5 parses average installation timing by treatment and control group. Control households

have an average delay between initial audit and install of 41.5 days and treated households 27.6

days. This difference is preserved when only including the pilots and waves one and two. This

shows weak evidence that treatment decreases time to make an install. We exclude regression

results but note similar findings with statistically significant negative differences at the 10% level

for kWh comparisons only. This is consistent with the idea that treated households view the audit

and installation procedure as more salient: treated households act more quickly than untreated.

While we acknowledge truncation of the data in December 2013 would lead to downward bias in the

likelihood of installations conditional on an audit, we view these results as strong evidence we have

very good coverage of treated installations.

   Turning to treated households’ propensity to make durable good purchases, we estimate treat-

ment’s effect on durable good purchases in two ways. First, we estimate the unconditional effect

of treatment on making an installation for all households in the sample. Second, we estimate the

effect of treatment on installations conditional on households who scheduled audits. While the first

specification captures the policy relevant effects, we believe that the second is more interesting

from an economic perspective. Specifically, the second specification allows us to derive an apples to

apples comparison of the likelihood of making a durable good purchase for control subjects who

self-select into an IHEA and subjects who are “nudged” or “priced” into an IHEA by treatment.

   To identify the unconditional effect of treatment on installations, we estimate the following




                                                 24
model:


                                                                                    X
1{Any Installi } = α + ωw + πm + ηtz + 1{Any Letteri }γ +                                        1{f Comparisoni }βf
                                                                             f ∈{kWh, $, CO2 }

                      + 1{$20 subsidyi }δ1 + 1{$50 subsidyi }δ2 + i .                                               (2)



As before, we study the cross section of roughly 99,000 households who we identified as non-movers.

Collapsing to a cross section handles heterogeneity in the time lag between when a household

schedules their initial IHEA and the final inspection IHEA to verify a installation occurred.24

    The left-hand side variable in equation (2) takes the value of one if a household made an install

at any time during the field experiment. Most of the right-hand side variables are defined as in the

IHEA regression in equation (1): the variable 1{Any Letteri } takes on a value of one if a household

received any treatment letter during the experiment. 1{f Comparisoni } takes on the value of one

if a household received any letter with framing f during the experiment. The subsidy indicators

denote households receiving each of the subsidy levels. Finally, ωw are wave fixed effects, as before.

    We make one alteration and one addition to the right-hand side variables in equation (1). First,

we introduce fixed effects ηtz capturing features of the particular month in which the install occurred

(t) and the particular five-digit zip code (z) where the household is located.25 In addition, we

introduce πm as fixed effects for the number of post-treatment months m ∈ {1, 2, . . . , 12} that

household i had in which to get an install. Together with the wave fixed effects, these πm control

for the variation induced by differential timing of treatment letters.

    While the coefficient α describes the average probability, for a particular subgroup, of making

a durable good purchase over the course of the field experiment, the coefficients γ, βf , δ1 , and δ2


  24
     We’ve estimated alternative specifications in which we don’t collapse to a cross section and also define installs by
treated households in more and less restricted ways. All specifications give very similar results and are available from
the authors upon request.
  25
     This is in contrast to the set of fixed effects νtz for each audit month and five-digit zip pair in equation (1).


                                                           25
capture the marginal impact of any letter, different frames and different subsidy treatments on the

unconditional probability of making an install. We are confident in the quality of our data since any

install must occur after an IHEA in order to be eligible for the $500 rebate in our study area.

   Table 6 reports the estimation results of equation (2). Recall that this specification measures

the propensity for a household to get an install over the entire treatment period, which is roughly

12 months. The audit regressions measured the propensity of households to get an audit over only

two months. As a result, the point estimates measure IHEAs and installs at different time scales

(two versus twelve months). Further, before we include various controls for post-treatment months,

month-of-year-zip, etc. the results aren’t directly comparable. In the raw data we observe roughly

67% of households scheduling an audit eventually getting an install.

   As with the IHEA regressions, we focus on our preferred specifications in columns 1 and 2.

In the first column without controls, there is a highly significant and negative treatment effect of

receiving a letter on getting an install. However, no marginal effects are statistically significant.

The point estimate for the treatment effect for receiving any letter is just over 50% of the point

estimate for install averages over the entire sample (.0016 versus .0028). This is consistent with the

raw data for install probabilities conditional on audits: for control households about 66% of IHEA

households made an install. The install rate for treatment households who scheduled an audit was

roughly 33%. We investigate these conditional installation results further below.

   The significance of the Any Letter coefficient but insignificance of the marginal impacts of

comparisons and subsidies can be explained straightforwardly as a power issue in column 1. Recall

that IHEAs significantly increased in the expenditure and kWh comparisons above. However, given

low installation rates of treated households it is feasible that marginal impacts are not pronounced

enough to be significant without adding additional controls.

   The underpowered explanation for column 1 is supported by results from column 2 which add



                                                 26
the full set of fixed effects. In that column, the first important result is that there is no negative

impact of Any Letter on installations but there is for kWh and expenditure Comparisons. This

implies households who are “nudged” are less likely to make an install than un-nudged households

despite them being more likely to have an IHEA. This asymmetry in search and purchase behavior

is not present in the impacts of subsidies: we find no statistically significant impact of receiving

subsidies on install probabilities. The subsidy estimates are imprecisely estimated zeroes with point

estimates an order of magnitude lower than the comparison estimates. This is informative since the

coefficient on the $50 subsidy indicator was positive and statistically significant at the 5% level in

the IHEA regression. As before, we are cautious to interpret columns 3-6 due to power concerns but

note the broad patterns are shared in those columns.

   The unconditional results show that while both nudges and subsidies are effective at increasing

IHEA, the subsequent behavior of treated households is different. Social comparison treatments

are not effective for increasing installs in our experiment but subsidized households do not install

in a significantly different way than households in the control group. This is consistent with

nudged households having a lower marginal value of installs than households that select to make an

installation on their own. Yet we note that there are a variety of other channels that could be at

play.

   We investigate treatment’s effect on installs further by restricting the sample to only households

who made scheduled audits in our sample and re-estimating equation (2). Trimming the sample

in this way changes the interpretation of the coefficients γ, βf , δ1 , and δ2 . In this specification

they are the average differences across treatment conditions in propensity to purchase a durable

good conditional on a household having scheduled an IHEA. Significant coefficients indicate that

households induced into search behavior by treatment are significantly different in their subsequent

purchase behavior than households who self-select into search.



                                                 27
    Table 7 shows the results of the conditional install regressions. Due to the very small sample

size, we view column 1 as the preferred specification. The estimated constant term in the first

column represents the probability (67.7%) a control household makes any installation after an IHEA.

Households induced into having an IHEA by kWh and expenditure comparisons were less likely to

make any installation than the control group of untreated households who self-selected into making

an installation. There is no statistically significant impact on either subsidy level although point

estimates are negative. Adding fixed effects in column two confirms much of the findings of column

1 despite the small sample size. Thus, the general asymmetry across nudges and dollars is preserved

vis-a-vis installations.

    These purchase results, both unconditional (Table 6) and conditional (Table 7) are somewhat

surprising: the same kWh and expenditure comparisons which led to a significant increase in search

led to a significant decrease in purchase behavior. There are a few possible candidate explanations,

some more plausible than others. First, consider who comprises the set of people eligible to be in

the treatment group: all households who had not scheduled an IHEA or made an install prior to the

our randomization of treatment status. As a result, they are the set of households least likely, in

some sense, to benefit from getting IHEA/install given that the IHEA/install program predated our

field experiment. However, the fact that these comparison effects are net of the pure information

treatment effect suggests that our result is not merely a function of the marginal household being

entirely inelastic. Further, subsidies induce households to audit and install behavior at a rate

statistically indistinguishable from the control group.

    An alternative take on this result is that there is a fundamental discrepancy in what causes

search behavior and what causes purchase behavior. The marginal person induced to search by

an expenditure comparison could be very different from the marginal person who is induced to

purchase conditional on the outcome of that search behavior (e.g., the information revealed in the



                                                 28
IHEA itself). For example, if the mechanism behind increased search is normative guilt, that guilt

could be alleviated by the IHEA. To the extent that such guilt is concentrated among households

that are least elastic on the purchase margin, such a “nudged” household could be less likely to

even consider making a purchase after an IHEA since they are simply focusing on the social norm

during an IHEA.26

         There are myriad other explanations. Our design does not allow us to identify the precise

mechanism at play. More research in the spirit of Allcott and Kessler (2015) would be useful in

understanding “nudges” more precisely along different margins. Our findings highlight, though,

that marginal consumers responding to non-pecuniary signals in search can be different than the

marginal consumer responding to pecuniary signals in search when we investigate the purchase

dimension. This is broadly consistent with other findings that even within the same behavioral

margin the impact of non-pecuniary signals can vary (Costa and Kahn, 2013; Gromet et al., 2013).

In this way it is in some ways unsurprising, but important for policy, that we find evidence that

nudges can be very effective at inducing some economic behaviors but not others.



5         Discussion

We find that non-pecuniary signals in our experiment significantly increased search: households

that received kWh and expenditure comparisons were significantly more likely to schedule IHEAs.

Comparing that to the point estimate for the treatment effect due to subsidies, it amounts to

a subsidy of the IHEA price of $35-$50, although the price effect is not statistically significant.

However, for purchase behavior we find largely the opposite result: conditional on getting an IHEA

and unconditionally, subjects in the expenditure and kWh comparison treatments were significantly


    26
   Similarly, someone clicking on an ad for a product that they were referred to by a friend may simply prefer to see
what their friend suggested rather than even consider purchasing the good.



                                                         29
less likely to make an installation than control households. There is no such divergence in direction

of effect for IHEA subsidies.

    We urge caution in generalizing our results as we study a very specific type of non-pecuniary

information (e.g., comparisons) in only a single scenario. While our results are novel, it is unclear

exactly how portable the results of our non-pecuniary signal are to other types of advertising.

Even other types of audit programs, for example one that provide a higher level of support to

households considering making energy-efficiency installations, could experience different returns

to non-pecuniary information. As a result, further research is needed since ours is a single field

experiment in a single area. To that end, we found that the content of the non-pecuniary signal

matters and simple messages about the existence of the program had little to no effect on search

nor purchase.27

    There are other important implications as well. Consistent with the priming literature, signal

framing matters for microeconomic decision-making like search behavior (Chen and Li, 2009; Chen

et al., 2010). We find that the “nudges” which have been shown to induce changes in electricity

use (e.g., the intensive margin) are not the same nudges that induce longer-lived changes through

expensive durable goods purchases (Allcott, 2011; Costa and Kahn, 2013; Ferraro and Price, 2013;

Ito et al., 2013; Schultz et al., 2007). This is not to say that the effect of nudges on the intensive

margin can’t be long-lived through habit formation or some other mechanism (Brent et al., 2015).

As a result, understanding who is the marginal consumer for “nudges” and in what way they are

marginal will require additional theoretical understanding of the mechanisms at play with different


  27
     While we’ve focused on the private good market implications of our research, there are also public good implications.
Different federal, state and local policies attempt to correct market failure by establishing or completing markets.
Take the example of healthcare.gov as an online marketplace for U.S. consumers to shop for health insurance: much
of the literature focuses on the effect of increased medical care on consumer welfare. We inform a complementary
question: if healthcare.gov is the solution to a market failure, are there effective non-pecuniary strategies to increase
search in addition to enrollment? Further, our results serve as caution against the assumption that strategies effective
at increasing search necessarily increase subsequent purchase.




                                                           30
forms of non-pecuniary signals.

   Our findings, while only a single study, suggest that additional research on the mechanisms

behind non-pecuniary signals’ effects on different but related dimensions of human behavior would

be valuable. The asymmetric effect of different frames offers suggestive evidence about the channel

determining increases in search behavior: privately-framed comparisons (kWh and expenditures),

rather than comparisons highlighting a public good aspect (CO2 ) or “pure information,” affected

search in our context. This result has implications for the channel through which comparisons may

operate. Our results are consistent with both 1) a social norm channel and 2) an information-based

channel in which households infer information about what their use could be based upon averages

in their local area. Finally, given that we provided the same information framed differently, it also

provides evidence of bounded rationality. Nonetheless, it is not clear what caused households to be

“nudged” into IHEAs by kWh and expenditure comparisons. Further work is needed to identify the

precise mechanism. In particular, our findings motivate future work to understand exactly who is

marginal for different kinds of non-pecuniary signals that affect various economic decisions (e.g.,

search, purchase, etc.).




                                                 31
References

Allcott, H. and T. Rodgers, “The Short-Run and Long-Run Effects of Behavioral Interventions:

  Experimental Evidence from Energy Conservation,” American Economic Review, 2014, 104 (10),

  3003–3037.


Allcott, Hunt, “Social Norms and Energy Conservation,” Journal of Public Economics, 2011, 95

 (9), 1082–1095.


   and Judd B. Kessler, “The Welfare Effect of Nudges,” NBER Working Paper 21671, 2015.


   and Michael Greenstone, “Is There an Energy Efficiency Gap?,” Journal of Economic

  Perspectives, 2012, 26 (1), 3–28.


   and    , “Measuring the Welfare Effects of Energy Efficiency Programs,” Working paper, 2015.


Attari, Shahzeen Z., Michael L. DeKay, Cliff I. Davidson, and Wändi Bruine de Bruin,

 “Public perceptions of energy consumption and savings,” Proceedings of the National Academy of

  Sciences, 2010, 107 (37), 16054–16059.


Bernedo, Marı́a, Paul Ferraro, and Michael Price, “The Persistent Impacts of Norm-Based

  Messaging and Their Implications for Water Conservation,” Journal of Consumer Policy, Septem-

  ber 2014, 37 (3), 437–452.


Beshears, John, James J. Choi, David Laibson, Brigitte C. Madrian, and Katherine L.

  Milkman, “The Effect of Providing Peer Information on Retirement Savings Decisions,” Journal

 of Finance, 2015, 70 (3), 1161–1201.


Brent, Daniel A, Joseph H Cook, and Skylar Olsen, “Social Comparisons, Household Water

  Use, and Participation in Utility Conservation Programs: Evidence from Three Randomized


                                              32
  Trials,” Journal of the Association of Environmental and Resource Economists, 2015, 2 (4),

  597–627.


Chen, Y. and S. Li, “Group Identity and Social Preferences,” American Economic Review, 2009,

 99 (1), 431–457.


  , F.M. Harper, and J. Konstan S. Li, “Social Comparisons and Contributions to Online

  Communities: A Field Experiment on MovieLens,” American Economic Review, 2010, 100 (4),

  1358–1398.


Cialdini, Robert B, Linda J Demaine, Brad J Sagarin, Daniel W Barrett, Kelton

  Rhoads, and Patricia L Winter, “Managing social norms for persuasive impact,” Social

  influence, 2006, 1 (1), 3–15.


Costa, Dora L and Matthew E Kahn, “Energy conservation nudges and environmentalist

  ideology: Evidence from a randomized residential electricity field experiment,” Journal of the

  European Economic Association, 2013, 11 (3), 680–702.


DellaVigna, Stefano, John A. List List, and Ulrike Malmendier, “Testing for Altruism

  and Social Pressure in Charitable Giving,” Quarterly Journal of Economics, 2012, 127 (1), 1–56.


  , John A. List, Ulrike Malmendier, and Gautam Rao, “Voting to Tell Others,” Review

 of Economics Studies, 2016, forthcoming.


Dolan, Paul and Robert Metcalfe, “Neighbors, knowledge, and nuggets: Two natural field

  experiments on the role of incentives on energy conservation,” University of Chicago Working

  paper, 2015.




                                               33
Duflo, Emmanuel Saez Esther, “The Role of Information and Social Interactions in Retirement

  Plan Decisions: Evidence from a Randomized Experiment,” The Quarterly Journal of Economics,

  2003, 118 (3), 815–842.


Edo, P. and B. Szentes, “The Price of Advice,” The RAND Journal of Economics, 2007, 38 (4),

  865–880.


Ferraro, Paul and Michael Price, “Using Non-Pecuniary Strategies to Influence Behavior:

  Evidence from a Large Scale Field Expirement,” Review of Economics and Statistics, 2013, 95

 (1), 64–73.


Ferraro, Paul J., Juan Jose Miranda, and Michael K. Price, “The Persistence of Treatment

  Effects with Norm-Based Policy Instruments: Evidence from a Randomized Environmental Policy

  Experiment,” American Economic Review, May 2011, 101 (3), 318–22.


Fowlie, Meredith, Michael Greenstone, and Catherine Wolfram, “Are the non-monetary

  costs of energy efficiency investments large? Understanding low take-up of a free energy efficiency

  program,” The American Economic Review, 2015, 105 (5), 201–204.


Frey, Bruno S. and Stephan Meier, “Social Comparisons and Pro-social Behavior: Testing

  &quot;Conditional Cooperation&quot; in a Field Experiment,” American Economic Review,

  December 2004, 94 (5), 1717–1722.


Gilbert, B., J. LaRiviere, and K. Novan, “Incentives and Additionality in Energy Efficiency

  Subsidies,” Association of Environmental and Resource Economists 4th Annual Summer Conerence,

  2015, June.




                                                 34
Gromet, Dena M, Howard Kunreuther, and Richard P Larrick, “Political ideology affects

  energy-efficiency attitudes and choices,” Proceedings of the National Academy of Sciences, 2013,

 110 (23), 9314–9319.


Ito, Koichiro, Takanori Ida, and Makoto Tanaka, “Using Dynamic Electricity Pricing to

  Address Energy Crises Evidence from Randomized Field Experiments,” Boston University Working

  Paper, 2013.


Lewis, R. and J. Rao, “The Unfavorable Economics of Measuring the Returns to Adverising,”

 Quarterly Journal of Economics, 2015, forthcoming.


McKinsey, “Unlocking energy efficiency in the US economy,” McKinsey and Company, 2009.


Palmer, Karen and Margaret Walls, “Limited Attention and the Residential Energy Efficiency

  Gap,” The American Economic Review, 2015, 105 (5), 192–195.


Pitchik, C. and A. Schotter, “Honesty in a Model of Strategic Information Transmission,” The

 American Economic Review, 1987, 77 (5), 1032–1036.


Rothschild, M., “A One-Armed Bandit Model of Search Behavior,” Journal of Economic Theory,

  1974, 9, 185–202.


Schultz, P Wesley, Jessica M Nolan, Robert B Cialdini, Noah J Goldstein, and Vladas

  Griskevicius, “The constructive, destructive, and reconstructive power of social norms,” Psy-

 chological science, 2007, 18 (5), 429–434.


Schutlz, PW, JM Nolan, RB Cialdini, NJ Goldstein, and V Griskevicius, “The Con-

  structive, Destructive, and Reconstructive Power of Social Norms,” Psychological Science, 2007,

 18 (5), 429–434.



                                               35
Shang, Jen and Rachel Croson, “A Field Experiment in Charitable Contribution: The Impact

  of Social Information on the Voluntary Provision of Public Goods,” The Economic Journal, 2009,

 119 (540), 1422–1439.


Trope, Yaacov and Nira Liberman, “Construal-Level Theory of Psychological Distance,” Psy-

 chological Review, 2010, 117 (2), 440–463.


Wichman, Casey, Laura Taylor, and Roger von Haefen, “Conservation policies: Who

  responds to price and who responds to prescription?,” Journal of Environmental Economics and

 Management, 2016, 79, 114–134.




                                              36
             Figure 1: Decision Tree for Field Experiment




                                 Treatment              Control




                                     USE



                             Audit           No Audit




                   Install           No Install




           Install Composition
Note: Control households have same access to same decisions over every node.




                                     37
                                                                     Figure 2: Timing of Waves Gantt Chart

12/1/2012                                                                                                                                                                   10/1/2013
       12/18/2012                      2/16/2013                                 5/3/2013                     7/1/2013                8/12/2013

                                                                                                                                           Wave 3 - Eligible Audit Period
                                                                                                                      Wave 2 - Eligible Audit Period
                                                                                     Wave 1 - Eligible Audit Period
                                               Pilot 2 - Eligible Audit Period
             Pilot 1 - Eligible Audit Period




         Pilot 1                        Pilot 2                                   Wave 1                      Wave 2                  Wave 3
    First Letter Sent                 Send Date                                  Send Date                   Send Date               Send Date

   Note: Timing of the experimental waves as well as the post-treatment windows during which we count eligible experimental audits. In general, each eligible
   audit period is 60 days from the wave-specific letter send date. In the case of Pilot 1, the letters were sent in two batches one on 12/18/2012 and one on
   12/21/2012. For households that were a part of Pilot 1, the eligible audit period is the 60 day period after either 12/18/2012 or 12/21/2012, respectively. We
   omit the 12/21/2012 batch from the Figure to simplify the presentation.
                              Figure 3: Variation in Letter Content




Note: The top left panel corresponds to the No Comparison treatment letters. The top right panel
corresponds to the kWh Comparison letters. The bottom left panel corresponds to the CO2 Comparison
letters. Finally, the bottom right panel corresponds to the $ Comparison (i.e., expenditure) letters.




                                                 39
                         Figure 4: Timing of Installs Relative to Audits
   .4
   .3
Density
.2 .1
   0




            0      1-10 11-20 21-30 31-40 41-50 51-60 61-70 71-80 81-90 91+
                               Days between Audit and Install


    Note: Data include all installations in the data set. All installations are preceeded by an audit.




                                                   40
                                Table 1: Treatments Used in Field Experiment and Covariate Balance

                                                                  No Subsidy     $20 Subsidy     $50 Subsidy     All Subsidy Levels

      No Comparison        Sample Size                               3,923           7,617           3,694             15,234
                           Mean Pre-Treatment Use (kWh)             1,326.90       1,322.06        1,312.30           1,320.94
                                                                     (9.33)         (6.76)          (9.71)              (4.77)
      kWh Comparison       Sample Size                               3,476           6,893           3,374             13,743
                           Mean Pre-Treatment Use (kWh)             1,316.45       1,319.69        1,327.60           1,320.81
                                                                    (10.25)         (7.09)          (10.23)             (5.07)
      $ Comparison         Sample Size                               3,737           7,736           3,756             15,229
                           Mean Pre-Treatment Use (kWh)             1,323.17       1,318.91        1,325.74           1,321.64
41




                                                                     (9.88)         (6.75)          (10.28)             (4.91)
      CO2 Comparison       Sample Size                               1,632           3,347           1,612              6,591
                           Mean Pre-Treatment Use (kWh)             1,317.90       1,317.50        1,330.52           1,320.79
                                                                    (14.48)         (10.59)         (15.07)             (7.44)

      All Letter Types     Sample Size                               12,768         25,593          12,436             50,797
                           Mean Pre-Treatment Use (kWh)             1,321.81       1,319.87        1,322.87           1,321.09
                                                                     (5.27)         (3.71)          (5.43)              (2.65)
     Note: In the No Comparison treatment row, households are told only their own use measured in kWhs. Elements of each cell indicate
     individual treatments, whereas numbers in parenthesis record the number of households in that treatment cell. There was also a large
     control group consisting of a within-wave control group and a super-control group never assigned to a wave. The size of the super
     control group was 49,751 households, with a mean pre-treatment use of 1,319.56 kWh and standard error of 2.69.
                                            Table 2: Sample Size by Wave and Treatment Type

                                                 Pilot 1           Pilot 2          Wave 1         Wave 2           Wave 3        Total
                                            Dec 18-21, 2012     Feb 16, 2013     May 3, 2013     Jul 1, 2013    Aug 12, 2013

      Within-Wave Control                          632               522             2,598           2,726           3,089        9,567
      No Comparison - No Subsidy                   280               304             1,075           1,097           1,167        3,923
      kWh Comparison - No Subsidy                  224                 0             1,121           1,019           1,112        3,476
      $ Comparison - No Subsidy                    253               298             1,046           1,074           1,066        3,737
      CO2 Comparison - No Subsidy                  209               333               0               0             1,090        1,632
      No Comparison - $20 Subsidy                  452               652             2,188           2,189           2,136        7,617
      kWh Comparison - $20 Subsidy                 423                 0             2,239           2,097           2,134        6,893
42




      $ Comparison - $20 Subsidy                   564               646             2,157           2,095           2,274        7,736
      CO2 Comparison - $20 Subsidy                 493               621               0               0             2,233        3,347
      No Comparison - $50 Subsidy                  192               332             1,051           1,033           1,086        3,694
      kWh Comparison - $50 Subsidy                 196                 0             1,055            997            1,126        3,374
      $ Comparison - $50 Subsidy                   205               288             1,039           1,139           1,085        3,756
      CO2 Comparison - $50 Subsidy                 204               308               0               0             1,100        1,612

      Total                                       4,327             4,304           15,569          15,466          20,698        60,364
     Note: Each column reports the sample size for a particular wave of the experiment and each row reports the sample size for a treatment
     type. The experiment also included a super-control of 40,184 households which were not assigned to any wave. Date represents the drop
     date for the mailing of the treatment letters in that wave. Any cells with 0 households indicate a letter type (either kWh Comparison or
     CO2 Comparison) that was not included in that particular wave.
Table 3: Unadjusted IHEA Uptake Rates During Experiment by Treatment Type

                         No Subsidy      $20 Subsidy     $50 Subsidy      Total

    No Comparison           0.0008          0.0012          0.0014       0.0011
    kWh Comparison          0.0021          0.0022          0.0036       0.0025
    $ Comparison            0.0016          0.0032          0.0022       0.0025
    CO2 Comparison          0.0006          0.0018          0.0006       0.0012
    Total                   0.0014          0.0021          0.0021       0.0019
   Note: Each cell in the table reports the average 60-day (from the date the
   treatment letters were sent out) uptake rate of IHEAs by households in that
   particular treatment cell. Omitted from the table is the average 60-day IHEA
   uptake rate for the control group (which was not sent any letter) which is .0011.
   Throughout, we exclude households with IHEAs prior to treatment or after the
   end of the observation period (1,548 households excluded, in total).




                                          43
                               Table 4: Impact of Treatment Letter and Subsidy on IHEA Uptake Rates

                                             1            2              3                  4                 5                6
      Any Letter                          -0.0005      -0.0003         -0.0001          -0.0000           -0.0002            -0.0001
                                         (0.0004)     (0.0002)        (0.0003)         (0.0002)          (0.0003)           (0.0002)
      kWh Comparison                    0.0014***     0.0004**         -0.0001          -0.0000           -0.0000            0.0000
                                         (0.0005)     (0.0002)        (0.0003)         (0.0001)          (0.0003)           (0.0001)
      $ Comparison                      0.0014***     0.0005**         0.0001          0.0005**            0.0001          0.0008***
                                         (0.0005)     (0.0002)        (0.0003)         (0.0002)          (0.0003)           (0.0003)
      CO2 Comparison                      0.0001        0.0003         0.0001            0.0001            0.0001             0.0001
                                         (0.0005)     (0.0002)        (0.0003)         (0.0002)          (0.0003)           (0.0002)
      $20 Subsidy                        0.0008*        0.0002         0.0002           -0.0002          0.0004**            -0.0002
                                         (0.0004)     (0.0002)        (0.0002)         (0.0002)          (0.0002)           (0.0002)
      $50 Subsidy                         0.0008      0.0005**         0.0001            0.0002           0.0002              0.0002
                                         (0.0005)     (0.0002)        (0.0003)         (0.0002)          (0.0002)           (0.0002)
      Constant                          0.0011***
                                         (0.0001)
      Audit Month-Year by ZIP5              No           Yes            Yes               Yes               Yes               Yes
44




      Wave                                  No           Yes            Yes               Yes               Yes               Yes
      Sample                              Full          Full         Above              Below            Above             Below
                                         Sample        Sample     Local Median       Local Median      MSA Median        MSA Median
      R2                                  0.0003       0.6950          0.7558            0.7283            0.7478           0.7251
      N                                   99,000       98,952          50,426            38,978            50,859           38,253
     Note: Dependent variable is an indicator for households that completed an IHEA within 60 days of receiving a treatment letter (or be
     part of the control group). Any Letter is an indicator for receiving any of the social comparison letters or an information-only letter
     during the study. kWh Comparison is an indicator for receiving a social comparison letter with units all in kWh during the study. $
     Comparison is an indicator for receiving a social comparison letter with units all in dollars during the study. CO2 Comparison is an
     indicator for receiving a social comparison letter with units all in pounds of CO2 during the study. Columns 1 and 2 are estimated
     on the full sample of households. Column 3 is estimated on the restricted sample of households with average pre-experiment use
     above the median in their local area. Column 4 is estimated on the restricted sample of households with average pre-experiment use
     below the median in their local area. Columns 5 and 6 reproduce Columns 3 and 4 (respectively), but use MSA instead of local area.
     Column 1 includes no controls. Columns 2-6 include controls for the wave of the experiment as well as month-year-ZIP5 level using
     the IHEA date. All standard errors are robust to heteroskedasticity. We exclude households with IHEAs prior to treatment or after
     the end of the observation period (a total of 1,548 households). Neither above- nor below-median models include households within
     the median (fifth) decile.
     ∗ ∗ ∗ significant at the 1% level, ∗∗ significant at the 5% level, ∗ significant at the 10% level.
Table 5: Unadjusted Time-to-Install (from Audit Date) by Treatment

                      No Subsidy      $20 Subsidy     $50 Subsidy     Total

No Comparison             44.33            40.75          13.40       37.68
kWh Comparison            52.62            14.47           6.42       19.82
$ Comparison              25.57            26.00          17.00       23.55
CO2 Comparison            39.50            20.56         224.00       40.67
Total                     41.46            26.35          19.00       27.58
Note: Each cell reports the average time-to-install (among installs within that
cell) from the date of the audit. Control group mean post-audit time-to-install
is roughly 41.46 days. Certain cells in the table only have 1 or 2 observations.




                                      45
                                  Table 6: Impact of Treatment Letter and Subsidy on Installs Ever

                                            1             2              3                 4                 5                6
     Any Letter                        -0.0016***      -0.0002         0.0001           -0.0003            0.0000          -0.0002
                                         (0.0004)     (0.0002)       (0.0003)          (0.0002)          (0.0003)         (0.0002)
     kWh Comparison                       -0.0005     -0.0003*        -0.0004           -0.0003           -0.0003          -0.0004
                                         (0.0004)     (0.0002)       (0.0003)          (0.0002)          (0.0003)         (0.0002)
     $ Comparison                         -0.0002    -0.0005**      -0.0008***           0.0002         -0.0007**          -0.0000
                                         (0.0004)     (0.0002)       (0.0003)          (0.0002)          (0.0003)         (0.0002)
     CO2 Comparison                       -0.0003      -0.0000        -0.0001           -0.0001           -0.0001          -0.0001
                                         (0.0005)     (0.0002)       (0.0003)          (0.0001)          (0.0003)         (0.0001)
     $20 Subsidy                           0.0002      -0.0000        -0.0002            0.0001           -0.0001          0.0000
                                         (0.0004)     (0.0002)       (0.0002)          (0.0002)          (0.0002)         (0.0002)
     $50 Subsidy                          -0.0004      -0.0000        0.0001            -0.0000            0.0001          0.0000
                                         (0.0004)     (0.0002)       (0.0002)          (0.0002)          (0.0002)         (0.0002)
     Constant                           0.0028***
                                         (0.0002)
     Install Month-Year by ZIP5            No           Yes             Yes               Yes              Yes               Yes
     Wave                                  No           Yes             Yes               Yes              Yes               Yes
46




     # Post-Treatment Months               No           Yes             Yes               Yes              Yes               Yes
     Sample                               Full         Full          Above             Below            Above            Below
                                         Sample       Sample      Local Median      Local Median      MSA Median       MSA Median
     R2                                  0.0005        0.7326         0.7443            0.8833            0.7321           0.8826
     N                                   99,000        98,962         50,435            38,969            50,865           38,248
     Note: Dependent variable is an indicator for households that made 1 or more energy-efficient installations at some point during the
     experiment and post-treatment. Any Letter is an indicator for receiving any of the social comparison letters or an information-only
     letter during the study. kWh Comparison is an indicator for receiving a social comparison letter with units all in kWh during
     the study. $ Comparison is an indicator for receiving a social comparison letter with units all in dollars during the study. CO2
     Comparison is an indicator for receiving a social comparison letter with units all in pounds of CO2 during the study. Columns 1
     and 2 are estimated on the full sample of households. Column 3 is estimated on the restricted sample of households with average
     pre-experiment use above the median in their local area. Column 4 is estimated on the restricted sample of households with average
     pre-experiment use below the median in their local area. Columns 5 and 6 reproduce Columns 3 and 4 (respectively), but use MSA
     instead of local area. Column 1 includes no controls. To account for differential timing of the treatment letter send dates, Columns
     2-6 include controls for the wave of the experiment as well as the number of post-treatment months that each household had to
     (potentially) respond to treatment. In addition, Columns 2 - 6 include fixed effects at the month-year-ZIP5 level using the install
     date. All standard errors are robust to heteroskedasticity. We exclude households with IHEAs prior to treatment or after the end of
     the observation period (a total of 1,548 households). Neither above- nor below-median models include households within the median
     (fifth) decile.
     ∗ ∗ ∗ significant at the 1% level, ∗∗ significant at the 5% level, ∗ significant at the 10% level.
                     Table 7: Impact of Treatment Letter and Subsidy on Installs Ever (Conditional on IHEA)

                                             1             2              3                  4                 5                6
      Any Letter                          -0.0819     -0.3235**         -0.3506          -0.3327            -0.3524          -0.5790
                                         (0.1221)      (0.1569)        (0.2193)         (0.2106)           (0.2524)         (0.3754)
      kWh Comparison                    -0.2494**       -0.0739         -0.0871        -0.8092***           -0.0760         -0.5279*
                                         (0.1111)      (0.1218)        (0.1493)         (0.1734)           (0.1554)         (0.2980)
      $ Comparison                       -0.2009*       -0.1179       -0.2324**           0.3230            -0.1976           0.1341
                                         (0.1089)      (0.0996)        (0.1169)         (0.1949)           (0.1288)         (0.1803)
      CO2 Comparison                      -0.0309       0.0122          -0.1391           0.1489            -0.1382           0.1503
                                         (0.1726)      (0.1473)        (0.2682)         (0.1451)           (0.2693)         (0.1603)
      $20 Subsidy                         -0.0643       0.0625          0.0637           -0.2515             0.0618          -0.1158
                                         (0.1128)      (0.1048)        (0.1644)         (0.1507)           (0.1791)         (0.2186)
      $50 Subsidy                         -0.1871      0.2448*          0.2400            0.0656            0.2475            0.2213
                                         (0.1266)      (0.1242)        (0.1636)         (0.1607)           (0.1918)         (0.3409)
      Constant                          0.6766***
                                         (0.0333)
      Install Month-Year by ZIP5            No           Yes             Yes               Yes               Yes               Yes
      Wave                                  No           Yes             Yes               Yes               Yes               Yes
47




      # Post-Treatment Months               No           Yes             Yes               Yes               Yes               Yes
      Sample                              Full          Full          Above              Below            Above             Below
                                         Sample        Sample      Local Median       Local Median      MSA Median        MSA Median
      R2                                  0.1215        0.5778         0.6687             0.8625            0.6399            0.8278
      N                                     335          297             167                62                162               68
     Note: All results are conditional on scheduling an IHEA. Dependent variable is an indicator for households that made 1 or more
     energy-efficient installations at some point during the experiment and post-treatment. Any Letter is an indicator for receiving any of
     the social comparison letters or an information-only letter during the study. kWh Comparison is an indicator for receiving a social
     comparison letter with units all in kWh during the study. $ Comparison is an indicator for receiving a social comparison letter with
     units all in dollars during the study. CO2 Comparison is an indicator for receiving a social comparison letter with units all in pounds
     of CO2 during the study. Columns 1 and 2 are estimated on the full sample of households. Column 3 is estimated on the restricted
     sample of households with average pre-experiment use above the median in their local area. Column 4 is estimated on the restricted
     sample of households with average pre-experiment use below the median in their local area. Columns 5 and 6 reproduce Columns 3
     and 4 (respectively), but use MSA instead of local area. Column 1 includes no controls. To account for differential timing of the
     treatment letter send dates, Columns 2-6 include controls for the wave of the experiment as well as the number of post-treatment
     months that each household had to (potentially) respond to treatment. In addition, Columns 2 - 6 include fixed effects at the
     month-year-ZIP5 level using the install date. All standard errors are robust to heteroskedasticity. We exclude households with
     IHEAs prior to treatment or after the end of the observation period (a total of 1,548 households). Neither above- nor below-median
     models include households within the median (fifth) decile.
     ∗ ∗ ∗ significant at the 1% level, ∗∗ significant at the 5% level, ∗ significant at the 10% level.
Appendix

Power Tests

    In choosing the size of our treatment and control groups we performed power tests for each

variable in order to determine the likelihood of discriminating effect sizes of economic significance.

We briefly summarize those power tests here.

    The auditor reported that the average monthly rate at which households in our sample sign up

for IHEAs was around 0.1%.28 In conversations with the auditing agency in our study region, they

said an optimistic expectation would be for treatment to cause IHEA rates to double. As a result,

we assume in our IHEA calculations that signup rates will average .19% (e.g., a marginal effect of

.09%) meaning that IHEA probabilities increase by roughly 90% with treatment.

    Our control group is roughly 50,000 households and the average treatment group is roughly

4600 households (total of 55,200 households). For our power tests, we assign binary IHEA uptake

decisions to simulated treatment and control households according to a binomial distribution with

the uptake probabilities for treatment and control households as described above. We then estimate

the marginal effect of being in any treatment group on IHEA uptake (i.e., pooled treatment versus

control). We reject the null hypothesis of zero effect in 98% of cases. As a result, we will very clearly

be able to tell if the field experiment had any effect when we aggregate all treatment cells.

    When we perform the same exercise, disaggregating by treatments so that there are only 4600

treated households per treatment, we reject the null hypothesis in only 41% of cases. The main

difference is the precision of the estimates: while the mean coefficient estimate is the same across

both power tests, the estimated t-stat of the marginal effect of treatment in the single treatment is

roughly one third of the t-stat when all treated groups are aggregated into a single large treated


  28
     In our data covering the duration of the experiment the rate of audit uptake in the control was in fact around half
that rate.



                                                           i
group (e.g., roughly 1.76, sitting just significant at the 10% level). Aggregating across signal types

or subsidy levels, improves the power greatly: the average t-stat is 2.67 and we are able to reject

the null hypothesis of zero effect 71.5% of the time.

   In sum, then, we are reasonably confident that we will be able to detect an effect of treatment

on IHEAs given the size of our field experiment when treatments are aggregated across signals and

less so for individual treatments of each of the twelve treatments. As a result, we are willing to

cautiously consider treatment effects that are significant at the 10% level as significant rather than

noise. That said, we take great care in trying to eliminate noise in both the treatment and control

group in robustness checks. For example, we remove around 3,000 returned letters by hand and

remove all households who had an IHEA within the previous 18 months of the start of the field

experiment. Doing this effectively increases the size of each treatment group by 10% and the size of

the control by 5%. The effect of doing so increases the average estimated t-stat to 1.83 (up from

1.76) and the percent of successfully rejected null hypotheses to 43% (up from 41%). There was a

similar increase when aggregating across prices for a given comparison so that we reject the null

hypothesis of no effect roughly 75% of the time for each individual comparison.

   Given the results of these power tests, distinguishing different treatment effects across individual

treatments (e.g., different signal types) requires that treatment vary by at least a factor of two

(e.g., the ATE for one of the twelve treatments is twice the ATE for another) to expect that we

find any significant effect across individual treatments. These results also motivate our empirical

specification to allow the price of the subsidy enter parametrically rather than use indicators for all

twelve treatments.

   Model of Audits as Search

   To fix ideas, we present a simplified version of the search model in Gilbert et al. (2015). Our

aim is not to provide a rigorous theoretical model to derive testable predictions. Rather, we aim to



                                                  ii
motivate how IHEAs are a form of search and develop a framework that links our treatments to

search intensity and the subsequent purchase of durable goods.

       Assume that conditional on household i’s (observable and unobservable) characteristics θi ,

monthly electricity bills are a random draw from the time-invariant distribution: ∀ t, et |θi ∼

N (µi (θi ), r) where r is the precision (i.e., the inverse of the variance) of the conditional distribution

of electricity bills.29 The mean of the distribution µi (·) is modelled as a function of θi , e.g., consumers

living in older houses are likely to have higher bills on average, ceteris paribus. While household i

knows its own characteristics θi with certainty, it has uncertainty over µi (·). In particular, household

i has priors over µi (·) described by F (µi (·)) which the household forms by observing household

characteristics (e.g., θi ) and updates these beliefs by using monthly electricity bills et to form

posteriors using Bayes’ rule. As a result, home owners who have lived in their homes for a longer

period of time will have a better idea of their average electricity use than do counterparts who have

lived in their home for a shorter period.

       Purchasing an energy-efficient durable good serves to reduce mean electricity use by a factor

of α ∈ (0, 1) with probability ρ. After a purchase, a household with characteristics θi will see

mean electricity bills drop to (1 − α)µi (θi ) with probability ρ and remain at µi (θi ) with probability

1 − ρ. Therefore, households are uncertain about the benefits of making an investment in a durable

good that is expected to improve energy efficiency. To resolve this uncertainty, a household can

conduct an IHEA for a cost c and learn whether or not an energy efficient upgrade lowers their

mean electricity use. IHEAs thus serve to eliminate uncertainty about the benefits associated with

the purchase of any given durable good. In this regard, IHEAs are akin to expert advice in models

such as Pitchik and Schotter (1987) and Edo and Szentes (2007) - the households pays a fixed cost


  29
       For simplicity, we follow Gilbert et al. (2015) and do not model the choice problem underlying monthly energy use.




                                                            iii
to the auditor as a way to resolve uncertainty before making a purchase decision.30

       Our experimental design, which we discuss in detail in Section IV, provides exogenous variation

over key parameters of this model. Our subsidy treatments provide exogenous variation in the cost

of an audit, c. In doing so, we generate exogenous variation in the expected net benefits of getting

an audit. Hence, we would expect to see increased participation in the IHEA for households in

our Subsidy treatments. Our Social Comparison treatments introduce random variation in what

households know about their consumption relative to the average consumption of their neighbors.

In our framework, this information could impact the household’s expected gains from an audit in

two ways. First, households may use information on relative usage to update their beliefs about the

probability that an install would result in savings (ρ) and/or the expected reductions in energy use

from a successful install (α). We are agnostic about the precise channel since our data do not allow

us to observe and model belief updating. Yet it is important to note that if a household were to

observe they are below mean local area use, it is plausible that the household would update their

beliefs such that it reduces the expected benefits of an audit. Second, it is possible that Social

Comparisons introduce a form of moral suasion that is akin to the social pressure term in DellaVigna

et al. (2012). If so, households may schedule an audit as a way to alleviate feelings of guilt that are

triggered upon learning that their consumption exceeds that of similar neighbors. However, as the

underlying decision to search is driven by the expected costs of not searching as opposed to the

expected benefits of search, such motives may lead to lower rates of purchase as such individuals

are searching for the “wrong” reasons.




  30
    This simple model has two notable shortcomings. First, there are well-known discounting issues in durable good
purchases known as the energy paradox. In the context of our field experiment, though, this is second order since any
discounting issues are shared by both the treatment and control groups. Second, the binomial distribution of α is very
much a simplifying abstraction. A richer model would offer a continuous distribution which is itself a function of θi .
However, the important characteristic of the model- uncertainty over benefits of an audit- is verified in data we show
below, e.g., incomplete install rates.


                                                          iv
Month Day, Year

Dear Valued Customer,

There’s no place like home, and there’s no time like now to make your home more energy efficient. You can
conserve energy, save on utility bills, and get cash rebates by participating in EnergyRight® Solutions In-Home
Energy Evaluation (IHEE) program. If you qualify, you can also use on-bill financing to pay for IHEE improvements.

If you sign up for an In-Home Energy Evaluation, a TVA Certified Energy Advisor will visit your home at a time
convenient for you. The advisor will recommend cost-effective ways to increase your home’s energy efficiency and
will install free CFLs and low-flow water saving measures if you choose.

The IHEE evaluation fee is $150 (currently with an instant rebate of $100). And you will receive the remaining $50 fee back
if you spend $150 or more on qualifying improvements. You will also receive matching rebates of up to $500 for installing
eligible improvements. As an additional thank you for participating, if you have an In-Home Energy Evaluation within 30
days from the date of this letter you will receive a $50 Visa gift card.

We thought that you might be interested in the following information about your energy usage last year:


                                    Relative Energy Usage over Past Year




   Your Average




                  0         50        100        150        200        250        300         350        400        450

                                                        Kilowatt-hours (kWh)
                  Kilowatt hours is a unit of energy equal to one kilowatt of power used for one hour. A 100 Watt
                                     bulb burning for 10 hours/week uses 1 kWh (100/1000x10)


                      Your average energy consumption over the past year: 400 kWh


For more information about the IHEE program, including on-bill financing, call 1-866-441-1430. You can also find more
information about the program and details about qualifying improvements by following the In-Home Energy Evaluation
link on the www.energyright.com home page.




Sincerely,

EnergyRight® Solutions Team




NC123




      Figure A1: No Comparison Letter Example with $50 Subsidy Offer


                                                                  v
Month Day, Year

Dear Valued Customer,

There’s no place like home, and there’s no time like now to make your home more energy efficient. You can
conserve energy, save on utility bills, and get cash rebates by participating in EnergyRight® Solutions In-Home
Energy Evaluation (IHEE) program. If you qualify, you can also use on-bill financing to pay for IHEE improvements.

If you sign up for an In-Home Energy Evaluation, a TVA Certified Energy Advisor will visit your home at a time
convenient for you. The advisor will recommend cost-effective ways to increase your home’s energy efficiency and
will install free CFLs and low-flow water saving measures if you choose.

The IHEE evaluation fee is $150 (currently with an instant rebate of $100). And you will receive the remaining $50 fee back
if you spend $150 or more on qualifying improvements. You will also receive matching rebates of up to $500 for installing
eligible improvements. As an additional thank you for participating, if you have an In-Home Energy Evaluation within 30
days from the date of this letter you will receive a $50 Visa gift card.

We thought that you might be interested in the following information about your energy usage last year:




                Your Average Energy Usage                                         400 kWh
         Local Area Homes’ Average Energy Usage                                   333 kWh

                     You consumed 20% more energy than other area homes.



For more information about the IHEE program, including on-bill financing, call 1-866-441-1430. You can also find more
information about the program and details about qualifying improvements by following the In-Home Energy Evaluation
link on the www.energyright.com home page.

Sincerely,

EnergyRight® Solutions Team


kWh123




    Figure A2: kWh Comparison Letter Example with $50 Subsidy Offer


                                                            vi
Month Day, Year

Dear Valued Customer,

There’s no place like home, and there’s no time like now to make your home more energy efficient. You can
conserve energy, save on utility bills, and get cash rebates by participating in EnergyRight® Solutions In-Home
Energy Evaluation (IHEE) program. If you qualify, you can also use on-bill financing to pay for IHEE improvements.

If you sign up for an In-Home Energy Evaluation, a TVA Certified Energy Advisor will visit your home at a time
convenient for you. The advisor will recommend cost-effective ways to increase your home’s energy efficiency and
will install free CFLs and low-flow water saving measures if you choose.

The IHEE evaluation fee is $150 (currently with an instant rebate of $100). And you will receive the remaining $50 fee back
if you spend $150 or more on qualifying improvements. You will also receive matching rebates of up to $500 for installing
eligible improvements. As an additional thank you for participating, if you have an In-Home Energy Evaluation within 30
days from the date of this letter you will receive a $20 Visa gift card.

We thought that you might be interested in the following information about your energy bills last year:


                                     Relative Energy Bills over Past Year

              Your Average

  Neighborhood Average

                                0             20      40           60           80            100        120
                                                   *Dollars per Month


   *Dollars per month calculated at $.XX per kWh




                   Your Average Energy Bill                                          $42.50
             Local Area Homes’ Average Energy Bill                                   $33.28

                          You spent 28% more dollars than other area homes.


For more information about the IHEE program, including on-bill financing, call 1-866-441-1430. You can also find more
information about the program and details about qualifying improvements by following the In-Home Energy Evaluation
link on the www.energyright.com home page.



Sincerely,

EnergyRight® Solutions Team




Ex2123




       Figure A3: $ Comparison Letter Example with $20 Subsidy Offer


                                                           vii
Month Day, Year

Dear Valued Customer,

There’s no place like home, and there’s no time like now to make your home more energy efficient. You can conserve
energy, save on utility bills, and get cash rebates by participating in EnergyRight® Solutions In-Home Energy Evaluation
(IHEE) program. If you qualify, you can also use on-bill financing to pay for IHEE improvements.

If you sign up for an In-Home Energy Evaluation, a TVA Certified Energy Advisor will visit your home at a time
convenient for you. The advisor will recommend cost-effective ways to increase your home’s energy efficiency and will
install free CFLs and low-flow water saving measures if you choose.

The IHEE evaluation fee is $150 (currently with an instant rebate of $100). And you will receive the remaining $50 fee back if
you spend $150 or more on qualifying improvements. You will also receive matching rebates of up to $500 for installing
eligible improvements. [NO GIFT CARD REBATE]

We thought that you might be interested in the following information about the CO2 created through your energy
consumption last year. Carbon emissions can best be defined as carbon substances which end up in the atmosphere.
Such gases are produced by many things including cars, industrial plants and electricity production.


                                   Relative CO2 Created over Past Year

    Neighborhood Average

               Your Average

                               0         100        200        300         400        500        600        700
                                                    CO2 lbs (1 kWh=2.17 CO2 lbs)




  Your Energy Use                                              500 kWh created 1,085 lbs of CO2 emissions
  Local Area Homes’ Energy Use                                 600 kWh created 1,302 lbs of CO2 emissions

                  You produced 20% more CO2 emissions than other area homes.

For more information about the IHEE program, including on-bill financing, call 1-866-441-1430. You can also find more
information about the program and details about qualifying improvements by following the In-Home Energy Evaluation link
on the www.energyright.com home page.



Sincerely,

EnergyRight® Solutions Team




CO2123




       Figure A4: CO2 Comparison Letter Example with No Subsidy Offer


                                                             viii
              Figure A5: Treatment Assignment (Proportion) by Local Decile of Pre-Treatment Use
              .2
Frequency Across Treatments
                       .15




                                                                           9
                                                                           4       12
                                                                                   10                       12
                                                           10              1               7
                                                                                           4        8
                                                                                                    12
                                                                                                    6
                                                                                                    5       3
                                                                                                            4
                                                                                                            11
                                                                                                            1
                                                                                                            10
                                                                                                            6
                                  4
                                  2
                                  0
                                  5        8       12      1       9       7
                                                                           2
                                                                           11      2
                                                                                   3
                                                                                   6       9
                                                                                           3
                                                                                           11
                                                                                           5        9
                                                                                                    1
                                                                                                    0       2
                                                                                                            0
                                                                                                            8
                                  3
                                  8
                                  6                3       5
                                                           11              8       0       1
                                                                                           2        7
            .1




                                  11
                                  12
                                  7
                                  10       6       11
                                                   2
                                                   6
                                                   9
                                                   0       8
                                                           4       7
                                                                   1
                                                                   12      0
                                                                           5
                                                                           10
                                                                           3
                                                                           6       5
                                                                                   8
                                                                                   7
                                                                                   9       6
                                                                                           0
                                                                                           10       11
                                                                                                    4
                                                                                                    3
                                                                                                    2       5
                                                                                                            7
                                  9
                                  1        2
                                           7
                                           11
                                           4
                                           0
                                           12
                                           9       5
                                                   7       7
                                                           6
                                                           0
                                                           9
                                                           3       10
                                                                   4
                                                                   3
                                                                   0
                                                                   5               11
                                                                                   1       8        10
                                           1
                                           10
                                           5       10      2
                                                           12      8
                                                                   6               4       12
                                           3       1
                                                   8
                                                   4               11
                                                                   2                                        9
                                                                           12
.05           0




                              1        2         3       4      5         6       7       8     9        10
                                                Pre-Treatment Decile of Use Within Local Area


  Note: The figure summarizes one measure of balance of treatment assignment along the decile of
  pre-treatment use within a local area (either nine or five digit ZIP). Exact balance across all 13
  treatments cells (control and 12 treatment letters) would require each decile represent 1/10 (the solid
  red line) of the assigned households for each treatment. Actual treatment assignment proportions
  can be identified by the treatment number. The control group is denoted as 0. Along the subsidy
  dimension: a) households receiving no subsidy are in treatments 1 through 4, b) households receiving a
  $20 subsidy are in treatments 5 through 8, and c) households receiving a $50 subsidy are in treatments
  9 through 12. Along the content dimension: a) households receiving a “No Comparison” letter are in
  treatments 1, 5, and 9, b) households receiving a kWh Comparison letter are in treatments 2, 6, and
  10, c) households a receiving $ Comparison letter are in treatments 3, 7, and 11, and d) households
  receiving a CO2 Comparison letter are in treatments 4, 8, and 12.




                                                                  ix
             Table A1: Impact of Treatment Letter and Subsidy on IHEA Uptake Rates (Saturated Model)

                                            1             2              3                 4                 5                 6
 No Comparison - No Subsidy               -0.0003    -0.0004*          -0.0004          -0.0001           -0.0004           -0.0002
                                         (0.0005)    (0.0002)         (0.0004)         (0.0001)          (0.0004)          (0.0001)
 kWh Comparison - No Subsidy               0.0010      0.0002          -0.0002          0.0003            -0.0001            0.0003
                                         (0.0008)    (0.0003)         (0.0003)         (0.0003)          (0.0003)          (0.0003)
 $ Comparison - No Subsidy                 0.0005      0.0002           0.0003           0.0001            0.0001            0.0005
                                         (0.0007)    (0.0003)         (0.0005)         (0.0002)          (0.0005)          (0.0004)
 CO2 Comparison - No Subsidy              -0.0005     -0.0000          -0.0003           0.0001           -0.0002            0.0001
                                         (0.0006)    (0.0002)         (0.0002)         (0.0001)          (0.0002)          (0.0002)
 No Comparison - $20 Subsidy               0.0001     -0.0001           0.0001          -0.0000            0.0002           -0.0001
                                         (0.0004)    (0.0003)         (0.0004)         (0.0003)          (0.0003)          (0.0003)
 kWh Comparison - $20 Subsidy             0.0011*      0.0000          -0.0003         -0.0003*           -0.0001          -0.0003*
                                         (0.0006)    (0.0002)         (0.0003)         (0.0002)          (0.0003)          (0.0002)
 $ Comparison - $20 Subsidy             0.0021***     0.0006*           0.0003           0.0002            0.0005            0.0004
                                         (0.0007)    (0.0003)         (0.0004)         (0.0002)          (0.0004)          (0.0003)
 CO2 Comparison - $20 Subsidy              0.0007      0.0004           0.0005          -0.0001            0.0005           -0.0001
                                         (0.0008)    (0.0003)         (0.0004)         (0.0003)          (0.0004)          (0.0003)
 No Comparison - $50 Subsidy               0.0003      0.0002           0.0002          -0.0001           0.0002            -0.0001
                                         (0.0006)    (0.0003)         (0.0005)         (0.0001)          (0.0005)          (0.0001)
 kWh Comparison - $50 Subsidy            0.0025**    0.0012**           0.0005          -0.0001            0.0005           -0.0001
                                         (0.0011)    (0.0005)         (0.0005)         (0.0001)          (0.0005)          (0.0001)
 $ Comparison - $50 Subsidy                0.0011      0.0003          -0.0005         0.0013**           -0.0004          0.0013**
                                         (0.0008)    (0.0003)         (0.0003)         (0.0006)          (0.0003)          (0.0006)
 CO2 Comparison - $50 Subsidy             -0.0005     -0.0000          -0.0003           0.0001           -0.0002            0.0001
                                         (0.0006)    (0.0002)         (0.0002)         (0.0001)          (0.0002)          (0.0002)
 Constant                               0.0011***
                                         (0.0001)
 Audit Month-Year by ZIP5                   No          Yes             Yes               Yes               Yes              Yes
 Wave                                       No          Yes             Yes               Yes               Yes              Yes
 Sample                                   Full         Full          Above             Below            Above             Below
                                         Sample       Sample      Local Median      Local Median      MSA Median        MSA Median
 R2                                       0.0004       0.6950         0.7559            0.7284            0.7478            0.7251
 N                                        99,000       98,952         50,426            38,978            50,859            38,253
Note: Dependent variable is an indicator for households that completed an IHEA within 60 days of being randomized to receive a
treatment letter (or be part of the control group). Rows are indicator variables on each of the 12 unique treatments. Columns 1
and 2 are estimated on the full sample of households. Column 3 is estimated on the restricted sample of households with average
pre-experiment use above the median in their local area. Column 4 is estimated on the restricted sample of households with average
pre-experiment use below the median in their local area. Columns 5 and 6 reproduce Columns 3 and 4 (respectively), but use
MSA instead of local area. Column 1 includes no controls. Columns 2-6 include controls for the wave of the experiment as well as
month-year-ZIP5 level using the IHEA date. All standard errors are robust to heteroskedasticity. We exclude households with IHEAs
prior to treatment or after the end of the observation period (a total of 1,548 households). Neither above- nor below-median models
include households within the median (fifth) decile.
∗ ∗ ∗ significant at the 1% level, ∗∗ significant at the 5% level, ∗ significant at the 10% level. ∗ ∗ ∗ significant at the 1% level, ∗∗
significant at the 5% level, ∗ significant at the 10% level.




                                                                  x
