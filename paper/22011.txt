                                NBER WORKING PAPER SERIES




SCHOOL FINANCE REFORM AND THE DISTRIBUTION OF STUDENT ACHIEVEMENT

                                         Julien Lafortune
                                          Jesse Rothstein
                                   Diane Whitmore Schanzenbach

                                        Working Paper 22011
                                http://www.nber.org/papers/w22011


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     February 2016




This research was supported by funding from the Spencer Foundation and the Washington Center
for Equitable Growth. We are grateful to Apurba Chakraborty, Elora Ditton, and Patrick Lapid for
excellent research assistance. We thank Julie Cullen, Tom Downes, Kirabo Jackson, Rucker Johnson,
Richard Rothstein, Max Schanzenbach, and conference and seminar participants at APPAM, AEFP,
Bocconi, Brookings, Chicago, Erasmus, Wisconsin (IRP), LSE, New York University, Northwestern,
Princeton, RAND, Teachers’ College, Texas A&M, Warwick, and the 2015 Stavanger-Bergen-Berkeley
workshop for helpful comments and discussions. The views expressed herein are those of the authors
and do not necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2016 by Julien Lafortune, Jesse Rothstein, and Diane Whitmore Schanzenbach. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including © notice, is given to the source.
School Finance Reform and the Distribution of Student Achievement
Julien Lafortune, Jesse Rothstein, and Diane Whitmore Schanzenbach
NBER Working Paper No. 22011
February 2016, Revised July 2016
JEL No. H73,H75,I22

                                         ABSTRACT

We study the impact of post-1990 school finance reforms, during the so-called “adequacy” era,
on absolute and relative spending and achievement in low-income school districts. Using an event
study research design that exploits the apparent randomness of reform timing, we show that
reforms lead to sharp, immediate, and sustained increases in spending in low-income school
districts. Using representative samples from the National Assessment of Educational Progress, we
find that reforms cause increases in the achievement of students in these districts, phasing in
gradually over the years following the reform. The implied effect of school resources on
educational achievement is large.

Julien Lafortune                               Diane Whitmore Schanzenbach
Department of Economics                        School of Education and Social Policy
University of California, Berkeley             Northwestern University
530 Evans Hall #3880                           Annenberg Hall, Room 205
Berkeley, CA 94720                             2120 Campus Drive
julien@econ.berkeley.edu                       Evanston, IL 60208
                                               and the Brookings Institution
Jesse Rothstein                                and also NBER
Goldman School of Public Policy                dws@northwestern.edu
and Department of Economics
University of California, Berkeley
2607 Hearst Avenue
Berkeley, CA 94720-7320
and NBER
rothstein@berkeley.edu
        Economists have long been skeptical of resource-based education policies, based in

part on observational studies showing small or zero effects of additional funding (see, e.g.,

Coleman et al. 1966, Hanushek 1986, Hanushek 2006).2 Hanushek, for example, writes:

“Simply providing more funding or a different distribution of funding is unlikely to improve

student achievement (even though it may affect the tax burdens of school financing across

the citizens of a state)” (1997, p. 153). Accordingly, recent policy discussions have focused

on ways to improve the productivity of existing inputs rather than on changes in school

resource levels.

        Nevertheless, states have continued to implement aggressive resource-based

policies, aimed in part at reducing achievement gaps. Between 1990 and 2011, average real

spending per pupil in K-12 schools rose by nearly 40 percent. This increase was

concentrated in low-income school districts. Figure 1 shows the evolution of average

revenues per pupil, in 2013 dollars, in the lowest-income school districts (defined as the

bottom fifth of each state’s district-level mean household income distribution) and the

highest-income districts (the top fifth), from 1990 to 2012.3 Over this period, real per-pupil

revenues rose by roughly 30% in the highest-income districts, and by over half in the

lowest-income districts. Thus, while low-income districts collected about 20% less than

high-income districts in 1990, they have been in rough parity since around 2001.

        Much of this change came via reforms to state education funding formulas. Figure 2

shows revenues of low-income districts relative to high-income districts, each defined as in


2 There are also observational (Card and Krueger 1992a) and experimental (Krueger 1999; Dynarski, Hyman
& Schanzenbach 2013) studies pointing to positive school resource effects. There is no consensus about how
to reconcile these (see, e.g., Burtless 1996; Hanushek 2003; Krueger 2003).
3 Hawaii and the District of Columbia are excluded. State means weight districts by log enrollment, then are

averaged without weights in Figure 1. Numbers in the text weight states by enrollment for comparability with
national aggregates. We discuss data sources and definitions in Section III.


                                                                                                          2
Figure 1, separately for the 26 states that have implemented school finance reforms—

typically but not always under court order—since 1990 and for 23 states that have not.

Growth in low-income districts’ relative revenues has been more than twice as rapid in the

former states than in the latter.

        The implications of school finance reforms (SFRs) for school funding have been

much studied (see, e.g., Hanushek and Lindseth, 2009; Card and Payne, 2002; Murray,

Evans, and Schwab, 1998; Ladd and Fiske 2015). The existing research focuses on so-called

“equity” reforms in the 1970s and 1980s, which aimed to reduce resource disparities

across districts. But most reforms since 1990 have been “adequacy” reforms that aim to

achieve sufficient funding in low-income districts, regardless of the implications for equity.

Adequacy reforms have been more numerous than the earlier equity reforms, but have

been much less studied.

        SFRs are arguably the most substantial national policy effort aimed at promoting

equality of educational opportunity since the turn away from school desegregation in the

1980s. But there is little evidence about their effects on student achievement. What

evidence there is derives from non-representative data on students who took the SAT

college entrance exam (Card and Payne 2002); from long-run outcomes measured in the

relatively small Panel Study of Income Dynamics sample (Jackson, Johnson, and Persico

2016); or from case studies of individual reforms (Clark 2003; Hyman 2013; Guryan

2001).4 These studies primarily examine pre-1990, equity-based SFRs, and generally find

positive effects on student outcomes. But funding levels were much higher by 1990 than



4 Cascio and Reber (2013) and Cascio, Gordon, and Reber (2013) examine the introduction of federal Title I
funding to low-income schools via the 1965 Elementary and Secondary Education Act.


                                                                                                             3
earlier, and the most severe inequities in school resources had been addressed. Thus, there

may have been less scope for more recent, adequacy-based SFRs to benefit students.

        The literature regarding whether “money matters” in education (Card and Krueger

1992a; Hanushek 1986, 2003, 2006; Burtless 1996) is contentious and does not offer clear

guidance. State funding formulas are the main policy tool available to address inequities in

academic outcomes, so funding shifts deriving from changes in these formulas are the most

policy-relevant variation in school resources. The very limited evidence on the impacts of

early SFRs, and the near-total lack of evidence regarding more recent reforms, represents a

major shortcoming in the literature.

        We provide the first evidence from nationally representative data regarding the

impact of SFRs on student achievement. We exploit little-used data from the National

Assessment of Educational Progress (NAEP), also known as “the Nation’s Report Card.”

NAEP has administered tests in math and reading to state-representative samples of

100,000-200,000 students in the fourth and eighth grades every two to four years since

1990. Importantly, the tests have been uniform across the country and over time,

facilitating comparisons.5

        We use the NAEP data to construct a state-by-year panel of relative achievement in

low-income school districts, covering 1990 to 2011. Conveniently, the beginning of our

NAEP panel coincides with the onset of the adequacy era of school finance, which dates to

the 1990 Kentucky Education Reform Act (KERA). Figure 3 shows the NAEP score gap (in

standard deviation units) between low- and high-income districts over time, using the

5Several studies (e.g., Dee and Jacob 2011, Levine and Schanzenbach 2009) exploit state mean scores.
Microdata are available under restricted-use data licenses from the National Center for Education Statistics
(NCES). We are grateful to Bruce Kaplan, Kate Pashley, and Fatih Unlu for their assistance in locating the
crosswalk from the older NAEP data to schools and districts.


                                                                                                               4
same definitions as in Figures 1 and 2. It shows that the test score gap has narrowed in

states that implemented reforms but has been stable in states that did not.

        Figures 2 and 3 can be seen as long-difference estimates of the effects of SFRs, and

indicate that SFRs led to increases in funding and test scores in low-income school districts.

But these patterns could be driven by other trends that differ between states that did and

did not implement reforms. To test this, we use an event study framework, taking

advantage of plausibly random variation in the location and timing of post-1990 SFRs. We

find no sign of systematic changes in either funding or test scores in the period leading up

to a reform, supporting our assumption that reform timing is exogenous. Following

reforms, we document sharp increases in state revenues, with larger increases in low-

income districts and smaller but still positive increases in high-income districts.6 These

changes occur quickly after reform events, persist for many years, and are not offset by

reductions in local revenues. Absolute and relative funding in low-income districts rises by

approximately $1,200 and $700 per pupil per year, respectively.

        Not surprisingly, we find no immediate effect of reforms on achievement. But we do

find clear changes in achievement trends following events. These cumulate over time: Ten

years after a reform, relative achievement of students in low-income districts has risen by

roughly 0.1 standard deviation, approximately one-fifth of the baseline gap between high-

and low-income districts. The implied impact is between 0.12 and 0.24 standard deviations

per $1,000 per pupil in annual spending. This is at least twice the impact per dollar that is




6 Anecdotally, legislators facing court orders to increase funding to low-income districts often respond by
increasing overall funding, as a way of disguising the resulting redistribution. Reforms are associated with
sharp increases in total state education expenditures and tax collections.


                                                                                                               5
implied by the Tennessee Project STAR class size experiment.7 Given existing estimates of

the relationship between test scores and students’ subsequent earnings, our results imply

that the benefits of marginal increases in school resources in low-income, poorly resourced

school districts, in terms of students’ increased eventual earnings, exceed the costs.

        Our paper makes three primary contributions. First, we present the first

comprehensive evidence regarding the fiscal impacts of post-1990, adequacy SFRs.8 We

show that these reforms lead to increased progressivity of state aid and total school

finance, with little if any of the additional state funding dissipated through reduced local

effort and with no sign of reactions that reduce overall funding.

        Second, we present the first national evidence regarding the effect of any finance

reforms on the achievement of a representative sample of students. Our estimates imply

that additional funding distributed through court-mandated changes in finance formulas is

highly productive in low-income school districts.

        Finally, we present the first analysis of the impact of finance reforms on overall

educational equity. We find no discernable effect of reforms on either the gap in

achievement between high- and low-income students or the minority-white gap. This is not

because funding is unproductive. Rather, low-income and minority students are not very

highly concentrated in school districts with low mean incomes, so are not closely targeted

by district-based finance reforms. Thus, while our analysis suggests that finance reforms

can be quite effective at reducing between-district inequities, other policy tools aimed at

7 STAR raised costs by about 30% in K-3, and raised test scores by 0.17 SDs (Krueger and Whitmore 2001).
Current spending per pupil in Tennessee is around $9,000, so comparable proportional class size reductions
would cost around $2,700 per pupil per year. The implied effect is thus around 0.06 SDs per $1,000 per pupil.
This comparison implicitly assumes that maintaining the smaller STAR class sizes beyond 3rd grade would
yield no additional growth in test scores.
8 Sims (2011a) and Corcoran and Evans (2015) contrast fiscal impacts of equity and adequacy reforms. But

their samples end in 2002, and thus reflect only the beginning of the adequacy era.


                                                                                                            6
within-district resource and achievement gaps will be needed to address overall equity

concerns.


I.      School finance reforms9

        Historically, American public schools were locally managed and financed primarily

via local property taxes. As school districts vary widely in both their tax bases and their

voters’ willingness to tax themselves to fund schools, this meant that school resources

varied substantially across districts.

        In the 1960s, a group of legal scholars argued that local school finance violates

federal and state constitutional provisions that guarantee equal access to public services

(see, e.g., Wise 1967; Horowitz 1966; Kirp 1968; and Coons, Clune, and Sugarman 1970).

Advocates brought and won suits in many states demanding more equitable school finance

systems; in other states, legislatures acted without court decisions (often to stave off

potential rulings).10

        The resulting finance regimes often involved substantial increases in state transfers

to districts that depended either on local fiscal capacity (“power equalization”) or realized

local revenues (“matching” or “variable” grants). An extensive “fiscal federalism” literature

examines the effects of these reforms on the distribution of school funding (see, e.g.,

Hanushek and Lindseth, 2009; Corcoran and Evans, 2015; Card and Payne, 2002; Murray,

Evans, and Schwab, 1998). A particular focus is whether formulas that raise the marginal




9Our discussion here draws heavily on Koski and Hahnel (2015).
10An early U.S. Supreme Court decision, San Antonio Independent School District v. Rodriguez (411 US 1, 1973)
held that education is not a fundamental right under the U.S. Constitution. Subsequent suits focused on state
constitutions, which often articulate responsibility for a system of public education.


                                                                                                           7
local cost of additional school spending affect voters’ choices about the local spending level

(e.g., Hoxby 2001).

        A second wave of finance reforms—the focus of this paper—is commonly dated to a

1989 Kentucky Supreme Court ruling. Here, the Court found that the state constitution,

which as in many other states dictates an “efficient system” of public schools, requires that

“[e]ach child, every child, … must be provided with an equal opportunity to have an

adequate education” (Rose v. Council for Better Education11; emphasis in original). The

ruling emphasized that equal funding was not sufficient, and articulated a standard closer

to equality of outcomes for students in low-income districts (“sufficient levels of academic

or vocational skills to enable public school students to compete favorably with their

counterparts in surrounding states, in academics or in the job market”). The Kentucky

legislature responded with the Kentucky Education Reform Act of 1990 (KERA), which

revamped the state’s educational finance, governance, and curriculum. Clark (2003) and

Flanagan and Murray (2004) find KERA substantially increased spending in low-income

districts.

        Since 1990, courts in many other states have found adequacy requirements in their

own constitutions. In many cases reforms have aimed at higher spending in low-income

than in high-income districts, to compensate for the out-of-school disadvantages that low-

income students face.12

        Reform advocates have consciously imitated the legal campaign for school

desegregation in the 1950s-1980s, and like that movement have operated


11790 SW 2d 186. Rose was not the first adequacy ruling, but earlier rulings attracted less attention.
12A small industry has developed to calculate the spending level needed to satisfy an adequacy standard. See,
e.g., Downes and Steifel (2015) and Duncombe, Nguyen-Hoang, and Yinger (2015).


                                                                                                            8
opportunistically, taking advantage of variation in legal precedent and the availability of

sympathetic judges to advance a national effort. Courts in different states have interpreted

seemingly similar state constitutional language quite differently, either imposing or ruling

out adequacy requirements.13 There is little reason to think that the cases are brought in

response to political or other developments that would have independently affected

achievement gaps in a state. Moreover, the vagaries of the judicial process—cases are

typically appealed upward through several levels of review—and decisions in some states

to implement legislative reforms to settle ongoing cases or forestall feared court rulings

generate additional quasi-random variation in timing. Our analytic strategy, developed

below, is premised on the assumption that reform timing is uncorrelated with other

determinants of trends in (relative) spending and achievement in low-income districts. We

present evidence in support of this assumption in Sections IV and V.

        We have attempted to identify all major SFRs between 1990 and 2011. We began

with lists of court-ordered reforms compiled by Jackson et al. (2016) and Corcoran and

Evans (2015). We supplemented these with our own research into case histories, and

updated them through 2011. We also tabulated major legislative SFRs. In some important

cases (e.g., Colorado, California), legislatures reformed finance systems without prior court

decisions, often to forestall adverse judgments in threatened or ongoing lawsuits. Our

primary analyses include these, though we also present results that focus exclusively on

court orders.



13For example, the Illinois Supreme Court has found that school finance rules are not justiciable by the courts
and must be addressed instead by the legislature (672 N.E.2d 1178 ). The relevant clause in the state’s
constitution (“an efficient system of high-quality public educational institutions and services”) is similar to
that in Ohio (“a thorough and efficient system of common schools throughout the State”), where the courts
have intervened.


                                                                                                             9
        Appendix Table A1 presents a complete list of our events and compares it to those

used in other studies. We identify a total of 64 school finance reform events in 26 states

between 1990 and 2011.14 39 (61%) involve court orders; the remainder are legislative

actions without a major court order in the same year.

        Figure 4 shows the distribution of events over time, with legislative SFRs indicated

by darker bars. There have been substantially more court-ordered SFRs during the

adequacy era than in the prior, more studied equity era.15 Figure 5 shows the geographic

distribution. States with events are quite geographically diverse, though reforms are rare in

the Deep South and upper Midwest.

        18 states had multiple events in our period. These were generally closely spaced:

60% were three or fewer years apart. In these cases, we suspect that only one generated a

major change in the state’s finance rules and that others were procedural steps (e.g., court

orders that were disregarded or legislation changes that were later found inadequate). Our

analytical strategy is built with this idea in mind, though our results are not sensitive to

how multiple events are treated.

        As with earlier equity reforms, states under adequacy orders have varied in the

finance systems that they have adopted. Despite this heterogeneity, there are two

important reasons to expect that adequacy reforms had different impacts on the level and

distribution of school funding than did earlier equity reforms. First, equity reforms often

focused on districts’ property tax bases, where adequacy reforms focused on student

disadvantage; the two may not be strongly correlated (Fischel 1989). Second, where a state


14Our panel excludes the 1989 Rose decision but includes KERA, the legislature’s response in 1990.
15Jackson et al. (2016) code 15 court-ordered SFRs from 1971 through 1989, and 48 since then. We code a
few cases differently than have earlier authors. These are discussed in the Appendix.


                                                                                                          10
might respond to an equity order by “leveling down” to stingy but equal funding, this would

not satisfy an adequacy mandate. States seem instead to have increased funding to all

districts to meet adequacy requirements while still allowing higher-income districts to

differentiate themselves.

       Overall, then, we expect that adequacy reforms caused higher spending, in general

and particularly in low-income districts, than did equity reforms, but perhaps also yielded

smaller reductions in the between-district dispersion (Baker and Green, 2015; Downes and

Stiefel, 2015). We confirm these predictions below.


II.    Analytic approach

       The primary challenge in estimating the causal effect of school funding is that it may

be correlated with other factors that affect realized school finance or student outcomes. An

important concern is that states that are more aggressive in targeting funding to low-

income school districts may also differ in other ways—they may have better developed

social welfare systems, more equitable housing price distributions, or different approaches

to regulating school quality (Hanushek, Rivkin, and Taylor 1996a,b).

       To address this, we leverage variation in the timing of reform events in an event-

study framework. Our strategy is based on the idea that states without events in a

particular year form a useful counterfactual for states that do have events in that year, after

accounting for fixed differences between the states and for common time effects. The key

assumption is that the exact timing of events is as good as random. We think this is

plausible, given the idiosyncrasies of judicial processes discussed above. An attractive




                                                                                            11
feature of our approach is that it builds in placebo tests that should identify likely

violations of this assumption.

         Our simplest event study specification models events as permanent, immediate

shifts in outcomes relative to other states:

   (1)      !"# = %" + '# + 1 ) > )"∗ , -./0 + 1"# .

Here, !"# represents some summary of the distribution of funding or achievement in state s

in year t . We discuss our particular measures below. %" and '# represent state and year

effects, respectively. )"∗ is the date on which state s’s event occurred. (For now, we assume

that each state just one event; this term is set to zero for states that do not have events.)

The coefficient estimate , -./0 represents the change in the outcome following the event.

         SFRs may not affect !"# immediately, but may develop more gradually. This is

particularly true for student achievement outcomes, as the achievement of a student in

year t likely depends in part on the quality of the schooling she received in prior years. In

addition, if event timing is non-random, states with events may diverge from states without

events even before the date of the event. To accommodate these ideas, we add two trend

terms to (1):

   (2)     !"# = %" + '# + 1 ) > )"∗ , -./0 + 1 ) > )"∗ ) − )"∗ , 034"567 + ) − )"∗ , #8579 + 1"# .

, 034"567 captures delayed event effects and represents the annual change in outcomes in

state s after )"∗ , relative to the same state prior to the event. , #8579 , which is identified from

changes in s relative to other states in years prior to )"∗ , represents a falsification test:

, #8579 ≠ 0 would indicate that event timing is meaningfully non-random.

         We also estimate non-parametric models that do not constrain the phase-in and

prior trend effects to be linear:


                                                                                                   12
                                 =>?@
   (3)         !"# = %" + '# +   8A=>BC 1   ) = )"∗ + < ,8 + 1"# .

Here,     r   represents the effect of an event in year )"∗ on outcomes r years later (or

previously, for r<0). These effects are measured relative to year r=0, which is excluded. We

censor r at kmin=-5, so      -5 represents   average outcomes five or more years prior to an

event, relative to those in the event year.

         Comparisons of the parametric and non-parametric estimates indicate that the

simple specification (2) does a good job of capturing dynamics in finances and student

achievement surrounding events, though the post-event “jump” is sometimes spread out

over a few years following the event. The {β-k, …, β-1} pre-event terms in (3) are the

equivalent of the pre-event trend coefficient , #8579 in (2). In only one of the specifications

that we estimate is either , #8579 or the set of nonparametric pre-event coefficients

significantly different from zero, and in this case it appears to be an idiosyncratic blip in a

single β-r coefficient (see Figure 12, below). This supports our identifying assumption.

         When we examine finance outcomes, all of the post-event effect appears to be nearly

immediate, so we focus on the simpler specification (1). By contrast, in our student

achievement analysis, the “jump” is never distinguishable from zero, and all of the effect

that we estimate operates through the , 034"567 coefficient. We thus emphasize

specifications that allow for a phase-in effect but no post-event jump. In each case, these

simple specifications fit the non-parametric results quite well.


Difference-in-differences and triple-differences

         The event study methodology outlined above is a form of difference-in-differences

(DD), identifying the effect of events from deviations in the trend in “treated” states relative



                                                                                               13
to states that have not yet had events. The identifying assumption is that without finance

reforms, outcomes would have moved in parallel in treated and untreated states. Hanushek

et al. (1996a,b) are critical of this assumption with regard to the impacts of school spending

in state-by-year panels. They argue the parallel trend assumption is unlikely to hold,

biasing DD estimates.

        Accordingly, while we present below DD estimates with mean spending or mean

test scores in a state as the outcome, we believe that more credible estimates of the effect of

funding reforms can be obtained from triple-difference (DDD) models that compare the

impacts of SFR events on high- and low-income districts in a state. We implement these

using the DD methodology above by using as the dependent variable !"# a measure of the

achievement of low-income districts in a state relative to that in higher-income districts.

With this type of dependent variable, the event study strategy is robust to arbitrary state-

by-year shocks to spending or achievement, so long as they have similar effects on districts

at different income levels. The identifying assumption is that the relative outcomes of low-

income districts would have followed parallel trends across states in the absence of SFRs.

        We consider two measures of relative spending or achievement in low-income

districts. First, we use the gap between districts in the top and bottom quintiles of the state

income distribution, as in Figures 2 and 3. These quintile gaps can be noisy, in part because

they discard information on the middle 60% of districts. We thus emphasize a second

measure, the slope of district-level outcomes with respect to log average income across all

districts in the state.16 A more negative slope corresponds to higher relative outcomes in



16Specifically, we regress district-level spending per pupil or mean achievement on log mean income,
controlling for log enrollment. The regression is estimated separately for each state and year, and in


                                                                                                         14
low-income districts. Appendix Figure A2 shows that the long-difference analysis from

Figures 2 and 3 is robust to using our slope measures in place of quintile gaps, and yields

even stronger results.

        To illustrate, Figure 6 shows the scatterplot of per pupil state transfers to districts

against log mean district income (measured in 1990) for each district in Ohio, first in 1990

and then in 2011. As the figure shows, state transfers rose dramatically over this period,

particularly in the lower-income districts. We overlay two fitted series on top of this: One

shows mean transfers across all districts in each income quintile, and the other shows the

slope as described above. In this case, the log-linear specification fits the quintile means

fairly well. Across states, the slope is correlated -0.73 with the first-quintile/fifth-quintile

gap.

        We show below that SFRs lead to higher absolute revenues in all districts in a state

and to higher relative revenues in low-income districts, as seen for Ohio in Figure 6. Each of

these could affect the relative achievement of students in low-income districts. First, if

money matters, then the increase in relative spending should raise low-income districts’

achievement. Second, the marginal effect of extra funds may be higher in low-income

districts, perhaps due to declining marginal productivity of additional resources. If so, even

an across-the-board spending increase would raise their relative achievement. Given these

two channels, and timing issues that will become clear below, we are cautious in converting

our estimated effects on achievement into estimates of output per dollar, as it is not clear

what is the appropriate denominator for our DDD treatment effects.



achievement models for each subject and grade. The district log income coefficients are used as !"# for
subsequent analyses at the state-year-(subject-grade) level. See the Appendix for further detail.


                                                                                                          15
Event studies with multiple events

       As noted above, many states had multiple events (court orders or legislation) over

our period. Unfortunately, there is no accepted strategy for conducting event studies with

multiple events per unit.

       Ohio illustrates both the challenge and our proposed solution. The state Supreme

Court ruled four times on the De Rolph v. State case, in 1997, 2000, 2001, and 2002. The

1997 ruling declared the state’s finance system unconstitutional on adequacy grounds, and

specifically rejected the state’s reliance on local property taxes. The Court ordered a

“complete systematic overhaul” of the school funding system. In 2000, the Court

determined that the legislature had failed to act and that funding levels remained

inadequate. The same year, the legislature revised the system, and a subsequent ruling in

2001 determined that the new system, with a few minor changes, satisfied constitutional

requirements. This decision was reversed in 2002, by the same Court (albeit with a

different makeup of judges), and the legislature ordered to make further changes. To our

knowledge, the legislature did nothing to comply with this.

       Our reform database includes Ohio events in 1997, 2000, and 2002. Based on the

above case history, we might expect only the 2000 event to be associated with major

changes in school finance in Ohio. But the data tell a different story. Figure 7 shows the

time series of our two measures of the progressivity of state aid in Ohio: The difference in

average state transfers per pupil between the lowest-income and highest-income fifths of

Ohio school districts (black) and the slope of state transfers with respect to log income,

multiplied by -1 for comparability (gray). Vertical lines indicate the reform events. The

figure shows that state transfers were progressive in 1990 and slowly became more so in



                                                                                             16
the first few years of our data. Around 1998, the trend became notably steeper, and by

2002 average state aid per pupil was $4,851 higher in low-income than in high-income

districts. If anything, relative funding has declined since 2002. This pattern appears

consistent with a gradual reaction to the initial 1997 ruling. There is less visual evidence of

the 2000 event, which did not interrupt the previous trend, while the 2002 ruling seems to

coincide with an end to the increases in progressivity.

         Based on the patterns in Ohio and elsewhere, we adopted two analytical decisions

for our primary estimates. First, we choose a single event in each state. Our idea here is that

when states have multiple events, they often represent jockeying between the legislature

and the courts with only minor changes in school finance until the legislature finally enacts

a major reform, and then continued jockeying afterward as advocates continue to push for

smaller additional changes.

         Second, we do not rely on reviews of case histories to identify the consequential

events, as the rhetoric in court orders and preambles to bills is often (as in Ohio)

misleading about the magnitude of the change being made. Rather, we use the state aid

data to identify a regime change in the progressivity of a state’s finance system, relying on

methods for the identification of change points in time series data (e.g., Bai 1997; see also

Card, Mas, and Rothstein 2008).

         Specifically, let !"# be our slope measure of the progressivity of state aid. For each

state and each potential event date )"∗ , we estimate a time series regression using as the

only explanatory variable an indicator for observations after that date:

   (4)     !"# = D + 1 ) > )"∗ ' + 1"# .




                                                                                                  17
We select the date that yields the largest t statistic for ' – or, equivalently, the smallest

mean squared error – for this time series regression.17 We treat the selected date as the

single event in state s. Bai (1997) shows that this method is super-consistent (with faster

than E convergence) for the location of a structural break in a time series, permitting

inference regarding the magnitude of the break to treat its location as known.

        We present estimates from two additional approaches to multiple events. One

includes all events, without judgment about their relative importance. We create a separate

copy of the time series for the state for each event, using a different value of )"∗ for each

copy. We then stack the copies, replacing the state effects in equations (1)-(3) with state-

by-event effects.18 In Monte Carlo simulations, this method works well to identify the

average effect of events both when each event has the same effect and when only one event

in a state has a non-zero effect.

        Our final approach follows the prior literature by focusing on the initial court order

in each state. Past authors have argued that the timing of initial court orders is effectively

random but that legislative events and subsequent court orders may not be. The drawback

to this approach is that there can be long lags between the initial court order and the

implementation of a reform. It is thus better suited to simple models like (1) that are not

sensitive to mis-timing the structural break—most past work using this approach has

focused on such models—than to more flexible models like our non-parametric

specification (3).




17We restrict attention to t* for which the estimated ' has the expected sign.
18Results are unchanged when data are reweighted to offset the overrepresentation of states with multiple
events.


                                                                                                        18
        In appropriate specifications, results are quite robust across all three methods.

Accordingly, we do not view multiple events as a major issue in practice.


III.    Data

        Our analysis draws on data from several sources. We begin with our database of

state SFR events, discussed above. We merge this to district-level school finance data, from

the National Center for Education Statistics’ (NCES) annual census of school districts (the

Common Core of Data, or CCD, district finance files, also known as the “F-33” survey) and

the Census of Governments; mean household income by district from the 1990 Census; and

NAEP achievement.

        The CCD district finance data report enrollment, revenues and expenditures

annually for each local education agency (LEA).19 We convert all dollar figures to 2013

dollars per pupil, and exclude very small districts and those with highly volatile enrollment

or implausible per-pupil funding. Details are in the appendix.

        Our student outcome measures come from the National Assessment of Educational

Progress (NAEP). We use restricted-use microdata from the “State NAEP,” designed to

produce state-representative samples. State NAEP began in 1990, with 42 states

participating. It has been administered roughly every two years since. Since 2003, all states

have participated in 4th and 8th grade assessments in math and reading in every odd-

numbered year.20 Table 1 shows the schedule. Tests are administered to around 100,000

students (more in later years) in each subject-grade-year. These consist of representative

samples of about 2,500 students per state, spread across about 100 schools.

19 Census data are available in 1989-90 and 1991-92, and annually since 1994-95. We use samples from the
Census Bureau’s Annual Survey of Government Finances for 1992-93 and 1993-94.
20 The NAEP also tests 12th graders, but samples are smaller, and other subjects.




                                                                                                       19
        The NAEP uses a consistent scoring scale across years for each subject and grade.

We standardize scores to have mean zero and standard deviation one in the first year that

the test was given for the grade and subject, but allow both the mean and variance to

evolve afterward. We then aggregate to the district-year-grade-subject level and merge to

the CCD and SDDB.21

        Table 2a presents district-level summary statistics, pooling data from 1990-2011.

Table 2b presents summary statistics for the state-year panel.


IV.     Finance reforms and school finance

        We begin our empirical analysis by documenting the implications of SFR events for

school finance. We use the approach discussed in Section II to identify a single SFR event in

each state, selecting among candidate events the one that best explains the time series of

the state aid – log district income slope in the state.

        Figure 8, panel A graphs event study results for average state transfers per pupil in

the state, pooling all districts. We present a number of plots of this basic form. The solid

line presents estimates of the non-parametric event study specification (3), while dotted

lines show pointwise 95% confidence intervals. The dashed line shows the parametric

specification (2).

        Point estimates indicate that average state transfers to districts rise in the years

leading up to an event, though this could be just sampling error – the p-value for equality

across all years prior to the events is 0.31. By contrast, in the four years following the event

average state transfers rise by roughly $1,000. They decline somewhat in subsequent

21The pre-2000 NAEP data do not use the same district codes as the CCD. We crosswalk using a link file
produced for NCES by Westat (and obtained from the Educational Testing Service), using district names to
check and supplement the crosswalk.


                                                                                                           20
years, but even 15 years after the focal event remain approximately $500 above what

would have been expected without the event. The differences from the event year are

significant both collectively (p<0.001) and individually for relative years 1-10. The

parametric specification fits the nonparametric results well. Panel B of Figure 8 repeats the

exercise, this time using total per-pupil revenues (inclusive of local revenues and federal

transfers) as the dependent variable. The pattern is quite similar here, with little indication

that increases in state revenues are offset by reductions in local effort on average.

       Columns 1 and 3 of Table 3 present coefficients from our simplest one-parameter

event study specification (1), first for state revenues and then for total revenues. Events are

associated with increases in state aid of $912 per pupil, and with slightly smaller increases

($829 per pupil) in total revenues. Columns 2 and 4 present the three-parameter

specification (2). Post-event effects are quite similar to those seen in the one-parameter

models; while point estimates indicate that they trend down over subsequent years, these

are not distinguishable from zero. In column 2, the upward trend preceding events that was

visible in Figure 8a is small and insignificant, supporting our assumption that event timing

is random.

       These results preview a general pattern we see throughout our finance analyses.

Nonparametric models show a large jump over the first three to four years following the

event, with relatively small trends before and after. Pre-event trends are never statistically

significant, and while we can generally reject zero effect of events on all post-event

outcomes, we can never (in the three-parameter model) reject a single jump following the

event that persists unchanged thereafter. Accordingly, we focus on the one-parameter

model for subsequent finance analyses.



                                                                                              21
       In additional analyses of state budgets, (Appendix Table A2) we have found no

indication that growth in educational spending following events crowds out state spending

on other programs; rather, SFRs are associated with increases in state tax collections large

enough to fully fund the increase in state transfers to districts.

       We turn next to examining the impact of SFRs on the distribution of funding across

school districts. Figure 9 presents event study analyses, similar to those in Figure 8, for

average state aid and total revenues per pupil in districts in the top and bottom quintiles of

the state income distribution. There is again some indication of pre-event upward trends in

state revenues, but again we cannot reject the null hypothesis of zero pre-event differences.

Both low- and high-income districts see increases in state and total revenues following the

event, but the increases are larger in low-income districts: Roughly $1,300 by the 4th post-

event year, vs. less than half that (and not robustly significant) in high-income districts.

Though out-year estimates are noisy, impacts appear to persist through the end of our

sample. Patterns for total revenues are very similar to those for state revenues, and show

little sign that state revenue increases are offset by reductions in local revenues.

       Panels B and C of Table 3 present the parametric estimates for the lowest- and

highest-income districts. Average state funding is $1,225 higher after events in first quintile

districts and $527 (not significant) higher in fifth quintile districts; in each case, total

revenue changes are of similar magnitude, and the more flexible specification yields similar

results.

       Figure 10 shows estimates of impacts on the progressivity of total revenues, using in

the top panel the difference in funding between bottom- and top-quintile districts and in

the lower panel the slope of funding with respect to log district income. Parametric models



                                                                                               22
for these outcomes are shown in Column 4 of Table 4. Using each measure, we see sharp

increases in relative state funding for low-income districts following events that are

sustained (though not always precisely estimated) for many years. In no case is there any

sign of a pre-event trend that would suggest a violation of our random timing assumption.

Nor is there any sign in Table 4 that increased progressivity of state aid is offset by local

revenues.22

        A natural question is how the additional funds are spent. Table 5 presents event-

study coefficients from our one-parameter model for per-pupil revenues and spending in

various categories. There is no apparent impact of SFRs on local or federal revenues. We

see substantial impacts of SFRs on average instructional spending, both overall and in Q1

districts (columns 2 and 3). We also see effects on teachers per pupil, suggesting that

districts use additional funds to reduce class size, though we find no sign of impacts on

teacher pay.23 We also see large increases in non-instructional expenditures, particularly

capital outlays.

        Columns 4 and 5 show results for relative spending in low-income districts. Little of

the increase in relative funding goes to instructional expenditures, while roughly half goes

to capital spending. The capital spending effect is not surprising; many lawsuits specifically

concern dreadful conditions in low-income schools, and SFR remedies often created funds

to support renovation of schools in poor shape.24


22 When we estimate specifications similar to Card and Payne’s (2002) closely related analysis of earlier SFRs
(Appendix Table A3), estimated SFR effects are slightly larger but imprecise, and well within the earlier
confidence intervals. Where Card and Payne find that total revenues rise by about $0.50 per extra $1 in state
aid, our estimates indicate much more stickiness for the recent reforms.
23 Using a different research design, Sims (2011b) finds effects of SFRs on teacher pay.
24 Neilson and Zimmerman (2014) find that school reconstruction causes increases in student achievement.

Cellini et al. (2010) and Martorell, Stange, and McFarlin (2015) fail to find significant effects, but each study is
under-powered to detect effects of plausible magnitude.


                                                                                                                 23
V.     Finance reforms and district-level student achievement

       We can now turn to our main analysis, examining the effect of SFRs on student

achievement. The above results establish that reform events are associated with sharp,

immediate increases in the progressivity of school finance, with absolute and relative

increases in revenues in low-income school districts. If additional funding is productive, we

might expect to see impacts on student outcomes.

       Where the !"# school finance measures formed a state-by-year panel, for test scores

we have two additional dimensions: Grade and subject. We replace the year fixed effects

('# ) in (1)-(3) with subject-grade-year effects. These capture any differences in tests

between administrations, as well as changes in student performance by grade and/or

subject that are common across states. To avoid confounding from state-level shocks, we

focus on DDD specifications that use the achievement gap between low- and high-income

districts as the dependent variable.

       Sharp, permanent changes in funding, if used productively, should increase the flow

of educational services. Achievement is cumulative, so these services are unlikely to have

immediate impacts on test scores, but should raise scores gradually as students are

exposed for longer. Effects should grow at least until students have been exposed to the

new funding levels for their entire careers. They may even continue to grow beyond this

point. For example, consider a state that responds to a court order by creating a new

permanent facility to fund several school renovation and construction projects each year.

Initially, only a few students benefit, but over time growing shares of students are exposed

to funded projects. Insofar as better facilities promote student learning, achievement

effects would continue to grow until several years after the last project is complete,



                                                                                             24
potentially decades after the initial policy change. We thus emphasize the phase-in

coefficient from equation (2) as the primary measure of SFR effects on test scores.

           Figure 11 presents our event-study analysis of the slope of achievement with

respect to district income. As before, we present non-parametric results (equation 3) as a

solid line and estimates of our three-parameter model (equation 2) as a dashed line. There

is no indication of a differential trend in reform states prior to events. Following events, the

non-parametric series does not react immediately, but begins trending noticeably

downward starting in about the fifth post-event year. The downward trend continues

through the end of our sample.25

           Table 6 presents parametric estimates. We begin in Column 1 with our three-

parameter model, as shown in Figure 11. Again, the estimated pre-event trend is essentially

zero and the post-event jump is also small, but the post-event change in trend is large and

statistically significant. Column 2 presents a specification that discards the other two

coefficients. Results are quite similar. The estimated change in the slope is -0.010 per year.

This implies that each year after an event, a district with log mean income one unit (about

two thirds) below the state average sees its scores rise relative to the state average by

0.010 standard deviations, accumulating to 0.10 SDs over ten years. This is quantitatively

meaningful – on average in our sample the slope of test scores with respect to log income is

0.96 so SFRs reduce this gradient by approximately one-tenth within ten years.

           As discussed above, the pattern of gradually growing effects in Figure 11 is

consistent with a view of achievement as a stock reflecting accumulated past input flows.

The pattern deviates from expectations in one respect, however: There is no indication that


25   The sawtooth pattern at the end of the sample likely reflects the biannual NAEP testing schedule.


                                                                                                         25
the phase-in of the effect slows five or nine years after the event, when the 4th and 8th

graders, respectively, will have attended school solely in the post-event period.26 This may

reflect the use of some additional funds for durable investments, as discussed above. We do

not have enough precision, however, to rule out a flattening of the effect at the expected

time.

        Figure 12 presents estimated test score impacts for the lowest- and highest-income

districts. The effects on the income gradient are driven by dramatic increases in test scores

in the lowest-income districts.27 In higher-income districts, there is little sign of a

systematic post-event change. Parametric estimates are shown in Columns 3 and 4 of Table

6; Column 5 shows that the impact of events on the test score gap between bottom- and

top-quintile districts is 0.008 SDs per year. This grows when trend terms are included

(column 6). The gap in mean log incomes between the top and bottom quintiles averages

0.65, so the quintile point estimate is a bit larger than what we obtain for our income slope

measure in columns 1-2. Our earlier finance analyses also indicated larger effects for

quintile gaps than for slopes.

        Appendix Figure A3 presents estimates of the phase-in coefficient for all five

quintiles. Only the first quintile effect is large or distinguishable from zero. The ratio of test

score effects to spending effects is larger at the bottom of the income distribution,

consistent with the idea that funding is more productive in low-income districts, but equal

ratios cannot be ruled out.



26 We have estimated separate non-parametric models for 4th and 8th grade scores. Both sets of effects grow
roughly linearly through the end of our panels. See Appendix Figure A4.
27 For the lowest-income districts (Figure 12A), we can reject the null hypothesis of zero pre-event effects.

This is driven by what appear to be a blip in test scores two years prior to events. A similar blip is apparent
for high-income districts in Panel B. There is no sign of systematic pre-event trends.


                                                                                                              26
       Table 7 presents estimates separately by grade and subject. We cannot reject the

null hypothesis of equal effects across each dimension.


Robustness

       Table 8 presents estimates of our key specifications from our two alternative

approaches to event multiplicity. Column 1 repeats the estimates from our preferred

approach from Tables 4 and 6. In Column 2, we include all identified events, creating

separate panels for each; in Column 3, we focus only on the first court order in each state.

Results are similar to those from our main specifications, though the initial court order

approach yields less precise, insignificant estimates of finance effects.

       One potential explanation for the achievement impacts that we identify is that they

reflect changes in population stratification rather than changes in educational production.

SFRs that flatten the gradient of school funding with respect to district income and that

reduce the local share of school finance reduce the value of living in a high-income district,

and may lead some high-income families to relocate to previously low-income districts.

This could lead to rising achievement in these districts with no change in school

effectiveness.

       We assess this possibility in three ways. First, we have tested whether between-

district income gaps narrow in the years following SFRs. We have found no evidence for

this – district log incomes in 2011 are highly correlated with those in 1990, and there is no

sign that gaps narrow in states that had reforms vs. those that didn’t. Second, we have

conducted event study analyses, parallel to those for test scores, for district income or the

district non-white or free- or reduced-price lunch eligible share (Appendix Table A5). In

only one specification – for the between-quintile gap in the free lunch share – do we find


                                                                                             27
evidence that the demographic composition of (initially) low-income districts changes

following SFRs. This result is not robust, and is small relative to the test score impacts that

we estimate.

       Third, we decompose test scores into two components, and estimate separate SFR

effects on each. Specifically, we estimate an individual-level regression of test scores on

student demographic characteristics, pooling NAEP data across years for each grade-

subject pair and including year fixed effects. We then construct separate achievement-log

district income gradients from the fitted values (excluding the fixed effects) for this

regression, representing student characteristics that would be affected by SFRs only

through changes in sorting, and from the residuals. Table 9 presents results of our event

study analyses of these gradients. We present two decompositions: The first panel uses

only race and gender, which are consistently available in each NAEP wave, along with

school means of these. The next uses additional covariates, parental education and free

lunch status, that are less consistently available, including indicators for years in which

each is unavailable. The first set of variables explains 22% of the variance in student test

scores (net of the subject-grade-year effects), while the second set explains 28%.

       We find no evidence that reforms affect the demographic component of our test

score progressivity measures. Point estimates are less than half the size of our overall test

score impacts, and are never significantly different from zero. By contrast, estimated effects

on the residual component of test scores are significant and about two-thirds the size of the

overall impacts. Thus, while we cannot rule out small effects of SFRs on student sorting, the

robustness of effects on the residual component supports our interpretation that our

results primarily reflect changes in educational production in low-income school districts.



                                                                                               28
       As a final robustness exercise, we have tested whether the SFR effect on

achievement is sensitive to including controls for the presence of a school accountability

policy in a state, or whether the SFR effect varies with school accountability. We found

evidence for neither.


VI.    Finance reforms and statewide achievement gaps

       The final topic that we investigate is whether finance reforms closed overall test

score gaps between high- and low-achieving, minority and white, or low-income and non-

low-income students in a state. These are perhaps better measures than our slopes and

quintile gaps of the overall effectiveness of a state’s educational system at delivering

equitable, adequate services to disadvantaged students (Krueger and Whitmore 2002; Card

and Krueger 1992b). However, because most inequality is within districts, changes in the

distribution of resources across districts may not be well enough targeted to meaningfully

close these gaps.

       Table 10 presents estimates of effects on mean test scores across different

subgroups of interest. The first panel shows a DD estimate of the effect on mean (pooled)

test scores. The point estimate (not insignificant) implies a smaller impact per dollar than

do our between-district contrasts, though we cannot rule out comparable effect sizes. In

any event, our research design is more credible for outcome disparities than for the level of

outcomes, as the latter would be confounded by unobserved shocks to average outcomes in

a state that are correlated with the timing of school finance reforms (Hanushek, Rivkin, and

Taylor 1996a,b). For example, if SFRs follow negative shocks to mean student achievement,




                                                                                             29
this effect would be downward-biased. Another interpretation is that the marginal

productivity of revenues is in fact higher in low-income districts.

       The second panel shows impacts on the standard deviation or interquartile range of

achievement within states, while the third and fourth panels present results by race and

income, respectively. There is no discernible effect on achievement gaps by race or income

or on the overall dispersion of test scores. Point estimates are all roughly a full order of

magnitude smaller than the earlier estimates for district-level progressivity of mean scores.

       Appendix Tables A6 and A7 resolve the discrepancy. While non-white, low-income,

and low-scoring students are more likely than their white, higher-income, and higher-

scoring peers to attend school in low-income school districts, the differences are not very

large. Roughly one-quarter of non-white and low-scoring students, and one-third of low-

income students, live in first-quintile districts, while about 10% of each live in fifth-quintile

districts. This leaves little room for SFRs to substantially affect the relative resources to

which the typical minority, low income, or low scoring student is exposed.

       To assess this more carefully, we assigned each student the mean revenues for

his/her district and estimated event study models for the black-white, income, or test score

gap in these imputed revenues. Results, in Appendix Table A7, indicate that finance events

raise relative per-pupil revenues in the average black student’s school district by only $195

(S.E. 164), in the average low-income student’s district by $23 (S.E. 195), in the average

low-scoring student’s district by 193 (S.E. 101). Even if funding was much more productive

than the average effect implied by our analysis, the funding changes seen here would still

not be enough to yield effects on black or low-income students’ average test scores large

enough to detect with our research design. Thus, while reforms aimed at low-income



                                                                                                30
districts appear to have been successful at raising resources and outcomes in these

districts, we conclude that within-district changes would be necessary to have dramatic

impacts on the average low-income, minority, or low-scoring student.


VII.   Discussion

       After desegregation, school finance reform is perhaps the most important education

policy change in the United States in the last half century. But while the effects of the early

reforms on school finance have been well studied, there is little evidence about the finance

effects of more recent “adequacy” reforms or about the effects of any of these reforms on

student achievement. Our study presents new evidence on each of these questions.

       We find that state-level school finance reforms enacted during the adequacy era

markedly increased the progressivity of school spending. They did not accomplish this by

"leveling down" school funding, but rather by increasing spending across the board, with

larger increases in low-income districts. Using nationally representative data on student

achievement, we find that this spending was productive: Reforms increased the absolute

and relative achievement of students in low-income districts. Our estimates thus

complement those of Jackson et al. (2016), who examine the long-run impacts of earlier

school finance reforms and find substantial positive impacts on a variety of long-run

outcomes.

       The different time patterns of impacts on resources and on student outcomes,

combined with the cumulative nature of the latter, prevents a simple instrumental

variables interpretation of the reduced-form coefficients in terms of the achievement effect

per dollar spent – it is not clear which years’ revenues are relevant to the accumulated




                                                                                              31
achievement of students tested r years after an event. To assess the magnitude of the

impacts we estimate, we focus on estimated effects on student achievement ten years after

an event. Because effects on school resources are stable in the years following events, these

can be interpreted as the impact of a change in resources for every year of a student’s

career (through 8th grade). Nevertheless, the focus on the r=10 estimate is arbitrary. We

would obtain larger estimates of the achievement effect per dollar if we used impacts more

than ten years after events, or smaller effects with a shorter window.

        Our preferred estimates, based on the gradient of student achievement with respect

to district income, indicate that an SFR raises achievement in a district with log average

income one point below the state mean, relative to a district at the mean, by 0.1 standard

deviations after ten years. Our finance estimates indicate that this district saw an increase

in relative state aid of $622 per pupil for each of those ten years, and an increase in total

revenues of $424 per pupil.

        $424 per pupil in spending each year from kindergarten through grade 8,

discounted to the student’s kindergarten year using a 3% rate, corresponds to a present

discounted cost of $3,400. Chetty et al. (2011) estimate that a 0.1 standard deviation

increase in kindergarten test scores translates into increased earnings in adulthood with

present value of $5,350 per pupil. This implies a benefit-cost ratio of 1.5, even when only

earnings impacts are counted as benefits.28

        This ratio is not wholly robust. Our quintile analysis shows larger revenue effects,

implying a benefit-cost ratio below one, while Jackson et al.’s (2016) study of the effects of


28The earnings effects of increases in 8th grade test scores are likely larger than those of increases in
Kindergarten scores, so using estimates of the latter biases our benefit calculation downward. We do not
count the cost of increased spending in grades 9-12, as we have no way to capture its benefits.


                                                                                                            32
earlier finance reforms on students’ adult outcomes implies much larger benefits per dollar

than does our calculation. Thus, although these sorts of calculations are quite imprecise,

the evidence appears to indicate that the spending enabled by finance reforms was cost-

effective, even without accounting for beneficial distributional effects.

        It is important to note that our research design is poorly suited to identifying the

optimal allocation of school resources across expenditure categories, or to testing whether

actual allocations are close to optimal. It allows us only to say that the average finance

reform—which we interpret to involve roughly unconstrained increases in resources,

though in some cases the additional funds were earmarked for particular programs or tied

to other reforms—led to a productive (though perhaps not maximally productive) use of

the funds.29

        Our results thus show that money can and does matter in education, and

complement similar results for the long-run impacts of school finance reforms from

Jackson et al. (2016). School finance reforms are blunt tools, and some critics (Hanushek,

2006; Hoxby, 2001) have argued that they will be offset by changes in district or voter

choices over tax rates or that funds will be spent so inefficiently as to be wasted. Our

results do not support these claims. Courts and legislatures can evidently force

improvements in school quality for students in low-income districts.

        But there is an important caveat to this conclusion. As we discuss in Section VI, the

average low-income student does not live in a particularly low-income district, so is not

well targeted by a transfer of resources to the latter. Thus, we find that finance reforms


29Stronger school accountability may provide incentives to schools to allocate their resources more
efficiently (Hanushek 2006). We investigated specifications that allowed for interactions between finance
reform events and the state’s accountability policy, but found no evidence for this.


                                                                                                            33
reduced achievement gaps between high- and low-income school districts but did not have

detectable effects on resource or achievement gaps between high- and low-income (or

white and black) students. Attacking these gaps via school finance policies would require

changing the allocation of resources within school districts, something that was not

attempted by the reforms that we study.



References

Bai, J. (1997). Estimation of a change point in multiple regression models. Review of
         Economics and Statistics, 79(4), 551-563.
Baker, B. D., & Green, P. C. (2015). Conceptions of equity and adequacy in school finance. In
         H. F. Ladd and M. E. Goertz, eds., Handbook of Research in Education Finance and
         Policy, 2nd edition. New York, NY: Routledge.
Burtless, G. (1996). Does Money Matter? The Effect of School Resources on Student
         Achievement and Adult Success. Washington, D.C.: Brookings Institution Press.
Card, D., & Krueger, A. B. (1992a). Does school quality matter? Returns to education and the
         characteristics of public schools in the United States. Journal of Political Economy,
         100(1), 1–40.
Card, D., & Krueger, A. B. (1992b). School quality and black-white relative earnings: A direct
         assessment. Quarterly Journal of Economics, 107(1), 151-200.
Card, D.; Mas, A., & Rothstein, J. (2008). Tipping and the dynamics of segregation. Quarterly
         Journal of Economics, 123(1), 177–218.
Card, D., & Payne, A. A. (2002). School finance reform, the distribution of school spending,
         and the distribution of student test scores. Journal of Public Economics, 83(1), 49-82.
Cascio, E. U., Gordon, N., & Reber, S. (2013). Local responses to federal grants: evidence
         from the introduction of title I in the South. American Economic Journal: Economic
         Policy, 5(3), 126-159.
Cascio, E. U., & Reber, S. (2013). The poverty gap in school spending following the
         introduction of Title I. American Economic Review, 103(3), 423-427.
Cellini, S., Ferreira, F., & Rothstein, J. (2010). The value of school facility investments:
         Evidence from a dynamic regression discontinuity design. Quarterly Journal of
         Economics 125(1), 215-261.
Chetty, R., Friedman, J. N., Hilger, N., Saez, E., Schanzenbach, D. W., & Yagan D. (2011). How
         does your Kindergarten classroom affect your earnings? Evidence from Project
         STAR. Quarterly Journal of Economics, 126(4), 1593-1660.
Clark, M. A. (2003). Education reform, redistribution, and student achievement: Evidence
         from the Kentucky Education Reform Act. Unpublished working paper, Mathematica
         Policy Research, Princeton, NJ.
Coleman, J. S., Campbell, E. Q., Hobson, C. J., McPartland, J., Mood, A. M., Weinfeld, F. D., &
         York, R. (1966). Equality of Educational Opportunity. Washington, DC, 1066-5684.


                                                                                             34
Coons, J. E., Clune, W. H., & Sugarman, S. (1970). Private Wealth and Public Education.
        Cambridge, MA: Belknap Press.
Corcoran, S. P., & Evans, W. N. (2015). Equity, adequacy, and the evolving state role in
        education finance. In H. F. Ladd and M. E. Goertz, eds., Handbook of Research in
        Education Finance and Policy, 2nd edition. New York: Routledge.
Dee, T. S., & Jacob, B. (2011). The impact of No Child Left Behind on student achievement.
        Journal of Policy Analysis and Management, 30(3), 418-446.
Downes, T., Stiefel, L. (2015). Measuring equity and adequacy in school finance. In H. F.
        Ladd & M.E. Goertz, eds., Handbook of Research in Education Finance and Policy, 2nd
        edition. New York, NY: Routledge.
Duncombe, W.D., Nguyen-Hoang, P., & J. Yinger (2015). Measurement of cost differentials.
        In H. F. Ladd, & M.E. Goertz, eds., Handbook of Research in Education Finance and
        Policy, 2nd edition. New York, NY: Routledge.
Dynarski, S., Hyman, J., & Schanzenbach, D. W. (2013). Experimental evidence on the effect
        of childhood investments on postsecondary attainment and degree completion.
        Journal of Policy Analysis and Management, 32(4), 692-717.
Fischel, W.A. (1989). Did Serrano cause Proposition 13? National Tax Journal 42(4): 465-
        73.
Flanagan, A. E., and Murray, S. E. (2004). A Decade of Reform: The Impact of School Reform
        in Kentucky. In J. Yinger, ed., Helping Children Left Behind: State Aid and the Pursuit
        of Educational Equity (pp. 165-213). Cambridge, MA: MIT Press.
Guryan, J. (2001). Does money matter? Regression-discontinuity estimates from education
        finance reform in Massachusetts. National Bureau of Economic Research Working
        Paper No. 8269.
Hanushek, E. A. (1986). The economics of schooling: Production and efficiency in public
        schools. Journal of Economic Literature, 24(3), 1141-1177.
Hanushek, E. A. (1997). Assessing the effects of school resources on student performance:
        An update. Educational Evaluation and Policy Analysis, 19(2), 141-164.
Hanushek, E. A. (2003). The failure of input-based schooling policies. The Economic Journal,
        113, F64-F98.
Hanushek, E. A. (2006). School resources. In E. A. Hanushek and F. Welch, eds., Handbook of
        the Economics of Education, vol. 2. Elsevier.
Hanushek, E. A. & Lindseth, A. A. (2009). Schoolhouses, Courthouses and Statehouses: Solving
        the Funding-Achievement Puzzle in America’s Public Schools. Princeton: Princeton
        University Press.
Hanushek, E. A., Rivkin, S. G., & Taylor, L. L. (1996a). Aggregation and the estimated effects
        of school resources. The Review of Economics and Statistics 78(4), 611-627.
Hanushek, E. A., Rivkin, S. G., & Taylor, L. L. (1996b). The identification of school resource
        effects. Education Economics, 4(2), 105-125.
Horowitz, H. (1966). Unseparate but unequal: The emerging Fourteenth Amendment issue
        in public school education. UCLA Law Review, 13, 1147-1172.
Hoxby, C. M. (2001). All school finance equalizations are not created equal. The Quarterly
        Journal of Economics, 116(4), 1189-1231.
Hyman, J. (2013). Does money matter in the long run? Effects of school spending on
        educational attainment. Unpublished manuscript.



                                                                                            35
Jackson, C. K., Johnson, R. C., & Persico, C. (2016). The effects of school spending on
       educational and economic outcomes: Evidence from school finance reforms.
       Quarterly Journal of Economics 131(1), 157-218.
Kirp, D. L. (1968). The poor, the schools, and equal protection. Harvard Educational Review
       38, 635-668.
Koski, W. S., & Hahnel, J. (2015). The past, present and future of educational finance reform
       litigation. In H. F. Ladd and M. E. Goertz, eds., Handbook of Research in Education
       Finance and Policy, 2nd edition. New York: Routledge.
Krueger, A. B. (1999). Experimental estimates of education production functions. The
       Quarterly Journal of Economics, 114(2), 497-532.
Krueger, A. B. (2003). Economic considerations and class size. The Economic Journal 113,
       F34-F63.
Krueger, A. B., & Whitmore, D. M. (2002). Would smaller classes help close the black-white
       achievement gap? In J. E. Chubb and T. Loveless, eds., Bridging the Achievement Gap.
       Washington: Brookings Institution Press.
Ladd, H. F., & Goertz, M. E. (Eds.). (2015). Handbook of Research in Education Finance and
       Policy, 2nd Edition. New York, NY: Routledge.
Levine, P. B., & Schanzenbach, D. (2009). The impact of children’s public health insurance
       expansions on educational outcomes. Forum for Health Economics & Policy, 12(1), 1-
       26.
Martorell, P., Stange, K. M., & McFarlin, I. (2015). Investing in schools: Capital spending,
       facility conditions, and student achievement. NBER Working Paper 21515,
       September.
Murray, S. E., Evans, W. N., & Schwab, R. M. (1998). Education-finance reform and the
       distribution of education resources. American Economic Review, 88(4), 789-812.
Nielson, C., & Zimmerman, S. (2014). The effect of school construction on test scores, school
       enrollment, and home prices. Journal of Public Economics 120.
Sims, D. P. (2011a). Lifting all boats? Finance litigation, education resources, and student
       needs in the post-Rose era. Education Finance and Policy, 6(4), 455-485.
Sims, D. P. (2011b). Suing for your supper? Resource allocation, teacher compensation and
       finance lawsuits. Economics of Education Review, 30(5), 1034-1044.
Wise, A. (1967). Rich Schools, Poor Schools: The Promise of Equal Educational Opportunity.
       Chicago, IL: University of Chicago Press.




                                                                                          36
Figures

       Figure 1: Mean revenues per pupil for highest and lowest income school districts, 1990-2012


                            14000
              Q1, Q5 Mean Total Revenues
                 10000        12000
                            8000




                                           1990   1995      2000      2005          2010
                                                               Year

                                                         Q1 Mean      Q5 Mean



Notes: Highest (lowest) income districts are those in the top (bottom) 20% of their states’ district-level
distributions of mean household income in 1990, and are labeled as ”Q5” and ”Q1”, respectively. See
appendix for details of quintile classifications. Revenues are expressed in real 2013 dollars. Districts are
averaged within states, weighing by log district enrollment; states are then averaged without weights. Hawaii
and the District of Columbia are excluded.




                                                                                                          37
Figure 2: Gap in revenues per pupil between lowest and highest income districts, by state finance reform
status, 1990-2012
                          1000
             Q1−Q5 Mean Total Revenues
               −500      0−1000   500




                                         1990   1995          2000           2005           2010
                                                                 Year

                                                No Reform States    Finance Reform States



Notes: See notes to Figure 1. Finance reform states are those with school finance reforms between 1990 and
2011, as listed in Appendix Table A1. Lines show unweighted best linear fit to time series.




                                                                                                       38
Figure 3: Gap in average test scores between lowest and highest income districts, by state finance reform
status, 1990-2011
                      −.4
             Q1−Q5 Mean Score
             −.6       −.5
                      −.7




                                1990   1995               2000            2005         2010
                                                            Year

                                       No Reform States        Finance Reform States



Notes: Lowest (Q1) and highest (Q5) income districts are defined as in Figure 1. NAEP observations in
districts in each quintile are averaged, using NAEP sampling weights and separately for each grade and
subject tested, and the Q1-Q5 di↵erence is computed for each state. State-grade-subject Q1-Q5 di↵erences
are averaged separately for each group of states, weighting by the harmonic mean of the sum of the student
weights in Q1 and Q5 districts. Lines show best linear fit to the time series.




                                                                                                       39
                                    Figure 4: Timing of school finance events
                   8




                                                                                         Statute
                                                                                         Court
                   6
           Events per year
                  42
                   0




                             1990                      2000                              2010
                                                        Year


Notes: Each entry represents a state with a school finance reform event (a major court ruling and/or
substantial statutory change) in a particular year. States may have multiple events. When states have
multiple events in the same year, they are counted only once, as a court event if any of the events were court
rulings and as a statute otherwise. Events are listed in Appendix Table A1.




                                                                                                           40
                   Figure 5: Geographic distribution of post-1989 school finance events




                                                                                                 No Event
                                                                                                 Post-1990
                                                                                                 Reform
                                                                                                 Event




Notes: Map indicates states that had school finance reform events, as listed in Appendix Table A1, between
1990 and 2011.




                                                                                                            41
                                         Figure 6: State revenues per pupil vs. district income, Ohio, 1990 and 2012



                                                             1990                                        2012
                                        20000




                                                                                    20000
          State aid per pupil (2013$)
                                        15000




                                                                                    15000
                                        10000




                                                                                    10000
                                        5000




                                                                                    5000
                                        0




                                                                                    0




                                                9.5   10   10.5    11   11.5   12           9.5   10   10.5   11   11.5   12

                                                                  ln(district avg. HH income, 1990)


Notes: Each circle represents one district; size is proportional to average district enrollment over 1990-2012.
Solid lines represent a regression of state revenue per pupil (2013$) on log 1990 district mean household
income, controlling for enrollment and district type (see footnote 16). Dashed lines represent means among
districts in each quintile of the district mean income distribution.




                                                                                                                               42
                                   Figure 7: Progressivity of state revenue distributions, Ohio, 1990-2012
                     5000  4000
           2013$ per pupil
              3000   2000




                                                                                    Q1−Q5 difference
                     1000




                                                                                    −1*(Log income gradients)

                                  1990            1995             2000              2005             2010
                                                                   Fiscal year


Notes: Dark line represents the di↵erence in mean state revenue per pupil (2013$) between the lowest (Q1)
and highest (Q5) income districts in Ohio. Districts are classified based on 1990 mean household income
and are weighted by log enrollment; see notes to Figure 1 for details. Lighter line represents regressions of
state revenue per pupil on log mean income, controlling for enrollment and district type (see footnote 16); in
this figure, coefficients are multiplied by -1 to facilitate comparisons. Solid vertical lines represent plainti↵
victories in the Ohio Supreme Court in De Rolph v State I, II, and IV in 1997, 2000, and 2002.




                                                                                                                43
   Figure 8: Event study estimates of e↵ects of school finance reforms on mean state and total revenues




                                                   2000
                     Change in mean state revenues
                      −1000      0         1000
                                       −2000




                                                          −5    0            5            10           15             20
                                                                            Years Since Event

                                                               Non−Parametric Estimate          Parametric Estimate


                                                                         (a) State revenue
                                                 2000
                     Change in mean total revenues
                     −1000      0       1000
                                       −2000




                                                          −5    0            5            10           15             20
                                                                            Years Since Event

                                                               Non−Parametric Estimate          Parametric Estimate


                                                                         (b) Total revenue


Notes: Figure displays coefficients from event study regressions, where the dependent variable is mean state
(panel A) and total (panel B) revenues per pupil (2013$) across all districts in a state. Dashed lines show
the three-parameter parametric model (equation 2). Solid lines show the non-parametric model (equation
3), with the event year (indicated as 0) as the excluded category; dotted lines represent 95% confidence
intervals. Estimates for the parametric models are reported in Table 3, Panel A, Columns 2 and 4. p values
for omnibus hypothesis tests of zero pre- and post-event e↵ects in the non-parametric model are 0.31 and
<0.001, respectively, in Panel A, and 0.15 and <0.001 in Panel B. In the parametric model, the p-value for
the hypothesis that the pre-event trend is zero is 0.18 in Panel A and 0.79 in Panel B; for the test that the
post-event jump and change in trend is zero it is 0.11 and 0.01, respectively.
                                                                                                                           44
Figure 9: Event study estimates of e↵ects of school finance reforms on mean revenues in lowest and highest
income districts
                  4000




                                                                                                                      4000
 Change in Q1 mean state revenues




                                                                                                     Change in Q1 mean total revenues
                     2000




                                                                                                                         2000
         0




                                                                                                             0
                  −2000




                                                                                                                      −2000
                                    −5    0            5            10           15             20                                      −5    0            5            10           15             20
                                                      Years Since Event                                                                                   Years Since Event

                                         Non−Parametric Estimate          Parametric Estimate                                                Non−Parametric Estimate          Parametric Estimate


                                              (a) State revenue, Q1                                                                               (b) Total revenue, Q1
                  4000




                                                                                                                      4000
 Change in Q5 mean state revenues




                                                                                                     Change in Q5 mean total revenues
                     2000




                                                                                                                         2000
         0




                                                                                                             0
                  −2000




                                                                                                                      −2000




                                    −5    0            5            10           15             20                                      −5    0            5            10           15             20
                                                      Years Since Event                                                                                   Years Since Event

                                         Non−Parametric Estimate          Parametric Estimate                                                Non−Parametric Estimate          Parametric Estimate


                                              (c) State revenue, Q5                                                                               (d) Total revenue, Q5


Notes: Figure displays coefficients from event study regressions. Dependent variables are mean state revenues
in the lowest income quintile of districts (panel A), mean total revenues in these districts (panel B), and
mean state and total revenues in the highest income quintile of districts (panels C and D, respectively), all
measured in 2013 dollars per pupil. Dashed lines show the three-parameter parametric model (equation 2).
Solid lines shows the non-parametric model (equation 3), with the event year (indicated as 0) as the excluded
category; dotted lines represent 95% confidence intervals. Estimates for the parametric models are reported
in Table 3, Panels B and C, Columns 2 and 4. p values for omnibus hypothesis tests of zero pre-event e↵ects
in the non-parametric model in Panels A-D are 0.53, 0.40, 0.41, and 0.74, respectively; p-values for zero
post-event e↵ects are <0.001 in all panels. In the parametric model, the p-values for the hypothesis that
the pre-event trend is zero are 0.24, 0.68, 0.21, and 0.78; for the test that the post-event jump and change
in trend is zero they are 0.01, <0.001, 0.30, and 0.22.




                                                                                                                                                                                                    45
 Figure 10: Event study estimates of e↵ects of school finance reforms on progressivity of district revenues




                          Change in Q1−Q5 mean total revenues
                     −2000 −1000       0    1000      2000




                                                                −5    0            5            10           15             20
                                                                                  Years Since Event

                                                                     Non−Parametric Estimate          Parametric Estimate


                                                                               (a) Q1-Q5 mean
                                                 2000
                      Change in total revenue slope
                     −1000      0        1000
                                          −2000




                                                                −5    0            5            10           15             20
                                                                                  Years Since Event

                                                                     Non−Parametric Estimate          Parametric Estimate


                                                                            (b) Total revenue slope


Notes: Figure displays coefficients from event study regressions. Dependent variables are the di↵erence in
mean total revenues per pupil (in 2013$) between districts in the bottom and top quintile by mean family
income in the state (panel A), and the slope of total per-pupil revenues (in 2013$) with respect to log
mean family income, controlling for log enrollment and district type (panel B). Dashed lines show the three-
parameter parametric model (equation 2). Solid lines shows the non-parametric model (equation 3), with
the event year (indicated as 0) as the excluded category; dotted lines represent 95% confidence intervals.
Estimates for the parametric models are reported in Table 4, Panels A and B, Columns 2 and 4. p-values
for omnibus hypothesis tests of zero pre-event e↵ects in the non-parametric model are 0.86 in Panel A and
0.96 in Panel B; p-values for zero post-event e↵ects are <0.001 in each panel. In the parametric model, the
p-value for the hypothesis that the pre-event trend is zero is 0.72 in Panel A and 0.58 in Panel B; for the
                                                                                                          46
test that the post-event jump and change in trend is zero it is 0.01 and 0.11, respectively.
    Figure 11: Event study estimates of e↵ects of school finance reforms on progressivity of test scores
                                         .1
              Change in test score slope
                 −.2     −.1 −.3  0




                                              −5    0             5            10          15              20
                                                                 Years Since Event

                                                   Non−Parametric Estimate           Parametric Estimate



Notes: Figure displays coefficients from event study regressions. Dependent variable is the slope of mean
test scores with respect to log mean family income, controlling for log enrollment. Dashed lines show the
three-parameter parametric model (equation 2). Solid lines shows the non-parametric model (equation 3),
with the event year (indicated as 0) as the excluded category; dotted lines represent 95% confidence intervals.
Both event study regressions include state and subject-grade-year fixed e↵ects. Estimates for the parametric
models are reported in Table 6, Column 1. p-values for the hypothesis that pre-event e↵ects are zero are 0.43
in the non-parametric model and 0.80 in the parametric model; for zero post-event e↵ects, they are <0.001
and 0.02, respectively.




                                                                                                                47
Figure 12: Event study estimates of e↵ects of school finance reforms on mean test scores in highest and
lowest income school districts




                                                   .3
                     Change in Q1 Mean Test Scores
                     −.1     0      .1      .2




                                                          −5    0             5            10          15              20
                                                                             Years Since Event

                                                               Non−Parametric Estimate           Parametric Estimate


                                                                      (a) Q1 mean test scores
                                                     .3
                       Change in Q5 Mean Test Scores
                     −.1     0       .1     .2




                                                          −5    0             5            10          15              20
                                                                             Years Since Event

                                                               Non−Parametric Estimate           Parametric Estimate


                                                                      (b) Q5 mean test scores


Notes: Figure displays coefficients from event study regressions. Dependent variables are mean test scores for
students at districts in the bottom quintile (panel A) or top quintile (panel B) of the state’s distribution of
1990 district mean household incomes. Dashed lines show the three-parameter parametric model (equation
2). Solid lines shows the non-parametric model (equation 3), with the event year (indicated as 0) as the
excluded category; dotted lines represent 95% confidence intervals. Both event study regressions include
state and subject-grade-year fixed e↵ects. p-values for omnibus hypothesis tests of zero pre-event e↵ects in
the non-parametric model are 0.01 in Panel A and 0.02 in Panel B; p-values for zero post-event e↵ects are
<0.001 in each panel. In the parametric model, the p-value for the hypothesis that the pre-event trend is
zero is 0.86 in Panel A and 0.15 in Panel B; for the test that the post-event jump and change in trend 48    is
zero it is 0.01 and 0.25, respectively.
Tables

                                      Table 1: NAEP Testing Years

          Year              Subjects and grades covered               Number of     Number of
                  Math G4    Math G8 Reading G4 Reading G8             States        Students
          1990                   X                                        38            97,900
          1992       X           X            X                           42           321,120
          1994                                X                           41           104,890
          1996       X           X                                        45           228,980
          1998                                X              X            41           206,810
          2000       X           X                                        42           201,110
          2002                                X              X            51           270,230
          2003       X           X            X              X            51           691,360
          2005       X           X            X              X            51           674,420
          2007       X           X            X              X            51           711,360
          2009       X           X            X              X            51           775,060
          2011       X           X            X              X            51           749,250


   Notes: In final column, students are cumulated across all tested subjects and grades, and rounded to the
nearest 10.




                                                                                                        49
                                           Table 2: Summary statistics

                                                  (a) District-year panel

                                                              Overall                 Mean by subgroup
                                                      N       Mean            SD       Q1         Q5
                 Enrollment                      229,386      67,523     181,811      13,537    31,403

                 Log(mean income, 1990)          223,334      10.53          .2935    10.21      10.9

                 Total revenue p.p.              229,386      11,087         3,489    10,809    11,871

                 State                           229,386      5,135          2,291    6,371      4,003

                 Local                           229,386      5,094          3,273    3,258      7,349

                 Federal                         229,386      858.2          641.4    1,180      518.4

                 Expenditures p.p.               229,386      11,264         3,685    10,837    12,116

                 Instructional                   229,386      5,845          1,953    5,659      6,167

                 Non-instructional               229,386      5,419          2,221    5,178      5,949

                 NAEP scores                      49,867      .2559          .4578    .02925     .5884



                                                   (b) State-year panel

                                  N              Q1                     Q5           Q1-Q5 di↵erence       Gradient
                                         Mean          SD      Mean           SD     Mean       SD       Mean      SD
    Log(mean income, 1990)        49      10.2        .135      10.8         .234    -.645     .167

    Total revenue p.p.           1,078   11,527       3,905    11,844        3,351   -329      2,158      539     3,574

    State                        1,078   6,552        2,822     4,347        2,006   2,196     2,244     -3,086   3,470

    Local                        1,078   3,658        1,600     6,893        3,477   -3,231    2,624     5,190    3,313

    Federal                      1,078   1,317        1,082     604          482      706      722       -1,565   1,532

    Mean NAEP score              532     .0374        .316      .513         .304    -.475     .326      .955     .337



    Notes: Panel (a) reports summary statistics at the district by year level, weighted by district enrollment
for the financial variables and by the sum of the student weights for the mean NAEP score. Panel (b) shows
summary statistics for the unweighted state-year panel.




                                                                                                                          50
Table 3: Event study estimates of e↵ects of school finance reforms on mean revenues per pupil, by district
income

                                                  State Revenue        Total Revenue
                                                   1p        3p         1p         3p
                   Mean:
                   Post Event                     912⇤⇤     672⇤⇤     829⇤⇤⇤     839⇤⇤⇤
                                                  (359)     (320)      (302)      (269)
                   Trend                                      68                     9
                                                             (50)                  (32)
                   Post Event * Yrs Elapsed                   -61                   -17
                                                             (60)                  (52)

                   Observations                   1,078     1,078     1,078      1,078

                   Q1 Mean:
                   Post Event                   1,225⇤⇤⇤   954⇤⇤⇤    1,233⇤⇤⇤   1,164⇤⇤⇤
                                                  (343)     (302)      (370)      (287)
                   Trend                                      60                    16
                                                             (50)                  (39)
                   Post Event * Yrs Elapsed                   -40                   -11
                                                             (70)                  (70)

                   Observations                   1,078     1,078     1,078      1,078

                   Q5 Mean:
                   Post Event                      527       351      544⇤⇤      471⇤
                                                  (378)     (325)     (277)      (277)
                   Trend                                      72                   9
                                                             (56)                 (32)
                   Post Event * Yrs Elapsed                   -84                   2
                                                             (61)                 (41)

                   Observations                   1,076     1,076     1,076      1,076


   Notes: Table reports estimates of the parametric event study models, equations (1) (columns 1 and
3) and (2) (columns 2 and 4). Dependent variables are mean state revenues per pupil (columns 1-2) and
mean total revenues per pupil (columns 3-4), weighting districts by their log enrollment; each is computed
separately for each state and year. In panel A, means are computed over all districts in each state; in panels
B and C, they are computed over the bottom and top, respectively, quintiles of the states’ district 1990
mean household income distributions. Event study regressions include state and year fixed e↵ects, and are
unweighted. Standard errors clustered at the state level.




                                                                                                           51
   Table 4: Event study estimates of e↵ects of school finance reforms on progressivity of school finance

                                                     State Revenue     Total Revenue
                                                      1p        3p       1p       3p
                      Q1-Q5 Mean:
                      Post Event                    711⇤⇤     606⇤⇤⇤   701⇤⇤    696⇤⇤⇤
                                                    (316)      (231)   (309)     (243)
                      Trend                                      -10                9
                                                                (25)              (24)
                      Post Event * Yrs Elapsed                    42               -14
                                                                (36)              (44)

                      Observations                   1,076    1,076    1,076    1,076

                      Slopes:
                      Post Event                    -622⇤⇤⇤   -522⇤⇤    -424    -469⇤⇤
                                                     (223)     (209)   (304)     (233)
                      Trend                                      -11               -25
                                                                (25)              (45)
                      Post Event * Yrs Elapsed                    -5                53
                                                                (21)              (61)

                      Observations                   1,078    1,078    1,078    1,078


    Notes: Table reports estimates of the parametric event study models, equations (1) (columns 1 and
3) and (2) (columns 2 and 4). In Panel A, dependent variable is the gap in state (columns 1-2) or total
(columns 3-4) revenues per pupil between districts in the bottom and top quintiles of the states’ district 1990
mean household income distributions. In Panel B, dependent variable is the coefficient from a district-level
regression of the relevant per-pupil revenue measure on the log of the district’s 1990 mean household income,
controlling for district log enrollment and district type (elementary / secondary / unified) and weighting by
the district’s average log enrollment over time. Event study regressions include state and year fixed e↵ects.
Event study regressions are unweighted in Panel A, and is weighted by the inverse squared standard error
of the dependent variable in Panel B. Standard errors clustered at the state level.




                                                                                                            52
   Table 5: Event study estimates of e↵ects of school finance reforms on components of district finance

                                       Mean of depvar     Mean      Q1 Mean     Q1-Q5 Mean       Slope
   Revenue E↵ects:
   Total revenue                           11,593         829⇤⇤⇤    1,233⇤⇤⇤        701⇤⇤         -424
                                                           (302)      (370)         (309)        (304)
      State revenue                         5,449         912⇤⇤     1,225⇤⇤⇤        711⇤⇤       -622⇤⇤⇤
                                                           (359)      (343)         (316)        (223)
      Local revenue                         5,238           -146       -126          -126          90
                                                           (307)      (233)         (235)        (339)
      Federal revenue                        907             63         134           116          34
                                                            (83)      (143)         (116)         (33)
   Expenditure E↵ects:
   Total expenditures                      11,595         907⇤⇤⇤    1,377⇤⇤⇤        753⇤⇤         -449
                                                           (290)      (367)         (309)        (309)
      Current instructional exp.            6,000         443⇤⇤⇤     604⇤⇤⇤          243⇤         -161
                                                           (134)      (155)         (127)        (208)
         Teacher salaries + benefits        5,533          339⇤⇤     449⇤⇤⇤          143          -103
                                                           (153)      (169)         (117)        (189)
           Mean teacher salary             63,425           -286       -245          272          -259
                                                          (1,024)    (1,107)        (947)       (1,122)
           Pupil teacher ratio              15.40        -0.62⇤⇤⇤   -0.67⇤⇤⇤         0.00         0.23
                                                           (0.19)     (0.19)        (0.20)       (0.17)
      Non-instructional exp                 5,595          464⇤⇤     773⇤⇤⇤         511⇤⇤         -232
                                                           (186)      (257)         (235)        (176)
         Student support                    3,426          221⇤⇤      299⇤⇤          100           -81
                                                           (102)      (119)          (83)         (88)
         Total capital outlays              1,076          272⇤⇤     486⇤⇤⇤         369⇤⇤          -87
                                                           (114)      (177)         (181)         (78)
         Other current exp.                 431.0            7.9        9.2          -2.5         -2.9
                                                           (12.4)     (14.5)        (13.3)       (12.1)


    Notes: Each entry in columns 2-5 represents the coefficient from a separate event study regression, using
the one-parameter specification in equation (1). Dependent variables are constructed from district-level
finance summaries indicated by row headings and expressed in per-pupil terms; means across districts are
reported in column 1. Specifications correspond to columns 1 and 2 of Table 3, panels A (column 2) and B
(column 3), and Table 4, panels A (column 4) and B (column 5). See notes to Tables 3 and 4.




                                                                                                          53
        Table 6: Event study estimates of e↵ects of school finance reforms on student achievement

                                               Slopes                 Q1           Q5              Q1-Q5
                                         (1)            (2)           (3)          (4)       (5)           (6)
                                               ⇤⇤             ⇤⇤⇤           ⇤⇤                     ⇤⇤
         Post Event * Yrs Elapsed     -0.011        -0.010          0.007         -0.001   0.008        0.013⇤⇤
                                       (0.004)       (0.003)        (0.003)      (0.003)   (0.004)      (0.006)
         Trend                          0.001                                                            -0.006
                                       (0.003)                                                          (0.005)
         Post Event                     0.001                                                            0.011
                                       (0.023)                                                          (0.024)
         Observations                   1498          1498           1509         1506      1504         1504
         p, total event e↵ect=0         0.02          0.01           0.02         0.69      0.04         0.07
         State FEs                       X             X              X            X         X            X
         Sub-gr-yr FEs                   X             X              X            X         X            X


    Notes: Each column represents a separate event study regression, using specification (2) and, in columns
2-5, constraining jump = trend = 0. Dependent variable in columns 1-2 is the slope of test scores with re-
spect to log mean 1990 income in the district, using NAEP weights and controlling for log district enrollment.
In columns 3-4, dependent variable is the weighted mean score in districts in the bottom or top quintile,
respectively, of the state district-level income distribution. In columns 5-6, dependent variable is the di↵er-
ence between the bottom and top quintiles. All are computed separately for each state-year-subject-grade
cell with available data. All event study specifications include state and subject-grade-year fixed e↵ects, and
are weighted by the inverse squared standard error of the dependent variable. p-values for total event e↵ect
in columns 1 and 6 test the hypothesis that the jump and phasein coefficients are both zero; in columns
2-5, the p-value is for the hypothesis that phasein = 0, with jump constrained to zero.




                                                                                                                  54
Table 7: Event study estimates of e↵ects of school finance reforms on student achievement by subject and
grade

                                            Test Score Slope    Q1-Q5 Mean
                              Pooled            -0.010⇤⇤⇤          0.008⇤⇤
                                                 (0.003)           (0.004)

                              By Subject:
                              Math              -0.012⇤⇤⇤          0.007⇤
                                                 (0.003)           (0.004)
                              Reading             -0.006           0.009⇤⇤
                                                 (0.005)           (0.004)
                              Di↵erence           -0.006            -0.002
                              p-value              0.09              0.46

                              By Grade:
                              G4                 -0.010⇤⇤          0.009⇤
                                                  (0.005)          (0.005)
                              G8                 -0.010⇤⇤          0.007⇤⇤
                                                  (0.004)          (0.004)
                              Di↵erence           0.000             0.001
                              p-value              0.93             0.72


   Notes: First row repeats specifications from Table 6, columns 2 and 5. See notes to that table for details.
Subsequent models restrict the event study sample to slope and quintile gaps computed in specific subjects
or grades. Di↵erence entries report the di↵erence in coefficients between math and reading or grade 4 and
grade 8 specifications, with p-values for the hypothesis that the event study coefficient is equal in the two
subsamples.




                                                                                                           55
       Table 8: Sensitivity of event study estimates to the treatment of states with multiple events

                                       Selected Events    All events (stacked)   Initial court events
        Panel A: Gradients
        State revenue p.p.                  -622⇤⇤⇤              -479⇤⇤⇤                -432⇤
                                             (223)                (160)                 (222)
        Total revenue p.p.                    -424                 -197                  -399
                                             (304)                (269)                 (292)
        NAEP scores                        -0.010⇤⇤⇤            -0.009⇤⇤⇤             -0.009⇤⇤⇤
                                            (0.003)              (0.003)               (0.003)

        Panel B: Q1-Q5 di↵erences
        State revenue p.p.                  711⇤⇤                 463⇤⇤                  516
                                            (316)                 (191)                 (354)
        Total revenue p.p.                  701⇤⇤                 448⇤⇤                  584
                                            (309)                 (195)                 (398)
        NAEP scores                        0.008⇤⇤              0.011⇤⇤⇤               0.008⇤⇤
                                           (0.004)               (0.004)               (0.004)


    Notes: Column 1 repeats estimates of the one-parameter parametric event study models from Table 4,
columns 1 and 3, and Table 6, columns 2 and 5. See notes to those tables for details. In column 2, each
potential event in each state is included, with a separate copy of the state’s finance or test score panel
for each event. Event study specification is modified to include state-by-event (-by-grade-by-subject) fixed
e↵ects; standard errors are clustered at the state level. Column 3 returns to the single-event specification,
but uses the first post-1990 court order in each state as its event; states without judicial events are treated
as not having finance reforms.




                                                                                                            56
                    Table 9: Impacts of student sorting on student achievement results

                                                           Q1-Q5 di↵erence       Slope
                  Baseline Estimates                            0.008⇤⇤        -0.010⇤⇤⇤
                                                                (0.004)         (0.003)

                  Decomposition 1: Common covariates
                  Predicted score                                0.003            -0.003
                                                                (0.004)          (0.004)
                  Residual score                                0.005⇤⇤         -0.007⇤⇤
                                                                (0.002)          (0.003)

                  Decomposition 2: Richer covariates
                  Predicted score                                0.004           -0.004
                                                                (0.004)         (0.003)
                  Residual score                                0.004⇤         -0.006⇤⇤⇤
                                                                (0.002)         (0.002)


    Notes: First row repeats estimates from Table 6, columns 2 and 5. In subsequent rows, dependent
variables are modified. We estimate student-level regressions of NAEP scores on student demographic
characteristics, with year fixed e↵ects, then compute predicted and residual test scores. We compute separate
slopes with respect to district income and quintile gaps for the predicted and residual test scores, and
estimate separate event study regressions for each. In decomposition 1, student demographic characteristics
are race/ethnicity and gender, along with school means (in the NAEP sample) of each. Decomposition 2
adds indicators for students whose parent is a college graduate and for free or reduced-price lunch receipt,
along with indicators for NAEP samples where these variables are unavailable and school means of each.




                                                                                                          57
                   Table 10: Event study estimates for mean NAEP scores by subgroup

                                                    Post Event * Yrs Elapsed
                   Overall mean                               0.004             (0.003)

                   Spread of distribution:
                   Std Dev.                                  -0.000             (0.001)
                   25th percentile                            0.004             (0.003)
                   75th percentile                            0.003             (0.002)
                   P75 - P25                                 -0.001             (0.002)

                   By race:
                   Black                                     0.001              (0.003)
                   White                                     0.004⇤             (0.003)
                   White - black                             0.002              (0.002)

                   By free lunch status:
                   Free lunch                                0.001              (0.003)
                   No free lunch                              0.004             (0.003)
                   No free lunch - free lunch gap            -0.000             (0.002)


    Notes: Table reports event study specifications, using equation (3) with jump and phasein constrained to
zero. Dependent variables are the indicated summaries of the state-level student achievement distribution:
The mean score; the standard deviation of scores; the 25th and 75th percentile scores; the interquartile
range; mean scores for black and white students, respectively; the white-black mean score gap; mean scores
for free/reduced-price lunch and non-free/reduced-price lunch students; and the gap between these.




                                                                                                         58
APPENDICES



Appendix A. Event database

Appendix Table A1 lists all of the events in our database, covering the period from
1990 forward. As noted in the text, we include both court orders and major
legislative reforms. Columns of the table indicate how our list compares with those
of Jackson, Johnson, and Persico (2016) and Corcoran and Evans (2015).

Appendix D, below, discusses in depth each case where our list differs from that of
Jackson, Johnson, and Persico (2016).


Appendix B. Details of samples and empirical specifications

The primary sources for our outcome measures are the Common Core of Data Local
Education Agency (LEA) finance survey (also known as the F-33), for finance
outcomes, and the NAEP, for test scores. Each is matched to district mean household
income from the 1990 School District Data Book (SDDB), a tabulation of Decennial
Census data at the district level. Mean incomes pertain to all households in the
district, with and without children and without regard to public school attendance.

Our analysis relies on collapsing the district- and student-level measures to
summaries at the state-by-year level. We use three types of summaries: Means for
districts in each quintile of family income, the difference in between the first and
fifth quintile means, and slopes with respect to log district income. Our methods
differ slightly among these; we describe them here.

Sample definitions

All of our samples exclude Hawaii and the District of Columbia, each of which has
only one school district.

Our finance analyses exclude district-year observations with enrollment of fewer
than 100 students. This removes 8% of district-year observations, with only 0.1% of
total enrollment.

We make two additional exclusions aimed at reducing volatility in the per-pupil
funding measures. Both total funding and enrollment can vary dramatically from
year to year in a district, particularly in small districts, creating enormous swings in
per-pupil revenues. We view this variability as likely to reflect measurement error;
it is particularly problematic when it derives from large proportional swings in
enrollment with more stable funding.




                                                                                           i
We begin by computing each district’s average enrollment over our sample, as well
as its average growth rate over our sample period. We exclude from our sample any
district-year observation with enrollment (a) more than double the district’s
average enrollment; (b) more than 15% above or below the prior year or the
subsequent year’s enrollment; or (c) more than 10% above or below the district’s
constant-growth-rate trend. In addition, for any district for which more than one-
third of annual observations are excluded under these criteria, we exclude all
remaining observations as well. Exclusion (a) in particular likely leads us to exclude
districts serving newly developed areas, but we are not confident that 1990 incomes
are reliable measures of population resources in these districts in any case.
Together, these exclusions capture 18% of district-year observations, with 8% of
enrollment.

To address volatility in the numerator of our revenue and expenditure measures, we
exclude as well district-year observations with per-pupil revenues (respectively,
expenditures) greater than 500% or less than 20% of the unweighted state-by-year
mean. Only 0.02% of district-year observations are excluded by these rules.

When analyzing mean teacher salaries and pupil-teacher ratios, each of which is
somewhat noisily measured, we exclude the top and bottom 2% of districts
(unweighted) in each state-year cell.

Finally, our NAEP analyses exclude students in charter schools.

For many purposes, it is useful to have a weight for each district that does not vary
over time. We use the geometric mean of the district’s enrollment in all available
years for this.

Definition of income quintiles

The basis for our income quintile calculations is the finance sample, as defined
above. Districts’ quintile assignments are treated as fixed over time.

To construct our income quintile cutoffs, we sort districts in a state by their 1990
mean family income and compute the 20th, 40th, 60th, and 80th percentile of the state
distribution of 1990 mean family income. These percentiles are based on the
districts in our finance sample in 1994 (the first year in which complete CCD data
are available), weighted by our stable enrollment count. Districts spanning the
quintile cutoffs are assigned with partial weights to each of the relevant quintiles.

Quintile means
Quintile means of our finance measures are computed as weighted averages over
the districts in each quintile, weighting each district by its average log enrollment
and including only districts that meet the criteria outlined above. The specific
districts included can vary slightly over time due to differences in the availability of
the dependent variable.


                                                                                        ii
Our NAEP quintile means are similar but weight districts by the sum of the NAEP
student weights in the district. Only districts meeting the finance sample restrictions
for the relevant year are included.

Income slopes

To construct state-by-year slopes of revenues with respect to district income, we
estimate a separate regression for each state and each year. Explanatory variables
are the log mean income of the district, based on the 1990 data, the district’s log
enrollment in that year, and indicators for whether the district is an elementary or a
secondary district (unified districts are the excluded category). These regressions
are weighted by our stable log enrollment measure and samples are defined as
above. The coefficient on the log mean district income is extracted, along with its
standard error.

NAEP score-income slopes are computed similarly, using NAEP data aggregated to
the district-year-subject-grade level. Separate regressions are estimated for each
state-year-subject-grade combination. The district-level regression is weighted by
the sum of NAEP student weights in the district, and does not include district type
controls. Standard errors account for the NAEP plausible values methodology, as
discussed below.

Event study regressions

Once quintile means, between-quintile gaps, and income slopes are constructed at
the state-year level, we estimate event-study regressions as described in the main
text.

For finance outcomes, where we have a census of school districts, the event study
regressions using quintile means as dependent variables are unweighted. For test
score outcomes, our quintile mean event study regressions are weighted by the sum
of the NAEP student weights within the grade-subject-quintile-year cell. When we
examine quintile gaps in scores, we weight by the harmonic mean of the two quintile
weights.

All event studies with income slopes as the dependent variable are weighted by the
inverse sampling variance of the state-year slope.

NAEP plausible values

NAEP does not report a single test score for each student, but rather reports five
plausible values, random draws from the student’s posterior distribution. We
average these five plausible values before computing quintile means or income
slopes. Our estimated standard errors for the income slopes account for the




                                                                                      iii
contribution of the sampling from the posterior distribution, following NAEP
guidance.

Jacob and Rothstein (2016) point out that the use of NAEP plausible values as
dependent variables may create biases, as the measurement error in PVs is not
classical. The bias depends on the degree to which the “conditioning variables” in
the NAEP model can predict the relevant explanatory variables in the research
regression, but likely takes the form of attenuated treatment effects.

Jacob and Rothstein (2016) discuss methods for obtaining unbiased estimates from
a single NAEP. We are not aware of methods for avoiding bias in analyses that pool
across many NAEP samples. We have verified that cross-sectional regressions of
NAEP PVs on measures of district finance, both across and within states, are
minimally biased relative to unbiased MML estimates, and therefore conclude that
the use of PVs is unlikely to meaningfully bias our results.


Appendix C. Robustness and additional analyses

Appendix figures and tables present numerous additional results.

Figure A1 tabulates our finance and NAEP samples by event time, the number of
years relative to the date of the event. In the NAEP data, we have large samples for
event years up to 10, but beyond that sample sizes diminish.

Figure A2 shows the time series of total revenue slopes and test score slopes, each
with respect to log district income, separately for reform and non-reform states.
Both revenue and test score slopes decline in reform states, relative to non-reform
states, between 1990 and 2011.

Figure A3 plots our event study estimates of impacts on total revenues and mean
test scores in each of the five quintiles, along with 95% confidence intervals.

Figure A4 presents event study estimates, analogous to Figure 11, separately for 4th
and 8th grade scores. There is no indication of meaningful differences between these.
Figure A5 shows the event study for the between-quintile gap in mean test scores.

Table A1 lists all of the events in our finance reform database, along with those in
the Jackson, Johnson, Persico (2016) and Corcoran and Evans (2015) databases.
This is discussed in greater detail in Appendix D.

Table A2 presents an event study analysis for state-level budgets, on both per-capita
and per-pupil bases. Our one-parameter specification (equation 1) is used. Events
are associated with sharp increases in both total revenues and total expenditures.
Expenditure increases are concentrated in the education and intergovernmental
transfer categories; there is no significant effect on other expenditures. The impacts


                                                                                       iv
on total per-pupil revenues and expenditures are larger than in our district-level
analyses. This may indicate that some of the new state expenditures involve re-
labeling existing funds rather than allocating new funds to education. Another
potential explanation is that some reforms may have led to state spending on pre-K
education that does not show up on district balance sheets.

Table A3 presents Card and Payne’s (2002) analysis of the effect of SFRs on the
slope of district revenues with respect to district income. Card and Payne use the
income level, in dollars, rather than log income as the explanatory variable in this
slope calculation. They compute a single long-difference of this slope for each state,
from 1977 to 1992, and regress it on indicators for plaintiff and defense victories in
court cases. We construct a similar slope with respect to income levels, and a similar
1990-2012 long difference. Columns 2 and 5 report regressions of this on an
indicator for a post-1990 event. Columns 3 and 6 report estimates of our one-
parameter event study model. Our estimates of the impacts of court rulings are
somewhat larger than in Card and Payne (2002), but we cannot rule out equal
effects.

Table A4 presents a similar comparison to Corcoran and Evans’ (2015) analysis of
the impact of SFRs on univariate measures of district finances in each state. Columns
1-3 are drawn from Corcoran and Evans. Column 1 reports coefficients of a
regression of the indicated finance summary on an indicator for a prior court ruling,
using Corcoran and Evans’ 1972-2002 panel. This regression controls for state
demographic characteristics and state and year effects. Columns 2 and 3 report
ruling main effects (column 2) and the effect of an adequacy ruling (column 3) from
specifications that include both together. Columns 4-5 report estimates using our
1990-2012 panel, without demographic controls, where we time events as in our
main analysis (column 4) or to the first court ruling in a state (column 5).

Note that the coefficients in columns 4-5 are comparable to the sum of those in
columns 2 and 3, or to those in column 1 without adjustment. Estimates for per-
pupil revenues are similar. We obtain smaller impacts on log mean per-pupil
expenditures and on the coefficient of variation of per-pupil expenditures.

Table A5 reports event study estimates where the dependent variable is the slope of
various demographic characteristics of a district’s students with respect to district
log income (panel A) or the between-quintile gap in mean demographic
characteristics (panel B). Log mean income is measured in 1990, 2000, and 2011.
(The slope of log mean income in 1990 with respect to a districts 1990 log mean
income is by construction 1 in every state, but this slope can vary in subsequent
years.) Minority and free lunch shares are measured in every year, though free
lunch data is missing for some states and years.

Table A6 reports the share of students of various characteristics who are in districts
in each quintile. Rows sum to 1.



                                                                                     v
Table A7 reports event study regressions where the dependent variable is the
difference in the revenues of the district attended by the average black (or free
lunch, or low scoring) student and the revenues of the district attended by the
average white (or non-free-lunch, or high scoring) student.


Appendix D. Reconciliation of school finance reform tabulations

The literature on school finance reforms has been plagued by a lack of authoritative
tabulations of court-ordered reforms, with substantial discrepancies between the
tabulations used by different authors. Our tabulation, too, differs from all previous
listings.

In an effort to provide clarity to the literature going forward, in this appendix we
discuss every case between 1990 and 2011 where our tabulation of court-ordered
school finance reforms differs from that of Jackson, Johnson, and Persico (2016;
hereafter JJP). Many of these discrepancies reflect judgment calls. We have
estimated our main results with a number of variants of the event sample, and in
general have found little sensitivity of the results; we nevertheless present the basis
for our preferred tabulation for completeness.

The states and years for which the two tabulations disagree are:
    - Alabama, 1993
    - Arizona, 2007
    - Connecticut, 1995 & 2010
    - Idaho, 1993 & 1998
    - Maryland, 1996 & 2005
    - Michigan, 1997
    - Montana, 1993 & 2008
    - New Hampshire, 2006
    - New Jersey, 1991, 1998 & 2000
    - New Mexico, 1998 & 1999
    - Oregon, 2009
    - South Carolina, 2005
    - Texas, 2004
    - Washington, 1991, 2007 & 2010
This includes only cases in scope for both lists but coded differently. This in
particular means that we do not discuss our tabulation of legislative school finance
reforms, as these are out of JJP’s scope. For each state, we discuss only the events
where the two tabulations disagree; see Appendix Table A1 for a full listing of
events in each state.

Alabama1

1Case histories from http://schoolfunding.info/2012/01/school-funding-cases-in-
alabama/; http://www.encyclopediaofalabama.org/article/h-2045.


                                                                                       vi
1993: JJP court order; Lafortune-Rothstein-Schanzenbach (LRS) no event

In 1993’s Alabama Coalition for Equity (ACE) v. Hunt, the public school funding
system was found inequitable, on both adequacy and equity grounds, by a lower
court, and a remedy order was issued. The remedy negotiated among the parties
and ordered by the court, in ACE v. Folsom, included equitable and adequate funding,
and in addition also covered performance-based education, professional
development, early childhood programs, and inclusive special education— all to be
fully funded within six years. No educational reform package made it through the
legislature before the 1994 election season, and education reform became an
important issue in the gubernatorial campaign, with incumbent governor Folsom
promising reform and compliance with the remedy order and his opponent (and
eventual winner) Forrest “Fob” James vowing to fight what he described as a
usurpation of executive and legislative powers. Upon appeal, the Alabama Supreme
Court decided in 1997 that while schools were inadequately funded, it would
decline to issue a remedy order, leaving the funding system unchanged. Because the
lower court was overturned and no school finance legislation was passed, we do not
code this event as a school finance reform.

Arizona2
2007: JJP court order; LRS no event

Flores v. Arizona was first decided in 1992 under Federal law, in the United States
District Court for the District of Arizona. The plaintiffs claimed that the state failed
to adequately fund programs for English language learners (ELLs). In 2000, the
district court found that the state's method and level of funding ELL programs was
"arbitrary and capricious" and ordered that the level of state funding for ELL
programs bear a rational relationship to the cost of those programs. The parties
reached an agreement in 2002, and the court ordered a costing-out study. The
state's repeated failure to comply led to a December 2005 order and daily fines that
mounted to $21 million before the state enacted additional funding in early March
2006. In August 2006, the Ninth Circuit Court of Appeals, in Flores v. Rzeslawski,
vacated the 2005 district court judgment and remanded the case so the district
court could hold new hearings to determine whether circumstances had changed
and required modification of the 2000 court order.

In March 2007 Judge Raner Collins of the U.S. District Court for the District of
Arizona ruled that Arizona was in violation of the Equal Educational Opportunities
Act (EEOA) by under-funding programs directed towards English learners,
invalidating HB 2064, the funding formula passed by the Arizona legislature in
response to the court's earlier decision. Judge Collins ordered the state to comply
with the order by the end of the 2007 legislative session, but when the legislature


2Case history from http://www.clearinghouse.net/detail.php?id=11194;
http://www.schoolfunding.info/states/az/lit_az.php3.


                                                                                      vii
failed to do so the judge issued a contempt order. The Ninth Circuit Court of Appeals
upheld the ruling in 2008.

In September 2008, the defendants petitioned the U.S. Supreme Court to review the
9th U.S. Circuit Court of Appeals' holding. In 2009’s Horne v. Flores, 129 S. Ct. 2579
decision, the Supreme Court reversed and directed the District Court to examine
several specific factors, including whether non-compliance was statewide.

On March 28, 2013, the plaintiff's statewide claims were dismissed, requiring
district-by-district analysis instead. The dismissal was upheld by the Court of
Appeals in June 2015.

Because the 2007 ruling was a Federal district court order that the state never
complied with and was subsequently overturned by the Supreme Court, we do not
code this event as a school finance reform.

Connecticut3
1995: JJP court order; LRS no event
2010: JJP court order; LRS no event

In 1996, the State Supreme Court ruled in Sheff v. O’Neill (coded by JJP as 1995) that
the separation of suburban and Hartford students violated the segregation clause in
the Connecticut Constitution, and ordered the State Legislature to take necessary
measures to integrate schools and to provide equal educational opportunity to all
children. This resulted in a plan by the 1997 State Legislature geared at promoting
voluntary school desegregation and magnet schools. Though plaintiffs made
adequacy-based arguments, the ruling and subsequent legislation focused on
desegregation and not school funding.

In 2010, the Supreme Court ruled in Coalition for Justice in Education Funding, Inc. v.
Rell that the state’s constitution guaranteed all students an adequate education. It
did not order changes in school finance, however, but rather sent the case back to a
trial court to determine whether the appropriate standard had been met. As of 2013,
the case was still pending. We therefore do not code it as a school finance reform
order.

Idaho4

3 Case history drawn from https://www.jud.ct.gov/external/news/sheff.htm;
http://connecticuthistory.org/sheff-v-oneill-settlements-target-educational-
segregation-in-hartford/#sthash.6QnsSrbm.dpuf;
https://scholar.google.com/scholar_case?case=10572221569547466633&q=Sheff+
v+o+neill+199&hl=en&as_sdt=400006; http://schoolfunding.info/2012/01/school-
funding-cases-in-connecticut-2/.
4 Case history from http://www.educationjustice.org/states/idaho.html;

https://nces.ed.gov/edfin/pdf/lawsuits/ISEEO_v_idaho.pdf.


                                                                                   viii
1993: JJP no event; LRS court order
1998: JJP court order; LRS no event

In the 1993 ruling on Idaho Schools for Equal Educational Opportunity v.
Evans (ISEEO) (850 P.2d 724), the Idaho Supreme Court found that the state
constitution required adequate (but not equitable) school spending. In 1994, the
legislature passed Senate Bill 1560 which revised the state funding formula in
regard to teacher salaries, allocating more than $90 million to public schools fund
this change. We code the 1993 decision as a court-ordered school finance reform.

After the legislative changes, the trial court declared the lawsuit moot, but this
decision was overturned by the state Supreme Court, which concluded that whether
a "thorough education" was being provided to students was still in question. In
1997, the trial court again dismissed the plaintiffs' claim. The state Supreme Court
reversed in part in 1998, in ISEEO v. State (976 P.2d 913), remanding the facilities
and capital funding portion of the case. The court held that "the Legislature has the
duty to provide a means for school districts to fund facilities that offer a safe
environment conducive to learning." In 2000 and 2001, the legislature passed minor
facilities measures that help property-poor districts, but plaintiffs argued these
measures were insufficient. We do not code this as an independent school finance
reform, due in part to its limited scope.

Maryland5
1996: JJP no event; LRS court order
2005: JJP court order; LRS no event

The ACLU and Baltimore City alleged that Baltimore’s students were not receiving
an adequate education. In a 1996 summary judgment decision in the consolidated
Bradford v. Maryland State Board of Education case, the trial court agreed, though
the cause of the inadequacies was in dispute. The parties entered into a settlement
that provided an increase in state funding for the Baltimore City Public Schools for
the next five years. During this period, the “Thornton” Commission on Education
Finance, Equity, and Excellence was established to address statewide adequacy in
funding. We code the 1996 court order as a school finance reform, in part because
Baltimore is such a large district.

In 2004, the Baltimore schools had an accumulated budget deficit of $58 million. In
response to a new state law requirement, it cut its budget drastically, and planned a
two-year paydown of the deficit. The ACLU returned to court in Bradford, trying to
restore funding to Baltimore schools and stop cuts to academic programs impacting
students. The Circuit Court ruled that the budget cuts had resulted in reduced
educational opportunity to students and that $30 million to $45 million in funds
should be restored, preferably with additional revenue from the city and state. The

5Case history drawn from http://www.schoolfunding.info/states/md/lit_md.php3;
http://www.aclu-md.org/uploaded_files/0000/0173/bradford_summary.pdf.


                                                                                       ix
State appealed, arguing that education funding levels are outside court jurisdiction.
In 2005, Marylandʼs highest court ruled against the Stateʼs attempt to strike the
lower court order, but did not overturn the state law for the deficit paydown. As a
result, the additional funding awarded under the Thornton commission would
proceed, but since no additional funds were ordered at this time we do not code this
as a separate court ordered school finance reform.

Michigan6
1997: JJP court order; LRS no event

Durant v. State of Michigan (“Durant I”), was filed in 1980 and decided in 1997. The
major issue was state funding for special education mandates. In its ruling on
Durant I, the Michigan Supreme Court unanimously held that state government had
not properly financed three state-imposed mandates: special education, special
education transportation and a school lunch program. The court split awarded
monetary damages to local school districts to repay past costs of mandates. Due to
the limited nature of the lawsuit, we do not code this as a school finance reform.

Montana7
1993: JJP court order; LRS legislative event but no court order
2008: JJP court order; LRS no event

Montana’s Supreme Court ruled in Helena Elementary School District No. 1 v. State in
1989 that the state’s school finance system was unconstitutional. This is outside the
scope of our sample. The legislature responded in 1989, then overhauled the
formula again in 1993 via House Bill 667. Earlier that year, the Montana Rural
Education Association v. State case was tried but not decided. Following the
legislative action, but still in 1993, the state’s First Judicial District Court for Lewis
and Clark County ruled that the case was moot due to the new law. It permitted the
plaintiffs to argue that the new law remained unconstitutional, but to our
knowledge the case ended then. JJP code this as a court order; we code House Bill
667 as a legislative action, but do not code the case as a court order.

In 2005, in Columbia Falls Elem. Sch. Dist. 6 v. State, the trial court found that the
state was not providing a “quality” education as mandated by the constitution, and

6Case history from https://www.mackinac.org/8568.
7Case history from http://www.mqec.org/school-funding-history/;
http://schoolfunding.info/2011/12/school-funding-cases-in-montana/;
https://static1.squarespace.com/static/53ab63e1e4b0cb2b67560152/t/55ef5b40
e4b064e46223df9f/1441749824419/CF-Decision-II.pdf;
http://static1.squarespace.com/static/53ab63e1e4b0cb2b67560152/t/55ef3dcbe
4b0adc4e323efbc/1441742283987/Rural_Ed_Assoc-v-
State_District_Order_re_Mootness_Issue_1993.pdf;
http://leg.mt.gov/content/committees/interim/2005_2006/edu_local_gov/minutes
/02242006exhibits/ELG02242006_ex5.pdf.


                                                                                         x
in particular it had violated the provision of the state constitution requiring the
state to commit to preserve the cultural heritage of American Indians. JJP and LRS
each code this as a court-ordered school finance reform. A subsequent 2007
legislative reform (which we code as a legislative event) made substantial changes
to the school finance system in light of this ruling.

Suit was filed in 2008 seeking supplemental monetary relief to help districts avoid
funding shortfalls in 2009. In December 2008, the district court declined to award
any supplemental relief, so we do not code 2008 as a court-ordered school finance
reform.

New Hampshire8
2006: JJP court order; LRS no event

In September 2006 in Londonderry School District v. State the New Hampshire
Supreme Court ordered the state to define a “constitutionally adequate education”
by June 2007. After recounting the failure to establish this definition in several
previous cases (both JJP and LRS code court orders in 1993, 1997, and 1999), the
court concluded that it is willing to defer to the legislature one more time, and that
“in the absence of action…, a judicial remedy is not only appropriate, but essential”
in order to vindicate the constitutional rights of New Hampshire’s students.

In the 2006 decision, the Court ordered the State to define a “constitutionally
adequate education” by the end of the 2007 legislative session, but deferred to the
legislature for appropriate action. We code the 2008 legislative action but not the
2006 court order.

New Jersey9
1991: JJP court order; LRS no event
1998: JJP no event; LRS court order
2000: JJP no event; LRS court order

New Jersey’s school finance litigation history is extremely complex, with a decades-
long exchange between the legislature and the courts. There have been many, many
rulings in the Abbott v. Burke case in particular. The court ruled in Abbott II in 1990
(counted by both JJP and LRS) that state funding statutes failed to ensure adequate

8Case history from https://www.nhbar.org/publications/display-journal-
issue.asp?id=365.
9 Case histories drawn from

http://www.schoolfunding.info/resource_center/legal_docs/New%20Jersey/Abbot
t%20Decisions/Abbott-SupremeCourt_May1997.PDF;
http://www.schoolfunding.info/resource_center/legal_docs/New%20Jersey/Abbot
t%20Decisions/Abbott-SupremeCourt-May-1998.PDF;
http://www.schoolfunding.info/resource_center/legal_docs/New%20Jersey/Abbot
t%20Decisions/Abbott-SupremeCourt-Feb-2002.PDF.


                                                                                         xi
funding in the low-wealth “Abbott districts”, and noted that students in these
districts need programs and services beyond those provided to students in
wealthier districts. In response, the legislature passed the Quality of Education Act
of 1990 (QEA; LRS code this as a legislative event).

In 1991, the plaintiffs applied to the court to declare the QEA unconstitutional. The
court declined to hear the motion at that time. JJP code this as a court order, but we
do not. The court did find the QEA unconstitutional in the 1994 Abbott III ruling;
both JJP and LRS count this event.

In 1998’s Abbott V ruling, the court required the state to increase funding to ensure
parity in per-pupil expenditures between the Abbott districts and the average of the
state's 110 successful suburban school districts, and directed the state to conduct a
study to determine the needs of Abbott students and the programs necessary to
meet those needs. Based on the State’s study, the court ordered additional remedial
measures for the Abbott children, including preschool for all three- and four-year
olds, adequate school facilities, and “supplemental” programs. We code this as a
school finance reform, though JJP do not.

After plaintiffs brought another motion alleging the state did not comply with the
Abbott V ruling, the court provided (in the 2000 Abbott VI ruling) more detail on the
preschool requirements, including substantive educational standards, certified staff,
and a maximum student/teacher ratio of 15:1. We code this as a school finance
reform; again, JJP do not.

New Mexico10
1998: JJP court order; LRS no event
1999: JJP no event; LRS court order

In 1998, a number of districts brought a capital funding/facilities suit, Zuni School
District v. State, CV-98-14-II (Dist. Ct., McKinley County Oct. 14, 1999), claiming that
the funding system for capital items was unconstitutional. The trial court granted
partial summary judgment in favor of plaintiffs and ordered the state to "establish
and implement a uniform funding system for capital improvements . . . and for
correcting existing past inequities."

The case was filed in 1998 but decided in 1999. JJP code it as a 1998 event, but we
code it as a 1999 event based on the decision date.

Oregon11
2009: JJP court order; LRS no event

10 Case history from http://www.schoolfunding.info/states/nm/lit_nm.php3;
https://nces.ed.gov/edfin/pdf/lawsuits/Zuni_v_%20nm.pdf;
http://ielp.rutgers.edu/resources/New_Mexico.
11 Case history from http://www.educationjustice.org/states/oregon.html.



                                                                                      xii
In January 2009, the Oregon Supreme Court found in Pendleton School District 16R v.
State that the legislature had, in violation of a 2000 constitutional amendment,
failed to fund the Oregon public school system at a level sufficient to meet the
quality education goals established by law. However, it concluded that the state
constitution did not give the court authority to issue an injunction requiring the
state to provide sufficient funding to reach those goals. Because the court ruled that
the law was not judicially enforceable, and no subsequent legislative actions were
taken, we do not code this event as a school finance reform.

South Carolina12
2005: JJP court order; LRS no event

In 1999, in Abbeville County Sch. Dist. v. State, the South Carolina Supreme Court held
that plaintiffs had a valid claim under the state constitution's education clause,
interpreted the clause to mean that the legislature must provide children with a
“minimally adequate education,” and remanded the case for trial. The lower court
ruled in 2005 that the state’s failed to meet its constitutional requirement by
inadequately providing early education programs, but ruled against plaintiff claims
requesting relief regarding school buildings and quality teaching. Because the court
did not order substantial school finance reform, we do not code a 2005 event.

Both plaintiffs and defendants appealed to the South Carolina Supreme Court, which
heard oral argument in 2008 and again in 2012. In 2014, the state supreme court
held the state’s school funding unconstitutional, declaring that "South Carolina's
education funding scheme is a fractured formula denying students ... the
constitutionally required opportunity." The court explained that the resources
provided failed to produce sufficient educational opportunities. The court explicitly
refrained from mandating how the state should remedy the system, but ordered the
parties to work together to present a new funding system to the court “within a
reasonable time.” The 2014 court order meets our definition of a court-ordered
school finance reform, but is outside of our sample period so is not included in our
tabulation (or in JJP’s).

Texas13
2004: JJP court order; LRS no event.

A trial court found in West Orange-Cove Consolidated ISD v. Nelson (2004) that the
Texas school finance system failed to provide “an adequate, suitable and efficient
education system” as required by the state constitution, and additionally found the
state property tax to be unconstitutional.


12Case history from http://www.educationjustice.org/states/southcarolina.html.
13Case history from http://caselaw.findlaw.com/tx-supreme-court/1153227.html;
http://www.schoolfunding.info/states/tx/McCown.pdf.


                                                                                   xiii
In 2005, the state Supreme Court ruled in Neeley v. West Orange-Cove Indep. Sch.
Dist. that the state property tax was unconstitutional, but held that despite funding
inequities the state’s education finance system did not violate the constitutional
adequacy, efficiency, and suitability requirements. The court wrote that the school
finance system displayed deficiencies that could in time render it unconstitutional
under the education article. Because the supreme court did not order reform’s, we
do not include this case.

Washington14
1991: JJP court order; LRS no event
2007: JJP court order; LRS no event
2010: JJP no event; LRS court order

Seattle School District v. State, also known as Seattle II, was a 1983 trial court ruling
following up on the 1978 Seattle I decision that prompted an overhaul of the school
finance system and the introduction of the Basic Education Act. Seattle II expanded
the definition of “basic education” in the state to include special education, and
bilingual and remedial programs. The state did not appeal, and the legislature
amended the school finance system to include funding for these programs. JJP date
this case to 1991. To our knowledge, it occurred in 1983, so does not fall into our
sample period.

In Federal Way Sch. Dist. v. State, filed in 2006, plaintiffs alleged that the state
funding system failed to amply fund education in all school districts and was
unconstitutional. In 2007, Judge Michael Heavey held in favor of plaintiffs, finding
that the State’s method of providing salary funding was unconstitutional. The state
Supreme Court, however, issued a narrower ruling in 2009 that a “uniform system”
of education governs educational content, teacher certification, instructional hour
requirements and the assessment system, but does not require uniform funding of
staff salaries. The court did not rule on whether the plaintiffs had “ample” funds
under the state constitution. Because the 2009 Supreme Court ruling did not involve
finances, we do not code this as an event.

McCleary v. State, filed in 2007, argued that although the state had developed
standards for a constitutional “basic education,” it was not fully funding that
education. In 2010, the Superior Court held that the state funding system was
unconstitutional because it neither determined the cost of nor provided the
resources needed for a basic education for all children in the state. The court
ordered the state to fund a constitutionally adequate education, using stable and

14Case history drawn from
https://www.courts.wa.gov/opinions/pdf/843627.opn.pdf;
http://digitalcommons.law.seattleu.edu/cgi/viewcontent.cgi?article=2290&context
=sulr;
https://www.courts.wa.gov/opinions/pdf/843627.opn.pdf;
http://www.schoolfunding.info/states/wa/lit_wa.php3.


                                                                                       xiv
dependable state sources. In response, the legislature enacted legislative reforms,
and in early 2012 the Washington Supreme Court affirmed the Superior Court
ruling. We code the 2010 event, as the legislature acted on it without waiting for it
to be upheld by the Supreme Court.


References

Corcoran, S. P., & Evans, W. N. (2015). Equity, adequacy, and the evolving state role
       in education finance. In H. F. Ladd and M. E. Goertz, eds., Handbook of
       Research in Education Finance and Policy, 2nd edition. New York: Routledge.
Jackson, C. K., Johnson, R. C., & Persico, C. (2016). The effects of school spending on
       educational and economic outcomes: Evidence from school finance reforms.
       Quarterly Journal of Economics 131(1), 157-218.
Jacob, B. & Rothstein, J. (2016). The measurement of student ability in modern
       assessment systems. Journal of Economic Perspectives, forthcoming.




                                                                                        xv
Appendix Figures

                                                             Figure A1: Event time balance
               30
               20
 # of States
               10
               0




                        −5   −4   −3   −2   −1   0   1   2   3   4   5   6   7   8   9   10   11   12   13   14   15   16   17   18   19   20


                                                                 (a) Finance (# of states)
               40
 # of St−Gr−Sub Cells
       20      10
               0 30




                        −5   −4   −3   −2   −1   0   1   2   3   4   5   6   7   8   9   10   11   12   13   14   15   16   17   18   19   20


                                                         (b) NAEP (# of state-grade-subject cells)


Notes: Figure shows the number of state-year (panel A) or state-subject-grade-year (panel B) observations
used in our event study samples, for each year relative to the focal event.




                                                                                                                                                xvi
Figure A2: Slopes of revenues per pupil with respect to log district mean income, by state finance reform
status, 1990-2012




                            2000   1500
                 Total Revenue Slope
               500       1000
                            0




                                          1990   1995            2000              2005          2010
                                                                    Year

                                                 No Reform States        Finance Reform States


                                                        (a) Total revenue slopes
                            1.05
                            1
               Test score slopes
                  .9       .95
                            .85
                            .8




                                          1990   1995               2000            2005           2010
                                                                      Year

                                                 No Reform States        Finance Reform States


                                                           (b) NAEP slopes


Notes: See notes to Figures 2 and 3. This figure repeats those, but uses the slopes of revenues (panel A) or
test scores (panel B) with respect to log district mean income in place of the between-quintile gaps.
                                                                                                          xvii
       Figure A3: Event study estimates for total revenues and test scores by district income group




                           2000   1500
                  Revenue effects
               500     10000




                                         1   2               3              4            5
                                                 District Income Quintile

                                                    Finance Beta: Tot Rev


                                                 (a) Total revenue
                           .1
                  10−year NAEP effects
               −.05      0 −.1   .05




                                         1   2               3              4            5
                                                 District Income Quintile

                                                          NAEP Beta


                                                    (b) NAEP


Notes: Figure shows event study estimates from one-parameter parametric models for mean revenues and
mean test scores in each quintile. Estimates for quintiles 1 and 5 are shown in Table 3, panels B and C,
column 3, and Table 6, columns 3 and 4. 95% confidence intervals shown by dotted lines.

                                                                                                      xviii
                                              Figure A4: Event study estimates of NAEP e↵ects, by grade




                                         .2            .1
                            Change in test score slope
                     −.6 −.5 −.4 −.3 −.2 −.1 0




                                                             −5    0             5            10          15              20
                                                                                Years Since Event

                                                                  Non−Parametric Estimate           Parametric Estimate


                                                                               (a) Grade 4
                                         .2             .1
                             Change in test score slope
                     −.6 −.5 −.4 −.3 −.2 −.1 0




                                                             −5    0             5            10          15              20
                                                                                Years Since Event

                                                                  Non−Parametric Estimate           Parametric Estimate


                                                                               (b) Grade 8


Notes: Figure shows event study estimates for NAEP scores, separately for 4th and 8th grade. Each
specification includes state and subject-year fixed e↵ects. p-values for omnibus hypothesis tests of zero
pre-event e↵ects in the non-parametric model are 0.05 in Panel A and 0.24 in Panel B; p-values for zero
post-event e↵ects are <0.001 in each panel. In the parametric model, the p-value for the hypothesis that
the pre-event trend is zero is 0.97 in Panel A and 0.69 in Panel B; for the test that the post-event jump and
change in trend is zero it is 0.23 and 0.005, respectively.



                                                                                                                               xix
Figure A5: Event study estimates of school finance reform e↵ects on the di↵erence in mean test scores
between lowest and highest income school districts.
                                              .3
               Change in Q1−Q5 Mean Test Scores
              −.1      0      .1     .2




                                                   −5    0             5            10          15              20
                                                                      Years Since Event

                                                        Non−Parametric Estimate           Parametric Estimate



Notes: Figure shows event study estimates for the gap in mean test scores between the bottom (Q1) and top
(Q5) quintiles of the state’s distribution of district mean household income. p-value for the hypothesis that
pre-event e↵ects are zero is 0.64 in the non-parametric model and 0.23 in the parametric model; p-values for
zero post-event e↵ects are <0.001 and 0.07, respectively.




                                                                                                                     xx
Appendix Tables

 Appendix Table A1
 Complete Event List, 1990-2011


                                                                  Lafortune, Jackson,
                                                                                       Corcoran
                                                                 Rothstein & Johnson
 State          Year    Event                                                          & Evans
                                                                Schanzenbach & Persico
                                                                                        (2015)
                                                                    (2016)    (2016)
 Alabama        1993    Alabama Coalition for Equity (ACE) v.                    X
                        Hunt; Harper v. Hunt
 Alaska         1999    Kasayulie v. State of Alaska               Court         X
 Arizona        1994    Roosevelt v. Bishop                        Court         X
                1997    Hull v. Albrecht                           Court         X
                1998    Hull v. Albrecht                           Court         X
                2007    Flores v. Arizona                                        X
 Arkansas       1994    Lake View v. Arkansas                      Court         X
                1995    Approved Equitable School Finance           Bill                 n/a
                        Plan (Acts 917, 916, and 1194)
                2002    Lake View v. Huckabee                      Court         X        X
                2005    Lake View v. Huckabee                      Court         X        X
                2007    Various acts resulting from Master's        Bill                 n/a
                        Report findings
 California     1998    Leroy F. Greene School Facilities Act       Bill                 n/a
                        of 1998
                2004    Senate Bill 6, Senate Bill 550,             Bill                 n/a
                        Assembly Bill 1550, Assembly Bill
                        2727, and Assembly Bill 3001
 Colorado       2000    Bill 181; Various Other Acts                Bill                 n/a
 Connecticut    1995    Sheff v. O’Neill                                         X
                2010    Coalition for justice in Education                       X       n/a
                        Funding, Inc. v. Rell
 Idaho          1993    Idaho Schools for Equal Educational        Court
                        Opportunity v. Evans (ISEEO)
                1994    Senate Bill 1560                            Bill                 n/a
                1998    Idaho Schools for Equal Educational                      X
                        Opportunity v. State (ISEEO III)
                2005    Idaho Schools for Equal Educational        Court         X
                        Opportunity v. Evans (ISEEO V)
 Indiana        2011    HB 1001 (Pl229)                             Bill                 n/a


  (continued)



                                                                                                  xxi
Appendix Table A1 (continued)
State          Year     Event                                 LRS (2016)   JJP (2016) CE (2015)
Kansas         1992 The School District Finance and              Bill                    n/a
                        Quality Performance Act
               2005 Montoy v. State; Montoy v. State            Both           X         X
                        funding increases
Kentucky       (1989) Rose v. Council for Better Education,     Court          X         X
                        Inc.
               1990 Kentucky Education Reform Act (HB            Bill                   n/a
                        940)
Maryland       1996 Bradford v. Maryland State Board of         Court
                        Education
               2002 Bridge to Excellence in Public Schools       Bill                   n/a
                        Act (BTE) (Senate Bill 856)
               2005 Bradford v. Maryland State Board of                        X      (upheld)
                        Education
Massachusets 1993 McDuffy v. Secretary of the Executive         Both           X         X
                        Office of Education; Massachusetts
                        Education Reform Act
Michigan       1997 Durant v. State of Michigan                                X
Missouri       1993 Committee for Educational Equality v.       Both           X
                        State of Missouri; Outstanding
                        Schools Act (S.B. 380)
               2005 Senate Bill 287                              Bill                   n/a
Montana        1993 House Bill 667                               Bill          X
               2005 Columbia Falls Elementary School v.         Court          X         X
                        State
               2007 M.C.A. § 20-9-309                            Bill                   n/a
               2008 Montana Quality Education Coalition                        X        n/a
                        v. Montana
New Hampshire 1993 Claremont New Hampshire v. Gregg             Court          X
               1997 Claremont School District v. Governor       Court          X         X
               1998 Opinion of the Justices--School                                      X
                        Financing (Claremont III)
               1999 Claremont v. Governor (Claremont            Both           X         X
                        III); RSA chapter 193-E
               2000 Opinion of the Justices--School                                      X
                        Financing (Claremont VI)
               2002 Claremont School District v. Governor       Court          X         X
               2006    Londonderry School District v. New                      X
                       Hampshire
               2008    SB 539                                    Bill                   n/a



(continued)

                                                                                              xxii
Appendix Table A1 (continued)
State          Year     Event                                LRS (2016)   JJP (2016) CE (2015)
New Jersey     1990 The Quality Education Act; Abbot v.        Both            X         X
                        Burke
               1991 Abbott v. Burke                                           X
               1994 Abbott v. Burke                            Court          X         X
               1996 Comprehensive Educational                   Bill                   n/a
                        Improvement and Financing Act of
                        1996
               1997 Special Master's Report; Abbott v.          Bill                    X
                        Burke
               1998 Abbott v. Burke                            Court                    X
               2000 Abbott v. Burke                            Court
               2008 The School Funding Reform Act of            Bill                   n/a
                        2008
New Mexico     1998 Zuni School District v. State                             X
               1999 Zuni School District v. State              Court
               2001 Deficiencies Corrections Program;           Bill                   n/a
                        Public School Capital Outlay Act
New York       2003 Campaign for Fiscal Equity, Inc. v.        Court          X         X
                        State
               2006 Campaign for Fiscal Equity, Inc. v.        Court          X
                        State
               2007 Education Budget and Reform Act             Bill                   n/a
North Carolina 1997 Leandro v. State                           Court          X
               2004 Hoke County Board of Education v.          Court          X         X
                        State
North Dakota 2007 SB 2200                                       Bill                   n/a
Ohio           1997 DeRolph v. Ohio                            Court          X         X
               2000 DeRolph v. Ohio; Increased school          Both           X         X
                        funding (see 93 Ohio St.3d 309 )
               2001 DeRolph v. Ohio                                                     X
               2002 DeRolph v. Ohio                            Court          X         X
Oregon         2009 Pendleton School District 16R v. State                    X        n/a
South Carolina 2005 Abbeville County School District v.                       X
                        State


(continued)




                                                                                             xxiii
Appendix Table A1 (continued)
State          Year     Event                                       LRS (2016)    JJP (2016) CE (2015)
Tennessee      1992 The Education Improvement Act                      Bill                     n/a
               1993 Tennessee Small School Systems v.                 Court            X         X
                        McWherter
               1995 Tennessee Small School Systems v.                 Court           X          X
                        McWherter
               2002 Tennessee Small School Systems v.                 Court           X          X
                        McWherter
Texas          1991 Edgewood Independent School                       Court           X          X
                        District v. Kirby
               1992 Carrolton-Farmers Branch ISD v.                   Court           X          X
                        Edgewood Independent School
                        District
               1993 Senate Bill 7                                       Bill                    n/a
               2004 West Orange-Cove ISD v. Nelson                                    X
               2005 West Orange-Cove Consolidated ISD                                            X
                        v. Neeley
Vermont        1997 Brigham v. State                                  Court           X          X
               2003 Revisions to Act 68; H.480                         Bill                     n/a
Washington     1991 Seattle II                                                        X
               2007 Federal Way School District v. State                              X
               2010 McCleary v. State                                 Court          n/a        n/a
West Virginia  1995 Tomblin v. Gainer                                 Court           X
Wyoming        1995 Campbell County School District v.                Court           X          X
                        State
               1997 The Wyoming Comprehensive                           Bill                    n/a
                        Assessment System; The Education
                        Resource Block Grant Model
               2001 Campbell II; Recalibration of the MAP               Bill          X         n/a
                        model

Notes: Table lists all events included in any of the Lafortune-Rothstein-Schanzenbach (2016); Jackson-
Johnson-Persico (2016); or Corcoran-Evans (2015) event lists, from 1990 onward. Xs indicate events
that appear in the relevant event list; n/a indicates events that were out of scope for the relevant
list, either because they were too recent or because it included only court cases and not legislative
events. In Lafortune et al. column, events are classified as "court," "bill," or "both"; rows without an
entry are not included in our event database but are included in one of the comparison samples.
Bold years indicate the single event per state selected by our algorithm (see text). Appendix D
discusses discrepancies between Lafortune et al. and Jackson et al. lists.




                                                                                                      xxiv
                                    Table A2: Event studies for state budgets

                                                                       Per capita    Per pupil
              Tax revenues:
              Total revenues                                             433⇤⇤        3,586⇤⇤
                                                                         (187)        (1,762)
              Expenditures:
              Total expenditures                                         415⇤⇤        3,113⇤⇤
                                                                         (162)        (1,508)
              Education expenditures                                     137⇤⇤        1,102⇤
                                                                          (68)         (605)
              Intergovernmental transfers                                164⇤⇤        1,264⇤⇤
                                                                          (70)         (581)
              General expenditures (less education, IG transfers)          83           537
                                                                         (105)         (707)


    Notes: Table shows estimates from the one-parameter event study specification (equation (1)) for state
budgetary aggregates. State and year fixed e↵ects are included. Standard errors are clustered at the state
level.

                                     Table A3: Comparison to Card-Payne

                               State revenues (per capita)             Total revenues (per capita)
                        1997-1992           1990-2012 (LRS)       1997-1992         1990-2012 (LRS)
                          (CP)                                      (CP)
                         Long di↵       Long di↵    Event study    Long di↵      Long di↵   Event study
     Court Ruling:
     Upheld                 -0.81                                    0.20
                           (0.67)                                   (0.52)

     Unconstitutional     -1.89⇤⇤⇤                                  -1.10⇤⇤
                           (0.62)                                    (0.48)
     Selected Events:
     Post Event                            -2.06      -2.25⇤⇤                      -2.44          -1.61
                                          (2.24)       (0.89)                     (4.73)         (2.38)


    Notes: This table shows results using slopes from a regression of per capita state or total funding on
district mean household income (note: district mean income here is in levels, not logs). Columns 1 and 4 are
from table 4 of Card and Payne (2002) and show the long di↵erence from 1977-1992 in the level-level slope
coefficient. In columns 2 and 5, we replicate the Card and Payne specification using data from 1990 and
2012. Columns 3 and 6 show estimated e↵ects from the one parameter event study specification (equation
(1)) where level-level per capita slope coefficients are the dependent variables.




                                                                                                          xxv
                                Table A4: Comparison to Corcoran-Evans

                                              CE 2015           CE 2015                LRS 2016
                                             Overturn     Overturn    Overturn*    Selected   First
                                                                      Adequacy                Court
     Per-pupil expenditure inequality :
     Coefficient of variation                 -0.029⇤⇤⇤   -0.044⇤⇤⇤    0.028⇤⇤      0.010      -0.001
                                               (0.010)     (0.014)     (0.014)     (0.011)    (0.008)
     Per-pupil expenditures:
     log(Mean)                                0.092⇤⇤⇤      0.056       0.068      0.056⇤⇤⇤   0.044⇤⇤
                                               (0.025)     (0.037)     (0.049)      (0.021)   (0.018)
     Per-pupil revenues, by source:
     Total revenues                            701⇤⇤⇤       478           416      829⇤⇤⇤     759⇤⇤⇤
                                                (256)      (360)        (445)       (302)      (264)
     State revenues                            786⇤⇤⇤      489⇤⇤        556⇤⇤      912⇤⇤      998⇤⇤
                                                (202)      (199)        (271)       (359)      (454)
     Local revenues                              -91        -31          -112        -146       -351
                                                (266)      (404)        (452)       (307)      (372)


    Notes: Columns 1-3 are from Table 19.3 of Corcoran and Evans (2015). In Columns 2 and 3, coefficients in
each row come from a single regression, where column 2 represents the impact of a court ruling overturning
the existing school finance system and column 3 represents the additional impact of an adequacy ruling
relative to an equity ruling. Columns 4-5 repeat the analysis, using our sample and an approximation to the
Corcoran and Evans specification.




                                                                                                        xxvi
                           Table A5: Event study for log income, race, free lunch

                                             (a) Income gradients

                                          Log mean income           Minority share        Free lunch share
                                            (1)        (2)          (3)          (4)        (5)          (6)
                                                                          ⇤
     Post Event * Yrs Elapsed             -0.0010    0.0008    0.0022          0.0018     0.0062       0.0091
                                         (0.0029)   (0.0040)   (0.0013)       (0.0015)   (0.0064)     (0.0071)
     Trend                                           -0.0026                   0.0008                  -0.0022
                                                    (0.0042)                  (0.0008)                (0.0030)
     Post Event                                      0.0193                    -0.0044                 -0.0227
                                                    (0.0368)                  (0.0051)                (0.0291)
     Observations                          147        147        1045           1045       958          958
     p(post-event=post-event*trend=0)      0.72       0.87       0.09           0.49       0.34         0.39
     State FEs                              X          X          X              X          X            X
     Yr FEs                                 X          X          X              X          X            X


                                             (b) Q1-Q5 di↵erence

                                         Log mean income         Minority share           Free lunch share
                                           (1)        (2)        (3)            (4)        (5)           (6)
                                                                                                  ⇤
     Post Event * Yrs Elapsed             -0.0017    -0.0008    -0.0015        -0.0017   -0.0036      -0.0052⇤⇤
                                         (0.0029)   (0.0035)   (0.0017)       (0.0020)   (0.0019)      (0.0024)
     Trend                                           -0.0004                   0.0003                  0.0018
                                                    (0.0035)                  (0.0016)                (0.0021)
     Post Event                                      -0.0073                   -0.0005                 -0.0048
                                                    (0.0290)                  (0.0081)                (0.0157)
     Observations                          145       145        1045           1045        962          962
     p(post-event=post-event*trend=0)      0.55      0.95       0.40           0.66        0.06         0.06
     State FEs                              X         X          X              X           X            X
     Yr FEs                                 X         X          X              X           X            X


   Notes: Table presents event study specifications where the dependent variable is the slope of the indicated
demographic characteristic with respect to the district’s 1990 log mean household income (panel A) or the
gap between the average for districts in the bottom and top quintiles of the 1990 income distribution (panel
B). Minority share and free lunch share are available annually from the Common Core of Data (though
missing in some states and some years); log mean income is available from the Census in 1990 and 2000 and
from the American Community Survey in 2007-11 (coded as 2011).




                                                                                                                  xxvii
                     Table A6: Stratification of race, FRL, & achievement, by quintile

                                                      Q1     Q2         Q3    Q4       Q5
                       Black                         0.24    0.24   0.24      0.17     0.11

                       Black/Hispanic                0.25    0.23   0.24      0.18     0.11

                       White                         0.20    0.20   0.18      0.20     0.22

                       Free/reduced-price lunch      0.32    0.23   0.20      0.15     0.10

                       25th pctl or below (NAEP)     0.27    0.21   0.22      0.17     0.13

                       75th pctl or above (NAEP)     0.14    0.15   0.17      0.22     0.32



    Note: Table shows fraction of students of various groups in districts in various quintiles of the state’s
district income distribution. Each row sums to 1. Racial and free lunch shares are computed using CCD
district-level data for the year 1994. The distribution of high- and low-achieving students is based on the
2003 NAEP data, which is the first year of comprehensive data for all grades and subjects.

          Table A7: Event studies for district-mean resource gaps by race, FRL, & achievement

                                Black/White           Free Lunch             25th/75th Pctl (NAEP)
                           St. Rev      Tot. Rev   St. Rev   Tot. Rev        St. Rev          Tot. Rev
          Post Event            197       195         2         23             143             193⇤
                               (160)     (164)      (185)      (195)          (141)            (101)
          Observations         1047      1047       938           938         1509             1509
          State FEs             X         X          X             X           X                X
          Yr FEs                X         X          X             X
          Sub-gr-yr FEs                                                        X                 X

    Note: In columns 1 and 2, the dependent variable in event study specifications is the average per-pupil
revenue in the district attended by the average black student, less that in the district attended by the
average white student in the same state. In columns 3 and 4, analogous revenue gaps are constructed for
free/reduced-price lunch and non-free/reduced-price lunch students. In columns 5 and 6, analogous revenue
gaps are constructed for students scoring at or below the 25th percentile in the NAEP, and students scoring
at or above the 75th percentile in the NAEP. The Post Event coefficient shows the estimated event e↵ect from
parametric event study model without controlling for prior trends. State and year fixed e↵ects are included
in columns 1-4. State and grade-subject-year fixed e↵ects are included in columns 5 and 6. Standard errors
are clustered at the state level.




                                                                                                         xxviii
