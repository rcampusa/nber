                              NBER WORKING PAPER SERIES




INFORMATION ACQUISITION, EFFICIENCY, AND NON-FUNDAMENTAL VOLATILITY

                                      Benjamin M. Hébert
                                         Jennifer La'O

                                      Working Paper 26771
                              http://www.nber.org/papers/w26771


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                    February 2020




We thank John Leahy for his excellent discussion and feedback on our paper. We also thank
Marios Angeletos and Mike Woodford for their insightful advice and comments. The views
expressed herein are those of the authors and do not necessarily reflect the views of the National
Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2020 by Benjamin M. Hébert and Jennifer La'O. All rights reserved. Short sections of text, not
to exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including © notice, is given to the source.
Information Acquisition, Efficiency, and Non-Fundamental Volatility
Benjamin M. Hébert and Jennifer La'O
NBER Working Paper No. 26771
February 2020
JEL No. C72,D62,D83

                                          ABSTRACT

This paper analyzes non-fundamental volatility and efficiency in a class of large games (including
e.g. linear-quadratic beauty contests) that feature strategic interaction and endogenous
information acquisition. We adopt the rational inattention approach to information acquisition but
generalize to a large class of information costs. Agents may learn not only about exogenous
states, but also about endogenous outcomes. We study how the properties of the agents'
information cost relate to the properties of equilibria in these games. We provide the necessary
and sufficient conditions information costs must satisfy to guarantee zero non-fundamental
volatility in equilibrium, and provide another set of necessary and sufficient conditions to
guarantee equilibria are efficient. We show in particular that mutual information, the cost
function typically used in the rational inattention literature, both precludes non-fundamental
volatility and imposes efficiency, whereas the Fisher information cost introduced by Hébert and
Woodford [2020] generates both non-fundamental volatility and inefficiency.


Benjamin M. Hébert
Graduate School of Business
Stanford University
655 Knight Way
Stanford, CA 94305
and NBER
bhebert@stanford.edu

Jennifer La'O
Columbia University
Department of Economics
1105A International Affairs Building
420 West 118th Street
New York, NY 10027
and NBER
jl4196@columbia.edu
1    Introduction
In many economic environments, agents make choices under incomplete information and have
incentives to align their actions with both economic "fundamentals" and the actions of other
agents [Morris and Shin, 2002, Angeletos and Pavan, 2007]. These games of strategic interaction
form the underlying basis for many micro-founded macroeconomic environments; examples
include firms' nominal price-setting decisions in New Keynesian models [Woodford, 2003],
firms' real quantity choices in business cycle models [Angeletos and La'O, 2010, 2013], as well as
investors' asset positions in models of financial trade [Grossman and Stiglitz, 1976, 1980].
    In these games, agents' beliefs over exogenous fundamentals and the endogenous actions
of others play a key role in determining equilibrium outcomes. But where do these beliefs
come from and how are they formed? In this paper we investigate the endogenous acquisition
of information within games of strategic interaction.      We ask two questions.      First, what
properties of the agents' information acquisition costs guarantee that an equilibrium of the
game does or does not exhibit non-fundamental volatility? Second, what properties of the
agents' information acquisition costs guarantee that an equilibrium is constrained efficient?
    A substantial literature has studied non-fundamental volatility and efficiency in exogenous
information environments, that is, when agents form their beliefs based on an exogenously-
given set of signals. In these environments, aggregate equilibrium outcomes are typically
driven by both fundamentals as well as shocks orthogonal to fundamentals. The latter, "non-
fundamental," shocks are rationalized as the result of errors in publicly-observed signals,
or more generally, correlated errors in beliefs--standard components of generic information
structures [Bergemann and Morris, 2013]. In fact, a robust positive prediction of these games is
that the greater the strategic complementarity in actions (i.e. the greater the incentive to align
actions with others), the greater the role of non-fundamental volatility in equilibrium outcomes
[Morris and Shin, 2002].
    Non-fundamental volatility can help explain short-run fluctuations in asset prices or
business cycle activity that appear to be driven by "market sentiment" or "animal spirits"
[Angeletos and La'O, 2010, 2013]. It is tempting to give a normative interpretation to these
positive predictions and assume that non-fundamental volatility is a sign of inefficiency.
Angeletos and Pavan [2007] demonstrate that, with exogenously given information structures,
such conclusions are unwarranted.
    But it is not obvious that non-fundamental volatility should be expected when agents
acquire their information endogenously. It is also not clear whether agents will acquire their
information efficiently, nor whether the questions of efficiency and non-fundamental volatility
are related. Our paper seeks to address these questions.




                                                1
This paper. We study a general class of large games of strategic interaction. A continuum
of ex-ante identical agents take actions under incomplete information. Each agent has the
incentive to align her own action with exogenous fundamentals as well as with the endogenous
mean action. Agents must therefore form beliefs over these objects.
       We allow information to be acquired endogenously. In particular, we adopt the rational
inattention approach to costly information acquisition proposed by Sims [2003]. However,
relative to the standard rational inattention framework, we make two important departures.
       First, we do not assume the information acquisition cost is mutual information--the typical
cost function introduced by Sims [2003] and used widely throughout the rational inattention
literature. We instead consider a more general class of cost functions: costs that are "posterior-
separable" in the terminology of Caplin, Dean, and Leahy [2019]. This class nests the standard
mutual information cost function as a special case. However, it also includes other cost
functions that have been proposed in the literature, including LLR cost function of Pomatto
et al. [2018] and the Fisher information cost function proposed by H´
                                                                    ebert and Woodford [2020].
       Second, we do not restrict agents to acquiring information only about exogenous
fundamentals. Instead, we follow Denti [2019] and allow the rationally-inattentive agents in
our model to learn not only about exogenous states but also about endogenous mean actions.
This modeling choice is motivated by the agents' incentives to align their actions with the
endogenous mean action, and hence learn about it.
       Thus, in our framework, a continuum of rationally-inattentive agents acquire information
in a relatively unrestricted way about payoff-relevant states, payoff-irrelevant states, and
endogenous mean actions. The payoff-irrelevant states are the potential source of "non-
fundamental" volatility in our framework; they play a role similar to "noisy public signals" in
exogenous information environments.
       Within this context, we answer the two questions posed above. What properties of the
agents' information cost structures guarantee that an equilibrium of the game does or does
not exhibit non-fundamental volatility? And, what properties of the agents' information cost
structures guarantee that an equilibrium exists that is or is not constrained efficient?1 Through
this analysis, we answer a third question: are these properties related?               That is, is non-
fundamental volatility synonymous with inefficiency?
       We begin our analysis with a leading example: the classic linear-quadratic-Gaussian setting.
In this setting, with either the Fisher information cost function or mutual information, agents
optimally receive Gaussian signals. As a result, one might be tempted to think the two cost
functions make identical predictions. We show that this is false--with mutual information,
there is zero non-fundamental volatility and an efficient equilibrium exists, whereas with the
Fisher information cost function the equilibrium exhibits non-fundamental volatility and is
   1
     Angeletos and Sastry [2019] consider the related question of what properties of information costs are
sufficient to ensure efficiency in a Walrasian context.

                                                    2
inefficient.
   This is our first indication that the cost function matters. But it leaves open the question
of what is it about these cost functions that lead to such divergent predictions. Our general
model and analysis is focused on answering this question, and showing that non-fundamental
volatility and efficiency are driven by separate properties.


Partial Monotonicity and Partial Invariance. Whether or not a cost function leads to non-
fundamental volatility or inefficiency depends on two key properties of the agents' information
cost structures: what we call "partial monotonicity" and "partial invariance."
   We introduce and define partial monotonicity and partial invariance as properties of
posterior-separable cost functions, and in particular the divergences that define these cost
functions. Loosely speaking, a divergence can be thought of as a measure of the "distance"
between the prior and posterior. Partial monotonicity and partial invariance describe how this
divergence responds to different transformations of the prior and posterior.
   Suppose an agent is uncertain about a multi-dimensional aggregate state, and receives a
signal that moves her posterior beliefs "away from" her prior in some dimension of the aggregate
state. This signal is, in a sense, more informative than another signal that leaves posterior beliefs
close to the prior in that dimension. This idea leads to a notion of monotonicity: a divergence is
monotonic if the cost decreases as we make the posterior more like the prior in some dimension.
But note that a divergence might be monotonic in some dimensions but not others--this is
essentially our definition of "partial monotonicity."
   Take for example, a two-dimensional state space, s  S and r  R. We will say that a cost
function is monotonic in R if the cost decreases when we replace the posterior's conditional
distribution of r given s with the prior's conditional distribution of r given s. That is, if we make
posteriors more like the prior in this one particular way, this decreases costs.
   We define another concept we call "partial invariance." Take again our two-dimensional
state space s  S and r  R. We will say that a cost function is invariant in R if, for any
prior and posterior with the same conditional distributions of r given s, the divergence between
them is the same regardless of what that conditional distribution is. That is, if their conditional
distributions of r given s are the same, only their marginal distributions on s matter for the
information cost.
   The advantage of defining partial monotonicity and partial invariance in this way is that it
allows us to consider cost functions that are monotonic in one dimension, but not monotonic
in others, or invariant in one dimension, but not invariant in others.
   The forms of partial monotonicity and partial invariance that we introduce are
generalizations of the invariance concept described in the literature on information geometry
[Chentsov, 1982, Amari and Nagaoka, 2007] and that derived from the behavioral "invariance-



                                                 3
under-compression" axiom of Caplin, Dean, and Leahy [2019]. Invariance in this sense has been
applied to particular economic applications by H´
                                                ebert [2018] and H´
                                                                  ebert and Woodford [2019].
   The invariance and monotonicity properties described by these authors indicate whether
a cost function is invariant or monotone with respect to all possible dimensions of the state
space. In contrast, we show how the answers to the questions posed in this paper relate
to invariance and monotonicity of the cost function with respect to specific dimensions of
the state space. That is, the properties of equilibria in this class of games--namely, non-
fundamental volatility and constrained efficiency--depend on the partial monotonicity and
partial invariance properties of information costs that we define.


Results. In our framework agents may acquire information about payoff-relevant states,
payoff-irrelevant states, and endogenous aggregate actions. We consider information costs that
may be monotone or invariant in any, all, or none of those dimensions.
   We first ask: under what conditions does there exist an equilibrium of the game that exhibits
zero non-fundamental volatility? We find that monotonicity of the cost function in payoff-
irrelevant states is necessary and sufficient to ensure the existence of such equilibria for all
payoff functions, and generically necessary. The intuition behind this result is that with such
a cost function, it is always cheaper for agents to condition their signals on the payoff-relevant
states and aggregate actions than to condition their signals on the payoff-irrelevant states. But
this form of monotonicity rules out "public signals," which are by definition not directly payoff-
relevant but more easily observed than the payoff-relevant state itself. As a result, it prevents all
shocks orthogonal to fundamentals from playing a role in equilibrium.
   We then ask: under what conditions does an equilibrium exist that is constrained
efficient? We first provide necessary and sufficient conditions for efficiency when information
is exogenous, extending prior results by Angeletos and Pavan [2007] on efficiency in the use of
information to our more general setting. We then show that, provided there is efficiency in the
use of information, invariance of the cost function in endogenous aggregate actions is sufficient
and generically necessary for the existence of a constrained efficient equilibrium.
   The intuition behind this result is the following. When cost functions are not invariant in the
aggregate action, agents' actions affect the ease with which other agents acquire information.
For example, with the Fisher information cost function in our linear-quadratic example, if
agents take more extreme actions in response to their signals, the endogenous aggregate action
becomes less costly to observe. This is an externality--the planner would like to encourage
more extreme actions to reduce information acquisition costs.
   Finally, we answer the third question: are the answers to our first two questions related?
Our results make evident that separate properties of the information cost determine whether
or not the equilibrium exhibits non-fundamental volatility and whether or not it is efficient. By



                                                 4
precisely defining these properties--namely, partial monotonicity and partial invariance--we
characterize the relationship between information costs and the properties of equilibria.
   Mutual information, the standard cost function used in the rational inattention literature, is
monotone and invariant in all dimensions; as a result, this cost leads to zero non-fundamental
volatility and efficiency. However, alternative cost functions such as the Tsallis entropy cost
[Caplin, Dean, and Leahy, 2019] and the Fisher information cost [H´
                                                                  ebert and Woodford, 2020]
have been proposed because they are better able to match observed experimental behavior (see,
e.g., Dean and Neligh [2019]). The Fisher information cost results in both non-fundamental
volatility and inefficiency, while the Tsallis entropy cost leads to non-fundamental volatility but
an equilibrium remains efficient.


Related Literature. A large literature has studied the positive and normative implications of
large games of strategic interaction and incomplete information, and applied these insights to
questions in macro, finance, and industrial organization (see Angeletos and Lian [2016] for a
recent survey). Much of this literature assumes linear-quadratic payoffs, Gaussian priors, and
exogenously specified Gaussian signals about exogenous states.
   Several authors (e.g. Hellwig and Veldkamp [2009], Myatt and Wallace [2012], Colombo,
Femminis, and Pavan [2014], Pavan [2016]) endogenize information acquisition in the linear-
quadratic setting, allowing agents to choose the precision with which they observe an
exogenously specified set of Gaussian signals about exogenous states.            In these papers,
the presence or absence of non-fundamental volatility depends on the assumed correlation
structure of the exogenously given signals (and, with precision choice across multiple signals,
agents' incentives to coordinate).
   Other authors (e.g. Mackowiak and Wiederholt [2009], Paciello and Wiederholt [2014],
Afrouzi [2019]) also endogenize information acquisition in this setting, but follow the rational
inattention approach of Sims [2003]. These models do not assume a particular set of available
signals; instead, agents can choose any signal structure, subject to a cost described by mutual
information. With quadratic payoffs, Gaussian priors, and mutual information costs, the agent's
optimal signal is a Gaussian signal about economic fundamentals. As a result, equilibria exhibit
zero non-fundamental volatility.
   Our paper also follows the rational inattention approach, but generalizes away from the
mutual information cost function. As a result, we are able to accommodate non-fundamental
volatility, building a bridge between these two seemingly distinct approaches.
   Our study of efficiency builds on the work of Angeletos and Pavan [2007] and Colombo,
Femminis, and Pavan [2014]. Angeletos and Pavan [2007] study the question of constrained
efficiency in the class of linear-quadratic games with exogenous information structures. We
extend their results to multi-dimensional settings with general payoff functions, and obtain



                                                5
necessary and sufficient conditions for efficiency in the use of information in our game.
   However, we shut down a key channel present in Angeletos and Pavan [2007] by assuming
that only the cross-sectional mean of actions, but not the cross-sectional variance, enters
payoffs. This is important for understanding our results vis-`
                                                             a-vis Colombo, Femminis, and
Pavan [2014]. Colombo, Femminis, and Pavan [2014] study the efficiency of information
acquisition within the Angeletos and Pavan [2007] linear-quadratic setting; they show that
efficiency in the use of information does not guarantee efficiency in the acquisition of
information because the dispersion of actions enters payoffs--an externality not internalized
by agents. With this channel shut down in our game, their results imply that efficiency in the
use of information should guarantee efficiency in the acquisition of information.
   Instead, we find that efficiency in the use of information is not sufficient for efficiency in
the acquisition of information because of a different externality: if agents' actions affect other
agents' information costs. The inefficiency we highlight is closely related to the informational
externality that arises when agents observe exogenous signals about endogenous objects such
as prices, as in Laffont [1985], Angeletos and Pavan [2009], Amador and Weill [2010], Vives
[2017], Angeletos, Iovino, and La'O [2020].
   In a similar vein, Angeletos and Sastry [2019] allow rationally inattentive agents to learn from
prices in a Walrasian context with complete markets over states and signal realizations. They
find that invariance of the information cost is sufficient to ensure that a planner cannot improve
allocations by sending a message that reduces information costs.2
   In considering a large class of possible information costs in a rational inattention problem,
and not just mutual information, we build on the work of Caplin, Dean, and Leahy [2019],
Pomatto et al. [2018], and H´
                            ebert and Woodford [2020]. Our focus on games with agents who
can acquire information about the endogenous actions of other agents builds on Denti [2019].
We adapt his approach to static games with a continuum of players. Relative to Denti [2019],
the "largeness" feature of our class of games permits a simpler definition of equilibrium, which
is essentially Bayesian Nash equilibrium in a static, simultaneous-move game. Our definition of
equilibrium can also be thought of as the limit of the dynamic process of strategic information
acquisition Denti [2019] introduces.
   We begin with a linear-quadratic-Gaussian example to illustrate the role that the
information cost plays in determining whether or not equilibria exhibit non-fundamental
volatility and are efficient. Following this, we introduce and analyze the general class of models.
    2
      That is, our paper and Angeletos and Sastry [2019] consider different planner's problems (among
other differences). We employ the constrained efficiency concept in Angeletos and Pavan [2007] and
Colombo, Femminis, and Pavan [2014] for abstract games in which the planner may only control the
action functions and information choices of the players. Angeletos and Sastry [2019] consider a planner
who can send messages to the agents, who can in turn learn about the content of the message (as opposed
to prices or states directly). They ask a different question: whether in markets the price function is an
efficient conveyer of information in the sense of Hayek [1945].


                                                   6
2    A Linear-Quadratic-Gaussian Example
In this section we use a linear-quadratic-Gaussian example to illustrate the impact that
information costs can have on non-fundamental volatility and efficiency.
    We consider a simple, stylized beauty-contest game, similar to the one studied in Morris and
Shin [2002]. A unit-mass continuum of ex-ante identical agents indexed by i  [0, 1] attempt to
choose an action to track both a fundamental state and the average action of the other agents.
Let s  R be the payoff-relevant dimension of the state, and let ai  R be the action of agent
                                                               1 i
i. We define the aggregate action of all agents as a
                                                   ¯=         0 a di.    The payoff of an agent who takes
action   ai   when the aggregate action is a
                                           ¯ and the fundamental state is s is given by

                               u(ai , a
                                      ¯, s) = -(1 -  )(ai - s)2 -  (ai - a
                                                                         ¯)2                          (1)

where   (0, 1) is a scalar.
    The first component of (1) is a quadratic loss in the distance between the agent's action
and the exogenous fundamental s; the second component is a quadratic loss in the distance
between the agent's action and the aggregate action. The scalar  governs the extent of strategic
interaction in this game; for this example, we assume  > 0 so that actions are "strategic
complements." We also assume that  < 1 so that there is a unique pure-strategy Nash
equilibria of this game under complete information, in which every agent takes the same action:
ai = a
     ¯ = s, i.
    In games with exogenous information, agents receive costless signals about the aggregate
state. Let  i  R be the realization of agent i's signal. With the quadratic payoffs in (1), each
agent's optimal action is chosen according to the linear best response function

                                      ai ( i ) = E[(1 -  )s +  a
                                                               ¯| i ],                                (2)

where E[·| i ] denotes the agent's expectations conditional on  i .
    Our focus is on games with endogenous information acquisition by rationally inattentive
agents. For this example, we will consider two different information cost functions: mutual
information and the Fisher information cost function.              With linear-quadratic payoffs and
Gaussian priors, both of these cost functions result in agents optimally choosing to observe a
one-dimensional Gaussian signal [H´
                                  ebert and Woodford, 2020]. As a result, our example falls
into the tractable class of linear-quadratic-Gaussian games. However, we will see that these cost
functions lead to different conclusions about the existence of non-fundamental volatility and
whether equilibria are efficient.
    We begin by discussing the issue of non-fundamental volatility, and then turn to the
question of efficiency.



                                                     7
2.1      Non-Fundamental Volatility
We allow agents to flexibly acquire signals of both the payoff-relevant state, s  R, as well as
a payoff-irrelevant state r  R, subject to a cost. We introduce the payoff-irrelevant states
as potential sources of non-fundamental volatility in equilibrium. Let x = (s, r)T denote the
aggregate state vector. To preserve the linear-quadratic-Gaussian structure of the model, we
assume that all agents have a common Gaussian prior over (s, r), with a prior mean of zero for
both variables and variance-covariance matrix of . That is, x  N (0, ).
      We consider equilibria in which the aggregate action a
                                                           ¯ is a linear function of the aggregate
state. In particular, we guess and verify the functional form

                                                a
                                                ¯=¯ss + ¯ r r,                                       (3)

for some constants ¯ s and ¯ r . Linearity of the aggregate action preserves the linear-quadratic
Gaussian nature of the individual agents' problem. Under this assumption, the agent's best
response after observing the signal  i is

                            ai ( i ) = E[(1 -  +  ¯ s )s +  ¯ r r| i ] = E[ T x| i ],

where  is a column vector of endogenous constants given by

                                            (1 -  +  ¯s,  ¯ r )T .                                   (4)

      Consider now the individual agents' problem in this game. With both mutual information
and the Fisher information cost function, agents will optimally choose to receive a one-
dimensional3 Gaussian signal,
                                                i = T x +  i ,                                       (5)

where  is a vector describing what the agent chooses to learn about,  2 is the variance of the
agent's signal, and   i   is a standard normal shock, i.i.d. across agents. That is, both cost functions
deliver Gaussian signals of the form in (5), but as we will show shortly, the two cost functions
have different implications for the agent's optimal choices of (,  ).
      Given such a signal, the agent's optimal action strategy follows from Bayesian updating (see
e.g. H´
      ebert and Woodford [2020]):

                                                        T                          -2
                   ai ( i ) =  i ,       =                                               .           (6)
                                                       T                     -2 + (T )-1
                                              "beta" between T x and  T x     update on T x

  3
    The one-dimensional nature of the signal is a consequence of the standard result in rational
inattention problems that it is without loss of generality to equate signals with recommended actions.




                                                       8
       The agent's unconditional expected payoff is - T  (,  ) ,4 where  (,  ) is the posterior
variance-covariance matrix given by

                                    ( (,  ))-1 = -1 +  -2 T .                                        (7)

Due to the structure of the agents' optimal signals, this matrix is independent of the realized
state and signal realizations, but depends on the agent's choice of (,  ).
       Following Sims [2003] and H´
                                  ebert and Woodford [2020], under both mutual and Fisher
information, the cost of information acquisition can be written a function of the prior and
posterior variance-covariance matrices  and  (,  ). In either case, the agent chooses
the parameters (,  ) of (5) subject to feasibility.           The feasibility set is given by  
{,  : || = | |,   0}. The first constraint on this set is a normalization. Expression (7) makes
clear that scaling both  and  by the same constant does not change the posterior variance.
To simplify notation, for our analysis of non-fundamental volatility we adopt the convention
that || = | |. The second constraint that   0 is called a "no-forgetting" constraint by
Van Nieuwerburgh and Veldkamp [2010], and reflects the fact that the agent cannot reduce
information costs by forgetting information.
       Before continuing, we should note that with both of these cost functions, it is possible that
no optimum over (,  ) exists, and the optimal policy is to receive a completely uninformative
signal (  ). This leads to an equilibrium in which all agents choose an action equal to their
prior mean about s. In our results, we will assume that information costs are sufficiently small
to rule out this possibility. We next characterize what kind of information the agents choose to
gather.
       Consider first the mutual information case.5

Example 1. With mutual information, the problem of the agent is

                      min  T  (,  ) +  ln(det(( (,  ))-1 )) - ln(det(-1 ))                           (8)
                     (, )


subject to (7), with  > 0. Substituting in (7), this simplifies to

                                              ( T )2
                         min  T  -  -2                 +  ln(1 +  -2 T ).                            (9)
                        (, )                1 +  -2 T 

       The first component of the agent's objective function is her unconditional expected payoff.
The second component is the agent's cost of information acquisition under mutual information.
   4
     The unconditional expected payoff is - T  (,  ) plus a constant. However, the constant term is
unaffected by the individual agent's choices. We ignore it when considering the agent's optimal choice of
(,  ), but must account for this constant when considering efficiency.
   5
     See the proof of Proposition 1 for a more detailed derivation.



                                                   9
This is given by the difference in the log-determinant of the (inverse) posterior and prior
variance-covariance matrices. The parameter  > 0 scales the cost of information.6
       We contrast this problem to the case with the Fisher information cost function.

Example 2. With Fisher information, the problem of the agent is

                           min  T  (,  ) +  tr(( (,  ))-1 ) - tr(-1 ) ,                                 (10)
                          (, )


subject to (7), where tr(·) is the trace operator, with  > 0. Substituting in (7), this simplifies to

                                                     ( T )2
                               min  T  -  -2                  +  -2 ||2 .                               (11)
                              (, )                 1 +  -2 T 

       The first component is again the agent's unconditional expected payoff.                 The second
component is her cost of information acquisition under Fisher information. This given by the
difference in the trace of the (inverse) posterior and prior variance-covariance matrices.
       Therefore, the only difference between the mutual information and Fisher information cases
is the functional form of information cost: the trace vs. the log-determinant. It is this difference
that leads to distinct predictions for the agent's optimal choice of signal structure.
                                                                              ~i   x denote the
       To understand the agent's optimal signal structure in either case, let a
agent's optimal action under complete information for a given  . This is the action the agent
would choose if she herself faced no cost of information acquisition.
       Under mutual information, the agent optimally receives a one-dimensional signal that
                                                          ~i .7 That is, the agent chooses
directly corresponds to her optimal complete info action, a

                                                   = ,

                                                            ~i .
and as a result her signal is an unbiased, noisy version of a
       In contrast, under Fisher information, the agent optimally receives a one-dimensional signal
                             ~i under the resulting posterior.8 That is, the agent's optimal
that maximally covaries with a
choice of  satisfies the fixed point:

                                     argmax:||=||  T  ( ,   ).                                          (12)

                                                                                                     ~i
       Both results are intuitive. It certainly seems logical to learn only about the optimal action a
and ignore everything else. On the other hand, it also seems perfectly natural to receive a signal
                             ~i .
that maximally covaries with a
   6
      Agents will find it optimal to gather some information if their uncertainty about the optimal action is
sufficiently large relative to the parameter . See the proofs of Propositions 1 and 2 for precise conditions.
    7
      This follows from the invariance properties of mutual information, but can also be shown using the
first-order condition from (9).
    8
      See H´ebert and Woodford [2020]. This can also be shown using the first-order condition from (11).

                                                     10
    In either case, the agent's optimal action is linear in her signal by (6), and her signal is linear
in the underlying state (5). Together, and aggregating across individuals, this implies that the
aggregate action is indeed linear in the state:

                                            ¯ =  ( )T x,
                                            a                                                     (13)

thereby verifying our guess in (3). Finally, in order for (13) to coincide with (3), the equilibrium
vector (¯s, ¯ r )T must satisfy
                                          (¯
                                           s , ¯ r )T =     ,                                     (14)

and is therefore proportional to the agent's optimal choice of  . That is, a linear equilibrium of
this game is a collection of parameters (¯r , ¯ s , , , , ) satisfying (4), (6), and (14), with (,  )
chosen optimally given  . This leads to the following result.

Proposition 1. (i) Under mutual information, there exists a linear equilibrium. Any such
equilibrium features zero non-fundamental volatility: ¯ r = 0.
    (ii) With the Fisher information cost, there exists a linear equilibrium. If r and s are correlated
under the prior and  is sufficiently small, any such equilibrium features non-fundamental
volatility, ¯ r = 0.

Proof. See the appendix, 11.1.

    Because agents choose different types of signal structures across the two cases, this leads to
distinct equilibrium properties. In the case of mutual information, the agent's optimal signal is
                                                         ~i , but ignores everything else. If all
one that directly tracks her complete-information action a
agents choose  =  , in equilibrium  must satisfy the fixed point:

                                        = (1 -  )e1 +  .

where e1 = (1, 0)T and  is a scalar function strictly less than one by equation (6). It
immediately follows that in any equilibrium, the second element of  must be zero; hence,
¯ r = 0. Therefore, with mutual information, the equilibrium aggregate action does not depend

on the payoff-irrelevant state r.
    In the case of Fisher information, the agent chooses a signal to maximize the covariance
between the signal  i and optimal action  T x. If s and r are correlated (if the off-diagonal
elements of  are non-zero), then this immediately rules out equilibria with zero non-
fundamental volatility. To see this, suppose by contradiction there exists an equilibrium in
which ¯ r = 0, so that the second element of  is zero. In this case, as long as s and r are
correlated, the agent chooses a signal such that the second element of  is non-zero: this choice
maximizes the covariance between her signal and her complete-information action (see (12)).
But if the second element of  is non-zero, then by (14), ¯ r must be non-zero, a contradiction.

                                                  11
We conclude that all linear equilibria in the case of Fisher information generically feature non-
fundamental volatility. The only cases in which ¯ r may be zero in equilibrium are the non-
generic cases in which s and r have zero correlation, or when no information is gathered in
equilibrium.
   Mutual information and Fisher information therefore generate starkly different predictions
for the existence of non-fundamental volatility in equilibrium in the simple beauty-contest
game. The distinction stems from what these costs imply for agents' optimal signal structures.
In the mutual information case, agents track their optimal action directly, but ignore everything
else--it would be costly to do otherwise. When all agents behave in this way, in equilibrium
there is no room for the payoff-irrelevant state r to affect equilibrium actions.
   In contrast, in the Fisher information case, agents instead find it optimal to receive a signal
that depends at least somewhat on r, as this maximizes covariance with s. That is, it is cheaper
for agents to learn about s by partially observing r, rather than learn about s directly. This
optimal cost-saving behavior is what opens the door for variation in r to affect individual actions
and thereby, in equilibrium, aggregate actions.
   One possible interpretation of r in this context is a noisy public signal. In exogenous
information environments, agents learn through costless public signals and base their actions
upon them. Common errors in these signals lead to variation in aggregate actions that is
orthogonal to fundamentals. In the Fisher information case, r plays the exact same role:
learning about r is not costless, but it is a "cheaper" way of learning about s than learning about
s alone.


2.2    Constrained Efficiency
Next, we consider the question of constrained efficiency in the beauty contest game. For
simplicity, we abstract from the payoff-irrelevant states r in our previous example and assume
s  R is the only exogenous aggregate state.
   To discuss efficiency in the context of our beauty contest game, we proceed in three steps.
The first step is to ask whether the game is constrained efficient under exogenous information,
that is, when agents cannot choose their information structure. The second step is to ask
whether the game is constrained efficient under endogenous information when agents may
acquire information about the exogenous aggregate state s. The third step is to ask whether
the game is constrained efficient under endogenous information when agents can learn not
only about the exogenous aggregate state s but also about the endogenous aggregate action a
                                                                                          ¯.


Step 1. We begin by asking first whether the equilibrium is constrained efficient under
exogenous information. Agents receive noisy signals  i  N (s,  2 ) about s  R.



                                                12
   Consider an equilibrium in which the aggregate action is a linear function of the state, a
                                                                                            ¯=
¯ s s. The agent chooses a strategy ai ( i ) in order to maximize her expected payoffs,


                                V (, ¯ s ) = max E[u(ai ( ), ¯ s s, s)| i ]                       (15)
                                             ai ( i )

The agent's first-order condition to this problem is what gives rise to the linear private best
response function reported in (2). A symmetric equilibrium, then, is an individual strategy a( )
(the same for all agents) and an aggregate action coefficient ¯ s , such that optimality conditions
(2) hold along with, by the law of large numbers,

                                     ¯ s s = E[a ( ) |s]
                                                                   s  R                           (16)

   Can a planner who controls how each agent responds to her own signal, but is unable to
share information across agents, improve welfare relative to the non-cooperative equilibrium?
To answer this question, we follow Angeletos and Pavan [2007] and solve a constrained planner's
problem. The constrained planner chooses strategies a( ) in order to maximize expected utility
across all agents,
                                W ( ) = max             E [u(a( ), ¯ s s, s)] di                  (17)
                                           a( )    i

subject to the constraint that the aggregate action ¯ s s satisfies (16). Taking first-order conditions
with the linear-quadratic payoffs of (1), we find that the efficient "best response" function
dictated by the planner is given by

                                    a( ) = E[(1 -  )s +  ¯ s s| ],

and thereby coincides exactly with the agent's private best response function in (2).
   We conclude that in this particular game, by construction, the equilibrium use of
information is efficient. See Angeletos and Pavan [2007] and Section 7 of this paper for a detailed
discussion of the intuition behind this result.


Step 2. We now ask whether the equilibrium is constrained efficient under endogenous
information acquisition. We begin by allowing agents to choose the standard deviation of their
signals,  , subject to a cost. Let C ( i ) be the cost of receiving a signal with standard deviation
 i . This cost could be based on mutual information, the Fisher information cost, or any other
cost--the details will not matter for our argument.
   Consider the individual agent's problem. Each agent takes ¯ s as exogenous, and chooses
both an action strategy i and a standard deviation  i . Fixing the agent's choice of  i , her choice
of i is exactly as in (15). The agent therefore chooses  i to maximize her private value minus
her information cost,
                                   i  argmax0 V (, ¯ s ) - C ( ).

                                                        13
   Can a planner who controls both how much information an agent acquires and how each
agent responds to her own signal improve welfare relative to the non-cooperative equilibrium?
Consider a planner that chooses a pair ( ,   ) to maximize expected utility across all agents,
less their information cost.
   Again, fix the planner's choice of   and observe that the problem of choosing  is exactly
the planner's problem with exogenous information, (17). The planner therefore chooses   to
maximize the social value minus the information cost,

                                    argmax0 W ( ) - C ( ).

   It follows almost immediately that the planner's optimal ( ,   ) is also an equilibrium.
To see this, again fix  and consider the inner problem of both the agent and the planner.
We know that the planner's optimal choice of  coincides with the equilibrium  in this " -
subgame." This in fact is true for any  -subgame, and is simply a restatement of the result that
the equilibrium use of information is efficient. It follows that for any  , the social value of 
forms an upper envelope of the private value:

                                     W ( ) = max V (, ¯ s ).                                (18)
                                                ¯s

That is, even if we were to ignore the mean-consistency requirement (16), the ¯ s that maximizes
the private value is the same ¯ s that solves the planner's problem and thereby satisfies mean
consistency.
   But observe from this equation that the planner's optimal choice of   coincides with
the agent's best response to    arg max V (  , 
                             ¯s                ¯ s ); therefore the solution to the planner's
                                       ¯s
problem is an equilibrium. We conclude that in this particular game, efficiency in the use of
information implies efficiency in the acquisition of information when agents receive signals
only about exogenous states. Note that this result relies on the fact that only the mean action,
and not higher moments of the action distribution, enters the agents' payoffs in (1); see
Colombo, Femminis, and Pavan [2014] for details.


Step 3. We now allow agents to learn not only about the exogenous fundamental s but also
about the endogenous aggregate action of other agents, a
                                                       ¯, as in Denti [2019].
                                                                                ¯)T denote
   To mirror our previous discussion of non-fundamental volatility, let x = (s, a
the vector of objects the agents can learn about. To preserve the linear-quadratic-Gaussian
                                                       2 ) and consider linear equilibria of
structure of the model, we continue to assume s  N (0, 0
the form a
         ¯ = ¯ s s. With either mutual or Fisher information, it remains the case that agents
optimally receive a one-dimensional Gaussian signal  i of the form given by (5).
   Unlike the previous step, agents may now learn about the aggregate action a
                                                                             ¯. Consequently,
as in our analysis of non-fundamental volatility, agents have choices about both the noise in

                                                14
their signal ( ) and what they learn about (). In this case, because the aggregate action a
                                                                                          ¯ is part
of the state vector x, the payoff-relevant dimension of the state is exogenous,  = (1 - ,  )T .
Note also that x = s, where we define  = (1, ¯ s )T . As a result, x is Gaussian, x  N (0, ) with
                                             2 T .
the degenerate variance-covariance matrix  = 0
       Let us now fix the agent's choice of  , and consider the optimal choice of  under
both mutual information and the Fisher information cost. For this analysis, we adopt the
normalization that T  = 1, and consider the optimal choice of  in (8) and (10) from the
previous section (because these formulas are valid even with a degenerate prior). With this
normalization, the information cost depends on the choice of , but the expected payoff
component of these two equations does not.
       With mutual information, as discussed in the previous section, an optimal choice of  is
proportional to the payoff-relevant dimension of the state space. With our normalization,
this is  = ( T )-1  . In contrast, with the Fisher information cost, we can see from the
first-order condition of (10) that  = (T )-1 . Again, with mutual information, the agent
receives a signal directly about the payoff-relevant dimension of the state, whereas with the
Fisher information cost the agent maximizes covariance with the payoff-relevant dimension of
the state.
       Plugging in these choices for  back into (8) and (10) , we see that the cost functions in
terms of  can be written in the mutual information case as


                                        C ( ) =  ln(1 +  -2 0
                                                            2
                                                              ),

and in the Fisher information case as
                                                         -2
                                          C (, ¯s) =       2
                                                             .                                       (19)
                                                        1+¯s

Let us now consider a planner who can choose ( ,   ) as in step 2 of our analysis.9 The following
result is then immediate.

Proposition 2. (i) With mutual information, an optimum of the planner ( ,   ) is also an
equilibrium. (ii) With the Fisher information cost, an equilibrium exists, but if  is sufficiently
small any optimum of the planner ( ,   ) is not an equilibrium.

Proof. See the appendix, 11.2.

       The result for mutual information follows directly from our analysis in step 2 and Colombo,
Femminis, and Pavan [2014]. As long as agents use their information efficiently in any  -
subgame, then the private value of information is the same as the social value. As a result, agents
behave exactly as the planner would dictate.
   9
    That is, we do not allow the planner to choose  . This is for expositional clarity and does not affect
our results.

                                                   15
       This is not the case with the Fisher information cost. In (19), the agent's cost of information
acquisition depends on the strategies of others, and in particular it is decreasing in ¯ s . Thus,
if agents make their actions more sensitive to their signals, this increases the sensitivity of
the aggregate action to the aggregate state, which in turn decreases the cost of information
acquisition for all agents.       Agents do not internalize this effect when making their own
individually-optimal decisions. The planner on the other hand takes this externality into
account when maximizing welfare, and as a result, dictates a higher  and lower   relative
to the non-cooperative equilibrium. Note that this externality exists only when agents gather
information in equilibrium, hence our assumption that  is sufficiently small.
       The aforementioned externality does not exist when agents can only gather information
about exogenous states (step 2). Why does it arise here? Agents in this economy learn from both
the fundamental state and the aggregate action. With the Fisher information cost, it is cheaper
for agents to observe the aggregate action when it is highly sensitive to the aggregate state, that
is, when ¯ s is larger. Fisher information thereby incorporates a scale effect into costs: when
aggregate actions are more extreme, they become more salient in the eyes of other agents, and
thereby less costly to observe. It is this scale effect on costs that the agents do not internalize.
Mutual information, on the other hand, is invariant to these scale effects, and as a result this
externality is absent.10


2.3       Summary and Layout
We have shown that these two information cost structures have significantly different
equilibrium implications in this simple linear-quadratic beauty contest game. Under mutual
information, the equilibrium features zero non-fundamental volatility and is constrained
efficient. With the Fisher information cost, the equilibrium exhibits non-fundamental volatility
and is constrained inefficient. But what is it about these two cost functions that leads to such
divergent predictions? We formally address this question in the general framework that follows.
       The remainder of this paper is organized as follows. In Section 3 we define the general class
of large games that we study. In Section 4 we define equilibria and prove its existence. In Section
5 we introduce and define certain properties of cost functions that we call partial monotonicity
and partial invariance. In Section 6 we characterize under what conditions equilibria do or do
not feature non-fundamental volatility. In Section 7 we define equilibria and efficiency under
exogenous information and characterize under what conditions there is efficiency in the use
of information. In Section 8 we show what needed in addition to efficiency in use to obtain
efficiency with endogenous acquisition of information. In Section 9 we conclude. All proofs are
  10
    Angeletos and Sastry [2019] construct a related example in which the variance of prices enters
information costs, and show that this leads in their Walrasian setting to multiple, Pareto-ranked
equilibria.



                                                   16
provided in the Appendix.


3          The General Game
We study large games of strategic interaction. These games generalize our simple example in
several respects. First, agents' action spaces can be multi-dimensional, payoff functions are not
necessarily quadratic, and the aggregate action is not necessarily linear in the state variables.
Second, we do not restrict ourselves to Gaussian structures: agents can have arbitrary priors.
Third, we study a large class of information cost functions which includes mutual information
and Fisher information but also includes many others. Fourth, we allow for learning about both
payoff-irrelevant states and endogenous actions, rather than consider these things separately
as in our simple examples. In all of these respects, our general environment nests the example
of the previous section; however, to avoid certain technical complications and simplify our
exposition, we assume that the exogenous state space is finite.


3.1         Agents, Actions, and Payoffs
There is a unit mass continuum of agents, indexed by i  [0, 1]. Agent i chooses her action,
ai  A  RL . Let a¯A   ¯  RL be the vector of aggregate actions, defined as the average action
chosen by agents:
                                                          1
                                                 a
                                                 ¯=           ai di.
                                                      0
   There is a finite set of exogenous payoff-relevant states, s  S . These states, along with
                                                                                        ¯×S 
                  ¯, determine the agent's payoffs. Agents have payoff function u : A × A
aggregate actions a
R; that is, an agent who takes action ai  A in state s  S when the aggregate action is a ¯
                                                                                       ¯ A
receives payoff u(ai , a
                       ¯, s). Note that individual agents--each of whom is infinitesimal--do not
take into account how their own action affects the aggregate action when making their own
strategic choices. This assumption is a defining feature of "large games."
         We impose the following regularity assumption on the payoff functions and action space.

Assumption 1. A is non-empty, convex, and compact, and u(ai , a
                                                              ¯, s) is continuously
                      ¯ for all s  S .
differentiable on A × A

         Assumption 1 will be sufficient, but not necessary, for our results.11 In particular, our results
could readily be extended to games with finitely many actions.
         The last primitives of our environment are the agents' information acquisition technologies,
which we describe next.
    11
    Note that Assumption 1 guarantees the existence of mixed strategy Nash equilibria under complete
information in games with continuous actions spaces. See, e.g., Fudenberg and Tirole [1991] theorem 1.2.


                                                      17
3.2       Shocks and Information Acquisition
Shocks and Priors. In addition to the payoff-relevant, or "fundamental," states, s  S , we
allow for a finite set of payoff-irrelevant states, r  R.
       Agents are endowed with a common prior µ0 (s, r) over the exogenous states. Let U0 
 (S × R) denote the space of probability measures over the exogenous states, with µ0  U0 .
Note that the payoff-irrelevant states can be independent of the fundamental states, in which
case they can be interpreted as pure noise, or correlated, in which case they case they can
be interpreted as noisy signals about fundamentals. These states are payoff-irrelevant by
definition, but are a potential source of non-fundamental volatility in equilibrium.
    We define  ¯ : S ×R  A  ¯ as a function mapping exogenous states to an aggregate action. Let
¯ be the space of all such functions.12 One may think of 
A                                                         ¯ as the "aggregate strategy," as this
                                                         ¯A
function will be determined endogenously by aggregating over the individual agents' strategies.
       We will allow agents to learn not only about the exogenous states, but also about
endogenous aggregate actions. Agents will optimally choose which objects to pay attention
                                                                                       ¯ space. Let
to; in order to facilitate this choice, we specify their prior over the larger S × R × A
¯  S×R×A
U      ¯ denote the space of probability measures over this space.
    We construct the agents' prior on this larger space from their prior on the exogenous states
µ0 and the aggregate strategy                             ¯U
                              ¯ as follows. Let  ¯ : U0 × A   ¯ denote a mapping from any pair
                                                   A
µ0 , ¯ to its induced probability measure, defined as

                  ¯ {µ0 , 
                  A       ¯ } (s, r, a                a-
                                     ¯) = µ0 (s, r)  (¯ ¯ (s, r)) , s  S, r  R, a
                                                                                ¯  A,
                                                                                   ¯             (20)

where  (·) is the Dirac delta function. We define the space of all probability measures that may
be generated on S × R × A  ¯ by some pair (µ0 ,         ¯, as
                                                ¯ ), U  U

                       ¯:
                  U = µU            µ0  U0    and  ¯ s.t. µ =  ¯ {µ0 , 
                                                  ¯A                   ¯} .
                                                              A


Given a prior µ0  U0 and an aggregate action function   ¯, the induced prior on the larger
                                                      ¯ A
                           ¯ {µ0 , 
space µ  U is given by µ = A       ¯ }.


Agents' strategies. We now consider the strategies of the agents. In games of imperfect
information with exogenous signals, an individual agent chooses her own action based on the
realization of her own signal  i  , where  is a signal alphabet. We assume  has a cardinality
weakly greater than RL (and hence the action space). In these games, an individual agent's pure
strategy is a mapping from signals to actions, i :   A. Let A be the space of all possible pure
strategies.
  12
    We are restricting the aggregate action to be a deterministic function of (s, r). However, r could
include elements that are independent of the rest of (s, r) and can be regarded as sunspots.


                                                  18
       In games with endogenous information acquisition, agents also choose their signal
structure. A signal structure is a conditional probability distribution function

                                                   ¯   () .
                                       i : S × R × A

where  () is the space of probability measures on . That is,  i ( |s, r, a
                                                                         ¯) denotes agent i's
                                                         ¯). Let V  be the space of all such
probability of observing signal    conditional on (s, r, a
functions; the superscript indicates the signal alphabet. In what follows, it will also be useful to
                                                                                  V  as the
consider signal structures that depend only on the exogenous states. We define V0
set of signal structures whose conditional probabilities depend only on the exogenous states.
That is,
                   
                  V0 = {  V  :  i ( |s, r, a
                                           ¯) =  i ( |s, r, a
                                                            ¯ ) s  S, r  R, a  ¯ A
                                                                            ¯, a ¯}.

       Note that our setup allows agents to learn about the mean (or aggregate) action, but
precludes agents from learning about any other particular agent's action.13 To summarize,
with endogenous information acquisition, an individual agent chooses both an action strategy
i  A and a signal structure  i  V  in order to maximize his or her payoffs subject to a cost
of information acquisition.14 We discuss these costs after introducing some notation for signal
probabilities and posteriors.


Posterior distributions. Take any signal structure   V  and prior µ  U ; together these
                                       ¯ × . The marginal distribution on  associated with
induce a joint distribution on S × R × A
this joint distribution is the agent's unconditional probability of observing signal   ,


                             {, µ} ( ) =                ( |s, r, a
                                                                 ¯) µ (s, r, a
                                                                             ¯) da
                                                                                 ¯,                  (21)
                                                 ¯
                                           sS,rR A

with  {, µ}   ().
                                                                       ¯ space. The agent's posterior
       The joint distribution also induces posteriors over the S × R × A
            ¯) conditional on observing any signal   , is given by
over (s, r, a

                                                       ( |s, r, a
                                                                ¯) µ (s, r, a
                                                                            ¯)
                                µ {, µ} (s, r, a
                                               ¯) =                            ,                     (22)
                                                           {, µ} ( )

consistent with Bayes' rule and assuming  {, µ} ( ) > 0. Note that, if µ  U (meaning that a
                                                                                          ¯ is
deterministic conditional on (s, r) under µ), then µ {, µ}  U for all   V  ,   . We adopt
the convention that, for zero probability signals, posteriors are equal to priors.
       We use these objects to define "uninformative" and "informative" signal structures.
  13
    This choice, made for tractability, is motivated by the "largeness" feature of the game.
  14
    By standard arguments in the rational inattention literature, it will be without loss of generality to
identify signals with actions, and hence to assume pure as opposed to mixed action strategies.



                                                      19
Definition 1. A signal structure  is uninformative if for all    such that  {, µ} ( ) > 0,
µ {, µ} = µ. A signal structure is informative if it is not uninformative, that is, if there exists an
 such that  {, µ} ( ) > 0 and µ {, µ} = µ.

       Thus, informative signal structures are those that move posteriors away from the prior.
Armed with these definitions, we next describe the cost of information.


Cost of information acquisition. Agents face a cost of acquiring informative signal
structures.     We generalize the standard rational inattention setup and define the cost of
information acquisition by a function

                                           C  : V  × U  R+ .

That is, given a prior µ, an agent i which chooses signal structure  i  V  incurs information
costs C  ( i , µ), where the superscript  indicates the signal alphabet over which the agent
chooses its signal structure.
       It is without loss of generality to impose the following assumptions on the cost function.

Assumption 2. For all µ  U ,

   1. The cost function C  (, µ) is zero if the signal structure  is uninformative.

   2. Take   V  and   V  for two signal alphabets  and  . If  Blackwell-dominates  in
         the sense of Blackwell [1953], then C  (, µ)  C  ( , µ).

   3. The cost function C  (, µ) is convex in  .

       As discussed by Caplin and Dean [2015], and invoking Lemma 1 of H´
                                                                        ebert and Woodford
[2019],15 these assumptions are without loss of generality. That is, any behavior that could be
observed for a rationally inattentive agent with a cost function not satisfying the second and
third conditions could also be observed for a rationally inattentive agent with a cost function
satisfying those conditions, and the first condition is a normalization. The intuition for this
result comes from the possibility of the agent pursuing mixed strategies over actions conditional
on a signal realization and over choices of signal structures.
       Our next assumption requires that the information costs we study are continuous. This
assumption is phrased in a somewhat technical fashion in order to account for the possibility
                                                                                   ¯  RL that A
that the signal space  is not a finite set. Observe by the finiteness of S × R and A          ¯
can be viewed as a subset of RL×|S |×|R| and endowed with the standard (Euclidean) topology.
  15
    Lemma 1 of H´   ebert and Woodford [2019] allows us to replace the Caplin and Dean [2015] "mixture
feasibility" condition with convexity. H´
                                        ebert and Woodford [2019] prove it in the context of a finite signal
alphabet, but nothing in the proof depends on the alphabet being finite.


                                                    20
Assumption 3. Under the topology of weak convergence on V  and U , the cost function C  is
continuous in the product topology of V  × U .

       Assumption 2 by itself implies continuity in  (due to convexity), holding fixed µ. What
Assumption 3 adds is the requirement of continuity in (, µ).16


Posterior-Separability. Finally, we restrict attention to information costs that are
"posterior-separable," in the terminology of Caplin, Dean, and Leahy [2019].                        Posterior-
separable cost functions can be written as the expected value of a divergence between the
agents' posterior and prior beliefs. A divergence is a measure of how "close" or "far" two
distributions are from one another.17 To capture the idea that the action of other agents might
influence the cost of information, we define these divergences on the larger space of probability
measures, U .
       Take any signal structure   V  and prior µ  U . A posterior-separable cost function is a
cost function that can be written as

                              C  (, µ) =         {, µ} ( ) D(µ {, µ}||µ)d,                                 (23)
                                             

where D : U × U  R+ is a divergence from the agents' prior µ to posterior µ , convex in its first
argument and continuous on U × U .18

Assumption 4. The cost function C  is posterior-separable as defined by equation (23), with a
divergence D that is continuously differentiable in both arguments.

       Mutual information, the standard rational inattention cost function, is posterior separable.
The associated divergence is the Kullback-Leibler divergence, defined in our context as

                                                                         µ (s, r, a
                                                                                  ¯)
                           DKL (µ ||µ) =               µ (s, r, a
                                                                ¯) ln(               )da
                                                                                       ¯.                  (24)
                                                 ¯                       µ(s, r, a
                                                                                 ¯)
                                           sS,rR A

Other posterior-separable cost functions include the Tsallis entropy cost function proposed
by Caplin et al. [2019], versions of the LLR cost function proposed by Pomatto et al. [2018],
  16
      Note that continuity in (, µ) implies continuity in (,  ¯ ) holding fixed µ0 .
  17
      A divergence is a function of two probability measures that is weakly positive and zero if and only if
the measures are identical. Unlike a distance, a divergence does not need to be symmetric, nor does not
necessarily satisfy the triangle inequality.
   18
      Convexity in the first argument is implied by Assumption 2 and continuity (under the weak topology)
by Assumption 3. Also note that we have defined the divergence D on U rather than the entire space
U¯ = (S × R × A  ¯); all priors and posteriors in our problem will remain in U , and therefore it is unnecessary
to define the divergence on the entire space. By the finiteness of S, R and the definition of U , elements
of U can be represented as a subset of R|S |×|R|×(L+1) , and as a result differentiability for D can be defined
in the usual way. Finally, observe that, under the assumption of posterior-separability, the cost function
depends on the signal alphabet only through the domain of integration.


                                                      21
and the neighborhood-based cost functions proposed by H´
                                                       ebert and Woodford [2020]. H´
                                                                                   ebert
and Woodford [2019] show that all differentiable information cost functions can be locally
approximated by a differentiable posterior-separable cost function.
    Hereinafter, we impose Assumption 1 on action spaces and payoffs and Assumptions 2, 3,
and 4 on information costs. Before turning to our definition of equilibrium, we briefly discuss
one implication of these assumptions.
    Recall that the set U is defined by the property that the aggregate action a
                                                                               ¯ is deterministic
conditional on the exogenous states (s, r). The following lemma demonstrates that, as a result,
for any signal structure   V  , there is another signal structure that does not condition on
       , that generates the same signal probabilities and posteriors, and consequently (by
¯,   V0
a
Assumption 4) the same information cost.

Lemma 1. Given any   V  and µ  U , there is signal structure   V0
                                                                 such that  {, µ} =

 { , µ} and, for all   , µ {, µ} = µ { , µ}.

Proof. See the appendix, 11.3.

    The intuition for this result is the following: zero-probability (s, r, a
                                                                            ¯) events have no
impact on either unconditional signal probabilities or posteriors, and therefore do not change
information costs. Because these two signal structures result in identical posteriors, we will see
that the resulting distribution of actions in our game are also identical, and therefore from an
individual agent's perspective the two signal structures are equivalent.
    Why, then, do we consider the possibility that agents acquire information about the
endogenous actions of the others? The answer is that, despite the fact that it is without loss
                                                             , the information cost of this signal
of generality for an agent to choose a signal structure in V0
structure might nevertheless be influenced by the actions of others. To see this, observe that by
(28), the prior µ  U depends the aggregate strategy ¯A   ¯. As a result, the divergence D in (23)
might depend on ¯ even if the signal structure  does not condition on a
                                                                      ¯, because both the prior
and posteriors will be affected by ¯ . This channel--aggregate actions affecting information
costs--is exactly the one illustrated by our beauty contest example with Fisher information. We
will eventually show that this can lead to an externality in our general game.


4    Equilibrium Definition and Existence
We proceed by defining our equilibrium concept and proving equilibrium existence.
    To streamline our exposition, we first invoke the usual result in rational inattention
problems that it is without loss of generality to equate signals with actions. To do so, let  :
   (A) denote a mixed strategy: a mapping from signal realizations    to distributions



                                               22
over actions,  (A). Given any mixed strategy  :    (A) and signal structure    V  , we
                                                                           ¯  (A), as
may define the induced conditional distribution over actions,  A : S × R × A

                                   A (a|s, r, a
                                              ¯) =       (a| )  ( |s, r, a
                                                                         ¯)d.                          (25)
                                                     

Let V A be the set of all conditional distributions over actions. Rather than write the problem of
the agent as a choice over both  and   , we condense these choices and write the problem of
the agent as a choice over the conditional distribution of actions,  A  V A .
   Each agent is infinitesimal, meaning that the agent treats the joint distribution of payoff-
relevant states, payoff-irrelevant states, and aggregate actions as exogenous. We will look for
symmetric Bayesian Nash equilibria in which all agents play best responses to the equilibrium
action function    ¯, all agents choose the same conditional distribution of actions  A , and
                ¯  A
the equilibrium action function is generated by these conditional distributions.
   We denote a symmetric strategy profile by

                                                     { A , ¯ },

consisting of identical strategies  A  V A for all agents and an aggregate action function  ¯.
                                                                                           ¯A
We furthermore assume that, conditional on (s, r, a
                                                  ¯), the realizations of signals across agents
are independent. That is, it is only the distributions of actions, not the realizations, that are
identical across agents. This independence of realizations allows us to apply the law of large
numbers and require that each agent's average action ai be consistent with the mean action a
                                                                                           ¯ in
the population [Uhlig, 1996]. We impose this as follows.

Definition 2. A symmetric strategy profile  is mean-consistent if it satisfies

                    ai  A (ai |s, r, ¯ (s, r))dai = ¯ (s, r)   s  S, r  R, s.t. µ0 (s, r) > 0.         (26)
                A
   By assuming that signal realizations are independent across agents, we are not ruling out
correlation in equilibrium actions. Instead, we are simply imposing that the only channel by
which agents may correlate is through their choice of how their actions condition on (s, r, a
                                                                                            ¯). In
particular, the exogenous state r allows agents to coordinate their actions on public signals or
sunspots.
   We define an equilibrium in our game as follows.

Definition 3. Given a common prior µ0  U0 , a symmetric Bayesian Nash equilibrium (BNE)
of the game is a mean-consistent strategy profile  such that agents' strategies  A  V A are best
responses

     A  argsup V A                           u ai , a
                                                    ¯, s  ai |s, r, a
                                                                    ¯ dai µ (s, r, a   ¯ - CA  , µ ,
                                                                                   ¯) da               (27)
                               ¯
                         sS,rR A         A

where
                                                     ¯ {µ0 , 
                                                 µ = A       ¯ }.                                      (28)

                                                        23
    Our equilibrium concept is based on Denti [2019]. Equilibrium Definition 3 is a hybrid of
a Bayesian Nash equilibrium and a Rational Expectations equilibrium. It is a Bayesian Nash
equilibrium in the sense that all agents play best responses given their beliefs, which we assume
to be formed according to Bayes' rule. It is a Rational Expectations equilibrium [Grossman,
1976, Grossman and Stiglitz, 1980, 1976] in the sense that agents' may learn from endogenous
aggregate variables while simultaneously choosing their own actions; thus beliefs are functions
of endogenous actions while actions are functions of endogenous beliefs. Consistency of beliefs
and actions is imposed by mean-consistency of strategy profiles (Definition 2) along with (28),
which is the usual requirement that agents best-respond to the equilibrium strategies of other
agents.
    Our first result is that such an equilibrium exists.

Proposition 3. A symmetric BNE of the game exists.

Proof. See the appendix, 11.4.

    The proof of this result uses Kakutani's fixed point theorem in the usual way, relying on the
finiteness of S × R, the continuity of the utility function, and the convexity and continuity of the
information cost function.
    Having now established that our equilibria exist, we begin to study these equilibria. We
first investigate under what circumstances equilibria do or do not exhibit "non-fundamental"
volatility; we then study the circumstances under which equilibria are constrained efficient,
defining constrained efficiency as coinciding with the solution to a particular planner's problem
(which we will define subsequently).
    For both of these results, the focus of our investigation will be the relationship between
properties of the information cost function, in particular its associated divergence D, and the
properties of the equilibrium. We therefore begin by defining the properties of information
costs that will be the focus of our analysis.


5     Partial Monotonicity and Partial Invariance
In this section we define two concepts, "partial monotonicity" and "partial invariance," as
properties of divergences.      Mutual information exhibits both of these properties; Fisher
information exhibits neither property.          We will later show how these two properties of
divergences are related to properties of the equilibria.


5.1    Coarsening and Embedding
We begin by introducing two types of operators, coarsenings and embeddings, which we define
with respect to different partitions of the state space. Coarsenings and embeddings are ways

                                                  24
of moving back and forth between joint and marginal distributions. Specifically, coarsenings
take joint distributions and transform them into marginal distributions, while embeddings
transform a marginal into a joint by adding a conditional distribution.
                                                                                      ¯)
   Consider first a "coarsening" that removes information about r  R. We let UR  (S × A
denote the space of probability measures on (S × A    ¯) and µR  UR denote a particular
distribution on this space. The subscript R indicates the dimension (of the larger space) that
is missing, a convention we follow below. We define a coarsening function R : U  UR by

                            R {µ} (s, a
                                      ¯) =                    ¯) ,
                                                     µ (s, r, a      s  S, a  ¯
                                                                           ¯  A.                       (29)
                                                rR

This operator takes a probability distribution µ  U on the larger space (S × R × A    ¯) and projects
                                     ¯). As indicated by its subscript, this coarsening "throws out"
it onto the smaller state space (S × A
all information about r  R, conditional on (s, a
                                               ¯).
  Consider now the opposite transformation, an "embedding," that adds information about
r  R. Letting ^R (r|s, a
                       ¯) denote a conditional distribution for r  R, conditional on (s, a
                                                                                         ¯),
we define an embedding function R : UR  U associated with the conditional distribution
function ^R : S × A
                  ¯   (R) by,

                   R {µR } (s, r, a
                                  ¯) = ^R (r|s, a            ¯) ,
                                                ¯) µR (s, r, a        s  S, r  R, a  ¯
                                                                                  ¯  A.                (30)

This operator takes a probability measure on the smaller space (S × A  ¯) and embeds it into the
larger space (S × R × A¯) using the information contained in ^R . It thereby "adds" information
                               ¯).19
about r  R, conditional on (s, a
       Any embedding R is associated with a particular conditional distribution ^R , and in turn
any conditional distribution function defines a particular embedding. Thus, while there is only
one way to coarsen from U to UR , there are many possible ways to embed from UR to U . Let R
denote the set of all possible embeddings from UR to U .


5.2       Monotonicity and Invariance in R
Armed with these definitions of coarsenings and embeddings with respect to R, we are now able
to define our concepts of partial monotonicity and partial invariance with respect to R.
       Consider a composition of the coarsening operator R and a specific embedding R  R .
Let R : U × U  U denote the operation that coarsens its first argument in R, then embeds
using the conditional distribution defined by its second argument. We define this compositional
operator as follows:
                                            µ2 (s,r,a
                                                    ¯)
                 R {µ1 , µ2 } (s, r, a
                                     ¯) =             ¯) R {µ1 } (s, a
                                            R {µ2 }(s,a              ¯)   if R {µ2 } (s, a
                                                                                         ¯) > 0
                                                                                                       (31)
                                            0                             if R {µ2 } (s, a
                                                                                         ¯) = 0.
  19
   To ensure that the resulting distribution on (S × R × A    ¯) remains in U , we require that for all s  S
and a
    ¯, a  ¯                  ^       ¯) and R (·|s, a
       ¯  A, the supports of R (·|s, a      ^       ¯ ) do not intersect.

                                                         25
To apply this operation, we require that R {µ1 } be absolutely continuous with respect to R {µ2 },
which we denote by R {µ1 }       R {µ2 }.
   This compositional operator first takes the probability measure µ1  U on the larger space
and projects it onto the smaller state space (S × A ¯) by coarsening it in R. It then takes
the resulting distribution and embeds it back into the larger space using not the conditional
distribution defined by µ1  U , but instead the conditional distribution defined by µ2  U . That
is, it essentially replaces the conditional distributions of µ1 (of r  R conditional on s, a
                                                                                           ¯) with
those of µ2 . The end result is a distribution that is arguably "more like" µ2 than µ1 was originally.
Note that by construction, R {µ, µ} = µ for any µ  U .
   With this compositional operator, we define "monotonicity in R" as follows.
Definition 4. A divergence D : U × U  R+ is monotone in R if for all µ, µ  U such that
R {µ }     R {µ},
                                   D(µ ||µ)  D(R {µ , µ}||µ).                                    (32)
   Recall that a divergence is a non-negative function of the prior and the posterior with no
requirements other than being equal to zero if and only if the prior and posterior are the same.
The above property compares the divergence of the prior µ to the posterior µ after replacing the
posterior's conditional distributions of r  R, conditional on (s, a
                                                                  ¯), with the divergence before
this replacement. Monotonicity captures the idea that if we make the posterior more like the
prior in this sense, then this reduces the divergence from the prior to the posterior.
   We next define a different concept, "invariance in R."
Definition 5. A divergence D : U × U  R+ is invariant with respect to R , or invariant in R, if
for all µ, µ , µ  U such that R {µ }        R {µ} and R {µ }     R {µ},

                           D(R {µ , µ}||µ) = D(R {µ , µ }||R {µ, µ }).                           (33)

   The above property compares the divergence of the prior µ to the posterior µ after replacing
both the prior and the posterior's conditional distributions (of r  R conditional on s, a
                                                                                        ¯), which
may originally differ, with an identical conditional distribution from µ . Invariance captures
the idea that if the prior and posterior share a common conditional distribution, the exact
values of this conditional distribution should not matter for the divergence from the prior to
the posterior. This is different than monotonicity, which requires that replacing the posterior's
conditional distributions of r  R with that of the prior reduces their divergence. Invariance
and monotonicity together require the divergence to shrink to the same value for all possible
conditional distributions (i.e. embeddings).


5.3                  ¯
       Invariance in A
We have thus far defined coarsenings, embeddings, monotonicity, and invariance only with
respect to partitions in r  R. However, we can define these concepts with respect to other

                                                  26
dimensions as well, e.g. in s  S or a
                                    ¯A¯. For the purposes of our exercise, we now consider
                                                         ¯  A
coarsenings and embeddings with respect to partitions in a    ¯ and define invariance in A
                                                                                         ¯
along the same lines as our previous definition of invariance in R.
   Consider U0   (S × R), the space of probability measures over the exogenous state space.
                                 ¯ : U  U0 , by
We define a coarsening function, A

                             ¯ {µ} (s, r ) =
                             A                     µ (s, r, a
                                                            ¯) da
                                                                ¯,   s  S, r  R.                  (34)
                                               ¯
                                               A

                                                                                 ¯) and projects
This operator takes a probability distribution µ  U on the larger space (S × R × A
it onto the smaller state space (S × R). As indicated by its subscript, this coarsening "throws
out" all information about a¯A  ¯, conditional on (s, r).
                                                            ¯. We have in fact already
                                                         ¯  A
   Consider now an embedding that adds information about a
                                        ¯ {µ0 , 
defined such an embedding; the function A       ¯ } defined in (20) is an embedding that maps
probability measures µ0  U0 on the smaller (exogenous) state space (S × R) to measures on the
larger one. The associated conditional distribution function for this embedding is given by

                        ^ ¯ (¯                                                 ¯
                         A a|s, r ) =  (¯
                                        a-¯ (s, r)) ,           s  S, r  R, a
                                                                            ¯  A,                 (35)

that is, the degenerate distribution induced by the aggregate action function   ¯ (s, r) . Any
aggregate action function ¯ A  ¯ defines a particular embedding from U0 to U with associated
conditional distribution (35), and the set U is defined by the property that for all µ  U , there
exists a µ0  U0 and ¯A   ¯ such that µ =  ¯ {µ0 ,                                ¯ as defining the
                                                  ¯ }. We can therefore think of A
                                                   A
set of all possible embeddings from U0 to U .
   Armed with these definitions of coarsenings and embeddings with respect to a   ¯A  ¯, we may
                                        ¯, in a manner that is exactly analogous to our defining
now define our concept of invariance in A
of invariance in R (Definition 5). Consider again a composition of the coarsening operation and
a specific embedding,  ¯ : U × U  U , that coarsens its first argument in a ¯A  ¯, then embeds
                         A
using the conditional distribution defined by its second argument. This operator is

                                          µ2 (s,r,a
                                                  ¯)
                                          ¯ {µ2 }(s,a
                                          A             ¯ {µ1 } (s, a
                                                    ¯ ) A           ¯)      ¯ {µ2 } (s, a
                                                                         if A           ¯) > 0
               ¯ {µ1 , µ2 } (s, r, a
               A                   ¯) =                                                           (36)
                                          0                                 ¯ {µ2 } (s, a
                                                                         if A           ¯) = 0,

                                                                               ¯ as follows.
which is the exact analog of (31). With this operator, we define invariance in A

                                                                      ¯, or invariant in A
Definition 6. A divergence D : U × U  R+ is invariant with respect to A                  ¯, if
for all µ, µ , µ  U such that A   
                              ¯ {µ }           ¯ {µ} and A
                                               A         ¯ {µ }          ¯ {µ},
                                                                         A

                                                      
                               ¯ {µ , µ}||µ) = D (A
                             D(A                  ¯ {µ , µ }||A
                                                              ¯ {µ, µ }).                         (37)

  In our game, different aggregate strategies  ¯, ¯  A  ¯ will lead to different priors µ, µ  U .
                                             ¯, we will demonstrate below that these different
However, if the divergence D is invariant in A

                                                        27
priors do not lead to different information costs for signal structures that condition only on
                      , as in Lemma 1). Consequently, with this form of invariance,
exogenous states (  V0
the aggregate action strategy will not matter for agents' information costs, as in the linear-
quadratic-Gaussian example with mutual information.


5.4    Relation to the standard definition of invariance.
This leads to our next point, which is the relationship between the forms of partial monotonicity
and invariance we have defined and the stronger form of invariance discussed in other papers.
The literature has focused on divergences that are simply "invariant," meaning that they are
both monotone and invariant with respect to all possible coarsenings and embeddings between
a larger space and a smaller space.         These invariant divergences have been described in
the information geometry literature (see Chentsov [1982], Amari and Nagaoka [2007]), and
employed in economics by H´
                          ebert [2018] and H´
                                            ebert and Woodford [2019]. Another term
for coarsening is "compression," and invariant divergences have a close connection to the
invariance-under-compression axiom described in Caplin, Dean, and Leahy [2019]. Mutual
information, in particular, is invariant in this stronger sense, and hence is invariant and
monotone in both R and A  ¯. Fisher information, in contrast, is not invariant or monotone in
either of these senses, provided that agents are allowed to learn about endogenous actions.
   Our generalization to partial monotonicity and partial invariance allows us to study
divergences that are invariant to some but not necessarily all partitions of the state space. In
particular our concepts of partial monotonicity and partial invariance are defined with respect
                                                ¯ Our framework thereby allows for divergences
to partitions in certain dimensions, e.g. R and A.
                                                               ¯, and vice-versa.
that may, for example, be invariant in R, but not invariant in A
   For example, consider the divergence defined by

               D (µ ||µ) = 1 DKL (µ ||µ) + 2          (         µ(s, r, a  ¯)DKL (µr ||µr ) ,
                                                                        ¯)da
                                                            ¯
                                                            A
                                                    rR sS

where DKL is the Kullback-Leibler divergence and, for values of r occurring with positive
probability,
                               µ(s, r, a
                                       ¯)                                 µ (s, r, a
                                                                                   ¯)
               µr (s, a
                      ¯) =                      ,     µr (s, a
                                                             ¯) =             
                                                                                           .
                             sS A          ¯)da
                                 ¯ µ(s, r, a  ¯                            ¯ µ (s, r, a
                                                                        sS A             ¯
                                                                                      ¯)da
                                                                          ¯) condition on
Here, µr  UR and µr  UR are the prior and posterior distributions on (S × A
observing r  R.
   When 2 = 0, this divergence is simply the KL divergence. When 2 > 0, there is an extra
penalty for having a distribution conditional on r under µ that deviates from the distribution
conditional on r under the prior µ. In the limit as 2  , the cost to learn about r remains
unchanged, but it becomes impossible to learn anything aside from r. In this limit, every agent

                                                     28
will optimally choose to learn about r and only r even if r is not payoff-relevant (that is, if a
                                                                                                ¯ does
not depend on r), provided that r is in some way correlated with the payoff-relevant variables.
Even away from this limit, it will generally be cheaper for the agent to choose signal structures
that vary in r, even if learning about r is less useful than learning directly about s. One very
straightforward interpretation of this cost function is that r is a public signal, and it is cheaper
for agents to observe this public signal than to observe either the fundamentals or other agents'
actions.
    From this discussion, it is immediately apparent that this divergence is neither invariant nor
monotone in R. However, because of the invariance of the Kullback-Leibler divergence, it is also
straightforward to observe that this divergence is invariant and monotone in A¯. We therefore
conclude from this example that cost functions with one form of partial invariance but not the
other exist and are potentially interesting.
    Armed with these definitions, we next demonstrate that monotonicity in R and invariance
   ¯
in A are critical in determining the equilibrium properties of our game.


6     Non-Fundamental Volatility in Equilibrium
In this section we consider the question of whether the equilibrium depends on the payoff-
irrelevant exogenous state r. We begin by defining a notion of measurability; we will say an
equilibrium is s-measurable if the agents' signal structures  A and the aggregate strategy ¯ do
not depend on r.

Definition 7. An aggregate strategy  ¯ is s-measurable if, for all s  S and r, r  R, 
                                    ¯A                                               ¯ (s, r) =
¯ (s, r ). A symmetric BNE (Definition 3)  = { A , 
                                                   ¯ } is s-measurable if ¯ is s-measurable and if,
for all s  S and r, r  R,  A (ai |s, r, ¯ (s, r)) =  A (ai |s, r , ¯ (s, r )).

    When the aggregate strategy ¯ depends on r, the associated equilibrium exhibits non-
fundamental volatility in the sense that outcomes depend on non-payoff-relevant exogenous
states. When it does not, the associated equilibrium exhibits zero non-fundamental volatility.
By definition, if an equilibrium is s-measurable, it exhibits zero non-fundamental volatility.
However, if an equilibrium is not s-measurable, it could either be that the aggregate strategy
¯ is not s-measurable, or that 
                               ¯ is s-measurable but the signal structure  A conditions on r. In
the first of these situations, the economy exhibits non-fundamental volatility.
    The second situation is non-generic. If  A conditions on r, then by the mean-consistency
condition (Definition 2) we would generically expect that ¯ (s, r) depends on r. The special
case in which this would not occur is if, under  A , r influences the higher moments of the
agents' actions but not the mean action. This case is non-generic, in the sense that by slightly
perturbing the agents' utility function, we can construct a new game with an equilibrium


                                                       29
involving an ¯ function that does depend on r. We discuss this issue in more detail in the
Appendix, Section 10.     In what follows, we will treat the question of whether or not the
equilibrium is s-measurable as equivalent to the question of whether or not ¯ is s-measurable,
which determines whether or not there is non-fundamental volatility.


6.1    Equilibrium Implications of Monotonicity in R
We begin by demonstrating that if the divergence D is monotone in R, an s-measurable
equilibrium (featuring zero non-fundamental volatility) exists.
   Monotonicity in R has the implication that if an agent does not care about r per se, only how
it affects a
           ¯, then there is no reason for the agent to acquire any information about r. Recall that
in our framework a signal structure   V  is a conditional distribution. That is,  ( |s, r, a
                                                                                           ¯) is
the probability of observing signal    conditional on the realization of (s, r, a
                                                                                ¯).
   Let us now define an operator R : V  × U  V  that removes from   V  the conditioning
of the signal on r, while preserving the probabilities of each    conditional on (s, a
                                                                                     ¯),


                              r R (   ( |s, r , a
                                                ¯) µ (s, r , a
                                                             ¯))         ¯ s.t. R {µ} (s, a
      R {, µ} ( |s, r, a
                       ¯) =                                      s  S, a
                                                                       ¯A                 ¯) > 0.
                                      R {µ} (s, a ¯)

From this definition, we can observe immediately that R {, µ} ( |s, r, a
                                                                       ¯) = R {, µ} ( |s, r , a
                                                                                              ¯)
for all r, r  R, which is to say that the signal structure does not condition on r. It also follows
immediately that  {R {, µ}, µ} =  {, µ}, which is to say that the unconditional probabilities
of each signal are preserved by this operator.
   Our next lemma answers the following question: when is it always less costly (in terms of the
information cost) to avoid conditioning signals on r?

Lemma 2. (i) If the divergence associated with the cost function C  is monotone in R, then for all
priors µ  U and all signal structures   V  ,

                                   C  (R {, µ}, µ)  C  (, µ) .

   (ii) If, for all priors µ  U and all signal structures   V  ,

                                   C  (R {, µ}, µ)  C  (, µ) ,

then the divergence is monotone in R.

Proof. See the appendix, 11.5.

   Part (i) of Lemma 2 states that if the divergence is monotone in R, then the minimally-
informative signal structure is also the least-costly. One implication of this result is conditional

                                                 30
independence: because the agents' payoff never depends on r conditional on (s, a
                                                                               ¯), the agent's
optimal signal  will be independent of r conditional on (s, a
                                                            ¯). Part (ii) of Lemma 2 states the
converse: if removing conditioning on r always reduces information costs, then the divergence
is monotone in R. Put together, Lemma 2 tells us that monotonicity in R is equivalent to
the statement that paying attention to r is always costly. We now use this result to show that
monotonicity in R is sufficient for the existence of s-measurable equilibria.

Proposition 4. If the divergence associated with the cost function C  is monotone in R, then an
s-measurable symmetric BNE of the game exists.

Proof. See the appendix, 11.6.

   Our proof is essentially a restatement of our existence proof combined with an application of
part (i) of Lemma 2. The key observation is that with monotonicity in R, agents optimally choose
actions that conditional on (s, a
                                ¯), are independent of r. This is because conditional on (s, a
                                                                                             ¯),
an agent has no reason to acquire information about r: this would only increase the agent's
information costs with no benefit. As a result, if agents face an s-measurable aggregate action
function ¯ , they best-respond with a policy whose mean action is indeed s-measurable.
   The sufficient conditions in Proposition 4 are in fact stronger than necessary: divergences
need not be R-monotone on all priors. Instead, it suffices for divergences to be R-monotone
only on priors that may occur in an s-measurable equilibrium. Intuitively, only these priors
matter when conjecturing the existence of an s-measurable equilibrium.
   To weaken the conditions Proposition 4, we define U s-meas (µ0 )  U to be the set of priors
that may be generated by s-measurable ¯ given the exogenous prior µ0  U0 ,

   U s-meas (µ0 ) = µ  U :  ¯ s.t. µ =  ¯ {µ0 , 
                           ¯A          A        ¯ } and ¯ (s, r) = ¯ (s, r ) s  S, r, r  R ,

and define U s-meas = µ0 U0 U s-meas (µ0 ) as the set of all s-measurable priors. We are now able to
state a version of Proposition 4 demonstrating that monotonicity in R on s-measurable priors
is both necessary and sufficient to ensure the existence of an s-measurable symmetric BNE,
regardless of the utility function.

Proposition 5. An s-measurable symmetric BNE of the game exists for all utility functions u
satisfying Assumption 1 if and only if the divergence associated with the cost function C  is
monotone in R on all priors µ  U s-meas (µ0 ).

Proof. See the appendix, 11.7.

   The intuition for this result is essentially the converse of our previous result. With non-
monotonicity in R, there are priors µ  U such that agents optimally choose actions that,
                   ¯), are not independent of r. This is because even if the agent has no particular
conditional on (s, a

                                                 31
concern for the value of r, she finds it cheaper to obtain signals correlated with r than to
gather no information about r at all. As a result, each agent best-responds with a policy that,
conditional on (s, a
                   ¯), varies in r, provided that the agent gathers any information at all.
    We conclude that R-monotonicity on s-measurable priors is the key condition that
guarantees zero non-fundamental volatility. When this condition is violated, there are utility
functions that will generate non-fundamental volatility in equilibrium (because an equilibrium
exists by Proposition 3, and it is not s-measurable by Proposition 5).
    To further extend our results, we consider cost functions that are generically non-monotone
in R. We define the "opposite" of monotonicity in R, relying on the "only-if" aspect of Lemma
                                                   that does not condition on r . We will say
(2). Consider any informative signal structure   V0
that a cost function C  is "generically non-monotone in R" if, generically on the set of priors
µ  U , the signal structure  is not the least-costly of all the signal structures that coarsen to  ,
except at isolated points. Our use of the term generic follows Geanakoplos and Polemarchakis
[1986] and Farhi and Werning [2016].

Definition 8. A cost function C  is generically non-monotone in R if, generically on the set µ 
U s-meas , for all informative signal structures   V0
                                                     such that  =  {, µ}, there exists a   V 
                                                                  R                         0
with  = R { , µ} such that
                                             C   , µ < C  (, µ) .

    We have defined generic non-monotonicity as a property of the cost function C  as
opposed to of the divergence purely for convenience. Note that monotonicity and generic
non-monotonicity are not exhaustive classes of cost functions; cost functions might exhibit
monotonicity in R for some priors but not others. We have little to say about whether s-
measurable equilibria will or will not exist in this case.
    The reason we need a notion of generic non-monotonicity, as opposed to non-monotonicity
for all priors, is illustrated in our linear-quadratic-Gaussian example with the Fisher information
cost function. In that example, if under the prior s and r are independent, then even with the
Fisher information cost function the equilibrium will have zero non-fundamental volatility. This
situation is non-generic in the sense that even small amounts of correlation between s and r will
restore the result that the equilibrium features non-fundamental volatility.
    Before presenting our result, we need one more definition. We will say that an equilibrium
is deterministic if the aggregate action is constant and agents do not acquire any information.

Definition 9. A symmetric BNE (Definition 3)  = { A , ¯ } is deterministic if, for all s, s  S and
r, r  R, ¯ (s, r) = ¯ (s , r ) and  A (ai |s, r, ¯ (s, r)) =  A (ai |s , r , ¯ (s , r )).

    As we discussed in our linear-quadratic-Gaussian example, if the costs of acquiring
any information exceed the benefits (which can happen in that example with both mutual
information and Fisher information), there can be equilibria in which no information is

                                                         32
acquired and the aggregate action is identical in all states.        This is also a possibility in
our general game, but as our next result shows, if the cost function is non-monotone in R
and the equilibrium features some information gathering, then it will generically have non-
fundamental volatility.

Proposition 6. If the cost function is generically non-monotone in R on the set of priors U s-meas ,
then generically all symmetric BNE of the game are either not s-measurable or are deterministic.

Proof. See the appendix, 11.9.


6.2    Interpretation and Remarks
When do equilibria exhibit non-fundamental volatility?                In exogenous information
environments, non-fundamental volatility originates as errors in public signals. Noisy public
signals, or more generally correlated errors in beliefs, are natural components of generic
information structures [Bergemann and Morris, 2013]. In these environments, agents costlessly
observe public signals; as long as public signals contain information about fundamentals,
agents condition their actions on it.       As a result, errors in these signals orthogonal to
fundamentals affect equilibrium outcomes.
   However, under endogenous information acquisition, what appears to be a rather natural
property to impose on cost structures--monotonicity in R--leads to a surprising and strong
result: zero non-fundamental volatility in equilibrium. That is, if agents have no reason per
se to obtain information about r  R, and paying attention to r only increases costs, then
in equilibrium agents will optimally choose to ignore r. As a result, actions are conditionally
independent of r, and equilibria feature zero non-fundamental volatility. In fact, as we show
in Section 2, mutual information--the typical cost function used in the rational inattention
literature--produces this result.
   To break this--to eliminate s-measurable equilibria altogether--we show that one must
break monotonicity in R. If cost functions are non-monotonic in R, then agents pay attention
to r, even conditional on s, a
                             ¯. And, because the realization of r is common across all agents,
it introduces correlated errors in agents' actions, resulting in non-fundamental volatility in
equilibrium outcomes.
   The variables r  R thereby play the role of "noisy public signals:" they capture the idea
that it is comparatively cheap for agents to observe r as opposed to receiving signals only about
fundamentals s. In fact, note that in the limit in which r is completely costless, they are identical
to costless public signals (e.g. as in the exogenous information case). Away from this limit, the
variables r  R are not costless, but are "salient."
   Our beauty contest example in Section 2 demonstrates that with Fisher information, the
equilibrium generically features non-fundamental volatility. It should now be clear that the

                                                 33
underlying reason for why Fisher information and mutual information lead to such different
equilibrium properties is due to this particular difference in cost structure: mutual information
is monotonic in R, while Fisher information is not.


7         Efficiency under Exogenous Information
We next turn to the question of efficiency, and the connection between the cost functions and
informational externalities. To study inefficiencies with endogenous information acquisition,
we must first isolate inefficiencies that may arise in any other aspect of the game. In this section,
we consider a version of the game in which information is incomplete but exogenous. If the
equilibrium is constrained efficient in the game under exogenous information, then agents use
their information efficiently.
         We first establish a sufficient condition that ensures the use of information is efficient.
Angeletos and Pavan [2007] provide a related condition in a linear-quadratic setting with one-
dimensional action spaces (like our beauty contest example). Our analysis in this section
generalizes their result to our game, which features multi-dimensional actions and general
payoffs. After we establish that our condition is sufficient, we show that it is also necessary
to guarantee constrained efficiency for all possible priors and signal structures.
         In the subsequent section, we assume efficiency in the use of information, and ask what
more is needed to guarantee efficiency in the acquisition of information.


7.1         The Game under Exogenous Information
In the spirit of Lemma 1, we define our game with exogenous information by endowing agents
with a given signal structure    V0
                                   . These signal structures are exogenous both in the

sense that agents do not choose them and in the sense that they condition only on exogenous
state variables.20 We formalize the agent's choice set under exogenous information in a slightly
unusual way, to emphasize the connection between games with exogenous information and
games with endogenous information.
         All other features of the game--payoffs, action spaces, exogenous priors­remain the same.
Throughout this section we continue to impose Assumption 1 on action spaces and payoffs.
Because the agent no longer chooses his own signal structure and there are no information
costs, our assumptions on information acquisition costs are not applicable in this section.
    20
    It is well-known that in games with exogenous information structures, allowing for signals about
endogenous objects introduces an informational externality; see e.g. Laffont [1985], Angeletos and Pavan
[2009], Amador and Weill [2010], Vives [2017], Angeletos, Iovino, and La'O [2020]. In order to maintain a
clean benchmark, we abstract from such externalities in this section.




                                                   34
Choice sets with exogenous signal structures. Recall that any mixed strategy  :  
 (A) and exogenously given signal structure    V0
                                                 together define a conditional distribution

over actions,  A  V0
                   A , by (25). In the game with endogenous information, we wrote the agent's

problem as a choice over his conditional distribution of actions,  A  V A ; see Definition 3. In
the exogenous information game, we instead endow the agent with a signal structure   ; as a
result, the agent's only choice is his mixed strategy .
   But now observe that the mapping  can be thought of as a "garbling" in the sense of
Blackwell [1953]. That is, the conditional distributions  A that arise from the signals   and
mixed strategies  are weakly Blackwell-dominated by the conditional distributions   . In fact,
by Blackwell's theorem, the set of conditional action distributions  A  V0
                                                                         A that can be feasibly

created by any mixed strategy  are precisely those that are Blackwell-dominated by   .
   For any signal structure    V0
                                 , let B A (  )  V A denote the convex subset of conditional
                                                  0
                         A that are Blackwell-dominated by   . In the game with exogenous
action distributions in V0
information, we can write the agent's problem as a choice over conditional action distributions
 A  B A (  ), given the exogenously endowed signal structure    V0
                                                                 .



7.2    Equilibrium and Efficiency Definitions
We are now in a position to define equilibrium and efficiency with exogenous information. As
in our definition of equilibrium in the original game with endogenous information (Definition
3), we focus on symmetric Nash equilibria in which all agents choose the same action strategy.

Definition 10. (Exogenous information game.) Given a common prior µ0  U0 and exogenous
signal structure    V0
                      , a symmetric Bayesian Nash equilibrium of the game under exogenous

information is a mean-consistent strategy profile  such that agents' strategies  A  V0
                                                                                     A are best

responses
               A        sup                          ¯, s  ai |s, r, a
                                              u ai , a               ¯ dai µ (s, r, a
                                                                                    ¯) da
                                                                                        ¯.
                                 ¯
                     B ( ) sS,rR A
                         A                A

with µ = A
         ¯ {µ0 , ¯ }.

   Our equilibrium definition under exogenous information mirrors our equilibrium definition
under endogenous information. In fact, Definitions 10 and 3 are nearly identical--the only
difference is that with endogenous information, agents face a convex cost of information (C A ),
whereas with exogenous information, their choice of signal structure is restricted to a convex
set (B A (  )). Viewed from this perspective, the game under exogenous information is not very
different from the game under endogenous information, and our proof of existence applies
almost unchanged.

Proposition 7. A symmetric BNE of the game under exogenous information exists.


                                                  35
Proof. See the appendix, 11.10.

       Having established equilibrium existence, we next consider constrained efficiency. We
define constrained efficiency in this game as the solution to a particular planner's problem.
Our definition enforces symmetry in strategies as a constraint on the planner, mirroring our
symmetric BNE definition.

Definition 11. (Exogenous information game.) Given a common prior µ0  U0 and exogenous
                      , a symmetric strategy profile   = ( A , 
signal structure    V0                                         ¯  ) is constrained efficient if it
solves

                      sup                      u ai , a
                                                      ¯, s  A ai |s, r, a
                                                                        ¯ dai µ (s, r, a
                                                                                       ¯) da
                                                                                           ¯
                              ¯       ¯
                  A BA (  ),¯ A sS,rR A    A


subject to µ = A
               ¯ {µ0 , ¯ } and mean-consistency (Definition 2).

       Our notion of constrained efficiency follows that in Angeletos and Pavan [2007].21 In our
environment, the planner chooses a mean-consistent symmetric strategy profile  in order to
maximize welfare. This planner can tell agents how to use their information, but is constrained
in that she may not endow agents with more information nor transfer information from one
agent to another. The planner therefore treats the convex set B A (  ) as a feasibility constraint
on the set of possible strategies.


7.3       A Sufficient Condition for Constrained Efficiency
As already stated, the purpose of this section is to obtain sufficient conditions for efficiency
in the use of information in our setting, as Angeletos and Pavan [2007] have done for linear-
quadratic games. This entails ensuring that no externalities exist in the game under exogenous
information.
       A symmetric BNE of the game under exogenous information will not necessarily be
constrained efficient in the sense of Definition 11. Even under complete information, standard
"payoff externalities" may arise in any environment in which agents' actions affect the payoffs
of others. Classic examples of payoff externalities include pollution, monopolistic competition,
public goods provision, network spillovers (vaccines), etc.22
       To understand the source of potential externalities in our game, consider first the special
case in which all agents have complete information, and suppose for expositional purposes
that the utility function is differentiable and all actions are interior. In this case, the first-
order conditions of an individual agent i and the planner with respect to that agent's action
  21
    See also Radner [1962] and Vives [1988].
  22
    Of course, payoff externalities also do not necessarily lead to inefficiency--as the classic welfare
theorems demonstrate in the case of pecuniary externalities.

                                                   36
are, respectively,
                 u(·)                       u(·)        u(·)
                      = 0,      and              +           dj = 0,           i  [0, 1], s  S.
                 ai                         ai          a¯
These first-order conditions are similar except that the planner considers the impact of agent i's
                             u(·)
action on other agents,      a¯ dj ,   whereas the agent does not. This term represents a standard
payoff externality: the effect of agent i's action on the aggregate action, which in turn affects all
other agents' payoffs. This effect is not internalized by agent i and is therefore absent from her
first-order condition. Constrained efficiency requires that this term be equal to zero given the
equilibrium actions of the other agents.
       Consider the same heuristic argument when agents have incomplete and dispersed
information. In the exogenous information game, the first-order conditions of an individual
agent i and the planner with respect to that agent's action are, respectively:
           u(·) i                           u(·)          u(·)
       E        = 0,         and        E        +             dj  i = 0,           i  [0, 1],  i     (38)
           ai                               ai            a¯
These conditions are similar to those in the complete information game; again the second
term in the planner's condition is absent from the agent's optimality condition. Now, however,
efficiency requires that this condition hold for all possible realizations of the agent's signal,
 i  . Thus, in order for the equilibrium to be efficient under exogenous information, there
must be no payoff externalities from the perspective of any agent in the economy conditional
on any realization of his or her signal.
       The question, then, is under what circumstances this equation will hold in equilibrium.
Angeletos and Pavan [2007] show that this condition requires more than what is required
for efficiency under complete information. That is, a game can be efficient under complete
information, but inefficient under incomplete and dispersed information. This is because
under complete information, the equilibrium actions of all agents are identical and equal to
the aggregate action. In this case efficiency only requires that the planner's and the agents'
optimality conditions coincide at the equilibrium aggregate action.                   With incomplete and
dispersed information, efficiency requires that (38) hold for all signal realizations in equilibrium
given the optimal strategies of agents  A and the associated aggregate action function ¯.
       With a one-dimensional action space and linear-quadratic payoffs, e.g. as in our beauty
contest example, Angeletos and Pavan [2007] demonstrate that
                                   2         i               2
                                         u( a  , a
                                                 ¯ , s ) = -    u(ai , a
                                                                       ¯, s)
                                   ai  a
                                       ¯                     ¯2
                                                             a
is sufficient to guarantee efficiency under exogenous information.23 Likewise, our main result
in this section provides a sufficient condition for efficiency with exogenous information to hold
  23
    In the context of our beauty contest game in Section 2, this condition holds for the quadratic payoff
function in (1).

                                                     37
given a utility function u defined on an action space A and set of fundamental states S , for all
finite sets R, priors µ0  U0 , and signal structures    V0
                                                         .


                                                   ¯ × S  R and a function g : A × S  R such
Proposition 8. Suppose there exists a function G : A
that

                          u(ai , a
                                 ¯, s) = g (ai ; s) + G(¯
                                                        a; s) + (ai - a
                                                                      ¯) · G(¯
                                                                             a; s),                    (39)

where G(¯
        a; s) denotes the gradient of G with respect to its first argument, and that u satisfies
Assumption 1.24 Then there exists a symmetric BNE with exogenous signals (Definition 10) that is
constrained efficient (Definition 11).

Proof. See the appendix, 11.11.

       The proof of sufficiency is relatively straightforward. The first-derivative of the payoff
function in (39) with respect to a
                                 ¯ is given by

                                      u (·)
                                                  a; s))(ai - a
                                            = H(G(¯           ¯).
                                      a¯
where H(G(·)) is the Hessian matrix of second-order partial derivatives of G. Integrating
this expression across agents results in a gradient of zero, as required by (38). It is also
immediately apparent from this expression that, if u were quadratic and the action space were
one-dimensional (so that H(G(¯
                             a; s)) is a constant), then our condition would reduce to the
Angeletos and Pavan [2007] condition.
       Note that condition (39) is a condition on payoffs u alone; it is sufficient for constrained
efficiency with exogenous information regardless of the details of the information structure.
Note also that the convexity or concavity of G determines whether this functional form exhibits
strategic complementarity of substitutability. For example, in the one-dimensional context, if G
is convex, then G is increasing in a
                                   ¯, and larger actions a become preferable as a
                                                                                ¯ increases.
       Armed with this result, we now know how to "shut down" these externalities, so as to isolate
externalities arising from information acquisition in our game with endogenous information--
the focus of our following section. Prior to that, however, we will show that our condition is not
only sufficient but in a certain sense necessary to guarantee constrained efficiency.


7.4       A Necessary Condition for Constrained Efficiency
In this sub-section, we demonstrate that the functional form described in Proposition 8
is necessary for constrained efficiency to hold regardless of the details of the information
structure, within a large class of utility functions.
  24
    That is, g is continuously differentiable on A for all s  S , and G is continuously twice-differentiable
   ¯ for all s  S .
on A

                                                     38
    To simplify our analysis, we focus on payoffs that are concave in a
                                                                      ¯; this is equivalent under
the functional form of (39) (and in Angeletos and Pavan [2007]) to assuming weak strategic
complementarity. The class of utility functions we consider in this sub-section is the set of
strictly concave and sufficiently smooth utility functions that guarantee optimal actions on
the interior of A. The two assumptions below formalize the properties of this class of utility
functions.

Assumption 5. For all s  S , the utility function u(ai , a
                                                         ¯, s) is strictly concave and continuously
twice-differentiable on (ai , a
                              ¯).

Assumption 6. There exists a set A in the relative interior of A such that for all a  A \ A there
exists an a  A satisfying u(a, a             ¯, s) s  S, a
                               ¯, s) > u(a , a           ¯A ¯.

    The utility function in our beauty contest fall into this class given any finite set S , for a
sufficiently large action space A. That is, at some point, actions are so far from optimal given
any exogenous state that they are dominated regardless of what the other agents do. As a
result, in any equilibrium, actions are guaranteed to be interior. To understand why we want to
ensure that optimal actions are interior, observe that if they are not, allocations can be efficient
despite the presence of externalities. For example, an excessive incentive for private agents to
consume gasoline does not lead to inefficiency if the planner would choose maximal gasoline
consumption anyways.
    Our necessity result shows that, if we are given a set S , action space A, and utility function
u satisfying Assumptions 1, 5, and 6, and are furthermore told that for all finite sets R, priors
µ0  U0 , and signals    V0
                          , there is a constrained efficient symmetric BNE, then the utility

function must satisfy (39) on the relevant part of its domain. To understand this last qualifier,
let us suppose we are given such a utility function u, and let us define given this utility function
the set Ace  A of actions that occur in some constrained efficient symmetric BNE. That is, if
a  Ace , there is some (R, µ0 ,   ) such that in a constrained efficient symmetric BNE this action
occurs with positive probability.
    Let us now consider a different utility function u~, with the property that u  ~(ai , a
                                                                                          ¯, s) = u(ai , a
                                                                                                         ¯, s)
         i   ce
for all a  A , a   ¯
                ¯  A, and s  S , and u     i
                                      ~(a , a           i  ¯, s) otherwise. It is immediately apparent
                                             ¯, s) < u(a , a
that the set of constrained efficient symmetric BNE given u
                                                          ~ is identical to the set of constrained
efficient symmetric BNE given u, because all we have done is make socially sub-optimal actions
even worse. Consequently the set of actions Ace is identical for the two utility functions, and if u
guarantees constrained efficiency, so does u
                                           ~.
    What we learn from this example is that it cannot be necessary for u to satisfy (39) on all of its
domain to guarantee constrained efficiency. Instead, we will show that Ace is a convex subset of
A, and that it is necessary for u to satisfy (39) on Ace × Ace × S to guarantee constrained efficiency.
We begin by formally defining Ace .

                                                     39
Definition 12. Fix a set S , action space A, and utility function u. An action a  A is an element
of the set Ace if there exists a finite set R, prior µ0  U0 , and signal structure    V0
                                                                                        such that a

constrained efficient symmetric BNE ( A , ¯ ) exists with  A (a|s, r, ¯ (s, r)) > 0 for some s  S, r  R
with µ0 (s, r) > 0.

    That is, a  Ace if there is some situation that rationalizes this action in some circumstances
as part of a constrained efficient equilibrium. Armed with this definition, we provide our
necessary condition to guarantee constrained efficiency with exogenous signals.

Proposition 9. Take as given the set of fundamental states S , action space A, and a utility
function u satisfying Assumptions 1, 5, and 6. If for all finite sets R, priors µ0  U0 and signal
structures    V0
                there exists a constrained efficient symmetric BNE, then u(ai , a
                                                                                ¯, s) satisfies (39)
for some functions g, G on all (ai , a
                                     ¯, s)  Ace × Ace × S , with G twice-differentiable and convex.

Proof. See the appendix, 11.12.

    Condition (39) is therefore both sufficient and necessary to guarantee efficiency in the use
of information. Let us now assume it, and ask what more is required to guarantee efficiency in
the acquisition of information.


8     Efficiency under Endogenous Information
We now return to the original game with endogenous information acquisition as described in
Section 3. In addition to Assumption 1 on action spaces and payoffs, we reinstate Assumptions
2-4 on the costs of information acquisition. We define constrained efficiency as the solution to
a certain planner's problem in this setting as follows.

Definition 13. Given a common prior µ0  U0 , a symmetric strategy profile   = ( A , ¯  ) is
constrained efficient if it solves

               sup                       u ai , a
                                                ¯, s  A ai |s, r, a
                                                                  ¯ dai µ (s, r, a    ¯ - C A  A, µ
                                                                                 ¯ ) da
                ¯       ¯
           V ,¯ A sS,rR A            A
           A    A




subject to µ = A
               ¯ {µ0 , ¯ } and mean-consistency (Definition 2).

    Our definition of constrained efficiency under endogenous information mirrors our
definition of constrained efficiency under exogenous information, but with a convex cost on
 A in the place of a restriction to a convex set. This cost enters the planner's problem; that is,
the planner acknowledges that the agents face information acquisition costs.
    The distinction between exogenous and endogenous information games in our context
makes clear why, at least potentially, a new externality may arise in the game with endogenous

                                                       40
information acquisition. In the exogenous information game, agents strategies' could affect
other agents only through payoffs. This was by construction: each agent's convex set B A (  )
of strategies was independent of other agents' actions.25                  In contrast, in the endogenous
information game, the cost function C A          can in general depend on the aggregate action function
¯ . This is true even though it is without loss of generality for agents to choose signals about

exogenous states only ( A  V0
                            A ), as discussed in Section 3. This dependence opens the door

to externalities in the acquisition of information: agents may not internalize how their own
strategy affects the information acquisition costs of others. In what follows, we derive under
what conditions such an externality can arise.


8.1       Efficiency in the Acquisition of Information
In order for there to be inefficiency in the acquisition of information, there must be an
externality by which the actions of one agent affect the welfare of others. In our framework,
such an externality can exist only via the the aggregate action function ¯ .26 Recall our definition
of posterior-separable cost functions C A in (23), and note that in what follows we will use the
action space A as the signal alphabet, to align our results with our definitions of equilibrium
and constrained efficiency. In principle, C A can vary with the aggregate action function ¯ via
both the unconditional signal probabilities  { A , µ} and the divergence D.
       However, Lemma 1 shows that it is without loss of generality to assume that  A  V0
                                                                                        A,

meaning that  A does not in fact condition on a
                                              ¯. As a result, the distribution of a
                                                                                  ¯ does not
affect the unconditional signal probabilities holding fixed such a signal structure, meaning that
for all µ0  U0 ,  A  V A , and ¯,   ¯,
                                  ¯ A
                         0


                                  { A , A
                                        ¯ {µ0 , ¯ }} =  { A , A
                                                              ¯ {µ0 , ¯ }}.

       Moreover,  A  V0
                      A has implications for the structure of the posteriors. Let µ =  {µ , 
                                                                                      ¯
                                                                                      A  0 ¯ },
and observe that the posterior after receiving the signal recommending action a  A, µa  U , is,
                     ¯,
                 ¯0  A
for an arbitrary a

                                                  A (a|s, r, a                a-
                                                             ¯0 ) µ0 (s, r)  (¯ ¯ (s, r))
                        µa { A , µ}(s, r, a
                                          ¯) =                     A
                                                                                          ,
                                                                { , µ} (a)

and therefore satisfies, for all all µ  U and  A  V0
                                                   A,


                                      µa { A , µ} = A   a A
                                                    ¯ {µ { , µ}, µ}

  25
     This was due to the assumption that    V0     
                                                     . If this were not the case, then this set would in general
vary with the aggregate action function ¯ , as it does in Laffont [1985], Angeletos and Pavan [2009], Amador
and Weill [2010], Vives [2017], Angeletos, Iovino, and La'O [2020].
  26
     As discussed in our beauty contest example, our framework precludes the possibility that the cross-
sectional dispersion of actions affects agents' payoffs. This channel is the central focus of Colombo,
Femminis, and Pavan [2014]; we abstract from it here.

                                                        41
where A ¯ is the composition of a coarsening and embedding we used to define invariance with
respect to A¯ (see (36) and Definition 6). That is, the conditional distribution of a
                                                                                    ¯ given (s, r)
under the posterior µa is the same as the conditional distribution under the prior µ.
   From this observation, it is a small step to show that, if D is invariant with respect to
¯
A and  A  V0  A , changing   ¯ does not change the divergence between the posterior and
prior. Consequently, in this case, ¯ does not change the information cost. Conversely, if the
information cost is unaffected by   ¯ regardless of the values of  A  V0
                                                                       A and µ  U , it must be
                                                                              0    0
                                               ¯
the case that the divergence D is invariant in A . The following lemma summarizes these results.

                                                                                     ¯, then for all
Lemma 3. (i) If the divergence associated with the cost function C A is invariant in A
                                        A     A
priors µ0  U0 and all signal structures   V , and all    ¯, ¯ A  ¯,
                                                 0


                            C A  A , A
                                     ¯ {µ0 , ¯ } = C A  A , A
                                                            ¯ {µ0 , ¯} .

    (ii) If, for all priors µ0  U0 and all signal structures  A  V0
                                                                  A , and all ¯,   ¯,
                                                                                 ¯ A

                            C A  A , A
                                     ¯ {µ0 , ¯ } = C A  A , A
                                                            ¯ {µ0 , ¯} ,

                                    ¯.
then the divergence is invariant in A

Proof. See the appendix, 11.14.

                                                                                           ¯,
    Thus, if the divergence associated with the cost function is invariant with respect to A
then there is no channel by which agents' actions affect another agents' cost of information.
Consequently, if the game is constrained efficient under exogenous information (which we
guarantee by assuming (39) holds), it will also be constrained efficient under endogenous
information acquisition.

Proposition 10. In the game with endogenous information, a constrained-efficient symmetric
BNE exists if u satisfies the conditions of Proposition 8 and the divergence D is invariant with
           ¯. There exists a convex function G
respect to A                                  ¯ :A¯  R, which is determined by g and C A , such
that if the function
                                ¯ (¯
                                G  ) -           µ0 (s, r)G(¯
                                                            (s, r); s)
                                         sS,rR

is convex (where g and G are defined as in Proposition 8), then all symmetric BNE are constrained
efficient.

Proof. See the appendix, 11.15.

    Proposition 10 provides sufficient conditions under which a constrained efficient
equilibrium exists in the game with endogenous information. If the game is efficient under
exogenous information, and if agents have cost functions with associated divergences that are

                                                     42
                          ¯, then there are no externalities related to the cost of information
invariant with respect to A
acquisition.
   Our proof of Proposition 10 shows something stronger: that all symmetric BNE are critical
points of the planner's problem. If strategic complementarities are not too strong (G is not too
convex), then the social planner's problem is concave, and consequently all symmetric BNE are
maximizers, and hence constrained efficient. The requirement that strategic complementarities
not be too strong is the analog of our assumption that  < 1 in our beauty contest example. Note
also that even in games of complete information, with strong strategic complementarities, there
are in general multiple Pareto-ranked equilibria.
   A related result appears in work by Angeletos and Sastry [2019], who study constrained
efficiency of equilibria in a Walrasian setting. Angeletos and Sastry [2019] consider two cases:
one in which agents can track only the exogenous state, and one in which agents can also track
endogenous prices. They show that the two cases are equivalent, and equivalent to the planner's
problem they consider (which is different than our planner's problem), if agents' information
costs are invariant in the standard sense (e.g. as in mutual information). The condition we offer
in Proposition 10 is weaker than the invariance condition in Angeletos and Sastry [2019] as it
only imposes invariance with respect to embeddings in A¯, rather than all possible embeddings.
This is a useful distinction in our setting when considering necessity, which we turn to next.


8.2    Inefficiency in Information Acquisition.
We begin by defining a notion of generic non-invariance. Loosely speaking, a cost function is
                                        ¯ if perturbations to the aggregate strategy affect the
generically non-variant with respect to A
cost of information.
Definition 14. A cost function C  is generically non-invariant with respect to A       ¯ at µ0  U0 if,
for all (   V  , ¯A  ¯) except possibly at a set of isolated points, there exists an  j   with
               0


                                  j |s, r, a
                                           ¯ 0 ¯ {C
                                                    
                                                       , A
                                                         ¯ {µ0 , ¯ } }(s, r) = 0
                       sS,rR
                                               ¯, there is an interaction between agent's
   With generic non-invariance with respect to A
actions and other agents' cost of information. Our necessity result shows that this leads
to inefficiency generically in the space of utility functions that would otherwise guarantee
efficiency under exogenous information. As in our necessity proof in the exogenous information
case, it is convenient to impose an assumption that guarantees interior actions (Assumption 6).
Proposition 11. Fix the sets S , R, and A, and let C  be a cost function that is generically non-
                          ¯ at the prior µ0  U0 . Generically on the space of utility functions u
invariant with respect to A
satisfying Assumptions 1 and 6 and the sufficient conditions of Proposition 8, all symmetric BNE
are either deterministic or not constrained-efficient.

                                                  43
Proof. See the appendix, 11.16.

   Even when the game is efficient under exogenous information, an externality arises in the
                                                                     ¯. When agents choose
endogenous information game if the cost function is non-invariant in A
how their conditional distribution of actions correlates with the exogenous states and other
agents' actions, they affect the conditional distribution of the aggregate action. If the cost
                                         ¯, then the equilibrium conditional distribution of the
function is generically non-invariant in A
aggregate action affects all agents' information acquisition costs. Agents do not internalize this
information cost effect, and as a result, the equilibrium is inefficient.
   In this case the planner chooses a different signal structure than the one that arises in
equilibrium--one that instead internalizes the aforementioned information cost externality. In
                                                                       ¯, then no such externality
contrast, if the agents' cost structures are invariant with respect to A
arises, and the planner's solution coincides with the equilibrium strategy profile.
   Our formulation of this proposition side-steps the issue of deterministic equilibria
(Definition 9), which also arose in our analysis of non-fundamental volatility. In a deterministic
equilibrium, agents do not gather information, and consequently their information costs are
zero. As a result, if both the planner and the agents are at this corner, there is no externality
even if the cost function is generically non-invariant.


8.3    Interpretation and Remarks
Does efficiency under exogenous information imply efficiency under endogenous information
acquisition? In our game, the answer is no. Propositions 10 and 11 demonstrate that efficiency
under endogenous information requires an extra condition on information costs: namely,
                           ¯.
invariance with respect to A
   This condition arises from the influence that agents' actions have on other agents'
information costs. Such a channel is natural if we imagine that agents learn in part by observing
other agents' actions; in this case, it is intuitive to suppose that some actions reveal more
information than other actions.
   With exogenous signals, which we interpret as restricting conditional action distributions to
a convex set, the importance of the distinction between signals about exogenous states and
signals about endogenous objects has been highlighted in several papers; see, e.g. Laffont
[1985], Angeletos and Pavan [2009], Amador and Weill [2010], Vives [2017], Angeletos, Iovino,
and La'O [2020].     When agents receive exogenous signals about endogenous objects, an
information-aggregation externality arises: agents do not take into account how their own use of
information affects the information content of these signals. In these environments, the planner
may wish for agents to use their information in a way that differs from what is privately-optimal,
in order to improve the aggregation of information in the endogenous signals.


                                                 44
         With endogenous acquisition of information, these issues are subtler. Many authors in the
literature have assumed both that agents can only acquire signals about exogenous states and
that the cost of such signals does not depend on the actions of other agents. That is, they have
implicitly assumed invariance with respect to A ¯. Our analysis makes clear that by doing so,
one is effectively substituting a fixed convex set (the exogenous signals case) with a convex cost
function invariant with respect to A  ¯. We show that this in and of itself unsurprisingly does not
alter whether the game is efficient or inefficient. Put simply, in this context, efficiency in the
use of information automatically implies efficiency in the acquisition of information. Although
this result may not be not well-known in this literature, it has been shown in some specific
contexts.27
         Our results offer a different perspective. Assuming that agents receive signals that condition
only on exogenous states is without loss of generality (Lemma 1), but it does not imply that
agents are not "learning about the actions of others" because those actions are in equilibrium
a deterministic function of the exogenous states. Put another way, when the prior µ  U over
exogenous states and endogenous outcomes is degenerate, and it always is in our framework,
which variables the signal structure conditions on cannot be interpreted as describing what
the agent is paying attention to. Instead, it is the invariance or lack thereof of the information
cost with respect to A¯ that describes whether agents are attending to the exogenous state,
endogenous outcomes, or some combination thereof.                Moreover, it is this condition that
determines the constrained efficiency properties of equilibria.


9         Conclusion
In this paper, we have explored the relationship between information cost functions
and the properties of equilibria in large games with strategic interaction and rationally
inattentive agents. Under the assumption of posterior separability, we have demonstrated the
close connection between certain properties of information cost functions--namely, partial
monotonicity and partial invariance--and whether or not the equilibrium is efficient/exhibits
non-fundamental volatility.         We have interpreted these forms of invariance as describing
whether or not it is possible to learn directly about the actions of others and whether or not
public signals are available to the agent.
         Efficiency holds only when cost functions are invariant in endogenous actions and when
there are no externalities under exogenous information. The class of utility functions that
rules out externalities under exogenous information has a particular functional form; this form
generalizes the characterization of Angeletos and Pavan [2007] to games that are not necessarily
    27
    See e.g. Online Appendix A of Angeletos and La'O [2020], the analysis in Angeletos and Sastry [2019]
of non-price-tracking economies, or the analysis of Colombo, Femminis, and Pavan [2014] when action
dispersion does not enter payoffs.


                                                    45
linear-quadratic. Non-fundamental volatility exists when information costs are non-monotone
in payoff-irrelevant dimensions of the exogenous state space. The standard rational inattention
cost function, mutual information, leads to both efficiency and zero non-fundamental volatility.
In contrast, Fisher information, an alternative cost function proposed by H´
                                                                           ebert and Woodford
[2020], leads to both non-fundamental volatility and inefficiency.


References
Hassan Afrouzi. Strategic inattention, inflation dynamics, and the non-neutrality of money.
  Columbia mimeo, 2019. 1

Manuel Amador and Pierre-Olivier Weill. Learning from prices: Public communication and
  welfare. Journal of Political Economy, 118(5):866­907, 2010. 1, 20, 25, 8.3

Shun-ichi Amari and Hiroshi Nagaoka. Methods of information geometry, volume 191. American
  Mathematical Soc., 2007. 1, 5.4

George-Marios Angeletos and Jennifer La'O. Noisy business cycles. In NBER Macroeconomics
  Annual 2009, Volume 24, pages 319­378. University of Chicago Press, 2010. 1

George-Marios Angeletos and Jennifer La'O. Sentiments. Econometrica, 81(2):739­779, 2013. 1

George-Marios Angeletos and Jennifer La'O.          Optimal monetary policy with informational
  frictions. Journal of Political Economy (forthcoming), 2020. 27

George-Marios Angeletos and Chen Lian.             Incomplete information in macroeconomics:
  Accommodating frictions in coordination. Handbook of Macroeconomics, 2:1065­1240, 2016.
  1

George-Marios Angeletos and Alessandro Pavan. Efficient use of information and social value
  of information. Econometrica, 75(4):1103­1142, 2007. 1, 1, 1, 2, 2.2, 2.2, 7, 7.2, 7.3, 7.3, 7.3, 7.4,
  9

George-Marios Angeletos and Alessandro Pavan. Policy with dispersed information. Journal of
  the European Economic Association, 7(1):11­60, 2009. 1, 20, 25, 8.3

George-Marios Angeletos and Karthik Sastry. Inattentive economies: General equilibrium and
  welfare theorems. MIT mimeo, 2019. 1, 1, 2, 10, 8.1, 27

George-Marios Angeletos, Luigi Iovino, and Jennifer La'O.               Efficiency and policy with
  endogenous learning. MIT/Columbia/Bocconi mimeo, 2020. 1, 20, 25, 8.3


                                                  46
Arindam Banerjee, Xin Guo, and Hui Wang. On the optimality of conditional expectation as a
  bregman predictor. IEEE Transactions on Information Theory, 51(7):2664­2669, 2005. 11.12

Dirk Bergemann and Stephen Morris.            Robust predictions in games with incomplete
  information. Econometrica, 81(4):1251­1308, 2013. doi: 10.3982/ECTA11105. URL https:
  //onlinelibrary.wiley.com/doi/abs/10.3982/ECTA11105. 1, 6.2

David Blackwell. Equivalent comparisons of experiments. The annals of mathematical statistics,
  24(2):265­272, 1953. 2, 7.1

Andrew Caplin and Mark Dean.           Revealed preference, rational inattention, and costly
  information acquisition. American Economic Review, 105(7):2183­2203, 2015. 3.2, 15

Andrew Caplin, Mark Dean, and John Leahy. Rationally inattentive behavior: Characterizing
  and generalizing Shannon entropy. Columbia mimeo, 2019. 1, 1, 1, 1, 3.2, 3.2, 5.4

Nikolai Nikolaevich Chentsov. Statistical decision rules and optimal inference. Number 53.
  American Mathematical Soc., 1982. 1, 5.4

Luca Colombo, Gianluca Femminis, and Alessandro Pavan.             Information acquisition and
  welfare. The Review of Economic Studies, 81(4):1438­1483, 2014. 1, 2, 2.2, 2.2, 26, 27

Mark Dean and Nathaniel Neligh. Experimental tests of rational inattention. Columbia mimeo,
  2019. 1

Tommaso Denti. Unrestricted information acquisition. Cornell University mimeo, 2019. 1, 1,
  2.2, 4

Emmanuel Farhi and Iv´
                     an Werning. A theory of macroprudential policies in the presence of
  nominal rigidities. Econometrica, 84(5):1645­1704, 2016. 6.1

Drew Fudenberg and Jean Tirole. Game theory, 1991. Cambridge, Massachusetts, 393(12):80,
  1991. 11

John D Geanakoplos and Heraklis M Polemarchakis. Existence, regularity, and constrained
  suboptimality of competitive allocations. Essays in Honor of Kenneth J. Arrow: Volume 3,
  Uncertainty, Information, and Communication, 3:65, 1986. 6.1

Sanford Grossman. On the efficiency of competitive stock markets where trades have diverse
  information. The Journal of Finance, 31(2):573­585, 1976. doi: 10.1111/j.1540-6261.1976.
  tb01907.x. URL https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-6261.1976.
  tb01907.x. 4


                                               47
Sanford J. Grossman and Joseph E. Stiglitz. Information and competitive price systems. The
  American Economic Review Papers and Proceedings, 66(2):246­253, 1976. 1, 4

Sanford J Grossman and Joseph E Stiglitz. On the impossibility of informationally efficient
  markets. The American economic review, 70(3):393­408, 1980. 1, 4

F. A. Hayek. The use of knowledge in society. The American Economic Review, 35(4):519­530,
  1945. ISSN 00028282. URL http://www.jstor.org/stable/1809376. 2

          ebert. Moral hazard and the optimality of debt. The Review of Economic Studies, 85
Benjamin H´
  (4):2214­2252, 2018. 1, 5.4

Benjamin H´
          ebert and Michael Woodford.          Rational inattention when decisions take time.
  Unpublished manuscript, October 2019. 1, 3.2, 15, 3.2, 5.4

Benjamin H´
          ebert and Michael Woodford. Neighborhood-based information costs. Technical
  report, National Bureau of Economic Research, 2020. (document), 1, 1, 1, 2, 2.1, 2.1, 8, 3.2, 9,
  11.1, 11.1, 11.1, 11.2

Christian Hellwig and Laura Veldkamp. Knowing what others know: Coordination motives in
  information acquisition. Review of Economic Studies, 76(1):223­251, 2009. 1

Emir Kamenica and Matthew Gentzkow. Bayesian persuasion. American Economic Review, 101
  (6):2590­2615, 2011. 11.11

Jean-Jacques M Laffont.     On the welfare analysis of rational expectations equilibria with
  asymmetric information. Econometrica, 53(1):1­29, January 1985. 1, 20, 25, 8.3

Bartosz Mackowiak and Mirko Wiederholt. Optimal sticky prices under rational inattention.
  American Economic Review, 99(3):769­803, June 2009. 1

Stephen Morris and Hyun Song Shin. Social value of public information. American Economic
  Review, 92(5):1521­1534, 2002. 1, 2

David P Myatt and Chris Wallace. Endogenous information acquisition in coordination games.
  The Review of Economic Studies, 79(1):340­374, 2012. 1

Luigi Paciello and Mirko Wiederholt. Exogenous information, endogenous information, and
  optimal monetary policy. Review of Economic Studies, 81(1):356­388, 2014. 1

Alessandro Pavan.     Attention, coordination, and bounded recall.      Northwestern University
  mimeo, 2016. 1



                                               48
Luciano Pomatto, Philipp Strack, and Omer Tamuz. The cost of information. arXiv preprint
  arXiv:1812.04211, 2018. 1, 1, 3.2

R. Radner. Team decision problems. The Annals of Mathematical Statistics, 33(3):857­881, 1962.
  21

Christopher A. Sims. Implications of rational inattention. Journal of Monetary Economics, 50(3):
  665 ­ 690, 2003. ISSN 0304-3932. Swiss National Bank/Study Center Gerzensee Conference
  on Monetary Policy under Incomplete Information. 1, 1, 2.1

Harald Uhlig. A law of large numbers for large economies. Economic Theory, 8(1):41­50, 1996. 4

Stijn Van Nieuwerburgh and Laura Veldkamp.                         Information acquisition and under-
  diversification. The Review of Economic Studies, 77(2):779­805, 2010. 2.1

Xavier Vives. Aggregation of information in large cournot markets. Econometrica, 56(4):851­76,
  1988. 21

Xavier Vives. Endogenous public information and welfare in market games. Review of Economic
  Studies, 84(2):935­963, 2017. 1, 20, 25, 8.3

Michael Woodford.        Imperfect common knowledge and the effects of monetary policy.
  Knowledge, Information, and Expectations in Modern Macroeconomics: In Honor of Edmund
  S. Phelps, 2003. 1



10       Non-s-Measurability and Generic Non-Fundamental
         Volatility
Let us suppose that, given some utility function u satisfying Assumption 1 and divergence D
satisfying our assumptions on information costs, there exists an equilibrium ( A , ¯ ) that is not
s-measurable (Definition 7), but satisfies ¯ (s, r) = ¯ (s, r ) for all s  S and r, r  R. By Lemma
1, it is without loss of generality to suppose that  A  V0
                                                         A.

      Let us now define a sequence of functions f : A  A with the following properties: f (a)
is strictly increasing and differentiable in each dimension of A  RL , strictly convex in a for
all    > 0, and satisfies lim   0+   f (a) = a for all a  A. Observe that each of these functions is
invertible. Given such a sequence of functions, define the utility functions

                           ¯ (s, r), s) = u(f -1 (a ), 
                    u (a , a                           ¯ (s, r), s) s  S, r  R, a  A,

                    ¯,
                ¯0  A
where, for some a
                                 a
                                 ¯ (s, r) =       a  A (f -1 (a )|s, r, a
                                                                        ¯0 )da .
                                              A

                                                       49
By construction, this                    ¯ ) =  A (f -1 (a )|s, r, a
                      ¯ and  A (a |s, r, a                         ¯0 ) are an equilibrium of the game
with the game with the u utility functions.
   But now observe that we can rewrite a
                                       ¯ as

                                  a
                                  ¯ (s, r) =       f (a ) A (a|s, r, a
                                                                     ¯0 )da .
                                               A

Because the higher moments of the distribution of a given (s, r) depend on r under  A , we can
find a sequence of functions such that, for some arbitrary s, a          ¯ (s, r ) for all
                                                              ¯ (s, r) = a                   > 0 and
r=r.
   We conclude that the case in which the equilibrium is not s-measurable but the economy
nevertheless exhibits zero non-fundamental volatility is non-generic, in the sense that arbitrary
perturbations to the utility function will generate non-fundamental volatility in this case.


11     Appendix A: Proofs
11.1     Proof of Proposition 1
The problems defined by (7), (8), and (10) follow from the results of H´
                                                                       ebert and Woodford [2020].
We first derive (9) and (11).
   By the Sherman-Morrison lemma and (7),

                                                                  ( T )2
                             T  (,  ) =  T  -  -2                          .
                                                                1 +  -2 T 
Using (7) and the matrix determinant lemma,

                           det(( (,  ))-1 ) = (1 +  -2 T ) det(-1 ),

and therefore with mutual information, using,

                     ln(det(( (,  ))-1 )) - ln(det(-1 )) = ln(1 +  -2 T ).

With Fisher information, using (7),

                                tr(( (,  ))-1 ) - tr(-1 ) = tr( -2 T )
                                                                =  -2 ||2 .

Note that in what follows we will assume (  )-2 > 0 (i.e. that the agents acquire information).
With mutual information, the agents will never find it optimal to choose   = 0, and we will
show below that this is also true with the Fisher information cost.



                                                      50
     The optimal action with mutual information described by (6) follows from standard
Bayesian updating (the fact that  =  is known in the literature, and follows from the first-
order condition of (9)). In this case,

                                              (  )-2 T 
                                      =                    < 1.
                                             (  )-2 T  + 1

We can rewrite (9) as
                                   max -( T  ) -  ln(1 -  ),
                                   [0,1]

noting that  = 1 will never be optimal. The first order condition yields

                                            
                                              - ( T  )  0,                                 (40)
                                         1 - 
with equality if  > 0. We conclude that  is continuous in  .
     From H´
           ebert and Woodford [2020], the optimal action with Fisher information described by
(6) simplifies to
                                                      1
                                             =  2 | |(  )-2 .

This could also be derived from the first-order condition characterizing  . Note here that our
normalization of  and  is different from the one used in H´ebert and Woodford [2020]. Let the
                                                         1                   1
H´
 ebert and Woodford [2020] parameters be    ^ = | |  2  and 
                                                   - 1 -
                                                                 ^ = | |-1 - 2  , noting that a
factor of two is omitted due to a difference in the definition of . The above equation follows
from H´
      ebert and Woodford [2020] and
                                                         1
                                               )-2 = | | 2  -2 .
                                           ^ (^
                                           

     The optimal value of (  )-2 satisfies, by H´
                                                ebert and Woodford [2020],

                                     |(-1 + -1 ^ -2 I )-1  |2  ,

with equality if the signal is informative. If the signal is informative, this is

                                   |(-1 + | |2 (  )-2 I )-1  |2 = ,

or
                                                  1
                                    |(-1 + - 2 | | I )-1  |2 =                             (41)

It follows that
                                              1
                                         |(- 2 | | I )-1  |2 > ,

which is
                                                   < 1.

If the signal is uninformative,  = 0. It follows that  is continuous in  .

                                                          51
    Equilibrium requires that
                                      = (1 -  )e1 +   ,
            1
where e1 = 0 . For both mutual information and Fisher information,  and  are continuous
in  under the optimal policies. It follows that this equation can be understood as a continuous
fixed point problem in  . Because  < 1 in both cases and   (0, 1), this fixed point problem
defines a mapping from the unit sphere to the unit sphere. By Brouwer's fixed point theorem,
a fixed point exists, and this fixed point characterizes an equilibrium of our linear-quadratic
game.
    In the case of mutual information, the fixed point satisfies

                                       = (1 -  )e1 +  ,

and it immediately follows that the second element of  (¯ r ) must be zero.
    In the case of the Fisher information cost, from H´
                                                      ebert and Woodford [2020] we have
(assuming some information is gathered)

                                    ^ = (-1 + (^
                                                )-2 I )-1 ,                                   (42)

where I is the identify matrix. Note that this could also be derived from the first-order condition
of (10).
    It follows immediately that ¯ r = 0 cannot be a fixed point if r and s are correlated, provided
that some information is gathered. If it were, we would require that the second element of  was
zero, and hence that the second element of  is zero. But the off-diagonal element

                                        (-1 + (^
                                                )-2 I )-1

will be zero if and only if r and s have zero correlation under .
    No information will be gathered with the Fisher information cost if | |  . In this case, we
must have  = (1 -  )e1 , and therefore a sufficient condition to ensure information gathering is

                                                     
                                          |e1 | >      .
                                                    1-

11.2       Proof of Proposition 2
                                         2 T , we can simplify (9) and (11). Conjecture that
With the degenerate covariance matrix  = 0
T  = 0, so that our normalization is innocuous. In this case, we have

                                    ( T )2                         4 T
                                                              -2 0 ( )
                                                                         2
                     T  -  -2                =  2
                                                0 (  T
                                                        )2
                                                           -         2  -2 ,
                                  1 +  -2 T                      1 + 0



                                                52
which does not depend on . In the mutual information case,

                           C ( ) =  ln(1 +  -2 T ) =  ln(1 + 0
                                                             2 -2
                                                                ),

as stated in the text. Hence it follows that the choice of  is irrelevant in this case, and it is
without loss of generality to assume    (which is the limit from the non-degenerate case).
   With the Fisher information cost, the agent solves

                                      C ( ) = min
                                               T
                                                   -2 ||2 ,
                                                 : =1


which is  = ||-2 . Note that this is also the limit of the non-degenerate case (as can be seen
from (12) or the explicit solution in (42)). Plugging this into the cost yields

                                     C (, ¯ s ) =  -2 ||-2
                                                =  -2 (1 +  2 -1
                                                           ¯s ) .

   Let us consider the fixed point that defines equilibrium. We have (as in the text)

                                 a
                                 ¯=¯ s s =  ( )T x =  ( )T s,

and therefore by our normalization

                                           ¯ s =   [0, 1).
                                           

   By equations (40) and (41) in the proof of Proposition 1,  is continuous in . This implies
equilibrium existence with either cost function. That is, given a ¯ s  [0, 1], there exists a best
response   [0, 1], continuous in ¯ s , and therefore by Brouwer's fixed point theorem a fixed
point exists. A sufficient condition for the Fisher information case to involve information-
                    ebert and Woodford [2020], | | > . To rule out equilibrium in which
gathering is, from H´
¯ s = 0, it is therefore sufficient to assume


                                                2      
                                                0 >      .
                                                      1-

   By the argument in the text (i.e. that the social planner would choose a mean-consistent ¯s
even if not required to), in the mutual information case the planner solves

                                        max      V (, ¯ s ) - C ( ),
                                       0,¯ s R

which is also an equilibrium of the problem in which the agents solve

                                        max V (, ¯ s ) - C ( )
                                          0



                                                    53
and ¯ s is determined by mean-consistency. Observe also that by the definition of the utility
function, (1), V (, ¯ s ) is strictly concave in ¯ s and diverges to negative infinity as ¯ s diverges.
Therefore, a maximizer exists and is unique.              It follows immediately that in the mutual
information case, assuming it is optimal to choose a finite  (gather some information), a
solution exists and is also an equilibrium. Note that our normalization was without loss of
generality, as
                                    T   T  = 1 -  +  ¯  > 0.

   Now consider the Fisher information cost case. In any equilibrium ( , ¯ s ), we must satisfy
mean-consistency. It follows that, assuming ( )-2 > 0,

                                                                 -2
                      [V ( , ¯ s ) - C (, ¯ s )]|¯ s =¯ s = 2 ( ) (1 + (¯ s )2 )-2 (¯
                                                                                    s ).
                   ¯s

Hence the equilibrium will be the solution to the planner's problem if and only if ¯ s = 0, but for
 sufficiently small, ¯ s > 0.


11.3     Proof of Lemma 1
We begin with the following observation: suppose that for some ,   V A and aggregate action
function ¯A  ¯,
                                  ( |s, r, ¯ (s, r)) =  ( |s, r, ¯ (s, r)).

for all (s, r)  S × R, and   . It immediately follows by (20) and (21) that

                    {, µ} ( ) =                 ( |s, r, a              a-
                                                         ¯) µ0 (s, r)  (¯ ¯ (s, r)) da
                                                                                     ¯
                                          ¯
                                    sS,rR A

                                =            ( |s, r, ¯ (s, r)) µ0 (s, r)
                                    sS,rR

                                =            ( |s, r, ¯ (s, r)) µ0 (s, r)
                                    sS,rR
                                =  { , µ}.

Similarly, by (20) and (22),

                                          ( |s, r, a              a-
                                                   ¯) µ0 (s, r)  (¯    ¯ (s, r))
                    µ {, µ} (s, r, a
                                   ¯) =
                                                       {, µ} ( )
                                          ( |s, r,                       a-
                                                   ¯ (s, r)) µ0 (s, r)  (¯    ¯ (s, r))
                                       =
                                                          {, µ} ( )
                                          
                                       = µ { , µ} (s, r, a¯) .




                                                     54
11.4     Proof of Proposition 3
Invoking the results of Lemma 1, it is without loss of generality to assume that  A  V0
                                                                                      A.

                                                                                    A is a finite
   By the finiteness of S × R and by the compactness for A (Assumption 1), the set V0
set of measures on the compact subsets of RL (i.e. A). Consequently, by Prokhorov's theorem,
                                         A is compact. Therefore, maxima exist; note also that
using the topology of weak convergence, V0
 A is non-empty and does not depend on 
V0                                     ¯.
   Individual optimality requires that

                    A  max
                         A
                                                            ui aj , a
                                                                    ¯, s  aj |s, r, a
                                                                                    ¯ daj µ (s, r, a
                                                                                                   ¯) da
                                                                                                       ¯
                             V0         ¯               i
                                  sS,rR A           A

                                   - C A (, µ) ,

          ¯ {µ0 , 
where µ = A       ¯ } as defined in (20), and mean consistency requires that


                       aj  A (aj |s, r, ¯ i (s, r))daj = ¯ i (s, r)          s  S, r  R s.t. µ0 (s, r) > 0.
               A   i


   We apply the Theorem of the Maximum and Kakutani's fixed point theorem in the usual
fashion. Observe by continuity of u (Assumption 1), and by continuity of C (Assumption 3), that
the objective function of the individual agent's problem is continuous in (, ¯ ). Consequently,
we can invoke the theorem of the maximum. It follows that the agent's optimal policy
correspondence A : A¯  V A is non-empty, upper semi-continuous, and compact-valued.
                                         0
By the concavity of the objective function (due the convexity of the cost function, Assumption
2), the optimal policy correspondence is convex.
                 ¯ is the set of possible aggregate actions 
     Recall that A                                                    ¯. Let a
                                                            ¯ : S ×R  A          ¯ be an arbitrary
                                                                             ¯0  A
value in A¯. Define the function f : V A  A   ¯ by
                                                0


                                             f ( ) =             ai  (aj |s, r, a
                                                                                ¯0 )daj .
                                                             A

                                                                                       A.
                                                                             ¯0 for   V0
Observe that f is continuous and linear in  , and does not in fact depend on a
   Define the correspondence F : A   ¯  A    ¯ by composing the correspondences A and the
function f ,
                                                       ) = f (A (¯
                                                    F (¯         )).

By the upper semi-continuity of A and continuity of f , F is upper semi-continuous. By the
non-emptiness of A , F is non-empty. By the convexity of A and the linearity of f , F is convex.
   By the finiteness of S × R and the fact that A¯  RL , A   ¯ is isomorphic to a subset of
R|S |×|R|×L . Consequently, by Kakutani's fixed point theorem, there exists a fixed point of the
correspondence F . This fixed point ¯  , along with the best response A (¯
                                                                          )  V0
                                                                              A , constitute a

symmetric BNE.


                                                                    55
11.5     Proof of Lemma 2
Part (i). By definition,

                                  r R (( |s, r , a
                                                 ¯) µ (s, r , a
                                                              ¯))                  ¯ 
        R {, µ}( |s, r, a
                        ¯) =                                      , s  S, r  R, a
                                                                                ¯  A,
                                      R {µ} (s, a  ¯)
and observe that this signal structure does not condition on r.
   Given this signal structure, the unconditional probability of observing    satisfies

                      {R {, µ}, µ} ( ) =                    R {, µ}(s, r, a
                                                                          ¯)µ(s, r, a
                                                                                    ¯)da
                                                                                       ¯
                                                    ¯
                                              sS,rR A

                                          =            R {, µ}{s, a
                                                                  ¯}R {µ}(s, a
                                                                             ¯)da
                                                                                ¯
                                                   ¯
                                                   A
                                              sS

                                          =                   |s, r , a
                                                                      ¯ µ s, r , a
                                                                                 ¯ da
                                                                                    ¯
                                                    ¯
                                              sS,rR A

and therefore
                             {, µ} =  {R {, µ}, µ},               V  , µ  U .                  (43)
   Let µ  µ {R {, µ}, µ}, which is
                                              R {, µ} ( |s, r, a
                                                               ¯) µ (s, r, a
                                                                           ¯)
                              µ (s, r, a
                                       ¯) =                                   ,
                                                  {R {, µ}, µ} ( )
and note that for all   ,
                                          rR R {, µ} ( |s, r, a
                                                              ¯) µ (s, r, a
                                                                          ¯)
                      R {µ } (s, a
                                 ¯) =
                                               {R {, µ}, µ} ( )
                                             ( |s, r, a
                                                      ¯) µ (s, r , a
                                                                   ¯)
                                     = rR
                                               {, µ} ( )
                                           
                                     = R {µ } (s, a
                                                  ¯)
                                       R {, µ} ( |s, r , a
                                                         ¯) R {µ} (s, a
                                                                      ¯)
                                     =                                   r  R,
                                             {R {, µ}, µ} ( )
where the last equality follows from the fact that R {, µ} ( |s, r , a
                                                                     ¯) does not condition on r.
   We now apply the composition operator R : U × U  U defined in (31). This operation that
coarsens its first argument in r, then embeds using the conditional distribution of its second
argument. Applying this operator to µ , we have
                                                   µ (s, r, a
                                                            ¯)
                           R {µ , µ} (s, r, a
                                            ¯) =                 R {µ } (s, a
                                                                            ¯) ,
                                                   R {µ} (s, a¯)
and therefore
                                                  µ (s, r, a
                                                           ¯)
                           R {µ , µ} (s, r, a
                                            ¯) =                R {µ } (s, a¯)
                                                 R {µ} (s, a ¯)
                                                 R {, µ} ( |s, r, a¯) µ (s, r, a
                                                                               ¯)
                                               =
                                                      {R {, µ}, µ} ( )
                                                  
                                               = µ (s, r, a
                                                          ¯).


                                                       56
By R-monotonicity,
                           D (µ ||µ)  D (R {µ , µ}||µ) = D µ ||µ ,

and combining this with (43), we conclude that

                                   C   , µ  C  (R {, µ}, µ) ,

as required.
   Part (ii). We prove the "only if" by contradiction. Suppose there exists µ0 , µ1  U with
R {µ1 }     R {µ0 } such that

                                  D (µ1 ||µ0 ) < D (R {µ1 , µ0 }||µ0 ) .

Define  = {1 , 2 } and define, for         > 0 sufficiently small, the signal structure   V  as
follows
                                                           R {µ1 } (s, a
                                                                       ¯)
                                 (1 |s, r, a
                                           ¯) =  (1 )
                                                           R {µ0 } (s, a
                                                                       ¯)
and
                                                            R {µ1 } (s, a
                                                                        ¯)
                            (2 |s, r, a
                                      ¯) =  (2 ) 1 -                               ,
                                                            R {µ0 } (s, a
                                                                        ¯)
where  (·) is the Dirac delta function. Note that this signal structure does not condition on r,
and that
                                                                  r R µ1 (s, r ,a¯)
                        R {µ1 , µ0 } (s, r, a
                                            ¯) = µ0 (s, r, a
                                                           ¯)
                                                                  r R µ0 (s, r , a
                                                                                 ¯)
Therefore
                                                        R {µ1 , µ0 } (s, r, a
                                                                            ¯)
                             (1 |s, r, a
                                       ¯) =  (1 )
                                                           µ0 (s, r, a¯)
and
                                                         R {µ1 , µ0 } (s, r, a
                                                                             ¯)
                         (2 |s, r, a
                                   ¯) =  (2 ) 1 -                                      .
                                                            µ0 (s, r, a¯)
Note also that  ( , µ0 )(1 ) = and  ( , µ0 )(2 ) = 1- , by construction. Posteriors are therefore

                            µ1 { , µ0 } = R {µ1 , µ0 } ,
                                           1
                            µ2 { , µ0 } =     µ0 -       R {µ1 , µ0 } .
                                          1-          1-

   Now consider instead an alternative signal structure   V  , defined by

                                                            µ1 (s, r, a
                                                                      ¯)
                                  (1 |s, r, a
                                            ¯) =  (1 )                   ,
                                                            µ0 (s, r, a
                                                                      ¯)

                                                                µ1 (s, r, a
                                                                          ¯)
                             (2 |s, r, a
                                       ¯) =  (2 ) 1 -                          .
                                                                µ0 (s, r, a
                                                                          ¯)



                                                   57
By construction,

                                                   R {µ1 } (s, a
                                                               ¯)
                   R { , µ0 }(1 |s, r, a
                                       ¯) =  (1 )                 =  (1 |s, r, a
                                                                               ¯) ,
                                                   R {µ0 } (s, a
                                                               ¯)
                                                       R {µ1 } (s, a
                                                                   ¯)
                   R { , µ0 }(2 |s, r, a
                                       ¯) =  (2 ) (1 -                ) =  (2 |s, r, a
                                                                                     ¯) ,
                                                       R {µ0 } (s, a
                                                                   ¯)

and therefore R { , µ0 } =  . Posteriors given  are given by

                                                µ1  , µ0 = µ1

                                               1
                                     µ2  , µ0 =   µ0 -    µ1 ,
                                             1-        1-
and again  ( , µ0 )(1 ) = and  ( , µ0 )(2 ) = 1 - .
   The cost of signal structure  is given by

        C ( , µ0 ) = D (R {µ1 , µ0 } ||µ0 ) + (1 - ) D         µ0 -         (R {µ1 , µ0 } - µ0 ) µ0 ,
                                                                      1-

and the cost of signal structure  is likewise given by,

                   C  , µ0 = D (µ1 ||µ0 ) + (1 - ) D           µ0 -         (µ1 - µ0 ) µ0 .
                                                                      1-

Now consider the difference between these two cost structures:

                                      f ( )  C  , µ0 - C ( , µ0 ) .

By assumption, D (µ ||µ0 ) is differentiable with respect to µ at µ = µ0 , and the gradient must
be zero by the definition of the divergence. Therefore, f ( ) is differentiable with respect to at
 = 0+ and
                           f ( )|   =0+   = D (µ1 ||µ0 ) - D (R {µ1 , µ0 } ||µ0 ) < 0.

But we must have that
                                    C   , µ0 - C  R { , µ0 }, µ0  0

for all feasible      0, and f (0) = 0 (both signal structures are uninformative in the limit),
a contradiction. We conclude that no such (µ0 , µ1 ) exists, and therefore that D satisfies R-
monotonicity.


11.6     Proof of Proposition 4
The proof is essentially identical to our existence proof (Proposition 3), and we will refer to the
existence proof (Proposition 3) rather than repeat most of the arguments. Let A   ¯S  A   ¯ denote
                                                     A  V A denote the set of signal structures
the subset of  functions that are s-measurable. Let VAR
                                                     ¯
who distributions do not in fact depend on ror a
                                               ¯.

                                                        58
   By Lemma 2 (characterizing R-monotonicity) and Lemma 1, the optimality policy
                                                                            ¯S (inducing s-
correspondences A (defined in the proof of Proposition 3) are mappings from A
                       A . By construction, the functions f defined in the proof of Proposition
measurable priors) to VAR
                       ¯
                                    A to functions that are measurable on s. Consequently,
3 map conditional distributions in VAR
                                    ¯
                                                                  ¯S to A
the mapping F defined in the proof of Proposition 3 is a map from A     ¯S .
   The arguments for the upper semi-continuity, non-emptiness, and convexity of F apply
                                                                            ¯S exists, and this
unchanged from the proof of Proposition 3. It follows that a fixed point in A
fixed point constitutes an s-measurable equilibrium.


11.7     Proof of Proposition 5
The "if" part of the proposition is implied by Proposition 4. We therefore focus on the "only-if."
To prove this result, we use the following lemma:

Lemma 4. Suppose the divergence D is not monotone in R on the set of s-measurable priors
U s-meas (µ0 ). Then there exists an s-measurable, mean-consistent ( A  V A ,    ¯) such that
                                                                              ¯  A             0
A   has finite support, and a   ^A
                                         A
                                        V0   such that   A    =   R {^A , A
                                                                          ¯ {µ0 , ¯ }}   and

                                C A (^
                                      A , A
                                          ¯ {µ0 , ¯ }) < C A ( A , A
                                                                   ¯ {µ0 , ¯ }).

Proof. See the appendix, 11.8.

    The only-if direction of the proposition requires that if D is not monotone in R on the set
of s-measurable priors, there exists a utility function satisfying Assumption 1 such that no s-
measurable equilibrium exists. Armed with this lemma, we take as given the s-measurable,
mean-consistent ( A , ¯ ) described in the lemma, along with the alternative ^A , such that

                                C A (^
                                      A , A
                                          ¯ {µ0 , ¯ }) < C A ( A , A
                                                                   ¯ {µ0 , ¯ }).

Note that if such an inequality holds, it holds by continuity for some prior µ0 with full support
on S × R.
    We will construct a utility function with the property that, if an s-measurable equilibrium
were to exist, it could only exist in the neighborhood of this ( A , ¯ ). Let A be the finite set of
actions that occur with positive probability under  A . Choose an arbitrary function  : S  R,
and define, for all a  A ,
                                                                           a ||µ)}(s, r, 
                                                 rR µ0 (s, r )1 {D (µ                    ¯ (s, r))
            u
            ~(a, ¯ (s, r0 ), s) = D(µa ||µ) +                                                        + (s),
                                                                    rR µ0 (s, r )

          ¯ {µ0 , 
where µ = A       ¯ }, µa = µa { A , µ}, and 1 denotes the gradient with respect to the first
argument. This is the first-order condition associated with choosing  A among all s-measurable
   A , and by the convexity of the cost function it is sufficient for optimality.
  V0

                                                         59
   We extend the utility function u                    ¯ using, for all a  A ,
                                  ~ to other values of a
                                                                                    
          ~(a, a
          u            ~(a, 
               ¯, s) = u    ¯ (s, r0 ), s) - (a - ¯ (s, r0 ))T · (¯
                                                                  a-¯ (s, r0 )) +      ¯-
                                                                                      |a ¯ (s, r0 )|2 .
                                                                                    2
We extend this utility function to other actions a  A \ A by defining

                                 u
                                 ~(a, a
                                      ¯, s) = min u     ¯, s) - |a - a|2 .
                                                  ~(a , a
                                                a A

By construction, all actions not in A are dominated by some action in A . Consequently, with
this utility function, any optimal policy will have support only on A .
   The utility function u
                        ~ is not differentiable at certain points. However, we can define a
mollified version of it,
                                u (a, a
                                      ¯, s) =        (a - a)~
                                                            u(a , a
                                                                  ¯, s)da ,
                                                A
where  (z ) is a smooth symmetric kernel with full support on z <  . Setting  sufficiently small
ensures that, for some constant c that depends on the kernel,

                                 u (a, ¯ (s, r0 ), s) = u
                                                        ~(a, ¯ (s, r0 ), s) - c

for all a  A , and that u is continuously differentiable, while preserving the property that
actions not in A are dominated.
   It immediately follows that, given the utility function u , ( A , ¯ ) cannot be an equilibrium,
                                              A, 
and moreover there is no other s-measurable (~   ¯ ) that can be an equilibrium, because all
such signal structures are dominated by ^A .
   Let us now rule out equilibrium for other s-measurable  ¯. We claim that, for sufficiently
                                                          ~A
large values of , any equilibrium must lie in the neighborhood of ¯ (s, r0 ). To see this, suppose
that for some > 0,
                                         |~ (s, r0 ) - ¯ (s, r0 )| > .

Observe by the optimality of the actions in A and mean-consistency that any equilibrium value
of ~ (s, r0 ) - ¯ (s, r0 ) must lie in the span of {a - ¯ (s, r0 )}aA . For sufficiently large , for any
a  A such that (a - ¯ (s, r0 ))T · (¯
                                    a-¯ (s, r0 ))  0 will be dominated by an action a  A
with (a - ¯ (s, r0 ))T · (¯
                          a-¯ (s, r0 ) > 0. As a result, under any optimal policy, only the latter
category of actions will be chosen, but this contradicts mean-consistency. We conclude that
any equilibrium ~ must be close to ¯ for sufficiently large .
   Now consider a sequence n with limn n = , and suppose that along this sequence
                                                               A, 
of utility functions there exists an s-measurable equilibrium (n  ¯ n ).                     By construction,
limn ¯n = ¯ . By the theorem of the maximum, the optimal policy correspondence for the
agents is upper semi-continuous (see the proof of existence, Proposition 3), and consequently
     A must be an s-measurable best response to 
limn n                                          ¯ . But we have already shown that no
such policy exists, and consequently for sufficient large  no s-measurable equilibrium exists.

                                                      60
11.8      Proof of Lemma 4
If D is not r-monotone on U s-meas (µ0 ), there exists an s-measurable    ¯, and µ  U with
                                                                       ¯  A
R {µ }     R {µ} such that

                            D(µ ||A
                                  ¯ {µ0 , ¯ }) < D(R {µ , A
                                                          ¯ {µ0 , ¯ }}||A
                                                                        ¯ {µ0 , ¯ })

    Observe that if this inequality holds, it holds by continuity for some µ that is mutually
absolutely continuous with µ on S (R {µ }  R {µ}). Similarly, such an inequality must hold
for some ¯ function whose image is strictly in the interior of A and that is non-degenerate. To
streamline the proof, we will assume without loss of generality that µ0 has full support on S × R.
               ¯ {µ0 , 
    Define µ = A       ¯ } and µ = R {µ , µ}, and observe that we must have A
                                                                            ¯ {µ } = µ0 .
Define the actions

                                        a1 =                     ¯ {µ }(s, r ),
                                                         ¯ (s, r)A
                                                 sS,rR

                                        a0 =             ¯ (s, r)µ0 (s, r).
                                                 sS,rR

Note that, under the interiority assumption on ¯ , a1 and a0 are interior, and by continuity it is
without loss of generality to assume they are not equal to each other.
    Now define a shifted ¯ function,
                                ¯ {µ }(s,r )
                                A µ0 (s,r)                                              (1 - )
~ (s, r) = ¯ (s, r)+         ¯ {µ }(s,r )
                                                         (s, r)-a1 )+
                                                        (¯                         ¯ {µ }(s,r )
                                                                                                              (s, r)-a0 )
                                                                                                             (¯
                       1-    A µ0 (s,r)     - (1 - )                     1-        A µ0 (s,r)     - (1 - )

for some > 0 and   (0, 1). By the interiority of the image of ¯ , for sufficiently small , ~ (s, r)
remains in A. By the fact that ¯ is s-measurable and µ = R {µ , µ}, ~ (s, r) is s-measurable.
    Define Aext as the set of extreme points A, and define A = Aext  {a0 , a1 }. Because a0 and
a1 are interior, they are not extreme points and hence not in Aext .
    By definition, every value in the image of ~ is a unique convex combination of elements of
Aext . Consequently, there is a unique measure ~A  V0 A such that, for each (s, r )  S × R, and an

              ¯, 
          ¯0  A
arbitrary a      ~A has support entirely on Aext and that satisfies

                                                a~A (a|s, r, a
                                                             ¯0 )da = ~ (s, r).
                                            A

Moreover, because ~ is s-measurable, ~A does not condition on r.
    Now define the signal structure
                                              A ¯ {µ }(s, r )
                        A (a|s, r, a
                                   ¯0 ) = (1 -                          A (a|s, r, a
                                                              - (1 - ))~           ¯0 )
                                                 µ0 (s, r)
                                          ¯ {µ }(s, r)
                                       +  A             (a1 - a) + (1 - ) (a0 - a)
                                           µ0 (s, r)

                                                            61
By construction,
                                        a A (a|s, r, a
                                                     ¯0 )da = ¯ (s, r),
                                    A

and the posterior associated with the signal a1 is (because a1 / Aext ) equal to µ . Similarly, the
posterior associated with a0 is the prior.
   Moreover, because ¯ does not condition on r, and because by definition

                                ¯ {µ }(s, r )
                                A               ¯ {R {µ , µ}}(s, r)
                                              = A
                                 µ0 (s, r)         A¯ {µ}(s, r )


does not depend on r,  A does not condition on r.
   Now observe by the convexity and differentiability of the divergence that

                           D(µ ||µ)  D(µ |µ) + (µ - µ ) · 1 D(µ |µ),

where 1 is the gradient with respect to the first argument. It follows by assumption that

                                    (µ - µ ) · 1 D(µ |µ) < 0.

   Let µa = µa { A , µ} be the posteriors associated with the signal structure  A , and let  { A , µ}
be the unconditional probabilities. Now consider a new set of unconditional probabilities and
posteriors, defined by ^ (a) =  { A , µ}(a) for a  A and
                                   a
                                  µ                     a / {a0 , a1 }
                                a     µ +    ( µ - µ )  a = a1
                              µ
                              ^ =
                                  µ -   (µ - µ ) a = a .
                                          1-                 0


Observing that ^ (a0 ) = (1 - ) and ^ (a1 ) = , this set of unconditional probabilities and
posteriors is Bayes-consistent with the prior µ. The resulting signal structure conditions on r,
because µ = µ . Define this signal structure as ^ . Considering the derivative, we have

                            A
                                , µ) = (µ - µ ) · 1 D(µa1 |µ)
                            C (^
                           
                                        
                                     -    (µ - µ ) · 1 D(µa0 |µ)
                                       1-

Evaluating at  = 0+ ,

                         A
                             , µ)| =0+ = (µ - µ ) · 1 D(µ |µ)) < 0.
                         C (^
                        
Hence it follows by convexity that for all  > 0,

                                        C A (^
                                              , µ) < C ( A , µ),

completing the proof.

                                                    62
11.9     Proof of Proposition 6
Suppose that in a neighborhood of some µ0  U0 , there generically exists an s-measurable
equilibrium. For each µ in this neighborhood, let         ¯ denote the corresponding s-
                                                  ¯ (µ )  A
                              0                                            0
measurable aggregate strategy. By the definition of generic R-non-monotonicity, agents must
respond to almost all (µ0 , ¯ (µ0 )) by choosing some  A  V A such that either the distribution
of ai  A depends on r or the signal structure is uninformative. But in the former case the
equilibrium cannot be s-measurable. Consequently, generically in all such neighborhoods,
either equilibria are not s-measurable or equilibria are deterministic.


11.10      Proof of Proposition 7
Our proof is almost identical to that of Proposition 3. By equation (25), B A (  ) is convex
                                                             A (i.e. like V A in the proof of
and compact (in the topology of weak convergence) subset of V0             0
Proposition 3). To adapt the proof of Proposition 3 to the exogenous information case, suppose
that the information cost function is C A (0 , µ) = 0, which is continuous and convex. The
remainder of the proof applies unchanged.


11.11      Proof of Proposition 8
Note that  A (ai |s, r, a
                        ¯) =  A (ai |s, r, a
                                           ¯0 ) for all ai  A, s  S, r  R, and a      ¯, by the
                                                                                  ¯0  A
                                                                               ¯, a
assumption that    V0
                     . We prove that



                            u(ai , a
                                   ¯, s) = g (ai ; s) + G(¯
                                                          a; s) + (ai - a
                                                                        ¯) · G(¯
                                                                               a; s)

with G convex and twice-differentiable and u concave in a
                                                        ¯, is sufficient.
   Consider the Lagrangean version of the planner's problem (Definition 11), substituting in
the mean-consistency constraint,

                            sup                       g (ai ; s) A ai |s, r, a
                                                                             ¯0 dai µ0 (s, r)
                        B ( ) sS,rR
                        A     A                   A


                                     +           µ0 (s, r)G(        aj  A aj |s, r, a
                                                                                    ¯0 daj ; s),
                                         sS,rR                  A


          ¯ is arbitrary.
      ¯0  A
where a
   Observe that any solution to the problem remains optimal if we replace g (ai ; s) with its
                                                           ^(ai ; s). Any action a in the support
concavification (see, e.g., Kamenica and Gentzkow [2011]), g
of the optimal policy  A must satisfy, if it is interior,

                        ^a (aj ; s) A aj |s, r, a
                        g                                                  (s, r); s) = 0,
                                                ¯0 µ0 (s, r) + µ0 (s, r)G(¯
                sS,rR


                                                           63
where ¯  (s, r) is the aggregate strategy associated with the solution to the planner's problem. If
ais on the boundary of A defined by the hyperplane a · x  b, the necessary condition is

                z·(            ^a (aj ; s) A aj |s, r, a
                               g                                                  (s, r); s))  0
                                                       ¯0 µ0 (s, r) + µ0 (s, r)G(¯
                     sS,rR


for any z  RL with z · x > 0.
    These necessary conditions are exactly the necessary and sufficient conditions in the
concavified version of the agent's problem, taking ¯  (s, r) as given. It follows immediately that
there exists a solution ( A , ¯  ) that is both optimal in the planner's problem and for which  A
is a best-response to ¯  . Therefore, there exists a constrained efficient symmetric BNE.


11.12         Proof of Proposition 9
We will use rely on the following lemma, which characterizes two useful properties of the set
Ace .

Lemma 5. The set Ace is a convex subset of A. For any a1 , a2  Ace and   [0, 1], there exists a
finite set R, prior µ0  U0 , and signal structure    V0
                                                       such that there exists a solution to the

planner's problem ( A , ¯ ) such that, for some s  S and r  R,  A is a two-point distribution on
a1 and a2 ,
                               A (ai |s, r, ¯ (s, r)) =  (ai - a1 ) + (1 - ) (ai - a2 ).

Proof. See the appendix, 11.13.

    Armed with this lemma, we prove necessity.                   Let us suppose that for all (µ0 ,   ), the
solution to the planner's problem coincides with the competitive equilibrium. By Assumption
5, in any symmetric BNE, agents will take interior actions for all realizations of their signals.
Consequently, this must be true in the solution to the planner's problem as well. Moreover, by
the strict concavity part of Assumption 5, in any symmetric BNE the best response to any signal
realization is unique. Consequently, this also applies in the planner's problem. Recall from
above that    V  does not condition on a ¯A   ¯.
                      0
    We can therefore write the planner's problem as

               sup         inf                     u ( j ), ¯ (s, r), s    j |s, r, a
                                                                                    ¯0 d j µ0 (s, r)
          A,  ¯  R|S |×|R|×L
            ¯ A                                 
                             sS,rR
                          L
                      +                                   l (s, r) -
                                       µ0 (s, r) l (s, r)[¯               ( j )   j |s, r, a
                                                                                           ¯0 d j ],
                          l=1 sS,rR                                    


where A    A is the set of action strategies. Note that we have scaled the multiplier by
µ0 (s, r) to denote that mean consistency need not hold for (s, r) not in the support of µ0 .

                                                         64
    The first-order condition for l ( j ) is

                                    u (a, ¯ (s, r), s)
                                                       |a=(j )    j |s, r, a
                                                                           ¯0 µ0 (s, r)
                                          al
                         sS,rR

                                            -           µ0 (s, r) l (s, r)   j |s, r, a
                                                                                      ¯0 = 0.
                                                sS,rR


Note that this must hold by the result that the optimal ( j ) is interior. The first-order condition
for ¯ l (s, r) is

                               u(( j ), a
                                        ¯, s)             
                                              |a
                                               ¯=¯ (s,r)    j |s, r, a
                                                                     ¯0 d j µ0 (s, r)
                                  a
                                  ¯l
                                                                    +µ0 (s, r) l (s, r) = 0,

and note that this also must be interior by mean consistency. In contrast, the private FOC for
al ( j ) is
                                    u (a, ¯ (s, r), s)
                                                       |a=(j )    j |s, r, a
                                                                           ¯0 µ0 (s, r) = 0,
                                          al
                         sS,rR

which again must hold because the optimal policy is interior. Consequently, because there
exists a symmetric BNE that coincides with the solution to the planning problem, we must have,
in any solution to the planner's problem,

                           u(( j ), a
                                    ¯, s)              
                                          |a
                                           ¯ =¯ (s,r)             ¯0 d j µ0 (s, r)   i |s, r, a
                                                         j |s, r, a                           ¯0 = 0           (44)
                              a
                              ¯l
              sS,rR


for all l  {1, . . . , L},  i  , and s  S, r  R such that µ0 (s, r) > 0.
    Suppose that, for some (µ0 ,   ) there exists a solution to the planner's problem ( A , ¯ ) such
that, for some s0  S and r0  R with µ0 (s0 , r0 ) > 0 and l  {1, . . . , L},

                                   u(( j ), a
                                            ¯, s)                 A
                                                  |a
                                                   ¯=¯ (s0 ,r0 )    aj |s0 , r0 , a
                                                                                  ¯0 daj = 0.
                               A      a
                                      ¯l

    By our assumption on the cardinality of , it is without loss of generality to suppose there
are elements of  that does not occur with positive probability under   . Consider a new signal
structure defined by

                                            ( |s, r, a
                                                     ¯0 )                               (s, r) = (s0 , r0 )
                      ( |s, r, a
                               ¯0 ) =             
                                          (1 - ) ( |s, r, a
                                                          ¯0 ) +  ( - 0 )               (s, r) = (s0 , r0 ).

Applying (44) to the model with this signal structure and the prior µ0 , in the case of the signal 0
we must have
                               u( ( j ), a
                                         ¯, s0 )                       
                                                 |a
                                                  ¯=¯     (s0 ,r0 )        j |s0 , r0 , a
                                                                                        ¯0 d j = 0,
                                   a
                                   ¯l


                                                            65
where  and ¯ satisfy

                   u (a, ¯ (s, r), s)                  
                                      |a=     ( i )        i |s, r, a
                                                                    ¯0 µ0 (s, r) = 0  l  {1, . . . , L},  i  ,
                         al
        sS,rR

and
                         ( i )  ( i |s, r, a
                                           ¯0 )d i = ¯ (s, r) s  S, r  R s.t. µ0 (s, r) > 0.
                     
Here, these should be understood as policies characterizing the solution to the planner's
problem given , and by assumption these solutions coincide with a symmetric BNE.
    Taking the limit as  0+ , we have by strict concavity and continuity of derivatives that

                                             lim   ( i ) = ( i )  = 0
                                             0  +



and lim   0+   ¯ (s, r) = ¯ (s, r). But this implies

                                   u( ( j ), a
                                             ¯, s0 )                        
                         lim                         |a
                                                      ¯=¯      (s0 ,r0 )        j |s0 , r0 , a
                                                                                             ¯0 d j = 0,
                         0  +
                                       a
                                       ¯l

a contradiction. It follows that, for all (µ0 ,   ) and associated solutions to the planner's problem
( A , ¯ ), we have

                   u(aj , a
                          ¯, s)              A
                                |a
                                 ¯ =¯ (s,r)    aj |s, r, a
                                                         ¯0 daj = 0 s  S, r  R s.t. µ0 (s, r) > 0.               (45)
               A     a ¯l

    Let us now invoke Lemma 5, and observe that one-point (degenerate)  A also exist, placing
all support on one a  Ace . It follows that we must have

                                                  u(a, a
                                                       ¯, s)
                                                             |a
                                                              ¯=a = 0,
                                                    a¯l

implying by concavity that for all s  S and a  Ace ,

                                               a  arg max  u(a, a
                                                                ¯, s).
                                                        ce ¯A
                                                           a

    Define the function
                                                ¯, s) = u(a, a, s) - u(a, a
                                          f (a, a                         ¯, s).

It follows immediately that
                                               a  arg min  f (a, a
                                                                 ¯, s),
                                                        ce ¯A
                                                           a

and f (a, a, s) = 0 by construction. Consequently, on the domain Ace × Ace × S , f (a, a
                                                                                       ¯, s) is a
weakly positive, continuously twice-differentiable function. Moreover, by mean-consistency,
(45), and Lemma 5, for all two-point measures   (Ace ),

                                         a(a)da  arg min                    f (a, a
                                                                                  ¯; s)(a)da.
                                   Ace
                                                       ce  ¯A
                                                           a        Ace


                                                              66
   By theorem 4 of Banerjee et al. [2005] (which is proven using only two-point measures; see
also the discussion in that paper on restrictions to subspaces of RL ), it follows that

                                 ¯; s) = G(a; s) - G(¯
                           f (a, a                   a; s) - (a - a
                                                                  ¯) · G(¯
                                                                         a; s).

Defining
                                           g (a; s) = u(a, a, s) - G(a; s)

proves the result.
   Note that by strict concavity and twice-differentiability of u, we have, for arbitrary vectors z ,

               2 u(a, a
                      ¯ + z, s)                         2 G(¯
                                                            a + z ; s)             2 G(¯
                                                                                       a + z ; s)
                                |   =0          ¯) ·
                                         = (a - a                      |   =0 -                   |   =0 ,
                     2                                     2                           2
and hence the gradient of G is twice-differentiable. Moreover, evaluating at a
                                                                             ¯ = a, we have

                                2 u(¯
                                    a, a
                                       ¯ + z, s)                  2 G(¯
                                                                      a + z ; s)
                                                 |     =0   =-                   |   =0
                                      2                               2
and therefore by strict concavity G is strictly convex.


11.13      Proof of Lemma 5
Let a1  Ace be an action that occurs in a constrained efficient symmetric BNE given prior
                   ) and non-fundamental states R , after agents observe signal  . Let a ,
and signals (µ1 , 1                              1                              1       2
       ), R , and  be another such set of objects. Suppose without loss of generality that R
(µ2 , 2    2      2                                                                          2
                                  and   use disjoint parts of the signal alphabet  (w.l.o.g.
does not intersect R1 , and that 1    2
due to our cardinality assumption on ). The actions a1 and a2 are associated with posteriors
µ1 = µ {1 , µ1 } and µ2 = µ {2 , µ2 }.
  1   1               2    2 

   Define a new set of states, R = R1  R2  {r0 }, and extend the distributions µ1 , µ2 , µ     2
                                                                                          1 , µ2 to
                                                                                           1



(S × R) by assigning zero probability any state not defined in the original distribution. Define
a new prior
                                  1         1
                           µ0, = ( - )µ1 + ( - )µ2 + 2 1(r = r0 , s = s0 )
                                  2         2
for some arbitrary s0  S . Define a new signal structure    V0
                                                              by, for arbitrary   [0, 1],

                                      
                                     1 ( |s, r, a¯0 )              r  R1
                      ( |s, r, a
                               ¯0 ) = 2 ( |s, r, a
                                                 ¯0 )              r  R2
                                       ( - 1 ) + (1 - ) ( - 2 ) r = r0 .
                                     

From this signal structure, it is immediately apparent that the posteriors µ {  , µ0, } converge
                                                                           , µ ) or (  , µ ). It
in the limit as approaches zero to the posteriors associated with either (1   1      2    2
follows that in this limit a solution to the social planner's problem conditional on r  R1 features
                                                             , µ ), and likewise for r  R with
actions that are identical to the solution associated with (1   1                        2


                                                            67
                               , µ ). Consequently, in this limit the action given  is a , and
the solution associated with (2   2                                                1    1
likewise with 2 and a2 . It follows immediately that in the planner's solution to the merged
problem,
                      lim   A aj |s0 , r0 , a
                                            ¯0 =  (aj - a1 ) + (1 - ) (aj - a2 ).
                      0  +


We conclude that given any pair (a1 , a2 ) from the set of actions that occur in a solution to the
planner's problem, any two-point distribution on these actions can occur in some equilibrium.
   Let us next demonstrate that Ace is convex. Consider the same setup as in the previous
argument, and suppose without loss of generality there is a signal 0   that does not occur
              or   . Let R = R  R and
under either 1   2            1  2

                                                  1    1
                                              µ0 = µ1 + µ2 .
                                                  2    2

Consider a signal structure   such that
                                                              , µ }( ) > 0
                            µ {1 , µ1 }                     {1   1
                                                              , µ }( ) > 0
              µ { , µ0 } = µ {2 , µ2 }                      {2   2
                             1 
                             µ {1 , µ1 } + (1 - )µ1 {1
                                                     , µ }  =  .
                                                        1      0

By Bayes' rule, such a signal structure exists with
                                      , µ }( )                    , µ }( ) > 0
                               
                                  {1     1               = 1 ,  {1   1
                                                                  , µ }( ) > 0
                                {2 , µ2 }( )             = 2 ,  {2
                               
                                                                     2
                               
               {  , µ0 }( ) =  {1     , µ }( ) - 
                                         1               = 1
                               
                                  {2  , µ }( ) - (1 - )  = 
                                         2                 2
                               
                                                         = 0
                               

for any sufficiently small.
   Now consider the socially optimal action after observing signal 0 in the limit as        0+ .
In this limit, the solution to the social planner's problem must converge to the aggregate action
strategies that are the solutions to the separate problems. By the strict concavity of the utility
function, the optimal action must be continuous in , and therefore by the intermediate value
theorem must traverse all points on the line segment between a1 and a2 . It follows that the set
of socially optimal actions is a convex set.


11.14      Proof of Lemma 3
By definition, for any µ0  U0 ,  ¯  A ¯,  A  V A , and µ  U such that µ =  ¯ {µ0 , ¯ }, and an
                                                0                         A
               ¯
          ¯0  A, the posterior after observing a  A is
arbitrary a

                                               A (a|s, r, a                a-
                                                          ¯0 ) µ0 (s, r)  (¯ ¯ (s, r))
                     µa { A , µ}(s, r, a
                                       ¯) =                     A
                                                                                       ,
                                                             { , µ} (a)



                                                     68
as described in the text. By the definition of A
                                               ¯ , (36),


                      a A                                          A (a|s, r, a
                                                                              ¯0 ) µ0 (s, r)
                  ¯ {µ { , µ}, A
                  A            ¯ {µ0 , ¯ }} =  (¯
                                                a-¯ (s, r))
                                                                       { A , µ} (a)
                                               = µa { A , µ }.

Consequently, for all µ  U and  A  V0
                                    A,



                          D(µa { A , µ}||µ) = D(A   a A
                                                ¯ {µ { , µ}, µ}||A
                                                                 ¯ {µ, µ}).


Note also that for all µ0  U0 and ¯,   ¯,
                                     ¯ A

                               ¯ {A
                               A  ¯ {µ0 , ¯ }, A
                                               ¯ {µ0 , ¯ }} = A
                                                              ¯ {µ0 , ¯ },

which implies by the definition of U that for all µ, µ  U ,

                                             ¯ {µ, µ } = µ .
                                             A

   With these results, we first prove sufficiency, then necessity.
                                  ¯, then by definition
   Part (i). If D is invariant in A

                        a A                             a A
                    ¯ {µ { , µ}, µ}||A
                  D(A                ¯ {µ, µ}) = D (A
                                                    ¯ {µ { , µ}, µ }||A
                                                                      ¯ {µ, µ })


for all µ, µ  U and  A  V0
                         A . It follows from the results above that


                           a A                               a A
                       ¯ {µ { , µ}, µ }||A
                     D(A                 ¯ {µ, µ }) = D (A
                                                         ¯ {µ { , µ}, µ }||µ )

                                                         = D(µa { A , µ }||µ ).

It immediately follows that for all µ0  U0 ,  A  V0
                                                  A , and ¯,   ¯,
                                                             ¯ A

               D(µa { A , A
                          ¯ {µ0 ,       ¯ {µ0 , 
                                  ¯ }}||A       ¯ }) = D(µa { A , A
                                                                  ¯ {µ0 , ¯ }}||A
                                                                                ¯ {µ0 , ¯ }),

and by the argument in the text

                                 { A , A
                                       ¯ {µ0 , ¯ }} =  { A , A
                                                             ¯ {µ0 , ¯ }}.

Consequently, by the definition of posterior separability, (23),

                              C A  A , A
                                       ¯ {µ0 , ¯ } = C A  A , A
                                                              ¯ {µ0 , ¯}

as required.
   Part (ii). Suppose that all µ0  U0 ,  A  V0
                                             A , and ¯,   ¯,
                                                        ¯ A

                              C A  A , A
                                       ¯ {µ0 , ¯ } = C A  A , A
                                                              ¯ {µ0 , ¯} .

                                                    69
It follows by the definition of posterior separability and the argument in the text that we must
have
                                   D(µa { A , µ}||µ) = D(µa { A , µ }||µ ).

But by the arguments above,

                           D(µa { A , µ}||µ) = D(A   a A
                                                 ¯ {µ { , µ}, µ}||A
                                                                  ¯ {µ, µ})


and
                       D(µa { A , µ }||µ ) = D(A   a A
                                               ¯ {µ { , µ}, µ }||A
                                                                 ¯ {µ, µ }),

and therefore
                      a A                             a A
                  ¯ {µ { , µ}, µ}||A
                D(A                ¯ {µ, µ}) = D (A
                                                  ¯ {µ { , µ}, µ }||A
                                                                    ¯ {µ, µ }).


Since this must hold for all µ, µ ,  A , D satisfies the definition of invariance.


11.15      Proof of Proposition 10
                                                                                   ¯,
                                                                               ¯0  A
Recall the definition of the planner's problem, applying Lemma 1 and using any a

         sup                    u ai ,                           ¯0 dai µ0 (s, r) - C A  A , A
                                       ¯ (s, r) , s  A ai |s, r, a                           ¯ {µ0 , ¯}
          A
        A V ,  ¯
             ¯ A            A
          0      sS,rR

subject to mean consistency.
   Now consider a relaxed version of the problem, without the mean consistency constraint.
Let ( A , ¯  ) denote a solution to the relaxed problem, which exists by our continuity
assumptions that guarantee compactness (see the proof of Proposition 3).
                                          ¯,
   Because D is invariant with respect to A

                                C A  A , A
                                         ¯ {µ0 , ¯ } = C A  A , A
                                                                ¯ {µ0 , ¯}

for all ¯,   ¯. Consequently,
           ¯ A

               ¯   arg max
                                              u ai , ¯ (s, r) , s  A ai |s, r, a
                                                                               ¯0 dai µ0 (s, r) .
                           ¯
                         ¯ A
                                          A
                                sS,rR

As shown in the proof of Proposition 8, given our assumptions on the utility function, ¯  satisfies
mean-consistency even though this was not imposed. We therefore conclude that the mean-
consistent symmetric strategy profile ( A , ¯  ) is a constrained-efficient (Definition 13) if it is
an equilibrium.
   By optimality in the relaxed problem,

  A  arg maxA                    u ai , ¯  (s, r) , s  A ai |s, r, a
                                                                   ¯0 dai µ0 (s, r) - C A  A , A
                                                                                               ¯ {µ0 , ¯} .
            A V0             A
                   sS,rR



                                                       70
It immediately follows that ( A , ¯  ) constitutes a symmetric BNE (Definition 3), proving the
result.
   By this argument, any symmetric BNE ( A , ¯ ) is a critical point of the social planner's
objective function. Consequently, if the social planner's problem is concave, all symmetric BNE
are constrained efficient. Define the function

                   f (¯
                       ) = maxA                      g (ai ; s) A ai |s, r, a
                                                                            ¯0 dai µ0 (s, r) - C A  A , A
                                                                                                        ¯ {µ0 , ¯}
                               A V0              A
                                      sS,rR

subject to µ(s, r)¯
                   (s, r) = µ(s, r)        g (ai ; s) A ai |s, r, a
                                                                  ¯0 dai , s  S, r  R,
                                       A

where g (a; s) is part of the functional form of the utility function. Observe that this constraint
set is convex in ¯ , and the objective does not depend on ¯ , and consequently f (¯
                                                                                   ) is concave.
   By the invariance of D and the functional form of the utility function, the social planner's
problem is
                               max f (¯ )+               µ0 (s, r)G(¯
                                                                    (s, r); s),
                                  ¯
                                ¯ A
                                
                                                sS,rR

noting that the term involving the gradient of G has vanished due to mean-consistency.
         ¯ (¯
Defining G   ) = -f (¯
                      ) proves the result.


11.16      Proof of Proposition 11
Let us assume that u satisfies the conditions of Proposition 8 and Assumptions 1 and 6, and let
U be the set of such functions. Endow this set with the topology of pointwise convergence.
   The social planner's problem is to solve

          sup                 u ai ,                           ¯0 dai µ0 (s, r) - C A  A , A
                                     ¯ (s, r) , s  A ai |s, r, a                           ¯ {µ0 , ¯}
      V ,
      A    ¯
           A
         ¯ A              A
           0 sS,rR

subject to mean consistency.
                                                                                    A is a
   By the finiteness of S × R and by the compactness for A (Assumption 1), the set V0
finite set of measures on the compact subsets of RL (i.e. A). Consequently, by Prokhorov's
                                                                                       ¯ and
theorem, using the topology of weak convergence, V A is compact. By the compactness of A
                                                              0
                         ¯ is compact, and it follows from the definition of mean-consistency that
the finiteness of S × R, A
the set of ( A , ¯ ) satisfying mean-consistency is compact. Therefore, a maximizing solution to
the social planner's problem exists for all u  U .
   We apply the Theorem of the Maximum. Observe by continuity of u (Assumption 1), and
by continuity of C (Assumption 3), that the objective function of the planner's problem is
continuous in (, ¯ ), and is continuous on U . Consequently, we can invoke the theorem of
the maximum. It follows that the planners optimal policy correspondence   : U  V A × A  ¯
                                                                                                       0
is non-empty, upper semi-continuous, and compact-valued.

                                                        71
   Let us suppose there is some u  U such, generically in a neighborhood around u, a non-
deterministic, constrained-efficient symmetric BNE exists. By Assumption 6, these equilibria
must involve interior actions.
                                                            ¯ implies that, generically in this
   We next show that generic non-invariance with respect to A
neighborhood, externalities exist. Define, for some arbitrary vector z  RL , a continuously
differentiable function f : A  A with the property that

                                             f (a) = a + z

for all a  A , and |f (a) - a|  |z | for all A. Because  A places support only on A , such a
function exists for sufficiently small .
   Now define the utility function

                      u (a, a
                            ¯, s) = u(f (a), a
                                             ¯, s)
                                                    a; s) + (f (a) - a
                                 = g (f (a); s) + G(¯                ¯)G(¯
                                                                         a; s),

By construction, µ  U , and lim    0 u     = u.
   Observe that in both the planner's problem and the competitive equilibrium, this
perturbation simply shifts the meaning of all relevant actions in the direction z , holding fixed
¯ . Consequently, holding fixed 
                                                               and    V  are identical,
                                ¯ , the optimal choice of    V0        0
but all actions are shifted in the direction z . However, this violates mean-consistency, and
consequently no (  , ¯ )    (u) can be an equilibrium with the utility function u . Similarly,
  (u ) and   (u ) must be disjoint for distinct , .
   By compactness and upper semi-continuity, there exists a convergent sequence of
constrained efficient symmetric BNE. By generic non-invariance we must have, along this
sequence we must have

                                j |s, r, a
                                         ¯ 0 ¯ {C
                                                  
                                                     , A
                                                       ¯ {µ0 , ¯ } }(s, r) = 0
                     sS,rR

for except at isolated values of . We conclude that this property holds generically in the
neighborhood of u.
   Let us next show that this creates a wedge between private and social incentives that rules
out constrained efficient equilibria. Consider the planner's problem, and observe also that it is
without loss of generality to equate signals with actions, and hence to assume there is a signal
action taken for each signal realization. We therefore rewrite the Lagrangean version of the
planner's problem as




                                                     72
             sup            inf                     u ( j ), ¯ (s, r), s    j |s, r, a
                                                                                     ¯0 d j µ0 (s, r)
            
        V ,A,
               ¯  R|S |×|R|×L
             ¯ A                                 
            0                 sS,rR

                       - C    , A
                                ¯ {µ0 , ¯}
                            L
                       +                µ0 (s, r)  l (s, r)[¯
                                                            l (s, r) -      l ( j )   j |s, r, a
                                                                                               ¯0 d j ],
                           l=1 sS,rR                                     


where A    A is the set of action strategies. Note that we have scaled the multiplier by
µ0 (s, r) to denote that the policy need not hold for (s, r) not in the support of µ0 .
    Recall that we have supposed that all utility functions in the neighborhood of u have
constrained-efficient, non-deterministic symmetric BNE, and therefore involve interior actions.
It follows that the first-order conditions are necessary.
    The planner's first-order condition for l ( j ) is

                                u (a, ¯ (s, r) , s)
                                                    |a=(j )    j |s, r, a
                                                                        ¯0 µ0 (s, r)
                                      al
                     sS,rR

                                        -           µ0 (s, r)  l (s, r)   j |s, r, a
                                                                                   ¯0 = 0.
                                            sS,rR

The first-order condition for ¯ l (s, r) is

                           u ( j ), a
                                    ¯, s              
                                         |a
                                          ¯ =¯ (s,r)    j |s, r, a
                                                                 ¯0 d j         µ0 (s, r)
                             a¯l
                                                         
                                                 -¯ l {C    , A
                                                              ¯ {µ0 , ¯ } }(s, r)
                                                                   +µ0 (s, r)  l (s, r) = 0,

why simplifies under the condition of Proposition 39 to

                           µ0 (s, r)  l (s, r) = ¯ l {C
                                                        
                                                           , A
                                                             ¯ {µ0 , ¯ } }(s, r).

In contrast, the private FOC for al ( j ) is

                                u (a, ¯ (s, r) , s)
                                                    |a=(j )    j |s, r, a
                                                                        ¯0 µ0 (s, r) = 0,
                                      al
                     sS,rR

Efficiency therefore requires

                      0=                j |s, r, a
                                                 ¯ 0 ¯ l {C
                                                            
                                                               , A
                                                                 ¯ {µ0 , ¯ } }(s, r)
                            sS,rR

for all  j  . But this is non-zero generically in the neighborhood of u, and therefore
generically all equilibria are either deterministic or inefficient.

                                                        73
