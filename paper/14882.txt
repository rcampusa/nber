                               NBER WORKING PAPER SERIES




  BAYESIAN AND FREQUENTIST INFERENCE IN PARTIALLY IDENTIFIED MODELS

                                      Hyungsik Roger Moon
                                       Frank Schorfheide

                                       Working Paper 14882
                               http://www.nber.org/papers/w14882


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                      April 2009




We thank seminar participants at the 2007 NASM, the 2008 SETA, Boston College, Johns Hopkins,
Ohio State, Rice, UC Davis, UC Irvine, UCLA, and Vanderbilt for helpful comments. Moon gratefully
acknowledges financial support from the USC Faculty Development Award. Schorfheide gratefully
acknowledges financial support from the Alfred P. Sloan Foundation and the National Science Foundation
under Grant SES 0617803. The views expressed herein are those of the author(s) and do not necessarily
reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2009 by Hyungsik Roger Moon and Frank Schorfheide. All rights reserved. Short sections of text,
not to exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including © notice, is given to the source.
Bayesian and Frequentist Inference in Partially Identified Models
Hyungsik Roger Moon and Frank Schorfheide
NBER Working Paper No. 14882
April 2009
JEL No. C11,C32,C35

                                              ABSTRACT

A large sample approximation of the posterior distribution of partially identified structural parameters
is derived for models that can be indexed by a finite-dimensional reduced form parameter vector. It
is used to analyze the differences between frequentist confidence sets and Bayesian credible sets in
partially identified models. A key difference is that frequentist set estimates extend beyond the boundaries
of the identified set (conditional on the estimated reduced form parameter), whereas Bayesian credible
sets can asymptotically be located in the interior of the identified set. Our asymptotic approximations
are illustrated in the context of simple moment inequality models and a numerical illustration for a
two-player entry game is provided.


Hyungsik Roger Moon
University of Southern California
Department of Economics
KAP 300
University Park Campus
Los Angeles, CA 90089
moonr@usc.edu

Frank Schorfheide
University of Pennsylvania
Department of Economics
3718 Locust Walk
McNeil 525
Philadelphia, PA 19104-6297
and NBER
schorf@ssc.upenn.edu
1    Introduction

In partially identified models one can only bound, but not point-identify the structural
parameter vector of interest, θ. Such models arise in many areas of economics. Prominent
examples in macroeconomics are structural vector autoregressions (VARs) and dynamic
stochastic general equilibrium (DSGE) models. In the VAR literature the identification
problem has traditionally be addressed by imposing enough restrictions on the structural
form such that the mapping between one-step-ahead forecast errors and structural shocks
becomes one-to-one. More recently however, Canova and De Nicolo (2002) and Uhlig (2005)
have developed more agnostic identification schemes that only restrict the signs of a subset
of impulse responses in the initial periods after the impact of the shock, which leads to
partially identified structural VAR. In DSGE models partial identification arises for instance
if a subset of structural parameters guarantees the uniqueness of a rational expectations
equilibrium but does not affect the equilibrium law of motion, e.g., Lubik and Schorfheide
(2004).

    Partially-identified models also percolate the microeconometric literature and include
censored sampling models and models for interval data, surveyed at length in Manski (2003).
Partial identification arises in models of industrial organization, for instance, in game-
theoretic models with multiple equilibria studied by Bresnahan and Reiss (1991), Berry
(1994), Halie and Tamer (2003), Pakes, Porter, Ho, and Ishi (2005), Bajari, Benkard, and
Levin (2007), and Ciliberto and Tamer (2007). Given the lack of point identification re-
searchers have rightly focused on set estimators for the parameter of interest. While the
macroeconometrics literature mostly applies Bayesian approaches, the microeconometric lit-
erature is dominated by frequentist procedures. The contribution of this paper is to compare
frequentist confidence sets and Bayesian credible sets, with a special focus on the properties
of Bayesian procedures.

    Starting point of our analysis is a likelihood function indexed by a finite-dimensional,
identifiable reduced-form parameter vector φ. Reduced-form and structural parameter are
linked through a correspondence, which we express as φ = G(θ, α), where α ∈ Aθ . The
presence of the nuisance parameter α complicates the inference about θ. We present a large
sample approximation of the posterior distribution of θ. The approximation is based on an
insight that dates back at least to Kadane (1974) and has recently been utilized, for instance,
by Poirier (1998): beliefs about the reduced form parameter φ are updated through the
likelihood function, but the conditional distribution of θ given φ remains unchanged in view
                                                                                             2


of new data. It is well known that under very general conditions the posterior distribution
of φ is asymptotically normal. We construct such a normal approximation for φ following
the analysis in Johnson (1970) and combine it with conditional prior distributions of θ given
φ to obtain our approximation of the posterior of θ. If H(φ, ξ) is the prior probability that
θ ∈ Tξ conditional on φ, then we show that under some regularity conditions an O(n−1/2 )
accurate approximation of the posterior probability is given by H(φ̂n , ξ), where φ̂n is the
maximum likelihood estimator of φ. This approximation implies there exist asymptotically
valid Bayesian credible sets inside the identified set of θ parameters associated with φ̂n ,
denoted by Θ(φ̂n ).

    There is a rapidly growing literature on the construction of asymptotically valid fre-
quentist confidence sets for θ, e.g. Manski and Tamer (2002), Imbens and Manski (2004),
Andrews, Berry, and Jia (2004), Pakes, Porter, Ho, and Ishi (2005), Rosen (2005), Galichon
and Henry (2006), Romano and Shaikh (2006), Woutersen (2006), Andrews and Guggen-
berger (2007), Andrews and Soares (2007), Canay (2007), Chernozhukov, Hong, and Tamer
(2007), Stoye (2007), and Beresteanu and Molinari (2008). The main challenge of this
literature is to obtain large sample approximations of the sampling distribution of an esti-
mation objective function or a test statistic that conditional on θ are uniformly valid for all
φ = G(θ, α), α ∈ Aθ . While we do not develop new methods to construct frequentist con-
fidence sets, we show that frequentist sets need to extend beyond the boundaries of Θ(φ̂n ).
Thus, we can deduce that in partially identified models, Bayesian credible sets tend to be
smaller than frequentist confidence sets. This finding is in contrast with the regular point
identified case, in which Bayesian and frequentist sets coincide in large samples.

    The remainder of the paper is organized as follows. In Section 2 we briefly review the
construction of Bayesian and frequentist set estimates for regular, point-identified models.
We then generalize the setup to models in which θ is set-identified and provide a simple
example of a partially identified model. The large sample approximation of the posterior of
θ and the construction of asymptotically valid credible sets for partially identified models
is presented in Section 3. In Section 4 we illustrate properties of the large sample approxi-
mation using simple moment inequality models. Section 5 provides a numerical illustration
in the context of an entry-game model and Section 6 concludes. Proofs are collected in an
Appendix.

    A word on notation. We often use M to denote a generic finite constant. When X is a
                           1/2
matrix, kXk = (tr (X 0 X))       denotes the Euclidean norm of X. We use N (µ, σ 2 ) to denote
a normal distribution with mean µ and variance σ 2 and φN (·) and ΦN (·) the probability
                                                                                             3


density (pdf) and cumulative density (cdf) functions of a vector of standard normal random
variables. Moreover, we denote the one-sided critical value for a standard normal random
variable by zτ = Φ−1
                  N (1 − τ ). U[a, b] denotes the uniform distribution on the interval [a, b].

We use Pba to denote a probability distribution of a random variable a conditional on the
realization of a random variable b. I{X ≤ ξ} denotes the indicator function that is equal to
one if X ≤ ξ and zero otherwise. Finally, the notation ⊆ is used to denote weak inclusion
and ⊂ is used for strict inclusion.



2    Identified and Partially Identified Models

We begin with a heuristic comparison of large sample approximations of Bayesian posterior
distributions and the frequentist distribution of likelihood ratios in a point identified model
in which the likelihood function is locally approximately quadratic and the maximum like-
lihood estimator (MLE) has a Gaussian limit distribution. It is well known that in this
environment the Bayesian 1 − τ credible Highest Posterior Density (HPD) set is approxi-
mately a level set of the likelihood function and has a 1 − τ coverage probability from a
frequentist perspective. A formalization and refinement of the subsequent heuristics can be
found in Severini (1991), who derives asymptotic expansions for the posterior probability of
confidence regions based on the likelihood ratio statistic and for the (frequentist) coverage
probability of highest posterior density regions.

    Suppose that a sequence of random variables Y n = {Yi }ni=1 is characterized by a density
p(Y n |φ) with respect to a dominating measure µ, where φ ∈ Φ ⊆ RK . Let ln (φ) = ln p(Y n |φ)
be the log likelihood function and φ̂n denote the maximum likelihood estimator (MLE), that
is ln (φ̂n ) ≥ ln (φ) for all φ ∈ Φ. A large sample approximation of the Bayesian posterior
density can be obtained from a second-order Taylor expansion of the log-posterior density
function around the MLE φ̂n . Let −Jˆn be the Hessian of the likelihood function evaluated
at the maximum φ̂n such that

                                     1
                 ln (φ) = ln (φ̂n ) − (φ − φ̂n )0 Jˆn (φ − φ̂n ) + Rl (kφ − φ̂n k2 ).      (1)
                                     2

Similarly, let π(φ) = ln p(φ) be the log prior density and assume that one can approximate
the log prior with a first-order Taylor series expansion of the form

                    π(φ) = π(φ̂n ) + π (1) (φ̂n )0 (φ − φ̂n ) + Rπ (kφ − φ̂n k).
                                                                                                           4


                                              1/2
Now transform φ according to s = Jˆn (φ − φ̂n ), such that
                                             1
                                         = − s0 s + Rl (kJˆn−1/2 sk2 )
                ln (φ̂n + Jˆn−1/2 s) − ln (φ̂n )
                                             2
                 π(φ̂n + Jn s) − π(φ̂n ) = π (φ̂n )0 Jˆn−1/2 s + Rπ (kJˆn−1/2 sk2 ).
                         ˆ−1/2              (1)



If φ is identifiable, then the smallest eigenvalue of Jn is positive and increasing with the
                        −1/2
sample size such that Jˆn s tends to zero and the influence of the prior distribution on the
posterior vanishes as n −→ ∞. Hence,
                                                                                       1
                  ln p(φ̂n + Jˆn−1/2 s|Y n ) − ln p(φ̂n |Y n ) ≈ ln (φ) − ln (φ̂n ) ≈ − s0 s,
                                                                                       2
that is, the posterior distribution of φ is approximately normal. Under suitable regularity
conditions, it can be deduced that

                        PYφn {2[ln (φ) − ln (φ̂n )] ≥ −cτ } − P {Z 0 Z ≤ cτ } −→ 0,                      (2)

where Z ∼ N (0, I). If one chooses cτ such that P {Z 0 Z ≤ cτ } = 1 − τ , then our heuristics
imply that the level set
                                                                    
                                      φ
                                  CS = φ 2[ln (φ) − ln (φ̂n )] ≥ −cτ                                     (3)

provides a large sample approximation to the HPD set that is 1 − τ credible.

    For a frequentist analysis it is convenient to approximate the likelihood function around
the probability limit φ0 of the maximum likelihood estimator:

                                 0              1
            ln (φ) = ln (φ0 ) + Zn,0 (φ − φ0 ) − (φ − φ0 )0 Jn,0 (φ − φ0 ) + R(kφ − φ0 k2 ).             (4)
                                                2
Here, Zn,0 and Jn,0 are the matrices of first and second derivatives of the log-likelihood
                                                    1/2
function evaluated at φ0 . Now let s = Jn,0 (φ − φ0 ) and write
                      1      −1/2              −1/2        1 0    −1             −1/2
   ln (φ) = ln (φ0 ) − (s − Jn,0 Zn,0 )0 (s − Jn,0 Zn,0 ) + Zn,0 Jn,0 Zn,0 + R(kJn,0 sk2 ).
                      2                                    2
                             1         p                  −1/2
In “regular”1 models         n Jn,0   −→ J0 and Jn,0 Zn,0 =⇒ Z uniformly in φ0 , where Z ∼
N (0, I). Under suitable regularity conditions one can show that
                                           1      −1/2              −1/2
                   ln (φ0 ) − ln (φ̂n ) = − (s − Jn,0 Zn,0 )0 (s − Jn,0 Zn,0 ) + op (1)
                                           2
and deduce
                              n
                    sup PφY {2[ln (φ) − ln (φ̂n )] ≥ −cτ } − P {Z 0 Z ≤ cτ } −→ 0.                       (5)
                    φ∈Φ

   1 An   important and widely studied irregular model in the econometrics literature is the autoregressive
model yt = φyt−1 +t , where φ ∈ [0, 1], see Sims and Uhlig (1991). Here the convergence of Jn (φ)−1/2 Zn (φ)
to a limit distribution is not uniform in φ and Bayesian and frequentist interval estimates differ.
                                                                                                        5


Thus, the set CS φ in (3) is also a uniformly valid frequentist confidence set.

     The above analysis remains essentially unchanged if one uses a smooth one-to-one func-
tion φ = G(θ) to re-parameterize the problem in terms of a structural parameter of interest
θ. The set                                                              
                              CS θ =    θ 2[ln (G(θ)) − ln (φ̂n )] ≥ −cτ

is (asymptotically) a 1 − τ credible set for a Bayesian and a 1 − τ confidence set for a
frequentist econometrician. The point of departure in this paper is to replace the function
G(θ) by a correspondence. Each value of the reduced form parameter φ ∈ Φ is associated
with a set of structural form parameters. This set is typically referred to as the identified set
and will be denoted by Θ(φ). Likewise, each structural parameter is potentially associated
with multiple reduced form parameters, which we collect in the set Φ(θ).

Example 1: Moment Inequalities. Consider the simple location model Yi = φ + Ui ,
where Ui is iid with some probability density function f (u). Suppose that the relationship
between the location parameter φ ∈ Φ ⊆ R and the structural parameter of interest is given
by the inequalities
                                             θ − λ ≤ φ ≤ θ,

where λ is a known constant that determines the length of the identified set. The model
specification is similar to the simple treatment effect model, in which observations are miss-
ing with a known probability, analyzed in Imbens and Manski (2004). In this example
Θ(φ) = [φ, φ + λ] and Φ(θ) = [θ − λ, θ]. 

     To study inference with respect to the partially identified parameter θ we express the
correspondence Φ(θ) in terms of a functional relationship between φ, θ, and an auxiliary
parameter α such that
                                               φ = G(θ, α).

We assume that for each φ there exists a suitable domain Aθ such that
                                                              
                      Φ(θ) = φ φ = G(θ, α) for some α ∈ Aθ .

In the moment inequality example we can choose2 G(θ, α) = θ−α and Aθ = [0, λ]. Replacing
the reduced form parameter in the likelihood function leads to the following log-likelihood
ratio:
                                          ln (G(θ, α)) − ln (φ̂n ).

From the perspective of inference about θ the auxiliary parameter α is a nuisance parameter.
   2 The   choice of G(θ, α) is not unique, because one can express α through arbitrary functions that map
into the unit interval.
                                                                                              6


3      Large Sample Analysis

We now derive a large sample approximation of the posterior distribution of a parameter
θ ∈ Θ ⊆ Rk in a partially identified model in which the identifiable reduced form parameter
φ ∈ Φ ⊆ RK is linked to θ through a correspondence that takes the form φ = G(θ, α),
α ∈ Aθ . We use the approximation to compare Bayesian credible sets and frequentist
confidence intervals in partially identified models.


3.1     Bayesian Analysis

In many applications Bayesian analysis can be conveniently implemented by combining
ln (G(θ, α)) with a prior distribution for θ and α. One can use numerical methods such
as importance sampling or Markov-Chain Monte Carlo algorithms to approximate finite-
sample moments of the posterior distribution of θ. For a theoretical analysis, on the other
hand, it is more convenient to work with the joint distribution of φ and θ, decomposed into
the marginal distribution of φ, P φ , and the conditional distribution of θ given φ, Pφθ .

      As emphasized by Kadane (1974), the derivation of the posterior distribution can be
done on the space of the reduced form parameter φ. Let T be a measurable subset of Θ.
Then
                                           I{θ ∈ T } exp[ln (φ)]dPφθ dP φ
                                   R R
                                    Φ Θ(φ)
              PYθ n {θ   ∈T}   =      R R                                                    (6)
                                        Φ Θ(φ)
                                                exp[ln (φ)]dPφθ dP φ
                                 Z Z                      
                                                          θ R     exp[ln (φ)]
                               =             I{θ ∈ T }dPφ                       φ
                                                                                  dP φ
                                  Φ     Θ(φ)                  Φ
                                                                 exp[l n (φ)]dP
                                 Z
                               =    Pφθ {θ ∈ T }dPYφn .
                                    Φ

Since conditional on φ the structural parameter θ does not enter the likelihood function the
prior distribution of θ given φ, Pφθ , is not updated in view of the data Y n . This point also
has been emphasized by Poirier (1998). To obtain a large sample distribution of PYθ n , we will
replace PYφn in (6) by a Gaussian approximation. There exists a long literature on normal
approximations of posterior distributions in identified models, including Bernstein (1934),
LeCam (1953), von Mises (1965). Our subsequent expansion of the posterior distribution of
φ follows work by Johnson (1970). Unlike Johnson, who provides higher-order expansions
of posterior distribution, we will only derive a first-order expansion. Rather starting from
low-level assumptions that guarantee the existence of a maximum likelihood estimate, we
begin by directly assuming the almost-sure convergence of the MLE.
                                                                                                   7

                                                                   n
Assumption 1 (i) The MLE φ̂n exists and φ̂n −→ φ0 [PφY0 ] almost surely.
                                                                             n
(ii) For any δ > 0, lim supn→∞ supkφ−φ0 k≥δ n1 [ln (φ0 ) − ln (φ)] > 0 [PφY0 ] almost surely.


        In order to construct a normal approximation of the posterior distribution of φ, we need
to make a few additional assumptions that guarantee the smoothness of the log likelihood
function.


Assumption 2 (i) Φ is a compact subset in RK and φ0 ∈ int (Φ) .
(ii) For n sufficiently large, p(Y n |φ) is twice continuously differentiable with respect to φ.
                            n
        1
(iii)   n Jn,0   −→ J0 [PφY0 ] almost surely and Jn is well-defined and negative definite.
(iv) There exists a δ > 0 and a finite constant M such that kφ1 − φ2 k implies that
                                               n
1
n   kJn (φ1 ) − Jn (φ2 )k ≤ M kφ1 − φ2 k, [PφY0 ] almost surely.


        Under Assumption 2, the log likelihood is continuous over a compact set, therefore the
MLE φ̂n is well defined. Under Assumption 2(ii), the log likelihood function is twice con-
tinuously differentiable. As in the previous Section, we use −Jn (φ) to denote the matrix
of second derivatives of the log-likelihood function around φ. We continue to use the ab-
breviations Jn,0 = Jn (φ0 ) and Jˆn = Jn (φ̂n ). Assumptions 1 and 2 cover models with iid
observations as well as time series models for weakly dependent data without trends. Large
sample approximations of posterior distributions for non-stationary time series models can
be found in Phillips and Ploberger (1996) and Kim (1998).


Assumption 3 (i) The prior density p(φ) is uniformly bounded in φ ∈ Φ and continuously
differentiable in a neighborhood around φ0 .
(ii) There exists a δp > 0 such that inf kφ−φ0 k≤δp p(φ) > 0 and supkφ−φ0 k≤δp p(1) (φ) ≤ M
for some finite constant M.


        According to Assumption 3 the parameter φ0 is drawn from the prior distribution P φ
whose density function is p(φ). When p(φ) is differentiable, we denote p(1) (φ) to be its first
                                                                1/2
derivative. We use s to denote the re-scaled parameter vector Jˆn (φ − φ̂n ). Based on the
above assumption we obtain the following approximation to the posterior distribution of φ.


Theorem 1 Suppose Assumptions 1 – 3 are satisfied. Let Y n be in the sure set of Assump-
tions 1 and 2.
                                                                                               8


(i) There exist finite constants M and N such that whenever n ≥ N we have for any sequence
of bounded functions |Hn (φ, ξ)| < MH
             Z                       Z
                                 φ
                                                                            M
                   Hn (φ, ξ) dPY n −          Hn φ̂n + Jˆn−1/2 s, ξ dΦN (s) ≤ √ .
                φ∈Φ                       R k                                  n

(ii) There exist finite constants M and N such that whenever n ≥ N

                                                                        M
                       sup      PYφn {Jˆn1/2 (φ − φ̂n ) ≤ ξ} − ΦN (ξ) ≤ √ .
                       ξ∈RK                                              n

    Part (i) of Theorem 1 is proved in the Appendix. Part (ii) follows directly from Part
                               1/2
(i) by setting Hn (φ, ξ) = I{Jˆn (φ − φ̂n ) ≤ ξ} and provides a normal approximation of the
                                      −1/2
posterior distribution of φ = φ̂n + Jˆn s. The constant M in Theorem 1 depends on the
function H(·) only through the bound MH .

    The remainder of the paper focuses on the characterization of the posterior distribution
of θ and the posterior probability of subsets of Θ. Let Tξ,n ⊆ Θ be a sequence of subsets of
the structural parameter space, indexed my a finite-dimensional vector ξ. Moreover, define

                                    Hn (φ, ξ) = Pφθ {θ ∈ Tξ,n }.                              (7)

If Tξ,n = {θ ≤ ξ} then Hn (φ, ξ) is the prior (and posterior) cdf of θ given φ and does not
depend on n. If θ = [θ10 , θ20 ]0 and Tξ,n = {θ1 ≤ ξ} then Hn (φ, ξ) is the cdf of the sub-vector
θ1 conditional on φ. In the context of Example 1 we will be interested in the posterior
probability of the sequence of sets Tn,ξ = [φ̂n + λξ, φ̂n + λ(1 − ξ)], which can be expressed as
   H (φ, ξ) dPYφn . Some of our subsequent results require that Hn (φ, ξ) satisfies a Lipschitz
R
  Φ n

condition.


Assumption 4 The sequence of functions Hn (φ, ξ) defined in (7) is Lipschitz in φ, that is,
|Hn (φ1 , ξ) − Hn (φ2 , ξ)| ≤ M (ξ)kφ1 − φ2 k, where M (ξ) is a constant that depends on ξ.


    Since we are interested in using large sample approximations of posterior distributions
to characterize asymptotically valid credible sets, we provide the following formal definition.

                                  θ
Definition 1 A sequence of sets CSB,τ (Y n ) is asymptotically 1 − τ credible if PYθ n {θ ∈
  θ
CSB,τ (Y n )} −→ 1 − τ .


    Combining (6) and Theorem 1 we obtain the following approximation to the posterior
probability that {θ ∈ Tξ,n }:
                                                                                               9


Corollary 1 Suppose Assumptions 1 – 3 are satisfied. Let Y n be in the sure set of As-
sumptions 1 and 2. The function Hn (φ, ξ) is defined in (7).
(i) There exist finite constants M and N such that whenever n ≥ N
                                      Z
                                                                            M
                  PYθ n {θ ∈ Tξ,n } −     Hn (φ̂n + Jˆn−1/2 s, ξ)φN (s)ds ≤ √ .
                                       RK                                    n

(ii) If the sequence of functions Hn (φ, ξ) satisfies Assumption 4, then there exist finite
constants M (ξ) and N such that whenever n ≥ N

                                                                M (ξ)
                              PYθ n {θ ∈ Tξ,n } − Hn (φ̂n , ξ) ≤ √ .
                                                                   n

(iii) If the sequence of functions Hn (φ, ξ) satisfies Assumption 4 and for every φ ∈ Φ and
τ ≥ ξ > 0 there is a set Tξ (φ) ⊂ Θ(φ) such that Pφθ {θ ∈ Tξ (φ)} ≥ 1 − ξ, then there exists a
                   θ
sequence of sets CSB,τ (Y n ) ⊆ Tξ (φ̂n ) ⊂ Θ(φ̂n ) that is asymptotically 1 − τ credible.


      Part (i) of Corollary 1 is a direct consequence of Theorem 1. Part (ii) is proved in
the Appendix and implies that an O(n−1/2 ) accurate approximation of the posterior dis-
tribution of θ can be calculated from the conditional prior distribution Pφ̂θ , provided that
                                                                                  n

Hn (φ, ξ) satisfies the Lipschitz condition. For instance, the Lipschitz condition is satisfied
in Example 1, if Pφθ is U[φ, φ + λ] and Tξ,n = {θ ≤ ξ}. According to Corollary 1(iii) one
can construct asymptotically valid credible sets as subsets of Tξ (φ̂n ). By construction, these
sets lie strictly inside of the identified set Θ(φ̂n ).


3.2     Frequentist Analysis

Starting point for our frequentist analysis is the log likelihood ratio ln (G(θ, α)) − ln (φ̂n ).
We begin by concentrating out the nuisance parameter α. Let

                                 α̂(θ) = argmaxα∈Aθ ln (G(θ, α))

and define the profile objective function

                               Qn (θ) = 2[ln (G(θ, α̂(θ))) − ln (φ̂n )].                     (8)

We consider consider confidence intervals that are of the form

                                     θ
                                   CSF,τ = {Qn (θ) ≥ −cτ (θ)}.                               (9)

If the critical value function cτ (θ) is constant, then the confidence interval is a level set of
                                             θ
the profile objective function Qn (θ). For CSF,τ to be a confidence set that is uniformly
                                                                                               10


valid asymptotically the following condition has to be satisfied:

                                            n
                           lim inf   inf PφY {Qn (θ) ≥ −cτ (θ)} ≥ 1 − τ.                     (10)
                       n−→∞ φ∈Φ θ∈Θ(φ)


Constructing a critical value function such that (10) holds with equality can be challeng-
ing and is the subject of a number of recent papers, including Imbens and Manski (2004),
Chernozhukov, Hong, and Tamer (2007), Romano and Shaikh (2005), Andrews and Guggen-
berger (2007), and Andrews and Soares (2007). For the remainder of this section we will
assume that such a critical value function is available and we will conduct a comparison
between Bayesian and frequentist confidence sets.

    Since the objective function Qn (θ) = 0 if θ ∈ Θ(φ̂n ) we can deduce immediately that
                                                                  θ
the frequentist confidence interval contains Θ(φ̂n ): Θ(φ̂n ) ⊆ CSF,τ . We now proceed by
                                                  θ
providing some conditions under which Θ(φ̂n ) ⊂ CSF,τ . Suppose to the contrary that
            θ
Θ(φ̂n ) = CSF,τ . As long as the likelihood function has a unique maximum φ̂n , Qn (θ) = 0
if and only if θ ∈ Θ(φ̂n ). Using our definition of Φ(θ) notice that

                                 n                    n
                              PφY {Qn (θ) = 0} = PφY {φ̂n ∈ Φ(θ)}.

Now consider

                       n                             n √            √
             inf    PφY {φ̂n ∈ Φ(θ)} =    inf     PφY { n(φ̂n − φ) ∈ n(Φ(θ) − φ)}.
           θ∈Θ(φ)                        θ∈Θ(φ)

                                                                              √
Let θ̃ be such that φ is on the boundary of Φ(θ̃). Moreover, assume that          n(Φ(θ̃) − φ) can
be covered with a convex cone C that is centered at φ. Then we obtain

                       n √            √                  n √
             inf    PφY { n(φ̂n − φ) ∈ n(Φ(θ) − φ)} ≤ PφY { n(φ̂n − φ) ∈ C}.
           θ∈Θ(φ)


This argument proves the following theorem.


Theorem 2 Suppose there exists a pair θ̃ and φ̃ such that (i) φ̃ is a boundary point of Φ(θ̃),
    √
(ii) n(Φ(θ̃) − φ̃) can be covered with a convex cone C, and (iii) P {Z ∈ C} ≤ 1 − τ . Then
            θ
Θ(φ̂n ) ⊂ CSF,τ .

              θ
    The set CSF,τ is a confidence set for the entire parameter vector θ. To conduct inference
                                                    θ
for a subset of parameters θ1 , one could project CSF,τ onto the relevant subspace of Θ. In
this case, it is still true that the projection of Θ(φ̂n ) is a strict subset of the projection of
  θ
CSF,τ .
                                                                                                            11


3.3      Bayesian versus Frequentist Sets

According to Theorem 2 an asymptotically valid frequentist confidence set for θ extends
beyond Θ(φ̂n ), whereas Corollary 1(iii) implies that asymptotically valid Bayesian credible
sets can be constructed as subsets of Θ(φ̂n ). Thus, unlike in the identified case discussed in
Section 2, frequentist and Bayesian set estimates are numerically different in large samples
if a model is partially identified. In particular, one can obtain Bayesian credible sets that
are strict subsets frequentist confidence sets.

      The frequentist literature on partially identified models is also concerned about esti-
mates of the identified set Θ(φ). Imbens and Manski (2004) highlight that confidence sets
for the set Θ(φ) tend to be larger than confidence sets for an element θ ∈ Θ(φ). The exist-
ing literature is not very clear about the instances in which an empirical researcher might
prefer an a confidence set for Θ(φ) over a confidence set for θ ∈ Θ(φ). A loose argument for
reporting an estimate of Θ(φ) is that the econometrician’s audience might be interested in
solving a minimax decision problem of the form3

                                                                 n
                                    min
                                     n
                                                  max        PφY [L(δ(Y n ), θ)]                           (11)
                                  δ(Y )∈D φ∈Φ, θ∈Θ(φ)


by replacing Θ(φ) in (11) with a confidence set that covers Θ(φ). Here δ(Y n ) is a decision
function and L(δ, θ) a loss function. In a Bayesian framework, the natural approach for the
econometrician would be to compute the posterior distribution for θ and solve the decision
problem by minimizing posterior expected loss

                                            min       PYθ n [L(δ(Y n ), θ)],
                                          δ(Y n )∈D


which does not require a credible set for Θ(φ). Nonetheless, a posterior credible set could
be obtained, for instance, by taking unions of Θ(φ) for values of φ in a set CSτφ :
                                                          [
                                             CSτ∗ =              Θ(φ).
                                                        φ∈CSτφ


By construction, I{Θ(φ) ⊆ CSτ∗ } ≥ I{φ ∈ CSτφ }. If CSτφ is both a valid frequentist
confidence set as well as a valid Bayesian credible set (see Section 2) we can deduce that
CSτ∗ is a valid set estimate for Θ(φ) from both the Bayesian and the frequentist perspective.
  3 As   an alternative to the expected loss one could consider the regret L(δ(Y n ), θ) − L(δ opt , θ).
                                                                                           12


4     Illustrations

The large sample approximations obtained in the previous section are now applied to several
specific examples, beginning with the moment inequality example presented in Section 2.
With our extensions of Example 1, we illustrate that Bayesian credible sets are asymptoti-
cally located inside Θ(φ̂n ), whereas frequentist confidence sets extend beyond the boundaries
of Θ(φ̂n ) (Section 4.1). This result also holds if frequentist inference is based on an inte-
grated instead of a profile likelihood function (Section 4.2, Example 1 continued). Our large
sample Bayesian inference can be extended to cover the models in which the volume of the
identified set depends on an estimable parameters and is potentially zero. We show how
to modify the approximation of the posterior to allow for reduced form parameters that lie
on the boundary of Φ (Section 4.2, Example 2). Finally, we consider a model in which the
reduced form parameter is uniquely determined by the structural parameter, but not vice
versa. If inference is conducted for the entire parameter vector θ (instead of a subset of θ),
then certain Bayesian 1 − τ credible sets are in fact valid 1 − τ frequentist confidence sets
(Section 4.2, Example 3).


4.1    Moment Inequalities, Part I

Consider Example 1 of Section 2: Yi = φ + Ui , Ui is iid with pdf f (u), and θ − λ ≤ φ ≤ θ,
where λ is known. Assume that the density function f (u) satisfies Assumptions 1 and 2 with
J0 = 1. Moreover, assume that the prior density p(φ, α) = p(φ)p(α) where p(φ) satisfies
Assumption 3 and the prior on the auxiliary parameter α = θ − φ is uniform on the interval
[0, λ]. To obtain a large sample approximation of the posterior cdf of θ, let Tξ,n = {θ ≤ ξ}.
Thus, the function Hn (φ, ξ) is the cdf of a U[φ, φ + λ] random variable and of the form
                                           
                                           
                                           
                                             0            if ξ < φ
                                           
                Hn (φ, ξ) = Pφθ {θ ≤ ξ} =     (φ − ξ)/λ if φ ≤ ξ ≤ φ + λ .              (12)
                                           
                                           
                                           
                                             1            otherwise
If λ > 0 the function Hn (φ, ξ) in (12) satisfies the Lipschitz condition in Assumption 4 and
we obtain the following two approximations of the posterior probability θ ≤ ξ:
                                1               √
         P̂Yθ n (i) {θ ≤ ξ} =     (ξ − φ̂n )ΦN ( n(ξ − φ̂n ))                            (13)
                                λ
                                  1                   √
                                − (ξ − (φ̂n + λ))ΦN ( n(ξ − (φ̂n + λ)))
                                  λ
                                             √                √
                                                                             
                                    1
                                + √ φN ( n(ξ − φ̂n )) − φN ( n(ξ − (φ̂n + λ))) ,
                                  λ n
         P̂Yθ n (ii) {θ ≤ ξ} = Hn (φ̂n , ξ).                                             (14)
                                                                                                 13


The posterior density associated with approximation (i) can be obtained by differentiating
the cdf P̂Yθ n (i) {θ ≤ ξ} with respect to θ:

                                       √                   √
                                                                            
                          n     1
                 p̂(i) (θ|Y ) =    ΦN ( n(θ − φ̂n )) − ΦN ( n(θ − (φ̂n + λ))) .                 (15)
                                λ
Since ΦN (x) = 1 − ΦN (−x), it is straightforward to verify that the approximate posterior
density p̂(i) (θ|Y n ) is symmetric around the mode θ̂n = φ̂n + λ/2. For large values of n
p̂(i) (θ|Y n ) approaches the density function associated with P̂Yθ n (ii) : it jumps from 0 to 1/λ
at θ = φ̂n , stays constant, and drops back to zero around θ = φ̂n + λ.

    According to P̂Yθ n (ii) the posterior distribution of θ is uniform on the Θ(φ̂n ) asymptot-
ically. This suggests that the set

                        θ
                      CSB,ξ (Y n ) = [φ̂n + ξλ/2, φ̂n + λ − ξλ/2] ⊂ Θ(φ̂n )

is an asymptotically valid 1 − ξ credible interval for θ. To verify this claim, let Tξ,n =
  θ
CSB,ξ (Y n ) and define
                                     Hn (φ, ξ) = Pφθ {θ ∈ Tξ,n }.                               (16)

This function is piecewise linear with a Lipschitz constant of 1/λ (see Assumption 4). Thus,
provided that λ > 0, the posterior probability PYθ n {θ ∈ CSB,ξ
                                                            θ
                                                                (Y n )} can according to
Corollary 1 be approximated by Hn (φ̂n , ξ) = 1 − ξ in (16), which verifies the claim. If
λ = 0 and θ is point identified, the Lipschitz condition is violated and the asymptotic
approximation of the posterior cdf is of the form P̂Yθ n (i) {θ ≤ ξ} = ΦN (ξ), which leads to
                                     √
the “standard” interval φ̂n ± zτ /2 / n.

    To illustrate the frequentist analysis we assume that f (u) = φN (u). Hence the profile
objective function is given by
                                  
                                  
                                  
                                   n(φ̂n − θ)2         if θ ≤ φ̂n
                                  
                     −Qn (θ) =      0                   if φ̂n < θ < φ̂n + λ .                  (17)
                                  
                                  
                                   n(φ̂ − θ + λ)2
                                  
                                                        if φ̂n + λ ≤ θ
                                        n

                                                                                 √
The finite-sample distribution of the maximum likelihood estimator is                n(φ̂n − φ) ∼ Z,
where Z is a standard normal random variable. It is convenient to re-scale θ according
        √
to sθ = n(θ − φ). In terms of the sθ transform, the identified set Θ(φ) is given by
        √
0 ≤ sθ ≤ nλ. We can now characterize the distribution of the profile objective function as
                                
                                
                                
                                 (Z − sθ )2        if sθ ≤ Z
                                                                        √
                                
          −Qn (φ + n−1/2 sθ ) ∼   0                 if Z < sθ < Z + nλ .              (18)
                                             √             √
                                
                                
                                 (Z − s + nλ)2 if Z + nλ ≤ s
                                
                                        θ                             θ
                                                                                             14


Now suppose that the critical value cτ solves the following equation:
                                 √    √            √
                             ΦN ( nλ + cτ ) − ΦN (− cτ ) = 1 − τ.                           (19)

In view of (18), we deduce
                                     n
                     inf   infPφY {Qn (θ) ≥ −cτ }
                   φ∈Φ θ∈Θ(φ)
                                           √      √          √
                       =    inf√ P {sθ − nλ − cτ ≤ Z ≤ sθ + cτ }
                         0≤sθ ≤ nλ
                                            √            √    √
                       =    inf√ ΦN (sθ + cτ ) − ΦN (sθ − nλ − cτ )
                           0≤sθ ≤ nλ
                       =   1 − τ,
                                                                               √
where the last line follows since the infimum is achieved at sθ = 0 or sθ =        nλ and by the
definition of cτ in (19) . Therefore, the resulting confidence interval is of the form
                                                                      
                            θ    n
                                             p                  p
                       CSF,τ (Y ) = φ̂n − cτ /n, φ̂n + λ + cτ /n .                          (20)

As pointed out by Imbens and Manski (2004), if the re-scaled length of the identified set is
large, then a 1−τ confidence set for the parameter θ is obtained by expanding the boundaries
                                                         √
of the interval Θ(φ̂n ) using a one sided critical value cτ ≈ zτ . If, on the other hand, the
                                                              √
length of the identified set is zero (exact identification) or nλ is close to zero, then the
                                                                          √
boundaries of Θ(φ̂n ) have to be expanded by a two-sided critical value cτ ≈ zτ /2 .

      A comparison of the frequentist and the Bayesian interval leads to the relationship
  θ                 θ
CSB,τ ⊂ Θ(φ̂n ) ⊂ CSF,τ , as postulated in Corollary 1(iii) and Theorem 2. To see that
the conditions of Theorem 2 are satisfied, choose, for instance, θ̃ = 0, φ̃ = −λ. Hence
                                                         √
Φ(θ̃) − φ̃ = [0, λ], which expands to C = R+ if scaled by n. Since P {Z ∈ R+ } = 1/2, a
confidence set with coverage probability greater than 50% has to extend beyond Θ(φ̂n ).

      A graphical comparison of the frequentist confidence intervals and Bayesian credible
intervals is provided in Figure 1, assuming that f (u) = φN (u). The two panels of the Figure
are drawn for a data set in which φ̂n = 0. We overlay sample sizes n = 5 and n = 500. The
top panel depicts posterior densities p(θ|Y n ) = p̂(i) (θ|Y n ) given in (15) and exact 90% HPD
intervals, calculated numerically. The bottom panel depicts the standardized frequentist
                      1
objective function    n Qn (θ)   from Equation (18), the critical values −cτ /n that solve (19),
and 90% frequentist confidence intervals.


4.2     Moment Inequalities, Part II

Example 1 (continued): Frequentist Analysis with Integrated Likelihood. Pre-
viously, our frequentist analysis was based on a profile likelihood function, whereas the
                                                                                                 15


Bayesian inference was based on an integrated likelihood function in which the nuisance pa-
rameter α was integrated out with respect to the prior distribution. We will now construct
a frequentist confidence interval for θ based on the integrated objective function obtained
with a prior (or weight function) α ∼ U[0, λ]:
                                          Z
                          ln,int (θ) = ln      exp[ln (G(θ, α))]dα.
                                            α∈Aθ

If f (u) = φN (u) then ln,int (θ) = ln p̂(i) (θ|Y n ) defined in (15). Now consider the distribution
of exp[ln,int (θ)] near the boundaries of the identified set Θ(φ) = [φ, φ + λ]. If λ > 0 and the
sample size is sufficiently large, then
                          
                                               √
                                                          
                        ΦN Φ−1
                          
                                     N  (λt) −   n(θ − φ0 )           for small |θ − φ0 |
 P ln,int (θ) ≤ ln t ≈           
                                               √
                                                                                                .
                                     −1
                           ΦN ΦN (λt) − n(θ − (φ0 + λ))              for small |θ − (φ0 + λ)|
                          
                          

Thus, we obtain the following approximation for level sets:
                                                         √              √
                                                                       
            θ
         CSF,τ = θ ln,int (θ) ≤ ln(τ /λ) = φ̂n − zτ / n , φ̂n + λ + zτ / n ,                   (21)

where zτ = Φ−1
            N (1 − τ ). From a comparison of (20) and (21) we deduce that the frequentist

intervals constructed from the profile and the integrated likelihood function are approxi-
mately the same. In particular, the interval obtained from the profile likelihood function
also has the property that it extends beyond Θ(φ̂n ). Thus, it is not the absence of a dis-
tribution over the identified set Θ(φ), but rather the requirement that the 1 − τ coverage
probability is guaranteed for all θ ∈ Θ(φ) that leads to frequentist set to be larger than the
Bayesian set.

Example 2: Unknown Length of Identified Set. We previously assumed that the
length of the identified set is known and made a distinction between identified intervals
of length zero and length greater than zero. Now suppose that the length itself depends
on an unknown but estimable reduced form parameter φ2 ≥ 0: θ − φ2 ≤ φ1 ≤ θ and
Θ(φ) = [φ1 , φ1 + φ2 ]. This modified version of the inequality moment example is a stylized
representation of the treatment effect model studied by Imbens and Manski (2004). The
problem has been recently analyzed from a frequentist perspective in Stoye (2007). Let
φ = [φ1 , φ2 ] and assume that the prior distribution for θ given φ is uniform on Θ(φ).

    We previously derived the approximation of the posterior distribution under the as-
sumption that the “true” reduced form parameter lies in the interior of the domain Φ. This
                                                                                 (1)
assumption guaranteed that φ̂n is also in the interior and the score Ẑn = ln (φ̂n ) = 0 even-
tually. To accommodate reduced form parameters on the boundary of Φ, that is φ2 = 0 in
                                                                                                               16


this example, the approximation in Theorem 1 can be modified as follows:
   Z                              
               H φ̂n + Jˆn−1/2 s, ξ dPYs n                                                                   (22)
       1/2
     Jˆn (Φ−φ̂n )
                                                                          −1/2
                                                               φN (s − Jˆn
              Z                                                          Ẑn )
          −                   H φ̂n + Jˆn−1/2 s, ξ R                        −1/2
                                                                                         ds = op (n−1/2 ).
                 1/2
               Jˆn (Φ−φ̂n )                                       φ  (s − ˆ
                                                                          J      Ẑ  )ds
                                                       Jˆ (Φ−φ̂n ) N        n      n
                                                         1/2
                                                        n



If the score Ẑn is non-zero and the Hessian −Jˆn is negative definite, the normal approxi-
                                    −1/2
mation of s has to be centered at Jˆn Ẑn instead of zero. Moreover, the distribution of
                             −1/2
s is restricted to the set Jˆn (Φ − φ̂n ), which guarantees that the resulting posterior of φ
has support on the domain Φ. The above approximation requires an additional assumption
                       −1/2
that guarantees that Jˆn Ẑn is stochastically bounded.4 Due to the behavior of the score
Ẑn , the bound is only valid with probability approaching one, rather than almost surely. If
we let H(φ, ξ) = Pφθ {θ ≤ ξ}, which is given by
                                               
                                                H (φ, ξ) if φ = 0
                                                  0           2
                                     H(φ, ξ) =                     ,
                                                H (φ, ξ) if φ > 0
                                                  +           2


where
                                                                    
                                                                   
                                                                    
                                                                     0             if ξ < φ1
                           0 if ξ < φ                              
                                      1                                 φ1 −ξ
              H0 (φ, ξ) =               ,         H+ (φ, ξ) =            φ2         φ1 ≤ ξ ≤ φ1 + φ2 ,
                           1 if φ ≤ ξ                              
                                  1                                 
                                                                    
                                                                     1             otherwise

then (22) provides a large sample approximation to the posterior of θ that is valid regardless
of whether the identified set has zero or non-zero length.

Example 3: Singleton Φ(θ). In some models the set of structural parameters uniquely
determines the reduced form parameters, that is Φ(θ) is a singleton, while Θ(φ) is set-valued.
An example of such a model is a structural vector autoregression, in which φ corresponds
to the regression coefficients and the non-redundant elements of the variance-covariance
matrix of the one-step-ahead forecast errors. The vector θ corresponds to a collection of
structural impulse response functions. These impulse responses depend in addition to φ on
a non-identifiable orthonormal matrix that rotates orthogonalized one-step-ahead forecast
errors into a vector of structural shocks.

     Consider the following modification of Example 1: θ = [θ1 , θ2 ]0 , θ1 − λ ≤ φ ≤ θ1 , and
θ2 = θ1 − φ. Notice that the slackness parameter α that arose in Example 1 is now called
   4 Classical                                                               −1/2
                  analysis is typically based on the assumption that Jn,0 Zn,0 = Op (1). Thus, stochastic
                                                        −1/2       (1)                                  −1/2
equicontinuity of the standardized score process Jn            (φ)ln (φ) would suffice to ensure that Jˆn    Ẑn =
Op (1).
                                                                                                         17


θ2 and part of the structural parameter vector θ. Θ(φ) is located in a one-dimensional
subspace of Θ and remains set-valued, while Φ(θ) = θ1 − θ2 is a singleton. The projections
of the identified set Θ(φ) on the domains of θ1 and θ2 are given by Θ1 (φ) = [φ, φ + λ] and
Θ2 (φ) = [0, λ] We maintain that conditional on φ the prior for θ1 is U[φ, φ + λ], which
implies the prior on Θ2 (φ) is also uniform.

    Using the same arguments as for Example 1, replacing α by θ2 , one can deduce that
the set
                                       θ1
                                     CSB,τ = [φ̂n + τ λ/2, φ̂n + λ − τ λ/2]
                                                                    θ2
is an asymptotically valid 1 − τ credible set for θ1 . Similarly, CSB,τ = [τ λ/2, λ − τ λ/2] is
a 1 − τ credible set for θ2 . Likewise, the set characterized in (20) is a valid 1 − τ frequentist
confidence set for θ1 . Thus, the lessons learned from Example 1 still apply to inference
about the θ1 element of the θ vector.

    More interestingly, we will now consider inference for the vector θ. Consider the follow-
ing subsets of Θ:

                             √                        √
                                                                                 
    Tξ,n = θ1 , θ2 φ̂n − ξ1 / n ≤ θ1 − θ2 ≤ φ̂n + ξ1 / n, λξ2 /2 ≤ θ2 ≤ λ(1 − ξ2 )                      (23)

and define
                                                                               √                  √
                                        
                                         1−ξ                     if φ̂n − ξ1 / n ≤ φ ≤ φ̂n + ξ1 / n
                                              2
          Hn (φ, ξ) = Pφθ {θ ∈ Tξ,n } =
                                         0                       otherwise

Since the sequence of functions Hn (φ, ξ) does not satisfy the Lipschitz condition in Assump-
tion 4 we use the following approximation
                                                            √
                                                    Z   ξ1 / n
             P̂Yθ n (i) {θ   ∈ Tξ,n } = (1 − ξ2 )        √
                                                                 φN (s)ds = (1 − ξ2 )(1 − 2ΦN (ξ1 )).
                                                    −ξ1 / n

Thus, an asymptotically valid credible set can be obtained by choosing ξ1 ≥ 0 and 0 ≤ ξ2 ≤ 1
such that (1 − ξ2 )(1 − 2ΦN (ξ1 )) = 1 − τ . It turns out that the volume of the 1 − τ credible
set is minimized by setting ξ2 = 0 and ξ1 = zτ /2 . The set Θ(φ̂n ), which is obtained from
Tξ,n in (23) by setting ξ1 = 0 and ξ2 = 0, is not an asymptotically valid credible set – it
is too small. However, since one can construct valid credible sets with ξ2 > 0, it is not the
case that Θ(φ̂n ) is nested in every asymptotically valid credible set. In this example Θ(φ̂n )
happens to be nested in the 1 − τ credible set with the smallest volume among the Tξ,n sets.

    Now consider the following construction of a frequentist confidence interval for θ. Since
Φ(θ) is a singleton, we can express φ = G(θ), without having to introduce an α. Moreover,
                                                                                                            18


the natural relationship between the domains Φ and Θ is: Φ = {φ | φ = G(θ), θ ∈ Θ}. Thus,

                                         n
                     inf     inf      PφY {2[ln (G(θ)) − ln (φ̂n )] ≥ −cτ }                                (24)
                     φ∈Φ θ∈Θ(φ)
                                                 n
                        =     inf     inf    PφY {2[ln (G(θ)) − ln (φ̂n )] ≥ −cτ }
                             θ∈Θ φ∈Φ(θ)
                                        n
                                   Y
                        =     inf PG(θ) {2[ln (G(θ)) − ln (φ̂n )] ≥ −cτ }
                             θ∈Θ
                                        n
                        =     inf PφY {2[ln (φ) − ln (φ̂n )] ≥ −cτ }
                             φ∈Φ


Using the large sample approximation described in Section 2 one can obtain an asymptoti-
cally valid confidence set CS φ that takes the form of the level set (3). In our example:

                                                  √                √
                             CS φ = [φ̂n − zτ /2 / n, φ̂n + zτ /2 / n].

                                                                       θ
                                                                                            S
According to (24) the corresponding confidence set for θ is given by CSF,τ =                     φ∈CS φ   Θ(φ).
This set equals Tξ in (23) for ξ1 = zτ /2 and ξ2 = 0. Thus, the frequentist confidence set is
identical to Bayesian credible set that has the smallest volume among the Tξ sets.



5    A Numerical Example: Bayesian Analysis of a Two-
     Player Entry Game

At last, we consider an example that has received a lot of attention in the microeconometric
literature on partially identified models: a two-player entry game, see for instance Bresnahan
and Reiss (1991), Berry (1994), Tamer (2003), and Ciliberto and Tamer (2007). Rather
than directly working with the asymptotic approximation derived in Section 3.1, we will use
Markov-Chain Monte Carlo techniques to generate posterior draws of θ for a small (n = 50)
and a large (n = 1, 000) sample. We will focus on a fairly simple version of the entry game
without firm-specific regressors. Depending on the entry decision of the second firm, Firm l
either does not enter market i, operates as monopolist, or operates as duopolist. Potential
monopoly (M) and duopoly (D) profits are given by

              M
             πi,l = x0i βl + i,l ,     D
                                       πi,l = x0i βl − γl + i,l ,   l = 1, 2 i = 1, . . . , n             (25)

The 0i,l s capture latent profit components that are known to the two firms but unobserved
by the econometrician and xi is a vector of observable market characteristics. We assume
that the outcome of the entry game in each market is a pure strategy Nash equilibrium.
It is straightforward to verify that the Nash equilibrium is unique, except if both firms are
profitable as monopolist but not as duopolist. In the latter case, the model is silent about
                                                                                                    19


which firm actually enters the market. As a consequence, the model only delivers bounds
for the probability of observing a particular monopoly.

    Suppose that i,l ∼ iidN (0, 1) and let θ = [β10 , γ1 , β20 , γ2 ]0 . Using (25) it is straightfor-
ward to calculate probabilities that firm l is profitable as monopolist (duopolist) in market
i. For xi = x we denote these probabilities by µl (θ, x) and δl (θ, x), respectively. Moreover,
we use
                              φ(x) = [φ00 (x), φ01 (x), φ10 (x), φ11 (x)]0

to denote the reduced form probabilities of observing no entry, entry of Firm 1, entry of
Firm 2, or entry of both firms in a market with characteristics x. We observe no entry if
neither firm is profitable as monopolist, we observe a duopoly if both firms are profitable
as duopolists. An upper bound on the probability that Firm 1 operates as monopolist is
given by the probability that Firm 1 is profitable as monopolist and Firm 2 is not profitable
as duopolist. The lower bound is given by the sum of the probability that Firm 1 is prof-
itable as monopolist and Firm 2 is not profitable as monopolist and of the probability that
Firm 1 would be profitable as duopolist, but Firm 2 would only be profitable as monopolist.
Formally,

                    φ00 (x)     =   (1 − µ1 (x))(1 − µ2 (x))                                      (26)

                    φ11 (x)     = δ1 (x)δ2 (x)                                                    (27)

                    φ10 (x) ≤ µ1 (x)(1 − δ2 (x))                                                  (28)

                    φ10 (x) ≥ µ1 (x)(1 − µ2 (x)) + δ1 (x)(µ2 (x) − δ2 (x)).                       (29)

It can be verified that the Nash equilibrium restriction for a Firm 2 monopoly does not add
any further restrictions on the reduced form probabilities.

    In order to be able to uniquely determine the reduced form parameters as a function
of the probabilities µi and δi , we introduce for each x an auxiliary parameter α(x) ∈ [0, 1]
that captures the slackness in the inequality restrictions for φ10 (x):

 φ10 (x) = µ1 (x)(1 − µ2 (x)) + δ1 (x)(µ2 (x) − δ2 (x)) + α(x)(µ1 (x) − δ1 (x))(µ2 (x) − δ2 (x)). (30)

The second term, which is pre-multiplied by α, can be interpreted as the probability that
both firms are profitable as monopolists but not as duopolists. Consequentially, the slack-
ness can be viewed as the probability of a sunspot shock that selects Firm 1 if the Nash
equilibrium is not unique. Equations (26), (27), and (30) define the function G(θ, α).

    For the large sample theory presented in Section 3 to be applicable to the entry game
we need to assume that the regressor x is discretized. The discretization ensures that the
                                                                                             20


reduced-form parameter vector φ is finite dimensional and is not uncommon in the empirical
literature. These regressors are assumed to take only finitely many values. In the subsequent
numerical illustration we only use an intercept as regressor.

    We proceed in several steps: (i) we specify a data generating process by choosing “true”
values of θ and α, which imply a “true” φ. (ii) Instead of specifying a prior distributions P φ
and Pφθ , we start from a prior on θ and α and generate draws from the implied distributions
P φ and Pφθ . (iii) Finally, will generate two samples of size n = 50 and n = 1, 000 and
compare the posterior distributions.

    The parameterization of the data generating process is summarized in the second column
of Table 1. The probabilities of a a Firm 1 monopoly, and Firm 2 monopoly, and a duopoly
are 48%, 33%, and 12%, respectively. The third column of Table 1 specifies the prior
distributions. We use fairly diffuse Gaussian priors for the elements of the θ vector. The
distributions of γ1 and γ2 are truncated at zero to ensure that duopoly profits are less
than monopoly profits. The auxiliary parameter α has support on the unit interval. We
consider three different priors, centered at 0.2 (low α), 0.5 (Benchmark), and 0.8 (high α),
respectively. By evaluating the function G(θ, α) at random draws from the prior distribution
of θ and α we obtain draws from the prior distribution of φ. Means and standard deviation
are reported in the last four rows of Table 1 under the Benchmark prior for α.

    According to our previous analysis the prior distribution of θ given φ plays an important
role in Bayesian inference for partially identified models. We depict unconditional prior
densities as well as prior densities conditional on the “true” value of φ in Figure 2. Except
for α, the unconditional prior densities are essentially invisible because they are very diffuse
compared to the conditional priors. While in a fully identified model the prior Pφθ should be
a pointmass at the singleton θ(φ), the entry game model is partially identified and leads to
a non-degenerate Pφθ . The prior distribution on α induces a prior distribution for the profit
function parameters given the reduced form entry probabilities. Figure 2 illustrates how Pφθ
shifts as one changes the prior for α. While the prior for α could in principle be correlated
with the prior for θ, for instance to reflect the belief that the firm with higher expected
monopoly profits is more likely to enter the market if the equilibrium is not unique, we will
treat α and θ as independent.

    We now generate samples of n = 50 and n = 1, 000 observations from the data generating
process and us a random-walk Metropolis Algorithm to generate draws from the posterior
of θ and α. Using the relationship φ = G(θ, α) we convert the θ-α draws into φ draws.
Figure 3 indicates that after 50 observations there is still substantial uncertainty about
                                                                                           21


the reduced form parameters. Since we specified the prior distribution for φ implicitly
through a prior for θ and α, changes in the prior for α can in principle affect the prior and
posterior of φ. However, according to Figure 3 this effect is negligible in our illustration.
Figure 4 depicts posterior densities for the profit function parameters β and δ. While the
prior distribution of α and hence Pφθ has some effect on the posterior, overall the posterior
distribution is dominated by the uncertainty about the reduced form parameter. Finally, the
two panels of Figure 5 show scatter plots of draws from the posterior distribution of β1 and
γ1 . Moreover, we outline the projection of the identified set Θ(φ̂n ) onto the domain of β1
and γ1 . Here φ̂n is the posterior mean of the reduced form parameter vector φ. According to
our asymptotic theory, the posterior distribution concentrates near Θ(φ̂n ), which is evident
from the posterior draws obtained with n = 1, 000.



6    Conclusion

We derived a large sample approximation for the posterior distribution of a structural param-
eter vector in a partially identified model to compare Bayesian credible sets and frequentist
confidence sets. Unlike in regular models, Bayesian and frequentist set estimates differ not
just with respect to their philosophical underpinnings. Frequentist confidence intervals have
to extend beyond the boundaries of the identified set (conditional on the estimated reduced
form parameter), whereas Bayesian credible sets can be be located in the interior of the
identified set asymptotically. The main challenge to frequentist inference is to establish the
uniform validity of the set estimate. The main challenge to Bayesian inference is to control
the shape of the prior distribution on the identified set conditional on the reduced form
parameter to avoid highly informative priors on the identified set induced by nonlinearities
of parameter transformations and to document the sensitivity of posterior inference to the
choice of prior even in large samples.
                                                                                               22


Appendix

The proof of Theorem 1 will closely follow the arguments in Johnson (1970). We rewrite
the posterior density of φ as
                                           
                                                  p(φ) exp[ln (φ)]
                                                                         if φ ∈ Φ
                        q φ (φ|Y n )   =         p(φ̂n ) exp[ln (φ̂n )]
                                            0                            otherwise
                                                   φ        n
                                                 q (φ|Y )
                        pφ (φ|Y n )    =   R                     .
                                               RK
                                                  q φ (φ|Y n )dφ
                    −1/2
Define Σ̂n = n1/2 Jˆn      and z = Σ̂−1                                 z    n     φ
                                     n (φ − φ̂n ) ∈ Φz . Moreover, let q (z|Y ) = q (φ̂n + Σ̂n z).

Then the posterior density of z can be expressed as
                                                         q z (z|Y n )
                                   pz (z|Y n ) = R                       .
                                                       RK
                                                          q z (z|Y n )dz
Let Ω0 and Ω1 denote the sure sets for which Assumptions 1 and 2 hold, respectively. We
begin by introducing several Lemmas that are useful for the proof of the theorem.

Lemma 1 Suppose that Assumptions 1 – 2 hold. Fix a constant κ1 with 0 < κ1 < 1.
Then, one can choose a constant δ1 > 0 and, for each ω ∈ Ω1 a constant N1ω such that
the following statements hold: (a) If n ≥ N1ω and kφ − φ0 k ≤ δ1 , then there exists finite
constants Mmin and Mmax such that

               0 < Mmin ≤ λmin (n−1 Jn (φ)) ≤ λmax (n−1 Jn (φ)) ≤ Mmax < ∞.

(b) If n ≥ N1ω , then

                   0 < Mmin ≤ λmin (n−1 Jˆn ) ≤ λmax (n−1 Jˆn ) ≤ Mmax < ∞

and (c)
                                                                  −1
                       −1
                  0 < Mmax ≤ λmin (n−1 Jˆn ) ≤ λmax (n−1 Jˆn ) ≤ Mmin < ∞.

Lemma 2 (Lemma 2.2 in Johnson) Suppose that Assumptions 1 – 2 hold. Then, we
can choose a constant δ2 (0 < δ2 < 1), a constant κ2 < 21 , and, for each ω ∈ Ω1 , a constant
N2ω (≥ N1ω ) such that if n ≥ N2ω and kzk ≤ δ2 , then
                         1               1  
                                                            2
                           ln φ̂n + Σ̂n z − ln φ̂n ≤ −κ2 kzk .
                         n                 n

Lemma 3 (Lemma 2.3 in Johnson) Suppose that Assumptions 1 – 2 hold. Suppose that
δ > 0 is given. Then, we can choose a constant κ3 > 0 and, for each ω ∈ Ω1 , a constant
N3ω (≥ N2ω ) such that whenever n ≥ N3ω and kzk ≥ δ, we have
                          1               1  
                            ln φ̂n + Σ̂n z − ln φ̂n ≤ −κ3 .
                          n                 n
                                                                                                  23


    Now define (our definition differs from Johnson’s)

                                                        p(1) (φ̂n )0
                            p1 (φ − φ̂n ; φ̂n ) = 1 +                  (φ − φ̂n ).
                                                          p(φ̂n )

Since φ̂n → φ0 a.s. and p(φ0 ) > 0, p(φ̂n ) > 0 near φ0 .


Lemma 4 (Lemma 2.4 in Johnson) Suppose that Assumptions 1 – 3 hold. Then, there
exists a constant δ4 ,a constant M, and, for each ω ∈ Ω0 , a constant N4ω (> N3ω ) such that
if n ≥ N4ω , then
                 Z                                                            
                                                                1                         M
                            z       n
                           q (z|Y ) − p1 Σ̂n z; φ̂n          exp − nz 0 z            dz ≤     .
                  kzk≤δ4                                          2                         n

Lemma 5 Suppose Assumptions 1 – 3 are satisfied. Let Y n be in the sure set of Assump-
tions 1 and 2. Then, there exist a finite constant M and a finite constant N such that
whenever n ≥ N we have
                     Z                              
                                  z    n         1 0        M
                                 q (z|Y ) − exp − nz z dz ≤   .
                           RK                    2          n

Proof of Lemma 5 For a given ω ∈ Ω0 , choose Nω ≥ N4ω in Lemma 4 such that when
n ≥ N4ω , the statements of Lemmas 1, 2, 3, and 4 hold, and for the δp in Assumption 3,
kφ̂n − φ0 k ≤ δp by Lemma 1 in Wu (1981). We bound
                  Z                                 
                                               1
                       q z (z|Y n ) − exp − nz 0 z dz
                    RK                         2
                         Z                                             
                                                                1
                     ≤         q z (z|Y n ) − p1 Σ̂n z; φ̂n exp − nz 0 z dz
                           RK                                     2
                            Z                                     
                                                            1 0
                         +        1 − p1 Σ̂n z; φ̂n exp − nz z dz
                             RK                               2
                     = I + II

Term I can be bounded by
                      Z                                                      
                                        z
                                                                    1 0
                                                                       
   III + IV + IV =              q (z|Xn ) − p1 Σ̂n z; φ̂n exp − nz z dz
                        kzk≤δ4                                       2
                       Z                         Z                                
                                                                          1
                     +         q z (z|Y n ) dz +         p1 Σ̂n z; φ̂n exp − nz 0 z dz,
                        kzk>δ4                    kzk>δ4                    2

where δ4 is defined in Lemma 4. The O(n−1 ) bound for III follows directly from Lemma
4. Now consider term IV :
                      Z
                                    p(φ̂n + Σ̂n z)                                  
             IV =                                    exp ln (φ̂n + Σ̂n z) − ln (φ̂n ) dz
                           kzk>δ4p(φ̂n )
                                        M
                     ≤ M exp(−κ3 n) ≤      .
                                         n
                                                                                                     24


The bound follows from Assumption 3 and Lemma 3. Finally, to obtain a bound for term
V , by Assumption 3 with kφ̂n − φ0 k ≤ δp and by Lemma 1(c), we can choose M such that

                                               p(1) (φ̂n )
                      p1 (Σ̂n z; φ̂n ) ≤ 1 +                 Σ̂n z ≤ 1 + M kzk .
                                                p(φ̂n )

Then,
              Z                        Z                       
                           1     2                        1     2     M
        V ≤           exp − n kzk dz + M         kzk exp − n kzk dz ≤   .
               kzk>δ4      2              kzk>δ4          2           n

Combining the bounds for terms III, IV , and V, we have

                                             M
                                               I≤ .
                                               n
                                                  
For the term II, from the definition p1 Σ̂n z; φ̂n and (6) and by change of variable v =
√
  n kzk, we have

                                                  M ∞
                 Z                                 Z           
                                1      2                      1 2 K         M
         II ≤ M      kzk exp − n kzk dz ≤               exp − v v dv ≤         ,
                  RK            2                  n  0       2              n

as required for the lemma. 
                                        √                                            √        √
Proof of Theorem 1(i): For s =              nz ∈ Φs the posterior is ps (s|Y n ) =       npz ( nz|Y n ).
                            −1/2
We now abbreviate H(φ̂n + Jˆn s, ξ) = H(s, ξ). Then,
 Z                 Z                    Z
             s
    H(s, ξ)dPY n −     H(s, ξ)dΦN (s) =     H(n1/2 z, ξ)[pz (z|Y n ) − n1/2 φN (n1/2 z)]dz.
   Φs                   RK                         RK

To prove the theorem it suffices to show that
               r     Z
                 2π                                                        M
                          H(n1/2 z, ξ)[pz (z|Y n ) − n1/2 φN (n1/2 z)]dz ≤   .
                  n RK                                                     n

Consider the following bound
           r       Z
              2π                                                    
                        H(n1/2 z, ξ) pz (z|Y n ) − n1/2 φN n1/2 z dz
               n RK
                                        p                                        !
                                          2π/n q z (z|Y n )
                   Z                                                  
                            1/2                                            1 0
              =         H(n z, ξ) R                           − exp − nz z          dz
                     RK                   RK
                                             q z (z|Y n ) dz               2
                   Z                                         p               !
                                                                 2π/n
              ≤         H(n1/2 z, ξ)q z (z|Y n ) 1 − R                         dz
                     RK                                  RK
                                                             q z (z|Y n ) dz
                      Z                                                 
                                                                  1
                  +       H(n1/2 z, ξ) q z (z|Y n ) − exp − nz 0 z            dz
                       RK                                         2
              = I + II, say.
                                                                                     25


Since |H(n1/2 z, ξ)| < MH , the first term can be bounded by
                                 Z                        r
                                           z    n             2π
                 I     ≤ MH               q (z|Y ) dz −
                                     RK                        n
                                 Z                        Z              
                                           z    n                     1 0
                       = MH               q (z|Y ) dz −        exp − nz z dz
                                     RK                     RK        2
                                 Z                                  
                                                               1
                       ≤ MH               q z (z|Y n ) − exp − nz 0 z dz
                                 RK                            2
                           M
                       ≤     .
                           n

The third inequality follows from Lemma 5. The bound for term II can be obtained in a
similar manner. 

Proof of Corollary 1(ii): Consider the following bound:

                 PYθ n {θ ∈ Tξ,n } − Hn (φ̂n , ξ)
                                            Z
                           θ
                  ≤ PY n {θ ∈ Tξ,n } −            Hn (φ̂n + Jˆn−1/2 s, ξ)φN (s)ds
                                               RK
                           Z h                                          i
                        +         Hn (φ̂n + Jˆn−1/2 s, ξ) − Hn (φ̂n , ξ) φN (s)ds
                            RK
                     = I + II, say.

Theorem 1 provides a bound for I. Using the Lipschitz assumption we deduce
               Z                                      Z
          ∗          ˆ−1/2                −1/2  ∗                            M (ξ)
   II ≤ M (ξ)      kJn skφN (s)ds ≤ n          M (ξ)      kΣ̂n kkskφN (s)ds ≤ √ .
                RK                                     RK                       n

The last inequality is a consequence of Lemma 1. 



References

 Andrews, Donald, Steven Berry, and Panle Jia (2004): “Confidence Regions for Parameters
     in Discrete Games with Multiple Equilibria, with an Application to Discount Chain
     Store Location,” Manuscript, Department of Economics, Yale University.

 Andrews, Donald and Patrik Guggenberger (2007): “Validity of Subsampling and ‘Plug-in
     Asymptotics’ Inference for Parameters Defined by Moment Inequalities,”Manuscript,
     Department of Economics, Yale University.

 Andrews, Donald and Gustavo Soares (2007): “Inference for Parameters Defined by Mo-
     ment Inequalities Using Generalized Moment Selection,”Manuscript, Department of
     Economics, Yale University.
                                                                                     26


Bajari, Patrick, Lanier Benkard, and Jonathan Levin (2007): “Estimating Dynamic Models
    of Imperfect Competition,”Econometrica, 75, 1331-1370.

Beresteanu, Arie and Francesca Molinari (2008): “Asymptotic Properties for a Class of
    Partially Identified Models,”Econometrica, 76, 763-814.

Bernstein, S.N. (1934): Theory of Probability, Gostekhizdat, Moscow.

Berry, Steven (1994): “Estimating Discrete Choice Models of Product Differentiation,”RAND
    Journal of Economics, 25, 242-262.

Bresnahan, Timothy and Peter Reiss (1991): “Empirical Models of Discrete Games,” Jour-
    nal of Econometrics, 48, 57-81.

Canay, Ivan A. (2007): “EL Inference for Partially Identified Models: Large Deviation
    Optimality and Bootstrap Validity,”Manuscript, Department of Economics, University
    of Wisconsin.

Canova, Fabio and Gianni De Nicolo (2002): “Monetary Disturbances Matter for Business
    Cycle Fluctuations in the G-7,”Journal of Monetary Economics, 49, 1131-59.

Chernozhukov, Victor, Han Hong, and Elie Tamer (2007): “Estimation and Confidence
    Regions for Parameter Sets in Econometric Models,”Econometrica, 75, 1243-1284.

Ciliberto, Federico and Elie Tamer (2007): “Market Structure and Multiple Equilibria in
    Airline Markets,”Manuscript, Department of Economics, University of Virginia and
    Northwestern University.

Galichon, Alfred and Marc Henry (2006): “Inference in Incomplete Models,”Manuscript,
    Columbia University.

Halie, Phil and Elie Tamer (2003): “Inference with an Incomplete Model of English Auc-
    tions,”Journal of Political Economy , 111, 1-51.

Imbens, Guido and Charles Manski (2004): “Confidence Intervals for Partially Identified
    Parameters,” Econometrica, 72, 1845-57.

Johnson, Richard, (1970): “Asymptotic Expansions of Associated with Posterior Distribu-
    tions,”Annals of Mathematical Statistics, 41, 851-864.

Kadane, Joseph B. (1974): “The Role of Identification in Bayesian Theory,” in S.E. Fien-
    berg and A. Zellner (eds.) Studies in Bayesian Econometrics and Statistics, 175-191.
    North Holland, Amsterdam.
                                                                                        27


Kim, Jae-Young (1998): “Large Sample Properties of Posterior Densities, Bayesian In-
    formation Criterion and the Likelihood Principle in Nonstationary Time Series Mod-
    els,”Econometrica, 66, 359-380.

LeCam, Lucien (1953): “On Some Asymptotic Properties of Maximum Likelihood Esti-
    mates and Related Bayes Estimates,” University of California Publications in Statis-
    tics, 1, 277-330.

Lubik, Thomas and Frank Schorfheide (2004): “Testing for Indeterminacy: An Application
    to U.S. Monetary Policy,” American Economic Review, 94, 190-217.

Manski, Charles (2003): Partial Identification of Probability Distributions, New York,
    Springer Verlag.

Manski, Charles and Elie Tamer (2002): “Inference on Regressions with Interval Data on
    a Regressor or Outcome,”Econometrica, 70, 519-547.

Pakes, Ariel, Jack Porter, Kate Ho and Joy Ishi (2005): “Moment Inequalities and Their
    Application,” Manuscript, Department of Economics, Harvard University.

Phillips, Peter C.B. and Werner Ploberger (1996): “An Asymptotic Theory of Bayesian
    Inference for Time Series,”Econometrica 64, 381-412.

Poirier, Dale (1998): “Revising Beliefs in Nonidentified Models,” Econometric Theory, 14,
    483-509.

Romano, Joseph P. and Azeem M. Shaikh (2006): “Inference for Partially Identified Econo-
    metric Models,” Manuscript, Stanford University.

Rosen, Adam (2005): “Confidence Sets for Partially Identified Parameters that Satisfy
    a Finite Number of Moment Inequalities,” Manuscript, Department of Economics,
    University College London.

Severini, Thomas (1991): “On the Relationship between Bayesian and Non-Bayesian In-
    terval Estimates,”Journal of the Royal Statistical Society. Series B, 53 611-618.

Sims, Chris and Harald Uhlig (1991): “Understanding Unit Rooters: A Helicopter Tour,”Econometrica,
    59, 1591-1599.

Stoye, Jörg (2007): “More on Confidence Intervals for Partially Identified Parameters,”
    Manuscript, Department of Economics, New York University.
                                                                                   28


Uhlig, Harald (2005): “What Are the Effects of Monetary Policy on Output? Results from
    an Agnostic Identification Procedure,” Journal of Monetary Economics, 52, 381-419.

von Mises, Richard (1965): Mathematical Theory of Probability and Statistics, Academic
    Press, New York.

Wu, Chien-Fu, (1981): “Asymptotic Theory of Nonlinear Least Squares Estimation,” An-
    nals of Statistics, 9, 501-513.
                                                                                               29




          Figure 1: Inference in the Inequality Condition Model, Known Length




Notes: The figures are drawn for φ̂n = 0 and overlay n = 5 and n = 500. The top panel
depicts posterior densities p(θ|Y n ) and 90% credible intervals. The bottom panel depicts
                                                  1
the standardized frequentist objective function   n Qn (θ),   the cut-off value cτ /n for τ = 0.1,
and 90% frequentist confidence intervals.
                                                                                          30




                   Table 1: Entry Game: “True” Parameters and Prior

                    Parameter    True Value         Prior Distribution
                                  Structural Parameters θ
                    β1               0.7                  N (0, 42 )
                    γ1               1.0                 N+ (0, 42 )
                    β2               0.5                  N (0, 42 )
                    γ2               1.0                 N+ (0, 42 )
                                  Auxiliary Parameter α
                    α                0.7       Benchmark: B(0.5, 0.22 )
                                     0.7            Low α: B(0.2, 0.12 )
                                     0.7            High α: B(0.8, 0.12 )
                           Implied Reduced Form Parameters φ
                    φ00              0.07       µ00 = 0.25, σ00 = 0.37
                    φ10              0.48       µ10 = 0.31, σ10 = 0.40
                    φ01              0.33       µ01 = 0.31, σ01 = 0.40
                    φ11              0.12       µ11 = 0.13, σ11 = 0.28




Notes: for the prior distribution of the reduced form parameters we report means µ and
standard deviations σ under α ∼ B(0.5, 0.22 ). N (ν, σ 2 ) and B(µ, σ 2 ) refer to Normal and
Beta distributions with mean µ and variance σ 2 .
                                                                                          31




                     Figure 2: Conditional Distribution of θ Given φ




Notes: Benchmark Prior (solid, green), Low α Prior (long dashes, red), High α Prior (short
dashes, blue). Each panel depicts 3 unconditional prior densities and 3 densities conditional
on the “true” φ. Except for α the unconditional prior densities appear invisible because
they are very diffuse compared to the conditional densities.
                                                                                         32




                       Figure 3: Posterior Distribution of φ, n = 50




Notes: Benchmark Prior (solid, green), Low α Prior (long dashes, red), High α Prior (short
dashes, blue). Since the posterior of φ is insensitive to the prior on α the three densities
appear on top of each other.
                                                                                       33




                      Figure 4: Posterior Distribution of θ, n = 50




Notes: Benchmark Prior (solid, green), Low α Prior (long dashes, red), High α Prior (short
dashes, blue).
                                                                                      34




                        Figure 5: Posterior Distribution of β1 and γ1




Notes: The panels depict draws from the posterior distribution and an outline of the pro-
jection of Θ(φ̂n ) onto the β1 -γ1 space.
