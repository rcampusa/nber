                                 NBER WORKING PAPER SERIES




                  DOES TEACHER TESTING RAISE TEACHER QUALITY?
                EVIDENCE FROM STATE CERTIFICATION REQUIREMENTS

                                             Joshua Angrist
                                            Jonathan Guryan

                                          Working Paper 9545
                                  http://www.nber.org/papers/w9545


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                      March 2003




This paper was prepared for the October 2002 conference in honor of Orley Ashenfelter’s 60th birthday.
Orley’s many contributions include early research on wage determination and unions in the public sector. The
authors thank Nate Baum-Snow, Naveed Khawaja, Andrew Kolesnikov and Nirupama Rao for excellent
research assistance. The confidential data used in this paper were provided by the National Center for
Education Statistics, U.S. Department of Education. This work is supported by the Centel Foundation/Robert
P. Reuss Faculty Research Fund at the Graduate School of Business, the University of Chicago. The views
expressed herein are those of the authors and not necessarily those of the National Bureau of Economic
Research.

©2003 by Joshua Angrist and Jonathan Guryan. All rights reserved. Short sections of text not to exceed two
paragraphs, may be quoted without explicit permission provided that full credit including ©notice, is given
to the source.
Does Teacher Testing Raise Teacher Quality? Evidence from State Certification Requirements
Joshua Angrist and Jonathan Guryan
NBER Working Paper No. 9545
March 2003
JEL No.J45, J48, J31, J24

                                             ABSTRACT

The education reform movement includes efforts to raise teacher quality through stricter certification
and licensing provisions. Most US states now require public school teachers to pass a standardized
test such as the National Teacher Examination. Although any barrier to entry is likely to raise wages

in the affected occupation, the theoretical effects of such requirements on teacher quality are
ambiguous. Teacher testing places a floor on whatever skills are measured by the required test, but

testing is also costly for applicants. These costs shift teacher supply to the left and may be especially
likely to deter high-quality applicants from teaching in the public schools. We use the Schools and
Staffing Survey to estimate the effect of state teacher testing requirements on teacher wages and
teacher quality as measured by educational background. The results suggest that state-mandated

teacher testing increases teacher wages with no corresponding increase in quality.


Joshua D. Angrist                               Jonathan Guryan
MIT Department of Economics                     University of Chicago Graduate School of Business
50 Memorial Drive                               1101 E. 58th St
Cambridge, MA 02142-1347                        Chicago, IL 60637
and NBER                                        and NBER
angrist@mit.edu                                 jonathan.guryan@gsb.uchicago.edu
         Economists, educators, and policymakers generally agree that better teachers are likely to lead to

better schools. But the question of how to attract better teachers remains open. A natural economic solution

is to raise teacher pay. From 1960 to 1998, teacher salaries rose in real terms by 43 percent, outpacing non-

teacher salaries. At the same time, the IQ scores of those who chose to teach fell, and evidence on the

relationship between salaries and measures of teacher quality or performance is mixed (Hanushek, Kain, and

Rivkin, 1999; Murnane, et al, 1991; Figlio, 2002).

         Beginning in the 1960’s, states began testing prospective teachers in a direct effort to ensure teachers

meet minimum standards for basic skills and subject knowledge.1 By 1999, 43 states required applicants to

pass some sort of standardized certification test such as the National Teacher Examination or Praxis

examinations published by the Educational Testing Service.2 Although there is some reciprocity in the form

of probationary and provisional licensing, states relying on tests typically require newly employed teachers

to pass their own tests even if they are licensed in other states. As a theoretical matter, the impact of such

testing is ambiguous. Test requirements may establish a minimum achievement standard, as their proponents

argue, but certification requirements may also deter applicants from choosing to teach. Moreover, stricter

certification procedures may be seen as especially costly hurdles by experienced teachers or teachers with

attractive employment options in other fields.

         In this paper, we estimate the impact of state-mandated certification tests on teacher quality. Data




         1
           Testing of teachers is not a new phenomenon. Teachers were tested in basic subjects in many states in the
19 century and at the beginning of the 20th century. However, in most states the tests were graded and certificates
  th

were issued at the county level. In the early part of the 20th Century a number of states began more widespread use
of testing for certification. But World War II led to a decrease in teacher supply and a subsequent increase in hiring
of teachers with alternative certification. As a result, most states had discontinued the use of required teacher testing
by the end of the war.
         2
          Since 1998, the ETS National Teachers Examination widely used to certify Education School graduates for
work as teachers has been known as the Praxis II and is part of a series that includes Praxis I, also known as the Pre-
Professional Skills test (PPST) which is used to screen applicants to Education Schools, and a series of classroom
performance assessments known as Praxis III. Many states (e.g., Minnesota as of September 2001) require both
Praxis I and Praxis II. As of this writing, sample Praxis content is available at
http://www.ets.org/praxis/download.html. The Praxis examinations consist of dozens of subtests. Each state selects
their own credentialing requirements. Some states, such as California, require a combination of Praxis tests and
locally developed tests, others, such as Massachusetts, rely on a locally developed exam only.
for our study come from the Schools and Staffing Survey (SASS), a nationally representative repeated cross-

section of teachers and schools, initially conducted during the 1987-88 school year and most recently

available for 1999-2000. This sample coverage is useful since testing requirements have grown most sharply

in recent years. In addition to providing information on teacher salaries, the 1987-88, 1993-94, and 1999-

2000 waves of SASS include measures of teacher educational background that we take to be indicators of

teacher quality. We first show that the impact of state provisions on the prevalence of teacher testing is about

50 percentage points. Consistent with the notion that certification requirements establish barriers to entry,

we also find that teacher testing increases teacher salaries. On the other hand, we find no evidence that

testing increases the quality of colleges attended by new teachers or the likelihood that teachers teach

material studied in college or graduate school.



                                              BACKGROUND

        A 1986 report of the Carnegie Task Force on Education and a follow-up report released in 1996

called for the introduction of more centralized systems of certification for public school teachers. A policy

of stricter and more centralized teacher licensing has also been supported by the National Education

Association and a range of groups promoting education reform (Ballou and Podgursky, 2000). Proposed

licensing systems involve the accreditation of education programs, longer apprenticeships, and teacher

testing. Proponents of teacher licensing point to the spread of medical licensure in the early 20th Century as

evidence that licensing raises professional standards. On the other hand, economists have long warned that

licensing and certification are potentially cost-raising barriers to entry (see, e.g., Friedman and Kuznets,

1945). Moreover, there is little hard evidence for any consumer benefits of mandatory occupational

licensing, even in medicine. In this paper, we attempt to estimate the impact of what is perhaps the simplest

component of teacher licensing provisions, a requirement that teachers pass a certification test that can be

seen as analogous to medical boards and legal bar exams.


                                                       2
        In a recent survey of research on occupational licensing, Kleiner (2000) observes that more American

workers are affected by licensing requirements than belong to unions or are covered by the minimum wage.

Yet there are remarkably few studies of the impact of licensing on wages or productivity. Standard economic

arguments suggest licensing provisions are likely to affect economic outcomes through a number of channels.

First, occupational licensing may provide a signal of worker quality and help to maintain quality standards

when information about quality is imperfect. Indeed, this is the stated rationale for government-imposed

licensing requirements. As Kleiner (2000) notes, however, the evidence of consumer benefits from most

licensing requirements is thin or nonexistent. In addition, mandatory licensing requirements impose a barrier

to occupational entry that is likely to increase wages in the licensed occupation.3

        One of the few previous attempts to estimate the effect of licensing requirements is a study of

teachers by Kleiner and Petree (1988), who link state licensing requirements with average teacher pay,

pupils’ SAT and ACT scores, and high school graduation rates. Their results show no clear relationship

between licensing and pupil achievement or teacher pay, though there is a robust negative relationship

between licensing and pupil-teacher ratios. The authors attribute the ambiguous results on licensing to the

weak licensing provisions in force during their sample period. The recent strengthening of state teacher

licensing provisions may provide stronger evidence on licensing effects. Another related study is Goldhaber

and Brewer (2000), who link student achievement with state teacher licensing and testing requirements.

Their analysis does not exploit changes in state provisions over time, and the effects of testing enter only as

interactions with other licensing provisions. Consistent with the entry-barriers story, Hanushek and Pace

(1995) find that state requirements for courses and tests significantly lower the probability prospective

teachers complete training, again using cross-state variation.

        Most studies of the economic consequences of occupational licensing look at the medical and dental



        3
         The literature on occupational regulation distinguishes between mandatory licensing such as that required
of medical professionals and voluntary certification such as that sometimes obtained by auto mechanics.

                                                         3
professions. In a study of dentistry, for example, Kleiner and Kudrle (2000) found that people in states with

strictly regulated entry to dentistry had dental health that is no better than those in states with less regulation.

Dental regulation, however, does appear to increase both the hourly earnings of dentists and consumers’ cost

of dental care.4 Similarly, in a recent study of immigrant physicians in Israel, Kugler and Sauer (2003) found

that immigrant physicians who obtained a license to practice medicine in Israel had sharply higher earnings

than those who did not. At the same time, a comparison of OLS and instrumental variables (IV) estimates

of the effect of licensing suggests that doctors who obtain licenses and end up practicing medicine have

lower earnings potential than those who do not. Thus, licensing appears to reduce average quality. It should

be noted, however, that teachers differ from medical professionals in that they are more likely to work in the

public sector. Certification may be more necessary to reveal worker quality in the absence of the market

forces more likely to operate in the private sector.



                                       THEORETICAL FRAMEWORK

        Although the theoretical impact of teacher testing on wages seems clear cut, the effect of testing on

quality is less so. The policy objective that motivates teacher testing, as with other worker screening devices,

is to identify and hire those most qualified to teach. In practice, however, the design of effective testing

strategies is difficult since tests are noisy predictors of worker quality. Moreover, testing is costly for

employers and employees. Teacher supply therefore shifts as salaries must compensate workers for their

time and effort in being tested. Finally, risk averse workers will view employment offers that are contingent

on stochastic test results as less attractive than unconditional offers.

        A large theoretical literature has looked at the impact of worker screening mechanisms on wages and

job assignments. We use basic elements of the Gausch and Weiss (1980, 1981) setup to discuss the possible


        4
         Licenses for dentistry appear to be the most widely studied in research on licensure. See Kleiner and
Kudrle (2000) for references to earlier work on dentists. Kleiner (2000) also compares wages in licensed
occupations with wages in unlicensed occupations requiring approximately the same level of education and training.

                                                         4
implications of standardized testing for teacher quality.5 Because school districts are not necessarily profit

maximizers or even costs minimizers, we focus on the impact of test-based hiring standards on teachers’

labor supply, as opposed to the more complex question of how worker testing affects equilibria in

competitive markets.

        Suppose an applicant for a teaching job can earn an alternative wage, wi, and teachers are paid w.

Applicants must be tested to get a job, a process which they view as costing an amount c. We can think of

c as a monetary cost or as the cost of time and effort directed towards preparation and completion of the test.

More generally, testing might involve a probationary period, in which case any wage reduction during the

probationary period is part of the testing cost.

        Worker i passes the test with probability pi. We presume the test has some screening value, so that

pi and wi are positively correlated. In other words, higher quality applicants, as measured by outside earnings

potential, are more likely to pass the test. Assuming teachers maximize expected utility with von Neumann-

Morgenstern utility of income U(C), applicant i must be offered a wage that satisfies

        pi U(w!c) + (1-pi)U(wi!c) $ U(wi)                                                                        (1)

if he or she is to find it worth applying. Clearly with a higher c, the wages offered teachers, w, must be

higher to obtain an applicant pool of the same quality. This is the entry-barrier effect on wages; positive c

reduces the supply of applicants, holding the underlying distribution of quality level wi fixed. Note also that

this effect is larger with risk averse than with risk-neutral applicants. Risk-neutral applicants require only

that pi(w!wi) $ c.

        How does testing affect average quality? Continuing to think of quality as indexed by the alternate

wage, wi, suppose that school boards would like to select applicants with wi$w
                                                                             G . For simplicity, suppose also

that applicants are risk neutral and that the certification test can be designed so that pi=1 if wi$w
                                                                                                    G and is zero




        5
         See also Lelande (1979). For more recent and more elaborate models along these lines, see, e.g., Wand
(1997) and Wang and Weiss (1998).

                                                        5
otherwise. Then average teacher quality in the testing regime is

         E[wi | w!c > wi $ w
                           G ].                                                                                    (2)

This average can be compared with the average teacher quality without testing, which is equal to E[wi | w >

wi]. Clearly the quality comparison depends on how w and c are determined. The imposition of a lower

       G , tends to increase quality. But if testing is viewed as very costly, so that the net teacher wage in
bound, w

the testing regime, w!c, is less than the teacher wage without testing, average quality may decline. This

decline in average quality occurs in spite of the fact that the lower quantiles of the quality distribution will

have increased if testing is effective.

         The notion that costly and time-consuming certification requirements limit teacher supply or

adversely affect teacher quality is behind education reform efforts promoting “alternative certification” paths

for public school teachers. Many researchers have noted that even though salaries tend to be higher in public

schools than private schools, bureaucratic and costly certification requirements may send the best teachers

to private schools, where these requirements are not imposed (e.g., Goldhaber and Brewer, 2000). Note also

that if c includes the opportunity cost of time invested in test preparation and test taking, then testing costs

                                                                                                       G .6
will be an increasing function of wi, further eroding the quality-enhancing effect of the lower bound, w

Finally, the discussion here presumes that teacher testing is of great value in predicting teacher quality.

While the National Council for the Accreditation of Teacher Education (1997) promotes this view, it seems

likely that the question of what teachers should know is not entirely clear-cut. In practice, those with wi $ w
                                                                                                              G

may not actually be more productive in the classroom.




         6
           Alternately, applicants with higher wi may also be better test-takers, implying c and wi are negatively
correlated. Then increased costs will tend to deter lower the average wi among applicants. The size of the net effect
of testing is the empirical question addressed below.

                                                          6
                                   DATA AND DESCRIPTIVE STATISTICS

         Data for this study come from the Teacher Demand and Shortage Survey (TDSS), a component of

the Schools and Staffing Survey (SASS), which links information on school districts, teachers, and students.

The first round of the SASS was in the 1987-88 school year, followed by rounds in 1990-91, 1993-94, and

1999-2000. The core survey in the SASS is a complex stratified sample of schools, drawn largely from the

Department of Education’s Common Core of Data (CCD) which is an administrative roster of schools from

state education agencies. Data for the TDSS come from surveys distributed to superintendents of Local

Education Agencies (LEAs; essentially, school districts) containing sampled schools. In addition, teachers

in sampled schools complete a Teacher Survey. Other components of the SASS, not used here, include a

School Principal Survey, a Teacher Follow-up Survey, and a collection of student records (in 1993-94 only).

Our estimates use the weights provided with the TDSS to make sample statistics representative of US school

districts.7

         Information on district testing requirements comes from the TDSS, as do other characteristics of the

district such as starting salaries and district size. In addition, we aggregate responses to the teacher survey

up to the district level to provide district-level measures of teacher characteristics and quality such as the

proportion of teachers who teach in their subject. We also match quality measures such as the average SAT

score in the teachers’ undergraduate institution from the Higher Education Research Institute to the SASS

LEA file. Although these quality measures are not as detailed as we would like, average SAT score of

undergraduate institution is a frequently used measure of new teacher quality (see, e.g, Figlio, 2002). Finally,

we collected information on state testing requirements for each survey year from published summaries.8 The

sample used here excludes districts with less than 50 pupils, below about the first percentile in the district

size distribution. The sample includes public schools only and omits charter schools in the last year


         7
          About one-third of districts appear in a subsequent round but we ignore this in the statistical analysis.
         8
          For a list of sources used to compile state testing requirements, see the data appendix.

                                                           7
(typically, each charter school is its own district). For additional details on the construction of the sample

and variable definitions, see the data appendix.



Descriptive statistics

        Table 1 reports descriptive statistics by survey year. Each round contributes almost 5,000 districts.

The average district size is about 3,000 pupils and 160 teachers. The table also shows the proportion of

districts with inexperienced teachers, defined as those hired in the last 3 years (preceding the survey) and

the proportion of districts with teachers hired in the past year. Over 40 percent of districts have

inexperienced teachers and almost 20 percent have hired teachers in the past year. In the analysis below, we

report results separately for the full sample, and for the 3-year and 1-year samples, since testing requirements

may have a bigger impact in districts that have recently been hiring.

        The first outcome variable used to measure the impact of teacher testing is teacher wages. Although

the theoretical discussion suggests the effect of testing on the distribution of teachers’ alternate wages is

ambiguous, the effect on teachers’ wages is likely to be positive since testing restricts supply (note that w!c

has to exceed the quality threshold). The SASS reports the wages paid to teachers in each district by

schooling and experience level, i.e., for teachers with a Bachelor’s degree (B.A.), with a Master’s degree

(M.A.), and with a Master’s degree plus 20 or more years of experience. The table shows teacher wages for

those with a B.A. of around 25,000-26,000 (1999 dollars). Wages went up between 1993-94 and 1999-2000.

Wages are also about 10 percent higher for those with an M.A., and much higher for experienced teachers

with a Master’s degree.

        To measure teacher quality we look at the average SAT scores of teachers’ undergraduate institution,

whether the institution is coded as a research university or liberal-arts college, the proportion of teachers with

alternative state certification, and the proportion of teachers with a degree in the subject they teach. Note

that the SAT and Carnegie variables cannot be linked to the 1990-91 SASS since this round did not identify


                                                        8
teachers’ undergraduate institutions. The college-based quality variables show fairly stable quality over the

sample period. In contrast, there is an increase in the proportion of inexperienced and new teachers with

alternative certification, and an increase in the proportion of teachers who have a degree in the subject they

teach. Finally, the table provides descriptive information for other characteristics of the teacher workforce

that might be affected by licensing. This includes the sex, race, and Hispanic ethnicity distribution among

all teachers and recently hired teachers.



Testing prevalence and requirements

         The proportion of districts subject to a state-mandated basic skills test requirement increased from

just over 40% in 1987-88 to 70% in 1993-94. This can be seen in the first row of Table 2, which reports the

prevalence of state test requirements based on our match of information for each state to the SASS. Although

the number of districts requiring a basic skills test fell slightly between 1993-94 and 1999-2000, the number

of states requiring tests continued to increase and reached two-thirds.9 Fewer states required a subject test

than required a test of basic skills in 1987, but this requirement also saw a dramatic and steady increase, so

that the proportion requiring subject and basic skills tests were about equal by 1999. By 1999, over 80% of

districts faced some kind of state-mandated test requirement.

         In addition to using published state testing requirements, we analyzed SASS questions put to district

administrators about the use of testing. In particular, the following two questions are relevant:

         Do you require or use information on whether an applicant passed a STATE test of
         basic skills?

         Do you require or use information on whether an applicant passed a STATE test of
         subject knowledge?

SASS respondents (i.e., officials completing the SASS on behalf of the district) answered with:



         9
          A few large states reversed their basic skills testing requirements so the proportion of districts requiring
testing dipped between 1993 and 1999.

                                                            9
         Require;

         Use, but not require;

         Do not use.

Rows 4, 5, and 6, in Table 2 show the proportion of districts which report they require state tests.

Surprisingly, this proportion is below the proportion of districts who were subject to a state-mandated test

requirement.

         The difference between state testing requirements and districts’ reported testing practices seems most

likely to be due to inaccurate responses and misunderstandings of SASS questions related to applicant

screening. We substantiated this hypothesis by surveying a sample of districts. In particular, we

administered the applicant-qualifications portion of the 1999-2000 SASS to 211 “dissonant districts” ,

defined as those where SASS responses to questions on testing conflicted with state requirements.10 In

response to our survey, only 13 percent of districts reported they neither use nor require a state test of basic

skills while only 17 percent reported they neither use nor require a state test of subject knowledge. On

further inquiry with some districts, we discovered that where tests are required, districts may waive this under

difficult hiring conditions, but typically still hope to “use the test”. An occasional source of confusion,

however, had to do with the definition of a “state requirement” or a “state test”. For example, the state may

require ETS’s Praxis exam, not strictly speaking a state test along the lines of, say, the test developed and

used by districts in the state of Massachusetts. In any case, the majority of districts in our sample appeared

to be trying to follow state testing mandates.

         The last three rows show the proportion of districts using tests based on a variable constructed by

recoding the response to SASS test-use questions to be consistent with state requirements (e.g., districts who

         10
            A district was determined to be dissonant if the response to both the basic skills and subject test questions
indicated no test requirement and no test use while the state required testing. We sampled up to 10 dissonant
districts in any state with dissonant districts. Of the 322 districts sampled, we obtained responses from 211 districts
for a response rate of 66 percent. In each district surveyed, we attempted to contact “the director of personnel or
someone knowledgeable about personnel policies in the district.” The original sample contained 7 vocational
districts and one charter district, so these factors cannot account for reporting conflicts.

                                                           10
report not using a subject test in a state that requires subject testing were recoded as using a subject test).

Not surprisingly, these recoded variables have higher means than the raw SASS responses in the second three

rows. They also show a consistent pattern of increasing test use over time. The impact of state requirements

on testing is gauged on the basis of these recoded variables.



Effects of state testing requirements on testing

        The impact of state testing requirements on test use is summarized by regressing dummies for test

use on dummies for state mandates, along with state and year main effects, dummies for urban, suburban,

and rural districts, district enrollment, district fraction minority enrollment, and a quadratic in the state

unemployment rate. In particular, Table 3 reports estimates of the coefficients "1 and "2 on basic skills and

subject test mandate dummies, bjt and sjt, in the equation

                 yijt = :s + *t + XijtN$ + "1bjt + "2sjt + ,ijt,                                               (3)

where yijt is an indicator for district requirements, :s and *t are state and year effects, and Xi is the vector of

other covariates (including individual district controls and the state-level unemployment rate). Some of the

models combine the separate basic skills and subject dummies into a single dummy for any test.

        Even in states that do not require testing, many districts use tests. Estimates of equation (3) can

therefore be seen as a measuring the difference between test use with and without requirements. Table 3

shows that state-mandated basic skills testing increases the likelihood of basic skills testing in school districts

by about 50 percent. As can be seen in column 2, subject test requirements are also correlated with the use

of basic skills tests, but column 3 shows that when both dummies are included, the basic skills requirement

dominates. The reverse pattern appears in columns 5-7 for models with the use of subject tests on the left

hand side. The imposition of any test requirement also increases the likelihood of testing by about 50

percent. Moreover, as the lower two-thirds of Table 3 shows, these effects are similar when the sample of

districts is limited to those that have new or inexperienced teachers.


                                                            11
                                            EFFECTS ON WAGES

        State testing requirements are associated with slightly higher wages. This can be seen in Table 4a,

which reports estimates of equation (3) for models with the log of teacher salaries on the left hand side.

Many of the estimated salary effects are significant. For example, column 1 shows that the salaries of

teachers with a B.A. degree are about 2.4 percent higher when states require a test of basic skills, an effect

estimated with a standard error of .009.11 Subject test requirements also appear to be associated with higher

wages, though the estimated effects of testing requirements are not significant when both the subject and

basic skill testing variables are entered at the same time.

        Most new teachers have a B.A. As the estimates in columns 5-8 and 9-12 show, however, state

testing requirements are also associated with higher wages for teachers with an M.A. and for experienced

teachers with an M.A. Since teachers with more advanced degrees and more experience are less likely to

have been hired recently, these effects may reflect the maintenance of relative wages by shifting the entire

pay scale in response to testing requirements. It should also be noted that in some states that require tests

for new hires, experienced teachers are subject to periodic re-certification tests as well.

        An alternative interpretation of the increase in wages for more educated or more experienced

teachers is that these effects reflect some sort of omitted variables bias. The possibility of omitted variables

bias is also raised by the fact that the estimated wage effects are similar in the full sample and the samples

of districts with inexperienced and new-teachers. Because testing requirements are time-varying state-level

variables, the most likely source of bias is some sort of state-specific trend in teacher wages in states that

adopt testing requirements. Therefore, as a specification check we re-estimated the wage equations using

a model that adds state-specific linear trends to specification (3). This controls for the fact that teacher

wages may be increasing due to secular trends such as a growing economy that contribute to the demand for



        11
          The regression estimates reported here and elsewhere in the paper were weighted using district sampling
weights. Standard errors are corrected for state-year clustering.

                                                        12
higher entry barriers. One possibility, for example, is that unions raise entry barriers in good times. On the

other hand, our survey of district personnel officers suggests districts and therefore perhaps also states want

to weaken formal requirements when teachers are hard to find.12

         The results of estimating equation (3) with state-specific linear trends, reported in Table 4b, show

even stronger wage effects than appear in Table 4a. For example, the imposition of a state test of basic skills

is associated with roughly 3.3% higher wages for teachers with a B.A., a precisely estimated effect.

Moreover, the effects of requiring tests of basic skills and subject matter remain significant when entered

jointly. The fact that estimates with state trends are larger is consistent with the view that testing provisions

are weakened in a strong economy. Most importantly, the pattern of effects is now more consistent with a

causal interpretation that attributes higher wages to the impact of state testing regulations. In particular, the

effects of testing are generally larger for teachers with a B.A. than for those with more education or

experience, consistent with the notion that entry wages should change the most in response to barriers.

Similarly, the effects are larger in the sample of districts that have new or inexperienced teachers than in the

full sample of districts.13

         Finally, it is worth repeating that the first-stage estimates of the effect of testing requirements in

Table 3 are on the order of 50 percentage points. This implies that two-stage least squares (2SLS) estimates

of the effect of the use of testing on teacher wages – using state testing regulations as instruments – are about



         12
            Angus (2001) and Ravitch (2002) argue that teacher certification requirements have been used to control
entry into the teaching profession since the mid-19th Century. The major players in the struggle to control entry
have been classroom teachers, professors of education and pedagogy, and professors of liberal-arts subjects. Various
groups were typically successful at increasing barriers to entry at times of abundant relative teacher supply. For
example, testing was a relatively common component of teacher certification in the early part of the 20th century. As
World War II drew current and potential teachers to other industries and occupations, however, states recognized
districts’ need to circumvent the strict licensure requirements. As a result, the use of tests declined dramatically
during the war. Note that endogeneity of this sort would tend to bias our estimated wage effects towards zero.
         13
            We also looked at whether testing has a different effect in non-union districts, as suggested by Figlio
(2002). We found no clear pattern of differences in impact by union status. It should be noted, however, that the
precision of union/non-union interactions is limited by the facts that the SASS collected district union status for only
two years and over 70% of districts are unionized.

                                                          13
twice as large as the reduced-form effects of testing regulations reported in Table 4.14



                            EFFECTS ON QUALITY AND OTHER OUTCOMES

         Although state testing requirements are associated with increased use of teacher tests and with higher

teacher wages, there is little evidence that this translates into better teachers, at least along the quality

dimensions we can measure. For example, columns 1-4 of Table 5 show no clear pattern of an association

between testing requirements and the quality of teacher’s undergraduate institutions as measured by average

SAT scores. While a required subject test is associated with a marginally significant increase in test scores

when both testing requirements are entered jointly and the sample includes districts with inexperienced

teachers (column 3), this effect is smaller and insignificant in all other specifications in this sample, and

insignificant and negative in the sample of districts with new teachers. Similarly the estimates in columns

5-8 do not point to an association between testing and the quality of teachers’ undergraduate institutions as

measured by the institutions’ classification as a research university or a liberal arts college.

         Two other measures of quality, alternative certification and whether teachers majored in their

teaching subject, describe teachers’ job assignments as opposed to teachers’ educational background. Of

course, the use of alternative certification methods could be seen as a plus or a minus, depending on the value

of traditional certification methods as a quality screen. An important question for our purposes, however,

is whether the introduction of tests is confounded with other sorts of licensing reforms. As it turns out,

alternative certification is uncorrelated with testing requirements. This suggests that it is reasonable to look

at testing requirements in isolation.

         In contrast with the alternative certification results, the probability that a teacher majored in their



         14
           The resulting 2SLS estimates need not capture the average causal effect of licensing on wages since the
amount teachers must be compensated to take a test may be a function of the relative scarcity of non-tested jobs.
Assuming such general equilibrium effects are modest, however, the implied 2SLS estimates can be seen as
capturing the average causal effect of licensing for districts that would not otherwise chose to test, in a world with
the observed baseline prevalence of testing.

                                                           14
teaching subject appears to rise in states that impose a subject test. On the other hand, this effect is not very

robust. When estimated in the sample of inexperienced teachers, the imposition of a subject test increases

the probability teachers teach in their major by about 2.7 percent, with a standard error of .011, but the

corresponding estimate is about half as large and insignificant in the sample of new teachers.

        The last set of estimates looks at the relationship between state testing requirements and the

demographic make-up of the teaching labor force. This inquiry is motivated partly by the fact that

standardized tests are sometimes thought to be more of a barrier for minorities. The first 4 columns of Table

6 show no relationship between state testing requirements and the percent of new or inexperienced teachers

who are black. On the other hand, there is some evidence of a negative association between testing

requirements, especially for basic skills, and the number of new teachers who are Hispanic. Columns 5-8

suggest that testing requirements reduce the proportion of new teachers who are Hispanic by about 2

percentage points, a large effect given that only 5 percent of new teachers were Hispanic in 1999-2000.

Finally, there is no relationship between testing requirements and the proportion of teachers who are female.



                                               CONCLUSIONS

        Recent years have seen an acceleration in the use of standardized tests when certifying new teachers.

Proponents hope these measures will help to maintain quality, but economists have long been skeptical of

entry barriers that may shift supply and discourage otherwise qualified applicants. Our investigation of the

impact of the use of tests to certify teachers for employment in public schools suggests state requirements

increase the use of tests by about 50 percentage points. Testing requirements are also associated with higher

teacher wages, consistent with a supply-shift story. Taking estimates from models that control for state-

specific linear trends, the reduced form effect of testing on wages is 3-5%. The implied two-stage least

squares effect of the use of tests is twice as large. But there is little evidence of an impact of testing on

teacher quality, at least as we measure it. Thus, our results are consistent with the view that testing has acted


                                                       15
more as a barrier to entry than a quality screen. Another interesting finding is the negative association

between teacher testing and probability new teachers are Hispanic.

         As a final bit of anecdotal evidence in support of a skeptical view of testing, it is worth observing

that while occupational licensing requirements are widespread and apparently increasing, most skilled

workers in the private sector are not subject to formal licensing or testing. For example, like many

professionals involved in research, American professors are not tested by their universities or even by most

(non-civil-service) non-academic employers.15

         Concerns about testing notwithstanding, the question of how to increase and maintain the quality of

the public-sector teacher labor force remains. Ballou’s (1996) results indicate that school districts pay

surprisingly little attention to the selectiveness of applicants undergraduate institution. Along these lines,

Manski (1987) suggested that a floor for teachers’ SAT scores could provide a useful screen. A reliance on

SATs would appear to avoid some of the problems outlined in our theoretical discussion since this avoids

the establishment of a unique barrier to teaching, and may also force school districts to focus more on college

quality. This naturally raises the question of whether teachers with higher SAT scores are indeed better

teachers, a subject for future research.




         15
           It may be instructive to compare the relatively free-wheeling US academic labor market with that of Italy
and Germany, where faculty are subject to testing. The top Ph.D. programs in the US are full of students from these
countries so the undergraduate talent is clearly there. But our impression from discussions with foreign colleagues is
that these requirements are widely seen by recent American-trained Ph.D.s as protecting domestically trained and
generally less productive incumbents.

                                                         16
Data Appendix:

         The analysis extract was drawn from the Public School Teacher Demand and Shortage Survey
(TDSS) component of the Schools and Staffing Survey (SASS). The TDSS is administered to a stratified
random sample of school districts in the U.S. The data used in the analysis are from the restricted-use files
of the 1987-88, 1990-91, 1993-94 and 1999-2000 waves of the SASS. Individual teacher-level information
is extracted from the Teacher Questionnaire of the SASS. Characteristics of colleges attended by teachers
are then merged by college FICE codes to the teacher-level data. These data are then weighted by sampling
means, aggregated to the district level, and merged to the district-level TDSS. Finally, state-by-year
economic measures are merged to the data set. Districts with fewer than 50 students are dropped from the
analysis, as are charter districts in the 1999-2000 wave. Throughout the analysis, first-year teachers are
defined as teachers who report their first year of teaching to be the year of the survey. Inexperienced teachers
are defined as teachers who report their first year of teaching to be less than four years before the year of the
survey.

The following definitions were used to create outcome variables extracted from the SASS:

Salary: B.A.: Data come from district-level responses. The base salary paid to a teacher in the district with
a Bachelor’s of Arts degree, no teaching experience, and no other relevant credentials. Responses are
inflated to 1999 dollars using the CPI-U.

Salary: M.A.: Data come from district-level responses. The base salary paid to a teacher in the district with
a Master’s degree, no teaching experience, and no other relevant credentials. Responses are inflated to 1999
dollars using the CPI-U.

Salary: M.A. + 20 years: Data come from district-level responses. The base salary paid to a teacher in the
district with a Master’s degree, at least 20 years teaching experience, and no other relevant credentials.
Responses are inflated to 1999 dollars using the CPI-U.

Majored in Teaching Subject: Data come from individual teacher responses. A dummy is created that equals
one if one of the following three criteria are met: (1) the teacher’s primary teaching assignment is
Mathematics and he completed either a B.A, M.A. Ph.D. or Education Specialist degree with a major in
either Mathematics, Engineering or Economics; (2) the teacher’s primary teaching assignment is English and
he completed either a B.A, M.A. Ph.D. or Education Specialist degree with a major in English Literature,
Letters, Speech, Classics or Composition; (3) the teacher’s primary teaching assignment is either Biology,
Chemistry, Geology/Earth Science, Physics or General Science and he completed either a B.A, M.A. Ph.D.
or Education Specialist degree with a major in either Biology, Chemistry, Geology/Earth Science, Physics,
or another Physical Science. This dummy variable is then aggregated using sampling weights to compute
the fraction of first-year teachers and inexperienced teachers for which the dummy is equal to one.

Alternative Certification: Data come from individual teacher responses. Teachers are asked what type of
state certification they hold in their main assignment field. A dummy is created that equals zero if the teacher
describes his certification as either regular, standard or advanced, and one otherwise. This dummy variable
is then aggregated using sampling weights to compute the fraction of first-year teachers and inexperienced
teachers for which the dummy is equal to one.

The following definitions are used to define hiring-practices variables extracted from the SASS:


                                                       17
Requires Basic Skills Test: Data are drawn from the TDSS survey of school districts. Districts are asked
whether they require teaching applicants to have passed a test of basic skills. A dummy is created which is
equal to one if the district requires a state test of basic skills, a district test of basic skills or the National
Teachers Exam/Praxis. In some of the analysis, this variable is automatically switched to one if the district
is in a state that is mandated by law to require new teachers to pass a standardized test of basic skills.

Requires Subject Test: Data are drawn from the TDSS survey of school districts. Districts are asked whether
they require teaching applicants to have passed a test of basic skills. A dummy is created which is equal to
one if the district requires a state subject test, a district subject test or the National Teachers Exam/Praxis.
In some of the analysis, this variable is automatically switched to one if the district is in a state that is
mandated by law to require new teachers to pass a standardized subject test.

The following definitions are used to define quality measures of undergraduate institutions attended by
teachers:

Average SAT Score: Data come from a survey conducted by the Higher Education Research Institute. The
average combined Math and Verbal SAT score of entering freshman in the fall of 1983 is collected for
colleges and universities from college guides and from surveys of college representatives. For schools that
do not require students to take the SAT, ACT averages are translated into SAT averages using the following
methodology. Samples of students who took both the SAT and ACT, or who took either test and a third
common test (the National Merit Scholarship Qualifying Test) are compared. These overlapping samples
are used to compute the equivalent percentiles in each test’s distribution. ACT scores are then replaced with
the corresponding SAT scores at the equivalent point in the distribution.

Attended Research University or Liberal Arts College: A dummy variable is created that equals one if the
college attended by the teacher is in one of the following categories of the Carnegie Classification of
Institutions of Higher Education (1994 definitions): Research University I, Research University II, or
Baccalaureate (Liberal Arts) Colleges I. The three categories included in the dummy are the three non-
specialized categories with average SAT scores greater than 1000.

Information on state testing laws was drawn from the following sources:

Teacher Education Policy in the States: A 50-State Survey of Legislative and Administrative Actions,
        American Association of Colleges for Teacher Education (Washington, DC: December 1994).
Teacher Education Policy in the States: A 50-State Survey of Legislative and Administrative Actions,
        American Association of Colleges for Teacher Education (Washington, DC: Spring 1994).
Goertz, Margaret E., State Educational Standards in the 50 States: An Update, Educational Testing Service
        (Princeton, NJ: March 1988).
Coley, Richard J. and Goertz, Margaret E., Educational Standards in the 50 States: 1990, Educational
        Testing Service (Princeton, NJ: June 1990).
Rudner, Lawrence M., What’s Happening in Teacher Testing: An Analysis of State Teacher Testing
        Practices, U.S. Department of Education (Washington, DC: August 1987).
The NASDTEC Manual on the Preparation and Certification of Educational Personnel, Kendall/Hunt
        Publishing Company (Dubuque, IA: 1999).




                                                        18
                                             REFERENCES

Angus, David L. (2001), Professionalism and the Public Good: A Brief History of Teacher Certification, ed.
Jeffrey Mirel , Washington, DC: The Fordham Foundation.

Astin, Alexander W., Kenneth C. Green, William S. Korn and Mary Jane Maier, The American Freshman:
National Norms For Fall 1983, Cooperative Institutional Research Program of the American Council on
Education.

Astin, Alexander W. (1971), Predicting Academic Performance in College: Selectivity Data for 2300
American Colleges, New York: The Free Press.

Astin, Alexander W. and James W. Henson (1977), “New Measures of College Selectivity,” Research in
Higher Education 6, 1-9.

Ballou, Dale (1996), “Do Public Schools Hire the Best Applicants?,” The Quarterly Journal of Economics
111, 97-133.

Ballou, Dale and Michael Podgursky (2000), “Gaining Control of Professional Licensing and Advancement,”
in Tom Loveless, ed., Conflicting Missions? Teachers Unions and Educational Reform, Washington, DC:
The Brookings Institution.

Figlio, David (2002), “Can Public Schools Buy Better-Qualified Teachers?,” Industrial and Labor Relations
Review 55, 686-699.

Friedman, Milton F., and Simon Kuznets (1945), Income from Independent Professional Practice, New
York: National Bureau of Economic Research.

Goldhaber, D., & Brewer, D. (2000), Does teacher certification matter? High school teacher certification
status and student achievement, Educational Evaluation and Policy Analysis, 22(2), 129-145.

Guasch, J. Luis and Andrew Weiss (1980), “Wages as Sorting Mechanisms in Competitive Markets with
Asymmetric Information,” Review of Economic Studies 47, 653-64.

Guasch, J. Luis and Andrew Weiss (1981), “Self-Selection in the Labor Market,” American Economic
Review 71, 275-84.

Hanushek, Eric A. and Richard A. Pace (1995), “Who Chooses to teach and Why,” Economics of Education
Review 14, 101-117.

Hanushek, Eric A., John F. Kain, and Steven G. Rivkin (1999), “Do Higher Salaries Buy Better Teachers?,”
NBER Working Paper 7082, April.

Kleiner, Morris M. (2000), “Occupational Licensing,” Journal of Economic Perspectives 14, 189-202.

Kleiner, Morris M. and Robert T. Kudrle (2000), “Does Regulation Affect Economic Outcomes? The Case
of Dentistry,” Journal of Law and Economics 43, 547-82.


                                                   19
Kleiner, Morris M. and Daniel L. Petree (1988), “Unionism and Licensing of Public School Teachers: Impact
on Wages and Educational Output,” Chapter 11 in R.B. Freeman and C. Ichniowski, eds., When Public
Sector Workers Unionize, Chicago: University of Chicago Press.

Kugler, Adriana, and Robert Sauer (2003), “Doctors Without Borders: The Returns to Professional Licensing
for Immigrant Physicians in Israel,” CEPR Discussion Paper 3683, January.

Lelande, Hayne E. (1979), “Quacks, Lemons, and Licensing: A Theory of Minimum Quality Standards,”
Journal of Political Economy 87, 1328-1346.

Manski, Charles F. (1987), “Academic Ability, Earnings, and the Decision to Become a Teacher: Evidence
from the National Longitudinal Study of the High School Class of 1972,” in D. Wise (ed.), Public Sector
Payrolls, Chicago: University of Chicago Press.

Murnane, Richard J. (1991), Who Will Teach? Policies that Matter, Cambridge: Havard University Press.

National Council for the Accreditation of Teacher Education (1997), Standards, Procedures, and Policies
for the Accreditation of Professional Education Units, NCATE: Washington, DC.

Ravitch, Diane (2002), “A Brief History of Teacher Professionalism,” White House Conference on Preparing
Tomorrow’s Teachers, Washington, DC

Wang, Ruqu (1997), “Competition, Wage Commitments, and Application Fees, “ Journal of Labor
Economics 15, 124-142.

Wang, Ruqu, and A. Weiss (1998), “Probation, Layoffs, and Wage-Tenure Profiles: A Sorting Explanation,”
Labour Economics 5, 359-383.




                                                   20
                                                                      Table 1: Means of Selected Variables
                                                 All Districts                     Sample with Inexperienced Teachers                   Sample with First-year Teachers
                                  87-88       90-91       93-94       99-00           87-88       90-91       93-94       99-00          87-88       90-91       93-94       99-00
 Unweighted Count                 4,790       4,831       4,920       4,644           2,073       2,277       2,390       2,374           930        1,068       1,166       1,138
       District Characteristics
 Enrollment                       2,751       2,826       2,976       3,402           4,069       3,943       4,372       5,257          6,257       5,405       6,365       7,855
 Full-time Equivalent
                                  158.1       159.3       159.0       211.0           227.6       218.1       227.8       320.2          343.3       293.5       327.6       470.1
 Teachers
 Frac. w/
                                   .401        .426        .427        .446             1            1          1           1               0           0           0           0
 Inexperienced Teachers
 Frac. w/
                                   .164        .194        .186        .192             0            0          0           0               1           1           1           1
 First-year Teachers
       Teacher Wage and Quality Measures
 Salary: B.A.                     25,344      25,481      25,320     25,898          25,071      25,009      24,883      26,074          25,076      24,680      24,724      26,232
 Salary: M.A.                     27,683      27,765      27,649     28,303          27,327      27,265      27,150      28,489          27,335      26,965      27,020      28,673
 Salary: M.A. + 20 years
                                  41,939      42,529      42,950     44,108          40,992      41,250      41,478      43,948          41,145      40,415      41,213      43,777
 experience
 Average SAT                      907.4          -        909.9       905.2           905.7          -        906.5       907.5          912.6          -        908.8       910.5
 Attended Research Univ.
                                   .218          -         .227        .210            .229          -         .220       .214            .264          -         .256        .213
 or Liberal Arts Coll.
 Majored in Teaching
                                   .067        .065        .074        .077            .075        .079        .095       .109            .075        .079        .092        .123
 Subject
 Frac. w/ Alternative
                                   .104        .075        .084        .116            .306        .316        .287       .402            .369        .382        .377        .516
 Certification
       Other Teacher Characteristics
 Fraction Female                   .693        .677        .662        .695            .720        .666        .645       .666            .700        .647        .634        .676
 Fraction Black                    .026        .029        .025        .028            .024        .018        .027       .036            .024        .022        .047        .042
 Fraction Hispanic                 .015        .018        .020        .029            .025        .027        .044       .043            .021        .048        .056        .050

Notes: District-weighted means are reported. Inexperienced teachers are defined as teachers with less than 4 years teaching experience. All salaries are reported in 1999 dollars.
Average SAT, Fraction of Teachers who Attended Carnegie I Schools, and Fraction of Teachers with Alternative Certification are measured for all teachers, inexperienced teachers
or first-year teachers. For all other variables, district means are estimated using all schools or using the sample of schools that employ either inexperienced or first-year teachers.
                                         Table 2: Testing Requirements and Prevalence
                                        Proportion of Districts                                     Proportion of States

                              87-88         90-91        93-94         99-00             87-88        90-91        93-94        99-00


 State Requirements

 Requires Basic                .429         .622          .697          .648             .431          .588         .627         .667
 Skills Test

 Requires Subject              .336         .365          .538          .674             .373          .373         .529         .608
 Test

 Requires Any Test             .540         .693          .736          .820             .529          .647         .667         .803


 District Response in the SASS

 Uses Basic Skills             .361         .425          .493          .646
 Test

 Uses Subject Test             .243         .341          .394          .552

 Uses Any Test                 .379         .452          .514          .669


 District Response in the SASS with State
 Requirements Imposed

 Uses Basic Skills             .554         .726          .778          .827
 Test

 Uses Subject Test             .494         .613          .703          .799

 Uses Any Test                 .612         .744          .802          .880

Notes: The first 4 columns report weighted fractions of districts. The top panel reports fraction (of states or districts) that require new
teachers to pass basic skills and/or subject tests to be licensed. The middle panel reports the fraction of districts that report in the
SASS that they require teaching candidates to have passed basic skills and/or subject tests. The bottom panel reports the fraction of
districts that either report in the SASS that they require teaching candidates to have passed basic skills and/or subject tests or are in
a state that requires that they do so.
                               Table 3: First-stage estimates with state and year fixed effects
                      District Requires Basic Skills Test                     District Requires Subject Test
                     (1)        (2)        (3)         (4)                  (5)        (6)        (7)      (8)
                                                            Full sample
 Basic Skills       .516                  .487                             .335                  .143
 Test Law          (.050)                (.053)                           (.061)                (.044)

 Subject                        .297        .081                                            .588        .525
 Test Law                      (.070)      (.049)                                          (.056)      (.060)

 Any                                                     .521                                                       .549
 Test Law                                               (.060)                                                     (.054)

 R2                 .736        .638        .738         .719               .568            .645        .653        .634
 N                                                                18,288
                                                          Inexperienced Teachers
 Basic Skills       .476                    .454                            .275                        .078
 Test Law          (.048)                  (.050)                          (.066)                      (.047)

 Subject                        .258        .063                                            .604        .570
 Test Law                      (.073)      (.055)                                          (.064)      (.070)

 Any                                                     .482                                                       .533
 Test Law                                               (.066)                                                     (.069)

 R2                 .719        .632        .721         .698                .549           .648        .650        .617
 N                                                                 6,476
                                                            First-year teachers
 Basic Skills       .449                    .433                             .205                       .048
 Test Law          (.046)                  (.048)                           (.062)                     (.042)

 Subject                        .221        .057                                            .566        .548
 Test Law                      (.075)      (.058)                                          (.060)      (.063)

 Any                                                     .452                                                       .466
 Test Law                                               (.065)                                                     (.074)

 R2                 .706        .622        .707         .682                   .539        .631        .631        .595
 N                                                                  3,008

Notes: Inexperienced teachers are defined as teachers with less than 4 years teaching experience. The table reports OLS
estimates of equation (3). The dependent variable is an indicator for whether districts either report in the SASS that they
use information on whether teaching candidates passed a basic skills or subject test or are in a state that requires that they
do so. Controls include state and year fixed effects, city, suburb and rural fixed effects, a quadratic in the state
unemployment rate, district enrollment, and district fraction minority enrollment. All regressions are weighted using district
sampling weights. Standard errors corrected for state-by-year correlation in the error term are reported in parentheses.
                                                Table 4a: Wage Estimates Controlling for State and Year Fixed Effects
                            Log (Salary with B.A.)                   Log (Salary with M.A.)                    Log (Salary with M.A. + 20 yrs)
                     (1)        (2)        (3)       (4)        (5)       (6)         (7)       (8)          (9)       (10)       (11)      (12)
                                                                            Full Sample
 Basic Skills       .024                  .018                 .025                  .022                   .026                  .026
 Test Law          (.009)                (.010)               (.009)               (.009)                  (.009)                (.009)
 Subject                       .023       .015                           .019        .010                              .012       .000
 Test Law                     (.012)     (.013)                         (.013)     (.014)                             (.014)     (.014)
 Any                                                .019                                       .021                                         .022
 Test Law                                          (.009)                                     (.009)                                       (.010)
 R2                 .831       .831       .831      .831       .803      .802        .803      .802         .767       .767       .767      .767
 N                                                                             18,060
                                                                      Inexperienced Teachers
 Basic Skills       .022                  .015                 .024                  .017                   .033                  .027
 Test Law          (.011)                (.012)               (.011)               (.012)                  (.012)                (.012)
 Subject                       .028       .022                           .027        .020                              .031       .019
 Test Law                     (.014)     (.015)                         (.015)     (.016)                             (.019)     (.019)
 Any                                                .019                                       .020                                         .042
 Test Law                                          (.013)                                     (.013)                                       (.015)
 R2                 .858       .858       .859      .857       .832      .832        .833      .832         .789       .789       .790      .790
 N                                                                              6,404
                                                                         First-year teachers
 Basic Skills       .024                  .019                 .022                  .018                   .036                  .035
 Test Law          (.014)                (.014)               (.014)               (.014)                  (.014)                (.014)
 Subject                       .026       .019                           .023        .016                              .017       .004
 Test Law                     (.019)     (.019)                         (.020)     (.020)                             (.023)     (.022)
 Any                                                .016                                       .012                                         .029
 Test Law                                          (.018)                                     (.017)                                       (.019)
 R2                 .866       .866       .866      .865       .839      .839        .840      .839         .786       .785       .787      .786
 N                                                                              2,979

Notes: Inexperienced teachers are defined as teachers with less than 4 years teaching experience. Reported coefficients are estimated from a regression of log salary
on state testing requirement dummy variables and a set of controls. Controls include state and year fixed effects, city, suburb and rural fixed effects, a quadratic in the
state unemployment rate, district enrollment, and district fraction minority enrollment. All regressions are weighted using district sampling weights. Standard errors
corrected for state-by-year correlation in the error term are reported in parentheses.
                             Table 4b: Wage Estimates Controlling for State and Year Fixed Effects and State-specific Linear Trends
                        Log (Salary with B.A.)                     Log (Salary with M.A.)                    Log (Salary with M.A. + 20 yrs)
                   (1)      (2)        (3)       (4)         (5)        (6)         (7)      (8)           (9)       (10)       (11)      (12)
                                                                          Full Sample
 Basic            .033                .026                  .032                   .025                   .020                  .016
 Skills          (.010)              (.011)                (.009)                 (.010)                 (.009)                (.010)
 Subject                   .032       .021                             .030        .019                              .020       .014
 Test Law                 (.010)     (.011)                           (.011)      (.011)                            (.014)     (.014)
 Any                                            .029                                        .030                                          .020
 Test Law                                      (.009)                                      (.009)                                        (.012)
 R2               .844     .844       .845      .844        .816       .815        .816     .815          .775       .775       .775      .775
 N                                                                           18,060
                                                                   Inexperienced Teachers
 Basic            .044                .030                  .044                   .030                   .030
 Skills          (.014)              (.015)                (.013)                 (.014)                 (.016)                 .012
 Subject                   .049       .037                             .050        .038                              .054       .049
 Test Law                 (.013)     (.013)                           (.012)      (.012)                            (.018)     (.019)
 Any                                            .039                                        .044                                          .050
 Test Law                                      (.012)                                      (.012)                                        (.019)
 R2               .873     .874       .874      .872        .847       .848        .848     .847          .800       .801       .801      .801
 N                                                                            6,404
                                                                      First-year teachers
 Basic            .044                .032                  .042                   .028                   .024                  .010
 Skills          (.015)              (.016)                (.015)                 (.015)                 (.018)                (.017)
 Subject                   .049       .037                             .056        .046                              .049       .045
 Test Law                 (.017)     (.017)                           (.016)      (.017)                            (.028)     (.029)
 Any                                            .035                                        .040                                          .028
 Test Law                                      (.014)                                      (.014)                                        (.022)
 R2               .886     .886       .887      .885        .860       .861        .861     .859          .800       .801       .801      .800
 N                                                                            2,979

Notes: Inexperienced teachers are defined as teachers with less than 4 years teaching experience. The estimates are from models as in Table 4a, with the addition of
state-specific linear trends. All regressions are weighted using district sampling weights. Standard errors corrected for state-by-year correlation in the error term are
reported in parentheses.
                                              Table 5: Teacher Quality Estimates
                                                      College Selectivity
                                   Average SAT                      Research Univ. or Liberal Arts Coll.
                       (1)          (2)       (3)       (4)          (5)       (6)        (7)       (8)
                                                   Inexperienced Teachers
 Basic Skills         0.77                  -2.10                  -.002                -.007
 Test Law            (2.96)                 (3.07)                 (.018)              (.020)
 Subject                           7.41         8.31                                    .011         .014
 Test Law                         (4.05)       (4.41)                                  (.020)       (.023)
 Any                                                        1.44                                                -.006
 Test Law                                                  (3.72)                                               (.021)
 R2                   .273         .274      .274           .273            .062        .062           .062      .062
 N                                     6,476                                                   6,716
                                                          First-year teachers
 Basic Skills        -5.52                     -5.07                     .031                        .036
 Test Law            (4.56)                    (4.62)                   (.026)                      (.030)
 Subject                          -3.48        -1.56                                    .000        -.013
 Test Law                         (6.23)       (6.39)                                  (.030)       (.033)
 Any                                                       -6.42                                                -.011
 Test Law                                                  (6.57)                                               (.026)
 R2                   .239         .239      .239           .239            .072        .072           .072      .072
 N                                     3,008                                                   3,160
                                                      Other Qualifications
                            Alternative Certification                   Majored in Teaching Subject
                       (9)        (10)       (11)       (12)         (13)     (14)       (15)     (16)
                                                    Inexperienced Teachers
 Basic Skills        -.017                  -.019                    .008               -.001
 Test Law            (.025)                (.027)                   (.008)             (.009)
 Subject                          -.003         .006                                    .027         .027
 Test Law                         (.036)       (.038)                                  (.011)       (.012)
 Any                                                       -.019                                                 .006
 Test Law                                                  (.024)                                               (.010)
 R2                   .183         .183      .184           .183            .018        .019           .019      .018
 N                                     9,114                                                   9,114
                                                          First-year teachers
 Basic Skills        -.024                     -.020                     .004                        .001
 Test Law            (.038)                    (.038)                   (.019)                      (.017)
 Subject                          -.023        -.015                                    .012         .011
 Test Law                         (.048)       (.049)                                  (.019)       (.019)
 Any                                                       -.041                                                -.005
 Test Law                                                  (.040)                                               (.019)
 R2                   .183         .183      .183           .183            .027        .027           .027      .027
 N                                     4,302                                                   4,302

Notes: Inexperienced teachers have less than 4 years teaching experience. Dependent variables are: Average SAT of matriculating
freshmen in 1983 at teachers’ undergraduate institution; the fraction of teachers that attended colleges in a Carnegie Research
University I & II or Baccalaureate (Liberal Arts) College I; an indicator for whether the teacher was hired without regular state
certification (alternatives are temporary certification, provisional certification and emergency certification); the fraction of teachers
whose primary teaching assignment is in the same subject as their B.A, M.A., Ph.D or Education Specialist degree major. Controls
include state and year fixed effects, city, suburb and rural fixed effects, a quadratic in the state unemployment rate, district enrollment,
and district fraction minority enrollment. All regressions are weighted using district sampling weights. Standard errors corrected for
state-by-year correlation in the error term are reported in parentheses. There are fewer observations for the Average SAT and
Carnegie Type I specifications because the 1990-91 SASS does not report the teacher’s undergraduate college.
                                                                    Table 6: Teacher Characteristics Estimates
                                Fraction Black                                  Fraction Hispanic                                        Fraction Female
                     (1)         (2)       (3)           (4)            (5)       (6)        (7)        (8)                   (9)        (10)       (11)           (12)
                                                                              Inexperienced Teachers
 Basic Skills      -.005                    -.006                     -.009                -.007                            -.001                     .004
 Test Law          (.005)                   (.005)                    (.004)               (.005)                           (.016)                   (.017)
 Subject                        .001         .003                                  -.008        -.005                                    -.016       -.018
 Test Law                      (.007)       (.007)                                 (.008)       (.009)                                   (.019)      (.020)
 Any                                                   -.003                                                -.010                                                 -.003
 Test Law                                              (.007)                                               (.005)                                                (.016)
 R2                 .141        .141           .141     .141            .081        .081        .081         .081            .032         .032           .032     .032
 N                                     9,114                                             9,114                                                   9,114
                                                                                   First-year teachers
 Basic Skills      -.002                    -.005                      -.020                   -.016                        -.012                    -.009
 Test Law          (.007)                   (.007)                     (.008)                 (.009)                        (.026)                   (.025)
 Subject                        .008         .010                                  -.019        -.013                                    -.012       -.008
 Test Law                      (.011)       (.011)                                 (.013)       (.014)                                   (.029)      (.027)
 Any                                                    .006                                                -.021                                                 -.023
 Test Law                                              (.009)                                               (.009)                                                (.027)
 R2                 .162        .162           .162     .162            .126        .126           .126                      .042         .042           .042      .042
 N                                     4,302                                               4,302                                                 4,302

Notes: Inexperienced teachers are defined as teachers with less than 4 years teaching experience. Dependent variables are the fraction of inexperienced or first-year teachers in the
district who fall into the respective category. Reported coefficients are estimated from an OLS regression on state testing requirement dummy variables and a set of controls. Controls
include state and year fixed effects, city, suburb and rural fixed effects, a quadratic in the state unemployment rate, district enrollment, and district fraction minority enrollment. All
regressions are weighted using district sampling weights. Standard errors corrected for state-by-year correlation in the error term are reported in parentheses.
