                             NBER WORKING PAPER SERIES




             MAKING THE MOST OF LIMITED GOVERNMENT CAPACITY:
                         THEORY AND EXPERIMENT

                                      Sylvain Chassang
                                      Lucia Del Carpio
                                       Samuel Kapon

                                     Working Paper 28042
                             http://www.nber.org/papers/w28042


                    NATIONAL BUREAU OF ECONOMIC RESEARCH
                             1050 Massachusetts Avenue
                               Cambridge, MA 02138
                                   October 2020




We are indebted to Vishal Ashvinkumar, Kathleen Ngangoue, Paula Onuchic, and Tianzan Pang
for feedback on our experiment design. Early discussions with Dilip Abreu, Abhijit Banerjee,
Daniel Diermeier, Guillaume Frechette, Navin Kartik, John Klopfer, Alessandro Lizzeri and Ariel
Rubinstein helped refine our thoughts on this topic. We are grateful to seminar participants at
PSE, LSE and MIT for very helpful comments. The views expressed herein are those of the
authors and do not necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2020 by Sylvain Chassang, Lucia Del Carpio, and Samuel Kapon. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.
Making the Most of Limited Government Capacity: Theory and Experiment
Sylvain Chassang, Lucia Del Carpio, and Samuel Kapon
NBER Working Paper No. 28042
October 2020
JEL No. C72,C73,C92,D73,D82,D86,H26

                                          ABSTRACT

Limits on a government's capacity to enforce laws can result in multiple equilibria. If most agents
comply, limited enforcement is sufficient to dissuade isolated agents from misbehaving. If most
agents do not comply, overstretched enforcement capacity has a minimal impact on behavior. We
study the extent to which divide-and-conquer enforcement strategies can help select a high
compliance equilibrium in the presence of realistic compliance frictions. We study the role of
information about the compliance of others both in theory and in lab experiments. As the number
of agents gets large, theory indicates that providing information or not is irrelevant in
equilibrium. In contrast, providing individualized information has a first order impact in
experimental play by increasing convergence to equilibrium. This illustrates the value of out-of-
equilibrium information design.

Sylvain Chassang                                 Samuel Kapon
Department of Economics                          New York University
Princeton University                             19 West 4th Street,
Julis Romo Rabinowitz Building                   New York, NY 10003
Princeton, NJ 08544                              sdk301@nyu.edu
and NBER
chassang@princeton.edu

Lucia Del Carpio
INSEAD
3022 Boulevard de Constance
77300 Fontainebleau
France
Lucia.delcarpio@insead.edu
1       Introduction
A government's ability to achieve goals such as tax collection, low crime rates, or environmen-
tal protection depends on its capacity to enforce mandated behavior on agents that refuse
to comply. In many cases, government capacity is limited: a government has the manpower
to enforce rules only for a small number of non-compliers. For instance, in the United States
the IRS has the capacity to audit under 1% of tax returns every year.1 In addition damages
for non-compliance are often limited, ruling out enforcement through large probabilistic pun-
         ` la Becker (1968).2 In the case of the IRS, penalties for negligent underreporting
ishments a
of income amount to 20% of unpaid taxes. Such limited enforcement capacity can lead to
multiple equilibria. If most agents comply with government policy, then limited enforcement
is sufficient to dissuade isolated agents from misbehaving. If many agents do not comply,
overstretched enforcement capacity has a minimal impact on incentives and behavior. The
goal of this paper is to better understand the extent to which divide-and-conquer enforce-
ment strategies can help select a high compliance equilibrium in the presence of realistic
compliance frictions.
    We study the problem of a government entitled to collect an amount of taxes D from
each of N agents. The government is able to forcefully collect the amount D, but only after
conducting an audit of the targeted agent. The difficulty is that: (i) the government is only
able to audit a share   (0, 1) of agents; (ii) upon audit, the maximum amount of damages
the government can claim is D. Instead of collecting taxes through audits, the government
can offer agents to settle their taxes for a given price P . Agents who accept to settle (or
comply) are not audited. Audit capacity is spent on auditing non-complying agents. The
government's main policy instrument is to commit to an auditing rule, i.e. an order in which
to audit non-compliant agents.
    We first establish benchmark results in a static frictionless environment in which agents

    1
    This varies by income bracket, from under .5% to roughly 5%. See IRS statistics for updated numbers.
    2
    In the US, the Eighth Amendment affords protections against excess punishment in order to limit the
scope for abuse by the state itself.


                                                   2
are able to settle with probability 1, and the amount of tax they owe is common-knowledge.
We contrast uniform auditing rules, in which a number N of agents are randomly cho-
sen from non-complying agents, with prioritized auditing rules, in which agents are given
common-knowledge priorities ahead of settling and non-complying agents are audited in
order of priority. We show that uniform random auditing leads to multiple equilibria, in-
cluding: high collection equilibria in which the government charges a settlement price P
slightly below D, and all agents settle; and low collection equilibria in which the government
charges a settlement price P = D, and agents all settle at that price, but refuse to settle
if the government charges a higher price. The reason for this multiplicity is that incentives
to settle depend on how many agents choose to settle or not. If most agents settle, then
even limited auditing capacity is sufficient to enforce compliance. If instead few agents are
expected to settle, auditing capacity is spread thinly across many non-complying agents so
incentives to settle are very weak. In contrast, under prioritized auditing, a unique, high col-
lection equilibrium is selected. The reason for this is that regardless of the overall behavior
of agents, incentives are tightly focused on a small group of marginal agents: it is dominant
for the N agents with the highest priority to settle. Given this, it is a best response for the
2N agents with the highest priority to settle, and so on.
    Our next set of results considers the impact of frictions on the effectiveness of prioritized
audits. Specifically, we assume that with exogenous probability q an agent is simply unable to
settle.3 Then, agents mechanically unable to settle risk interrupting the unraveling argument
described above. We show that as the number of agents N gets large, there is essentially a
unique equilibrium. With probability approaching 1, the share /q of agents with the highest
priority settle (if they can), while remaining agents do not. In order to get full collection,
audit capacity  must be larger than settlement friction q . We show that when taxes owed
D, and frictions q are heterogenous among agents, it is optimal to rank agents according to

   3
     This may be interpreted as the impact of psychological payoff shocks along the lines of quantal response
equilibrium (McKelvey and Palfrey, 1995). Alternatively, if the taxes owed determined by an audit are
uncertain and simply predicted, then q may be the share of agents for whom settlement price P is less than
the taxes D they really owe.


                                                     3
score D/q .
   Finally, we let settlement decisions take place over time and study the impact of providing
agents information about the settlement decisions of others. This analysis is motivated by
a recent empirical literature evaluating such policies in the context of taxation (Del Carpio,
2014, Castro and Scartascini, 2015, Dwenger et al., 2016), as well as recent interest in the
value of information design in equilibrium (Kamenica and Gentzkow, 2011). We establish
an irrelevance benchmark result: as the number of agents N gets large, for any information
structure with probability 1, the share /q of agents with the highest priority settle as soon
as they are able to. This implies that any effect of information on play must be assigned to
either behavioral forces, or non-equilibrium play.
   We complement our theoretical analysis of the auditing strategies for three reasons. First,
prioritized auditing need not improve on uniform random auditing if agents somehow coordi-
nate on a high collection equilibrium. Second, the effectiveness of prioritized auditing relies
on agents being able to perform many rounds of iterated best-response ahead of choosing
their play. Prioritized auditing may be much less effective in environments where players
exhibit bounded rationality. Third, in the presence of bounded rationality, information that
helps players make better individual choices may improve the effectiveness of prioritized
auditing.
   Experimental data collected from an implementation of our dynamic settlement game
both supports and qualifies the theory. Prioritized auditing does improve over uniform
random auditing. However, agents do not systematically coordinate on a low settlement
equilibrium under uniform auditing, and settlement under prioritized auditing falls short of
our theoretical benchmark. Additionally we find that contrary to predictions of our irrele-
vance result, information can significantly improve settlement rates, but that this depends
on the nature of the information. Information targeted to individual agents clarifying their
effective rank given settlement by others is more effective than aggregate information simply
reporting the overall share of agents that have settled. This suggests that information design
plays an important role out-of-equilibrium by helping players approach equilibrium play.

                                              4
   Our work contributes to the literature on full implementation in mechanism design
(Maskin, 1999, Jackson, 1992) that emphasizes implementation of desirable outcomes in
all equilibria. In particular, the work of Abreu and Matsushima (1992) on virtual implemen-
tation highlights the value of more sophisticated divide-and-conquer schemes to achieve full
implementation. Divide-and-conquer schemes also play an important role in the literature
on contracting with externalities, including Segal (2003), Winter (2004) and more recently
Halac et al. (2019, 2020). Halac et al. (2020) also studies the impact of information design,
but allows for schemes in which the rank of agents is not common knowledge. In contrast
to our results (which pertain to revealing information about the compliance of others), they
find that appropriately designed information about others' rank can increase the principal's
surplus. Our experimental findings suggest that it may be worth investigating the validity of
such results in realistic non-equilibrium settings, and that the details of how the information
is conveyed to agents' may be of considerable importance in practice.
   The paper also contributes to the literature on out-of-equilibrium mechanism design.
A large body of experimental work reviewed in Chen and Ledyard (2010) has emphasized
the learning properties of mechanisms, and in particular dominance solvable mechanisms.
Among others, Healy (2006) shows that in repeated public goods mechanisms, contribution
behavior is well explained as a best-response to recent play. Mathevet (2010), Healy and
Mathevet (2012) emphasize design steps that can be taken to ensure a mechanism is super-
modular, ensuring more stable learning dynamics. Crawford and Iriberri (2007) shows that
a level-k model can explain overbidding in experimental auctions. More recently De Clippel
et al. (2019) studies implementation using k iterations of best reply as a solution concept.
We emphasize the value of information design out-of-equilibrium.
   Most importantly, the paper hopes to stimulate and guide the evaluation of divide-and-
conquer mechanisms in real-life settings. Operation Ceasefire, introduced in Boston in the
mid-1990s to reduce gang violence, and applied in several dozen cities, illustrates the value of
divide-and-conquer strategies in practice. As described in Braga et al. (2001) and Kennedy
(2011), a key aspect of Operation Ceasefire was to commit dedicated police resources to deal

                                               5
with the first few gang related murders that would happen after a specific call in date during
which gang members were invited together and commonly informed of these new policies.4
By treating the next few murders differently from pre-existing cases, Operation Ceasefire
refocused a police force, overstretched by the crack epidemic, to unravel the equilibrium
logic of violence: if no gang wants to initiate violence, then no violence happens. Chassang
and Chen (2020) evaluate more than 20 years of evidence across dozens of cities and show that
Operation Ceasefire had a significant impact on homicide rates, especially when evaluated
as a real option. In addition, recent work has demonstrated the real-life effectiveness of
mechanism design steps in improving governance: Duflo et al. (2013) evaluate the value of
cross validating messages from multiple environmental inspectors in India, Del Carpio (2014)
studies the importance of information about group compliance on own compliance, similarly
Pomeranz (2015) highlights the usefulness of the value-added tax in generating actionable
information about the profits of other firms permitting cross validation. We hope that by
clarifying the impact of realistic frictions and how to address them, this paper serves as
a blueprint for the implementation of divide-and-conquer strategies to improve governance
capabilities in real-life environments.
   The paper is structured as follows. Section 2 sets up a simple model in the context of
tax collection. It establishes benchmark results clarifying the value of common-knowledge
enforcement priorities in a static setting with fully responsive agents. Section 3 clarifies the
impact of agent non-response on the effectiveness of enforcement priorities. Section 4 casts
compliance decisions in a dynamic context, and shows that schemes that provide agents
with information about the compliance of others have a negligible impact on collection as
the number of agents gets large. Section 5 describes our experimental hypotheses and the
corresponding design. Section 6 describes our findings. Section 7 discusses applications
besides tax collection. A subset of player instructions is included in Appendix A.



   4
    Operation Ceasefire included other important steps, such as involving respected community members,
and convincingly demonstrating the police and district attorney's ability to deliver on their commitments.


                                                    6
2       Static Enforcement without Errors

2.1      Framework

We flesh out our model in the context of tax auditing, and discuss other applications in
Section 7. N agents indexed by i  I  {1, · · · , N } each owe a principal a fixed amount D.
The principal can potentially collect D from each agent, but can only do so following a due
process requiring a formal audit. The agents and the principal are all risk-neutral.
    The difficulty is that the principal has limited capacity. Specifically, the principal can
only audit N  1 agents with   (0, 1). If the principal audits an agent, he collects D but
can do nothing more. With experimental evaluation in mind, we are interested in a specific
class of collection mechanisms. The principal can make settlement offers and commit to an
audit schedule according to the following extensive-form game:

 (i) The principal gives each agent the possibility to settle at a common price P .
        Agents who accept are spared from audits.

(ii) Agents simultaneously decide whether or not to settle and pay price P or not.

(iii) The principal audits agents who have not settled according to a complete order
         over I . An audited agent pays D.

We consider two possible enforcement priorities :

    · Random priorities R : audited agents are drawn sequentially ex post (i.e. period (iii)),
        with uniform probability and without replacement;

    · Common knowledge priorities CK : the ordering is specified ex ante (i.e. period
        (i)) and is common knowledge among players. For simplicity, we assume that non-
        compliant agents are audited in order of their index i  {1, · · · , N }.5
    5
     Halac et al. (2020) show in a related context that incomplete information over rank can increase the
principal's surplus. Since we have experimental implementation in mind, we prefer to focus on a relatively
simpler class of mechanism. Even under this simpler class of mechanism, common knowledge of rationality
does not appear to hold in our data.


                                                    7
Payoffs and solution concept. We denote by si  {0, 1} agent i's decision to settle for
the principal's offer. The principal's total payoff is

                                              1
                                                       si P.
                                              N   iI


Note that payoffs exclude the proceeds from directly audited agents. This simplifies compu-
tations and reflects the fact that the net benefits of audits may be ambiguous: investigation
costs may be well above the amount that can be legally collected from agents. This also
clarifies that the value of audits comes from incentive provision rather than actual collection.
   We use both Bayes Nash Equilibrium and rationalizability as solution concepts.


Modeling assumptions. In our model, audits are free to the principal but constrained
in number. This assumption implies that the principal cannot commit to audit every agent
that does not settle. Our result would continue to hold if the principal could freely choose
auditing capacity at a variable cost, provided that the cost is paid regardless of whether
audits happen or not (investigators must be hired, trained, and paid even if there are no
crimes to investigate). Alternatively, even if auditors are only paid in the event an actual
audit happens, then limited capacity may capture limits on the principal's ability to commit
to run expensive audits ex post.
   We note that we do not allow for dissuasive punishments in the style of Becker (1968).
Our results would be changed if arbitrarily high punishments were available, but not if only
intermediate punishments were available. If arbitrarily high punishments are allowed, they
can compensate for very limited enforcement capability. However, in practice, there are
limits to legitimate levels of punishments. In the US where the Eighth Amendment limits
the punishments that both federal and state governments can apply. In the case of tax
collection, the maximum penalty that the IRS can apply in case of underreported income is
20%.
   In principle, the use of prioritized audits may raise fairness concerns. Indeed, similar


                                                  8
agents can be treated differently when they do not accept settlement. However, because set-
tlement price P applies uniformly to all agents, agents that comply are treated identically.
We believe this is a socially acceptable relaxation of fairness constraints. In contrast we
think that charging similar agents a different settlement amount would not be socially ac-
ceptable because it would treat similar compliant agents differently.6 In other terms, unequal
treatment of equals strikes us as much more acceptable off-of-the-equilibrium-path, than on-
the-equilibrium-path. Ortner and Chassang (2018) make a similar point in the context of
counter-corruption measures.


2.2     The Value of Common-Knowledge Enforcement Priorities

The following results clarify the value of prioritized enforcement: it selects a high collection
equilibrium as the unique rationalizable strategy profile; in contrast, random enforcement
induces multiple equilibria involving both high and low collection levels.

Proposition 1 (multiple equilibria under random enforcement). Under random enforcement
order R , for any settlement offer P  [D, D], there exists a Nash equilibrium such that
the principal makes offer P , all agents accept offers below or equal to P and reject any offer
higher than P . There does not exist an equilibrium such that the principal makes an offer
P / [D, D].

Proof. We first establish that for any P  [D, D], the profile of strategies such that the
principal offers settlement price P , while agents accept any offer less than P and reject all
options higher than P is a Nash equilibrium. Offering P is a best response for the principal
since lower offers yield lower collections and a higher offer leads to no collection at all.
Accepting an offer P  P is a best response for an agent if and only if P  D, which holds
since P  D. Rejecting an offer P > P is a best response provided that P  D, using the


   6
     Note that charging different agents a different price may increase the amount of revenue that could
be raised. This point is emphasized in a joint production context by Winter (2004), and in a fund-raising
context by Halac et al. (2019).


                                                   9
fact that under random order R , an agent is audited with probability  when all agents do
not comply.
   There can be no equilibrium such that P > D, since in that case, it is dominant for agents
not to settle, and the principal collects an amount equal to zero. In addition, there cannot
be an equilibrium such that P < D, since when the principal offers any P  (P, D), it
is dominant for all agents to accept: a non-compliant agent gets audited with probability at
least , regardless of the behavior of other players.


   A corollary of Proposition 1, is that for any given settlement amount P  (D, D),
random enforcement is consistent with two corner equilibria: a high compliance equilibrium
in which all agents comply so that even limited enforcement capacity is enough to discipline

Proposition 2 (equilibrium selection via common-knowledge priorities). Under common-
knowledge enforcement order CK , a unique strategy profile survives iterated elimination of
dominated strategies. The principal makes an offer P , which all agents accept.

Proof. We show that for every settlement offer P < D, it is iteratively dominant for all
agents to settle, so that the principal collects an amount N P . The proof is by induction on
the priority of agents. The induction hypothesis is that in all strategy profiles that survive
k -iterations of elimination of dominated strategies, all agents with priority higher than k
choose to settle. The induction hypothesis holds for k = 0 since the highest priority agent is
audited with probability 1 in the event they do not comply. In turn, if the hypothesis holds
for k  0, then an agent of rank k + 1 that does not comply is audited with probability 1.
Hence, it is conditionally dominant for an agent of rank k + 1 to comply, which establishes
the induction step.
   In turn, it is dominant for all agents to refuse any offer P > D regardless of how other
agents behave. It follows that setting P = D maximizes the principal's payoff.
The proof makes clear that the important aspect of CK is that players know their own rank,
and this is common knowledge. Since players are symmetric, whether or not they know the

                                             10
rank of others does not change Proposition 2.
    It is also worth noting that in the absence of frictions, prioritized enforcement is extremely
effective: an auditing capacity of one is enough to induce any arbitrary number of agents to
settle. Sections 3 and 4 study how realistic frictions perturb the effectiveness of prioritized
enforcement.



3     Static Enforcement with Errors
Proposition 2 suggests that even with very limited enforcement capacity (N = 1), priori-
tized enforcement can ensure a high compliance equilibrium. However, the argument relies
on the principal's ability to essentially "recycle" enforcement capacity, and relies on a high
degree of confidence that higher ranked agents will not exhaust the principal's enforcement
capacity. We now consider a variant of the game introduced in Section 2 in which agents are
exogenously and independently unable to settle with probability q . This friction naturally
reduces the effectiveness of prioritized audits.
    Exogenous non-compliance rate q can be interpreted in different ways. In practice, the
agent may simply not be aware of the collection problem, or experience liquidity shocks
preventing any payment. Alternatively, the agent may know that the amount collected by
the principal is erroneous, and that an investigation will prove she does not owe money. Such
errors are especially likely in a setting where the principal attempts to predict owed taxes on
the basis of informative but imperfect data. In such settings, it may be reasonable to assume
that non-compliance rate q is an increase function of price P , or that both non-compliance
rate q and taxes due D are heterogeneous across agents. We discuss these extensions below.
    Going forward, it is convenient to index an agent with rank i  I by her scaled rank
 = i/N . This facilitates the statement of asymptotic results as the number N of agents
grows large.

Proposition 3. Consider prioritized enforcement order CK . Set a settlement price P 
(0, D), and fix   > 0. For N large enough, under all rationalizable strategy profiles,

                                               11
                                 
    (i) agents with rank  >      q
                                      + do not comply;

                                  
    (ii) agents with rank  <      q
                                      - comply if they are able to settle.

                                                                                              
Proof. We first show that for N large enough, it is dominant for agents with rank  >          q
                                                                                                  +
not to comply. For any given strategy profile, let us denote by

                                                      N
                                             1
                                        A()                 1si =0
                                             N        i=1


the realized share of agents with rank less than  who do not settle. By the Law of Large
Numbers, with probability approaching 1 as N gets large, for any strategy profile, A( q
                                                                                        + )>
. This implies that uniformly over strategy profile, an agent with rank  > q
                                                                             + gets audited
with probability 0. Hence, for N large enough, it is dominant to refuse any settlement offer
P > 0.
                                                               
   Now consider the case of agents with rank  <                q
                                                                     - . We define the sequence K 
    K                                            
    k=0 (1   - q )k . Note that K converges to   q
                                                     as K gets large.
   For any k  N and  > 0, we establish the following hypothesis HK, :

 (i) uniformly over strategy profiles surviving K iterated elimination of dominated
      strategies, with probability 1 as N gets large, A(K - (K + 1) ×  )  qK .

(ii) as N gets large enough, for all strategy profiles surviving K iterated elimination
      of dominated strategies, agents with rank  < K - K ×  settle if they can.

   Consider the case where K = 0. Since 0 = , it is dominant for all players with rank
  0 to comply if they can. Since the exogenous non-compliance rate is q , it follows that
with probability 1 as N gets large, A(0 -  )  q0 .
   We now show that HK, implies HK +1, . Indeed, since A(K - (K + 1) ×  )  qK with
probability approaching 1, this means that spare audit capacity that can be used on agents
with rank greater that K - (K + 1) is greater than  - qK with probability one. This
implies in all strategy profiles surviving K + 1 iterations of iterated elimination of dominated

                                                 12
strategies, non-complying agents with rank less that K -(K +1) +-qK = K +1 -(K +1)
get audited with probability 1. Hence, all strategy profiles surviving K + 1 rounds are such
that agents with rank less than K +1 - (K + 1) settle. By the Law of Large Numbers, this
implies that A(K +1 - (K + 2) )  qK +1 with probability 1 as N gets large.
   To conclude, observe that we only need a fixed number of induction steps to establish
                                                     
point (ii). Consider K large enough that K           q
                                                         - 2 , and set  =    2K
                                                                                  . The induction
hypothesis HK, implies point (ii).




Corollaries. Proposition 3 admits two corollaries that are relevant for applications. First,
in a realistic context, the principal may be able to estimate a "demand curve" for settlement
Q(P ), mapping settlement offer P to a non-compliance rate q = Q(P ). For instance, if
there was uncertainty about the actual amount of taxes due, we would have q = Q(P ) =
prob(D > P ). In this context, Proposition 3 implies the following:

Corollary 1 (endogenous frictions). As N gets large, it is approximately optimal to make
a settlement offer P solving

                                                            
                           max P × (1 - Q(P )) × min             ,1 .                         (1)
                            P                              Q(P )

   The expression for profits differs from the usual expression for revenue P × (1 - Q(P ))
because of the endogenous externality across agents. Non-compliant agents not only fail to
settle, but they reduce the incentives of lower priority agents to settle.
   Another realistic possibility is that agents are heterogeneous. Assume that agents belong
to a finite number of groups indexed by g  {1, · · · , G}, associated with population weights
mg (summing to 1), settlement offers Pg and non-compliance rates qg . In addition, the
auditing difficulty of different groups may vary, so that auditing an agent from group g
consumes g from the principal's auditing capacity.



                                              13
Corollary 2 (heterogeneous agents). As N gets large, the maximum profit  the principal
can achieve under any prioritized enforcement mechanism is asymptotically equal to

                  G                                                        G
         max            g mg (1 - qg )Pg   (g )G
                                               g =1
                                                            G
                                                       [0, 1] such that          g mg qg g   .         (2)
                 g =1                                                     g =1


                                                                                                 (1-qg )Pg
    This maximum is achieved by prioritizing groups in order of decreasing score                   qg g
                                                                                                           ,
and setting an arbitrary ordering of agents within each group.



4     Dynamic Settlement
In this section, we embed the decision to comply or not over time. This is realistic: in
practice agents need some time to respond. In addition this allows us to explore two relevant
policy dimensions: discounts for early settlement of taxes (equivalent to penalties for late
payment), as well as revealing information about the compliance of others as in Del Carpio
(2014), Castro and Scartascini (2015), Dwenger et al. (2016).
    We consider the following variant of the static game introduced in Section 3. Time t 
[0, 1] is continuous. The principal commits to a deterministic settlement schedule (Pt )t[0,1] .
Each agent i  {1, · · · , N } becomes able to settle according to a Poisson process with
intensity 1 - q . If an agent is able to settle at date t, she is able to settle at all further
dates t  (t, 1]. Settlement decisions are irreversible. We denote by si,t  {0, 1} the agent's
compliance status at time t. Once date t = 1 is reached, the principal investigates non-
compliers according to common knowledge enforcement priorities CK .
    We allow the principal to commit to arbitrary information policies over the past settle-
ment behavior of agents. Specifically, in each period t, given a history of settlement decisions
ht = (si,t )i{1,··· ,N },t <t each agent i obtains a signal zi,t measurable with respect to ht . This
may include revealing the entire set of agents who have settled, revealing the highest rank
of agents that have settled, or any other statistic of history ht .
    The following benchmark is useful. If (i) the path of settlement prices is constant, i.e.

                                                      14
Pt = P for all t  [0, 1], and (ii) no information is provided to agents over time, then equilib-
rium settlement in this game will be identical to equilibrium settlement in the static game
with frictions of Section 3. The timing of settlement, however, will be indeterminate: agents
may settle as early as possible, or right at the end of the game. From this benchmark, pro-
viding price discounts would incentivize early settlement. In contrast, providing information
about the settlement of others would delay settlement (so that players can capture the option
value of information). This suggests that both discounts and information policy may have a
non-trivial effect on settlement behavior. We show that this is not the case: to a first order
approximation, both information and discount design are irrelevant in equilibrium.

Definition 1. We say that a price schedule (Pt )t[0,1] is strictly discounted if P0 > 0,
P1 < D, and for all    > 0, there exists  > 0 such that for all t  [0, 1],


                                           Pt+ - Pt  .


Proposition 4 (irrelevance of design). Take as given a strictly discounted price schedule,
and an information policy. For any          > 0, as N becomes large, under any rationalizable
strategy profile,

                                                                   
     (i) with probability approaching 1, an agent with rank  <     q
                                                                        - settles within a
      delay   of being able to settle;

                                                                    
     (ii) with probability approaching 1, an agent with rank  >     q
                                                                        + does not settle.

Proof. The proof is closely related to that of Proposition 3. We first establish point (ii).
                                    
Consider an agent with rank  >      q
                                         + . The number of agents with rank  <  who cannot
settle is greater than N with probability approaching 1 as N becomes large. This implies
that the payoff from never settling approaches 0 as N gets large, or, using Landau notation,
is of order o(1). Denote by Settles the event that the agent settles at some point. The agent's
expected payoff is bounded above by -P0 × prob(Settles). By revealed preferences, we must


                                                15
have o(1)  -P0 × prob(Settles), which implies that prob(Settles) = o(1). Hence, a single
round of rationality is sufficient to establish point (ii).
                                                                                    1     N -1
    Let us turn to point (i). We proceed by induction. Let A()                      N     i=1    (1 - si,t=1 )
denote the ultimate mass of agents with rank less than  who get audited. For K  N, let
            K
K           k=0 (1   - q )k . Our induction hypothesis at K  N is that for all            > 0, and for all
agents with rank   K - , the probability that the agent ultimately settles if possible
approaches 1 as N becomes large.
    Consider first agents with rank   . Those agents know they will be audited with
probability one if they do not settle. Since the price schedule is strictly discounted, their
best response is to settle immediately. This establishes the induction hypothesis for K = 0.
    We now show that the induction hypothesis at K - 1 implies the induction hypothesis at
K . We establish in passing that it also implies vanishing delays. Pick > 0 and consider an
                             K           k
agent with rank  <           k=0 (1 - q ) -   . The induction hypothesis at K - 1 implies that with
                                                                                 K -1
probability approaching 1, all agents with rank  strictly below                  k=0 (1   - q )k ultimately
settle. This implies that the mass of audits A(K -1 ) converges to qK -1 as N grows large.
This means that the spare audit capacity (scaled by 1/N ) that can be assigned to agents with
rank   K -1 is asymptotically equal to  - qK -1 . Since K = K -1 +  - qK -1 , it follows
that with probability 1 as N becomes large, A(K - )   with probability approaching 1.
Since audit is almost certain for such players it is intuitive that they should settle with very
little delay with probability approaching 1. Under strict discounting any amount of delay is
costly, and not settling is almost certainly a losing proposition. We now provide a formal
argument.
    Regardless of the agent's strategy, she is unable to settle with probability q , leading to
a payoff -qD. Since this component of payoffs is independent of the player's strategy, we
focus on payoffs conditional on the event that the agent is ultimately able to settle.7 Let
¬Settle denote the event that the agent never settles, Delay denote the event that the agent

   7
    In other terms, payoffs conditional on being able to settle at some point are an affine transformation of
unconditional payoffs.


                                                     16
settles but with a delay greater than , and let t denote the first date at which the agent is
able to settle.
    By settling immediately, the agent is able to guarantee herself a payoff equal to E[-Pt ].
The payoff from the agent's subjectively optimal strategy is bounded above by


          E[-Pt × (1 - 1Delay - 1¬Settle )] - E[Pt + 1Delay ] - E[D1¬Settle 1A(K - ) ].


By optimality, this implies that,


     E[-Pt ]  E[-Pt × (1 - 1Delay - 1¬Settle )] - E[Pt + 1Delay ] - E[D1¬Settle 1A(K - ) ].


Observe that prob(¬Settle and A(K - ))  )  prob(¬Settle) - prob(A(K - ) > ).
Since prices are strictly discounted, this implies that there exists  > 0 such that


                  E[-Pt ]  E[-Pt × (1 - 1Delay - 1¬Settle )] - E[(Pt +  )1Delay ]

                          - E[(Pt +  )1¬Settle ] + D × prob(A(K - ) > )


                    [prob(Delay) + prob(¬Settle)]  D × prob(A(K - ) > ).

As we noted above, the induction hypothesis at K - 1 implies that prob(A(K - ) > ) goes
to 0 as N gets large. Since  > 0 is fixed independently of N , this proves that the induction
hypothesis holds at K and that delay also vanishes as N gets large. This concludes the
proof.




5     An Experiment
Our theoretical analysis makes three potentially important points for practice:

 (i) random enforcement can lead to multiple equilibria, and in particular to a low
     collection equilibrium;

                                                17
(ii) prioritized enforcement selects a high enforcement equilibrium that can improve
     on random enforcement, even in the presence of frictions;

(iii) information design (as well as discounts for early settlement) has a negligible
      impact on collection.

   However, properties of prioritized enforcement rely crucially on agents being able to
perform many iterated eliminations of dominated strategies. In contrast, experimental work
identifying levels of rationality (see for instance Camerer et al., 2004, Costa-Gomes and
Crawford, 2006) suggests that in many settings, a majority of players engage in less than
two rounds of iterated best-reply.8 This section investigates the extent to which points (i),
(ii), and (iii) hold in experimental data. We show that prioritized enforcement improves over
random enforcement, but that prioritized enforcement falls short of theoretical expectations,
likely because of bounded rationality frictions. In this context, we show that information
has a role to play by making it easier for players to optimize, and anticipate the behavior of
others.


Baseline game. We implement essentially as is the dynamic settlement game of Section
4, with the experimenter playing the role of the principal, and recruited participants playing
the role of agents. Parameters were specified as follows: the number N of agents was set
to 10. All agents received an initial endowment of 100 points and owed the same amount
D = 100pts. The initial and final settlement prices P0 and P1 were set to P0 = 80pts and
P1 = 92pts. Settlement prices evolved linearly over time. Time t = 1 corresponded to 30
seconds.
   The probability q with which an agent is exogenously unable to settle was set to q =
20%. The principal's audit capacity was also set to  = 20%. This implies that under the
benchmark of Proposition 4, in principle, the share of agents able to settle who do so should
be close to 1.


   8
       Nonetheless, in dominance-solvable games, a non-zero share of players seems to play in equilibrium.


                                                      18
   The key departure from Section 4 is that we constrained the realization of times after
which agents were able to settle. This would not change our findings for large numbers of
players. Our restrictions seek to reduce sampling noise by ensuring that all realizations are
typical enough. Specifically we took the following steps. In each realization of the game,
exactly 2 players were exogenously unable to settle: one uniformly selected player with rank
less than 5, and one uniformly selected player with rank strictly greater than 5. Among
players able to settle, 3/4 were able to settle (at a uniformly drawn date) within the first 15
seconds of the game, and 1/4 were able to settle (at a uniformly drawn date) within the last
15 seconds.


Treatments. We experimented with four treatments corresponding to different enforce-
ment policies and different information designs. In a random enforcement treatment, partic-
ipants were not informed of the order in which they would be audited, and did not receive
information about the settlement behavior of others. Players were simply made aware of
when it was possible for them to settle, and at what price.
   We implemented three prioritized enforcement treatment. In each of these treatments,
participants were informed of their rank in the audit line. The treatments differed in the
additional information provided to participants about the settlement behavior of others:

   · In the priority only treatment, players were given no information about the realized
     settlement of others.

   · In the aggregate information treatment, players were informed of the aggregate settle-
     ment rate in their group. This matches taxpayer information experiments (Del Carpio,
     2014, Castro and Scartascini, 2015), as well as experiments seeking to increase pro-
     social behavior through norms (Allcott, 2011). Additionally, such information may
     foster learning if a majority of players settle, and some behavioral players choose their
     play by imitating others.

   · In the targeted information treatment, players are informed of both the aggregate set-

                                              19
       tlement rate in their group, and of their real time effective rank, i.e. their audit rank
       after taking into account settlement by other players. This targeted information has
       an immediate strategic interpretation for players: if their effective rank is 1 or 2, it is
       dominant for players to settle immediately.


Protocol. Experimental sessions took place on MTurk between March 2020, and August
2020. The experiment design was filed with the AEA RCT registry under ID number
AEARCTR-0004802. The experiment was programmed in oTree (Chen et al., 2016) and
experimental instructions were conveyed to players through their browser. Screenshots of
instructions are reproduced in Appendix A.9
    We ran 20 sessions, with 40 participants in each session. Participants were randomly
assigned to the 4 treatment groups, and played the collection game 4 times. The first
collection game did not count towards participants' final payoff. Points earned in the last
three collection games were averaged across games, and converted to cash at the rate of
USD8 for 100pts. Players were not reallocated across different treatments over time. To
reduce noise due to sampling, the realization of the times at which players can start settling,
which we call wake-up times, was kept the same across different treatments of a given session.
    On average, completing the experiment took 23 minutes. Participants earned a USD3.5
fee for showing up at a pre-announced time. As subset of 40 participants was selected from
this group to continue with the experiment. Participants earned between USD0 and USD8
from their play in the collection game, with mean earnings at USD3.2. For reference the
mean payoff from settling as soon as possible was equal to USD.992.
    Participants were selected from a pool of US adults over 18 years old, with an MTurk
approval rate over 98% and who had completed at least 50 tasks on MTurk.10 Experiments
were all run between 11am and 4pm EST, Monday to Friday.

   9
      A preliminary version of the experiment (excluding the targeted information treatment) ran in a phys-
ical lab for 12 sessions before the COVID19 pandemic started. Findings from this preliminary round are
qualitatively similar.
   10
      These selection criteria are meant to filter out bots.


                                                    20
6       Findings
Throughout this section, we report findings for payoff relevant games. We begin with the
treatment effect of different enforcement mechanisms on settlement behavior.


6.1           Treatment Effects

                      0.70
                      0.65
                      0.60
                      0.55
      share settled




                      0.50
                      0.45
                      0.40
                      0.35
                      0.30      random          priority only            aggregate info           targeted info

                       Figure 1: Mean settlement rate by treatment conditional on waking up.


                                                   mean               pct point
                                                settlement            diff over      pct diff
                                                    rate               random      over random
                               random              0.477
                               priority only       0.544              6.8 (.02)           14.2%
                               aggregate info      0.596             11.9 (.002)          25.0%
                               targeted info       0.666             18.9 (.000)          39.7%

                         Table 1: Settlement rates across treatment conditional on waking up.
Two-sided p-values in parentheses. Treatment effect estimates include session fixed-effects; standard-errors
                             are clustered at the (treatment, session) level.




                                                                21
Mean settlement by treatment. Figure 1 and Table 1 display the mean settlement rate
across treatments in the population of agents that are able to settle at some point. The key
takeaways are the following:

   · Roughly 50% of players settle under random enforcement, halfway between the high
     compliance equilibrium, and the low compliance equilibrium.

   · Prioritized enforcement improves significantly over random assignment, but does not
     attain the theoretical 100% settlement rate.

   · Contrary to the prediction of Proposition 4, information, and especially targeted in-
     formation, helps improve settlement rates.



           1.0
                       treatment
                        random
           0.8          priority only
                        aggregate info
                        targeted info
           0.6
     CDF




           0.4

           0.2

           0.0   0.0         0.1         0.2   0.3      0.4         0.5   0.6   0.7   0.8
                                               shared settled in group

        Figure 2: Cumulative distribution function of settlement rate by treatment.


The distribution of settlement rates. Figure 2 plots the c.d.f. of group-level settlement
rates by treatment. The most noticeable fact is that prioritized enforcement doesn't just in-
crease the mean settlement rate, but induces a first-order stochastic dominance (FOSD)
increase in settlement rates. This means that even if the principal is risk averse over settle-
ment and collection outcomes, prioritized enforcement improves on random enforcement.

                                                      22
   Focusing on prioritized enforcement treatments, there is no FOSD ranking of the priority
only treatment and the priority with aggregate information treatment. Specifically, the
aggregate information treatment seems to increase the mean settlement rate, but perhaps
at the cost of a small increase in the spread of the distribution of settlement rate. In
contrast, the targeted information treatment generates a first order increase in settlement
shares compared with any other treatment.
   Finally, we note that the distribution of settlement under random enforcement is uni-
modal. This suggests that the data is not well explained by a mixture of agents coordinating
on low and high enforcement equilibria.


Collection. Figure 3 shows that the findings of Figure 1 are also reflected in average
collection amounts. Collection averages to 40.1pts under random enforcement, and respec-
tively increases to 46.2, 50.9, and 56.8 under prioritized enforcement alone, with aggregate
information, and with targeted information.

                      65
                      60
                      55
                      50
     amount settled




                      45
                      40
                      35
                      30
                      25
                      20   random         priority only        aggregate info   targeted info

                              Figure 3: Mean settlement amount by treatment.




                                                          23
6.2     Delay

In principle, giving players more information may delay settlement: the anticipation of
receiving information creates an option value for waiting since it may reveal that other
players are in fact not settling.


Information does not delay settlement. We define settlement delay as the difference
between the time at which a player wakes up and the time at which they settle. Figure 4
illustrates the distribution of settlement delay for players who do wake up. The settlement
delay of players who choose not to settle is set to 30s. Figure 4 shows that prioritized

            0.9
                      treatment
            0.8        random
                       priority only
            0.7        aggregate info
            0.6        targeted info
            0.5
      CDF




            0.4
            0.3
            0.2                                                          non-settlement
            0.1
            0.0   0             5       10          15          20      25          30
                                             settlement delay

                      Figure 4: CDF of settlement delay conditional on waking


enforcement causes a FOSD reduction in delay compared to random enforcement. The
impact of aggregate information on delay is more ambiguous: under prioritized enforcement,
no information yields a higher mass of settlement times under 5s than providing aggregate
information, but the difference is small. Targeted information yields a more sizeable FOSD
reduction in delay relative to all other treatments.



                                                24
Information delays settlement, conditional on settlement. While information does
not increase delay, Figure 4 suggests that both targeted information and aggregate infor-
mation increase the mass of players settling after some delay, say after 10s from waking
up. This is confirmed by Figure 5 which plots the CDF of settlement delay conditional on
settling.

            1.0

            0.9

            0.8
      CDF




            0.7
                                                                            treatment
                                                                             random
            0.6                                                              priority only
                                                                             aggregate info
                                                                             targeted info
            0.5   0               5               10             15              20
                                              settlement delay

                      Figure 5: CDF of settlement delay conditional on settling


   Conditional on settlement, prioritized enforcement without information decreases set-
tlement delay compared to random enforcement. In contrast, prioritized enforcement with
either aggregate or targeted information increases settlement delay compared to random
enforcement. Targeted information causes the largest increase in delay.


6.3     Rationality

The impact of information on settlement and delay suggests that information is effective
through its interaction with players' rationality. We are specifically interested in under-
standing the rationality of players in prioritized enforcement treatments with no information


                                                 25
and targeted information since they correspond to very clearly interpretable information
environments.
   In principle, several possible forces may be active. First, information can reduce the
strategic difficulty of decision problems faced by agents. Keeping rationality the same, this
may increase convergence to equilibrium behavior. Second, information may affect rational-
ity. It may increase rationality by making the incentives of other players more transparent.
Alternatively it may decrease rationality. For instance, targeted information may lead players
to stop thinking about the incentives of others and instead adopt the rule-of-thumb consist-
ing in settling whenever their effective rank (i.e. their rank net of higher ranked agents who
have settled) drops to 2.
   Correspondingly, we are interested in distinguishing the three following scenarios:

A. Information decreases the rationality of players; as a result agents settle only when it is
   dominant to do so.

B. Information does not affect the rationality of players, but increases the likelihood of
   information sets at which settling is a best-response given the rationality of players.

C. Information increases the rationality of players.

   As Proposition 4 shows, the game is essentially dominance solvable, with higher rank
players requiring more iterated eliminations of strategies to settle. Correspondingly, we can
use players' rank at time of settlement as an indicator of rationality.
   We are interested in both the players' effective rank and max rank at the moment they
wake up, and at the moment they make a settlement decision, if they do. Effective rank
corresponds to a player's initial rank net of the number of players ahead of them who have
chosen to settle. Effective rank is the same across both treatment but is only in the informa-
tion set of players in the targeted information treatment. In contrast, max rank corresponds
to the maximum effective rank consistent with the player's information. Under the targeted
information treatment, max rank and effective rank are identical. Under the priority only
treatment, max rank is equal to a player's initial rank. Settlement at effective rank 1 or 2

                                              26
indicates a single round of best-reply. Settlement at ranks 3 or higher indicates strategic
thinking taking into account the behavior of others.


Rank at settlement is ambiguous. Figure 6 displays the proportions of the overall
population choosing to settle at different effective ranks.11 Targeted information results in
more agents settling at most ranks. There is a particularly large increase in the number of
agents settling at effective rank 2, but also a noticeable increase in the number of agents
settling at effective ranks 3 and 4.


                          0.16                                                              treatment
                                                                                              priority only
                          0.14                                                                targeted info
                          0.12
       population share




                          0.10
                          0.08
                          0.06
                          0.04
                          0.02
                          0.00   1.0    2.0    3.0     4.0      5.0       6.0   7.0   8.0   9.0      10.0
                                                             rank at settlement

                             Figure 6: Share of population settling by effective rank at settlement.


   Considering players' max rank at the time of settlement is a better reflection of rationality
since players in the no information treatment do not receive information about their effective
rank. The only hard information they have is their initial rank. Figure 7 displays the
proportions of the overall population choosing to settle at different max effective ranks. As
expected, the max rank of agents settling under priority only is shifted upwards. There is
a greater mass of agents settling with max rank equal to 3 under targeted information, but
  11
     The population shares displayed do not sum to 1: players who choose not to settle are the excluded
category.


                                                                27
the mass of agents settling with rank 4 are similar across treatments. This suggests that
targeted information acts mainly through reducing the difficulty of decision problems, and
not by increasing rationality. This hypothesis is confirmed by further analysis.


                        0.16                                                                   treatment
                                                                                                 priority only
                        0.14                                                                     targeted info
                        0.12
     population share




                        0.10
                        0.08
                        0.06
                        0.04
                        0.02
                        0.00    1.0     2.0    3.0    4.0        5.0      6.0      7.0   8.0   9.0      10.0
                                                            max rank at settlement

                               Figure 7: Share of population settling by max rank at settlement.



Targeted information reduces max rank at wake. Figure 8 illustrates the distribution
of agents' max rank at wake (population shares sum to one since we condition on agents'
waking). This is not informative of their rationality. Rather, it clarifies that targeted
information leads to a different distribution of decision problems than the no information
treatment: mass assigned to difficult problems, corresponding to a rank of 8 or higher, is
shifted to relatively simpler problems of a rank 4 or less.
   We note that for both treatments, the distribution of max rank at wake for players with
a max rank below 4 is approximately uniform. This means that focusing on the subset of
events where an agent wakes up with a max rank less 4 allows us to control for the impact
of information on the difficulty of problems faced by agents, and identify the impact of
information on rationality.

                                                                  28
                                                                                 treatment
                        0.14                                                       priority only
                                                                                   targeted info
                        0.12
                        0.10
     population share



                        0.08
                        0.06
                        0.04
                        0.02
                        0.00   1   2     3      4     5         6      7    8     9        10
                                                    max rank at wake

                                   Figure 8: Distribution of max rank at wake.




Settlement given max rank at wake, and rationality. Figure 9 displays the settlement
rate of agents conditional on their max rank at wake, for max rank at wake less than 4.
Conditioning on max ranks such that both no information and targeted information have
the same distribution of max rank lets us partial out the effect of information on the strategic
difficulty of decision problems agents face.
   Figure 9 shows that controlling for the difficulty of decision problems entirely removes
the increase in settlement rates associated with targeted information. The no information
and targeted information treatment lead to the same ultimate settlement behavior. In other
terms, targeted information does not act by increasing the strategic sophistication of players.
   Figure 10 confirms this conclusion. It plots the distribution of players' max rank at
settlement, conditional on settling, and their max rank at wake being less than 4. If any-
thing, the settlement behavior of players under targeted information reflects lower strategic
sophistication than the settlement of players under no information.
   This decomposition of the aggregate effect of information suggests that scenario B is in



                                                       29
                                                                                  priority only
                                                                                  targeted info
                       0.8

                       0.6
     settlement rate




                       0.4

                       0.2

                       0.0       1                2                      3          4
                                                      max rank at wake

                        Figure 9: Settlement rate by max rank at wake (max rank at wake  4).


                                                                                  treatment
                       0.30                                                         priority only
                                                                                    targeted info
                       0.25

                       0.20
     probability




                       0.15

                       0.10

                       0.05

                       0.00       1.0              2.0                  3.0          4.0
                                                    max rank at settlement

                  Figure 10: Distribution of max rank at settlement (max rank at wake  4).


fact the most plausible. Targeted information acts by reducing the strategic difficulty of
problems faced by agents. It does not change the strategic sophistication of players (by
improving or reducing it) in a large way. If anything, targeted information may slightly
reduce the strategic sophistication of players.

                                                          30
7     Discussion
We believe that divide and conquer schemes have wide applicability. Chassang and Chen
(2020) provides evidence that divide-and-conquer can be effective in practice based on Op-
eration Ceasefire programs implemented in a large number of US cities over the last 25 years
(Braga et al., 2001, Kennedy, 2011, 2012). Operation Ceasefire was initiated in Boston in the
mid-90s during a wave of gang related homicides. It first clarified to gangs that the police
were in fact fairly good at associating homicides with gang, even though bringing together
actionable evidence valid in a court of justice was much more difficult. Second, it shifted
some police resources away from uniform enforcement, and instead, promised that a signifi-
cant share of police effort was going to be directed towards making life difficult for the first
gang suspected of committing a murder. This is a clever prioritized enforcement strategy
that uses a natural common-knowledge rank: the time at which a murder is committed.
    Besides debt collection, we believe that prioritized enforcement offers particular promise
in fighting widespread corruption or misbehavior (including discrimination, verbal abuse,
and sexual harassment) in organizations. If misbehavior is widespread, it may be effectively
impossible to fire all misbehaving agents without seriously crippling an organization: for
instance, it may be that cops who take bribes are better than no cops at all. Prioritized
enforcement provides a way to initiate organizational change without firing all misbehavers.
Proposition 2 provides potential guidance on how to rank agents: prioritized high offenders
most likely to comply if given a take-it or leave-it offer.
    We conclude with a discussion of limits and possible extensions to our theoretical and
experimental analysis.


Dissuasive punishment. The analysis of Sections 3 and 4 assumes that collection in the
event of a successful audit is equal to the amount owed D. It turns out that the asymptotic
collection rate /q is not affected if a penalty is applied, so that the amount collected
following an audit is (1 +  )D with  > 0. The reason for this is that agents with normalized


                                               31
rank  > /q have a probability 0 of being audited. As a result, raising penalties has
a negligible effect on them. However, when the population is finite and fixed, dissuasive
penalties certainly raise settlement rates.


Information is relevant in a Level-k model. The experimental results of Section 6 fal-
sify the theoretical prediction of Section 4: information, and especially targeted information,
has a large impact, likely because it simplifies the decision problems faced by agents. This
observation is amenable to theoretical modeling. Specifically, we can use k -iterated-best-
response as our solution concept (with values of k relatively small, say 3 or 4). In that case,
even as the sample size N grows large, information design makes a difference. Whenever
 < q , then under no information, the fraction of agents who settle will be bounded away
below the rationalizable threshold /q , even as the population size N gets large. In contrast,
under targeted information, it is sufficient that players be capable of best-replying in order
to guarantee that the share who settle approaches /q as N gets large.


Incomplete information over rank. Halac et al. (2020) show that providing players
incomplete information over their rank can improve the effectiveness of divide-and-conquer
strategies. Our analysis suggests that information can be quite helpful if it does not require
high degrees of sophistication to be interpreted. We believe that there may be ways of
providing information that exploit both ideas. For instance, under targeted information, it
is likely unimportant that lower ranked players know their rank. It may be more effective
to keep such players in some amount of doubt.


Aggregate uncertainty about the settlement rate. In Section 4, providing infor-
mation about the settlement behavior of other players has little impact because there is
essentially no aggregate uncertainty to be uncovered. This would not be the case if the
friction level q was uncertain and needed to be learned. In that case, providing information
about friction rate q would have an impact. In the context of our experiment, the aggregate



                                              32
information treatment would provide such information.
   Preliminary analysis suggests that providing information about q would raise expected
collection. Indeed, consider the extreme case where a small sample of the overall large pop-
ulation is used to estimate q , which is then revealed to remaining agents. The continuation
                                                        
game is the one studied in Section 4, so that a share   q
                                                            agents choose to settle. Since this is
a convex function of q providing such information raises the expected collection rate.


Small versus large groups. The analysis of Sections 3 and 4 considers games in which
agents are put together in a single large group, and follow a single order. An intuitive
practical question is whether it is helpful to split agents in many fixed size groups in which
a small fixed number of agents can be audited.
   Theory suggests that the effect is at best ambiguous. Consider the case of targeted
information in the case where   q . Proposition 4 implies that all agents who are able
to settle will settle. This is not the case in the small group case: due to random variation,
some small groups will have their audit capacity exhausted, leading low rank individuals not
to settle. As a result, under a many-small-groups design a positive share of agents who can
settle will choose not to.
   What would happen in an experiment or in the field is less clear. Intuitively, it may
be that smaller group help place agents in a context where they think strategically. Also
if players react with delay, it may be that large groups cause very large settlement delays.
In contrast small groups may allow for parallel processing. We speculate that this force is
important in practice.




                                             33
A     Player instructions
This section reproduces instructions given to participants in different treatments.


A.1     Instructions for Random Treatment




                                             34
35
36
During the game, players were shown the following screen. Whenever a player was unable
to settle, the "Accept Offer" button was deactivated.




A.2    Instructions for Priority Treatment
The instructions are identical to the random treatment, except for the description of the
collection stage (and the snapshots page).


                                           37
   During the game, players were shown the following screen, reminding them of their initial
rank.




A.3     Instructions for Priority with Aggregate Information Treat-
        ment
The instructions are identical to the priority treatment, except for an added description of
the information (and the snapshots page).




                                            38
    During the game, players were shown the following screen, informing them of both their
initial rank, and of the aggregate share of players in their group who had settled.




A.4     Instructions for Priority with Targeted Information Treat-
        ment
The instructions are identical to the priority treatment, except for an added description of
the information and an updated version of the collection stage (and the snapshots page).




                                            39
    During the game, players were shown the following screen, informing them of their effec-
tive rank.




                                            40
References
Abreu, D. and H. Matsushima (1992): "Virtual implementation in iteratively undom-
 inated strategies: complete information," Econometrica: Journal of the Econometric So-
 ciety, 993­1008.

Allcott, H. (2011): "Social norms and energy conservation," Journal of public Economics,
 95, 1082­1095.

Becker, G. S. (1968): "Crime and punishment: An economic approach," in The economic
 dimensions of crime, Springer, 13­68.

Braga, A. A., D. M. Kennedy, E. J. Waring, and A. M. Piehl (2001): "Problem-
 oriented policing, deterrence, and youth violence: An evaluation of Boston's Operation
 Ceasefire," Journal of research in crime and delinquency, 38, 195­225.

Camerer, C. F., T.-H. Ho, and J.-K. Chong (2004): "A cognitive hierarchy model of
 games," The Quarterly Journal of Economics, 119, 861­898.

Castro, L. and C. Scartascini (2015): "Tax compliance and enforcement in the pampas
 evidence from a field experiment," Journal of Economic Behavior & Organization, 116,
 65­82.

Chassang, S. and M. Chen (2020): "Social Change as a Real Option: the Case of
 Operation Ceasefire," Princeton University Working Paper.

Chen, D. L., M. Schonger, and C. Wickens (2016): "oTree--An open-source platform
 for laboratory, online, and field experiments," Journal of Behavioral and Experimental
 Finance, 9, 88­97.

Chen, Y. and J. O. Ledyard (2010): "Mechanism design experiments," in Behavioural
 and Experimental Economics, Springer, 191­205.

Costa-Gomes, M. A. and V. P. Crawford (2006): "Cognition and behavior in two-
 person guessing games: An experimental study," American Economic Review, 96, 1737­
 1768.

Crawford, V. P. and N. Iriberri (2007): "Level-k Auctions: Can a Nonequilibrium
 Model of Strategic Thinking Explain the Winner's Curse and Overbidding in Private-Value
 Auctions?" Econometrica, 75, 1721­1770.

                                          41
De Clippel, G., R. Saran, and R. Serrano (2019): "Level-k mechanism design," The
 Review of Economic Studies, 86, 1207­1227.

Del Carpio, L. (2014): "Are the neighbors cheating? Evidence from a social norm exper-
 iment on property taxes in Peru," Unpublished Manuscript, Princeton University.

Duflo, E., M. Greenstone, R. Pande, and N. Ryan (2013): "Truth-telling by third-
 party auditors and the response of polluting firms: Experimental evidence from India,"
 The Quarterly Journal of Economics, 128, 1499­1545.

Dwenger, N., H. Kleven, I. Rasul, and J. Rincke (2016): "Extrinsic and intrinsic
 motivations for tax compliance: Evidence from a field experiment in Germany," American
 Economic Journal: Economic Policy, 8, 203­32.

Halac, M., I. Kremer, and E. Winter (2019): "Raising capital from heterogeneous
 investors," American Economic Review.

Halac, M., E. Lipnowski, and D. Rappoport (2020): "Rank Uncertainty in Organi-
 zations," Available at SSRN 3553935.

Healy, P. J. (2006): "Learning dynamics for mechanism design: An experimental compar-
 ison of public goods mechanisms," Journal of Economic Theory, 129, 114­149.

Healy, P. J. and L. Mathevet (2012): "Designing stable mechanisms for economic
 environments," Theoretical economics, 7, 609­661.

Jackson, M. O. (1992): "Implementation in undominated strategies: A look at bounded
  mechanisms," The Review of Economic Studies, 59, 757­775.

Kamenica, E. and M. Gentzkow (2011): "Bayesian persuasion," American Economic
 Review, 101, 2590­2615.

Kennedy, D. M. (2011): Don't shoot: one man, a street fellowship, and the end of violence
 in inner-city America, Bloomsbury Publishing USA.

------ (2012): Deterrence and crime prevention: Reconsidering the prospect of sanction,
  Routledge.

Maskin, E. (1999): "Nash equilibrium and welfare optimality," The Review of Economic
 Studies, 66, 23­38.

                                           42
Mathevet, L. (2010): "Supermodular mechanism design," Theoretical Economics, 5, 403­
 443.

McKelvey, R. D. and T. R. Palfrey (1995): "Quantal response equilibria for normal
 form games," Games and economic behavior, 10, 6­38.

Ortner, J. and S. Chassang (2018): "Making Corruption Harder: Asymmetric Infor-
 mation, Collusion, and Crime," Journal of Political Economy.

Pomeranz, D. (2015): "No taxation without information: Deterrence and self-enforcement
 in the value added tax," American Economic Review, 105, 2539­69.

Segal, I. (2003): "Coordination and discrimination in contracting with externalities: Divide
  and conquer?" Journal of Economic Theory, 113, 147­181.

Winter, E. (2004): "Incentives and discrimination," American Economic Review, 94, 764­
 773.




                                            43
