                              NBER WORKING PAPER SERIES




       RATIONAL INATTENTION AND SEQUENTIAL INFORMATION SAMPLING

                                       Benjamin Hébert
                                       Michael Woodford

                                       Working Paper 23787
                               http://www.nber.org/papers/w23787


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                   September 2017




The authors would like to thank Mira Frick, Matthew Gentzkow, Emir Kamenica, Divya Kirti,
Ran Shorrer, Stephen Morris, Ming Yang, Doron Ravid, Mark Dean, Pietro Ortoleva, Sebastian
Di Tella, Ilya Segal, Jacob Leshno, and participants at the Cowles Theory conference, Barcelona
GSE Summer Conference on Stochastic Choice, and Stanford GSB research lunch for helpful
discussions on this topic, and the NSF for research support. Portions of this paper appeared in
Benjamin Hébert's Ph.D. dissertation at Harvard University. All remaining errors are our own.
The views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.˛

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2017 by Benjamin Hébert and Michael Woodford. All rights reserved. Short sections of text,
not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.
Rational Inattention and Sequential Information Sampling
Benjamin Hébert and Michael Woodford
NBER Working Paper No. 23787
September 2017
JEL No. D83,E70

                                          ABSTRACT

We propose a new principle for measuring the cost of information structures in rational
inattention problems, based on the cost of generating the information used to make a decision
through a dynamic evidence accumulation process. We introduce a continuous-time model of
sequential information sampling, and show that, in a broad class of cases, the choice frequencies
resulting from optimal information accumulation are the same as those implied by a static rational
inattention problem with a particular static information-cost function. Among the static cost
functions that can be justified in this way is the mutual information cost function proposed by
Sims (2010), but we show that other cost functions can be micro-founded in this way as well. In
particular, we introduce a class of “neighborhood-based” cost functions, which make it more
costly to undertake experiments that can produce different results in similar states, and show that
the predictions of this alternative rational inattention theory better conform with evidence from
perceptual discrimination experiments.


Benjamin Hébert
Stanford Graduate School of Business
655 Knight Way
Stanford, CA 94305
bhebert@stanford.edu

Michael Woodford
Department of Economics
Columbia University
420 W. 118th Street
New York, NY 10027
and NBER
mw2230@columbia.edu




An online appendix is available at http://www.nber.org/data-appendix/w23787
1     Introduction

The theory of rational inattention, proposed by Christopher Sims and surveyed in Sims
(2010), endogenizes the imperfect awareness that decision makers have about the circum-
stances under which they must choose their actions. According to the theory, a decision
maker (DM) chooses her action on the basis of a subjective representation of the decision
situation that can be treated (formally) as a signal transmitted to the DM by a sender with
knowledge of the true state. The signal structure is assumed to be optimal, in the sense
of allowing the best possible state-contingent action choice, subject to a cost of more in-
formative signal structures. In Sims’ theory, the cost of an arbitrary signal structure is
proportional to the Shannon’s mutual information between the state of the world (that de-
termines the DM’s reward from choosing different actions) and the signal received by the
DM.
    In this paper, we will introduce the “neighborhood-based cost functions” as an al-
ternative to Shannon’s mutual information for use in rational inattention problems. We
demonstrate that these cost functions have three appealing features. First, they satisfies the
standard conditions (e.g. the conditions of De Oliveira et al. (2017) and Caplin and Dean
(2015)) typically assumed for cost functions in rational inattention problems. Second, when
used in a static rational inattention problem, they summarize the choice probabilities that
arise from a dynamic problem, in which the DM gathers information sequentially before
making her choice. Third, the neighborhood-based cost functions can capture the notion
that certain pairs of states are “similar,” meaning that it is difficult for the DM to discrimi-
nate between these states. Shannon’s mutual information has the first two of these features,
but not the third; we will provide an example, motivated by perceptual experiments, in
which rationally inattentive DMs’ behavior is consistent with the neighborhood-based cost
function, but not the mutual-information cost function. We also argue that this distinc-


                                               1
tion has consequences in economic applications, focusing on the global games example
of Morris and Yang (2016). We provide an example neighborhood-based cost function,
the expected Fisher information, which, like mutual information, has only a single param-
eter, but unlike mutual information, captures the notion that similar states are difficult to
distinguish.
    Sims’ original work on rational inattention motivated the use of Shannon’s mutual in-
formation, a measure of the degree to which the signal is informative about the state of the
world, by referencing the central role it plays in information theory (Cover and Thomas
(2012)). Mutual information is central to information theory as a consequence of pow-
erful mathematical results that are of considerable practical relevance in communications
engineering. It is not obvious, though, that the theorems that justify the use of mutual
information in communications engineering provide any warrant for using it as a cost func-
tion in a theory of attention allocation, either in the case of economic decisions or that of
perceptual judgments.1
    Moreover, the mutual-information cost function has implications that are unappealing
on their face, and that seem inconsistent with evidence on the nature of sensory process-
ing, as discussed in Woodford (2012). For example, the mutual-information cost function
imposes a type of symmetry across different states of nature, so that it is equally easy or
difficult to distinguish between any two states that are equally probably ex ante. In the
experimental task discussed by Caplin and Dean (2015), in which subjects are presented
with an array of 100 red and blue balls, and must determine whether there are more red
balls or more blue on a given trial, Sims’ theory of rational inattention implies that, be-
   1 As  explained in Cover and Thomas (2012), these theorems rely upon the possibility of “block coding” of
a large number of independent instances of a given type of message, that can be jointly transmitted before any
of the messages have to be decoded by the recipient. In the kind of situation with which we are concerned, an
action must be taken in an individual instance of a decision problem, and we wish to formulate a constraint
on the precision of the subjective perception of the decision problem in the individual instance, without
supposing that subjective descriptions of a long sequence of similar problems can be jointly formed before
deciding how to act in any of the individual problems.


                                                      2
cause the reward from any action (e.g., declaring that there are more red balls) is the same
for all states with the property that there are more red balls than blue, the probability of a
subject’s choosing that response will be the same in each of those states. In fact, it is much
easier to quickly and reliably determine that there are more red balls for some arrays in
this class (e.g. one with 98 red balls and only two blue balls) than others (e.g. one with 51
red balls and 49 blue balls, relatively uniformly dispersed), and subjects make more correct
responses in the former case.2
    One response to unappealing features of the mutual-information cost function is to
develop a theory of rational inattention that makes only much weaker assumptions about
the cost function (typically assumptions that are consistent with mutual information, but
not requiring it), as authors such as De Oliveira et al. (2017), Caplin and Dean (2015), and
Huettner et al. (2016) have done. This approach results in a theory with correspondingly
weaker predictions. We seek instead to motivate a more specific class of information-cost
functions, so as to allow more definite conclusions, while still including cases that we
regard as more realistic specifications than mutual information.
    Our approach exploits the special structure implied by an assumption that information
sampling occurs through a sequential process, in which each additional signal that is re-
ceived determines whether additional information will be sampled, and if so, the kind of
experiment to be performed next. We emphasize the limiting case in which each individual
experiment is only minimally informative, but a very large number of independent exper-
iments can be performed. In this continuous-time limit, we obtain strong and relatively
simple characterizations of the implications of rational inattention, owing to the fact that
only local properties of the assumed cost function for individual experiments matter in this
   2 Dewan  and Neligh (2017) present results from a related experiment in which subjects must instead esti-
mate the number of dots in a visual array. In this case, Sims’ theory would predict that all erroneous estimates
should occur with equal frequency, since the reward for an erroneous response is the same regardless of which
erroneous response is given. Instead, subjects are more likely to offer incorrect estimates that are close to the
correct number than incorrect estimates that are far from the correct number.


                                                       3
limiting case.
    We believe that it is often quite realistic to assume that information is acquired through
a sequential sampling process. As discussed in Fehr and Rangel (2011) and Woodford
(2014), an extensive literature in psychology and neuroscience has argued that data on both
the frequency of perceptual errors and the frequency distribution of response times can
be explained by models of perceptual classification based on sequential sampling. More
recently, some authors have proposed that data on stochastic choice and response time in
economic contexts can be similarly modeled.3
    Much of the empirical literature that models stochastic choice as the outcome of a
sequential sampling process aims simply to provide a process model of observed behavior,
but a number of recent papers endogenize at least some aspects of the information-sampling
process. Fudenberg et al. (2015) consider the optimal stopping problem for an information
sampling process described by the sample path of a Brownian motion with a drift that
depends on the unknown state of the world.4 This can be thought of as a problem in which
a given experiment (with the probability of positive or negative outcomes dependent on
the state of the world) can be repeated an indefinite number of times, with a fixed cost
per repetition of the experiment. The sequence of outcomes of the successive experiments
becomes a Brownian motion in the limiting case in which individual experiments require
only an infinitesimal amount of time (and hence involve only an infinitesimal cost, as a
fixed cost of sampling per unit time is assumed), and are correspondingly minimal in the
information that they reveal about the state (because the difference in the mean outcome of
an individual experiment across different states of the world is tiny relative to the standard
   3 In addition to the references in Fehr and Rangel (2011), recent examples include Krajbich et al. (2014)
and Clithero (2016). In the case of preferential choice between goods, the sampling presumably does not
refer to a sequence of repeated observations that are required to verify that the candy bar offered for sale is
indeed a Snickers bar, but more plausibly to a sequence of repeated value assessments used to estimate the
value of this option to the DM. These might be draws from memory (associations or recollections of past
experiences), as suggested by Shadlen and Shohamy (2016).
    4 See also Tajima et al. (2016) for analysis of a related class of models.




                                                      4
deviation of the outcome). In the case assumed by Fudenberg et al. (2015), there is no
choice about the type of experiment that can be repeatedly performed, but the decision
when to stop collecting further information is optimized.
   Woodford (2014) instead takes as given a stopping rule (motivated by the empirical psy-
chology and neuroscience literatures), but endogenizes the information sampling process,
as in theories of rational inattention. The assumed stopping rule makes the decision whether
to continue sampling (and the event action chosen) a function only of a single number, the
cumulative excess of positive over negative signals from the sequence of experiments; but
at each point in the sequential process, it is assumed to be possible to vary the probability of
a positive response conditional upon the true state, subject to an information-cost function
that makes more informative experiments more costly. Under the assumed cost function,
Woodford (2014) finds that optimal information sampling results in an evidence process
that evolves as a continuous stochastic diffusion process, and that it is optimal for the drift
of this process to be an increasing function of the relative value of the two choice options,
as assumed by Fudenberg et al. (2015); but rather than this process being a Brownian mo-
tion with a constant drift, as in Fudenberg et al. (2015), it is generally optimal for the drift
also to depend on the current belief state.
   Our approach differs from these earlier efforts in seeking to endogenize both the nature
of the information that is accumulated at each stage of the information-sampling process
and the stopping rule that determines how much information is collected before a decision
is made. We also consider decision problems with an arbitrary finite number of choice
alternatives, rather than restricting attention to binary choice problems, as in both Fuden-
berg et al. (2015) and Woodford (2014). In the sequential information sampling problem
considered here, we allow the information sampled at each stage to be chosen very flexi-
bly, as in Woodford (2014), subject only to a “flow” information-cost function; but we also
allow the decision when to stop sampling and make a decision to be made optimally, on

                                               5
the basis of the entire history of information sampled to that point, as in Fudenberg et al.
(2015). Among other results, we describe a class of information-cost functions such that in
the case of a binary decision, the DM’s beliefs evolve according to a diffusion along a one-
dimensional line segment, with a decision being made when either of the two endpoints is
reached, as postulated by Woodford (2014).
   In our continuous time model, the optimal information-sampling problem is presented
as a problem of optimal control of a diffusion process on the probability simplex (the set of
possible posterior beliefs), with sampling stopping when certain (endogenous determined)
boundaries are reached. For a special (but still relatively flexible) family of possible cost
functions for individual experiments, the continuous time model’s predictions with regard
to choice frequencies conditional on the state of the world are the same as those of a static
rational-inattention model, with an appropriately chosen information-cost function for the
choice of a single signal. The finite set of possible signals in the equivalent static model cor-
responds to the set of different possible terminal information states in the dynamic model,
each of which corresponds to one of the possible actions. For a particular family of flow
information-cost functions, the cost function for the equivalent static model is just the mu-
tual information between the action chosen and the true state of the world; we thus provide
foundations for the kind of rational inattention problem proposed by Sims (2010), that do
not rely on any analogy with rate-distortion theory in communications engineering.
   While our dynamic model makes predictions that are equivalent to those of the rational
inattention theory of Sims (2010) (and more particularly, its application to stochastic choice
by Matêjka et al. (2015)) for this particular family of flow information-cost functions, we
show that different predictions can be obtained under other, very plausible specifications
of the flow cost function. We focus on the implications of an attractive family of flow
information-cost functions, which we call “neighborhood-based” cost functions. The idea
of this class of information-cost specifications is that information structures are more costly

                                               6
the greater the extent to which they allow intrinsically similar states of the world (states
that share a “neighborhood”) to be discriminated; the dependence on a concept of intrinsic
similarity between states (the “neighborhood structure”) distinguishes cost functions of this
kind from the mutual-information cost function assumed by Sims. We show that versions of
our theory that assume a flow information-cost function in this family can explain the kind
of continuous variation of response frequencies with changes in the characteristics of the
alternatives presented that is commonly observed in perceptual discrimination experiments
(but that would not be predicted by the standard theory of rational inattention).
   As a still more specific special case, we consider a neighborhood-based cost function
that can be defined in the limiting case of a continuum of states that can be ordered on
a line — a case of considerable interest, both for economic applications and for applica-
tions to perceptual psychology. We consider the continuous-state limit of a static rational
inattention problem with a particular type of neighborhood-based cost function, and show
that it is equivalent to a static rational inattention problem with a particular cost function,
proportional to the average Fisher information (rather than the mutual information) of the
continuous family of statistical models defined by the information structure. Like Sims’
proposal, this proposal yields a highly parsimonious theory of rational inattention with
only one free parameter, indexing the degree of overall scarcity of attentional resources,
but one that we believe may be preferable to Sims’ proposal for many applications, such
as the problem of endogenous information in global games discussed by Morris and Yang
(2016).
   Our paper builds upon the rational inattention literature, surveyed in Sims (2010). In
its use of axioms to characterize the assumed form of the flow information-cost function,
it is particularly close to Caplin and Dean (2015), Caplin et al. (2017), and De Oliveira
et al. (2017). The Chentsov (1982) theorems used to characterize the properties of general
rational inattention cost functions were also used by Hébert (2014), in a different context.

                                              7
We also use techniques developed by Kamenica and Gentzkow (2011) and Matêjka et al.
(2015) in characterizing the solution to our problem.
   Section 2 begins directly with a description of our continuous-time model, and intro-
duces the information-cost matrix function as a way of parameterizing information costs
in this model. Section 3 then presents one of our main results (Theorem 1), that in a large
set of cases, the solution to the continuous-time model is equivalent, in terms of the joint
distribution of choices and states, to the implications of a static rational inattention model
with a suitable static information-cost function. In section 4, we discuss the connection
between the information-cost matrix function of the continuous-time model and the flow
information-cost function for an individual signal, and state a set of general assumptions
that flow information-cost functions are assumed to satisfy, in the spirit of the treatment of
static rational inattention problems by De Oliveira et al. (2017).
   In section 5, we introduce a specific class of flow cost functions that satisfy these gen-
eral conditions, and are of interest because they incorporate a notion of “distance” between
different states of the world; we then derive the static information-cost functions that corre-
spond to them, as possible alternatives to mutual information as a cost function in rational
inattention models. In subsection 5.2 of this section, we propose an even more specific
static cost function, based on the Fisher information as a measure of the informativeness of
an information structure, that can be applied to rational inattention models with a contin-
uum of states.
   Finally, section 6 provides a justification for the continuous-time model proposed in
section 2, and for the connection between flow cost function specifications and information-
cost matrix function of the continuous-time model asserted in section 4. Here we show
that a discrete-time dynamic evidence accumulation problem, in which the cost of each
individual signal is given by a flow cost function satisfying the assumptions stated in section
4, leads to the continuous-time problem discussed in section 2, in the limit as the number

                                              8
of successive signals per time period is made large, while the informativeness of each
individual signal is made small at a corresponding rate. Section 7 concludes.



2    A Continuous-Time Model of Sequential Evidence Ac-

     cumulation

We begin by directly introducing our continuous-time model of sequential evidence accu-
mulation, leaving for later (section 6) the demonstration that it arises as a limiting case of
an explicit discrete-time dynamic evidence accumulation problem. Let x ∈ X be the un-
derlying state of the nature, and a ∈ A be the action taken by the DM. For simplicity, we
assume that A and X are finite sets. We also assume that the number of states is weakly
larger than the number of actions, |X| ≥ |A|. The DM’s utility from taking action a in state
x at time t is ua,x − κt. The parameter κ > 0 governs the penalty for delaying making a
decision; the DM does not discount the future. We assume a penalty of this kind, rather
than time discounting, for reasons of tractability.
    The DM does not perfectly observe the state x ∈ X. At each time t, the DM holds
beliefs qt ∈ P(X), where P(X) ⊂ R|X| denotes the probability simplex over X. That is, qt
is a vector of length |X|, whose elements, denoted qx,t , are the probability, under the DM’s
beliefs at time t, of state x. Time begins at t = 0, when the DM holds prior beliefs q0 . At
each moment in time, the DM faces two decisions: whether to gather information about
the state x ∈ X, and whether to stop and make a decision. When stopping with beliefs qτ at
time τ, the DM will simply choose a to maximize uTa · qτ , where ua is the vector of utilities
associated with action a, resulting in payoff û(qτ ) − κτ.
    When the DM gathers information, she chooses the variance-covariance matrix of pos-
sible changes in her beliefs, subject to certain constraints. In our model, the DM’s beliefs



                                               9
evolve as
                                         dqx,t = qx,t σx,t · dBt ,                                    (1)

where dBt is an |X| − 1-dimensional Brownian motion,5 σt is a matrix that can be chosen
by the DM, and σx,t is a particular row of that matrix.
    The DM’s choice of σt is subject to restrictions — a trivial one to ensure that the beliefs
stay in the simplex, and an economic restriction that limits the amount of information the
DM can acquire. The trivial restriction is that


                                              ι T · dqt = 0


always, where ι is a vector of ones. This restriction is equivalent to requiring that


                                               σtT qt = ~0.


We will use M(qt ) to denote the set of |X| × |X| matrices satisfying this condition. Our
notation enforces the requirement that dqx,t = 0 if qx,t = 0.
    The non-trivial restriction, which limits the quantity of information the DM can acquire
at each moment, is
                                         1
                                           tr[σt σtT k(qt )] ≤ χ,                                     (2)
                                         2

where k(qt ) is an |X| × |X| dimensional matrix-valued function we will refer to as the
“information-cost matrix function”, tr[·] is the trace, and χ is a positive constant that in-
dexes the tightness of the constraint. We discuss this constraint, and the information-cost
matrix function, in more detail below. For now, we note simply that the information-cost
matrix function satisfies certain properties: for any qt , k(qt ) is symmetric and positive
   5 Notethat this is largest possible number of independent Brownian motions of which dqt may be a linear
combination.



                                                   10
semi-definite, and its null space is the space of vectors that are constant for all x ∈ X in the
support of qt .6
    Using her control of the volatility of her beliefs, and subject to the constraints imposed
by the information-cost matrix function, our DM attempts to maximize her expected payoff.
Her sequence problem can be written, given beliefs qt at time t,


                             V (qt ) =        sup           Et [û(qτ ) − κ(τ − t)],
                                         {σs ∈M(qs )},τ≥t


where τ is the DM’s endogenous stopping time, subject to the constraints listed previously.
    Wherever this value function is twice-differentiable and the DM does not choose to
stop, the problem can be given a simple recursive representation:

                                        1
                                sup       tr[σtT D(qt )Vqq (qt )D(qt )σt ] = κ,
                             σt ∈M(qt ) 2


subject to the information constraint (2), where D(qt ) is a diagonal matrix with the elements
of qt on its diagonal, and Vqq (qt ) is the Hessian of V (q) evaluated at q = qt .7
    The following lemma describes the Hamilton-Jacobi-Bellman (HJB) equation associ-
ated with this dynamic optimization problem. It is derived by showing that the information
constraint binds.8 The maximum eigenvalue appears in place of a maximization over σt ,
   6 Actually,  because we require that σt ∈ M(qt ), constraint (2) only involves the quadratic form vT k(qt )w
defined for vectors v and w such that vT qt = wT qt = 0. We extend the definition of the quadratic form to
all vectors v, w ∈ R|X| , in order to obtain a unique representation in terms of a matrix k(qt ), by adding the
requirement that k(q)v = 0 for any vector v ∈ R|X| with the property that vx is equal to a constant for all x in
the support of q.
    7 In the case of a differentiable function V (q) defined on the probability simplex P(X), in order to write

the Hessian of the function as a matrix, we must adopt a coordinate system for the tangent space to the
                                                                                                         |X|
probability simplex. Throughout this paper, we do this by extending the function to the domain R+ by
defining the function to be homogeneous of degree one on this larger domain (an assumption that does not
restrict the function’s values on the simplex). Vectors in the tangent space are then simply vectors in R|X| ,
which we express using the natural set of basis vectors corresponding to each element of X. The Hessian
matrices appearing in equations such as (3), (11), (15), and (17) below should also all be understood in this
way.
    8 The derivation depends on an additional property of the k(q ) matrix that will be discussed below.
                                                                    t



                                                       11
but this is just a compact way of expressing the idea that the DM is choosing in which
direction(s) to update her beliefs.

Lemma 1. Anywhere the value function V (qt ) is twice-differentiable, it satisfies


                   max{λ1 (D(qt )Vqq (qt )D(qt ) − θ k(qt )), û(qt ) −V (qt )} = 0,                        (3)


where θ = χ −1 κ, and for any |X| × |X| matrix K, λ1 (K) denotes the largest eigenvalue of
K associated with an eigenvector v such that ι T v = 0.9

Proof. See the appendix, section A.1.

    This equation has the standard form of an optimal stopping problem, with the twist that
it is a “Hessian equation” in the continuation region. The parameter θ describes the race
between information acquisition and time in this model. The larger the penalty for delay,
and the tighter the information constraint, the larger the parameter θ . The caveat about
twice-differentiability plays several roles. First, as is common in optimal stopping prob-
lems, the value function may not be twice differentiable on the stopping boundary. Second,
the Hessian equation in the continuation region is “degenerate elliptic”, and therefore a
solution that is twice-differentiable everywhere in the continuation region may not exist. A
third complication is that the beliefs qt may come to place zero weight on a certain state —
that is, the beliefs may hit the boundary of the simplex, at which point the value function
V (qt ) is not twice-differentiable in all directions. Fortunately, in what follows, these issues
will be a nuisance, rather than a serious obstacle.
   9 Here  we are interested in the eigenvectors of the matrix corresponding to elements of the tangent space
to the probability simplex. Note that under our notation for writing quadratic forms over the probability
simplex as matrices, explained in footnotes 6 and 7 above, ι is a null eigenvector of both D(q)Vqq D(q) and
k(q), for any q; but we do not wish to count this as one of the eigenvectors of the linear operator for purposes
of defining the maximum eigenvalue, as our first-order condition actually involves a linear operator defined
on the tangent space of the probability simplex.




                                                      12
    The DM’s optimal stopping rule is characterized by the standard value-matching and
smooth-pasting conditions. Let Ω ⊂ P(X) be the open subset of the simplex on which the
DM continues to search for information, and let ∂ Ω denote its boundary. For all q ∈ ∂ Ω,
the value matching condition, V (q) = û(q), and smooth pasting condition, Vq (q) = ûq (q),
will hold. Note, however, that the derivative ûq (q) does not exist everywhere — at beliefs
where the DM is just indifferent between two actions with distinct state-contingent payoffs,
the stopping payoff is non-differentiable.10 However, it will never be optimal for the DM
to stop at one of these indifference points.
    Before we describe the value function, we will provide some intuition for the volatility
constraint and describe in more detail the information-cost matrix function. The volatility
constraint is a limit on the information the DM can acquire, because it limits the volatility
of her beliefs. Our DM is a Bayesian, meaning that she can never expect to revise her
beliefs in a particular direction — her beliefs must be a martingale; this is why there can be
no drift term in equation (1). If she receives a mostly uninformative signal at a particular
moment, her beliefs have a small amount of volatility at that moment. In contrast, if she
receives an informative signal, her beliefs will be very volatile.
    Our specification assumes that her beliefs are driven by a Brownian motion, which
generates continuous sample paths and does not have jumps.11 This embeds the idea that,
as one looks at smaller and smaller time intervals, the informativeness of the signals the
DM is observing scales down. In section 6, we discuss more primitive assumptions about
the cost of alternative dynamic information sampling strategies that lead the DM to want
to smooth the quantity of information gathered across time, so that the continuity assumed
  10 At this point, we have also not shown that V (q) is differentiable everywhere, but this is proven in the
proof of Theorem 1.
   11 Che and Mierendorff (2016) and Zhong (2017) explore related models with jumps in beliefs. These are

assumed to represent the only possible form of information arrival in the former paper, and demonstrated
to represent an optimal form of experimentation in the latter paper, under assumptions different from those
made here.



                                                    13
in this section is a feature of the optimal strategy, in a continuous-time limiting case of the
model presented in that section.
   We derive the information constraint (equation (2)) from a model in which the DM can
choose any information structure she desires at each time period, as in standard rational
inattention models. One result of our derivation is the observation that the DM can choose
any volatility matrix σt . This is, in a sense, a familiar idea — Kamenica and Gentzkow
(2011), for example, emphasize the idea of choosing a distribution of posteriors, subject
to the constraint that the mean posterior is equal to the prior. Our DM appears to choose
only the volatility, and not the higher cumulants of the distribution of posteriors, but this is
because she finds it optimal to smooth her information gathering over time, and the instan-
taneous volatility is sufficient to characterize the resulting process for beliefs. This result
permits both a relatively parsimonious specification of the information sampling strategies
available to the DM, and a relatively parsimonious specification of possible forms for the
information constraint.
   In modeling the evolution of the DM’s beliefs as a diffusion process, our model resem-
bles those proposed by authors such as Krajbich et al. (2014) and Fudenberg et al. (2015),
though unlike those authors we endogenize the diffusion process through which additional
information arrives while sampling continues. Additionally, our model emphasizes the “un-
conditional” dynamics of beliefs (that is, not conditional on any particular state being the
true state), whereas the models discussed by those authors are described in terms of their
“conditional” dynamics (that is, conditional on some particular state being the true state).
   The information-cost matrix function k(qt ) is more than simply a way of obtaining a
single (scalar) measure of the “size” of the elements of σt . The relative size of different
elements of the matrix also allows us to specify the degree to which it is more costly
to obtain more precise information of some kinds rather than others. Larger (positive)
diagonal elements kxx for certain states x imply that it is relatively more costly to obtain

                                              14
signals that reveal much about the likelihood of those states; larger negative off-diagonal
elements kxx0 (relative to the size of the diagonal elements kxx and kx0 x0 ) for pairs of states
x, x0 imply that it is relatively more costly to obtain signals that allow one to differentiate
sharply between states x and x0 .
       An example of an information-cost matrix function that satisfies our general assump-
tions (and will be important for the discussion below) is the inverse Fisher information
matrix (g+ (q)),12

                                                                                           
                                  q (1 − q1 )   −q1 q2                ...      −q1 q|X|
                                  1                                                        
                                                                                           
                                  −q1 q2     q2 (1 − q2 )            ...      −q2 q|X| 
                          +
                  k(q) = g (q) =                                                           .             (4)
                                                                                           
                                       ..           ..                ..            ..
                                 
                                       .            .                    .          .
                                                                                            
                                                                                            
                                                                                           
                                   −q1 q|X|    −q2 q|X|               . . . q|X| (1 − q|X| )


In this case, the off-diagonal element kxx0 (q) is equal to −q(x)q(x0 ) for any pair of states
x, x0 ; thus it depends only on the prior probabilities of the two states, and is otherwise the
same regardless of the states selected. Thus any two states are assumed to be equally easy
or difficult to tell apart: it only matters whether two states are the same or not, and how
likely they are to occur.
       While this kind of symmetry might seem appealing on a priori grounds for some appli-
cations (where the different possible states are a set of alternatives, each equally unrelated
to all of the others), we view it as quite implausible for many cases of economic relevance.
For example, one is often interested in states that represent different possible values of
some quantity (a “state variable”), and hence can be ordered on a line.13 One might well
suppose that possible methods of learning about the value of that variable will all have the
  12 The    Fisher information matrix, of which this can be viewed as a pseudo-inverse, is described in section
4.2.
  13 This is also often true of perceptual classification experiments, in which subjects are asked to classify
stimuli that differ from one another in their intensity or magnitude along some single dimension.


                                                       15
property that nearby values of the state variable result in similar probabilities of receiving
particular signals, and hence that it is particularly costly to arrange an information structure
that makes the conditional probabilities of signals very different for states that are near one
another in the ordering of states.
   An alternative possible information-cost matrix function, also satisfying our general
assumptions, is given by

                                                                                                        
               q1 q2
              q1 +q2      − qq11+q
                                q2
                                   2
                                             0                      ...                        0
                                                                                                       
         
         − q1 q2       q1 q2                                       ..                         ..       
          q1 +q2      q1 +q2+ qq22+q
                                    q3
                                      3
                                        − qq22+q
                                               q3
                                                 3
                                                                       .                        .       
                                                                                                        
                                          ..                        ..
                                                                                                       
  k(q) =  0                 q2 q3
                          − q +q              .                          .                               . (5)
                                                                                                       
                                2        3
                                                                                                0
                                                                                                       
          .                    ..           ..         q|X|−1 q|X|−2      q|X| q|X|−1      q|X|−1 q|X| 
          ..                        .            .                                      − q +q
                                                       q|X|−2 +q|X|−1 + q|X|−1 +q|X|
                                                                                                        
                                                                                            |X|   |X|−1
                                                                                                       
                                                                                                       
                                                                   q q                     q|X|−1 q|X|
            0                   ...          0                 − q |X|+q|X|−1             q|X| +q|X|−1
                                                                    |X|  |X|−1



In this case, the only off-diagonal elements kxx0 (q) are negative elements in the case that x0
directly follows x in the ordering of states (or vice versa). This form of matrix k(q) implies
that an information structure is costly only to the extent that there are pairs of “neighboring”
states x, x0 for which the conditional probabilities of signals are different (px0 6= px ).
   The differing implications of these two alternative assumptions about the form of the
information-cost matrix function are explored in section 5. For now, we simply note that
our model allows for different specifications in this regard, and that we regard this as desir-
able, as it will often be reasonable for the specification of information costs to incorporate
a notion of “distance” between different possible states.
   Our derivation of the continuous-time problem set out above from a more explicit evi-
dence accumulation problem places additional restrictions on the information-cost matrix
function, beyond the properties already mentioned above: it will in fact be necessary that
k(q) be continuous, and that there exist a positive constant m such that k(q) − mg+ (q) is


                                                      16
positive semi-definite.14
     For a large class of information-cost matrix functions k(qt ), we can solve the sequence
problem described in this section, and show that the solution is equivalent to a certain static
rational inattention problem. We present these results in the next section.



3      The Equivalence of Static and Dynamic Rational Inat-

       tention Problems

In most theories of rational inattention, including the classic formulations of Sims, only a
single signal is collected for each decision that must be made. In a decision problem where
an action is to be chosen once from a set of possibilities, the rational inattention problem is
static; a signal is obtained (once) that depends on the state, an action is taken that depends
on the signal, and that is all. The kind of dynamic optimization model proposed in the
previous section seems quite different.
     Nonetheless, we establish below that in a broad class of cases, it is possible to estab-
lish an equivalence between the information that is acquired through an optimal evidence
accumulation process of the kind proposed in the previous section and the information ac-
quired in a static model of rational inattention, with a particular type of cost function. Thus
our dynamic model does not necessarily have different implications than a static rational
inattention model; however, the dynamic optimization problem can provide a reason for
interest in static information-cost functions of particular types.
    14 Examples (4) and (5) above are both continuous in q. The second of these examples does not strictly
satisfy the second requirement stated in the text for m > 0, but is the limit of a sequence of examples that
does. These examples are closely related to the mutual-information cost function proposed by Sims and to a
“neighborhood-based” cost function that we introduce in section 5, respectively.




                                                    17
3.1     Static Rational Inattention Problems

We begin by explaining the form of a static rational inattention problem. As in the previous
section, let x ∈ X be the underlying state of nature, and let s ∈ S be a signal the DM can
receive, which might convey information about the state. We assume that X and S are
finite sets. Let q ∈ P(X) denote the DM’s prior belief (before receiving a signal) about
the probability of state x. Define ps,x as the probability of receiving signal s in state x,
let px ∈ P(S) be the associated conditional probability distribution of the signals given
state x, and let p be the |S| × |X| matrix whose elements are ps,x . The matrix p, which is
a set of conditional probability distributions for each state of nature, {px }x∈X , defines an
“information structure.” After receiving signal s, the DM will hold a posterior, qs ∈ P(X),
which is a function of p and q, defined by Bayes’ rule.
    The maximum achievable expected payoff, given an information structure p and prior
q, can be written as
                               ū(p, q) ≡ max      ∑ ∑ qx ps,x u(a(s), x).
                                             {a(s)} x∈X s∈S


The standard static rational inattention problem, given the signal alphabet S,15 is then


                                       max        ū(p, q) − θC(p, q; S),                                 (6)
                                  {px ∈P(S)}x∈X


where
                                  C(·, ·; S) : P(S)|X| × P(X) → R                                         (7)

is a cost function for information structures, and θ > 0 is a multiplicative factor that lets
us consider alternative assumptions about the tightness of the information constraint, given
a measure of the informativeness of alternative information structures represented by the
  15 The full problem includes a choice over the signal alphabet S. A standard result, which will hold for all
of the cost functions we study, is that |S| = |A| is sufficient.



                                                     18
function C.
    In the classic formulation of Sims, a problem of the form equation (6) is considered, in
which the cost function C(p, q; S) is given by the Shannon mutual information between the
signal and the state. This can be defined using Shannon’s entropy,16


                                H Shannon (q) ≡ − ∑ (eTx q) ln(eTx q).                                  (8)
                                                      x∈X


Shannon’s entropy can in turn be used to define a measure of the degree to which the
posterior qs associated with any signal differs from the prior q, the Kullback-Leibler (KL)
divergence,


              DKL (qs ||q) ≡ H Shannon (q) − H Shannon (qs ) + (qs − q)T HqShannon (q).                 (9)


Mutual information is then the expected value of the KL divergence over possible signals,


                             I Shannon (p, q; S) ≡   ∑ (eTs pq)DKL (qs||q).                            (10)
                                                     s∈S


It is a measure of the informativeness of the signal, in that it provides a measure of the
degree to which the signal changes what one should believe about the state, on average.
    Shannon’s mutual information is not, however, the only possible measure of the in-
formativeness of an information structure, or the only plausible cost function for a static
rational inattention problem. We discuss additional examples below.
  16 We   use the notation ex to denote the vector (element of RX ) with a one in the place corresponding to
state x, and zeros elsewhere (column x of the identity matrix of dimension |X|).




                                                     19
3.2        A Tractable Class of Continuous-Time Models

We return to our discussion of the continuous-time information sampling problem intro-
duced in section 2. To obtain further results, we restrict our attention to information-cost
matrix functions with the following property: there exists a twice-differentiable function
          |X|
H : R+ → R such that, for all qt in the interior of the simplex,


                                      D(qt )−1 k(qt )D(qt )−1 = Hqq (qt ).                                   (11)


This class includes a number of information-cost matrix functions of interest: for example,
it includes the case in which k(qt ) is the inverse Fisher information matrix, which we will
show corresponds to the standard rational inattention model, and the case in which k(qt ) is
the “neighborhood-based” function that we introduce in section 5.17 We shall refer to the
function H as the “generalized entropy function,” for reasons that will become clear below.
Using this convex function, we can define a Bregman divergence,


                              DH (qs ||q) = H(qs ) − H(q) − (qs − q)T Hq (q).


The Kullback-Leibler divergence is a Bregman divergence (see equation (9)), with a gen-
eralized entropy function equal to the negative of Shannon’s entropy.
    With these information-cost matrix functions, it is easy to show (using equation (3))
that the quantity V (q) − θ H(q) is a local martingale inside the continuation region, any-
where the value function is twice differentiable. Ignoring several technicalities, which are
  17 It   is more restrictive, however, than the class of information-cost matrix functions defined in section 2.




                                                         20
discussed in the proof, we can apply the optional stopping theorem:


                            V (q0 ) = E0 [V (qτ ) − θ H(qτ ) + θ H(q0 )]

                                   = E0 [û(qτ ) − θ H(qτ ) + θ H(q0 )].


Using this idea, and the notion that, in an optimal stopping problem, the DM “chooses the
boundaries,” we conjecture and verify the following result:

Theorem 1. There exists a unique solution to the continuous time sequential evidence
accumulation problem, in which


          V (q0 ) =          max           ∑ π(a)(uTa · qa) − θ ∑ π(a)DH (qa||q0),
                      π∈P(A),{qa ∈P(X)}a∈A a∈A                    a∈A


subject to the constraint that ∑a∈A π(a)qa = q0 .
   There exist maximizers of this problem, π ∗ and q∗a , such that π ∗ is the unconditional
probability, in the dynamic problem, of choosing a particular action, and q∗a , for all a such
that π ∗ (a) > 0, is the unique belief the DM will hold when stopping and choosing that
action.

Proof. See the appendix, section A.2.

   Thus the sequential evidence accumulation problem is equivalent to a static rational
inattention problem of the kind stated in section 3.1, with a particular kind of static information-
cost function,


                            C(p, q0 ; S) =     ∑ π(s)DH (qs||q0),                          (12)
                                              s∈S
                                          =    ∑ π(s)H(qs) − H(q0)
                                              s∈S


where π(s) now refers to the unconditional probability of receiving signal s in the static

                                                 21
problem, and qs to the posterior when signal s is received; and with the signal space S
in the static problem identified with the set of possible actions A.18 We shall call a cost
function that can be written in the form (12) “posterior-separable.”19
    The mutual-information cost function (10) proposed by Sims is one such cost func-
tion. In this case, the generalized entropy function H is the negative of Shannon’s entropy
(8), the corresponding information-cost matrix function is the inverse Fisher information
matrix (4), the Bregman divergence is the Kullback-Leibler divergence (9), and the in-
formation measure defined by (12) is then the Shannon mutual information (10). Thus
Theorem 1 provides a foundation for assuming endogenous information of the same kind
as the standard static rational inattention model, and hence for the same predictions regard-
ing stochastic choice as are obtained by Matêjka et al. (2015).20 This assumes a particular
information-cost matrix function; but below we show not only that a continuous-time model
with this particular information-cost matrix function can arise as the limit of a well-behaved
discrete-time model of sequential evidence accumulation, but also that any of an entire class
of possible specifications of the flow information cost function for that discrete-time model
will lead to this result in the continuous-time limit.
    On the other hand, Theorem 1 also implies that other posterior-separable cost functions
can similarly be justified. Indeed, any static information cost function (12), where DH is
the Bregman divergence derived from some convex, twice-differentiable function H, can
be given such a justification.21 We give additional examples in section 5. The divergence
DH associated with such a model is of interest apart from its role in defining the equivalent
  18 The  “signal” can thus be viewed as an instruction as to which action is advisable.
  19 This  kind of cost function is instead called “uniformly posterior-separable” in Caplin et al. (2017). The
class of static cost functions that can be justified by Theorem 1 is also related to the class of “GERI” cost
functions defined by Fosgerau et al. (2016).
   20 For a related foundation for this static cost function, in the special case in which there are only two

possible states, see Morris and Strack (2017).
   21 The continuous-time information sampling process that is required is simply the one in which the

information-cost matrix function is given by equation (11).



                                                     22
static information-cost function (12). In particular, the expected value of the divergence
indicates the expected time cost required for the DM to reach a decision.
   Theorem 1 shows that we can associate a particular posterior-separable static information-
cost function with any matrix-valued function k(q) satisfying certain conditions: this is the
information cost function that defines a static rational-inattention problem that is equiva-
lent in certain respects to the continuous-time problem defined by k(q). But we also show
below how to derive a particular information-cost matrix function k(q) corresponding to
any information-cost function C(p, q; S) satisfying certain conditions: k(q) defines a local
approximation to the function C(p, q; S), and defines a continuous-time problem that rep-
resents a limiting case of a discrete-time optimal evidence accumulation problem, in which
C(p, q; S) is the flow information-cost function specifying the cost associated with each
individual signal that is received.
   Thus, there is a two-way relationship between matrix-valued functions k(q) and cost
functions C(p, q; S). Posterior-separable cost functions are the fixed points of the result-
ing mapping: if one uses a posterior-separable cost function to derive an information-cost
matrix function, and then solves the continuous-time model defined by that function k(q),
one will recover that same posterior-separable cost function as the static information-cost
function of the equivalent static rational inattention problem.
   Another important general consequence of Theorem 1 concerns posterior beliefs at the
time of an eventual decision. The probability distribution q∗a ∈ P(X) is the DM’s belief
conditional on taking action a ∈ A. The vector q∗a is unique, given a particular action a,
meaning that there is only one belief the DM can reach before choosing to stop and take
a particular action. (The further this belief is from the DM’s prior, q0 , as measured by the
divergence DH , the more time it will take, in expectation, for the DM to arrive at this belief
before acting.) The martingale property of beliefs during the evidence accumulation pro-
cess thus requires that beliefs qt at each stage of the process are some convex combination

                                              23
of the finite set of posteriors {q∗a }a∈A .
    Hence beliefs diffuse on a simplex of dimension |A| − 1 during the decision process;
if there are only two possible actions (as in the binary choice problems to which the drift-
diffusion model is applied by authors such as Fehr and Rangel (2011)), then the belief state
must diffuse along a line segment, as assumed in the DDM, regardless of the number of
possible states |S|. Thus an apparently arbitrary feature of the DDM (outside the two-state
case in which the DDM is known to correspond to optimal Bayesian decision making, as
discussed by Fudenberg et al. (2015)) can be shown to be follow from optimal sequential
evidence accumulation, if the information sampling is flexible in the way that we model it
here.



4       Flow Information Costs

In this section, we further elaborate on the connection, suggested above, between the
information-cost matrix function in our continuous-time model of information sampling
and the kind of cost function for an individual signal that is assumed in static rational inat-
tention models. The continuous-time model can be viewed as a limiting case of a discrete-
time model of optimal evidence accumulation, in which an endogenously determined signal
is received each period, and the choice of the signal to receive each period is subject to a
cost for more informative signals, specified by an information-cost function similar to the
kind assumed in static rational inattention models. We call this cost function for an in-
dividual signal in a dynamic model of evidence accumulation the “flow information-cost
function.”
    While we defer until section 6 a complete discussion of how the continuous-time model
can be derived as a limiting case of a discrete-time dynamic model, in this section we
preview certain conclusions from that analysis by explaining the connection between the


                                              24
flow information-cost function of the discrete-time dynamic model and the information-
cost matrix function of the continuous-time model. (Here the connection is simply asserted;
the connection is proven in section 6.) We preview the results before proceeding to the
complete derivation, because understanding them can help to explain the assumptions about
the information-cost matrix function that we have proposed above. Additionally, in the
following section we discuss a particular class of information-cost matrix functions, and
wish to motivate this specification in terms of the form of flow information-cost functions
from which these information-cost matrix functions can be derived.
    An important conclusion of this section is our demonstration that many different flow
information-cost functions can give rise to the same information-cost matrix function,
and hence to the same predictions about the information that will be accumulated in the
continuous-time limit. This is one of the main advantages, in our view, of considering the
continuous-time limit: while our conclusions still depend on assumptions about the nature
of information costs, there are less ways in which our conclusions can vary once we pass
to the continuous-time limit.


4.1     Assumptions about Flow Information-Cost Functions

At each stage of the discrete-time sequential evidence accumulation problem discussed
in section 6, the DM chooses an information structure that determines the kind of signal
observed in that stage. Any such information structure p has a cost C(p, q; S), given by
a function of the form of (7), where q indicates the DM’s prior in this stage (that is, the
posterior beliefs following from observations prior to the current stage of the dynamic
problem), and S is again the signal alphabet.22 Our most general results depend only on
  22 The  information-cost functions that we study, like mutual information, are defined for all finite signal
alphabets S. Note, however, that mutual information is also defined over alternative sets of states of nature X.
We do not impose this requirement on our more general cost functions — all of our analysis takes the set of
states of nature as given.


                                                      25
assuming that this flow information-cost function satisfies a set of six general conditions,
stated below.
    All of these conditions are satisfied by the mutual-information cost function (10) pro-
posed by Sims, but they are also satisfied by many other cost functions. (Additional ex-
amples are given in section 5.) They are closely related to conditions that other authors
have also proposed as attractive general properties to assume about information-cost func-
tion, though in the context of static information-cost functions of the kind discussed in
section 3.1. Here we assume that the flow information-cost function in our dynamic model
satisfies all six of these conditions; we then prove that under our assumptions, the equiva-
lent static rational inattention problem (the existence of which is guaranteed by Theorem 1)
involves a static information-cost function that satisfies these conditions.

Condition 1. Information structures that convey no information (px = px0 for all x, x0 in the
support of q) have zero cost. All other information structures have a weakly positive cost.

    This condition ensures that the least costly strategy for the DM in the standard static
rational inattention problem is to acquire no information, and make her decision based on
the prior. The requirement that gathering no information has zero utility cost is a normal-
ization.
    The next condition is called mixture feasibility by Caplin and Dean (2015). Consider
two information structures, {p1,x }x∈X , with signal alphabet S1 , and {p2,x }x∈X , with alpha-
bet S2 . Given a parameter λ ∈ (0, 1), we define a mixed information structure, {pM,x }x∈X
over the signal alphabet SM = (S1 ∪ S2 ) × {1, 2}. For each s = (s1 , 1) in the alphabet
SM , pM,x (s) is equal to λ p1,x (s) if s1 ∈ S1 , and equal to 0 otherwise. Likewise, for each
s = (s2 , 2), pM,x (s) is equal to (1 − λ )p2,x (s) if s2 ∈ S2 , and equal to 0 otherwise.
    That is, this information structure results, with probability λ , in a posterior associated
with information structure p1 , and with probability 1 − λ in a posterior associated with in-


                                                26
formation structure p2 . The distribution of posteriors under the mixed information structure
is a convex combination of the distributions of posteriors under the two original information
structures, as if the DM flipped a coin, observed the result, and then randomly chose one
of the two information structures. The mixture feasibility condition requires that choosing
a mixed information structure costs no more than the cost of randomizing over information
structures (using a mixed strategy in the rational inattention problem).

Condition 2. Given two information structures, {p1,x }x∈X , with signal alphabet S1 , and
{p2,x }x∈X , with alphabet S2 , the cost of the mixed information structure is weakly less than
the weighted average of the cost of the separate information structures:


                    C(pM , q; SM ) ≤ λC(p1 , q; S1 ) + (1 − λ )C(p2 , q; S2 ).


   The next condition uses Blackwell’s ordering. Consider two signal structures, {px }x∈X ,
with signal alphabet S, and {p0x }x∈X , with alphabet S0 . The first information structure
Blackwell dominates the second information structure if, for all utility functions u(a, x)
and all priors q ∈ P(X),
                                      ū(p, q) ≥ ū(p0 , q).

If one information structure Blackwell dominates another, it is weakly more useful for
every decision maker, regardless of that decision maker’s utility function and prior. In this
sense, it conveys weakly more information. This ordering is incomplete; most information
structures neither dominate nor are dominated by a given alternative information structure.
However, when an information structure does Blackwell dominate another one, we assume
that the dominant information structure is weakly more costly.

Condition 3. If the information structure {px }x∈X with signal alphabet S is more informa-



                                               27
tive, in the Blackwell sense, than {p0x }x∈X , with signal alphabet S0 , then, for all q ∈ P(X),


                            C({px }x∈X , q; S) ≥ C({p0x }x∈X , q; S0 ).


   The first three conditions are, from a certain perspective, almost innocuous. For any
joint distribution of actions and states that could have been generated by a DM solving
a rational inattention type problem, with an arbitrary information cost function, there is
a cost function consistent with these three conditions that also could have generated that
data (Theorem 2 of Caplin and Dean (2015)). The result arises from the possibility of
the DM pursuing mixed strategies over information structures, or in the mapping between
signals and actions. These conditions also characterize “canonical” rational inattention cost
functions, in the terminology of De Oliveira et al. (2017).
   The mixture feasibility condition (Condition 2) and Blackwell monotonicity condition
(Condition 3) are equivalent to requiring that the cost function be convex over informa-
tion structures and Blackwell monotone. We summarize this equivalence in the following
lemma.

Lemma 2. Let p and p0 be information structures with signal alphabet S. A cost function
is convex in information structures if, for all λ ∈ (0, 1), all signal alphabets S, and all
q ∈ P(X),


                C(λ p + (1 − λ )p0 , q; S) ≤ λC(p, q; S) + (1 − λ )C(p0 , q; S).


A cost function satisfies mixture feasibility and Blackwell monotonicity (Conditions 2 and
3) if and only if it is convex in information structures and satisfies Blackwell monotonicity.

Proof. See the appendix, section A.3.

   The fourth condition that we assume, which is not imposed by Caplin and Dean (2015),

                                                28
Caplin et al. (2017), or De Oliveira et al. (2017), is a differentiability condition that will
allow us to characterize the local properties of our cost functions.

Condition 4. For all signal alphabets S, in a neighborhood around any uninformative in-
formation structure, the information cost function is continuously twice-differentiable in
information structures {px }x∈X , in all directions that do not change the support of the signal
distribution, and directionally differentiable, with continuous directional derivatives, with
respect to perturbations that increase the support of the signal distribution. The information
cost function is also Lipschitz-continuous in q.

While this may seem a relatively innocuous regularity condition, it is not completely gen-
eral; for example, it rules out the case in which the DM is constrained to use only signals in
a parametric family of probability distributions, and the cost of other information structures
is infinite. Thus it rules out information structures of the kind assumed in Fudenberg et al.
(2015) or Morris and Strack (2017). Condition 4 also rules out other proposed alternatives,
such as the channel-capacity constraint suggested by Woodford (2012).
   The next condition that we assume, which is also not imposed by Caplin and Dean
(2015), Caplin et al. (2017), or De Oliveira et al. (2017), is a sort of local strong convexity.
We will assume that the cost function exhibits strong convexity, in the neighborhood of an
uninformative information structure, with respect to information structures that hold fixed
the unconditional distribution of signals, uniformly over the set of possible priors.

Condition 5. There exists constants m > 0 and B > 0 such that, for all priors q ∈ P(X),
and all information structures that are sufficiently close to uninformative (C(p, q; S) < B),

                                           m
                            C(p, q; S) ≥     ∑ (eTs pq)||qs − q||2X ,
                                           2 S∈S

where qs is the posterior given by Bayes’ rule and || · ||X is an arbitrary norm on the tangent

                                               29
space of P(X).

    This condition is slightly stronger than Condition 1; it it essentially an assumption of
“local strong convexity” instead of merely local convexity. It implies that all informative
information structures have a strictly positive cost, and that (regardless of the DMs’ current
beliefs) there are no informative information structures that are “almost free.”
    The mutual-information cost function (10) satisfies each of these five conditions. How-
ever, it is not the only cost function to do so. For example, we can construct a family of
such cost functions, using the family of “f-divergences,” defined as

                                                                      eTx qs
                                     D f (qs ||q) =   ∑ (eTx q) f (   eTx q
                                                                             ),
                                                      x∈X


where f is any strictly convex, twice-differentiable function with f (1) = f 0 (1) = 0 and
f 00 (1) = 1. (The KL divergence is a member of this family, corresponding to f (u) = u ln u−
u + 1.) For any divergence in this family, we can define an information cost function


                                   I f (p, q; S) = ∑ (eTs pq)D f (qs ||q).               (13)
                                                  s∈S


(When I f is the KL divergence, this is just mutual information.) It is relatively easy to
observe that this family of information cost functions satisfies all five of the conditions
described above.23
    As another example of a class of cost functions that satisfy the conditions, we can
establish the following.

Corollary 1. Under the assumptions of Theorem 1, the posterior-separable cost function
(12) that defines the equivalent static rational inattention problem satisfies Conditions 1-5.
  23 This   follows from Lemma 3 in the next section.




                                                        30
This follows directly from the form of the cost function (12) and Lemma 3, described in
the next section.


4.2       Local Characterization of Flow Information Costs

Next we discuss the local (second-order) properties of any information cost function satis-
fying the conditions stated above. The condition requiring that Blackwell-dominant infor-
mation structures cost weakly more (Condition 3) is of particular importance. To under-
stand why, it is first useful to recall Blackwell’s theorem.
Theorem. (Blackwell (1953)) The information structure {px }x∈X , with signal alphabet S,
is more informative, in the Blackwell sense, than {p0x }x∈X , with signal alphabet S0 , if and
only if there exists a Markov transition matrix Π : S → S0 such that, for all s0 ∈ S0 and x ∈ X,


                                          p0x = Πpx .                                      (14)


   This Markov transition matrix is known as the “garbling” matrix. Another way of
interpreting Condition 3 is that garbled signals are (weakly) less costly than the original
signal.
   There are certain kinds of garbling matrices that don’t really garble the signals. These
garbling matrices have left inverses that are also Markov transition matrices. If we de-
fine an information structure {px }x∈X , with signal alphabet S, and another information
structure {p0x }x∈X , with signal alphabet S0 , using one of these left-invertible matrices,
via equation (14), then {px }x∈X is more informative than {p0x }x∈X , but {p0x }x∈X is also
more informative than {px }x∈X . These two information structures are called “Blackwell-
equivalent,” and it follows that the cost of these two information structures must be equal,
by Condition 3. The left-invertible Markov transition matrices associated with Blackwell-
equivalent information structures are called Markov congruent embeddings by Chentsov

                                              31
(1982). Chentsov (1982) studied tensors and divergences that are invariant to Markov con-
gruent embeddings (we will say “invariant” for brevity).
    An invariant divergence is a divergence that is invariant to these embeddings. Let Π
be a Markov congruent embedding from P(S) to P(S0 ). The KL divergence and the
f-divergences more generally are invariant, meaning that


                                       D f (Πp||Πr) = D f (p||r)


for all p, r ∈ P(S). There are also other, non-additively-separable invariant divergences.
Chentsov’s theorem (Chentsov (1982)) states that, for any invariant divergence DI ,

                                      ∂ 2 DI (p||r)
                                                    | p=r = c · gi j (r),                              (15)
                                        ∂ pi ∂ p j

where c > 0 is a positive constant and gi j (r) is the (i, j)-element of the Fisher information
matrix evaluated at r. Written in terms of the coordinate system used previously in the
paper,24
                                          g(r) = D(r)+ − ιι T .                                        (16)

Here, D+ (r) denotes the inverse of the |S| × |S| diagonal matrix whose diagonal elements
are the elements of r, and ι is a vector of ones of length |S|.
    However, the focus of this paper is not invariant divergences, but rather invariant in-
formation cost functions. By Condition 3, all information cost functions satisfying our
conditions are invariant to Markov congruent embeddings. It necessarily follows that, for
any Markov congruent embedding Π, that
  24 This corresponds to the standard definition of the Fisher information matrix, if derivatives of smooth
functions defined on the probability simplex are written in terms of the coordinates explained in footnote 7.




                                                     32
                               C({px }x∈X , q; S) = C({Πpx }x∈X , q; S0 ).

Using this invariance, and results from Chentsov (1982), we will describe the local structure
of all information cost functions satisfying our conditions.
    Chentsov establishes the following results:25

    i) Any continuous function that is invariant over the probability simplex is equal to a
       constant.

   ii) Any continuous, invariant 1-form tensor field over the probability simplex is equal to
       zero.

  iii) Any continuous, invariant quadratic form tensor field over the probability simplex is
       proportional to the Fisher information matrix.26

These results allow us to characterize the local properties of rational inattention cost func-
tions, via a Taylor expansion. Hold fixed the signal alphabet S, and consider an information
structure px (ε, ν) = r + ετx + νωx , where r ∈ P(S). Here, τx satisfies ι T τx = 0 for all x,
and. for all s ∈ S, eTs τx 6= 0 only if eTs r > 0. That is, τx is an element of the tangent space
of the probability simplex at r, and the same holds true for ωx . As a result, for values of
the perturbation parameters ε and ν sufficiently close to zero, px ∈ P(S) for all x ∈ X. In
other words, the parameters ε and ν index a two-parameter family of perturbations of an
uninformative information structure (corresponding to ε = ν = 0), in which the perturbed
  25 See  Lemma 11.1, Lemma 11.2, and Theorem 11.1 in Chentsov (1982). See also Proposition 3.19 of Ay
et al. (2014), who demonstrate how to extend the Chentsov results to infinite sets X and S.
   26 A 1-form tensor field on a probability simplex P is a function T : V × P → R, where V is the tangent

space of the simplex. Let Π : P → P 0 be a mapping from the simplex P to the simplex P 0 , let V 0 be the
tangent space of the simplex P 0 , and let dΠ : V → V 0 be the pushforward of the mapping Π. The tensor
field is invariant under Π if T (dΠv, Πp) = T (v, p) for all p ∈ P and v in the tangent space at p, and a
similar definition holds for quadratic form tensor fields. This means that if the quadratic form is extended to
a quadratic form over R|X| using the method defined in footnote 6, its matrix representation is proportional to
the matrix defined in (16).


                                                     33
information structures will generally be informative; the τx and ωx specify two directions
of perturbation. Each of the perturbed information structures has the property that px is
absolutely continuous with respect to r.
    By Condition 1, C({px (0, 0)}x∈X ; q; S) = 0. The first order term is


                     ∂
                        C({px (ε, ν)}x∈X , q; S)|ε=ν=0 = ∑ Cx ({r}x∈X , q; S) · τx ,
                     ∂ε                                  x∈X

where Cx denotes the derivative with respect to px . This derivative, Cx ({r}; q; S), forms a
continuous 1-form tensor field over the probability simplex P(S). By the invariance of
C(·), it also follows that Cx is invariant, and therefore, by Chentsov’s results, it is equal to
zero.
    We repeat the argument for the second derivative terms. Those terms can be written as


            ∂ ∂
                  C({px (ε, ν)}x∈X , q; S)|ε=ν=0 = ∑ ∑ ωxT0 ·Cxx0 ({r}x∈X , q; S) · τx .
            ∂ν ∂ε                                 x0 ∈X x∈X

By the invariance of C(·), the quadratic form Cxx0 (·) is invariant for all x, x0 ∈ X, and there-
fore is proportional to the Fisher information matrix for all x, x0 ∈ X. We can define a matrix
k(q) consisting of the constants of proportionality associated with each x, x0 ∈ X.27 That is,

                  ∂ ∂
                        C({p(·|·; ε, ν)}, q)|ε=ν=0 = ∑ ∑ (eTx k(q)ex0 )ωxT0 g(r)τx ,
                  ∂ν ∂ε                             x0 ∈X x∈X


where g(r) is the Fisher information matrix evaluated at the unconditional distribution of
signals r ∈ P(S). We note that the matrix k(q) can depend on the prior q, but cannot depend
on the unconditional distribution of signals, r; otherwise, invariance would not hold.
    In the case of the mutual-information cost function, the matrix k(q) is itself the inverse
  27 Our   re-use of the notation k(q) here is intentional.




                                                         34
Fisher information matrix,


                               k(q) = g+ (q) = D(q) − qqT .


In general, however, the matrix-valued function k(q) is not the inverse Fisher information
matrix, but rather an arbitrary matrix-valued function satisfying certain restrictions. Our
choice of notation hints at what we will prove in section 6: that this matrix-valued function
is just the information-cost matrix function described in section 2.
   We are now in position to discuss our approximation of the information cost function.
We use Taylor’s theorem to approximate the cost function and its gradient up to order ∆
(we use ∆ because in section 6, we will be looking at small time intervals). We consider
perturbations that, as above, preserve the support of the signal structure. As a result, this
theorem should be interpreted as applying to “frequent but not very informative” signals, as
opposed to “rare but informative” signals. We will discuss the latter type of signals shortly.

Theorem 2. Suppose that an information structure {px }x∈X , with signal alphabet S, is
described by the equation
                                              1          1
                                   px = r + ∆ 2 τx + o(∆ 2 ),

where, for any x ∈ X and any ∆ ≥ 0, eTs px 6= 0 ⇒ eTs r > 0. Let C(·) be an information
cost function that satisfies Conditions 1-4. Then, for ∆ sufficiently small, the cost of this
information structure can be written as

                                    1
                C({px }x∈X ; q; S) = ∆ ∑ ∑ (eTx k(q)ex0 )τxT0 g(r)τx + o(∆),
                                    2 x0 ∈X x∈X

where the matrix k(q) is positive semi-definite and symmetric, and satisfies k(q)ι = 0.
   If in addition the cost function satisfies Condition 5, Then there exists a constant mg > 0
such that the difference between k(q) and the inverse Fisher information matrix, g+ (q),

                                              35
multiplied by that constant, is positive semi-definite: k(q) − mg g+ (q)  0.

Proof. See appendix, section A.4.

   There are, in effect, two ways for a signal to be contain a small amount of information,
and different costs associated with these different types of signals. The results of Theorem 2
characterize, for any rational inattention cost function satisfying our conditions, the cost of
receiving frequently, but relatively uninformative, signals. As Corollary 2 below demon-
                                                                                       1
strates, the posteriors associated with these signals are close to the prior (order ∆ 2 ). We
will discuss the cost of receiving a rare but informative signal below. Previewing the results
of section 6, these two types of uninformative signals correspond, in the continuous-time
limit, to the diffusion and jump components of the belief process.
   The theorem substantially restricts the local structure of the cost of commonly occur-
ring, but not particularly informative, signals, relative to the most general possible alter-
natives (which would not satisfy our conditions). Potential information structures {px }x∈X
can be represented as vectors of dimension N = (|S| − 1) × |X|. Under the assumptions of
Condition 1, convexity, and Condition 4 (but not the Blackwell ordering condition, Condi-
tion 3), the cost function must locally resemble an inner product with respect to a positive
semi-definite, N × N matrix. If we impose Condition 3 as well, the results of Theorem 2
show that we can restrict this matrix to the k(q) matrix, an |X| × |X| matrix. If the DM
were only allowed binary signals (|S| = 2), this restriction would be trivial. When the DM
is allowed to contemplate more general information structures, the restriction is non-trivial.
   Several authors (Caplin and Dean (2015); Caplin et al. (2017); Kamenica and Gentzkow
(2011)) have observed that it is easier to study rational inattention problems by considering
the space of posteriors, conditional on receiving each signal, rather than space of signals.
We can redefine the cost function using the posteriors and unconditional signal proba-
bilities, rather than the prior and the conditional probabilities of signals. The results are


                                              36
described in the corollary below.

Corollary 2. Under the assumptions of Theorem 2, the posterior beliefs can be written, for
any s ∈ S such that eTs r > 0, as

                                              1      eTs τn,x       1
                              qs,n,x = qx + ∆ 2 qx            + o(∆ 2 ).
                                                       eTs r

Define the matrix
                                    k̄(q) = D+ (q)k(q)D+ (q),

where D+ (·) is the pseudo-inverse of the diagonal matrix. The cost function can be written
as
                                    1
             C({px }x∈X , q; S) =        ∑T (eTs r)(qs − q)T k̄(q)(qs − q) + o(∆).
                                    2 s∈S:e
                                          s r>0

Proof. See the appendix, section A.5.

     The theorem and corollary above describe the costs of receiving frequent, but relatively
uninformative signals. We next discuss the cost of receiving rare, but informative signals.
These types of signals, in the limit that we discuss in section 6, will lead to jumps in beliefs.
After we describe the cost of these signals, we will introduce a condition that ensures that
jumps in beliefs are not part of an optimal evidence accumulation strategy.

Corollary 3. Under the assumptions of Theorem 2, define the signal structure


                                          p̂ = p̄∆ + ∆ω,


where p∆ is a signal structure of the type described in Theorem 2, with lim∆→0+ p̄∆ = rι T ,
and ∑s∈S ωex = 0 for all x ∈ X, with eTs ωex ≥ 0 for all s ∈ S such that eTs p̄∆ = 0.




                                                  37
   The cost of this information structure can be written in the form

                                 1
                   C(pn ; q; S) = ∆n ∑ (eTs r)(qs − q)T k̄(q)(qs − q)
                                 2 s∈S:eT r>0
                                               s


                              +      ∑T     (eTs φ )D∗ (qs ||q) + o(∆),
                                  s∈S:es r=0


where the divergence D∗ is finite and twice-differentiable in its first argument for q0 suffi-
ciently close to q, with
                                   ∂ 2 D∗ (r||q)
                                                 |r=q = k̄(q).                           (17)
                                      ∂ ri ∂ r j

Proof. See the appendix, section A.6.

   The divergence D∗ represents the cost of acquiring an infrequent, but potentially in-
formative, signal. Naturally, if the signal is in fact not very informative, this cost must be
closely related to the costs of other uninformative signals, which gives rise to the condition
on the Hessian of the divergence. Note that the corollary requires that the cost is additive
with respect to the other signals being received (at least up to order ∆). The result follows
from the directional differentiability of the cost function with respect to signals that occur
with zero probability, the continuity of that directional derivative, and invariance.
   We now introduce the last condition we will impose on our cost functions. This condi-
tion, which is expressed in terms of the k̄(q) matrix-valued function and the divergence D∗ ,
is a sufficient condition to ensure that the discrete-time models that we study in section 6
converge to the model with continuous sample paths (no jumps) described in section 2. The
condition reflects an assumption that learning gradually over time, receiving frequent but
never very informative signals, is less costly than receiving rare signals that lead to large
changes in beliefs when they occur.

Condition 6. The matrix-valued function k̄(q) and divergence D∗ associated with the cost


                                                   38
function C(p, q; S) satisfy, for all q, q0 ∈ P(X) with q0  q,

                                         ˆ 1
                      ∗   0    1 0     T
                    D (q ||q) ≥ (q − q) (    k̄(sq0 + (1 − s)q)ds)(q0 − q).
                               2          0


    We will say that a cost function satisfying this condition exhibits a preference for grad-
ual learning. We will call this preference “strict” if the inequality is strict for all q0 6= q. If
the k̄(q) function is the Hessian of some generalized entropy function (see equation (11)),
this condition is equivalent to requiring that


                                        D∗ (q0 ||q) ≥ DH (q0 ||q),                                      (18)


where DH is the associated Bregman divergence. In the particular case of mutual infor-
mation, both D∗ and DH are the KL divergence, and the condition is (weakly) satisfied. It
is also easy to construct cases in which it is strictly satisfied, as the example below illus-
trates.28
    Consider the family of information cost functions built from f-divergences defined in
equation (13) above. All of the cost functions in this family resemble mutual information,
to second order, in the sense defined by Corollary 2. Assuming that the posteriors induced
by the information structure p and prior q, {qs }s∈S , are close to the prior q, and that the
  28 Itis the assumption that the flow cost function in our dynamic evidence accumulation problem satisfies
Condition 6 that allows us to avoid considering the possibility of Poisson jumps in the posterior belief state
of the kind assumed by Che and Mierendorff (2016) and Zhong (2017) in the continuous-time model pre-
sented in section 2. Zhong (2017) presents conditions under which information accumulation with Poisson
jumps can be optimal, but considers only posterior-separable flow cost functions of the form (12) based on
a Bregman divergence, so that (18) holds with equality rather than an inequality. In this special case, in
our framework jumps can also be among the optimal policies, but an equally good outcome can always be
achieved by an information sampling strategy that involves no jumps, as we establish in section 6. When
the inequality is instead strict, jumps cannot be optimal in the continuous-time limit of the kind of dynamic
evidence accumulation problem considered in this paper.




                                                     39
prior q is on the interior of the simplex,

                                1
              I f (p, q; S) ≈     ∑ (eTs pq)(qs − q)T D(q)+g+(q)D(q)+(qs − q).
                                2 s∈S
                                                                                          (19)


In other words, in a sense that we will show formally in section 6, all of these flow cost
functions will induce the same information-cost matrix function in the continuous-time
problem.
   However, all such functions do not induce the same divergence D∗ . (Note that for this
family, D∗ = D f .) Nonetheless, if D f ≥ DKL (which holds strictly, for example, in the
case of the χ 2 -divergence), these cost functions will generate the same solution in the
continuous-time problem: the solution to a static rational-inattention problem with the
mutual-information cost function. Regardless of whether the f-divergence used to con-
struct the flow cost function is the KL divergence or not, the KL divergence will appear in
the solution to the continuous-time problem. In fact, this result applies to the larger class
of invariant divergences, which includes the f-divergences, and follows from Chentsov’s
theorem (equation (15)).
   Of course, we argued in section 2 that the inverse Fisher information matrix, when used
as the information-cost matrix function, lacks certain desirable properties related to the dis-
tance between different states of the world. In the next section, we will introduce a new
family of cost functions, all of which induce information cost matrix functions that do cap-
ture these notions. Moreover, these information-cost matrix functions satisfy equation (11),
and therefore Theorem 1 applies. We will solve examples of the static model implied by
Theorem 1 and compare it to the same static model with mutual information, illustrating
why notions of the distance between states matters in economic applications.




                                               40
5     Neighborhood-Based Cost Functions

Suppose that the state space X can be written as the union of a finite collection of “neigh-
borhoods” {Xi }, and suppose furthermore that the state space is connected, in the sense that
any two states can be connected by a sequence of overlapping neighborhoods. That is, for
any two states x, x0 ∈ X, there exists a sequence of states {x0 , . . . , xn } with x0 = x, xn = x0 ,
and the property that for any 1 ≤ m ≤ n, states xm and xm−1 belong to a common neigh-
borhood. Define the selection matrices Ei as the |Xi | × |X| matrices that select each of the
elements of Xi from a vector of length |X|.
     For any prior q ∈ P(X), let I (q) be the (necessarily non-empty) set of neighborhoods
Xi such that some state belonging to Xi has positive probability under the prior, and let
q̄i ≡ ∑x∈Xi eTx q be the prior probability that some state belonging to neighborhood Xi occurs.
Let qi ∈ P(Xi ) be the conditional probability distribution over states in neighborhood Xi ,
given the prior q and conditional on the state being in neighborhood Xi . That is, for all
x ∈ Xi ,
                                                     1
                                           qi ≡         Ei q.
                                                    q̄i

     Similarly, let qs ∈ P(X) be the posterior after receiving signal s ∈ S, and let qi,s ∈
P(Xi ) be the posterior over states in neighborhood Xi , conditional on receiving signal s
and having the state be part of neighborhood Xi . That is, for all x ∈ Xi ,

                                                    1
                                         qi,s ≡          Ei qs ,
                                                   q̄i,s

with q̄i,s ≡ ∑x∈Xi eTx qs . We adopt the convention that qi,s = qi if q̄i,s = 0. Finally, let p̄i ∈
P(S) be the conditional distribution of signals under the information structure p and prior
q:
                                               ∑x∈Xi pex eTx q
                                       p̄i =                   .
                                                    q̄i

                                                  41
   We will say that a cost function has a “neighborhood structure” if it can be written in
the form
                             CN (p, q; S) =      ∑       q̄i   ∑ eTs p̄i Di(qi,s||qi),             (20)
                                               i∈I (q)         s∈S

where for each i ∈ I (q), Di (·||·) is a divergence (not necessarily the same for all i) defined
over probability distributions in P(Xi ) that is a twice-differentiable and strongly convex
in its first argument.29 Mutual information is an example of a flow cost function in this
family, corresponding to the case in which there is only a single neighborhood, consisting
of the entire state space X, and the divergence is the KL divergence, so that


                    C(p, q; S) =    ∑ (eTs pq)DKL (qs||q)            = I Shannon ({px }, q; S).
                                    s∈S


The information cost functions based on f-divergences, defined by (13), are also single-
neighborhood examples of neighborhood-based cost functions.
   The following lemma shows that all cost functions with a neighborhood structure satisfy
the conditions defined in section 4.1.

Lemma 3. All cost functions with a neighborhood structure (20) satisfy Conditions 1-4
stated in section 4. If the neighborhood structure includes a neighborhood containing all
of the states x ∈ X, the cost function also satisfies Condition 5.

Proof. See the appendix, section A.7.

An implication of this lemma is that any posterior-separable cost function (12) based on a
strongly convex generalized entropy function H satisfies Conditions 1-5. Below, we give a
sufficient condition for Condition 6 to be satisfied as well.
   We will study a particular family of cost functions with a neighborhood structure, the
“neighborhood-based cost functions.” This family is defined by the additional require-
  29 The   f-divergences defined previously satisfy these conditions (Amari and Nagaoka (2007)).

                                                     42
ments that (i) the divergences Di be invariant, and (ii) each of the Di is bounded below by
some positive multiple of DKL , the Kullback-Leibler divergence.30 As an example of the
possibility of satisfying these latter requirements, the Di may be α-divergences (or Rényi
divergences, van Erven and Harremoës (2014))

                                                     1           pi (x)α
                                Dα (pi ||qi ) ≡         log ∑             ,
                                                   α −1    x∈Xi qi (x)
                                                                      α−1



of order α ≥ 1.31
    This family can have complex neighborhood structures, for which the requirement that
each of the individual divergences Di be invariant is a less restrictive requirement. The idea
of this class of cost functions is that information structures are costly only to the extent that
they result in different signal distributions for states that are “similar” to one another, in
the sense of belonging to the same neighborhood. If there is only one neighborhood that
includes all of the states (the mutual-information case), all states are equally difficult to
distinguish from one another. Allowing for more complex neighborhood structures allows
us to assume instead that it is much more difficult to tell some pairs of states apart than
others. Note that under the general formalism (20), this is true not only because some pairs
of states share a neighborhood while others do not — and more generally, that the length
of the chain of neighborhoods required to link two states differs for different pairs of states
— but also because the divergences Di can be different for different neighborhoods.
    As discussed above, the fact that Di is an invariant divergence implies that its Hessian
  30 Stipulation  (ii) is added in order to ensure that Condition 6 is satisfied. For this it suffices that Di be
bounded below by a Bregman divergence for each i. But as explained in section 4.2, any invariant divergence
is locally equivalent (for p near q) to a positive multiple of DKL . Hence in order for Di to be bounded below
by a Bregman divergence, it must be bounded below by a positive multiple of DKL .
   31 The definition is here stated only for the case α 6= 1. When α = 1, the α-divergence is simply the KL

divergence, and Condition 6 is weakly satisfied. If α > 1, the α-divergence satisfies Dα (p||q) > DKL (p||q)
for all p 6= q, so that the strong form of Condition 6 is satisfied, implying a strict preference for gradual
learning.




                                                      43
matrix is proportional to the Fisher information matrix. As a result, the approximation
described in equation (19) applies, but only within each neighborhood. That is,

                                  1
               CN (p, q; S) ≈         ∑ ciq̄i ∑ (eTs pq)(qi,s − qi)T g(qi)(qi,s − qi),
                                  2 i∈I
                                                                                                       (21)
                                        (q)   s∈S


where the ci > 0 are positive constants. This implies the following structure for the information-
cost matrix:

Lemma 4. The information-cost matrix function kN (q) associated with the neighborhood-
based cost function is
                                   kN (q) =     ∑       ci q̄i EiT g+ (qi )Ei ,
                                              i∈I (q)

where g+ is the inverse Fisher information matrix and the constant ci > 0 for each i.

Proof. See the appendix, section A.8.

    We can use the information-cost matrix function in our continuous-time problem (the
problem defined in section 2).32 It satisfies the equation necessary for the results of Theo-
rem 1 to apply (equation (11)). As a result, there is a generalized entropy function, HN (q),
associated Bregman divergence, DN (p||q), and posterior-separable static information-cost
function, CNstatic (p, q; S), that can be used to define the static rational-inattention problem
the choice probabilities of which coincide with the solution to the dynamic model. The
following lemma describes these functions:

Lemma 5. Let H Shannon (q) be Shannon’s entropy (8). Then the generalized entropy func-
tion HN (q) associated with the neighborhood-based information-cost matrix function kN (q)
  32 Our  derivation of the continuous-time model from the discrete-time model applies only to cost functions
satisfying Conditions 1-6. We have established these conditions only for neighborhood structures that include
a neighborhood containing all states. However, the constant ci associated with this neighborhood can be
arbitrarily small, and in what follows we will ignore this requirement.



                                                    44
is given by
                             HN (q) = −         ∑         ci q̄i H Shannon (qi ),
                                              i∈I (q)

and the associated Bregman divergence is


                           DN (qs ||q) =       ∑          ci q̄i,s DKL (qi,s ||qi ).
                                             i∈I (q)


The posterior-separable static information cost function derived from the neighborhood-
based generalized entropy can then be written as


                      CNstatic (p, q; S) =     ∑         ci q̄i   ∑ p̄i,s DKL (qi,s||qi)
                                             i∈I (q)              s∈S

                                         = ∑ (eTs pq)DN (qs ||q),
                                             s∈S


or alternatively as


                  CNstatic (p, q; S) =     ∑       ci   ∑ (eTx q) DKL (pex ||pEiT qi).
                                         i∈I (q)        x∈Xi


Proof. See the appendix, section A.9.

   The fact that k̄N (q) is the Hessian of a convex function HN (q) means that we can apply
the sufficient condition (18) in order to verify that Condition 6 is satisfied by any cost
function in this family. For a flow cost function of the form (20), the marginal cost of
increasing the probability of a jump to an arbitrary posterior q0 is given by the divergence


                              D∗N (q0 ||q) =            ∑         q̄0i Di (q0i ||qi ).
                                                    i∈I (q)




                                                        45
Under our assumption that Di is bounded below by ci DKL for each i, it follows that


                      D∗N (q0 ||q) ≥     ∑       ci q̄0i DKL (q0i ||qi ) = DN (q0 ||q),
                                       i∈I (q)


and condition (18) is verified. Thus under the assumptions stated above, any neighborhood-
based cost function satisfies all of Conditions 1-6 for a flow information-cost function. If
for each i, Di is a positive multiple of an α-divergence with αi > 1, then (18) holds with
a strict inequality for any q0 6= q. In this case, the cost function satisfies the strong form of
Condition 6, so that there is a strict preference for gradual learning.
    Lemma 5 allows us to write the static rational inattention problem (Theorem 1) directly
in terms of an optimization over choice probabilities {πx } so as to maximize


                         ∑ eTx q0 ∑ eTa πx ux,a − θC({πx }x∈X , q0; A).                      (22)
                         x∈X       a∈A


As discussed previously, in the special case in which there is only a single neighborhood,
this is the standard rational inattention problem. The relevance of alternative assumptions
about the neighborhood structure is illustrated by the following result.

Lemma 6. Consider a rational inattention problem (22) with a neighborhood-based information-
cost function, and let x, x0 be two states with the property that (i) ua,x = ua,x0 for all actions
a ∈ A, and (ii) the set of neighborhoods {Xi } such that x ∈ Xi is the same as the set such
that x0 ∈ Xi . Then under the optimal policy, πx∗ = πx∗0 .

Proof. The result follows directly from the problem in (22) and the alternative expression
for the cost function in Lemma 5.




                                                     46
5.1    An Application: Psychometric Functions

The significance of Lemma 6 can be seen if we consider the predictions of rational inatten-
tion for a standard form of perceptual discrimination experiment. Suppose that the different
states X = {1, 2, . . . , N} represent different stimuli that may be presented to the subject, and
that the subject is asked to classify the stimulus that is presented as one of two types (L or
R); R is the correct answer if and only if x > (N + 1)/2. For example, the stimuli might
be visual images with different orientations relative to the vertical, with increasing values
of x corresponding to increasingly clockwise orientations; the subject is asked whether the
image is tilted clockwise or counter-clockwise relative to the vertical. In such experiments,
the subject’s goal is often simply to give as many correct responses as possible; hence we
suppose that ux,a = 1 if a = R and x > (N + 1)/2 or if a = L and x < (N + 1)/2, while
ux,a = 0 in all other cases. We shall assume that each of the possible stimuli is presented
with equal prior probability, and hence (assuming that N is odd) that both responses have
an equal ex ante probability of being correct.
   The standard theory of rational inattention, in which the static information cost is mu-
tual information, corresponds to a special case of a neighborhood-based cost function, in
which all states belong to the unique neighborhood. Hence condition (ii) of Lemma 6 holds
for any pair of states. Lemma 6 thus implies that if any two states result in the same payoff
regardless of the action chosen, the frequency with which different actions will be chosen
under an optimal policy must be the same in the two states.
   In the problem just posed, this implies that the probability of response R must be the
same for all states x < (N + 1)/2, and also the same (but higher) for all states x > (N +
1)/2. Changing the severity of the information constraint changes the degree to which
the probability of responding R is higher when x > (N + 1)/2, but it cannot change the
prediction that the response probabilities should depend only on whether x is greater or less



                                               47
than (N + 1)/2. This is illustrated in Figure 1, which plots the optimal response frequencies
as a function of x, for alternative values of the cost parameter θ , in a numerical example in
which C is given by mutual information and N = 20.


                   1
                  0.9
                  0.8
                  0.7
                  0.6
        Prob(R)




                  0.5
                  0.4
                  0.3
                                                                       3=.5
                  0.2                                                  3=1
                  0.1                                                  3=2
                                                                       3=4
                   0
                            5               10               15               20
                                              x

Figure 1: Predicted response probabilities with a mutual-information cost function, for
alternative values of the cost parameter θ .


   Alternatively, consider a posterior-separable neighborhood-based cost function in which
the neighborhoods are given by
                                       Xi = {xi , xi+1 }                                  (23)

for i = 1, 2, . . . , N −1. Thus two states belong to a common neighborhood if and only if they
are either identical or one comes immediately after the other in the sequence. This captures
the idea that the available measurement technologies all respond similarly in states that
are “similar,” in the sense of being at nearby positions in the sequence, so that repeated
measurements are necessary to reliably distinguish between two states if and only if they

                                              48
are near each other in the sequence. Suppose further that ci = 1 for all i, implying that it is
equally difficult to distinguish two neighboring states at all points in the sequence.33 These
assumptions suffice to completely determine a static information cost function (Lemma 5).
    With this alternative neighborhood structure, Lemma 6 no longer requires that the re-
sponse frequencies be identical for any two states. Moreover, because the cost function
penalizes large differences in signal frequencies (and hence in response frequencies) in the
case of neighboring states, in this case an optimal policy involves a gradual increase in the
probability of response R as x increases, even though the payoffs associated with the dif-
ferent actions jump abruptly at a particular value of x. This is illustrated in Figure 2, which
again shows the optimal response frequencies as a function of x, for alternative values of θ ,
in the case of the alternative neighborhood structure (23). The sigmoid functions predicted
by rational inattention with this cost function — with the property that response frequen-
cies differ only modestly from 50 percent when the stimuli are near the threshold of being
correctly classified one way or the other, and yet approach zero or one in the case of stimuli
that are sufficiently extreme — are characteristic of measured “psychometric functions” in
perceptual experiments of this kind.34
  33 If ci is the same for all i, we can without loss of generality set it equal to one, as the multiplier θ can still
be used to scale the overall magnitude of information costs.
   34 For the general concept of a psychometric function, see, for example, Gabbiani and Cox (2010), chap.

25, especially Figures 25.1 and 25.2, and discussion on p. 360; or Gold and Heekeren (2014), p. 356. For
an example of an empirical psychometric function for the kind of task discussed in the text (classification
of a field of moving dots as to which of two opposing directions is the dominant direction of motion), see
Shadlen et al. (2007), Figure 10.1A. Note not only that the curve is monotonically increasing, with many data
points corresponding to different response probabilities between zero and one, but also that in this experiment
the subject’s reward function is clearly of the kind assumed in the text: only two possible reward levels (for
correct vs. incorrect responses), with a discontinuous change in the reward where the sign of the “motion
strength” changes from negative to positive.




                                                         49
                   1
                  0.9
                  0.8
                  0.7
                  0.6
        Prob(R)




                  0.5
                  0.4
                  0.3
                                                                  3=2.5
                  0.2                                             3=10
                  0.1                                             3=25
                                                                  3=50
                   0
                           5              10              15              20
                                            x

Figure 2: Predicted response probabilities with a neighborhood-based cost function, in
which each neighborhood consists only of two adjacent states.


   The continuity of choice probabilities across points at which there are discrete changes
in payoffs is also an important issue for the global games literature (Morris and Yang
(2016)). However, this literature typically assumes a continuum of states, and many of
the perceptual experiments that we have just referred to are naturally modeled with a con-
tinuum of states as well. In the next sub-section, we consider a continuous-state limit of
the example just analyzed, that can be used as a model of imprecise perception in such
examples.


5.2   The Fisher-Information Cost Function

In this subsection, we continue our discussion of the neighborhood-based cost function
proposed in the previous subsection, and consider the limit as the number of states of the



                                           50
world, |X|, becomes infinite. This example is motivated by the work of Yang (2015) and
Morris and Yang (2016), who study global games (e.g. Morris and Shin (2001)) with
endogenous information acquisition. However, we derive our limiting result for arbitrary
action spaces and utility functions.
   The result corresponds to a static rational inattention problem with a continuum of
states, in which the information cost function is given by the average value of the Fisher
information, a measure of the precision with which an information structure allows nearby
states to be distinguished from each other (Cover and Thomas (2012)). Like Sims’ proposal
of a cost function proportional to Shannon’s mutual information, the Fisher-information
cost function is a single-parameter cost function, and it can also be applied in almost any
context, as long as the state space is continuous. But unlike Shannon’s mutual informa-
tion, our measure of the informativeness of an information structure based on the Fisher
information depends on the topological structure of the state space.
   This is of considerable significance for the literature on global games. In the well-
known analysis of Morris and Shin (2001), with exogenous private information, there is
a unique equilibrium despite the incentives for coordination across DMs (subject to some
caveats and details that are not relevant for our discussion). Instead Yang (2015) demon-
strates that allowing for endogenous information acquisition, with mutual information as
the information cost, restores a multiplicity of equilibria.
   The key to Yang’s result is that DMs can tailor the signals they receive to sharply dis-
criminate between nearby states of the world, as discussed in our previous example. As a
result, they can all coordinate their decision (say, to invest or not) on a particular threshold,
and there are many such thresholds that can represent equilibria if coordinated upon. But
this result depends on the fact that the mutual-information cost function does not make
it costly to have abrupt changes in signal probabilities as the state of the world changes
continuously. Morris and Yang (2016) develop the complementary result, showing that

                                               51
even in the case of an endogenous information structure, if signal probabilities must vary
continuously with the state, there is again a unique equilibrium.
   Here we show that a neighborhood-based cost function can provide a justification for
the kind of continuity condition that the result of Morris and Yang (2016) requires. How-
ever, our results in the previous subsection cannot be applied directly to the model of Morris
and Yang (2016), because the global games model in that paper assumes a continuum of
states, whereas our analysis above supposes that |X| is finite. To bridge this gap, we study
an example of the static model implied by Theorem 1 with a particular neighborhood-based
cost function, and consider the limit as the number of states becomes unboundedly large.
We show that the example model converges to a static rational inattention model with a
particular cost function, similar in certain respects to the leading example of Morris and
Yang (2016), that satisfies the continuous choice condition established by those authors.
   For each of a sequence of values for the finite integer N, we assume a neighborhood
structure of the kind discussed in the previous subsection for a model with N + 1 states.
The set of states is ordered, X N = {0, 1, . . . , N}, and each pair of adjacent states forms a
neighborhood, X j = {i, i+1}, for all j ∈ {0, 1, . . . , N −1}. We will also assume that there is
an N + 1st neighborhood containing all of the states. Note that N indexes both the number
of states and the number of neighborhoods, which is always equal to the number of states.
We consider the limit as N → ∞.
   To study this limit, we need to define how the initial beliefs, qN , and the magnitude of
the information costs vary with N. For the initial beliefs, we shall assume that there is a
differentiable probability density function f : [0, 1] → R+ , with full support on [0, 1], with
a derivative that is Lipschitz continuous. Using this function, we define, for any i ∈ X N ,

                                                 ˆ    i+1
                                                      N+1
                                    eTi qN   =              f (x)dx.
                                                      i
                                                     N+1




                                                     52
That is, for each value of N, the prior qN is assumed to be a discrete approximation to the
Lipschitz-continuous p.d.f. f (x), which becomes increasingly accurate as N → ∞.
    For our neighborhood structures, we assume that that the constants associated with the
cost of each neighborhood, c j , are equal to N 2 for all j < N, and N −1 for j = N. In this
particular example, the scaling ensures that the DM is neither able to determine the state
with certainty, nor prevented from gathering any useful information, even as N is made
arbitrarily large; moreover, the scaling ensures that the neighborhood containing all states
plays no role in the limiting behavior, so that in the limit all information costs are local. We
also scale the entire cost function by a constant, θ̄ > 0.
    We also need to define the set of actions, and the utility from those actions. We will as-
sume the set of actions, A, remains fixed as N grows, and define the utility from a particular
action, in a particular state, as

                                                   ´ N+1
                                                     i+1
                                                       i    f (x)ua (x)dx
                                      eTi ua,N =      N+1
                                                                            .
                                                            eTi qN

Here, the utility ua : [0, 1] → R is a bounded measurable function for each action a ∈ A.35
In other words, as N grows large, the prior converges to f (x) and the utilities converge to
the functions ua (x).
    Under these assumptions, the static model of Theorem 1 can be written as


  VN (qN ; θ̄ ) =              max             ∑ πN (a)(uTa,N · qa,N ) − θ̄ ∑ πN (a)DN (qa,N ||qN ),
                    πN ∈P(A),{qa,N ∈P(X N )}a∈A a∈A                             a∈A
                                                                                                       (24)
  35 Note  that we do not require the payoff resulting from a action to be a continuous function of x at all
points, though it will be continuous almost everywhere. This allows for the possibility that a DM’s payoffs
change discontinuously when the state x crosses some threshold, as in the kind of equilibria discussed by
Yang (2015).




                                                       53
subject to the constraint that

                                            ∑ πN (a)qa,N = qN .
                                            a∈A

Here DN denotes the divergence associated with the neighborhood-based cost function in-
troduced above, specialized to the particular neighborhood structure of this section:


        DN (qa,N ||qN ) = N 2           ∑      q̄ j,a,N DKL (q j,a,N ||q j,N ) + N −1 DKL (qa,N ||qN ).
                                        N
                                    j∈X \{N}


   The following theorem shows that the solution to this problem, both in terms of the
value function and the optimal policies, converges to the solution of a static rational inat-
tention problem with a continuous state space.

Theorem 3. Consider the sequence of finite-state-space static rational inattention prob-
lems (24), with progressively larger state spaces indexed by the natural numbers N. Then
there exists a sub-sequence of integers n ∈ N for which the solutions to the sub-sequence of
problems converge, in the sense that

   i) limn→∞ Vn (qn ; θ̄ ) = V (q; θ̄ );

  ii) limn→∞ πn∗ = π ∗ ; and

                                                            bxnc              ´x
  iii) for all a ∈ A and all x ∈ [0, 1], limn→∞ ∑i=0 eTi q∗a,n =                  0   fa∗ (y)dy.

Moreover, the limiting value function V (q; θ̄ ) is the value function for the following continuous-
state-space static rational inattention problem:

                                                                            ˆ     1
               V ( f ; θ̄ ) =               sup                    ∑ π(a)             ua (x) fa (x)dx
                                π∈P(A),{ fa ∈PLipG ([0,1])}a∈A a∈A            0
                                             ˆ 1 0                      ˆ
                                θ̄               ( fa (x))2       θ̄          1
                                                                                  ( f 0 (x))2
                          −       ∑ {π(a)                   dx} +                             dx,
                                4 a∈A          0     fa (x)       4       0          f (x)



                                                       54
subject to the constraint that, for all x ∈ [0, 1],


                                                  ∑ π(a) fa(x) = f (x),                                              (25)
                                                 a∈A


and where PLipG ([0, 1]) denotes the set of differentiable probability density functions with
full support on [0, 1], whose derivatives are Lipschitz-continuous. Furthermore, the limiting
action probabilities π ∗ (a) and posteriors fa∗ are the optimal policies for the continuous-
state-space problem.

Proof. See the appendix, section A.11.

     The static rational inattention problem for the limiting case of a continuous state space
can be given an alternative, equivalent formulation, in which the objects of choice are the
conditional probabilities of taking different actions in the different possible states, rather
than the posteriors associated with different actions.

Lemma 7. Consider the alternative continuous-state-space static rational inattention prob-
lem:

                                        ˆ    1                                    ˆ   1
                                                                          θ̄
        V̄ ( f ; θ̄ ) =      sup                 f (x) ∑ pa (x)ua (x)dx −                 f (x) I Fisher (x; p)dx,
                          p∈PLipG (A)   0             a∈A                 4       0


where PLipG (A) is the set of mappings p : [0, 1] → P(A) such that for each action a, the
function pa (x)36 is a differentiable function of x with a Lipschitz-continuous derivative, and
for any information structure p ∈ PLipG (A), the Fisher information at state x ∈ X is defined
as
                                                                   (p0a (x))2
                                            I Fisher (x; p) ≡   ∑             .
                                                                a∈A pa (x)
  36 Here for any x ∈ [0, 1], we use the notation pa (x) to indicate the probability of action a implied by the
probability distribution p(x) ∈ P(A).



                                                           55
This problem is equivalent to the one defined in Theorem 3, in the sense that the information
structure p∗ that solves this problem defines action probabilities and posteriors

                                     ˆ
                            ∗
                                           1
                                                                              f (x)p∗a (x)
                          π (a) =              f (x)p∗a (x),      fa∗ (x) =                             (26)
                                       0                                         π ∗ (a)

that solve the problem in Theorem 3, and conversely, the action probabilities and posteriors
{π ∗ (a), fa∗ } that solve the problem stated in the theorem define state-contingent action
probabilities
                                                           π ∗ (a) fa∗ (x)
                                               p∗a (x) =                                                (27)
                                                                f (x)

that solve the problem stated here. Moreover, the maximum achievable value is the same
for both problems: V̄ ( f ; θ̄ ) = V ( f ; θ̄ ).

Proof. See the appendix, section A.12.

    Theorem 3 shows that the limit of our neighborhoods problem converges to a static
rational inattention problem with a particular cost function. That cost function is just the
expected value of the Fisher information I Fisher (x; p), defined locally for each element of
the continuum of possible states x, with the expectation taken with respect to the prior over
possible states.37 This cost function, unlike mutual information, depends only on the degree
to which the information structure allows states to be distinguished from ones extremely
close to them (under the topology of the real line); and unlike the rational inattention prob-
lem based on mutual information, this static mutual information problem will generate the
smoothness of responses across discrete changes in payoffs shown in Figure 2.
    For these reasons, we believe that the Fisher-information cost function is likely to be
more appropriate than mutual information in a wide range of settings. It should also be
noted that, as in the case of Sims’ theory of rational inattention, the Fisher-information cost
  37 This   aggregate Fisher information has also proven useful in a variety of physics applications (Frieden
(2004)).

                                                           56
function has only a single degree of freedom. We thus obtain a rational inattention theory
for problems with a continuous space that yields highly specific predictions, albeit different
ones from Sims’ theory.
     We can apply this result to the problem considered in Morris and Yang (2016). Those
authors study a global game with two possible actions, “invest” and “not-invest,” with equi-
librium behavior characterized by a probability s(x) of investing when the state is x. Their
equilibrium uniqueness result depends on an assumption of continuous choice, meaning
that for all θ̄ > 0 and all parameterizations of the relevant utility function, s(x) is abso-
lutely continuous. Our Theorem 3 provides an example of more primitive assumptions that
would guarantee continuous choice in this sense.
     We believe that these results show the usefulness of our continuous-time model of evi-
dence accumulation as a micro-foundation for interesting classes of static rational-inattention
problems, with properties that are relevant for economic applications. It remains for us to
explain the justification for our proposed formulation of the continuous-time model of evi-
dence accumulation itself.



6     Derivation of the Continuous-Time Model

We now show how the continuous-time model proposed in section 2 can be obtained as
the limit of a discrete-time model of sequential evidence accumulation, with a sequence
of endogenous signals as in dynamic rational inattention models like that of Steiner et al.
(2017), and an information cost function for each of the individual signals that satisfies
the properties proposed for flow cost functions in section 4. In particular, we will justify
the link proposed above between a second-order approximation to the information cost
function for an individual signal and the information-cost matrix function defined in section
2.


                                             57
    We study a dynamic problem in which the DM has repeated opportunities to gather
information before making a decision. The state of the world, x ∈ X, remains constant over
time. At each time t, the DM can either stop and take an action a ∈ A, or continue and
receive a signal drawn from the information structure {pt,x ∈ P(S)}x∈X , for some signal
alphabet S. We assume that the number of potential actions is weakly less than the number
of states, |A| ≤ |X|.
    We also assume that the signal alphabet S is finite and fixed over time, with |S| ≥
2|X| + 1. However, the information structure {pt,x }x∈X is a choice variable that can be
state- and time-dependent. Fixing the signal alphabet S has no economic meaning, because
the information content of receiving a particular signal s ∈ S can change between periods.
The assumption allows us to assume a finite information structure and invoke the results
from section 4.38 As a technical device, we assume that S contains one signal, s̄, that is
required to be uninformative. This assumption is a technical device to ensure that the DM
can choose to mix any arbitrary signal structure with an uninformative one, even if she has
already used up her “useful” signals.
    The DM’s prior beliefs at time t, before receiving the signal, are denoted qt . Each time
period has a length ∆. Let τ denote the time at which the DM stops and makes a decision,
with τ = 0 corresponding to making a decision without acquiring any information. At this
time, the DM receives utility u(x, a) − κτ if she takes action a at time τ and the true state of
the world is x. As in the previous sections, let û(qτ ) be the utility (not including the penalty
for delay) associated with taking an optimal action under beliefs qτ . The parameter κ
governs the size of the penalty the DM faces from delaying his decision. The reason the DM
does not make a decision immediately is that she is able to gather information, and make a
more-informed decision. The setup thus far is essentially identical to the continuous-time
  38 Asmentioned previously, the work of Ay et al. (2014) discusses how to extend the Chentsov (1982)
theorems to infinite-dimensional structures. We conjecture that their results would allow us to extend our
theorems to infinite signal spaces, but do not attempt such an extension here.


                                                   58
model described previously.
   The DM can choose an information structure that depends on the current time and past
history of the signals received. As we will see, the problem has a Markov structure, and
the current time’s “prior,” qt , summarizes all of the relevant information that the DM needs
to design the information structure. The DM is constrained to satisfy

                                 −1
                              ∆ τ∆ −1                        1
                         E0 [     ∑   C({p∆ j , q∆ j ; S)ρ ] ρ ≤ ∆cE0 [τ],              (28)
                              ρ j=0

if the DM choose to acquire any information at all (τ > 0 always in this case). In words, the
Lρ -norm of the flow information cost function C(·) over time and possible histories must
be less that the constant c per unit time.
   In the limit as ρ → ∞, this would approach a per-period constraint on the amount of in-
formation the DM can obtain. For finite values of ρ, the DM can allocate more information
gathering to states and times in which it is more advantageous to gather more information.
We assume, however, that ρ > 1, for reasons that we discuss later. We also assume that the
flow cost function C(·) satisfies Conditions 1-6 stated in section 4.
   Let V (q0 ; ∆) denote the value of the solution to the sequence problem for a DM with
prior beliefs q0 , and let qτ denote the DM’s beliefs when stopping to make a decision. The
DM’s problem is
                             V (q0 ; ∆) = max E0 [û(qτ ) − κτ)],
                                          {p∆ j },τ

subject to the information-cost constraint (28). The dual version of this problem can be




                                                59
written as


                  W (q0 , λ ; ∆) = max E0 [û(qτ ) − κτ)]−
                                      {p∆ j },τ
                                                  τ∆−1 −1
                                           1−ρ             1
                                λ E0 [∆             ∑     { C(p∆ j , q∆ j ; S)ρ − ∆ρ cρ }].       (29)
                                                    j=0    ρ


Here, the function W (q0 , λ ; ∆) can be thought of as the value function of a different prob-
lem, in which there is a cost of gathering information proportional to λ ρ1 C(·)ρ . In what fol-
lows, we will refer to the function W as the value function, bearing in mind that λ is not ac-
tually exogenous to the problem. We will proceed under the assumption that λ ∈ (0, κc−ρ ).
In our proofs, we demonstrate that there is no duality gap in the continuous time limit of
this problem, and that our assumption about λ is without loss of generality.
    We begin by describing the recursive representation for the value function W (qt , λ ; ∆),
and discussing certain technical lemmas that are necessary to establish our main results.
The value function has a recursive representation:

                                                           1
             W (qt , λ ; ∆) = max{max −κ∆ + λ ∆1−ρ (∆ρ cρ − C(pt , qt ; S)ρ ) +
                                   pt                      ρ
                                ∑ (eTs pt qt )W (qt+∆,s, λ ; ∆), û(qt )},
                                s∈S


where qt+∆,s is pinned down by Bayes’ rule. In standard rational inattention problems, it is
without loss of generality to equate signals and actions. In this problem, when the DM does
not stop and make a decision, the “action” is updating one’s beliefs. Rather than consider
a probability distribution over signals, and then an updating of beliefs by Bayes’ rule, one
can consider the DM to be choosing a probability distribution over posteriors, subject to
the constraint that the expectation of the posterior is equal to the prior.39
  39 The notion of choosing a probability distribution over posteriors appears in Kamenica and Gentzkow
(2011), Caplin and Dean (2015), and Caplin et al. (2017), among other papers.



                                                          60
   To begin our analysis, we note that the value function W (qt , λ ; ∆) is well-behaved:

Lemma 8. The value function W (qt , λ ; ∆) is bounded on qt ∈ P(X), and convex in q. The
optimal stopping time τ∆ is bounded in expectation by a constant, τ̄, for all ∆:


                                              E0 [τ∆ ] ≤ τ̄.


Proof. See the appendix, section A.13.

   The boundedness of the value function follows from the setup of the problem: ulti-
mately, the DM will make a decision, and the utility from making the best possible decision
in the best possible state of the world is finite. The convexity of the value function is what
motivates the DM to acquire information. By updating her beliefs from q to either q0 or q00 ,
with q = αq00 + (1 − α)q0 for some α ∈ (0, 1), the DM improves her welfare by enabling
better decision making. That the optimal stopping time is bounded in expectation follows
from an obvious point: waiting too long to make a decision will eventually become worse,
even if the DM eventually makes the best possible decision, than making the worst possible
decision immediately.
   Next, we show that, because of the curvature (ρ) that we impose, the DM will choose,
under any optimal policy, to gather only a small amount of information in each time period,
as the length of each time period shrinks.

Lemma 9. Let n ∈ N denote a sequence such that limn→∞ ∆n = 0. Any associated sequence
                     ∗ satisfies, for all elements of the sequence,
of optimal policies pt,n


                                        ∗                  θ 1
                                     C(pt,n , qt,n ; S) ≤ ( ) ρ−1 ∆n ,
                                                           λ

                     ρ     ρ−1
                    c
where θ = λ (ρ λκ−λ
                 (ρ−1) )
                            ρ    .


                                                    61
Proof. See appendix, section A.14.

   The key step in proving this lemma is demonstrating that, as the time period shrinks,
the optimal quantity of information acquired vanishes at a sufficiently fast rate. The con-
vergence of the information structure to an uninformative one, as the time period shrinks,
allows us to use the approximation described in Theorem 2 to study the continuous-time
limit of the sequential evidence accumulation model. The assumption that ρ > 1 is criti-
cal to generating this result. When ρ = 1, the DM has no particular desire to smooth the
quantity of information gathered over time, and might choose to gather a large quantity of
information in a single period (as in Steiner et al. (2017)).
   We next discuss the convergence of an arbitrary sequence of stochastic processes for
beliefs (denoted qt,m ) and of stopping times (denoted τm ) to their continuous-time limits,
under the assumption that the policies generating them satisfy the bound in Lemma 9 and
the bound on expected stopping times. This lemma applies to a sequence of optimal poli-
cies, but also to sequences of sub-optimal policies. The lemma describes the convergence
of the beliefs process to a martingale, which is not necessarily a diffusion (it may have
jumps, or even be a semi-martingale that is not a jump-diffusion).

Lemma 10. Let ∆m , m ∈ N, denote a sequence such that limm→∞ ∆m = 0. Let pm (q) de-
note a sequence of Markov policies satisfying the bound in Lemma 9. Let qt,m denote the
stochastic process for the DM’s beliefs at time t, under such a policy, and let τm be a
sequence of stopping policies such that E0 [τm ] ≤ τ̄.
   There exists a sub-sequence n ∈ N and a probability space such that:

   i) The beliefs qt,n and the stopping time τn converge almost surely to a martingale qt
      and a stopping time τ.




                                              62
  ii) The martingale qt can be represented in terms of its semi-martingale characteristics,

                                             ˆ       t    ˆ
                                    Bt = −               (            ψs (x)xdx)dAs
                                                 0        R|X| \{0}

                                           ˆ     t
                                    Ct =             D(qs− )σs σsT D(qs− )dAs
                                             0

                                               νt (x) = dAt ψt (x),

      where σs is an |X| × |X| matrix-valued predictable stochastic process, satisfying
      qTs− σs =~0, ψs is a measure on R|X| \ {0} such that qs− + x ∈ P(X) and qs− + x  qs−
      for all x in the support of ψs , and dAs is the increment of a weakly increasing process.

  iii) For all stopping times T ,

                  ˆ T                       ˆ
                       1
              Et [             T
                      { tr[σs σs k(qs− )] +         ψs (x)D∗ (qs− + x||qs− )dx}dAs ] ≤
                   t   2                      |X|
                                             R \{0}
                                                                   θ 1
                                                                  ( ) ρ−1 Et [T − t].
                                                                   λ


  iv) The limit of the cumulative information cost is bounded below,

                                                                      ˆ     τn
                                                              lim E0 [           ∆1−ρ                      ρ
                                                                                  n C(pn (qt,n ), qt,n ; S) dt] ≥
                                                              n→∞
              ˆ τ                    ˆ                                  0
                  1                                                            dAs ρ
                        T
          Et [ { tr[σs σs k(qs− )] +            ψs (x)D∗ (qs− + x||qs− )dx}ρ (     ) ds].
               0 2                    R|X| \{0}                                 ds


Proof. See the appendix, section A.15.

   In essence, the stochastic process qt,n converges to a jump-diffusion process. The semi-
martingale characteristics, Bt ,Ct , νt , summarize the DM’s policy function. They have a
representation as a function of σt , ψt , At because of the need for beliefs to remain the sim-
plex, and the property that, once a state x ∈ X has been assigned zero probability, it will be

                                                          63
assigned zero probability forever after.
   To finish the proof, we resolve several issues. We show that the constraint given in
Lemma 9 binds. We show that the limiting value function W is unique, that duality holds
(V = W for a suitable choice of λ ), and that the the limit of V is the solution to the
continuous-time problem described in section 2. We also show that there is a sequence
of (possibly sub-optimal) policies in the discrete-time model that achieve, in the limit, the
optimal utility and converge to a diffusion. Moreover, if the cost function C(p, q; S) ex-
hibits a strict preference for gradual learning (it satisfies Condition 6 strictly for q0 6= q),
then all sequences of optimal policies converge to diffusions that are optimal policies of the
continuous-time model.

Theorem 4. Let n ∈ N index a sub-sequence of policies described in Lemma 10. There
exists a λ ∗ ∈ (0, κc−ρ ) such that


                        lim W (qt , λ ∗ ; ∆n ) = lim V (q0 ; ∆n ) = V (q0 ),
                        n→∞                     n→∞



where V (q0 ) is the solution to the continuous-time problem described in section 2, with
        −1
χ = ρ ρ c and µ = κ. There exists a sequence of policies in the discrete-time models that
achieve, in the limit, the value function V (q0 ) and for which the associated belief process,
qt,n , and stopping time τn converges in law to a belief process qt∗ and stopping time τ ∗ that
are induced by an optimal policy in the continuous-time model (and hence qt∗ is a diffusion).
If the cost function exhibits a strict preference for gradual learning, every convergent sub-
                              ∗ associated with optimal policies in the discrete-time model
sequence of belief processes qt,n
converges in law to a diffusion.

Proof. See the appendix, section A.16.

   We have shown that the DM’s behavior in the continuous-time problem can be thought

                                                64
of as an approximation of her behavior in discrete-time problems with flow cost functions
drawn from a very general class. These convergence results can be viewed as offering a sort
of micro-foundation for the continuous-time model, and in particular for our assumptions
in section 2 about the information-cost matrix function.



7    Conclusion

We have derived a continuous-time rational-inattention model as the limit of a discrete-time
sequential evidence accumulation problem. While assumptions about the cost of more pre-
cise signals in the sequential evidence accumulation problem are important determinants
of the predictions obtained for the choices that will be made, we have shown that rela-
tively specific conclusions are possible about the endogenous information structure in the
continuous-time limit, even under relatively general assumptions about the flow cost func-
tion for individual signals. This is because in the limit of a very large number of successive
signals, each of which is only minimally informative, only the local properties of the flow
cost function near purely uninformative information structures matter. The relevant proper-
ties of the flow cost function can be summarized by a matrix-valued function defined on the
space of possible posterior beliefs, that we call the information-cost matrix function. This
summarizes the degree to which it is costly to further distinguish between different pairs of
possible states, when one’s posterior belief given observations to that point is a particular
point in the probability simplex. We view it as desirable that our framework retains the
flexibility to allow different specifications of the degree to which it is intrinsically difficult
to distinguish certain pairs of states from one another.
    Quite generally, the solution to our continuous-time rational inattention model can be
characterized by the solution to a partial differential equation (HJB equation) that involves
the information-cost matrix function. For a broad class of possible specifications of the


                                               65
information-cost function, we are able to solve this equation, and further show that the
solution to our continuous-time dynamic model is equivalent to the solution to a static
rational-inattention problem, with a particular posterior-separable information-cost func-
tion (which depends on the information-cost matrix function, and hence on the local prop-
erties of the flow information-cost function). The use of posterior-separable cost functions
of this kind in static rational-inattention problems can thus be justified summarizing the
implications of a dynamic evidence accumulation process.
   Among the static cost functions that can be justified in this way is the mutual-information
cost function proposed by Sims, but we show that it is not the only static cost function that
can be given such a justification. We give particular attention to the existence of cost
functions that can be justified as the outcome of a dynamic evidence accumulation pro-
cess, but that incorporate an assumption that “nearby” states are more difficult to distin-
guish from one another, unlike the mutual-information cost function. We exhibit a class
of “neighborhood-based” cost functions that are convenient specifications of this kind, and
discuss in particular a limiting case of such functions that can be used in problems with
a continuous state space, our Fisher-information cost function. This cost function has the
attractive feature that an optimal endogenous information structure implies that action prob-
abilities will vary continuously with the state, even when action payoffs jump discontinu-
ously. A model of this kind better matches observed behavior in perceptual experiments,
and we suspect that it represents a more realistic assumption for economic applications as
well, such as global game models of the kind analyzed by Yang (2015) and Morris and
Yang (2016).




                                             66
References

Shun-ichi Amari and Hiroshi Nagaoka. Methods of information geometry, volume 191.
  American Mathematical Soc., 2007.
Nihat Ay, Jürgen Jost, Hông Vân Lê, and Lorenz Schwachhöfer. Information geometry and
  sufficient statistics. Probability Theory and Related Fields, pages 1–38, 2014.
David Blackwell. Equivalent comparisons of experiments. The annals of mathematical
  statistics, 24(2):265–272, 1953.
Andrew Caplin and Mark Dean. Revealed preference, rational inattention, and costly in-
  formation acquisition. American Economic Review, 105(7):2183–2203, 2015.
Andrew Caplin, Mark Dean, and John Leahy. Rationally inattentive behavior: Character-
  izing and generalizing Shannon entropy. Unpublished manuscript, July 2017.
Yeon-Koo Che and Konrad Mierendorff. Optimal sequential decision with limited atten-
  tion. Unpublished manuscript, 2016.
Nikolai Nikolaevich Chentsov. Statistical decision rules and optimal inference. Number 53.
  American Mathematical Soc., 1982.
John A. Clithero. Improving out-of-sample predictions using response times and a model
  of the decision process. Unpublished manuscript, June 2016.
Thomas M Cover and Joy A Thomas. Elements of information theory. John Wiley & Sons,
  2012.
Henrique De Oliveira, Tommaso Denti, Maximilian Mihm, and Kemal Ozbek. Rationally
  inattentive preferences and hidden information costs. Theoretical Economics, 12:621–
  624, 2017.
Ambuj Dewan and Nate Neligh. Estimating information cost functions in models of rational
  inattention. Unpublished manuscript, January 2017.
Ernst Fehr and Antonio Rangel. Neuroeconomic foundations of economic choice — recent
  advances. Journal of Economic Perspectives, 25(4):3–30, 2011.
Mogens Fosgerau, Emerson Melo, and Matthew Shum. Discrete choice and rational inat-
  tention: A general equivalence result. Unpublished manuscript, 2016.
B Roy Frieden. Science from Fisher information: a unification. Cambridge University
  Press, 2004.
Drew Fudenberg, Philipp Strack, and Tomasz Strzalecki. Stochastic choice and optimal
  sequential sampling. Unpublished manuscript, 2015.
Fabrizio Gabbiani and Steven J. Cox. Mathematics for Neuroscientists. Academic Press,
  2010.
Joshua I. Gold and Hauke R. Heekeren. Neural mechanisms for perceptual decision mak-
  ing. In Paul W. Glimcher and Ernst Fehr, editors, Neuroeconomics: Decision Making
  and the Brain, 2d ed. Academic Press, 2014.
Benjamin Hébert. Moral hazard and the optimality of debt. Unpublished manuscript, 2014.
Frank Huettner, Tamer Boyaci, and Yalcin Akcay. Consumer choice under limited attention


                                           67
   when options have different information costs. Unpublished manuscript, 2016.
Emir Kamenica and Matthew Gentzkow. Bayesian persuasion. American Economic Re-
   view, 101(6):2590–2615, 2011.
Ian Krajbich, Bastiaan Oud, and Ernst Fehr. Benefits of neuroeconomics modeling: New
   policy interventions and predictors of preference. American Economic Review, 104(5):
   501–506, 2014.
Filip Matêjka, Alisdair McKay, et al. Rational inattention to discrete choices: A new
   foundation for the multinomial logit model. American Economic Review, 105(1):272–
   98, 2015.
Stephen Morris and Hyun Song Shin. Global games: theory and applications. 2001.
Stephen Morris and Philipp Strack. The Wald problem and the equivalence of sequential
   sampling and static information costs. Unpublished manuscript, June 2017.
Stephen Morris and Ming Yang. Coordination and the relative cost of distinguishing nearby
   states. Unpublished manuscript, 2016.
Michael Shadlen and Daphna Shohamy. Decision making and sequential sampling from
   memory. Neuron, 90(5):927–939, 2016.
Michael N. Shadlen et al. The speed and accuracy of a perceptual decision: A mathematical
   primer. In K. Doya et al., editors, Bayesian Brain: Probabilistic Approaches to Neural
   Coding. M.I.T. Press, 2007.
Christopher A Sims. Rational inattention and monetary economics. Handbook of Monetary
   Economics, 3:155–181, 2010.
Jakub Steiner, Colin Stewart, and Filip Matějka. Rational inattention dynamics: Inertia and
   delay in decision-making. Econometrica, 85(2):521–553, 2017.
Satohiro Tajima, Jan Drugowitsch, and Alexandre Pouget. Optimal policy for value-based
   decision-making. Nature communications, 7, 2016.
Tim van Erven and Peter Harremoës. Rényi divergence and Kullback-Leibler divergence.
   IEEE Transactions on Information Theory, 60:3797–3820, 2014.
Michael Woodford. Inattentive valuation and reference-dependent choice. Unpublished
   manuscript, May 2012.
Michael Woodford. An optimizing neuroeconomic model of discrete choice. Technical
   report, National Bureau of Economic Research, February 2014.
Ming Yang. Coordination with flexible information acquisition. Journal of Economic
   Theory, 158:721–738, 2015.
Weijie Zhong. Optimal dynamic information acquisition. Unpublished manuscript, March
   2017.




                                            68
