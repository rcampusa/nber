                                 NBER WORKING PAPER SERIES




                            SEMIPARAMETRIC CAUSALITY TESTS
                           USING THE POLICY PROPENSITY SCORE

                                         Joshua D. Angrist
                                        Guido M. Kuersteiner

                                         Working Paper 10975
                                 http://www.nber.org/papers/w10975


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                     December 2004




We thank Christina Romer for sharing the Romers’ data, Alberto Abadie, Xiaohong Chen, Simon Gilchrist,
Stefan Hoderlein and James Stock for helpful discussions and seminar and conference participants at
Columbia University, Harvard-MIT, 2004 NSF/NBER Time Series Conference, Rochester, Rutgers, the
Triangle Econometrics Workshop, Wisconsin and the 2nd conference on evaluation research in Mannheim
for helpful comments. Kuersteiner gratefully acknowledges support from NSF grant SES-0095132. The
views expressed herein are those of the author(s) and do not necessarily reflect the views of the National
Bureau of Economic Research.

 © 2004 by Joshua D. Angrist and Guido M. Kuersteiner. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit, including ©
notice, is given to the source.
Semiparametric Causality Tests Using the Policy Propensity Score
Joshua D. Angrist and Guido M. Kuersteiner
NBER Working Paper No. 10975
December 2004
JEL No. C14, C22, E52

                                           ABSTRACT

Time series data are widely used to explore causal relationships, typically in a regression framework

with lagged dependent variables. Regression-based causality tests rely on an array of functional form

and distributional assumptions for valid causal inference. This paper develops a semi-parametric test

for causality in models linking a binary treatment or policy variable with unobserved potential

outcomes. The procedure is semiparametric in the sense that we model the process determining

treatment -- the policy propensity score -- but leave the model for outcomes unspecified. This general

approach is motivated by the notion that we typically have better prior information about the policy

determination process than about the macro-economy. A conceptual innovation is that we adapt the

cross-sectional potential outcomes framework to a time series setting. This leads to a generalized

definition of Sims (1980) causality. We also develop a test for full conditional independence, in

contrast with the usual focus on mean independence. Our approach is illustrated using data from the

Romer and Romer (1989) study of the relationship between the Federal reserve's monetary policy

and output.

Joshua D. Angrist
Department of Economics
MIT, E52-353
50 Memorial Drive
Cambridge, MA 02142-1347
and NBER
angrist@mit.edu

Guido M. Kuersteiner
Department of Economics
Boston University
270 Bay State Road
Boston, MA 02215
gkuerste@bu.edu
1    Introduction
The possibility of a causal connection between monetary policy and real economic variables is one of the
most important and widely studied questions in macroeconomics. Most of the evidence on this question
comes from regression-based statistical tests.   That is, researchers regress an outcome variable such as
industrial production on measures of monetary policy, while controlling for lagged outcomes and contem-
poraneous and lagged covariates, with the statistical significance of policy variables providing the test
results of interest. Two of the most influential empirical studies in this spirit are by Sims (1972, 1980),
who discusses conceptual as well as empirical problems in the money-income nexus.
    The foundation of regression-based causality tests is a simple conditional independence assumption.
The core null hypothesis is that conditional on lagged outcomes and an appropriate set of control vari-
ables, the absence of a causal relationship should be manifest in a statistically insignificant connection
between policy variables and contemporaneous and future outcomes. In the language of cross-sectional
program evaluation, policy variables are assumed to be "as good as randomly assigned" after appropriate
regression conditioning, so that conditional eﬀects have a causal interpretation. While this is obviously a
strong assumption, it seems like a natural place to begin empirical work, at least in the absence of a true
randomized trial or a compelling exclusion restriction. The analogy between a time series causal inquiry
and a cross-sectional selection-on-observables argument is even stronger when the policy variable can be
coded as a binary treatment.     For example, we can consider the causal eﬀect of exposure to a discrete
monetary shock, with the latter viewed as a binary treatment. This is the essence of the approach taken
in Romer and Romer’s (1989) seminal analysis of the federal reserve’s open market committee decisions,
an application that we use here to illustrate theoretical ideas.
    While providing a flexible tool for the analysis of causal relationships, an important drawback of
regression-based conditional independence tests is that they typically require an array of auxiliary as-
sumptions that are hard to assess and interpret, especially in a time series context. In addition to the
linearity implicit in any regression test, researchers must choose conditioning variables, lag lengths, and
impose assumptions that imply some sort of stationarity. The principal contribution of this paper is to
develop an alternative approach to time series causality testing that shifts the focus away from modelling
the relatively mysterious process determining outcomes towards a model of the process determining policy
decisions. That is, we develop tests for causality that rely on a model for the conditional probability of
treatment, which we call the "policy propensity score", leaving the model for outcomes unspecified. This
approach seems especially appealing for the sort of time series applications we have in mind. In many of
these cases there is some agreement — and even some evidence — as to what the conditioning variables used
by policy makers are. Moreover, the binary nature of some policy variables provides a natural guide as to
the choice of functional form. A second contribution of our paper is the outline of a potential-outcomes


                                                      1
framework for causal research using time series data. In particular, we show that a generalized Sims-type
definition of dynamic causality provides a coherent conceptual basis for time series causal inference.
       We use the time series causal framework to develop new distribution-free Kolmogorov-Smirnov (KS)
and von Mises (VM) statistics that test for full conditional independence in time series models.                     The
tests developed here are distribution-free in the sense that critical values do not depend on the sample
for a given model design. Testing for full independence is also an innovation since most previous work
on time series causality testing is concerned solely with mean independence. Finally, the tests developed
here are semiparametric in the sense that a parametric model is used for the policy propensity score, but
other features of the data-generating process are left unspecified. Our approach is related to earlier work
on semiparametric estimation of average causal eﬀects by Robins, Mark, and Newey (1992), who focus
on sequential randomized trials. Also related is the Linton and Gozalo (1999) study of non-parametric
causality tests in a cross-sectional context. Linton and Gozalo consider KS- and VM-type statistics, as we
do, but the limiting distributions of their test statistics are not asymptotically distribution-free. These
distributions are also diﬃcult to bootstrap in a time series context. More recently, Su and White (2003)
have proposed a nonparametric conditional independence test for time series data based on orthogonality
conditions obtained from an empirical likelihood specification. The Su and White procedure converges at
a less-than-standard rate due to the need for nonparametric density estimation.
       The main advantage of using the propensity score in our context lies in the fact that this reduces the
problem of testing for conditional distributional independence to a problem of testing for a martingale
diﬀerence sequence property of a certain function of the data. This problem is relatively easy to handle
and has been analyzed by, among others, Bierens (1982, 1990), Bierens and Ploberger (1997), Chen
and Fan (1999), Stute, Thies and Zhu (1998) and Koul and Stute (1999). Earlier contributions propose
a variety of schemes to find critical values for the limiting distribution of the resulting test statistics
but most of the existing procedures involve nuisance parameters. In light of this diﬃculty, Bierens and
Ploberger (1997) propose asymptotic bounds, Chen and Fan (1999) use a bootstrap and Koul and Stute
(1999) apply the Khmaladze transform to produce a statistic with a distribution-free limit.1 Our work
extends Koul and Stute (1999) by allowing for more general forms of dependence, including mixing and
conditional heteroskedasticity. These extensions are important in our application because even under the
null hypothesis of no causal relationship, the observed time series are not Markovian and do not have
a martingale diﬀerence structure. Most importantly, direct application of the Khmaladze (1988,1993)
method in a multivariate context appears to work poorly in practice. We therefore use a Rosenblatt
(1952) transformation of the data in addition to the Khmaladze transformation. This combination of
   1
       The univariate version of the Khmaladze transform was first used in econometrics by Bai (2002) and Koenker and Xiao
(2002) .




                                                             2
methods seems to perform well, at least for the low-dimensional multivariate systems explored here.
        The paper is organized as follows. The next section outlines our conceptual framework and provides
a heuristic derivation of our semiparametric test statistics. Strategies for constructing feasible versions of
these statistics are discussed in Section 3 and Section 4 discusses the construction of feasible critical values.
Although in principal straightforward, in practice, the distribution theory is complicated by the need to
account for estimation of the propensity score.2 We briefly explore finite-sample properties of the new
statistics in a Monte Carlo study discussed in Section 5. The empirical behavior of alternative causality
concepts and test statistics is illustrated through a re-analysis of the Romer and Romer (1989, 1994) data
in Section 6. The last section of the paper concludes and suggests directions for further theoretical work.


2        Notation and Framework
Causal eﬀects are defined here using the Rubin (1974) notion of potential outcomes.                          The potential
outcomes concept originated in experimental studies where the investigator has control over the assignment
of treatments, but is now widely used in observational studies. See, e.g. Rosenbaum and Rubin (1983),
who introduced the propensity score as a tool for causal inference in the potential-outcomes framework.
        Our basic definition of causality relies on distinguishing the outcomes that would be realized with
and without treatment, denoted by Y1t and Y0t . The observed outcome in period t can then be written
Yt = Y1t Dt + (1 − Dt ) Y0t , where Dt is treatment status. In the absence of any serial correlation or
covariates, the causal eﬀect of a treatment or policy action is unambiguously defined as Y1t − Y0t . It is
clear that this eﬀect can never be measured in practice. Researchers therefore focus on either the average
eﬀect E(Y1t − Y0t ), or the eﬀect in treated periods, E(Y1t − Y0t |Dt = 1). We refer to both of these as the
average causal eﬀect of policy action Dt , since under our identifying assumptions they are the same.
        In a dynamic setting, the definition of causal eﬀects is complicated by the fact that potential out-
comes are determined not just by current policy actions but also by past actions and covariates. To
capture dynamics, we assume the economy can be described by the vector stochastic process χt (ω) =
(Yt (ω) , Xt (ω) , Dt (ω)) , defined on the probability space (Ω, F, P), where Yt (ω) is a vector of outcome
variables, Dt (ω) is a vector of policy variables, and Xt (ω) is a vector of other exogenous and (lagged)
endogenous variables that are not part of the null hypothesis of no causal eﬀect of Dt (ω) . The elements of
the sample space, ω, can be thought of as indexing parallel universes, while the random variables defined
on the sample space pick out the time series determined by realizations of ω. We assume that Dt takes
values in the set Dt . The observed sample χt is a realization of χt (ω) . Let X̄t = (Xt , ..., Xt−k , ...) denote
the covariate path, with similar definitions for Ȳt and D̄t .
    2
        Recent studies of the consequences of using an estimated propensity score for cross-sectional causal inference include
Heckman, Ichimura and Todd (1998) Hahn (1999) and Hirano, Imbens, and Ridder (2003).


                                                                3
         This framework leads to a definition of counterfactual outcomes based on the notion that past policy
actions have the potential to change any future outcome variable, for each realization of the outcome ω :

Definition 1 Assume that there exists a measurable map ξ t+j such that

                                Yt+j (ω) = ξ t+j (ω, Dt (ω)) for all t, j > 0 and almost all ω.

Potential outcomes are defined as

                                               d
                                             Yt+j (ω) = ξ t+j (ω, d) for all d ∈ Dt .

                                                                                                   0
                                                                                   d (ω) = Y d (ω) , j > 0 for
         The sharp null hypothesis of no causal eﬀects for potential outcomes is Yt+j       t+j
all possible realizations d, d0 ∈ Dt . This coincides with the hypothesis of no causal eﬀects in the simple
situation studied by Rubin (1974), where we would write Y0t = Y1t .3
         Our approach to causal testing allows the map ξ t+j to be unspecified. On the other hand, it is common
practice in econometrics to model χt as a function of its own lags and possibly exogenous variables or
innovations in variables, and so it is worth thinking about what potential outcomes would be in this case.
Given such a functional relationship, the map ξ t+j can be constructed in an obvious way; a simple but
common example is given below:
                                                P∞
Example 1 Suppose that Yt (ω) =                    k=0 ψ k Dt−k   (ω), using notation that makes the dependence of the
policy variables on the sample space explicit. This model could be one equation from a structural VAR. In
this simple example, the map ξ t+j is given by
                                                          P∞
                                         ξ t+j (ω, d) =     k=0,k6=j   ψ k Dt+j−k (ω) + ψ j d.

                d (ω) = Y
Equivalently, Yt+j       t+j (ω) + ψ j (d − Dt (ω)). The sharp null hypothesis of no causal eﬀect holds if
and only if ψ j = 0 for all j. This is the familiar restriction that the impulse response function be identically
equal to zero.

         In practice, of course, we obtain only one realization each period, and therefore cannot directly test
the non-causality null. Our tests therefore rely on the identification condition below, referred to in the
cross-section treatment eﬀects literature as "ignorability" or "selection-on-observables." This condition
allows us to establish a link between potential outcomes and the distribution of observed random variables.
     3                                                                                                           (0)
         In a study of sequential randomized trials, Robins, Greenland and Hu (1999) define potential outcome Yt       as the outcome
that would be observed in the absence of any current and past interventions, i.e. when Dt = Dt−1 = ... = 0. They denote by
 (1)
Yt       the set of values that could have potentially been observed if for all i ≥ 0, Dt−i = 1. This approach seems too restrictive
to fit the macroeconomic policy experiments we have in mind.



                                                                   4
As part of this setup, we assume that the information used by policy makers at time t, denoted Ft , is
contained in the public record or otherwise available to researchers. Formally, the relevant information
is assumed to be described by Ft = σ (zt ) where zt = Πt (X̄t , Ȳt , D̄t−1 ) is a sequence of finite dimensional
              Ndim(χ )
functions Πt : i=1 t R∞ → Rk2 of the entire observable history of the joint process. For the purposes
of empirical work, the mapping Πt is assumed to be known.

Condition 1 Selection on observables:

                                  d
                                Yt+j (ω) ⊥Dt (ω) |Ft for all j > 0 and for all d ∈ Dt .

   Note that implicit in this assumption is the notion that even after conditioning on observables, there is
stochastic variation in policy decisions. This variation is taken to be due to idiosyncratic factors such as
those detailed for monetary policy by Romer and Romer (2004). These factors include the variation over
time in operating procedures used to convert information into decisions, changes in policy-makers’ beliefs
about the workings of the economy, decision-makers’ tastes and goals, political factors, the temporary
pursuit of objectives other than changes in the outcomes of interest (e.g., monetary policy that targets
exchange rates instead of inflation or unemployment), and finally harder-to-quantify factors such as the
mood and character of decision-makers. A key element of Condition 1 is that, conditional on observables,
this idiosyncratic variation is taken to be independent of potential future outcomes.
                            0
                        d (ω) = Y d (ω), the key testable conditional independence assumption can now
   Substituting using Yt+j       t+j
be written in terms of observable distributions as:

                                              Yt+1 , ..., Yt+j , ... ⊥ Dt |Ft .                              (1)

   In other words, conditional on observed covariates and lagged outcomes, there should be no relationship
between treatment and outcomes Of course, Condition 1 is a strong restriction. But this condition is
imposed in the rational expectations models outlined by Lucas (1972) and Sims (1980). In particular,
when there are no informational asymmetries between the public and monetary authorities these models
also imply that Equation 1 holds. The following example describes another assignment mechanism that
satisfies this condition:

Example 2 Suppose policies depend on observed variables Ft through the function D(Ft , t), as well as
an unobserved (to the econometrician) variable, εt . Policies are determined by Dt = f (D(Ft , t), εt ), where
f is a general mapping.         For example, Shapiro (1994) postulates Dt = 1 {zt0 θ + εt > 0} where εt is iid
Gaussian. In this case D(Ft , t) = zt0 θ, f (a, b) = 1 {a + b > 0} and Dt = {0, 1} . If εt is independent of
  d (ω) , Condition 1 is satisfied. This means we can view ε as essentially randomly assigned, with no
Yt+j                                                        t
direct eﬀect on outcomes.

                                                             5
       Tests based on condition (1) can be seen as testing a generalized version of Sims causality. A natural
question is how this relates to the Granger causality tests widely used in empirical work.                    Note that if
Xt can be subsumed into the vector Yt , Sims non-causality simplifies to Yt+1 , ..., Yt+k , ... ⊥ Dt |Ȳt , D̄t−1 .
Chamberlain (1982) and Florens and Mouchart (1982, 1985) show that under plausible regularity conditions
this is equivalent to generalized Granger non-causality, i.e.,

                                                    Yt+1 ⊥ Dt , D̄t−1 |Ȳt .                                             (2)

In the more general case, however, where Dt potentially causes Xt+1 , so X̄t can not be subsumed into Ȳt ,
(1) does not imply
                                                 Yt+1 ⊥ Dt , D̄t−1 |X̄t , Ȳt .                                          (3)

       This result was shown for the case of linear processes by Dufour and Tessier (1993) but seems to
have received little attention in the literature.4 We summarize the non-equivalence of Sims and Granger
causality in the following theorem:

Theorem 1 Let χt be a stochastic process defined on a probability space (Ω, F, P) as before, assuming also
that conditional probability measures P (Yt+1 , Dt |Ft ) are well defined ∀t except possibly on a set of measure
zero. Then (1) does not imply (3) and (3) does not imply (1).

       The intuition for the Granger/Sims distinction is that while Sims causality looks forward only at
outcomes, the Granger causality relation is defined by conditioning on potentially endogenous responses
to policy shocks and other disturbances. To prove the nonequivalence theorem, it is enough to give
a counterexample. We do this for linear Gaussian processes since discrete variables can be defined as
functions of underlying linear indices.

Example 3 Assume that the vector χt = (yt , xt , Dt ) takes values in R3 and that χt has a representation
in terms of an overidentified structural VAR where yt = bxt−1 + cDt−1 + εyt , xt = fDt + εxt and Dt = εDt
where εt = (εyt , εxt , εDt ) is such that εt ˜N (0, I3 ) and I3 is the 3 × 3 identity matrix. The impulse response
function of yt is yt = εyt + bεxt−1 + (c + bf ) εDt−1 . Sims non-causality holds if c + bf = 0 which occurs if
c = 0 and either b = 0 or f = 0 or if c = −bf. On the other hand, Granger non-causality requires that
c = 0. We therefore can have Sims non-causality but Granger causality when c 6= 0 and c = −bf. On the
other hand, we have Granger non-causality but Sims causality when c = 0 and both b and f are non-zero
   4
       Many authors have studied the relationship between Granger and Sims-type conditional independence restrictions. See,
for example, Dufour and Renault (1998) who consider a multi-step forward version of Granger causality testing, and Robins,
Greenland, and Hu (1999) who state something like theorem 1 without proof.          Robins, Greenland and Hu also present
restrictions on the joint process of wt under which (1) implies (3) but these assumptions are unrealistic for applications in
macroeconomics.


                                                               6
                            Figure 1: The vertical lines indicate Romer Dates.


   A scenario with Granger non-causality but Sims causality is of potential relevance in the debate over
money-output causality. Suppose yt is output, xt is inflation and Dt is a proxy for monetary policy. Then
this stylized model captures a direct eﬀect of monetary policy on inflation and an indirect eﬀect on output
through the eﬀect of inflation on output. In this case, Granger tests will fail to detect a causal link between
monetary policy and output while Sims tests will detect this relationship. One way to understand this
diﬀerence is through the impulse response function, which shows that Sims looks for an eﬀect of structural
innovations in policy (i.e., εDt ). In contrast, Granger non-causality is formulated as a restriction on the
relation between output and all lagged variables, including covariates that themselves have responded to
the policy shock of interest. Granger causality therefore provides an incorrect answer to a question that
Sims causality tests answer correctly: will output change in response to a random manipulation if we
randomly shock monetary policy?
   This example raises the question of how important time-varying, policy-sensitive covariates are in
practice. In research on monetary policy, Shapiro (1994) and Leeper (1997) argue that it is important to
include inflation in the conditioning set when attempting to isolate the causal eﬀect of monetary policy
innovations. This point is illustrated in Figure 1, which marks the Romer dates on the time series of
inflation. In most cases, Romer dates are followed by an inflationary peak. This acceleration in inflation
is both a cause of monetary policy and a response to earlier policy changes. Moreover, inflation may have
eﬀects on real variables. Thus, the causal relationship between monetary policy and activity in the real


                                                      7
sector may be more appropriately analyzed in a framework that incorporates inflation and other nominal
variables that respond to policy.
       In the remainder of the paper, we assume the policy variable of interest is binary, although our con-
ceptual framework applies more generally. We focus here on binary policy decisions because we are
interesting in exploiting parallels with the cross-sectional treatment eﬀects literature and because this
leads naturally to a setup relying on the propensity score.5                   To develop this setup, we assume that
models for the policy function can be written in the parametric form P (Dt = 1|zt ) = p(zt , θ0 ) for
some function p(., .) and an unknown parameter vector, θ0 . Under the null hypothesis it follows that
P (Dt = 1|zt , Yt+1 , ..., Yt+j , ...) = P (Dt = 1|zt ). A test of the null hypothesis can therefore be obtained by
augmenting the policy function p(zt , θ0 ) with future outcome variables. This test has correct size though
it will not have power against all alternatives. In the Monte Carlo and empirical parts of the paper, we
explore simple Sims-type tests based on augmenting the policy function with future outcomes. But our
main objective is to develop a more flexible class of semiparametric causality (conditional independence)
tests that can be used to direct power in specific directions or to construct tests with power against general
alternatives. A major advantage of our approach is that we do not have to attempt to identify and estimate
a fully specified model of the entire macroeconomy or even the money-output relation. This saves the need
to impose identifying restrictions on a complete structural VAR as in, e.g., Bernanke and Blinder (1992).
       A natural substantive question at this point is what should go in the conditioning set for the policy
propensity score and how this should be modeled. In practice, Fed policy is commonly modeled as being
driven by a few observed variables like inflation and lagged output growth. Examples include papers
by the Romers and others inspired by their work.6 The fact that Dt is binary in our application also
suggests Logit or similar models provide a natural functional form. A motivating example that seems
especially relevant in this context is Shapiro (1994), who develops a parsimonious Probit model of Fed
decision-making as a function of net present value measures of inflation and unemployment. Finally, we
note that while it is impossible to know for sure whether a given set of conditioning variables is adequate,
diagnostic tests such as those proposed by Rosenbaum and Rubin (1985) can help decide when the model
for the policy propensity score is an adequate representation of the role of the chosen set of covariates.
A key technical advantage of reliance on the relatively tractable problem of modeling fed decision-making
through the policy propensity score, is that this allows us to derive a semi-parametric test statistic with a
   5
       The recent empirical literature on the eﬀects of monetary policy has focused on developing policy models for the federal
funds rate. See, e.g., Bernanke and Blinder (1992), Christiano, Eichenbaum, and Evans (1996), and Romer and Romer (2004).
In future work, we hope to develop an extension for mutli-valued or continuous causal variables like the Federal funds rate.
For a recent extension of cross-sectional propensity-score methods to multi-valued treatments, see Hirano and Imbens (2004).
   6
     Stock and Watson (2002a, 2002b) propose the use of factor analysis to construct a low-dimensional predictor of inflation
rates from a large dimensional data set. This approach has been used in the analysis of monetary policy by Bernanke and
Boivin (2003) and Bernanke, Boivin and Eliasz (2004).


                                                                8
limiting distribution that depends only on the marginal distribution of outcome and conditioning variables
(as opposed to the full joint distribution of the entire underlying process).


3    Semiparametric Causality Tests
We are interested in testing the conditional independence restriction yt ⊥Dt |zt where yt takes values in Rk1
and zt takes values in Rk2 with k1 + k2 = k finite. Typically, yt = (Yt+1
                                                                       0 , ..., Y 0   0
                                                                                 t+m ) but it is also possible
                                                    0
to focus on particular future outcomes, say, yt = Yt+m , when causal eﬀects are thought to be delayed by
m periods. Assuming that Dt is binary, the conditional independence hypothesis can be written

                        P (yt ≤ y, Dt = i|zt ) = P (yt ≤ y|zt )P (Dt = i|zt ) for i = {0, 1} .                      (4)

We use the short hand notation p(zt ) = P (Dt = i|zt ) and assume that p(zt ) = p(zt , θ) is known up to a
parameter θ.
    Linton and Gozalo (1999) develop a fully nonparametric test of (4). Their test statistic is based on the
empirical joint and marginal distributions of yt , Dt , zt . The resulting procedure is more flexible than ours
but does not have a distribution-free limit distribution, a fact that leads Linton and Gozalo to bootstrap.
In our setting, application of the bootstrap is complicated by the need to account for serial dependence
and to impose the null while resampling. The bootstrap is also complicated by the fact that even under the
null hypothesis the joint process of yt , Dt , zt is not Markovian and does not have a martingale diﬀerence
sequence property. More recently, Su and White (2003) propose a nonparametric test based on estimates
of conditional densities. Their procedure is asymptotically normal but converges more slowly than a n−1/2
rate since their statistic involves non-parametric density estimates.
    A convenient representation of the hypotheses we are interested in testing can be obtained by noting
that under the null,

                P (yt ≤ y, Dt = 1|zt ) − P (yt ≤ y|zt )p (zt ) = E [1 (yt ≤ y) (Dt − p(zt )) |zt ] = 0.             (5)

This leads to a simple interpretation of test statistics based on this moment condition as looking for a
relation between policy innovations, Dt − p(zt ), and the distribution of future outcomes.
    We now define Ut = (yt , zt ) so that the null hypothesis of conditional independence can be represented
very generally in terms of moment conditions for functions of Ut . Let φ(., .) : Rk × Rk → R be a function of
Ut and some index v. Under the null we then have E [φ(Ut , v)(Dt − p(zt ))|zt ] = 0. Examples are φ(Ut , v) =
                                                 √
1 {Ut ≤ v} or φ(Ut , v) = exp(iv 0 Ut ) where i = −1, as suggested by Bierens (1982) and Su and White
(2003). A natural choice for φ(Ut , v) is φ(Ut , v) = ytj 1 {zt ≤ v} where ytj = y1t
                                                                                  j1
                                                                                     ....ykjk1 t , which generates tests
of conditional moment independence.


                                                           9
       Equation (5) shows that the hypothesis of conditional independence, whether formulated directly or
for conditional moments, is equivalent to a martingale diﬀerence sequence (MDS) hypothesis for a certain
empirical process. In particular, define the empirical process
                                                              n
                                                              X
                                                       −1/2
                                           Vn (v) = n               m(yt , Dt , zt , θ0 ; v)
                                                              t=1

with
                                       m(yt , Dt , zt , θ; v) = [Dt − p(zt , θ)] φ(Ut , v).

This is similar in spirit to the process analyzed by Koul and Stute (1999) except for the fact that it depends
on the parameter v ∈ Rk while Koul and Stute only consider the univariate case.7
       Under regularity conditions that include stationarity of the observed process we show in Appendix A
that Vn (v) converges weakly to a limiting Gaussian process V (v) on the space of cadlag functions8 denoted
by D [−∞, ∞]k with covariance function Γ(v, τ ), defined as
                                                             £               ¤
                                                 Γ(v, τ ) = E Vn (v)Vn (τ )0

where ν, τ ∈ Rk and we note that EVn (v) = 0. Using the fact that under the null E [Dt |zt , yt ] = E [Dt |zt ] =
p (zt ) and partitioning u = (u1 , u2 ) with u2 ∈ [−∞, ∞]k2 we define H(v ∧ τ ) with
                                              Z v
                                                   ¡                 ¢
                                      H(v) =         p(u2 ) − p(u2 )2 dFu (u)                                            (6)
                                                     −∞

where Fu (u) is the cumulative marginal distribution function of Ut and ∧ denotes the element by element
                                                                            R
minimum. The covariance function Γ(v, τ ) can now be written as Γ(v, τ ) = φ(u, v)φ(u, τ )dH (u) . Note
that when φ(Ut , v) = 1 {Ut ≤ v} then Γ(v, τ ) = H(v ∧ τ ). This is the case we consider in the empirical
application. The statistic Vn (v) can be used to test the null hypothesis of conditional independence by
                                                       R
comparing the value of KS = supv |Vn (v)| or V M = (Vn (v))2 dFu (v) with the limiting distribution of
these statistics under the null hypothesis.
       Implementation of statistics based on Vn (v) requires the construction of appropriate critical values.
This problem is complicated by two factors aﬀecting the limiting distribution of Vn (v). The first factor is
the dependence of Vn (v) on φ (Ut , v) which induces data dependent correlation in the process Vn (v). Hence,
the nuisance parameter Γ(v, τ ) appears in the limiting distribution. This is handled in two ways: First,
critical values for the limiting distribution of Vn (v) are computed numerically conditional on the sample in
a way that accounts for the covariance structure Γ (v, τ ) . We discuss this procedure at the end of Section
   7
       Another important diﬀerence is that in our setup, the process 1 (yt ≤ y) (Dt − p(zt )) is not Markovian even under the
null hypothesis. This implies that the proofs of Koul and Stute do not apply directly for our case.
   8
     Cadlag functions are functions which are continuous from the right with left limits.



                                                               10
4.1. An alternative to numerical critical values is to apply a transformation proposed by Rosenblatt (1952)
which transforms Vn (v) to a standard Gaussian process on the k-dimensional unit cube. The advantage
of the latter transformation is that asymptotic critical values can be based on standardized tables that
only depend on the dimension k and the function φ, but not on the distribution of Ut and thus not on the
sample. We discuss how to construct these tables numerically in Section 5 and report critical values for
the special case when φ(., v) = 1 {. ≤ v} in Table 2.
    The second factor that aﬀects the limiting distribution of Vn (v) is the fact that the unknown parameter
θ needs to be estimated. We use the notation V̂n (v) to denote test statistics that are based on an estimate
θ̂ for θ. Estimation of θ aﬀects the limiting distribution of V̂n (v) and needs to be taken into account. In
Section 4 we discuss a martingale transform proposed by Khmaladze (1988, 1993) to remove the eﬀect of
variability in V̂n (v) stemming from estimation of θ. The resulting corrected test statistic then has the same
limiting distribution as Vn (v), and thus, in a second step, critical values that are valid for Vn (v) can be
used to carry out tests based on the transformed version of V̂n (v).


4    Implementation
Critical values for the KS and VM statistics are obtained through a series of transformations to correct
for the fact that estimated parameters aﬀect the relevant limiting distributions and to account for the
correlation between the elements in Ut that lead to the presence of the nuisance parameter Γ (v, τ ) in the
limiting distribution.
    As a first step, let V̂n (v) denote the test statistic of interest where p(zt , θ) is replaced by p(zt , θ̂) and
the estimator θ̂ is assumed to satisfy the following asymptotic linearity property:
                                         ³       ´        n
                                                          X
                                   1/2               −1/2
                                 n        θ̂ − θ0 = n       l (Dt , zt , θ0 ) + op (1).
                                                               t=1

A more formal statement of this assumption is contained in Condition 7 in Appendix A. In our context,
l (Dt , zt , θ) is the score for the maximum likelihood estimator of the propensity score model. To develop a
structure that can be used to account for the variability in V̂n (v) induced by the estimation of θ, define
the function m̄(v, θ) = E [m(yt+k , Dt , zt , θ; v)] and let

                                                                   ∂ m̄(v, θ)
                                                  ṁ(v, θ) = −                .
                                                                       ∂θ
                                                                                              Pn
It therefore follows that V̂n (v) can be approximated by Vn (v) − ṁ(v, θ0 )0 n−1/2            t=1 l (Dt , zt , θ 0 ).   The
empirical process V̂n (v) converges to a limiting process V̂ (v) with covariance function

                                     Γ̂(v, τ ) = Γ (v, τ ) − ṁ(v, θ0 )0 L(θ0 )ṁ(τ , θ0 ),


                                                              11
as shown in Appendix A.        Next we turn to details of the transformations.                  Section 4.1 discusses a
Khmaladze-type martingale transformation that corrects V̂ (v) for the eﬀect of estimation of θ. Section 4.2
then discusses the problem of obtaining asymptotically distribution free limits for the resulting process.
This problem is straightforward when v is a scalar, but extensions to higher dimensions are somewhat
more involved.


4.1    Khmaladze Transform

The object here is to define a linear operator T V̂ (v) with the property that the transformed process,
W (v) = T V̂ (v), is a mean zero Gaussian process with covariance function Γ(v, τ ). While V̂ (v) has a
complicated data-dependent limiting distribution (because of the estimated θ), the transformed process
W (v) has the same distribution as V (v) and can be handled more easily in statistical applications. Khmal-
adze (1981, 1988, 1993) introduced the operator T in a series of papers exploring limiting distributions of
empirical processes with possibly parametric means.
   When v ∈ R, the Khmaladze transform can be given some intuition. First, note that V (v) has in-
dependent increments ∆V (v) = V (v + δ) − V (v) for any δ > 0. On the other hand, because V̂ (v)
                               P
depends on the limit of n−1/2 nt=1 l (Dt , zt , θ0 ) this process does not have independent increments. Defin-
            ³            ´
ing Fv = σ Ṽ (s), s ≤ v , we can understand the Khmaladze transform as being based on the insight that,
                                                                ³           ´
because V̂ (v) is a Gaussian process, ∆W (v) = ∆V̂ (v) − E ∆V̂ (v) |Fv has independent increments. The
Khmaladze transform thus removes the conditional mean of the innovation ∆V̂ . When v ∈ Rk with k > 1
as in our application, this simple construction can not be trivially extended because increments of V (v) in
diﬀerent directions of v are no longer independent. As explained in Khmaladze (1988), careful specification
of the conditioning set Fv is necessary to overcome this problem.
   Following Khmaladze (1993), let {Aλ } be a family of measurable subsets of [−∞, ∞]k , indexed by
λ ∈ [−∞, ∞] such that A−∞ = ∅, A∞ = [−∞, ∞]k , λ ≤ λ0 =⇒ Aλ ⊂ Aλ0 and Aλ0 \Aλ → ∅ as λ0 ↓ λ.
Define the projection π λ f (v) = 1 (v ∈ Aλ ) f (v) and π ⊥                             ⊥
                                                             λ = 1− π λ such that π λ f (v) = 1 (v ∈
                                                                                                   / Aλ ) f (v). We
                                                     R
then define the inner product hf (.), g (.)i := f (u)g(u)0 dH (u) and the matrix
                                D                          E Z
                         Cλ = π ⊥    ¯l(., θ), π ⊥ ¯l(., θ) = π ⊥¯l(u, θ)π ⊥¯l(u, θ)0 dH(u).
                                   λ             λ              λ          λ


We note that the process V (v) can be represented in terms of a Gaussian process b(v) with covariance
                                           R
function H(v ∧ τ ) as V (φ(., v)) = V (v) = φ(u, v)db(u). Using the same notation the transformed statistic
W (v) is given by
                                                   Z
                                                       ­            ¡            ¢®
                    T V̂ (v) := W (v) = V̂ (v) −        φ (., v) , d π λ ¯l(., θ) Cλ−1 V̂ (π ⊥ ¯
                                                                                             λ l(., θ))             (7)




                                                          12
       ¡            ¢
where d π λ ¯l(., θ) is the total derivative of π λ ¯l(., θ) with respect to λ and

                                         ¯l(v, θ) =              1             ∂p(v2 , θ)
                                                                            2             .
                                                      (p(v2 , θ) − p(v2 , θ) )    ∂θ

We show in Appendix A that the process W (v) is zero mean Gaussian and has covariance function Γ(v, τ ).
   The transform above diﬀers from that in Khmaladze (1993) in that ¯l(v, θ) is diﬀerent from the optimal
score function that determines the estimator θ̂. The reason is that here H(v) is not a conventional cumu-
lative distribution function as in these papers. It should also be emphasized that unlike Koul and Stute
(1999), we make no conditional homoskedasticity assumptions.                       9

       To construct the test statistic proposed in the theoretical discussion we must deal with the fact that
the transformation T is unknown and needs to be replaced by an estimator Tn where
                                            Z µZ                               ¶
                                                         ¡            ¢
            Ŵn (v) = Tn Vn (v) = V̂n (v) −      φ(u, v)d π λ ¯l(u, θ) dĤn (u) Ĉλ−1 V̂n (π ⊥ ¯
                                                                                             λ l(., θ̂))                       (8)

                                  Pn                 ³               ´
with V̂n (π ⊥ ¯            −1/2          ⊥¯
            λ l(., θ̂)) = n            π
                                    s=1 λ l(Us , θ̂)  Ds − p(zs , θ̂)  and the empirical distribution Ĥn (v) is defined
in Appendix B.
       The transformed test statistic depends on the choice of the sets Aλ . Here we focus on sets Aλ =
[−∞, λ] × [−∞, ∞]k−1 , which turns out to be convenient in this context. Denote the first element of yt by
y1t . Then (8) can be expressed more explicitly as
                                   "                                                                                 #
                               Xn
                                               ∂p(z  , θ̂)            Xn                            ³               ´
                                                   t
     Ŵn (v) = V̂n (v) − n−1/2      φ {Ut , v}      0      Ĉy−1
                                                               1t
                                                                  n−1     1 {y1s > y1t } ¯l(Us , θ̂) Ds − p(zs , θ̂)           (9)
                               t=1
                                                 ∂θ                   s=1

Critical values for Ŵn (v) can be computed numerically as follows: Draw Ut∗ randomly from the empirical
distribution F̂u (v). Let ε∗t be an iid(0,1) random variable independent of Ut∗ . Then
                                                                    n
                                                                    X
                                              Wn∗ (v)   =n   −1/2
                                                                          ε∗t 1 {Ut∗ ≤ v}                                    (10)
                                                                    t=1

has the same limiting distribution as Ŵn (v) by standard arguments (see Van der Waart and Wellner,
1996). Critical values for Ŵn (v) can therefore be computed by repeatedly drawing from the distribution
of Wn∗ (v). In Section 5 we report Monte Carlo results based on critical values obtained numerically from
Wn∗ (v). These results show some size distortions. We therefore turn in the next section to a further
transformation that leads to a distribution free limit for the test statistics.
   9
       Stute, Thies and Zhu (1998) analyze a test of conditional mean specification in an independent sample allowing for
heteroskedasticity by rescaling the equivalent of our m(yt , Dt , zt , θ0 ; v) by the conditional variance. But their approach does
not work for our problem because the relevant conditional variance depends on the unknown parameter θ. Instead of correcting
m(yt , Dt , zt , θ0 ; v) we adjust the transformation T in the appropriate way.


                                                                    13
4.2       Rosenblatt Transform

The implementation strategy discussed above has improved operational characteristics when the data
are modified using a transformation proposed by Rosenblatt (1952). This transformation produces a
multivariate distribution that is i.i.d on the k-dimensional unit cube, and therefore leads to a test that
can be based on standardized tables such as Table 2. Let Ut = [Ut1 , ..., Utk ] and define the transformation
w = TR (v) component wise by w1 = F1 (v1 ) = P (Ut1 ≤ v1 ) , w2 = F2 (v2 |v1 ) = P (Ut2 ≤ v2 |U1t =
v1 ),..., wk = Fk (vk |vk−1 , ..., v1 ) = P (Utk ≤ vk |Utk−1 = vk−1 , ..., Ut1 = v1 ) . The inverse v = TR−1 (w) of this
transformation is obtained recursively as v1 = F1−1 (u1 ) ,
                                                 ¡             ¢
                                       v2 = F2−1 w2 |F1−1 (w1 ) , ....

Rosenblatt (1952) shows the random vector wt = TR (Ut ) has a joint marginal distribution which is uniform
and independent on [0, 1]k .
   Using the Rosenblatt transformation we define
                                              £       £          ¤      ¤
                          mw (wt , Dt , θ|v) = Dt − p( TR−1 (wt ) z , θ) φ(wt , w)
                          £         ¤
where w = TR (v) and zt = TR−1 (wt ) z denotes the components of TR−1 corresponding to zt .
       The null hypothesis is now that E [Dt φ(wt , w)|zt ] = E [φ(wt , w)|zt ] p(zt , θ), or equivalently,

                                                 E [mw (wt , Dt |v)|zt ] = 0.

Also, the test statistic Vn (v) becomes the marked process
                                                    P
                                    Vw,n (w) = n−1/2 nt=1 mw (wt , Dt , θ|w).

       Rosenblatt (1952) notes that tests using TR are generally not invariant to the ordering of the vector
wt because TR is not invariant under such permutations. Of course, our test statistic also depends on the
choice of φ(., .). This sort of dependence on the details of implementation is a common feature of consistent
specification tests. From a practical point of view it seems natural to fix φ(., .) using judgements about
features of the data where deviations from conditional independence are likely to be easiest to detect
(e.g., moments).         In contrast, the wt ordering is inherently arbitrary. As a strategy for dealing with
this arbitrariness, Justel, Pẽna and Zamar (1997) propose the use of tests di indexed by all possible k!
permutations of the elements of wt and consider summary statistics such as maxi di . We investigate the
performance of this strategy in the Monte Carlo and empirical sections below.
       We denote by Vw (v) the limit of Vw,n (v) and by V̂w (v) the limit of V̂w,n (v) which is the process
obtained by replacing θ with θ̂ in Vw,n (v) . Define the transform Tw V̂w (w) as before by10
                                                  Z
                                                     ­                          ®
              Tw V̂w (w) := Ww (w) = V̂w (w) −        φ (., w) , dπ λ ¯lw (., θ) Cλ−1 V̂w (π ⊥ ¯
                                                                                             λ lw (., θ)).         (11)
  10
       For a more detailed derivation see Appendix B.


                                                             14
Finally, to convert Ww (w) to a process which is asymptotically distribution free we apply a modified version
of the final transformation proposed by Khmaladze (1988, p. 1512) to the process W (v). In particular,
using the notation Ww (φ(., w)) = Ww (w) to emphasize the dependence of W on φ, it follows from the
previous discussion that
                                                   ³                   ´
                                     Bw (w) = Ww φ(., w)/(hw (.))1/2
                                              R1      R1                                      £          ¤
is a Gaussian process with covariance function 0 · · · 0 φ(u, w)φ(u, w0 )du, where hw (.) = p( TR−1 (wt ) z , θ)(1−
   £         ¤
p( TR−1 (wt ) z , θ)).
   In practice, wt = TR (Ut ) is unknown because TR depends on unknown conditional distribution func-
tions. In order to estimate TR we introduce the kernel function Kk (x) where Kk (x) is a higher order
kernel satisfying Conditions (9) of Section A.2. A simple way of³ constructing´ higher order kernels is
                                                     P                                     P
given in Bierens (1987). Let Kk (x) = (2π)−k/2 ωj=1 θj |σ j |−k exp −1/2x0 x/σ 2j with ωj=1 θj = 1 and
Pω               2                                        −1/(2+k) ) be a bandwidth sequence and define
   j=1 θ j |σ j | = 0 for = 1, 2, ..., ω − 1. Let mn = O(n

                                                 n
                                                 X
                             F̂1 (x1 ) = n−1           1 {Ut1 ≤ x1 }
                                                 t=1
                                             ..
                                              .  P
                                              n−1 nt=1 1 {Utk ≤ xk } Kk−1 ((xk− − Utk− ) /mn )
                 F̂k (xk |xk−1 , ..., x1 ) =            P
                                                  n−1 nt=1 Kk−1 ((xk− − Utk− ) /mn )

where xk− = (xk−1 , ..., x1 )0 and Utk− = (Utk−1 , ..., Ut1 )0 . An estimate ŵt of wt is then obtained from the
recursions

                                       ŵt1 = F̂1 (Ut1 )
                                              ..
                                               .
                                       ŵtk = F̂k (Utk |Utk−1 , ..., Ut1 ).

We define Ŵw,n (w) = Tw,n V̂w,n (w) where Tw,n is the empirical version of the Khmaladze transform applied
to the vector wt . Let Ŵŵ,n (w) denote the process Ŵw,n (w) where wt has been replaced with ŵt . For a
detailed formulation of this statistic see Appendix B. An estimate of hw (w) is defined as
                                                           ³            ´
                                         ĥw (.) = p(., θ̂) 1 − p(., θ̂) .

   The empirical version of the transformed statistic is
                                        ³                 ´
                   B̂ŵ,n (w) = Ŵŵ,n φ(., w)/ĥw (.)1/2
                                           n
                                           X                  h                       i
                                = n−1/2          ĥw (zt )−1/2 Dt − p(zt , θ̂) − Ân,t φ (ŵt , w)         (12)
                                           t=1


                                                          15
                          Pn                       ³               ´
                                                                     ∂p(zs ,θ̂) −1 ¯
where Ân,s = n−1            t=1 1 {ŵt1 > ŵ s1 }  Dt − p(zt , θ̂)    ∂θ0
                                                                               Ĉŵ1s l(zt , θ̂). Finally, Theorem 7 in Appendix
A formally establishes that the process B̂ŵ,n (v) converges to a Gaussian process with covariance function
equal to the uniform distribution on [0, 1]k .
   Note that the convergence rate of B̂ŵ,n (v) to a limiting random variable does not depend on the di-
                                                                                           £    ¤
mension k or the bandwidth sequence m. Theorem 7 shows that B̂ŵ,n (w) ⇒ Bw (w) on D Υ[0,1] where
                                                       n                   o
Bw (w) is a standard Gaussian process and Υ[0,1] = w ∈ [0, 1]k |w = π x w . It thus follows that trans-
formed versions of the VM and KS statistics converge to functionals of Bw (w). These results can be stated
formally as                                   Z                          Z
                                                        ³          ´2
                                    V Mw =               B̂ŵ,n (w) dw ⇒              (Bw (w))2 dw                         (13)
                                               Υ[0,1]                        Υ[0,1]

and                                                ¯          ¯
                                                   ¯          ¯
                                         KSw = sup ¯B̂ŵ,n (w)¯ ⇒ sup |Bw (w)| .                                           (14)
                                                   v∈Υ[0,1]               v∈Υ[0,1]

Here V Mw and KSw are the VM and KS statistics after both the Khmaladze and Rosenblatt transforms
have been applied to V̂n (v). In practice the integral in (13) and the supremum in (14) can be computed
over a discrete grid. The asymptotic representations (13) and (14) make it possible to use asymptotic
statistical tables. For the purposes of the Monte Carlo below, we computed critical values for the VM
statistic in the special case where φ (., v) = 1 {. ≤ v} (These are reported in Table 2). These critical values
depend only on the dimension k and are thus distribution free.11 Table 2 is also used to construct critical
values in our empirical application in Section 6.


5         Monte Carlo Evidence
We evaluated the performance of our semiparametric tests using a simple data generating process that
nevertheless captures important features of the empirical applications we have in mind. The process is

                                                  yt = βyt−1 + γDt + εt
                                                  Dt = 1 {yt−1 − α + η t > 0} ,

where εt and ηt are independent with εt ∼ N (0, 1) and η t has a logistic distribution. We choose α = 3
which leads to an unconditional probability of Dt = 1 of roughly 5% which is comparable to our empirical
sample. This model has a standard lagged-dependent-variable structure that captures serial correlation in
the outcome. The policy assignment is also correlated with lagged outcomes.
         The simulation used samples of 100 and 200 observations in 500 replications. The reported results are
rejection rates for the test statistics derived above and for a conventional t-test for the significance of γ in
    11
         See Section 5 for a more detailed discussion of how Table 2 was constructed.


                                                                 16
a regression of yt on yt−1 and Dt . To construct the semiparametric test statistics, we used a Logit model
for the propensity score and the test function φ(Ut , v) = 1 {(yt , yt−1 ) ≤ v}.
   Table 1 reports results  for´ several implementations of our semiparametric test. These results are for
                    R³          2
the statistic V M =    V̂n (v) dFu (v) and diﬀer only in the way in which V̂n (.) is implemented and the
method by which critical values were obtained. We choose a bandwidth of m = 10n−1/(2+k) .12
       We begin with statistics and significance levels calculated using the numerical methods to determine
critical values, as described in Section 4.1. In particular, Column (1) in Table 1 reports results for
the statistic Ŵn (v) defined by (9), with critical values obtained by numerical simulation conditional on
the sample as described by equation (10). The test statistic reported here can therefore be written
R³        ´2
   Ŵn (v) dF̂u (v), where F̂u (v) is the empirical distribution of Ut . This statistic relies on the Khmaladze
transformation alone to adjust inference for estimation of the propensity score.
   Test’s based on the asymptotic critical values reported in Table 2 and using the Rosenblatt transfor-
                                                         Rh          i2
mation as in (12), were constructed as follows. Let di =   B̂ŵ,n (w) dw be the statistic based on the i-th
permutation of the elements in Ut before the Rosenblatt transform is applied to Ut . Column (2) in Table 1
reports results for the statistic md ≡ maxi di where the maximum statistic is taken over all permutations
of the elements in Ut and uses critical values from Column (1) of Table 2.13 We use the notation mda to
denote results for the md statistic that are based on asymptotic critical values.
       Column (3) of Table 1 was calculated using upper bounds for the asymptotic critical values of the md
statistic proposed by Justel, Peña and Zamar (1997). We use the notation mdb to denote results for the md
                                                                                   P
statistic that are based on upper bounds. Upper bounds are based on P (md > cα ) ≤ i P (di > cα ) = k!α
such that αmd = α/k! leads to a critical value with P (md > cα/k! ) ≤ α. When α = .05 is the desired
significance level, we use the critical value corresponding to d for k = 2 and 1 − α = .975 in Table 2.
Columns (4) and (5) of Table 1 report corresponding results based on asymptotic critical values for d1 and
d2 . Since in this case Ut = {yt , yt−1 } these two tests are based on the two permutations of Ut , {yt , yt−1 }
and {yt−1 , yt } .
       As predicted by the theoretical discussion, the results in Table 1 show the tests d1 and d2 to have
similar properties, with accurate size at all degrees of serial correlation in yt that we investigated. When
  12
       Experimentation with diﬀerent choices of m indicate that the tests are not very sensitive to this parameter. Nevertheless,
for much smaller values of m such as m = n−1/(2+k) /10 we found that the tests were undersized.
  13
     Note that the asymptotic critical values for di do not depend on the permutation chosen. For this reason we only
distinguish between the maximum statistic md and d in Table 2. Critical values do depend on the dimension k of the vector
Ut . Table 2 was obtained by randomly drawing Ut∗∗ from a Gaussian distribution with a randomly drawn covariance matrix
and then applying the Rosenblatt transform to the generated random variables Ut∗∗ .Note that here the Rosenblatt transform
                                                               −1 Sn    ∗ −1
TR is known because Ut∗∗ is Gaussian. We thus compute d∗∗i = n
                                                                                 ∗∗
                                                                   t=1 εt TR (Ut ) for the i-th permutation of Ut
                                                                                                                  ∗∗
                                                                                                                     where
εt is iid standard Gaussian. The sample size is set to n = 100 and 100, 000 replications of d∗∗
                                                                                             i are used to approximate the

distributions of md and d.



                                                                17
compared with a t-test, reported in Column (6), which in this scenario is both asymptotically optimal and
has good finite sample size properties, the tests di fare quite well. It is especially encouraging to see that
the semiparametric test statistics have good power properties, though these naturally fall somewhat short
of the power for the parametric t-test.
    The semiparametric tests have most accurate size when the asymptotic critical values for the statistic
md are used, reported in Column (2). The resulting test is only slightly oversized for most values of β.
Power is also quite good in this case, and the mda test is at least as powerful as the individual statistics,
di , although the diﬀerences are very small. This may be due in part to small size distortions of the mda
test. The mdb test based on upper bound critical values, reported in Column (3), is somewhat undersized
for models with larger values of β and consequently has less power. This version of the test therefore leads
to a conservative test of the null hypothesis.
    Finally, the version of the test based on simulated critical values conditional on the sample in Column
(1) has size distortions somewhat larger than the distortion for the individual tests di based on asymptotic
critical values in Columns (4) and (5) when β is low to moderate, i.e. β ≤ .5. At the same time, with
simulated critical values, power is somewhat lower, a feature which clearly makes this implementation less
attractive. Moreover, when β = .9 this version of the test displays fairly large size distortions, unlike
the other implementations of the test. Overall, the mda test using asymptotic critical values seems to
provide the best combination of accuracy and power. The mdb test using upper bound critical values leads
to a more conservative version of the test. We therefore used both test statistics for the empirical work
described in the next section. At least in our application we found the diﬀerences to be minor with mda
only leading to slightly more significant results.


6    Causal Eﬀects of Monetary Policy Shocks Revisited
In an influential study of the eﬀects of monetary policy, Romer and Romer (1989) constructed a monetary
policy shock variable derived using what they call the narrative approach, inspired by Friedman and
Schwartz’ classic monetary history. The narrative approach uses Federal Open Market Committee minutes
to construct a dummy variable, Dt , to indicate episodes where the Fed took a marked anti-inflationary
stance. Thus, Dt indicates periods that are now known as "Romer dates." The Romer dates mark Fed
decisions to change short term interest rates, discount rates, or reserve requirements. There were six such
dates in the original Romer sample, running from 1948-1987, with a 7th date added when the sample was
extended through 1991 in Romer and Romer (1994). The link between Romer Dates and later economic
activity provides a natural setting for propensity-score based estimates of the eﬀects of monetary policy.
    The key identifying assumption in the Romer papers is that, conditional on lagged outcomes, the Romer
dates are as good as randomly assigned in the sense that regressions of future output growth on (lagged)

                                                     18
dummies for these dates have a causal interpretation. A substantial literature has developed challenging
this premise. Examples include Leeper (1997), who argues the Romer dates are determined in part by the
Fed’s (nonlinear) forecast of future output and Shapiro (1994) who similarly argues that monetary policy
is forward-looking in a way that induces omitted variables bias in the Romers’ regressions. Both of these
critiques are consistent with the modeling strategy outlined here in that we focus attention on models
for the policy-determination process. Romer and Romer (1997) defend the notion that, after appropriate
conditioning, the dates can be seen as exogenous. Romer and Romer (2004) provide new estimates of the
dates of monetary shocks using a somewhat more systematic version of the narrative approach. We focus
on the original Romer dates because they correspond to our binary-policy-variable setup, though in future
work we hope to address the more general policy evaluation problem.
       Our re-analysis of the Romer data begins with Granger-style regressions of the growth of industrial
production (IP) on contemporaneous and lagged dummies for Romer dates (”Romer dummies”), controlling
for lags of IP growth. This is similar to the Romer’s econometric approach, with two modifications. First,
we aggregate monthly data to the quarterly level since there is probably little additional information in
the higher-frequency series. Romer quarters are identified as quarters with a Romer month.14 This also
serves to increase the proportion of the sample coded as a Romer date, making it easier to estimate the
policy propensity score. Second, the Romers assess the role of monetary policy variables by looking at
the impulse response function, while we focus on F-statistics for the Romer dummies.
       Controlling for 8 lags of output and no other covariates, a test for the joint significance of the Romer
dummies generates a p-value of about .01. This result, consistent with the Romers’ original findings, can
be seen in the first two columns of Table 3.15 We report both robust F-statistics based on White standard
errors as well as non-robust standard errors. Significance levels using robust standard errors tend to be
higher, especially in models with additional covariates. Non-robust standard errors may be more reliable
in these cases since increased precision with robust standard errors is often an artifact of finite sample bias
and size distortion (Chesher and Jewitt, 1987).
       Much of the debate over the Romer’s empirical approach focuses on whether it is enough to control
for lagged output when assessing the causal eﬀect of Romer dates on output. An especially important
  14
       Quarterly series for all variables were constructed by averaging monthly series. Growth rates were constructed as the first
diﬀerences of the log of the quarterly averages. All quarterly series were deseasonalized by recursive regressions on quarter
dummies.       The regressions are recursive in that coeﬃcients were estimated using only information available prior to each
observation.     This procedure allows us to ignore the estimation error arising from this de-seasonalization. The series used
in this section are listed in the last table. The original monthly series were obtained from the Wharton/DRI Global Insight
service. Although standard and widely available, these series diﬀer somewhat from the Romers’ original as they have since
been revised. We us the 1952-91 sample used by Shapiro (1994).
  15
     The specification includes 12 lagged Romer dummies (3 years worth). This corresponds to the Romers’ original equation
which included 3 years worth of lagged Romer dummies.



                                                                 19
control variable in this context is inflation, since the Fed presumably looks at this when making monetary
policy decisions. On the other hand, inflation clearly responds to monetary policy and may therefore not
be an exogenous control. This possibility was highlighted in the discussion of Granger-testing pitfalls in
Example 3.         To explore the consequences of adding inflation controls, we fit a version of the Romer’s
principal estimating equation after adding eight lags of inflation to the list of covariates. These results,
reported in Columns 3 and 4 of Table 3, show that the addition of inflation controls reduces the significance
level of the Romer dummies somewhat, though some eﬀects are still significant. Similarly, adding controls
for lagged unemployment rates further reduces the significance of the joint F test for the Romer dummies.
These results appear in columns 5 and 6 of the table. The p-value for the joint significance of the Romer
dummies becomes .09 for the non-robust version of the F-statistic.
       Finally, we explore Sims-type semiparametric tests of conditional independence in this context using
the transformed VM and KS statistics described above.                    For purposes of comparison, results from a
parametric analog of the semiparametric tests are also reported. The semiparametric test results are for
tests of conditional distributional independence where φ(Ut , v) = 1 {Ut ≤ v} and the policy propensity
score was estimated using Logit, as for the Monte Carlos in the previous section. The semiparametric tests
were implemented using the same bandwidth as used for the simulations.16
       The foundation of our semiparametric testing procedure is a parsimonious model for the policy propen-
sity score. Following Shapiro (1994), we used a parsimonious model based on the notion, also discussed
by Romer and Romer (2004), that the systematic component of Fed policy decisions is driven by forecasts
of inflation and unemployment. In particular, we first fit a vector autoregressive model (VAR) to unem-
ployment and inflation. We then used predictions up to 100 periods ahead to construct a forecast of the
”present value” of future inflation and unemployment in each period, similar to the present value forecasts
used by Shapiro. The idea is that the Fed sets monetary policy based on this measure, or other summary
forecasts that are highly correlated with this one. A detail here, however, is that because Shapiro’s fore-
casting parameters were estimated on the entire sample, the resulting present value measures are not part
of the relevant information set of the Fed. To avoid this conceptual ( if not practical) problem, we also used
a true out-of-sample forecasting procedure to construct the present value measures by estimating the VAR
parameters on the sample prior to the forecast period only. The present value inflation and unemployment
forecasts are the main covariates in the model for the policy propensity score, though some estimates also
include lagged dependent variables.17
  16
       We have experimented with diﬀerent choices of the bandwidth, but found that the results are not sensitive to the choice
of m.
  17
     Lagged Romer dummies were also used as explanatory variables in the forecasting equations. The discount rate was set
at 2%. The forecasting equation has eight lags for inflation and unemployment and 16 lags for the Romer dummies. When
constructing out-of-sample forecasts, lag length for all covariates was reduced to four periods at the beginning of the sample.



                                                               20
       The semiparametric mdb tests were constructed for three specifications, with results reported in columns
1-3 of Table 4. The first two specifications use full-sample and out-of-sample forecasts. The third speci-
fication adds lagged dependent variables to the model using out-of-sample forecasts. Results in diﬀerent
rows are for diﬀerent lead lengths, e.g., causal eﬀects on output growth one period ahead, two periods
ahead, and so on. We look at each lead one at a time because the number of permutations required for
the Rosenblatt transform grows rapidly with the dimensionality of a joint test. The upper bound method
was used to obtain critical values for the semiparametric tests.18
       Results from the first specification oﬀer some evidence of a money-output relation at some lags. In
particular, semiparametric tests reject non-causality at one, three to five, seven and eight quarter leads.
These results may be misleading because full sample estimation of zt invalidates the semiparametric tests.
Significance levels are reduced considerably when out-of-sample forecasts are used to construct control
variables, but there are still rejections at the third and eight quarter leads and a weakly significant result
at the first lead. Adding lagged output growth does not change these findings, which can be seen in
column 3. In Table 5 we report the same statistic but now judged against asymptotic critical values from
Column (3) of Table 2. The results are essentially the same except that the first lead is now statistically
significant. On balance, it seems fair to say that a forward-looking Sims test provides weak support the
Romers’ original conclusion, at least as far the correlation between Romer dates and future output growth
as concerned. Not surprisingly, however, given the paucity of Romer dates that form the essence of the
"natural experiment" that lies behind this inquiry, the evidence for money-output causality can fairly be
described as "mixed."19
       To gauge the extent to which our semiparametric test results have reduced power relative to similar
parametric tests, we added future output growth to the present value variables (and possibly lagged
output growth variables) already in the policy propensity score. The significance level of future output
variables in the policy propensity score provides a parametric Sims-type test of a particular version of the
conditional independence hypothesis that is at the heart of the semiparametric tests. In particular, we
report significance levels for the coeﬃcient θ3 in the following choice equation of a Logit model for Fed
  18
       The p-values reported in the table were obtained by translating the p-values in Table 2 into p-values for the upper bound
test by multiplying α by k!. To achieve a 5% level of significance and with k = 3, this implies a critical value corresponding to
1 − α = .9916 needs to be used in Column (4) of Table 2. In Table 4 we report intervals for p-values. These are constructed
translating the interval of critical values in which the test statistic falls into corresponding significance values. For example if
md = .4 then the interval of critical values is [.33, .42] from Column (4) of Table 2 with corresponding α ∈ [.01, .025]. Because
k! = 6 this translates into an eﬀective α that is contained in [.06, .15].
  19
     The Romer’s original findings showed statistical significance for Romer dummies at particular groups of lags in Granger-
style regressions. These eﬀects were large enough to induce a clear shift in the impulse response function, a relation analogous
to the one checked by our forward-looking Sims tests.




                                                                21
action
                              Dt = 1 {θ0 + θ1 upv        pv
                                               t + θ 2 π t + θ 3 Yt+j + εt > 0} .
                    0
where zt = [upv    pv
             t , π t ] contains the present value measures for unemployment and inflation discussed earlier.
The variable Yt+j is the change in industrial production at lead j. Under the null hypothesis, the parameter
θ3 should be zero. The parametric version of this test has the advantage that, subject to having correctly
specific the policy propensity score, the model is correct under the null hypothesis of non-causality. On
the other hand, this specification need not be correct under the alternative, even if the policy propensity
score is correctly specified, and may therefore have reduced power in some directions.
    As it turns out, results from the parametric analog of our semiparametric tests are generally in line
with the semiparametric results, especially for the out-of-sample forecast case. This can be seen in columns
4-6 of Table (4). In particular, there is some evidence of causality at the first and eighth lead, while two
of the specifications also show something at an intermediate lead, in this case the third. The fact that
the semiparametric and parametric models generate results with the same patterns of significance suggests
power considerations do not substantially handicap the semiparametric results.


7    Conclusions and Directions for Further Work
This paper develops a causal framework for time series data using the notion of potential outcomes com-
monly used in cross-sectional evaluation research. This leads to a definition of causality similar to the one
proposed by Sims. For models with covariates, Sims causality is not the same as Granger causality, and
the distinction between these two concepts turns out to be conceptually important. In particular, Granger
causality may confuse system dynamics with the causal eﬀects of isolated policy actions. In contrast, Sims
causality hones in on isolated policy shocks relative to a well-defined counter-factual baseline.
    A major part of our agenda is to develop a causality test that focuses on the policy assignment
mechanism, which we call the policy propensity score. In particular, we develop a new semiparametric test
of conditional independence, valid under the selection-on-observables null hypothesis that is at the heart
of much of the empirical work on time series causal eﬀects. A major advantage of this approach is that it
does not require researchers to model the process determining the outcomes of interest. The resulting tests
have power against all alternatives but are necessarily joint tests of the null of no causality and correct
specification of the policy propensity score.
    The development here is limited to binary treatments but it seems likely our approach can be extended
to multivalued treatments, perhaps along the lines explored in recent work by Hirano and Imbens (2004).
Of course, it is an open question whether the technical machinery used here, such as the Khmaladze
transform, transfers to the more general setting. This is a question we hope to address in future work.


                                                      22
We also plan to explore the question of whether tests for conditional mean and second-order moment
independence have advantages over omnibus tests.




                                                   23
A     Asymptotic Critical Values
This Appendix provides formal results on the distribution of the test statistics described above and forms
the basis for the construction of asymptotic critical values. The theorems and proofs use the additional
notation outlined below.

A.1    Additional Notation and Assumptions

We focus initially on the process Vn (v) and the associated transformation T. Results for Vw,n (w) and the
transformed process Tw Vw,n (w) then follow as a special case.
    Let χt = [yt0 , zt0 , Dt ]0 be the vector of observations. Assume that {χt }∞  t=1 is strictly stationary with
                                      ¡ k+1 k+1 ¢           k+1
values in the measurable space R , B                where B     is the Borel σ-field on Rk+1 and k is fixed with
2 ≤ k < ∞. Let Al1 = σ (χ1 , ..., χl ) be the sigma field generated by χ1 , ..., χl . The sequence χt is β-mixing
or absolutely regular if
                                         "                         #
                                                 ¯ ³      ´      ¯
                                                 ¯      l        ¯
                           β m = sup E       sup ¯Pr A|A1 − P (A)¯ → 0 as m → ∞.
                                 l≥1     A∈A∞
                                            l+m

A sequence is called α-mixing if
                             ⎡                                              ⎤
                  αm = sup E ⎣           sup      |Pr (A ∩ B) − P (A) P (B)|⎦ → 0 as m → ∞
                           l≥1    A∈Al1 ,B∈A∞
                                            l+m


and it is well known that αm ≤ β m .

Condition 2 Let χt be a stationary, absolutely regular process such that for some 2 < p < ∞ the β-mixing
coeﬃcient of χt satisfies mp/(p−2) (log m)2(p−1)/(p−2) β m → 0.

Condition 3 Let Fu (u) be the marginal distribution of Ut . Assume that Fu (.) is absolutely continuous
with respect to Lebesgue measure on Rk and has a density fu (u)

Condition 4 The function φ(., .) belongs to a VC subgraph class of functions with envelope M (χt ) such
that E |M (χt )|2+δ < ∞ for some δ > 0.

    We note that |m(yt , Dt , zt , θ0 |v)| ≤ 2 for φ(., v) = 1 {. ≤ v} such that by Pollard (1984) Theorem II.25,
mv (Wt ) = m(yt , Dt , zt , θ0 |v) is a VC subgraph class of functions indexed by v with envelope 2.

Condition 5 Let H(v) be as defined in (6) . Assume that H(v) is absolutely continuous in v with respect
to Lebesgue measure and for all v, τ such that v ≤ τ with vi < τ i for at least one element vi of v it follows
that H(v) < H(τ ). Let h(v) = ∂ k H(v)/∂v1 ...∂vk and assume that h(v) > 0 for all v ∈ Rk .

Remark 1 A suﬃcient condition for Condition (5) is that 0 < p(zt , θ0 ) < 1 almost surely.

                                                        24
A.2     Limiting Distributions

Let D [−∞, ∞]k be the space of functions that are continuous from the right with left limits (Cadlag)
mapping [−∞, ∞]k → R. We consider weak convergence on D [−∞, ∞]k equipped with the sup norm.
Here [−∞, ∞]k denotes the k-fold product space of the extended real line equipped with the metric q(v, τ ) =
³P                          ´1/2
   k                      2
   i=1 |Φ(vi ) − Φ(τ i )|        where Φ is a fixed, bounded and strictly increasing function. It follows that
                                                           n                      o
[−∞, ∞]k is totally bounded. The function space F = m(., v)|v ∈ [−∞, ∞]k of functions m indexed by
v then is a subset of the space of all bounded functions on [−∞, ∞]k denoted by l∞ ([−∞, ∞]k ).

Proposition 2 Assume that Conditions 2, 3 and 5 are satisfied. Let vi ∈ [−∞, ∞]k for i = 1, ..., s be a
finite collection of points. Then, for all finite s, Vn (v1 ) , ...., Vn (vs ) converges in distribution to a Gaussian
limit with mean zero and covariance function Γ(vi , vj ). Moreover, Vn (v) converges in D [−∞, ∞]k to a
Gaussian process V (v) with covariance kernel Γ(v, τ ) with v, τ ∈ [−∞, ∞]k and V (−∞) = 0, H(v) is
positive with H(v) increasing in v.

     Proof of Proposition 2. As noted before, under H0 , mv (χt ) is a martingale diﬀerence sequence such
that E (mv (χt )|zt ) = 0. Let λ = (λ1 , ..., λs )0 with kλk = 1. For finite dimensional convergence we apply
Corollary 3.1 of Hall and Heyde (1980) to Yt = λ1 mv1 (χt ) + λ2 mv2 (χt ) + ... + λs mvs (χt ). Then, clearly Yt
                                                             √
is also a martingale diﬀerence sequence. Consider Ynt = Yt / n. Then, for all ε > 0,
              X ¡                             ¢ X ¡ 2 © P                 √ ª          ¢
                 E Ynt 2
                         1 {|Ynt | ≥ ε} |At−1
                                          1    ≤ E Ynt 1 2 i |λi | ≥ nε |At−1       1    → 0 a.s.
                t                                        t
          2+δ
because EYnt  is bounded for some δ > 0. Also,
X                     n
                      X
      £ 2 t−1 ¤          £          ¤
     E Ynt |A1  = n−1   E Yt2 |At−1
                                1
 t                            t=1
                             n
                             X       h                                                                                                 i
                    = n−1           E p(zt , θ0 ) (1 − p (zt , θ0 )) (λ1 φ (ut , v1 ) + λ2 φ (ut , v2 ) + ... + λs φ(ut , vs ))2 |At−1
                                                                                                                                   1
                              t=1
                         p   X
                         →         λi λj Γ(vi , vj )
                             i,j

where the last line is a consequence of Theorem 2.1 in Arcones and Yu (1994). By the Cramer-Wold theorem
this establishes finite dimensional convergence. The functional central limit theorem again follows from
Theorem 2.1 in Arcones and Yu (1994).
     The next proposition establishes a linear approximation to the process V̂n (v) evaluated at the estimated
parameter value θ̂. The fact that l (Dt , zt , θ0 ) is a martingale diﬀerence sequence is critical to the develop-
ment of a distribution free test statistic. The next condition states that the propensity score p(zt , θ) is the
correct parametric model for the conditional expectation of Dt and lists a number of additional regularity
conditions.

                                                              25
Condition 6 Let θ0 ∈ Θ where Θ ⊂ Rd is a compact set and d < ∞. Assume that E [Dt |zt ] = p(zt |θ0 )
and for all θ 6= θ0 it follows E [Dt |zt ] 6= p(zt |θ). Assume that p(zt |θ) is diﬀerentiable a.s. for θ ∈
{θ ∈ Θ| kθ − θ0 k ≤ δ} := Nδ (θ0 ) for some δ > 0. Let N(θ0 ) be a compact subset of the union of all
neighborhoods Nδ (θ0 ) where ∂p(zt |θ)/∂θ, ∂ 2 p(zt |θ)/∂θi ∂θj exists and assume that N (θ0 ) is not empty. Let
∂pi (zt |θ)/∂θ be the i-th element of the vector of partial derivatives ∂p(zt |θ)/∂θ and let ¯li (zt , θ) be the i-th
element of ¯l (zt , θ) . Assume that there exists a function B(x) and a constant α > 0 such that
                                 ¯                             ¯        °       °
                                 ¯∂pi (x|θ)/∂θ − ∂pi (x|θ0 )/∂θ¯ ≤ B(x) °θ − θ0 °α ,
¯ 2                                      ¯        °       °       ¯                              ¯        °       °
¯∂ p(x|θ)/∂θi ∂θj − ∂ 2 p(x|θ)/∂θi ∂θj ¯ ≤ B(x) °θ − θ0 °α and ¯∂ ¯li (x|θ)/∂θ − ∂ ¯li (x|θ0 )/∂θ¯ ≤ B(x) °θ − θ0 °α
for all i and θ, θ0 ∈ int N (θ0 ), E |B(zt )|2+δ < ∞, E |∂pi (zt |θ0 )/∂θ|4+δ < ∞,
                                       h                                    i
                                     E (p(zt , θ0 ) (1 − p(zt , θ0 )))−(4+δ) < ∞

and                           ¯                                                     ¯ 4+δ
                              ¯                                                     ¯ 2
                            E ¯(∂pi (zt |θ0 )/∂θ)2 / (p(zt , θ0 ) (1 − p(zt , θ0 )))¯     <∞

for all i and some δ > 0.

Remark 2 By Pakes and Pollard (1989, Lemma 2.13) the uniform Lipschitz condition for the derivatives
∂p(zt |θ)/∂θ
       ³ √ guarantees  that the functions ∂p(zt |θ)/∂θ indexed by θ form a Euclidian class for the envelope
                    °       °´α
                    °
B(zt ) 2 d supN(θ0 ) θ − θ 0°
                                + |∂pi (zt |θ0 )/∂θ| .

Condition 7 Let
                                                       (Dt − p(zt , θ)) ∂p (Dt |zt , θ) /∂θ
                               l (Dt , zt , θ) = Σ−1
                                                  θ                                                             (15)
                                                        p (Dt |zt , θ) (1 − p (Dt |zt , θ))
where                                 ∙                                              ¸
                                   ∂ log p (Dt |zt , θ) /∂θ∂ log p (Dt |zt , θ) /∂θ0
                             Σθ = E                                                    .      (16)
                                          p (Dt |zt , θ) (1 − p (Dt |zt , θ))
Assume that Σθ is positive definite for all θ in some neighborhood N ⊂ Θ such that θ0 ∈ int N and
0 < kΣθ k < ∞ for all θ ∈ N. Let li (Dt , zt , θ) be the i-th element of l (Dt , zt , θ) . Assume that there
                                                              °                             ¡          ¢     °
exists a function B(x1 , x2 ) and a constant α > 0 such that °∂li (x1 , x2 , θ) /∂θj − ∂li x1 , x2 , θ0 /∂θj ° ≤
      °      °α
B(x) °θ − θ0 ° for all i and θ, θ0 ∈ int N , EB(zt ) < ∞ and E |l (Dt , zt , θ)| < ∞ for all i.

Proposition 3 Assume that Conditions 2, 3,4, 5, 6 and 7 are satisfied. Then
                          °                                                    °
                          °                                n
                                                           X                   °
                          °                                                    °
                   sup °V̂n (v) − Vn (v) + ṁ(v, θ0 )n−1/2    l (Dt , zt , θ0 )° = op (1)                       (17)
                v∈[−∞,∞]k
                          °                                                    °
                                                                         t=1

and if l (Dt , zt , θ0 ) is as defined in 15 and 16 then V̂n (v) converges weakly in D[ − ∞, ∞]k equipped
with the sup norm to a limiting Gaussian process with mean zero and covariance function Γ̂(v, τ ) =
Γ (v, τ ) − ṁ(v, θ0 )L(θ0 )ṁ(τ , θ0 )0 where L(θ0 ) = Σ−1
                                                         θ0 defined in 16.


                                                             26
                                                                               Pn h                        i
   Proof of Proposition 3.          Note that V̂n (v) − Vn (v) = n−1/2          t  p(z  ,
                                                                                       t 0θ ) − p(z t , θ̂)  φ(Ut , v) such
that we can approximate
                                        ³        ´0 1 Xn ∙                           ¸
                                          1/2              ∂p(zt , θn ) ∂p(zt , θ0 )
                 V̂n (v) − Vn (v) = n    θ̂ − θ0                        −              φ(Ut , v)
                                                    n t       ∂θ               ∂θ
                                          ³        ´0 1 X
                                                        n
                                                           ∂p(zt , θ0 )
                                    +n1/2 θ̂ − θ0                       φ(Ut , v)
                                                      n t      ∂θ
                   °        °                                             h                   i
                   °        °
where kθn − θ0 k ≤ °θ̂ − θ0 ° by the mean value theorem. Let ṁ (θ, v) = E ∂p(z
                                                                             ∂θ
                                                                               t ,θ)
                                                                                     φ(Ut , v)  and ṁ(Ut , θ, v) =
∂p(zt ,θ)
  ∂θ φ(Ut , v)   − ṁ (θ, v) . From Pakes and Pollard (1989, Lemmas 2.13 and 2.14) and Condition (6)
it follows that ṁ(., θ, v) is a Euclidian class of functions indexed on N (θ0 ) × [−∞, ∞]k with envelope
        ³ √            °       °´α
(B(zt ) 2 d supN(θ0 ) °θ − θ0 ° + |∂pi (zt |θ0 )/∂θ|)M (χt ). Then
       ° n ∙                                       °
       ° 1 X ∂p(z , θ ) ∂p(z , θ ) ¸               °
       °            t n           t 0              °
       °                 −               φ(Ut , v)°
       °n          ∂θ           ∂θ                 °
             t
                   ° n                                    °
                   °1 X                                   °
                   °                                      °
     ≤    sup sup °      [ṁ(zt , θ, v) − ṁ(zt , θ0 , v)]° + sup kṁ(θ, v) − ṁ(θ0 , v)k + op (1) = op (1)
       kθ−θ0 k≤δ v ° n                                    ° kθ−θ0 k≤δ
                       t
                        ° P                                    °
since supkθ−θ0 k≤δ supv ° n1 nt [ṁ(zt θ, v) − ṁ(zt , θ0 , v)]° = op (1) by Lemma 2.1 of Arcones and Yu (1994).
This completes the proof of 17.
   The second part of the result follows from the fact that the class of functions F = mv (.)+ṁ (θ, v) l(., ., θ0 )
is a Euclidian class by Lemma 2.14 of Pakes and Pollard (1989). Since mv (Xt ) + ṁ (θ, v) l(Dt , zt , θ0 ) is
a martingale diﬀerence sequence with respect to the filtration At−1
                                                                1   finite dimensional convergence to a
Gaussian random variable with zero mean and covariance function Γ̂(v, τ ) follows from the martingale
CLT (Hall and Heyde, Corollary 3.1) and the fact that 0 < kΣθ0 k < ∞ by Condition 7. Convergence to a
weak limit in D [−∞, ∞]k then follows again by Lemma 2.1 of Arcones and Yu (1994).
   We now establish that the process T V̂ (v), defined in (7) is zero mean Gaussian with covariance function
Γ(v, τ ). This establishes that the process T Ṽ (v) = W (v) can be transformed to a distribution free process
via Lemma 3.5 and Theorem 3.9 of Khmaladze (1993).
   In order to define the transform T we choose a grid −∞ = λ0 < λ1 < ... < λN = ∞ on [−∞, ∞] , let
∆π λi = π λi+1 − π λi and set
                                         N
                                         X ­                         ®
                             cN (V ) =      φ (., v) , ∆π λi ¯l(., θ) Cλ−1
                                                                         i
                                                                           V (π ⊥  ¯
                                                                                λi l(ϑ, θ)).                          (18)
                                         i=1

This construction is the same as in Khmaladze (1993) except that we work on [−∞, ∞] rather than [0, 1] .
In Proposition (4) we show that cN (V ) converges as N → ∞ and maxi (Φ(λi+1 ) − Φ (λi )) → 0. Let the
                                       R­                        ®      ¡           ¢
limit of cN (V ) be denoted as c(V ) =   φ (., v) , dπ λ ¯l(., θ) Cλ−1 V π ⊥ ¯
                                                                           λ l(., θ)


                                                           27
Condition 8 Let {Aλ } be a family of measurable subsets of [−∞, ∞]k , indexed by λ ∈ [−∞, ∞] such that
A−∞ = ∅, A∞ = [−∞, ∞]k , λ ≤ λ0 =⇒ Aλ ⊂ Aλ0 and Aλ0 \Aλ → ∅ as λ0 ↓ λ. Assume that the sets
{Aλ } form a V-C class (polynomial class) of sets as defined in Pollard (1984, p.17). Define the projection
π λ f (v) = 1 (v ∈ Aλ ) f (v) and π ⊥                        ⊥
                                    λ = 1− π λ such that π λ f (v) = 1 (v ∈  / Aλ ) f (v). We then define the inner
                         R           0
product hf (.), g(.)i := f (u)g(u) dH(u) and the matrix
                                  D                      E Z
                                      ⊥¯        ⊥¯               ¯        ⊥¯
                            Cλ = π λ l(., θ), π λ l(., θ) = π ⊥                    0
                                                               λ l(u, θ)π λ l(u, θ) dH(u).


Assume that hf (v), π λ g(v)i is absolutely continuous in λ and Cλ is invertible for λ ∈ [−∞, ∞).
                                                   n                       o
Proposition 4 Assume condition 8 holds. Define Υx = v ∈ [−∞, ∞]k |v = π x v for some x < ∞. Let
cN (v) be defined as in 18. Then cN (v) converges with probability 1 to c(v) for all v ∈ Υx . Let T V̂ (v) be
as defined in 7. Then T V̂ (v) is a Gaussian process with zero mean and covariance function Γ(v, τ ) for all
v, τ ∈ Υx .

    Proof of Proposition 4. The proof of this result follows closely Khmaladze (1993) with the necessary
adjustments pointed out. First, let V (v) be a Gaussian process on [−∞, ∞]k with zero mean and covariance
function Γ(v, τ ) and V (−∞) = 0. See Kallenberg (1997, p. 201) for the construction of such a process.
Then, V (π ⊥ ¯l(., θ)) is a process with trajectories that are continuous in λ by essentially the same argument
              λ
as in Lemma 3.2 of Khmaladze. To see this fix α ∈ Rk such that α0 V (π ⊥       ¯
                                                                             λ l(., θ)) is a Wiener process on
[−∞, ∞] with mean zero, α0 V (π ⊥ ¯l(., θ)) = 0 and variance α0 Cλ α with almost all trajectories continuous in
                                     ∞
λ on [−∞, ∞]. To show that cN (v) → c(v) almost surely we adapt the proof of Lemma 3.3 of Khmaladze
(1993). As there, define ρ1 (ξ) = |ξ 1 | + ... + |ξ k | for any vector ξ = (ξ 1 , ..., ξ k ) ∈ Rk and ρ∞ (ξ) = maxi |ξ i | .
         ­              ®
Set ξ = φ, ∆π µ ¯l(., θ) and η (µ, λ) = Cµ−1 V (π ⊥       ¯           −1     ⊥¯
                                                        µ l(., θ)) − Cλ V (π λ l(., θ)). By Condition 8 the matrix Cλ
is invertible on [−∞, ∞) and C −1 is continuous in λ. Then, since V (π ⊥ ¯l(., θ)) is continuous in λ almost
                                     λ                                              λ
surely, we have
                                                 sup        ρ∞ (η (µ, λ)) → 0
                                            |Φ(λ)−Φ(µ)|<δ
                                              λ,µ∈[−∞,x]

with probability 1 for any fixed x < ∞. The remainder of the proof in Khmaladze (1993) then goes through
without change.
                                                                           R
    We first represent V̂ (v) in terms of V (v). Let V (l (., θ0 )) =          l(u, θ0 )db(u) as before for any function
l(v, θ) and b(v) a zero mean Gaussian process with covariance function H(v ∧ τ ) and note that V̂ (v) =
V (φ(.,v)) − ṁ(v, θ)Σ−1 V (¯l(., θ0 )). In order to establish a corresponding result to Lemma 3.4 of Khmaladze
                        θ
(1993) we first show that V̂ (v) = V (φ(.,v)) − ṁ(v, θ)Σ−1   ¯
                                                         θ V (l(., θ 0 )) is a valid representation of the limiting
distribution of V̂n (v) which was derived in Proposition 3. Clearly, V̂ (v) is zero mean Gaussian and the



                                                             28
covariance function is
                                               Z                                 Z
            EV (v)V   (τ ) − ṁ(v, θ0 )Σ−1
                                        θ          φ (u, τ ) ¯l(u, θ0 )H(du) −       φ (u, v) ¯l(u, θ0 )H(du)Σ−1
                                                                                                              θ ṁ(τ , θ 0 )
                               Z
            +ṁ(v, θ0 ) Σ−1
                        0          ¯l(u, θ0 )¯l(u, θ0 )0 H(du)Σ−1 ṁ(τ , θ0 ).
                         θ                                     θ

                  ¡                   ¢
Note that dH(u) = p(u2 ) − p(u2 )2 dFu (u) such that
              Z                              Z
                                                                  1          ∂p(u2 , θ0 )
                 φ (u, τ ) ¯l(u, θ0 )dH(u) =   φ (u, τ )                                  dH(u)
                                                         (p(u2 ) − p(u2 )2 )    ∂θ
                                             Z
                                                         ∂p(u2 , θ0 )
                                           =   φ (u, τ )              dFu (u) = ṁ(τ , θ0 )
                                                             ∂θ
and
                                    Z
                                        ¯l(u, θ0 )¯l(u, θ0 )0 dH(u)
                                    Z
                                            1           ∂p(u2 , θ0 ) ∂p(u2 , θ0 )
                               =                                                  dH(u)
                                                   2
                                   (p(u2 ) − p(u2 ) ) 2    ∂θ           ∂θ0
                                 Z
                                            1           ∂p(u2 , θ0 ) ∂p(u2 , θ0 )
                               =                                                  dFu (u) = Σθ
                                   (p(u2 ) − p(u2 )2 )2    ∂θ           ∂θ0

such that E V̂ (v)V̂ (τ )0 = H(v ∧ τ ) − ṁ(v, θ0 )0 Σ−1
                                                      θ ṁ(τ , θ 0 ) as required.
    We now verify that the transformation T has the required properties. Note that
                                        Z
                    ­               ®                       1           ∂p(u2 , θ0 )
                             ¯
                     φ(.,v), l(., θ) =     φ (u, v)                                  dH(u)
                                                    (p(u2 ) − p(u2 )2 )    ∂θ
                                      = ṁ(v, θ0 )
                                 ­                    ® −1
such that V̂ (v) = V (φ (., v)) − φ (., τ ) , ¯l(., θ) C−∞    V (¯l(v, θ)).
                                                    R­                         ®
   In order to establish T V̂ (v) = V̂ (v) −           φ (., v) , dπ λ ¯l(., θ) Cλ−1 V̂ (π ⊥ ¯
                                                                                           λ l(., θ)) has covariance function
Γ(v, τ ) we first consider E (T V (v))2 where
                µ          Z                                   Z                      ¶2
                               ­                        ® −1
              E V (v) −                          ¯
                                φ (., v) , dπ λ l(., θ) Cλ          ⊥¯
                                                                  π λ l(ϑ, θ)db(u)
                          Z                                   D                      E
                              ­                        ®
            = Γ(v, v) − 2      φ (., v) , dπ λ ¯l(., θ) Cλ−1 φ (., v) , π ⊥λ
                                                                             ¯l(., θ)
                Z Z                                    Z
                      ­                        ®                                              ­                          ®
              +        φ (., v) , dπ λ ¯l(., θ) Cλ−1 π ⊥     ¯        ⊥¯         0
                                                           λ l(u, θ)π µ l(u, θ) dH(u)Cµ
                                                                                           −1
                                                                                               φ (., v) , dπ µ ¯l(., θ)0
                          Z                                   D                      E
                              ­                        ®
            = Γ(v, v) − 2      φ (., v) , dπ λ ¯l(., θ) Cλ−1 φ (., v) , π ⊥  ¯
                                                                           λ l(., θ)
                Z Z
                      ­                        ®                 ­                       ®
              +        φ (., v) , dπ λ ¯l(., θ) Cλ−1 Cλ∨µ Cµ−1 φ (., v) , dπ µ ¯l(., θ)0 .



                                                                 29
         ­                        ®                    ­                    ®
Note that φ (., v) , dπ λ ¯l(., θ) Cλ−1 Cλ∨µ Cµ−1 φ (., v) , dπ µ ¯l(., θ)0 is symmetric in λ and µ such that
                                Z Z
                                       ­                        ®               ­                         ®
                                        φ (., v) , dπ λ ¯l(., θ) Cλ−1 Cλ∨µ Cµ−1 φ (., v) , dπ µ ¯l(., θ)0
                                  Z                                 Z
                                     ­                         ® −1 ∞ ­                            ®
                         = 2                           ¯
                                      φ (., v) , dπ λ l(., θ) Cλ          φ (., v) , dπ µ¯l(., θ)0
                                Z                                     λ
                                   ­                         ® −1 D                    E
                         =          φ (., v) , dπ λ ¯l(., θ) Cλ φ (., v) , π ⊥  ¯
                                                                              λ l(., θ)

           ¡        R­                        ®                    ¢2
such that E V (v) −   φ (., v) , dπ λ ¯l(., θ) Cλ−1 V (π ⊥ ¯
                                                         λ l(., θ))   = Γ (v, v) . By the same arguments it follows
that E [T V (v)T V (τ )] = Γ (v, τ ) .
    That the result then also holds for T V̂ (v) follows from Khmaladze (1993, Theorem 3.9).
    Khmaladze (1993, Lemmas 3.2-3.4) shows that the argument need not be limited to all v such that
v ∈ Υx . As noted by Koul and Stute, however, once T is replaced by Tn convergence can only be shown on
the subset π x v of [−∞, ∞]k for some finite x due to the instability of the estimated matrix Cλ as λ → ∞.
    The next step is to analyze the transform T when applied to the empirical processes Vn (v) and V̂n (v)
and in particular to show convergence to the limiting counterpart, T V̂ (v).

Proposition
    n       5 Assume Conditions
                           o     2, 3, 4, 5, 6, 7 and 8 are satisfied. Fix x < ∞ arbitrary and define
                 k
Υx = v ∈ [−∞, ∞] |v = π x v . Then,
                                                 ¯                    ¯
                                                 ¯                    ¯
                                             sup ¯T V̂n (v) − T Vn (v)¯ = op (1)
                                             v∈Υx

and T Vn (v) ⇒ T V (v) in D [Υx ] where ⇒ denotes weak convergence.

    Proof of Proposition 5. By Theorem 3 we have uniformly on [−∞, ∞]k that V̂n (v) − Vn (v) =
               P
ṁ(v, θ0 )n−1/2 nt=1 l (Dt , zt , θ0 ) + op (1). Thus consider the diﬀerence

                      T V̂n − T Vn                                                                               (19)
                                          n
                                          X
                 = −ṁ(v, θ0 )n−1/2              l (Dt , zt , θ0 )
                                           t=1
                          Z                                   ³ ³                ´    ³              ´´
                              ­                          ®
                      −        φ (., v) , dπ λ ¯l(., θ0 ) Cλ−1 V̂n π ⊥
                                                                     λ
                                                                       ¯l(., θ0 ) − Vn π ⊥ ¯l(., θ0 ) + op (1)
                                                                                         λ




                                                                     30
                                                              °        °
                                                              °        °
where Ĥn and Hn are defined in Appendix B.1 for kθn − θ0 k ≤ °θ̂ − θ0 ° it follows by the mean value
theorem that
                                     ³              ´    ³              ´
                                  V̂n π ⊥ ¯                 ⊥¯
                                        λ l(., θ 0 ) − Vn π λ l(., θ 0 )
                                             n
                                             X                               ³                        ´
                         = n−1/2                          / Aλ } ¯l(zt , θ0 ) p(zt , θ0 ) − p(zt , θ̂)
                                                    1 {Ut ∈
                                              t=1
                                             n
                                             X                                  µ                               ¶³        ´
                                                                                    ∂p(zt , θn ) ∂p(zt , θ0 )
                         = n          −1/2
                                                          / Aλ } ¯l(zt , θ0 )
                                                    1 {Ut ∈                                     −                 θ̂ − θ0
                                           t=1
                                                                                       ∂θ           ∂θ
                                                                             ∂p(zt , θ0 ) ³        ´
                                             Xn
                                  +n    −1/2
                                                         / Aλ } ¯l(zt , θ0 )
                                                   1 {Ut ∈                                 θ̂ − θ0
                                               t=1
                                                                                ∂θ
                          :       = R1 (λ) + R2 (λ) .
                 h                i
                     ∂p(zt ,θ)                               ∂p(zt ,θ)
Let ṁ (θ) = E         ∂θ             and ṁ(zt , θ) =         ∂θ        − ṁ (θ) . First consider

                         °        °      n                 °                             °
                                  ° −1 X °
                                      1/2 ° °¯
                                                         ° ° ∂p(zt , θn ) ∂p(zt , θ0 ) °
                                                         ° °                             °
     sup kR1 (λ)k ≤ n °θ̂ − θ0 ° n            l(zt , θ0 ) °               −              °
      λ                                 t=1
                                                                ∂θ               ∂θ
                         °        °     Xn
                                            °            °
                         °        °         °¯l(zt , θ0 )° kṁ(zt , θn ) − ṁ(zt , θ0 )k
                  ≤ n1/2 °θ̂ − θ0 ° n−1
                                                               t=1
                                        °        °     n
                                                       X °            °
                                        °        °       °¯l(zt , θ0 )° kṁ (θn ) − ṁ (θ0 )k
                                  +n1/2 °θ̂ − θ0 ° n−1
                                                                   t=1
                                                         Ã                             !1/2 Ã                                              !1/2
                                 °        °     n
                                                X °            °                                    n
                                                                                                    X
                                 °        °       °¯l(zt , θ0 )°2
                          ≤ n1/2 °θ̂ − θ0 ° n−1                                               n−1         kṁ(zt , θn ) − ṁ(zt , θ0 )k2
                                                                   t=1                              t=1

where the third inequality follows from Hölder’s inequality. Since kθn − θ0 k = op (1) it follows from the con-
                                                                                              °                 °
tinuous mapping theorem that kṁ (θn ) − ṁ (θ0 )k = op (1). Together with the fact that E °¯l((yt , zt ) , θ0 )° <
∞ and Lemma 2.1 of Arcones and Yu (1994) this implies that
                                       °        °    n
                                 1/2 °          ° −1 X °                    °
                                                       °¯l((yt , zt ) , θ0 )° kṁ (θn ) − ṁ (θ0 )k = op (1).
                              n        °θ̂ − θ0 ° n
                                                             t=1

By Condition 6 it follows that

                                             kṁ(zt , θn ) − ṁ(zt , θ0 )k2 ≤ k |B(zt )|2 kθn − θ0 k2α

for some α > 0 such that
                              n
                              X                                                                     n
                                                                                                    X
                     n−1              kṁ(zt , θn ) − ṁ(zt , θ0 )k2 ≤ k kθn − θ0 k2α n−1                 |B(zt )|2 = op (1).
                              t=1                                                                   t=1



                                                                              31
This establishes supλ kR1 (λ)k = op (1) such that uniformly on Υx
  °Z                                      °                            Z
  ° ­                           ® −1      °                              ¯­                          ®¯
  °                    ¯                  °
       φ (., v) , dπ λ l(., θ0 ) Cλ R1 (λ)° ≤ sup kR1 (λ)k sup kCλ k−1   ¯ φ (., v) , dπ λ ¯l(., θ0 ) ¯ = op (1) .
  °
                                                      λ                λ:π λ ∈Υx
                      R                             ³       ´
Next consider R2 (λ) − π ⊥ ¯l(ϑ, θ0 )ṁ(dϑ, θ0 )n1/2 θ̂ − θ0 . Note that
                         λ
                              ∙                                       ¸ Z
                                                         ∂p(zt , θ0 )
                                     / Aλ } ¯l(zt , θ0 )
                             E 1 {Ut ∈                                 = π⊥ ¯
                                                                          λ l(ϑ, θ 0 )ṁ(dϑ, θ 0 )
                                                            ∂θ0
and
                            °                                                °
                            °                                   ∂p(zt , θ0 ) °
                            °
                       sup °1 {Ut ∈                  ¯
                                       / Aλ } l(zt , θ0 )                    °
                         λ                                           ∂θ0 °
                       °                               °
                       °             ∂p(z  t ,  θ 0  ) °
                   ≤   °¯l(zt , θ0 )                   °
                       °                 ∂θ   0        °
                       °                                                                 °
                       ° ∂p(zt , θ0 ) ∂p(zt , θ0 )                       1               °
                   =   °                                                                 °
                       °      ∂θ             ∂θ    0
                                                          p(zt , θ0 ) (1 − p(zt , θ0 )) °
                       °                                                        °2
                       ° ∂p(z , θ )                           1                 °
                       °        t 0                                             °
                   ≤   °                                                        °
                       °      ∂θ        [p(zt , θ0 ) (1 − p(zt , θ0 ))] °   1/2

                       Xd µ                      ¶
                                ∂pi (zt , θ0 ) 2                       1
                   =
                                     ∂θ                 [p(zt , θ0 ) (1 − p(zt , θ0 ))]
                       i=1
                                       Ã d µ                                                                      !2/(4+δ)
                        −(1− 2+δ 2       X ∂pi (zt , θ0 ) ¶4+δ                               1
                   ≤   d             )
                                        i=1
                                                           ∂θ              [p(zt , θ0 ) (1 − p(zt , θ0 ))](4+δ)/2
with                          " d µ                                                                  #
                               X ∂pi (zt , θ0 ) ¶4+δ                            1
                          E                                                                              <∞
                                 i=1
                                           ∂θ               [p(zt , θ0 ) (1 − p(zt , θ0 ))](4+δ)/2
                                                                     ¯          ∂p(zt ,θ0 )
by Condition
         ° 6. This shows           ° that (1 − 1 {(yt , zt ) ∈ Aλ }) l(zt , θ0 ) ∂θ0 is a Euclidian class with integrable
         °                      0) °
envelope °¯l(zt , θ0 ) ∂p(zt ,θ
                        ∂θ   0     ° such that by Lemma 2.1 of Arcones and Yu it follows that
                              °        Z                              ³       ´°
                              °                                                °
                              °           ⊥¯
                          sup °R2 (λ) − π λ l(ϑ, θ0 )ṁ(dϑ, θ0 )n−1/2
                                                                       θ̂ − θ0 °
                                                                               ° = op (1).
                             λ

It then follows that uniformly on Υx
           Z                                 ∙      Z                              ³       ´¸
              ­                         ® −1
                               ¯                       ⊥¯
               φ (., v) , dπ λ l(., θ0 ) Cλ R2 (λ) − π λ l(ϑ, θ0 )ṁ(dϑ, θ0 )n−1/2
                                                                                    θ̂ − θ0 = op (1) .
                   R
Now note that π ⊥         ¯
                        λ l(ϑ, θ 0 )ṁ(dϑ, θ 0 ) = Cλ such that
Z                                   Z                                ³        ´   Z                                   ³        ´
  ­                         ® −1                                                     ­                          ®
                   ¯
   φ (., v) , dπ λ l(., θ0 ) Cλ          ⊥¯
                                       π λ l(ϑ, θ0 )ṁ(dϑ, θ0 )n−1/2
                                                                      θ̂ − θ0   =     φ (., v) , dπ λ ¯l(., θ0 ) n−1/2 θ̂ − θ0
                                                                                                   ³            ´
                                                                                = ṁ(v, θ0 )n−1/2 θ̂ − θ0 .

                                                                  32
                                                ¯                    ¯
                                                ¯                    ¯
Substituting back in 19 then shows that supv∈Υx ¯T V̂n (v) − T Vn (v)¯ = op (1).
    For the second part of the proposition consider
                           Z                                        n
                                                                    X
                             ­                          ®
       T Vn (v) = Vn (v) −    φ (., v) , dπ λ ¯l(., θ0 ) Cλ−1 n−1/2         / Aλ } ¯l(zt , θ0 ) (Dt − p(zt , θ0 )) .
                                                                      1 {Ut ∈
                                                                             t=1

Under H0 it follows that
                                       £                                                 ¤
                                              / Aλ } ¯l(zt , θ0 ) (Dt − p(zt , θ0 )) |zt
                                      E 1 {Ut ∈
                                                                      / Aλ } |zt ] ¯l(zt , θ0 ) = 0
                               = E [(Dt − p(zt , θ0 )) |zt ] E [1 {Ut ∈

such that Vn (v) is a martingale. The finite dimensional distributions can therefore be obtained from a
martingale diﬀerence CLT. Let
                                              Z
                                                  ­                          ®
                           g(yt , zt , v) =                                              / Aλ } ¯l(zt , θ0 )
                                                   φ (., v) , dπ λ ¯l(., θ0 ) Cλ−1 1 {Ut ∈
                               Pn
such that T Vn (v) = n−1/2        t=1 (φ (Ut , v)     − g(yt , zt , v)) (Dt − p(zt , θ0 )) . Then let

                                          Y1t (v) = φ (Ut , v) (Dt − p(zt , θ0 )) ,
                                          Y2t (v) = g(yt , zt , v) (Dt − p(zt , θ0 )) ,

Yt (v) = Y1t (v) − Y2t (v) and Ynt (v) = n−1/2 Yt (v) . It follows that

                                                          EY1t2 = Γ(v, v),
                    Z Z
         2                 ©­                          ®
EY2t (v)     = E             φ (., v) , dπ λ ¯l(., θ0 ) Cλ−1
                    ∙                                                                                 ¸                                ¾
                                                      ∂ log pt (zt , θ0 ) /∂θ∂ log pt (zt , θ0 ) /∂θ0    −1
                                                                                                            ­
                                                                                                                           ¯        0
                                                                                                                                      ®
               × E 1 {Ut ∈    / Aλ } 1 {Ut ∈   / Aµ }                                                   Cµ φ (., v) , dπ µ l(., θ0 )
                                                              pt (zt , θ0 ) (1 − pt (zt , θ0 ))
               Z
                  ­                          ®               ­                           ®
             =     φ (., v) , dπ λ ¯l(., θ0 ) Cλ−1 Cµ∨λ Cµ−1 φ (., v) , dπ µ ¯l(., θ0 )0
                 Z                                  D                     E
                    ­                        ®
             = 2     φ (., v) , dπ λ ¯l(., θ) Cλ−1 φ (., v) , π ⊥
                                                                λ
                                                                  ¯l(., θ) ,

and
                                  Z
                                 ­                          ®
        EY1t (v) Y2t (v) =        φ (., v) , dπ λ ¯l(., θ0 ) Cλ−1 E [1 {Ut ∈
                                                                           / Aλ } φ (Ut , v) ∂ log pt (zt , θ0 ) /∂θ]
                               Z                                D                        E
                                 ­                        ®
                             =    φ (., v) , dπ λ ¯l(., θ) Cλ−1 φ (Ut , v) , π ⊥
                                                                               λ
                                                                                 ¯l(., θ)

which shows that EYt (v)2 = Γ(v, v). Also, EY1t (v) Y1t (τ ) = Γ (v, τ ) ,
                                        Z                               D                        E
                                          ­                        ®
                  EY2t (v) Y2t (τ ) = 2    φ (., v) , dπ λ ¯l(., θ) Cλ−1 φ (., τ ) , π ⊥
                                                                                       λ
                                                                                         ¯l(., θ)


                                                                   33
and                                         Z                                  D                         E
                                                ­                         ®
                     EY1t (v) Y2t (τ ) =         1 (. ≤ v) , dπ λ ¯l(., θ) Cλ−1 1 (. ≤ τ ) , π ⊥
                                                                                               λ
                                                                                                 ¯l(., θ)

such that EYt (v) Yt (τ ) = Γ (v, τ ) . It also follows that EYt2 < ∞ such that the conditional Lindeberg
condition of the CLT is satisfied. We conclude that the finite dimensional distributions of T Vn (v) converge
to a Gaussian limit with mean zero and covariance function Γ(v, τ ). For weak convergence in the function
space note that
                                                 Z
                                                     ¯­                          ®                 ¯
                           |g(yt , zt , v)| ≤        ¯ φ (., v) , dπ λ ¯l(., θ0 ) C −1 ¯l(zt , θ0 )¯
                                                                                   λ
                                                 Z
                                                     °­                          ®     °°             °
                                            ≤        ° φ (., v) , dπ λ ¯l(., θ0 ) C −1 ° °¯l(zt , θ0 )°
                                                                                   λ

      R °­                          ®     °                                         °     °       ¯            ¯
where   ° φ (., v) , dπ λ ¯l(., θ0 ) C −1 ° is uniformly bounded on Υx and °¯l(zt , θ0 )°2 = Pd ¯¯li (zt , θ0 )¯2 such
                                        λ                                                     i=1
                                      °        °2+δ       P ¯                  ¯2+δ
that by the Hölder inequality °¯l(zt , θ0 )°        ≤ dδ/2 di=1 ¯¯li (zt , θ0 )¯    where
                           ¯              ¯                       ¯                                  ¯
                           ¯¯li (zt , θ0 )¯ ≤ |∂pi (zt , θ0 )/∂θ| ¯(p(zt , θ0 ) (1 − p(zt , θ0 )))−1 ¯ .

By the Cauchy Schwartz inequality it then follows that
          ¯              ¯2+δ ³                          ´1/2 ³ ¯                                   ¯4+2δ ´
        E ¯¯li (zt , θ0 )¯   ≤ E |∂pi (zt , θ0 )/∂θ|4+2δ       E ¯(p(zt , θ0 ) (1 − p(zt , θ0 )))−1 ¯       <∞

which is bounded for some δ by Condition (6). This shows that g(yt , zt , v) is a Euclidian class of functions
and by Lemma 2.14 of Pakes and Pollard it follows that Yt (v) is a Euclidian class of functions. Lemma
2.1 of Arcones and Yu then can be used to establish weak convergence on D [Υx ] .
    Our main formal result is established next.

Theorem 6 Assume Conditions 2, 3, 4, 5,6, 7 and 8 are satisfied. Fix x < ∞ arbitrary and define
    n                       o
Υx = v ∈ [−∞, ∞]k |v = π x v . Then,
                                               ¯                     ¯
                                               ¯                     ¯
                                           sup ¯Tn V̂n (v) − T Vn (v)¯ = op (1).
                                          v∈Υx

    Proof of Theorem 6. We start by considering Ĉλ − Cλ . Let
                                      ∙                                  ¸
                                                    ¯         ∂p(zt , θ)
                          Cλ (θ) = E 1 {Ut ∈ / Aλ } l(zt , θ)
                                                                ∂θ0
such that Cλ = Cλ (θ0 ) and
                                     n
                                     X                       ∂p(zt , θ̂)
              Ĉλ − Cλ = n      −1
                                          / Aλ } ¯l(zt , θ̂)
                                    1 {Ut ∈                              − Cλ (θ0 )
                                t=1
                                                               ∂θ0
                                Xn
                                                             ∂p(zt , θ̂)      ³ ´        ³ ´
                          = n−1           / Aλ } ¯l(zt , θ̂)
                                    1 {Ut ∈                              − Cλ  θ̂   + Cλ  θ̂ − Cλ (θ0 ) .
                                t=1
                                                               ∂θ0

                                                               34
                       R
Note that Cλ (θ) =     (1 − 1 (u ∈ Aλ )) ¯l(u, θ)¯l(u, θ)0 H(du) such that for any λ, θ it follows that
                                       °Z                                                        °
              °   ¡ 0¢          °      °                                                         °
              °Cλ0 θ − Cλ (θ)° ≤ ° (1 (u ∈ Aλ0 ) − 1 (u ∈ Aλ )) ¯l(u, θ )¯l(u, θ ) dH(u)°
                                                                                0      0 0
                                       °                                                         °
                                            °Z                                                       °
                                            °                ¡                                 ¢     °
                                            °
                                       + ° 1 (u ∈ Aλ ) l(u, θ )l(u, θ ) − l(u, θ)l(u, θ) dH(u)°
                                                              ¯    0 ¯    0 0  ¯     ¯       0
                                                                                                     °
                                           ³                         ´
where |1 (u ∈ Aλ0 ) − 1 (u ∈ Aλ )| ≤ 1 u ∈ Amax(λ,λ0 ) \Amin(λ,λ0 ) → 0 as λ0 → λ by Condition 8. Continuity
                                                                °          °2
of ¯l(u, θ)¯l(u, θ)0 and integrability of the envelope function °¯l(u, θ0 )° then establish uniform continuity of
Cλ (θ) on Υx × N (θ0 ) by use of the dominated convergence          ° ³ ´          theorem. ° By continuity of Cλ (θ) and the
                                                                    °                       °
continuous mapping theorem it now follows that °Cλ θ̂ − Cλ (θ0 )° = op (1) uniformly on Υx × N (θ0 ).
                       P
Let vn (θ, λ) = n−1 nt=1 1 {Ut ∈        / Aλ } ¯l(zt , θ) ∂p(zt ,θ)
                                                            ∂θ0
                                                                    − Cλ (θ) . We note that
           °                                      °
           °                           ∂p(zt , θ) °       °                    °                                 °          °
           °1 {Ut ∈  / A   } ¯
                             l(z  , θ)            ° ≤ 2 °¯l(zt , θ)¯l(zt , θ)0 ° |p(zt , θ) (1 − p(zt , θ))| ≤ 2 °¯l(zt , θ)°2
           °             λ      t
                                         ∂θ0 °
                                                                 ³ √                °         °´α ¯             ¯
where ¯li (zt , θ) has the integrable Envelope B(zt ) 2 d supN(θ0 ) °θ − θ0 ° + ¯¯li (zt , θ0 )¯ on N (θ0 ) by Con-
dition 6. By Condition 8 the functions 1 {(yt , zt ) ∈ Aλ } form a Euclidian class. It now follows from Lemma
2.1 of Arcones and Yu (1994) that, because n1/2 vn (θ, λ) converges weakly to a Gaussian limit, a tightness
condition must hold, i.e. for any ε, η > 0, ∃δ > 0 such that
                          Ã                                                               !
                                                           ¯                         ¯
               lim supP         sup             sup        ¯vn (θ0 , λ0 ) − vn (θ, λ)¯ > ε < η.                           (20)
                      n         λ,θ∈Υx ×N(θ0 ) λ0 ,θ0 :d((λ,θ),(λ0 ,θ0 ))<δ

Property 20 together with the boundedness of the space Υx × N (θ0 ) now implies by a conventional ap-
proximation argument, that
                                                    sup          |vn (θ, λ)| = op (1).
                                              λ,θ∈Υx ×N(θ0 )

It now follows that
                                                    Ã                                       !
               ³°        ³ ´°     ´                                                                ³            ´ p
                °            °
              P °Ĉλ − Cλ θ̂ ° > ε ≤ P                       sup         |vn (θ, λ)| > ε        + P θ̂ ∈
                                                                                                       / N (θ0 ) → 0      (21)
                                                        λ,θ∈Υx ×N(θ0 )
                  °         °
                  °         °
such that supλ∈Υx °Ĉλ − Cλ ° = op (1).
    Then
                                                                        n
                                                                        X
                 Tn V̂n (v) − T Vn (v) = −ṁ(v, θ0 )n−1/2                     l (Dt , zt , θ0 ) + op (1)
                                                                        t=1
                                                    Z       µZ                                ¶
                                                −       d                     ¯
                                                                 φ (u, v) π λ l(., θ̂)dĤn (u) Ĉλ−1 V̂n (π ⊥ ¯
                                                                                                            λ l(., θ̂))
                                                    Z
                                                        ­                          ®
                                                +        φ (., v) , dπ λ ¯l(., θ0 ) Cλ−1 Vn (π ⊥ ¯
                                                                                               λ l(., θ 0 )).


                                                                   35
>From before we have
                                  Z        µZ                   ¶
                                  φ (u, v) π λ ¯l(., θ̂)dĤn (u) Ĉλ−1 V̂n (π ⊥
                                       d                                        ¯
                                                                              λ l(., θ̂))
                             Z µZ                               ¶³                 ´
                           =  d                ¯
                                  φ (u, v) π λ l(., θ̂)dĤn (u) Ĉλ−1 − Cλ−1 V̂n (π ⊥          ¯
                                                                                             λ l(., θ̂))
                              Z µZ                                ¶
                             + d                   ¯
                                    φ (u, v) π λ l(., θ̂)dĤn (u) Cλ−1 V̂n (π ⊥    ¯
                                                                                 λ l(., θ̂))

where
               °Z µZ                                 ¶³                    ´              °
               °                                                                          °
               ° d     φ (u, v) π λ ¯l(., θ̂)dĤn (u) Ĉλ − Cλ V̂n (π λ ¯l(., θ̂))°
                                                           −1         −1          ⊥
               °                                                                          °
                     °                  Z
                                      ° °    °  µ Z                                ¶°
                     °                °                                             °°                   °
             ≤   sup °Ĉλ−1 − Cλ−1 ° °        d      φ (u, v) π   ¯l(., θ̂)dĤn (u) ° °
                                                                                      °V̂  (π ⊥¯
                                                                                                l(., θ̂))
                                                                                                         °
                                                                                                         ° = op (1)
                                             °                  λ                   °    n    λ
                  λ∈[−∞,x]

by 21. Next we consider
                                       n
                                       X                             ³               ´
    V̂n (π ⊥ ¯            −1/2
                                                   / Aλ } ¯l(Ut , θ̂) Dt − p(zt , θ̂)
           λ l(., θ̂)) = n                   1 {Ut ∈
                                       t=1
                                       Xn
                      = n−1/2                      / Aλ } ¯l(Ut , θ0 ) (Dt − p(zt , θ0 ))
                                             1 {Ut ∈
                                       t=1
                              "                                                           #
                                             n
                                             X     ∂ ¯l(Ut , θn )                            ³         ´
                                      −1/2
                       + n           1 {Ut ∈
                                           / Aλ }           0      (Dt − p(zt , θ0 )) θ̂ − θ0
                                 t=1
                                                        ∂θ
                         "                                                             #
                                X n
                                                                       ∂p(z    , θ   )   ³         ´
                                                                             t     n
                       − n−1/2             / Aλ } ¯l((yt , zt ) , θ0 )
                                     1 {Ut ∈                                              θ̂ − θ 0
                                 t=1
                                                                           ∂θ0
                                    "                                                          #
                         ³       ´0        Xn
                                                                  ∂ ¯l(Ut , θn ) ∂p(zt , θn ) ³              ´
                       − θ̂ − θ0     n−1/2     1 {Ut ∈  / Aλ }                                      θ̂ − θ 0
                                           t=1
                                                                        ∂θ              ∂θ0
                                        ³      ´                       ³           ´           ³         ´0        ³         ´
                  ≡ R1 (λ) + R2 (λ) θ̂ − θ0 + R3 (λ) n1/2 θ̂ − θ0 + n1/2 θ̂ − θ0 R4 (λ) θ̂ − θ0
                   °      °                                                                                 R
                   °      °                                                                                      ¯
where kθn − θ0 k ≤ °θ̂ − θ° and we have used the mean value theorem. Note that R1 = π ⊥                        λ l(ϑ, θ 0 )dVn (u),
                                             n
                                             X          ∂ ¯l(Ut , θ0 )
                 R2 (λ) = n−1/2                  1 {Ut ∈
                                                       / Aλ }    0     (Dt − p(zt , θ0 ))
                                       t=1
                                                             ∂θ
                                         Xn                µ ¯                            ¶
                                    −1/2                     ∂ l(Ut , θn ) ∂ ¯l(Ut , θ0 )
                                  +n         1 {Ut ∈
                                                   / Aλ }                  −                (Dt − p(zt , θ0 ))
                                         t=1
                                                                   ∂θ0          ∂θ0
                           ≡ R21 (λ) + R22 (λ, θn )

satisfies ER21 (λ) = 0 because
                            ∙                                                           ¸
                                         ∂ ¯l((yt , zt ) , θ0 )
                          E 1 {Ut ∈
                                  / Aλ }                         (Dt − p(zt , θ0 )) |zt
                                                 ∂θ0
                            ∙                                      ¸
                                         ∂ ¯l((yt , zt ) , θ0 )
                       = E 1 {Ut ∈/ Aλ }                        |zt E [(Dt − p(zt , θ0 )) |zt ] = 0
                                                 ∂θ0

                                                                     36
under H0 such that finite dimensional convergence follows by the martingale diﬀerence CLT and uniform
                                                              ¯
                                             / Aλ } ∂ l(U
convergence follows from the fact that 1 {Ut ∈           t ,θ0 )
                                                        ∂θ0
                                                                 (Dt − p(zt , θ0 )) is a Euclidian class of functions
                                                                            ³         ´
by Condition 8. It thus follows that supλ R21 (λ) = Op (1) and R21 (λ) θ̂ − θ0 = op (1) uniformly in λ. For
the term R22 (λ, θn ) we note that
                                ∙                                              ¸
                                            ∂ ¯l(Ut , θ)
                             E 1 {Ut ∈
                                     / Aλ }              (Dt − p(zt , θ0 )) |zt = 0
                                                 ∂θ0
for any θ. By Lemma 2.1 of Arcones and Yu it thus follows that R22 (λ, θ) converges to a Gaussian limit
process uniformly in λ and θ. Consequently, a tightness condition implied by this result can be used to show
              h                                i
that lim sup P supθ:d(θ,θ0 )≤δ |R22 (λ, θ)| > ε < η for all ε, η > 0 and some δ > 0. Use root-n convergence
of θn to conclude from this that R22 (λ, θn ) = op (1). The terms involving θn in the remainder terms R3
and R4 containing θn can be handled in similar form and we therefore only consider the leading terms
where θn is replaced by θ0 . For R4 (λ) where
                                               n
                                               X                     ∂ ¯l(Ut , θ0 ) ∂p(zt , θ0 )
                                R4 (λ) = n−1          1 {Ut ∈
                                                            / Aλ }
                                                t=1
                                                                          ∂θ           ∂θ0

we note that n1/2 (R4 (λ) − ER4 (λ)) satisfies the conditions of Lemma 2.1 of Arcones and Yu (1994)
such ³that it´ follows ³by similar
                              ´    arguments as before that supλ R4 (λ) = Op (1).                  Then conclude that
              0
n1/2 θ̂ − θ0 R4 (λ) θ̂ − θ0 = op (1) uniformly in λ.
    For R3 (λ) note that
                                                 n
                                                 X                                 ∂p(zt , θ0 )
                                 R3 (λ) = n−1                / Aλ } ¯l(Ut , θ0 )
                                                       1 {Ut ∈
                                                 t=1
                                                                                      ∂θ0
uniformly converges to
                                          ∙                                       ¸
                                                                     ∂p(zt , θ0 )
                                                 / Aλ } ¯l(Ut , θ0 )
                               ER3 (λ) = E 1 {Ut ∈                                  = Cλ .
                                                                        ∂θ0
We have thus established that
                          °                                             ³        ´°
                          °         ¯                 ⊥¯                          °
                      sup °V̂n (π ⊥
                                  λ l(., θ̂)) − Vn (π λ l(., θ 0 )) − Cλ θ̂ − θ 0 ° = op (1) .
                           λ
Using this result we obtain
  Z µZ                                  ¶    ³                                        ´
     d                  ¯
           φ (u, v) π λ l(u, θ̂)dĤn (u) Cλ−1 V̂n (π ⊥ ¯l(., θ̂)) − Vn (π ⊥¯l(., θ0 ))
                                                     λ                    λ
                                                             Z µZ                                    ¶³      ´
                                                         = d                          ¯
                                                                        φ (u, v) π λ l(u, θ̂)dĤn (u) θ̂ − θ0 + op (1).

The leading term is then
        Z µZ                                 ¶   Z µZ                                   ¶
          d                  ¯
                φ (u, v) π λ l(u, θ̂)dĤn (u)  =  d                ¯
                                                      φ (u, v) π λ l(u, θ0 )dHn (u)                                 (22)
                                                  Z µZ                                        ¶³         ´
                                                                      ∂ 2 p(zt , θn )
                                                 + d    φ (u, v) π λ                  dF̂u (u)  θ̂ − θ 0
                                                                          ∂θ∂θ0

                                                             37
where F̂u (u) is defined in (24) in Appendix B.1 and
 °Z Z                                   °       n °
                                                X                                        °
 °                 2                    °         °                         2            °
 ° d φ (u, v) π λ ∂ p(zt , θn ) dF̂u (u)° ≤ n−1   °1 {Ut ≤ v} 1 {Ut ∈ Aλ } ∂ p(zt , θn ) °
 °                   ∂θ∂θ  0            °         °                           ∂θ∂θ °0
                                                           t=1
                                                         Xn ° 2              °       Xn ° 2                              °
                                                             ° ∂ p(zt , θ0 ) °           ° ∂ p(zt , θn ) ∂ 2 p(zt , θ0 ) °
                                                  ≤ n −1     °               °    −1     °                               °
                                                             ° ∂θ∂θ0 ° + n               ° ∂θ∂θ0 − ∂θ∂θ0 °
                                                         t=1                         t=1
                                                         Xn ° 2              °                       Xn
                                                             ° ∂ p(zt , θ0 ) °
                                                  ≤ n−1      °               ° + C kθn − θ0 kα n−1       B(zt ) = Op (1)
                                                             ° ∂θ∂θ0 °
                                                         t=1                                         t=1

where C is a finite constant, the third inequality uses Condition (6) and the last equality follows from a
standard law of large numbers for strong mixing sequences. The first term in 22 then is
                  Z       µZ                                ¶      n
                                                                   X
                                            ¯                                                ∂p(zt , θ0 )
                      d        φ (u, v) π λ l(u, θ0 )dHn (u) = n−1   φ (Ut , v) 1 {Ut ∈ Aλ }
                                                                                                ∂θ
                                                                    t=1
        h                                    i
where E φ (Ut , v) 1 {Ut ∈ Aλ } ∂p(z∂θt ,θ0 ) = ṁ(v, θ0 ) for v ∈ Υx . It thus follows again by a law or large
            R ¡R                                  ¢
numbers that d φ (u, v) π λ ¯l(u, θ0 )dHn (u) = ṁ(v, θ0 ) + op (1) uniformly on Υx .
   Finally we need to show that
        Z µ µZ                                 ¶                            ¶
                                                 ­                         ®
            d                  ¯                                  ¯
                  φ (u, v) π λ l(u, θ0 )dHn (u) − φ (., v) , dπ λ l(., θ0 ) Cλ−1 Vn (π ⊥ ¯
                                                                                       λ l(u, θ 0 )) = op (1).           (23)


Let g(zt , λ, v) = φ (Ut , v) 1 {Ut ∈ Aλ } ∂p(z∂θt ,θ0 ) . We first note that uniformly in λ on [−∞, x] and v ∈ Υx ,
       Z                                                                  n
                                                                          X
                                          ­                        ®
                        ¯                                 ¯
           φ (., v) π λ l(., θ0 )dHn (v) − φ (., v) , π λ l(., θ0 ) = n−1
                                                                            g(zt , λ, v) − E (g(zt , λ, v)) → 0 a.s.
                                                                          t=1

Weak convergence of Cλ−1 Vn (π ⊥ ¯
                               λ l(u, θ 0 )) uniformly in λ on [−∞, x] can be established by the same methods
as for T Vn (v) ⇒ T V (v) in the second part of the proof of Proposition 5. We can thus proceed in the same
                                                                    P
way as Koul and Stute (1999, Lemma 4.2). Let Gn (λ, v) = n−1 nt=1 g(zt , λ, v), G(λ, v) = E (g(zt , λ, v))
and let ζ (λ) = C −1 Vn (π ⊥ ¯l(u, θ0 )). Then each component ζ (λ) of the vector ζ (λ) is asymptotically
           n              λ       λ                                         ni                        n
tight by Prohorov’s Theorem. In other words there exists a compact set H such that ζ ni (λ) ∈ H with
probability no less than 1 − η for any η > 0. Following the proof of Lemma 3.1 of Chang (1990) we choose
step functions a1 , a2 , ..., ak ∈ D [−∞, x] such that for any ζ ∈ H, sup |ai − ζ| < ε for some i, 1 ≤ i ≤ k. The
                                                  Rx
right hand side of 23 can now be written as −∞ ζ n (λ)0 (Gn (dλ) − G(dλ)) such that for any δ > 0
   µ¯Z                                    ¯     ¶     Ã                     ¯Z                                      ¯     !
     ¯     x                              ¯                                 ¯    x                                  ¯
  P ¯¯          ζ n (λ) (Gn (dλ) − G(dλ))¯¯ > η
                      0
                                                  ≤ P              sup      ¯
                                                                            ¯         ζ (λ) (Gn (dλ, v) − G(dλ, v))¯¯ > δ
                                                                                          0
           −∞                                                    ζ∈H,v∈Υx        −∞
                                                           +P (ζ n ∈
                                                                   / H) .



                                                              38
Since ζ ∈ H it follows that
         ¯Z x                               ¯              µ    Z                                         Z                   ¶
         ¯                                  ¯                                      x                          x
  sup ¯  ¯          0                       ¯
               ζ (λ) (Gn (dλ, v) − G(dλ, v))¯ ≤ sup kζ (λ)k sup                        kG(dλ, v)k + sup           kGn (dλ, v)k
ζ∈H,v∈Υx     −∞                                        ζ∈H               v∈Υx     −∞               v∈Υx   −∞
        Rx                                     Rx
where   −∞ kG(dλ, v)k   = kG(x, v)k and         −∞ kGn (dλ, v)k         = kGn (x, v)k . Since G(x, v) → 0 uniformly in v
as x → −∞ and Gn (λ, v) converges uniformly to G(x, v) we can focus on a subset [xu , x] ⊂ [−∞, x] where
xu is such that                           ¯Z                                      ¯
                                          ¯    xu                                 ¯
                                  sup     ¯         ζ (λ) (Gn (dλ, v) − G(dλ, v))¯¯ < δ
                                                        0
                                          ¯
                               ζ∈H,v∈Υx    −∞

with probability tending to one. Now, for any component i, there exists a strictly increasing, con-
tinuous mapping κ of [−∞, x] onto itself, depending on ζ i such that sup−∞≤λ≤x |κ (λ) − λ| < ε and
sup−∞≤λ≤x |ζ i (λ) − ai (κ(λ))| < ε. Then
      ¯Z x                                    ¯    ¯Z                                                            ¯
      ¯                                       ¯    ¯           x                                                 ¯
      ¯    ζ i (λ) (Gni (dλ, v) − Gi (dλ, v))¯¯ ≤ ¯¯            (ζ i (λ) − ai (κ(λ))) (Gni (dλ, v) − Gi (dλ, v))¯¯
      ¯
             xu                                              xu
                                                             ¯Z x                                       ¯
                                                             ¯                                          ¯
                                                             ¯
                                                            +¯     ai (κ(λ)) (Gni (dλ, v) − Gi (dλ, v))¯¯
                                                                   xu
                                                ¯R                                     ¯
                                                ¯ x                                    ¯
which implies that for some N0 and all n > N0 , ¯ −∞ ζ i (λ) (Gni (dλ, v) − Gi (dλ, v))¯ < 3ε uniformly on
H × Υx by the arguments of Chang (1994, p.396) which establishes 23. This now implies that Tn V̂n (v) −
T Vn (v) = op (1).
    Theorem 6 together with Propositions 5 and 4 implies that Ŵn (v) − Vn (v) = op (1) uniformly in v ∈ Υx .
This in turn means that the limiting distribution of Ŵn (v) is a zero mean Gaussian process with covariance
function H(v, τ ). This distribution is not nuisance parameter free but can be computed conditional on the
sample relatively easily as pointed out in Section 4.
                                                                                                  ¡                 ¢
    Section 4.2 introduced the distribution free statistic B̂w,n (w), defined as B̂w,n (w) = Ŵw,n φ(., w)/hw (.)1/2 .
By the arguments preceding Theorem 6, it follows that B̂w,n (w) =⇒ Bw (w) on Υ[0,1] . The only adjustments
necessary are a restriction of [−∞, ∞]k to [0, 1]k . What remains to be shown is that
                                          ¯                    ¯
                                          ¯                    ¯
                                    sup ¯B̂ŵ,n (w) − B̂w,n (w)¯ = op (1).
                                     v∈Υ[0,1]

This is done in the next Theorem. We impose the following assumptions on the kernel function and density.

Condition 9 The density fu (u) is continuously diﬀerentiable to some integral order ω ≥ max(2, k) on
Rk with supx∈Rk |Dµ h(x)| < ∞ for all |µ| ≤ ω where µ = (µ1 , ..., µk ) is a vector of non-negative inte-
            Pk               µ        |µ|      µ1    µk
gers, |µ| =  j=1 µj , and D f (x) = ∂ h(x)/∂x1 ....∂xk is the mixed partial derivative of order |µ| .
                            R             R µ                                         R
The kernel K(.) satisfies i) K(x)dx = 1, x K(x)dx = 0 for all 1 ≤ |µ| ≤ ω − 1, |xµ K(x)| dx < ∞
for all µ with |µ| ≤ ω, K(x) → 0 as kxk → ∞ and supx∈                        Rk   (1 + kxk) |Dei K(x)| < ∞ for all i ≤ k

                                                              39
and ei is the i-th elementary vector in Rk . ii) K(x) is absolutely integrable and has Fourier transform
              R                               R                          √
Ψ(r) = (2π)k exp(ir0 x)K(x)dx that satisfies |Ψ(r)| dr < ∞ where i = −1.



Theorem n 7 Assume Conditions o 2, 3, 4, 5,6, 7, 8 and 9 are satisfied. Fix x < 1 arbitrary and define
                   k
Υ[0,1] = w ∈ [0, 1] |w = π x w . Then,
                                              ¯                      ¯
                                              ¯                      ¯
                                          sup ¯B̂ŵ,n (w) − B̂w,n (w)¯ = op (1).
                                       w∈Υ[0,1]


   Proof of Theorem 7:. By Theorem 1 of Andrews (1995) it follows that
                 ¯                                                    ¯
                 ¯                                                    ¯
             sup ¯F̂k (xk |xk−1 , ..., x1 ) − Fk (xk |xk−1 , ..., x1 )¯ = Op (T −1/2 m−k         ω
                                                                                      n ) + Op (mn ).
                  x

By Pakes and Pollard (1989, Lemma 2.15) it follows that the composition of a function from a Euclidian
class with envelope M and a measurable map with envelope M1 forms another Euclidian class with envelope
M ◦ M1 . Since Fk (xk |xk−1 , ..., x1 ) is takes values in [0, 1] it clearly has an envelope M1 . It follows that
Ŵw,n is a sample average over functions that belong to a Euclidian class plus remainder terms that vanish
by similar arguments as before. It thus follows by the same arguments as before that for all ε, δ > 0 there
exists an η > 0 such that
                               ⎛                                                                  ⎞
                                ⎜                                  ¯                            ¯    ⎟
                                ⎜                                  ¯                            ¯    ⎟
                      lim sup P ⎜              sup                 ¯B̂w1 ,n (w) − B̂w10 ,n (w0 )¯ > ε⎟ < δ.
                           n    ⎝   w,w0 ∈Υ[0,1] ,kw−w0 k<η,                                         ⎠
                                   w1 ,w10 ∈[0,1]k ,kw1 −w10 k<η


It then follows that B̂n (s) ⇒ B(s).
   This result allows us to conduct inference using critical values that do not depend on nuisance para-
meters. Although these critical values must be calculated numerically, they are invariant to the sample
distribution for a given design.




                                                               40
B     Implementation Details
B.1       Details for the Khmaladze Transform

To construct the test statistic proposed in the theoretical discussion we must deal with the fact that the
transformation T is unknown and needs to be replaced by an estimator. In this section, we discuss the
details that lead to the formulation in (9). We also present results for general sets Aλ . We start by defining
the empirical distribution
                                                                     n
                                                                     X
                                                                −1
                                                F̂u (v) = n                {Ut ≤ v} ,                              (24)
                                                                     t=1

and let
                                             Z   v    ¡                             ¢
                             Hn (v) =                     p(u2 , θ0 ) − p(u2 , θ0 )2 dF̂u (u)
                                                −∞
                                                     n
                                                     X ¡                          ¢
                                        = n−1           p(zt , θ0 ) − p(zt , θ0 )2 1 {Ut ≤ v}
                                                     t=1

as well as
                                             Z   v    ³                        ´
                             Ĥn (v) =                 p(u2 , θ̂) − p(u2 , θ̂)2 dF̂u (u)
                                                 −∞
                                                     n ³
                                                     X                          ´
                                        = n−1           p(zt , θ̂) − p(zt , θ̂)2 1 {Ut ≤ v} .
                                                     t=1

We now use the sets Aλ and projections π λ as defined in Section 4.1. Let
                         Z
                Ĉλ =      π⊥ ¯         ⊥¯        0
                            λ l(v, θ̂)π λ l(v, θ̂) dĤn (v)
                                  n
                                  X                                               ³                         ´
                        = n−1           (1 − 1 {Ut ∈ Aλ }) ¯l(Ut , θ̂)¯l(Ut , θ̂)0 p(zt , θ̂) − p(zt , θ̂)2
                                  t=1

such that                                   Z        µZ                               ¶
                  Tn V̂n (v) = V̂n (v) −         d         φ(u, v)π λ ¯l(u, θ)dĤn (u) Ĉλ−1 V̂n (π ⊥ ¯
                                                                                                    λ l(u, θ̂))

where               Z                                                n
                                                                     X                             ∂p(zt , θ̂)
                        φ {u, v} π λ ¯l(., θ̂)dĤn (u) = n−1               φ(Ut , v)1 {Ut ∈ Aλ }               .
                                                                     t=1
                                                                                                     ∂θ
Finally, write
                                                 n
                                                 X                                      ³               ´
                    V̂n (π ⊥ ¯            −1/2
                                                          (1 − 1 {Ut ∈ Aλ }) ¯l(Ut , θ̂) Dt − p(zt , θ̂) .
                           λ l(u, θ̂)) = n
                                                 t=1




                                                                  41
   We now specialize the choice of sets Aλ to Aλ = [−∞, λ] × [−∞, ∞]k−1 . Denote the first element of yt
by y1t . Then
                                       n
                                       X                                        ³                        ´
                         Ĉλ = n−1           1 {y1t > λ} ¯l(zt , θ̂)¯l(zt , θ̂)0 p(zt , θ̂) − p(zt , θ̂)2 ,                               (25)
                                       t=1
                                                                   n
                                                                   X                            ³               ´
                         V̂n (π ⊥ ¯            −1/2
                                                                         1 {y1t > λ} ¯l(Ut , θ̂) Dt − p(zt , θ̂)
                                λ l(u, θ̂)) = n                                                                                           (26)
                                                                   t=1

and                  Z                                                       n
                                                                             X                              ∂p(zt , θ)
                         φ(u, v)π λ ¯l(u, θ̂)dĤn (u) = n−1                        φ {Ut , v} 1 {y1t ≤ λ}                                 (27)
                                                                             t=1
                                                                                                              ∂θ
Combining 25, 26 and 27 then leads to the formulation 9.


B.2     Details for the Rosenblatt Transform

As before implementation requires replacement of θ with an estimate. We therefore work with the process
                 P
V̂w,n (v) = n−1/2 nt=1 mw (wt , Dt , θ̂; w). Define
                                         Z       1         Z   1          ¡ ¡£       ¤      ¢    £        ¤      ¢
           E [mw (wt , Dt , θ); w)] =                ···           φ(u, w) p TR−1 (u) z , θ0 − p( TR−1 (u) z , θ) du
                                             0             0

such that ṁ(w, θ) evaluated at the true parameter value θ0 is

                              ṁw (w, θ0 ) = E [∂p(zt , θ0 )/∂θφ(Ut , w)]
                                             Z          £        ¤
                                                     ∂p( TR−1 (u) z , θ0 )
                                           =                               φ(u, w)du
                                              [0,1]k          ∂θ
                                                                                                                         Pn
It therefore follows that V̂w,n (v) can be approximated by Vw,n (v) − ṁw (w, θ0 )0 n−1/2                                 t=1 l (Dt , zt , θ 0 ).
This approximation converges to a limiting process V̂w (v) with covariance function

                               Γ̂w (w, τ ) = Γw (w, τ ) − ṁw (w, θ0 )0 L(θ0 )ṁw (τ , θ0 )

where                              Z
                                                            ¡ £         ¤        £        ¤ ¢
                    Γw (w, τ ) =             φ(u, w)φ(u, τ ) p( TR−1 (u) z ) − p( TR−1 (u) z )2 du.
                                   [0,1]k
                                                                                       R
   We represent V̂w in terms of Vw . Let Vw (lw (., θ0 )) =                                lw (w, θ0 )bw (dv) where bw (v) is a Gaussian
                k
process on [0, 1] with covariance function Γw (v, τ ) as before, for any function lw (w, θ). Also, define
                                 £        ¤
                              ∂p( TR−1 (w) z , θ) ¡ £ −1    ¤      ¡      £        ¤      ¢¢−1
                 ¯lw (w, θ) =                      p( TR (w) z , θ) 1 − p( TR−1 (w) z , θ)
                                     ∂θ
                                            ¡          ¢
such that V̂w (w) = Vw (w) − ṁw (w, θ0 )Vw ¯lw (w, θ) as before.


                                                                            42
   Let {Aw,λ } be a family of measurable subsets of [0, 1]k , indexed by λ ∈ [0, 1] such that Aw,0 = ∅,
Aw,1 = [0, 1]k , λ ≤ λ0 =⇒ Aw,λ ⊂ Aw,λ0 and Aw,λ0 \Aw,λ → ∅ as λ0 ↓ λ. We then define the inner product
                 R
hf (.), g(.)iw := [0,1]k f (w)g(w)0 dHw (w) where
                                         Z
                                                ¡ £ −1    ¤           £        ¤     ¢2
                            Hw (w) =             p( TR (u) z , θ) − p( TR−1 (u) z , θ )du
                                          u≤w

and the matrix
                            D                            E Z
                               ⊥¯             ⊥¯                ¯          ⊥¯
                    Cw,λ   = π λ lw (., θ), π λ lw (., θ) = π ⊥                       0
                                                              λ lw (w, θ)π λ lw (w, θ) dHw (w).
                                                              w

and define the transform Tw Vw (w) as before by
                                                          Z
                                                              ­                          ®
                Tw V̂w (w) := Ww (w) = V̂w (w) −               φ (., w) , dπ λ ¯lw (., θ) Cλ−1 V̂w (π ⊥ ¯
                                                                                                      λ lw (., θ)).


Finally, to convert Ww (w) to a process which is asymptotically distribution free we apply a modified version
of the final transformation proposed by Khmaladze (1988, p. 1512) to the process W (v). In particular,
using the notation Ww (φ(., w)) = Ww (w) to emphasize the dependence of W on φ, it follows from the
previous discussion that
                                                       ³                 ´
                                       Bw (w) = Ww φ(., w)/(hw (.))1/2
                £        ¤      ¡      £        ¤      ¢
with hw (.) = p( TR−1 (.) z , θ) 1 − p( TR−1 (.) z , θ) and Bw (w) is a Gaussian process on [0, 1]k with covari-
               R1    R1
ance function 0 · · · 0 φ(u, w)φ(u, w0 )du.
   The empirical version of Ww (w), denoted by Ŵw,n (w) = T̂w V̂w,n (w), is obtained as before from
                      "                                                                                                  #
                  Xn
                                                        ∂p(zt , θ̂) −1 −1 X
                                                                            n                           ³               ´
Ŵw,n (w) = n−1/2
                       mw (wt , Dt , θ̂|w) − φ {wt , w}            Ĉwt1 n                    ¯
                                                                               1 {ws1 > wt1 } l(zs , θ̂) Ds − p(zs , θ̂)
                  t=1
                                                          ∂θ0              s=1

                    Pn                                           ³                        ´
where Ĉws1 = n−1          1 {wt1 > ws1 } ¯l(zt , θ̂)¯l(zt , θ̂)0 p(zt , θ̂) − p(zt , θ̂)2 .
                       t=1




                                                                  43
References
Andrews, D. W. (1995): “Nonparametric Kernel Estimation for Semiparametric Models,” Econometric
  Theory, pp. 560—596.

Arcones, M. A., and B. Yu (1994): “Central Limit Theorems for Empirical and U-Processes of Sta-
  tionary Mixing Sequences,” Journal of Theoretical Probability, pp. 47—71.

Bai, J. (2002): “Testing Parametric Conditional Distributions of Dynamic Models,” mimeo.

Bernanke, B. S., and A. S. Blinder (1992): “The Federal Funds Rate and the Channels of Monetary
  Transmission,” The American Economic Review, 82, 901—921.

Bernanke, B. S., and J. Boivin (2003): “Monetary Policy in a Data-Rich Environment,” Journal of
  Monetary Economics, 50, 525—546.

Bernanke, B. S., J. Boivin, and P. Eliasz (2004): “Measuing the Eﬀects of Monetary Policy: A
  Factor-Augmented Vector Autoregressive (FAVAR) Approach,” NBER Working Paper 10220.

Bierens, H. J. (1982): “Consistent Model Specification Tests,” Journal of Econometrics, 20, 105—134.

        (1987): “Kernel Estimators of Regression Functions,” in Advances in Econometrics: Fifth World
  Congress, ed. by T. Bewley, pp. 99—144. Cambridge University Press, New York.

        (1990): “A consistent conditional moment test of functional form.,” Econometrica, 58, 1443—1458.

Bierens, H. J., and W. Ploberger (1997): “Asymptotic theory of integrated conditional moment
  tests,” Econometrica, 65, 1129—1152.

Chamberlain, G. (1982): “The General Equivalence of Granger and Sims Causality,” Econometrica, pp.
  569—581.

Chen, X., and Y. Fan (1999): “Consistent hypothesis testing in semiparametric and nonparametric
  models for econometric time series.,” Journal of Econometrics, 91, 373—401.

Chesher, A., and I. Jewitt (1987): “The Bias of a Heteroscedasticity-Consistent Covariance Matrix
  Estimator,” Econometrica, 55, 1217—1222.

Christiano, L. J., M. Eichenbaum, and C. Evans (1996): “The Eﬀects of Monetary Policy Shocks:
  Evidence from the Flow of Funds,” The Review of Economics and Statistics, 78, 16—34.

                                                  44
Dufour, J.-M., and E. Renault (1998): “Short Run and Long Run Causality in Time Series: Theory,”
  Econometrica, pp. 1099—1125.

Dufour, J.-M., and D. Tessier (1993): “On the relationship between impulse response analysis, inno-
  vation accounting and Granger causality,” Economics Letters, 42, 327—333.

Florens, J.-P., and M. Mouchart (1982): “A Note on Non-Causality,” Econometrica, pp. 582—591.

Florens, J.-P., and M. Mouchart (1985): “A Linear Theory for Noncausality,” Econometrica, pp.
  157—176.

Hahn, J. (1999): “How informative is the initial condition in the dynamic panel model with fixed eﬀects,”
  Journal of Econometrics, 93, 309—326.

Hall, P., and C. Heyde (1980): Martingale Limit Theory and its Application. Academic Press.

Heckman, J. J., H. Ichimura, and P. E. Todd (1998): “Matching as an Econometric Evaluation
  Estimator,” Review of Economic Studies, 65, 261—294.

Hirano, K., and G. Imbens (2004): “The Propensity Score with Continuous Treatments,” Berkeley
  Department of Economics, mimeo.

Hirano, K., G. Imbens, and G. Ridder (2003): “Eﬃcient Estimation of Average Treatment Eﬀects
  using the Estimated Propensity Score,” Econometrica, 71, 1161—1189.

Justel, A., D. Pena, and R. Zamar (1997): “A multivariate Kolmogorov-Smirnov test of goodness of
  fit,” Statistics and Probability Letters, 35, 251—259.

Khmaladze, E. (1981): “Martingale Approach in the Theory of Goodness-of-fit Tests,” Theory of Prob-
  ability and Its Applications, pp. 240—257.

         (1988): “An Innovation Approach to Goodness-of-Fit Tests in Rm ,” Annals of Statistics, pp.
  1503—1516.

Khmaladze, E. V. (1993): “Goodness of Fit Problem and Scanning Innovation Martingales,” The Annals
  of Statistics, pp. 789—829.

Koenker, R., and Z. Xiao (2003): “Inference of the Quantile Regression Process,” Forthcoming Econo-
  metrica.

Koul, H. L., and W. Stute (1999): “Nonparametric Model Checks for Time Series,” Annals of Statistics,
  pp. 204—236.

                                                      45
Leeper, E. M. (1997): “Narrative and VAR approaches to Monetary Policy: Common Identification
  Problems,” Journal of Monetary Economics, pp. 641—657.

Linton, O., and P. Gozalo (1999): “Conditional Independence Restrictions: Testing and Estimation,”
  mimeo.

Lucas, R. E. (1972): “Expectations and the Neutrality of Money,” Journal of Economic Theory, pp.
  103—124.

Pakes, A., and D. Pollard (1989): “Simulation and the Asymptotics of Optimization Estimators,”
  Econometrica, 57(5), 1027—1057.

Pollard, D. (1984): Convergence of Stochastic Processes. Springer-Verlag New York, Inc.

Robins, J. M., S. Greenland, and F.-C. Hu (1999): “Estimation of the Causal Eﬀect of a Time-
  Varying Exposure on the Marginal Mean of a Repeated Binary Outcome,” Journal of the American
  Statistical Association, pp. 687—712.

Robins, J. M., S. D. Mark, and W. K. Newey (1992): “Estimating Exposure Eﬀects by Modelling
  the Expectation of Exposure Conditional on Confounders,” Biometrics, pp. 479—495.

Romer, C. D., and D. H. Romer (1989): “Does Monetary Policy Matter? A New Test in the Spirit of
  Friedman and Schwartz,” NBER Macroeconomics Annual, pp. 121—170.

        (1994): “Monetary Policy Matters,” Journal of Monetary Economics, pp. 75—88.

         (1997): “Identification and the Narrative Approach: A Reply to Leeper,” Journal of Monetary
  Economics, 40, 659—665.

           (2004): “A New Measure of Monetary Shocks: Derivation and Implications,” The American
  Economic Review, 94, 1055—1084.

Rosenbaum, P., and D. B. Rubin (1985): “Constructing a Control Group using Multivariate Matching
  Methods that include the Propensity Score,” American Statistician, 39, 33—38.

Rosenbaum, P. R., and D. B. Rubin (1983): “The Central Role of the Propensity Score in Observational
  Studies for Causal Eﬀects,” Biometrika, pp. 41—55.

Rosenblatt, M. (1952): “Remarks on a Multivariate Transform,” The Annals of Mathematical Statistics,
  23(3), 470—472.



                                                  46
Rubin, D. B. (1974): “Estimating Causal Eﬀects of Treatments in Randomized and Non-Randomized
  Studies,” Journal of Educational Psychology, pp. 688—701.

Shapiro, M. D. (1994): “Federal Reserve Policy: Cause and Eﬀect,” in Monetary Policy, ed. by G. N.
  Mankiew, pp. 307—334. University of Chicago Press.

Sims, C. A. (1972): “Money, Income and Causality,” American Economic Review, pp. 540—562.

        (1980): “Macroeconomics and Reality,” Econometrica, pp. 1—48.

Stock, J. H., and M. W. Watson (2002a): “Forecasting Using Principle Components from a Large
  Number of Predictors,” Journal of the American Statistical Association, 97, 1167—1179.

         (2002b): “Macroeconomic Forecasting Using Diﬀusion Indexes,” Journal of Business and Eco-
  nomic Statistics, 20, 147—162.

Su, L., and H. White (2003): “Testing Conditional Independence via Empirical Likelihood,” UCSD
  Discussion Paper 2003-14.

Sute, W., S. Thies, and L.-X. Zhu (1998): “MOdel Checks for Regression: An Innovation Process
  Approach,” Annals of Statistics, pp. 1916—1934.

VanderVaart, A. W., and J. A. Wellner (1996): Weak Convergence and Empirical Processes.
  Springer Verlag.




                                                    47
                         Rejection Probabilities
             VM-MC      mda     mdb     d1       d2      t-test
γ     β       (1)       (2)     (3)    (4)       (5)      (6)

                          A. Sample Size = 100

0     -0.5    0.096     0.070    0.036   0.070   0.042   0.072
0.5   -0.5    0.140     0.148    0.064   0.080   0.170   0.178
1     -0.5    0.394     0.468    0.292   0.226   0.496   0.574
2     -0.5    0.810     0.888    0.780   0.456   0.906   0.960

0     0       0.082     0.064    0.026   0.046   0.056   0.050
0.5   0       0.154     0.162    0.070   0.068   0.182   0.188
1     0       0.438     0.500    0.328   0.298   0.506   0.570
2     0       0.814     0.906    0.834   0.612   0.862   0.952

0     0.5     0.098     0.060    0.030   0.042   0.060   0.048
0.5   0.5     0.264     0.188    0.088   0.096   0.194   0.202
1     0.5     0.548     0.534    0.360   0.406   0.486   0.616
2     0.5     0.872     0.930    0.868   0.840   0.822   0.970

0     0.9     0.210     0.064    0.010   0.040   0.060   0.042
0.5   0.9     0.436     0.252    0.122   0.180   0.200   0.276
1     0.9     0.766     0.744    0.606   0.616   0.664   0.804
2     0.9     0.928     0.252    0.186   0.158   0.244   0.402

                          B. Sample Size = 200

0     -0.5    0.096     0.058    0.018   0.064   0.054   0.052
0     0       0.084     0.072    0.020   0.052   0.080   0.058
0     0.5     0.104     0.066    0.024   0.050   0.066   0.078
0     0.9     0.226     0.044    0.012   0.034   0.050   0.062

Table 1: Rejection Probabilities from a dynamic Logit Model




                            48
                    k=2                       k=3                        k=4
            md               d        md                d        md                d
1-α         (1)             (2)       (3)              (4)       (5)              (6)
0.5       0.17555         0.13877    0.1224         0.079614   0.08127         0.045061
0.8       0.36124         0.29359   0.21503          0.14446   0.12871         0.073065
0.9       0.51805         0.43536   0.28873          0.20363   0.16503         0.097858
0.95      0.68209         0.58862   0.36511          0.26808   0.20114          0.12482
0.975     0.85668          0.7454   0.44198          0.33422   0.23826          0.15462
0.99        1.081         0.96801    0.5486          0.42748   0.28919          0.19535
0.995      1.2597          1.1296   0.62995           0.4994   0.32922          0.22667
0.999      1.6911           1.573    0.8238          0.68994    0.4225          0.30895
0.9995     1.9174          1.7816   0.91185          0.77078   0.46407          0.33938
0.9999     2.2286          2.1684     1.083          0.99037   0.53436          0.40949

         Table 2: Critical Values based on 100,000 Simulation Replications




                                        49
                                                            Control variables (lagged)
                                            output                   output                      output
                                                                    inflation                  inflation
                                                                                            unemployment
                                      estimate    p-value      estimate    p-value       estimate p-value
        Lagged Romer Dummies             (1)        (2)            (3)       (4)             (5)        (6)
        RD(-1)                         0.0129      0.093         0.0125     0.057          0.0150      0.035
                                      (0.0076)                 (0.0065)                  (0.0070)
        RD(-2)                         -0.0218     0.037        -0.0210    0.022          -0.0176      0.063
                                      (0.0104)                 (0.0091)                  (0.0094)
        RD(-3)                         -0.0176     0.123        -0.0145    0.219          -0.0146      0.159
                                      (0.0113)                 (0.0117)                  (0.0103)
        RD(-4)                         -0.0089     0.292        -0.0043    0.644          -0.0020      0.801
                                      (0.0084)                 (0.0093)                  (0.0079)
        RD(-5)                         0.0013      0.895         0.0042    0.724          -0.0001       0.99
                                      (0.0101)                 (0.0119)                  (0.0109)
        RD(-6)                         -0.0057     0.278        -0.0031    0.543          -0.0078      0.279
                                      (0.0052)                 (0.0051)                  (0.0072)
        RD(-7)                         -0.0182     0.105        -0.0142    0.214          -0.0118      0.216
                                      (0.0112)                 (0.0114)                  (0.0095)
        RD(-8)                         -0.0248     0.011        -0.0238    0.029          -0.0143      0.179
                                      (0.0096)                 (0.0108)                  (0.0105)
        RD(-9)                         -0.0122     0.386        -0.0157    0.235          -0.0122      0.371
                                      (0.0140)                 (0.0131)                  (0.0136)
        RD(-10)                        -0.0228     0.014        -0.0221     0.02          -0.0235      0.002
                                      (0.0092)                 (0.0094)                  (0.0074)
        RD(-11)                        -0.0107     0.199        -0.0075    0.336          -0.0060      0.383
                                      (0.0083)                 (0.0078)                  (0.0068)
        RD(-12)                        0.0019      0.847         0.0035    0.743           0.0056      0.613
                                      (0.0099)                 (0.0106)                  (0.0111)

        R2                               0.3888                   0.4358                   0.5243
        F                                  2.42                     2.05                     1.63
        (p-val)                        (0.0069)                 (0.0250)                 (0.0908)
        F-robust                           2.27                   2.0900                     1.99
        (p-val)                        (0.0115)                 (0.0215)                 (0.0303)

Table 3: Granger Causality Tests using Quarterly Data. Models include 8 lags of the control variables indicated in
the column headings. Robust standard errors are reported in brakets. The F-statistic is for the joint significance
of the lagged Romer Dummies. The robust F-Statistic was computed using White standard errors. The sample
includes 160 quarters from 1952-91.




                                                       50
  Future Output                                     mdb                                                    Logit
  Variable                         (1)               (2)               (3)               (4)               (5)                (6)
  yn(1)                      [0.06, 0.15]       [0.06, 0.15]       [0.06, 0.15]        0.0241            0.0777             0.0604
  yn(2)                       [0.15, 0.3]          [0.6, 1]         [0.3, 0.6]         0.1915            0.1344             0.2113
  yn(3)                     [0.003, 0.006]      [0.03, 0.06]      [0.006, 0.03]        0.1774            0.0536             0.0494
  yn(4)                       [0, 0.0006]        [0.15, 0.3]         [0.6, 1]          0.8805            0.4214             0.2928
  yn(5)                       [0, 0.0006]         [0.3, 0.6]        [0.3, 0.6]         0.0525            0.1572             0.3009
  yn(6)                      [0.06, 0.15]          [0.6, 1]          [0.6, 1]          0.8819            0.9706             0.7651
  yn(7)                    [0.0006, 0.003]        [0.3, 0.6]         [0.6, 1]          0.3144            0.2382             0.2135
  yn(8)                       [0, 0.0006]     [0.0006, 0.003]    [0.0006, 0.003]       0.0227            0.0129             0.0174

  Forecasts                 full sample       out-of-sample       out-of-sample      full sample     out-of-sample      out-of-sample
  Lagged IP controls             No                No                  Yes                No              No                 Yes

Table 4: P-values for the md-statistic and parametric Logit. Square brakets indicate that actual p-value lies in the interval of values
reported in the table. p-values for the md-statistic are based on simulated critical values reported in Table 2 for the d-statistic and
are adjusted to provide a bound as described in the main text. In particular, we use critical values for d and k=3 from Table 2. The
corresponding significance levels are then 6α. We report a confidence level interval because the quantiles of the distribution need to be
computed numerically.




                                                                   51
                 Future Output                                       mda
                 Variable                         (1)                 (2)                (3)
                 yn(1)                      [0.025, 0.05]       [0.025, 0.05]       [0.025, 0.05]
                 yn(2)                        [0.1, 0.2]           [0.2, 0.5]         [0.2, 0.5]
                 yn(3)                     [0.001, 0.005]       [0.01, 0.025]       [0.01, 0.025]
                 yn(4)                    [0.0001, 0.0005]        [0.05, 0.1]         [0.2, 0.5]
                 yn(5)                    [0.0001, 0.0005]         [0.1, 0.2]         [0.1, 0.2]
                 yn(6)                      [0.025, 0.05]          [0.2, 0.5]         [0.2, 0.5]
                 yn(7)                     [0.001, 0.005]          [0.1, 0.2]         [0.2, 0.5]
                 yn(8)                       [0, 0.0006]       [0.0005, 0.001]     [0.0005, 0.001]

                 Forecasts                  full sample        out-of-sample       out-of-sample
                 Lagged IP controls              No                 No                  Yes

Table 5: P-values for the md-statistic. Square brakets indicate that actual p-value lies in the interval of values
reported in the table. p-values for the md-statistic are based on simulated critical values reported in Table 2 for
the md-statistic. In particular, we use critical values for md and k=3 from Table 2. We report a confidence level
interval because the quantiles of the distribution need to be computed numerically.




              Variable    Definition
              IPN         Industrial Production, total Index not seasonally adjusted, revised 1990
              output      Growth Rate Industrial Production New : ∆ ln(IPN)
              RD          Original Romer Dummy
              CPU         Consumer Price Index, all urban consumers, not seasonally adjusted
              inflation   Inflation rate: ∆ln(CPUt )

                                 Table 6: Data Source and Variable Definitions




                                                          52
