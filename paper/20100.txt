                                NBER WORKING PAPER SERIES




                 EVALUATING POLICIES TO PREVENT ANOTHER CRISIS:
                             AN ECONOMIST’S VIEW

                                            Paul S. Willen

                                        Working Paper 20100
                                http://www.nber.org/papers/w20100


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                      May 2014




This paper was prepared for the Cato Papers on Public Policy. I thank the editor, Jeff Miron, for taking
a chance on a somewhat speculative project and Parag Pathak and Neng Wang for thoughtful discussions
at the conference. Helpful comments and suggestions from Alberto Bisin, Ryan Bubb, Chris Foote,
Kris Gerardi, and Bob Triest are gratefully acknowledged. The views expressed in this paper are the
author’s and do not necessarily reflect those of the Federal Reserve Bank of Boston, the Federal Reserve
System, the Federal Open Market Committee (FOMC), or the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2014 by Paul S. Willen. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to
the source.
Evaluating Policies to Prevent another Crisis: An Economist’s View
Paul S. Willen
NBER Working Paper No. 20100
May 2014
JEL No. D61,D82,G21,G28

                                             ABSTRACT

I consider four policies created to address the financial crisis: (1) the ability-to-repay requirement in
mortgage underwriting; (2) reform of rating agency compensation, (3) risk retention in securitization,
and (4) mandatory loan renegotiation. I show that according to standard models, policies (1)–(3) do
not address the standard asymmetric information problems that afflict financial markets. Policy (4)
could reduce the deadweight losses associated with asymmetric information but requires that policy
makers allocate gains and losses.


Paul S. Willen
Federal Reserve Bank of Boston
600 Atlantic Avenue
Boston, MA 02210-2204
and NBER
willen968@gmail.com
               Economic analysis does have one important benefit, which is that it can
               help kill ideas that are completely logically inconsistent or wildly at
               variance with the data. This insight covers at least 90 percent of
               proposed economic policies.

                                                                            – Ben Bernanke, 6/2/20131

In the wake of the financial crisis and recession that started in 2008, policymakers instituted

legal and institutional changes with the goal of preventing a recurrence. In this paper, I evaluate

four of those policies and ask the central question of classical economics: Do these government

policies have the potential to improve upon the market?


Let me illustrate the point of this paper using mandatory risk retention, a key provision of the

Dodd-Frank Act. Mandatory risk retention specifies that firms that securitize mortgages must

retain not less than 5 percent of the credit risk for any security they issue backed by mortgages.

The idea is that the 5 percent retained risk exposes the lender to losses when borrowers default,

inducing the lender to exert more effort underwriting loans, which in turn, reduces losses to

investors. Is welfare higher in an economy with government-mandated risk retention than it

would be without it? The answer is not clear. If the benefit of fewer defaults to the investor

exceeds the cost of retained risk to the lender, why wouldn’t the lender volunteer to retain the

risk? Why would government need to force investors and lenders to do something that is

already in their interests? The purpose of this paper is to answer these questions. Surprisingly,

in the literally thousands of papers, reports, and op-eds written about the role of securitization

in the crisis, no one has really tried to answer them. Policymakers and, surprisingly, most

economists have been satisfied with the argument that risk retention leads to more effort and

have not seen the need to evaluate the costs and benefits of that effort.


In what follows, in addition to risk retention (Section 3) I discuss the ability-to-repay

requirement (Section 1), reform of rating agency compensation (Section 2), and mandatory loan

renegotiation (Section 4), each time asking the same question, Does this policy improve on the


1
    http://www.federalreserve.gov/newsevents/speech/bernanke20130602a.htm


                                                       2
market? As with any policy analysis in economics, the starting point is the first theorem of

Classical Welfare Economics, the “First Welfare Theorem” hereafter, which states that under

standard assumptions, market equilibrium is Pareto optimal, meaning that if we try to

reallocate resources, the only way we can make one person better off is by making someone else

worse off. The necessary conditions for the First Welfare Theorem to hold are many, but the

ones we care about here are that (1) all market participants have the same (“symmetric”)

information; (2) all market participants are rational; and (3) there are no externalities. For

government policies to work, one of these assumptions must fail.


Two pieces of economic jargon help here. If the First Welfare Theorem does not hold in an

economy, then we say that there is a market failure in the economy. The gap between the

optimal allocation (one with resources reallocated) and market equilibrium is known as the

deadweight loss of the market failure. Policy analysis in classical economics essentially consists

of the search for deadweight losses. The existence of a deadweight loss is a necessary condition

for effective policy and the net reduction of deadweight loss is a sufficient condition.


In Sections 1 to 4, the main focus is on whether failure of the first assumption, symmetric

information, is enough to justify the policies. These sections form the core of the paper because

all the policies I discuss involve some form of asymmetric information. For example, the

economic issue in risk retention is that investors (or anyone else providing funds to a lender,

including depositors or shareholders) cannot observe how much effort the lender puts into

underwriting a loan. This asymmetric information does lead to a deadweight loss in

equilibrium, but I show that, under standard assumptions, mandatory risk retention actually

makes the deadweight loss worse.


For all of the policies except loan renegotiation, I argue that, according to standard models,

asymmetric information alone cannot justify government intervention. In all three cases,

another argument for government intervention is that market participants are irrational. In my

view, irrationality is at the heart of many of the bad decisions that caused the crisis, but the




                                                 3
policies described do not deal with the relevant problem: unrealistic beliefs about house price

appreciation.


In Section 5, I turn to externalities. Foreclosure externalities could provide justification for any

of the four policies because all, in theory, could reduce the number of foreclosures, but I draw

attention to the distinction between physical externalities, which always generate deadweight

losses, and pecuniary externalities, which under standard assumptions, do not.


There exists, for all practical purposes, a theorem in economics that for any proposed economic

policy there is some cocktail of market imperfections that can justify the policy. Geanakoplos

and Polemarchakis (1986), for example, show that with multiple goods and incomplete markets,

a government policy always exists that can increase welfare. But precisely because it is so easy

to come up with such examples, the null hypothesis in economics has been that government

policy cannot improve on the market. To show that a policy will work, one must have robust

evidence of a market imperfection and a clear logic for how the proposed policy addresses it. I

argue below that only one of the proposed policies, mandatory loan modifications, appears

most likely to pass this test.


All policy analysis in economics depends on what we assume about the economy and, here, the

two key assumptions are that the economy is composed of rational individuals and that

foreclosures generate no physical externalities. As I explain, failure of either of these conditions

could make the four policies discussed welfare improving. However, to make policy work,

economists cannot simply say that people are irrational or that there are externalities. If one

believes, for example, that investors in subprime securities were irrational, then we need to

know how they were irrational and how important that irrationality was. So, in a sense, this

paper is not a criticism of policy but rather a call for better models and better research.


1 Ability to Repay

Title XIV(B), Section 1411, of Dodd-Frank states the following:


                                                  4
          In accordance with regulations prescribed by the Board, no creditor may make a
          residential mortgage loan unless the creditor makes a reasonable and good faith
          determination based on verified and documented information that, at the time
          the loan is consummated, the consumer has a reasonable ability to repay the
          loan, according to its terms, and all applicable taxes, insurance (including
          mortgage guarantee insurance), and assessments.

On the face of it, Section 1411 seems like common sense. Would a rational lender make a loan

that a borrower doesn’t have a “reasonable ability to repay”? And would a rational lender make

a determination without “verified and documented information”? Yet, I contend that the

answer to both questions is “yes” and that, as a result, the ability to repay generates deadweight

losses.


Let us start with the idea that a lender should make loans only when the borrower has, “a

reasonable ability to repay the loan.” On the face of it, this sounds reasonable. Why would a

lender make a loan if the probability of default was high? Why would a rational borrower want

such a loan? The classic subprime story is of a person who has a history of credit problems, a lot

of high-interest, unsecured debt, and an equity stake in his or her home. By taking out a

mortgage secured by the house, the borrower can get a much lower interest rate and in doing

so, improve his finances. To be sure, there is a high likelihood that the borrower will default,

but the lender compensates for this by charging a much higher interest rate than if the borrower

had a clean credit history. In this example, the borrower gets a lower interest rate than would be

available without home equity collateral, and the lender gains because the benefits of the high

interest rate outweigh the costs of higher default risk, so both parties gain from the transaction.

In this example, by preventing lenders from making loans because the borrower lacks a

“reasonable ability to repay the loan,” Section 1411 creates a deadweight loss: the benefits to the

borrower of getting the loan exceed the costs to the lender of producing the loan.


Now, we turn to the question of verification. Even if lenders want to make risky loans, doesn’t it

always make sense to verify what the borrower reports? The answer, again, is “not necessarily.”

Suppose we have a lender who is confronted with 10 observably identical borrowers who have

applied for $10 loans. Four of the borrowers will default on their loans and the lender will


                                                5
recover nothing. To understand the lender’s problem, we turn to a great insight attributed to the

pioneering 19th century retailer John Wanamaker, who famously quipped,


       Half the money I spend on advertising is wasted; the trouble is, I don’t know
       which half.

The lender here might paraphrase Wanamaker, saying, “I have 10 borrowers and four will

default; the trouble is, I don’t know which four.” Suppose, however, that by verifying the

information in the borrower’s application, the underwriter can identify two of the defaulters,

but suppose that the verification process costs $2.50 per loan. Should a rational lender do it?

One might think the answer would be an emphatic yes. By spending $2.50, the lender can avoid

a much bigger loss of $10. But in fact, the answer is no. The problem is that the lender has to pay

the verification costs on all 10 loans because, of course, the point here is that he can’t tell which

borrowers will default, so the cost of verification is actually $25. Since verification prevents only

two defaults, it saves the lender only $20, so the costs of verification outweigh the benefits and

the lender opts against verification.


1.1 A simple model of underwriting

To expand on this example, consider a simple model of underwriting due to Bubb and

Kaufman (2009). Suppose we have a set of borrowers. For each borrower, the lender observes a

verifiable, public piece of information x. Think of x as, for example, an index of the number of

times the borrower has been delinquent on his or her current mortgage in the last year. For

simplicity, assume that x is some number between 0 and 1 and that x equals the probability of

default. In other words, if 100 borrowers apply for loans with x = 0.2, then the lender knows that

20 of the borrowers will default, but, of course, the problem is that the lender doesn’t know

which 20. We can formalize the idea of verification by supposing that if the lender pays an

amount c, it can identify some fraction s of the borrowers who will default. If s is 50 percent and

x is 20 percent, then the lender will learn the identity of 10 of 100 defaulters. After verification,

the lender extends loans to the remaining 90 borrowers, knowing that 10 will default, but,

again, the lender does not know which 10.

                                                 6
Suppose that the lender earns an interest rate of R > 1 if the borrower repays and faces a cost of

funds of 1. The lender faces a choice: to verify or not to verify. If the lender chooses not to

verify, the payoff is:



                                                                                               (1)
                                              .


If the lender chooses to verify, then the payoff is:



                                                                                                (2)
                                                                                        .

Subtracting equation (1) from equation (2) yields the condition for optimal verification:




Verification makes sense only if s ⋅ x, the losses associated with the defaulters identified by the

verification, exceed the costs, implying that if x is sufficiently low (< xA), verification does not

make economic sense.


To illustrate the effects of mandatory verification, I plot the payoff to verifying loans and not

verifying loans as a function of x, the ex ante probability of default. The top panel of Figure 1

shows that we can divide borrowers into three regions. For the borrowers with x > xR, lending is

never profitable, even with verification. At the other extreme, the costs of screening exceed the

benefits for borrowers with x<xA, so the lender accepts these borrowers without screening. In

the middle, the benefits of screening exceed the costs and the lender screens. Screening clearly

generates welfare benefits: For borrowers between xA and xR, profits are higher for the lender

and, in the absence of screening, borrowers between xR and x* would not get loans at all.

Suppose Congress now imposes mandatory verification. What happens to welfare? The green

shaded area on the upper left shows the resulting deadweight loss. No additional borrowers

receive credit, and for the lender, the benefits of the additional screening do not justify the costs.




                                                  7
The lower panel of Figure 1 shows the effect of mandatory screening when the cost of

verification is even higher. Suppose, for example, that we are considering a sample of self-

employed borrowers for whom measuring income is extremely complex. In this example, x*

falls below xA, so verification dominates only for loans that are unprofitable anyway. The

resulting deadweight loss is, of course, much larger but there is an even worse aspect. Now,

mandatory verification means that loans between xV and x* are no longer profitable for the

lender, and borrowers in that region no longer receive credit.


1.2 The role of irrationality

For lenders at least, forcing verification reduces welfare. Some critics of the lending industry

have accused lenders of “not bothering” to verify income, but, as the model shows, a perfectly

rational lender may choose not to verify. Proponents of the ability-to-repay rule will respond

that the purpose is not to protect lenders but to protect borrowers. But, to an economist, this

argument should strike one as odd. Notice that in our simple model of underwriting it is the

borrower who has private information about whether he or she can repay the loan, not the

lender. The purpose of the underwriting process is to maximize profits for the lender, not to

maximize utility for the borrower.


Ultimately, any justification for the ability-to-repay standard has to rely on a behavioral model

and argue that limiting choice increases borrower utility. Laibson (1997) has stressed the idea

that when we consider alternatives to classical assumptions on preferences, limiting choice can

make an individual better off. Gul and Pesendorfer (2001) consider preferences defined over

sets of consumption bundles in which it is possible for a consumer to prefer a subset to the set

itself. In either setup, it is possible that a borrower’s utility will be higher if Congress makes it

impossible for him to get a loan.


My view is that the deeper problem here is that the true irrationality in the crisis involved

expectations of house price appreciation. A mortgage is collateralized debt and the assumption

underlying the contract is that the value of the collateral guarantees the ability to repay because


                                                 8
the borrower can sell the house. In 2005, both borrowers and lenders were exceptionally

confident that houses would be significantly more valuable over time and very unlikely to be

less valuable. Under those circumstances, the ability-to-repay standard would have had only a

minimally deterrent effect. The only way in which ability to repay from income would be an

issue is if the ability to repay by selling was not an option, and, since the lender believed this

latter scenario to be highly unlikely, the benefits of high-interest income from subprime loans

would outweigh the cost of the higher risk of a lawsuit in the event that the borrower proved

unable to sell the house and lacked the income to repay the loan.


Before concluding, it is important to stress how odd the ability-to-repay standard is. To see

why, consider another important decision: hiring. If we applied a similar rule to hiring, we

would require that employers carefully verify everything in a prospective job applicant’s file. If

the worker were hired and then subsequently fired, the worker would have the right to sue the

employer if the worker found out that, for example, the employer had failed to call all the

references. No such law has ever been proposed despite the fact that the consequences of job

loss are, in many cases, worse than those of default and foreclosure.


2 Rating Agencies

Title IX: Subtitle C of the Dodd-Frank Act specifies, “Improvements to the Regulation of Credit

Rating Agencies.” The authors of the bill wrote:


       In the recent financial crisis, the ratings on structured financial products have
       proven to be inaccurate. This inaccuracy contributed significantly to the
       mismanagement of risks by financial institutions and investors, which in turn
       adversely impacted the health of the economy in the United States and around
       the world. Such inaccuracy necessitates increased accountability on the part of
       credit rating agencies.

As a result, they proposed that:


       In certain activities, particularly in advising arrangers of structured financial
       products on potential ratings of such products, credit rating agencies face


                                                9
       conflicts of interest that need to be carefully monitored and that therefore should
       be addressed explicitly in legislation in order to give clearer authority to the
       Securities and Exchange Commission.

Among other things, the law directs the SEC to study the following aspects of the institutional

structure of the rating agency model:


       (1) the credit rating process for structured finance products and the conflicts of
       interest associated with the issuer-pay and the subscriber-pay models; (2) the
       feasibility of establishing a system in which a public or private utility or a self-
       regulatory organization assigns nationally recognized statistical rating
       organizations to determine the credit ratings of structured finance products,

What is the basic economics here? Rating agencies analyze securities and evaluate the likelihood

of credit losses and then relate that information to investors who can, as a result, make rational

decisions about whether to invest in the securities. According to the crisis consensus, the

problem was that rating agencies had a conflict of interest because they were paid by the issuers

of the securities they were supposed to evaluate. The result was that the agencies gave

optimistic ratings which led investors to over-invest in securities and subsequently lose money.


On the face of it, this appears to be a classic example of incentives at work, but what does

economic theory say? Consider a simple model of rating agencies. Suppose that there is a

lemons problem in the securities market. Issuers have private information about whether a

security is a peach, which is worth VG to investors and VG - δ to the issuer, or a lemon, which is

worth VB < VG to investors and VB - δ to the issuer. The probability that a security is a peach is π,

and we assume that the expected value of a security is πVG + (1-π)VB < (1-δ)VG. Investors know

their own valuation, the valuation of the issuer, and the probability of a peach, but they do not

know whether a particular security is a peach or a lemon. Akerlof (1970) showed that in such a

model, the only securities traded in equilibrium are lemons. The intuition is that if the investor

knows that if he pays the expected value of the security πVG + (1 - π)VB, the issuer will sell only

the bad security, meaning that the investor will lose money, so the only possible equilibrium is

with price VB. Equilibrium is Pareto inefficient because the investor values the peach more than

the issuer does, but trade cannot take place.


                                                 10
Suppose we introduce a rating agency. The issuer reveals its private information to the rating

agency, which, in turn, can credibly announce whether a particular security is a peach or a

lemon. Now trade can occur in both securities at prices VG and VB, respectively. The new

equilibrium is Pareto improving, as the price for the lemons stays the same but trade now

occurs for peaches, making the issuer better off because he receives VG for something he valued

at only VG - δ.


What can go wrong? The critique of rating agencies on which Dodd-Frank is based depends on

the fact that the pay of the rating agency depends on the rating. Suppose, we change the model

above a little and say that the rating agency is paid a share of the valuation of the security, γ(Vi -

VB). Now the rating agency has an incentive to always report that the security is a peach because

it will get paid γ(VG - VB), but if it reports that the security is a lemon, it will get nothing. Now if

investors pay VG, on average they will get securities worth πVG + (1 - π)VB < VG. According to

this narrative, misaligned incentives of rating agencies can explain why investors lost money.


There is a flaw in the logic here: the situation described is not an equilibrium. The investors in

the model do not know whether a security is a peach or a lemon, but they know the incentives

of the issuer and the rating agency. If the rating agency makes more money by saying that a

security is a peach, then the agency will always say a security is a peach and therefore the rating

will have no meaning. As a result, the investor will treat the rating as “cheap talk” and the

original Akerlof equilibrium will re-emerge. Who loses? Everyone. Since all traded securities

are lemons, the rating agency gets paid nothing and both the issuer and investor lose the gains

from trading peaches.


2.1 The role of irrationality

Of course, one could argue that investors did not understand the conflicts of interest for the

agencies, but, given that the firms that lost the largest sums of money on structured products




                                                  11
were issuers of the securities, that is a hard argument to make.2 In addition, even if one tried to

argue that investors were ignorant of the corruption of the rating agencies in 2005, it is hard to

see how they could remain ignorant now; yet all three rating agencies are still doing business

and still rating mortgage-backed securities.


2.2 Alternative information issues in ratings

That said, one cannot dismiss the broader idea that bad ratings have real effects, but to do so,

one needs to understand exactly what ratings were used for. Specifically, investment funds

often use ratings to limit a manager’s investment choices. For example, pension funds might say

that the manager of the fund can invest only in AAA-rated securities.


I propose that use of rating agencies to limit investment manager choice results in a different

asymmetric information problem. Suppose that the returns to a pension fund depend on the

unobservable effort of the manager, so, following the discussion in Section 3, the manager’s

compensation depends on returns. However, suppose that the fund manager is risk neutral and

the investors are risk averse. By investing in riskier assets, the manager can raise the expected

return and his expected pay but at a cost of increasing risk to the investors. One solution to this

problem would be to limit the fund manager to observably low-risk securities, which is exactly

what funds typically do.


The implication of the fund’s asymmetric information problem is that the investment manager

now has an incentive to get the rating agency to give high ratings to risky products. In other

words, both the issuer and the investment manager have an incentive to get high ratings for

lemons. If this were the case, then the “investor pays” model would be no more likely to lead to

more accurate ratings than the much-maligned “issuer pays” model.




2
 Bolton, Freixas, and Shapiro (2012) construct a model with “naive” investors who do not understand the incentives
of the rating agency.



                                                       12
In the end, though, the point here is that, for the rating agencies to have value to issuers, they

must have value to investors, otherwise investors would not pay more for a rated security than

they would for an unrated security. And to have value to investors, rating agencies must be

credible. In other words, the rating agencies have a strong market incentive to solve the

credibility problem and it is not clear why government needs to tell them to do it. No

government agency needs to regulate Consumer Reports to make sure they are objective: If they

were perceived to be biased, no one would pay for the magazine.


3 Risk Retention

Title IX: Subtitle D of the Dodd-Frank act, entitled, “Improvements to the Asset-Backed

Securitization Process,” specifies that firms that securitize mortgages are required to retain not

less than 5 percent of the credit risk for any security they issue that is backed by mortgages.

Framers of the law included an exemption for “qualified residential mortgages” (QRMs), which

are loans deemed to be of low risk of credit loss. The law also prohibits securitizers from

hedging or transferring the credit risk that it is required to retain with respect to the assets.


Risk retention has been broadly popular across the board, earning praise from journalists,

academics, and policymakers. One of the reasons why so many mortgages defaulted, the

argument goes, is that the lenders who made the loans were selling the loans in securities and

had no reason to invest effort in underwriting the loans because they did not share in any losses

when the loan defaulted. In popular parlance, lenders had no “skin in the game.” If lenders

knew they would lose money if loans defaulted, they would have been much more careful.

With more careful underwriting, investors, in turn, would not have lost money on mortgage

backed securities (MBSs) and we would not have had a crisis. Keys et al. (2013), for example,

write that it would be:


       …beneficial to enforce some mandatory retention of a fraction of lower tranche
       by originators/ underwriters to better align their interests with those of investors.




                                                  13
How does this fit in to our discussion of the First Welfare Theorem? Proponents of risk

retention argue that there is an asymmetric information problem in securitization. Although one

can imagine how mortgage underwriting could lead to both moral hazard and adverse selection

problems, researchers and policymakers have focused on the moral hazard problem, which

results from the fact that investors cannot observe how much effort the securitizer puts into

screening the mortgages. As previously mentioned, the presence of asymmetric information

typically leads to inefficiency, and thus, in principle, government policy might lead to a welfare

improvement. But, as I will show now, the Dodd-Frank requirement not only fails to eliminate

the deadweight loss caused by asymmetric information, it actually inflates it.


It is important to stress here that securitization does not create the moral hazard problem, but is,

instead, a method of dealing with it. The underlying problem in financial intermediation is that

savers want to lend to borrowers but need someone to help them make sure they get their

money back. The moral hazard problem emanates from the fact that the savers cannot observe

the effort put in by the intermediary. Over the years, market participants have come up with

many different mechanisms to deal with the moral hazard problem. Securitization is one

contract, or incentive scheme as we call it below, in which the intermediary takes on very little

of the risk of default. An alternative contractual mechanism is portfolio lending, in which the

owners of the bank (who may not be the ones making the lending decision) take on all the risk.

The problem of choosing the optimal contract consists of deciding which incentive scheme

maximizes the joint surplus of the intermediary and the savers. In other words, which incentive

scheme deals best with the underlying problem that the savers cannot observe the effort of the

intermediary?


To understand the problem of incentives in mortgage underwriting, we consider a pool of 10

loans. If the lender puts no effort into underwriting the loans, three borrowers will default, but,

as always, the lender does not know which three. By investing effort, the lender can identify the

problem borrowers. The column labeled total effort in Panel A of Table 1 shows that by

spending $4 in effort, the lender can identify one of the problem borrowers and thus reduce

defaults to two from three. The column labeled “marginal effort” shows that the cost of

                                                14
reducing defaults is increasing: the marginal effort required to reduce defaults from two to one

costs twice as much as to reduce defaults from three to two. The columns labeled “Recovery”

show the benefits of default prevention: for each default prevented, the total recovery of

principal increases by $10.


Now suppose that we have an investor who wants to invest in mortgages and so he offers to

buy mortgages from a lender. The lender is willing to underwrite mortgages but has an outside

option which will yield a profit of $69. In the language of contract theory, we call the investor

the principal and the lender the agent. How can the principal ensure that the agent expends the

proper amount of effort? Panel B shows three possible incentive schemes that the principal can

use. In each scheme, the principal promises the agent a combination of a fixed payment and an

incentive payment, which is a fraction of the amount recovered. For example, Incentive Scheme

1 gives the agent a base payment of $33 and then the agent keeps 50 percent of any money

recovered. For example, if the agent expends effort of $4, the agent will receive 33 + 0.5 × 80 =

$73, which yields a profit to the agent of 69, which is the $73 payment less the $4 expended in

effort.


The design of the optimal contract proceeds in two steps. First, the agent chooses a level of

effort conditional on the contract. For Incentive Scheme 1, marginal analysis shows that the

optimal level of effort for the agent is $4: the marginal income to the agent from reducing a

default is 0.5 × 10 = $5, which exceeds the marginal cost of reducing defaults from 3 to 2, but not

from 2 to 1. The top left graph in Figure 2 illustrates the agent’s optimal decision graphically.


In the second stage of the solution, the principal chooses an incentive scheme, taking the agent’s

optimal response as given. In other words, the principal scans Panel A of Table 1 and,

corresponding to each incentive scheme, the principal can read off levels of effort, defaults, and

payments to the agent and, as a result, profits. Analysis of Panel A illustrates a central point of

contract theory: despite not being able to observe effort directly, the principal can deduce the

effort level from his understanding of the agent’s optimal decision problem. The top right panel

of Figure 2 makes the point that the principal can, in a sense, invert the agent’s decision


                                                 15
problem and, in doing so, choose the level of unobservable effort by choosing the incentive

scheme.


Which is the optimal scheme? This is displayed in Panel B of Table 1. For example, for Incentive

Scheme 3, the agent will put in maximal effort leading to 0 defaults and a profit of $7 to the

principal. Incentive Scheme 1 will generate much less effort, but the corresponding payment to

the agent is smaller so the profit stays the same at $7. Incentive Scheme 2 yields maximal profits

with more effort than Scheme 1 but lower payments than Scheme 3.


What are the welfare implications? Incentive Scheme 2 is privately optimal, but is it socially

optimal? Yes. The lower left panel of Figure 2 illustrates the principal’s choice graphically. The

principal’s choice of 1 default maximizes the total social surplus and is thus socially optimal.

Adam Smith’s “Invisible Hand” at work again!


If the private outcome is socially optimal, then why did I say in the introduction that the First

Welfare Theorem fails in the presence of asymmetric information? The reason is that there is no

meaningful asymmetric information problem here. The principal cannot observe effort, but he

can observe output, which is perfectly correlated with effort. To see the failure of the First

Welfare Theorem, we need to introduce asymmetric information, and we do this by supposing

that there is some random variation in the number of defaults. If the agent expends $4 in effort,

the expected number of defaults equals 2, but suppose, actually, with 50 percent probability

there will be 1 default and with 50 percent probability, there will be 3.


Risky payoffs to the agent change the profit maximizing contract. The optimal contract from

Panel B now delivers the agent a lottery paying 72 and 90 with equal probabilities. For a risk-

averse agent, the lottery is worth less than a certain payment of 81, meaning that the agent’s

utility now falls short of 69, and, recall from above, we assumed that the agent had an outside

option paying 69, so now the agent rejects the contract and refuses to work. Assume,

specifically, that the agent has negative exponential utility with an absolute risk aversion

coefficient of 0.69, which implies that Incentive Scheme 2 yields a utility of 61, 8 less than it did


                                                 16
with certainty. Similar analysis of Incentive Scheme 1 shows that the addition of uncertainty

also lowers the utility of the contract to the agent. However, because risk retention is lower, the

sensitivity of the payout is smaller (Incentive Scheme 1 pays out 68 and 78 with equal

probabilities as opposed to 73 with certainty) and so risk reduces utility from 69 to 65, that is, by

half as much as for Incentive Scheme 2.


By raising the base payments, the principal can induce the agent to come back to work, and

Panel C of Table 1 shows the uncertainty-adjusted incentive schemes. Panel C shows that

uncertainty has inverted the ranking of the two Incentive Schemes: Incentive Scheme 1 is now

profit maximizing. What changed? The key point here is that the addition of risk

disproportionately affects Incentive Scheme 2 because of the higher level of risk retention.


The bottom right panel of Figure 2 illustrates the effects of adding uncertainty. The dashed line

shows the marginal cost of different levels of effort and defaults. Without uncertainty, the

principal simply had to compensate the agent for his effort, but now, to elicit a higher level of

effort, the principal must increase risk retention, which, in turn, increases risk for which the

principal must now compensate the agent. In other words, there are two components to the

marginal cost of effort: the direct cost of compensating the agent for his time and the indirect

cost of eliciting effort.


What about welfare? The failure of the First Welfare Theorem occurs here because of the

indirect cost of eliciting effort. An all-knowing, all-seeing social planner would not need to use

risk retention to get the agent to work and would choose the higher level of effort because the

marginal benefit of reduced defaults exceeds the marginal cost of additional effort by the agent.

Compared to that benchmark, there is a deadweight loss represented by the gray shaded area

under the marginal benefit line.


But is an all-knowing, all-seeing social planner the right benchmark? For situations like this,

economists have defined an alternate welfare concept called “Constrained Pareto Optimality,”

which limits the planner to the same information set as the one the principal has, meaning that


                                                 17
the planner has to choose from the same incentive schemes as the principal. In designing the

Dodd-Frank risk retention requirement, Congress implicitly acknowledged the idea of

constrained optimality by imposing an incentive scheme and not a level of effort.


Does the risk retention requirement increase welfare? Suppose, in the model, Congress decided

that it wanted first-best levels of effort and, as a result, imposed Incentive Scheme 2 on the

principal. The bottom right panel of Figure 2 shows that such a rule would create a deadweight

loss. On one hand, the policy would eliminate the deadweight loss of reduced effort— the

shaded area under the marginal benefit curve— but the cost of eliminating that deadweight loss

would be the area between the two marginal cost curves, which, by construction, exceeds the

deadweight loss from reduced effort; the overall deadweight loss is the red shaded triangle

above the marginal benefit line.


Before continuing, it is important to address three questions:


1. By reducing defaults, wouldn’t a requirement of risk retention have attenuated the crisis?


Yes and no. In theory, mandatory risk retention should have had no effect on the investors’

massive losses, which caused the financial crisis. This may sound surprising, as we have shown

that higher risk retention reduces defaults, but the problem here is that investors lose money

not when more borrowers default but when more borrowers default than expected. With more

risk retention, investors would have expected more effort and fewer defaults and so, in the

model, the losses would have been exactly the same.


At the same time, in the model, requiring risk retention does lead to fewer defaults. In a sense,

one can think about retention as a tax on defaults: it causes a deadweight loss, but it does

reduce defaults. In Section 5, we return to this question.


2. Isn’t there empirical evidence showing that securitization caused lenders to expend less effort and thus

contribute to the crisis?




                                                    18
Many researchers cite a paper by Keys et al. (2010) as evidence that securitization led to lower

levels of effort in underwriting, which, in turn, caused the crisis. Keys et al. (2010) purport to

show that when lenders knew that there was a higher likelihood that they would sell the loan in

a security, they did a worse job screening, leading to higher default rates.3 The problem with

interpreting Keys et al. (2010) as evidence in favor of the Dodd-Frank risk retention requirement

is that their findings are completely consistent with the model described above. They show that

more risk retention leads to more effort and, in the model, more risk retention leads to more

effort, as shown in Figure 2, but risk retention still reduces welfare. In other words, all Keys

et al. (2010) do is confirm that the top left panel of Figure 2 is an accurate description of the

world.


To illustrate the point, suppose policymakers were considering an interest rate subsidy for

manufacturers as a way of increasing manufacturing investment. What Keys et al. (2010) do is

essentially equivalent to showing that lower interest rates lead to more investment, but it would

obviously be wrong to conclude that manufacturing investment was suboptimal or that an

interest subsidy would be welfare improving.


3. Doesn’t the model imply that some risk retention is optimal?


In the model, the optimal incentive scheme involves 50 percent risk retention, far in excess of

what Dodd-Frank requires. Indeed, in the Holmstrom-Milgrom model, the optimal scheme

always involves some risk retention, so one might conclude that whether five percent is right or

not, it is still better than the zero percent that prevailed in many securitization deals in 2005.

Doesn’t this mean that policy should at least force lenders always to retain some risk if not

exactly five percent? No. The purpose of the model is to illustrate how the market determines

the optimal level of risk sharing. The fact that firms in the real world did not exactly conform to



3Bubb and Kaufman (2009) argue that Keys et al. (2010) misunderstood the institutional evidence and that the
patterns they observed reflect underwriting rules having nothing to do with securitization, but, for pedagogic
purposes, we will assume that the interpretation by Keys et al. (2010) is correct.




                                                     19
the model means there is something wrong with the model, not that there is an opportunity for

government to tell firms what to do.


To illustrate the point, consider portfolio choice theory. All standard models of portfolio choice

imply that the optimal allocation to stocks is greater than zero. But the data show that many

households hold no equities. One might argue that, based on the model, the government

should enforce a minimum 5 percent allocation to stocks. But, instead, economists have tried to

come up with economic explanations for why so few households hold stock.


3.1 Moral hazard and government policy

The fact that the risk retention requirement enhances incentives but that a government policy to

increase risk retention reduces welfare exposes a tension in economic thought. On one hand,

standard economic theory stresses the role of incentives. Adam Smith, the father of the

“invisible hand,” wrote:

          It is the interest of every man to live as much at his ease as he can; and if his
          emoluments are to be precisely the same, whether he does, or does not perform
          some very laborious duty, it is certainly his interest either to neglect it altogether,
          or to perform it in [a] careless and slovenly a manner. (Smith, 1776)

Milton Friedman, Smith’s modern disciple, makes a similar argument, laying out a simple

theory:

          When you spend, you may spend your own money or someone else’s; and you
          may spend for the benefit of yourself or someone else. Combining these two
          pairs of alternatives gives four possibilities summarized in the following simple
          table:” (Friedman and Friedman, 1980, 116)


                                              On Whom Spent
                       Whose Money           You         Someone Else
                       Yours                   I              II
                       Someone Else’s         III             IV
Friedman then focuses on Category IV:

          “Category IV refers to your spending someone else’s money on still another

                                                    20
       person. You are paying for someone else’s lunch out of an expense account. You
       have little incentive either to economize or to try to get your guest the lunch he
       will value most highly.” (Friedman and Friedman, 1980, 117)

The tension here is that both Adam Smith and Milton Friedman were dedicated opponents of

government intervention in markets, and, I am quite certain, would have opposed the Dodd-

Frank risk retention provision. But how could they oppose a policy that moves economic

activity from Box IV of the table above to Box I? The key point of the principal-agent model is

that the principal knows that more risk retention leads to more effort but chooses less risk

retention. In Friedman’s example, the employer knows that workers in Category I work harder

than workers in Category IV, and, in a market economy, the employer is free to choose

Category I if she wants to do so. The fact that she chooses Category IV despite the availability of

Category I means that, for some reason, she believes that the benefits of Category IV versus

Category I outweigh the costs.


Another way to see this point is to understand how the Dodd-Frank requirement affects the

different market participants. Proponents view it as a limit on the behavior of the agent: the law,

as written, circumscribes the behavior of the agent. But in practice, the law actually restricts the

choice set of the principal: the law blocks an investor who wants to take on all the credit risk in

a transaction from his desired choice. The implicit presumption of the framers of Dodd-Frank

was that no reasonable person would want to invest in a security in which the issuer held no

risk retention. But we turn to the central principle established by Smith and described by

Friedman as follows:


       “Adam Smith’s key insight was that both parties to an exchange can benefit and
       that, so long as cooperation is strictly voluntary, no exchange will take place
       unless both parties do benefit.” (Friedman and Friedman, 1980, 1)

3.2 More general models

In the example in Table 1, government policy cannot increase welfare, but the result is

substantially more general than that. The example is, as mentioned already, a special case of

Holmstrom and Milgrom (1987), and the result extends to that model. But, in fact, Prescott and

                                                21
Townsend (1984) show that in any moral hazard model with a single consumption good,

equilibrium is constrained to be efficient, so the risk retention requirement always reduces

welfare. In adverse selection models, Bisin and Gottardi (2006), however, show that equilibrium

is typically constrained inefficient. In other words, government could increase welfare by

restricting the space of available contracts. However, the general problem in adverse selection

models is that there is too little risk sharing, not too much. Consider the leading example, health

insurance. Rothschild and Stiglitz (1976) consider a world where risk-averse individuals have

private information about how healthy they are and show that the First Welfare Theorem fails

because more healthy individuals fail to insure fully—in other words, they retain some of their

health risk. The solution, according to Rotschild and Stiglitz (1976), and as implemented in the

Affordable Care Act, is to force individuals to buy insurance—to ban risk retention. In other

words, if economists really believed that adverse selection was a problem in mortgage

underwriting, the solution would not be to force lenders to retain bad loans, it would be to force

them to securitize good loans!


In models with multiple goods, the situation becomes more complex. Changes in policy have

general equilibrium effects on relative prices and pretty much anything can happen. Greenwald

and Stiglitz (1986), in a celebrated paper, show that, generically, governments can change the

contract space in such a way as to increase welfare. The issue with asymmetric information is

that agent behavior is circumscribed by a set of incentive compatibility constraints. As

Greenwald and Stiglitz (1986) show, changes in relative prices can relax these constraints and

thus lead to a welfare improvement.


To illustrate why the existence of additional constraints allows government policy to improve

welfare, consider some real world examples. Suppose that lenders constrain households to

borrow up to a specific multiple of income when they are buying homes. For households with

an upward-sloping income profile, as Gerardi, Rosen, and Willen (2010) show, such a constraint

prevents smoothing of housing consumption over the life cycle. A government policy to drive

down house prices relaxes the borrower’s constraint and allows him to buy a bigger house and

better smooth consumption over the life cycle. An alternative example is that existing

                                                22
homeowners who want to move face a downpayment constraint, as in Stein (1995). A

government policy to increase house prices would relax the downpayment constraint and allow

better matching of households with homes.


Congress points explicitly in the Dodd-Frank Act to the possibility that risk retention has broad

effects. In Section 946, Congress asks for a, “Study On The Macroeconomic Effects Of Risk

Retention Requirements.” Specifically, they propose


          ...an analysis of the effects of risk retention on real estate asset price bubbles,
          including a retrospective estimate of what fraction of real estate losses may have
          been averted had such requirements been in force in recent years.

The link between risk retention and asset price bubbles is, at best, purely speculative.

Economists have few good models of how bubbles form and no models that link low levels of

risk retention to bubbles. Indeed, the macroeconomic effects, almost by definition, are

somewhat limited. To understand why, remember that the upper right panel of Figure 2 shows

that principals can infer how much effort agents are putting in, meaning that, in the models at

least, if investors invest in mortgage-backed securities (MBS) with low levels of risk retention,

they do so knowing that many borrowers will default, and therefore they will pay a

correspondingly low price.


Ultimately, pointing to the macroeconomic benefits of risk retention is also somewhat

disingenuous. The main appeal of risk retention is its simplicity, displayed in the top left panel

of Figure 2. More risk retention leads to more effort; that at least is settled in economics. As we

have explained here, that alone, unfortunately, does not justify mandatory risk retention as a

policy.


3.3 Irrationality

One potential justification for risk retention is that investors did not understand that there was a

relationship between risk retention and effort. To see why investor misunderstanding could

lead to an opportunity for government policy, imagine that, for example, the market outcome

                                                  23
was Incentive Scheme 1 in Panel C of Table 1. But suppose investors believed that lenders

misunderstood incentives and believed that lenders were putting in $12 of effort, whereas the

lender’s optimal response to Incentive Scheme 1 was to exert only $4 of effort. Investors would

then be shocked when twice as many defaults occurred as they expected. Such a result is

broadly consistent with what happened in the crisis. If government policy forced lenders to use

Incentive Scheme 2, then policy would bring investor beliefs into line with reality and their

expectations of default into line with outcomes, potentially avoiding the financial crisis.


As a theory of the crisis, however, the idea that investors did not understand the incentives of

lenders is problematic. As Foote, Gerardi, and Willen (2012) and Richardson et al. (2010) show,

most of the firms with the greatest exposure to subprime risk were underwriters and

securitizers of subprime mortgages. It seems implausible that Bear Stearns executives would not

have understood the link between effort and risk retention.


More broadly, investors based their beliefs about the performance of securitized mortgages on

the historical performance of securitized mortgages. If no risk retention means no effort, then

loans made with no risk retention will perform badly and investors buying loans with no risk

retention will pay accordingly. So it is hard to see how investors could have formed incorrect

beliefs about the relationship between effort and retention.


4 Renegotiation

During the crisis, many commentators lamented the unwillingness of lenders to renegotiate or

“modify” mortgages. The logic was as follows: suppose the borrower owes amount M*, the

house is worth P < M*, and the lender will recover (1 - λ)P from a foreclosure. If the lender sets

the loan balance to M′ = (1 - λ)P, the lender will be no worse off, and since M′ < P, the borrower

now has positive equity, can sell the property if needed, and has an incentive to keep making

payments. Critics of the lending industry wondered why there were any foreclosures at all.




                                                24
Throughout the crisis, there have been vigorous calls for executive action and legislation to

force lenders to modify mortgages. For example, in a recent op-ed, Martha Coakley and Eric

Schneiderman, attorney general of Massachusetts and New York, respectively, wrote that:


       Mortgage modification, including significant principal reduction for underwater

       mortgages, can actually increase the lifetime value of a mortgage by reducing the

       likelihood of default. It is far more profitable for any financial institution to hold

       a portfolio of performing $200,000 mortgages that keep families in their homes

       than a portfolio of nonperforming $250,000 mortgages headed toward default.


The most popular explanation for why lenders modified so few mortgages was institutional

frictions particularly related to securitization. Since the entity making the decision about

renegotiation, the servicer of the loan, did not actually own the loan, it did not stand to gain

from modification and so generally opted against it. Subsequently, critics blamed the shortage

of renegotiation on the intransigence of Edward DeMarco, the acting director of the Federal

Housing Finance Agency, who had blocked principal reduction as a tool for the institutions he

regulated, Fannie Mae and Freddie Mac.


One result is that there have been major policy changes with respect to delinquent loans. In the

short run, the administration implemented in 2009 the Home Affordable Modification Program

(HAMP), which provided subsidies to servicers with the goal of overcoming institutional

frictions. But in addition to the emergency measures, policymakers have also made permanent

changes to the relationship between borrower and lender. As part of the 2012 National

Mortgage Settlement (NMS) with the state attorneys general, servicers agreed to a set of

standards that gave borrowers substantial rights in the loan modification process. While in

theory, no one has challenged the idea that the lender should maximize profits when

conducting loss mitigation on delinquent loans, the NMS and other legal actions like the Multi-

Agency Consent Decree and the California Homeowners Bill of Rights have established

substantial rights for the borrower in the loss mitigation process.




                                                25
However, as we will now discuss, it is not clear that the institutional friction theory of why

modifications are rare is the correct one. As Adelino, Gerardi, and Willen (2013) show, these

frictions could, at most, explain only a small part of the unwillingness of lenders to renegotiate

loans. Figure 3, which is from their paper, shows that portfolio lenders who faced neither the

frictions of private label securitization nor the strictures of Federal Housing Finance Agency

(FHFA) regulations were not more likely to renegotiate mortgages. In short, securitization

cannot explain why lenders failed to modify most mortgages.


Why do lenders renegotiate so few mortgages? The economics of asymmetric information here

provides a plausible explanation. To see why, return to the example at the beginning of the

section. Now suppose that for each borrower there is some amount Vi that he is willing to

repay. Suppose that there is a continuum of borrowers uniformly distributed along the interval

[0 a/b]. Suppose that the lender instead of modifying the loan to M′ = (1 - λ)P , sets the balance at

M>M’ and forecloses on any borrower unwilling to repay M. Now,



                                                                           ;

borrowers are willing to pay the modified balance, but overall the lender collects M > (1 - λ)P from the Q
borrowers who are willing to pay M and still collects (1 -λ)P from the borrowers on whom it forecloses
and so the lender is better off. It is easy to see that to choose the optimal number of modifications Q, the
lender solves the problem:



                                                                                       .             (3)


Equation (3) should look familiar as it is the optimization problem of a monopolist facing a linear demand
curve. Optimal Q solves the first-order condition


                                                                  ,

where the left-hand side is the “marginal revenue” of an additional modification. Figure 4 illustrates the
solution. The top line labeled “# of borrowers who can repay” is Q as defined above, and we can think
of it as the demand for modifications. The “cost” of doing a modification is the revenue from the

                                                    26
alternative, (1 - λ)P. The no-foreclosures solution, where the lender reduces principal to (1 - λ)P
for everyone, is the competitive solution. However, for the lender, the monopoly solution of
setting the price equal to M* obviously dominates the competitive solution.

Thinking about the modification problem as a monopoly pricing problem reconciles different

views. On one hand, critics of the industry were right that lender policy was leading to a large

deadweight loss. In Figure 4, many borrowers were willing to pay more than the lender

recovered from foreclosures. However, the view of the critics that lenders could increase profits

by modifying more loans was wrong. The argument is precisely the same as saying that a hotel

with empty rooms represents a deadweight loss but that, at the same time, cutting room rates to

fill the rooms is not profit maximizing for the hotel.


What is the optimal policy here? In 2009, based on the logic that institutional frictions were the

main reason lenders weren’t modifying loans, the administration’s HAMP program intervened

by providing financial incentives to intermediaries to modify loans. The analysis above

illustrates why relatively small financial incentives could not overcome the basic economics of

loan renegotiation.


To prevent foreclosures, a government in Figure 4 has two options. First, it can force lenders to

implement the competitive solution by requiring that lenders modify all loans down to (1 - λ)P.

While this would inflict a large financial penalty on lenders, there would be a substantial

increase in total surplus. Second, the government could force lenders to implement the

competitive solution and use a tax to compensate them for lost profits. What should be clear

though is that preventing foreclosures without inflicting losses on lenders or covering their

losses is impossible.


Going forward, one could argue that a government policy that forced modifications would

increase consumer surplus. The zero economic profit condition means that somewhere earlier in

the process, lenders paid for the right to extract surplus from delinquent borrowers and so the

elimination of the deadweight loss will not cost lenders anything. Of course, in a sense, that

surplus extraction was embedded in the price borrowers paid for the loans when they got them,

                                                 27
so while the overall economic gain will be positive, some borrowers may complain that they

would prefer to pay a lower rate up front and suffer the consequences later.


5 Externalities

As mentioned in the introduction, the presence of externalities in an economy invalidates the

First Welfare Theorem. Consider a simple supply and demand model from Econ 101 with a

downward-sloping demand curve and an upward-sloping supply curve. The top panel of

Figure 5 illustrates the problem with externalities. Firms make decisions based on the curve

labeled “Marginal Private Cost” but production of the commodity inflicts an additional cost η

on neighbors, which means that the “Marginal Social Cost” is higher. To understand why

equilibrium is inefficient, imagine that we introduce a tax τ = η on producers. On one hand the

tax reduces welfare by the triangle ABC, the usual deadweight loss resulting from the fact that

consumer and producer surplus fall by more than the tax revenue generated. But, because

production has fallen from Q to Q′, the neighborhood costs fall by the quadrilateral ADBC.

Subtracting the deadweight loss from the reduction in neighborhood costs yields the net benefit

of the tax, the triangle ABD. Intuitively, the triangle is a loss to society that results from the fact

that the costs of the foreclosure to neighbors exceed the consumer and producer surplus

generated by the production. The first Q′ of output still generates externalities, but from the

standpoint of society as a whole, the tax revenue exactly offsets the costs. The fact that the

government can increase welfare with a tax illustrates that the First Welfare Theorem cannot

hold.


What are the externalities in the mortgage market and how could government policies offset

them to improve welfare? To answer this, we need to distinguish between two types of

externality. The first type, depicted in the top panel of Figure 5, are known as technological or

physical externalities, and they occur when something an individual or a firm does directly

enters into the utility or production function of another individual or firm, respectively, in the

economy. Pollution is the classic example, but for our purposes the more natural example is



                                                  28
foreclosures, which, many have argued, led to neglect of properties, which in turn inflicts

damage on neighboring properties.


The second type of externalitiy referred to by Viner (1932) and elucidated by Scitovsky (1954) as

z pecuniary externality is more subtle and work through market mechanisms. An example of a

pecuniary externality occurs when I list my house for sale, thereby making it somewhat more

difficult for someone selling a close substitute. Obviously, I don’t take that into account when I

list the property, just as I don’t take into account the effect on my neighbors if I play loud music

late at night or do compression tests on my motorcycle on a peaceful Saturday afternoon.

Doesn’t that provide another opportunity for government intervention? As we now explain, in
our standard undergraduate models, the First Welfare Theorem still holds in the presence of
pecuniary externalities: government cannot make everyone better off. In richer models, as we
discuss below, pecuniary externalities do allow for welfare-improving government policies.

To see why government cannot help, consider first a demand shock, as depicted in the lower

left panel of Figure 5. The left panel shows what happens if prices fall because of a demand

shock δ. Suppose the government could introduce a subsidy τ = δ that would restore the

previous equilibrium prices and quantities. The figure illustrates that such a policy would

reduce welfare, generating a deadweight loss, shaded in the picture, which results from the fact

that the subsidy leads transactions to occur between sellers who value the properties less than

the buyers do. Now, turning to the right panel of Figure 5 and, more to the point, suppose a

lender forecloses on a property and lists it for sale, shifting the supply curve by amount δ down

and to the right, lowering prices and increasing the level of sales in the market. Now suppose

the government intervenes and introduces a tax τ = δ on property sales, which exactly offsets

the shift in the supply curve and restores prices to the previous level. Isn’t this a good thing?

No. The shaded triangle shows that there is deadweight loss to the economy: there are potential

buyers who value properties more than potential sellers do, but because of the tax, those trades

don’t take place.




                                                29
Conclusions

In the end, I believe that externalities have to be at the heart of any justification of the slate of

policies discussed in this paper. Let me focus on riskretention to illustrate the point.. As I have

shown, risk retention does not solve the asymmetric information problem; instead it simply

makes lenders more cautious and thus reduces the number of defaults but at the cost of a

deadweight loss to the investors and lenders. If one believes that foreclosure externalities are

significant, then one might view risk retention as a sort of Pigovian tax4 in which the social

benefits of eliminating externalities make up for the deadweight loss.


But in practice, I am skeptical that risk retention would even achieve the goal of reduced

defaults. As we argued (Foote, Gerardi, and Willen, 2012), the financial crisis resulted from the

fact that most of the key financial intermediaries had too much exposure to residential real

estate: in other words, they had too much skin in the game.


If externalities are the justification for risk retention, then one might well ponder a more direct

approach: default taxes. In other words, risk retention is a roundabout way of preventing

default that would have been ineffective anyway. A default tax on the other hand targets the

externality precisely and has the added benefit of generating revenue for the government at the

time when it is needed.


Academics and journalists are fond of saying that the crisis occurred because of “misaligned

incentives.” It is never exactly clear what they mean. In economics, misaligned incentives lead

to a breakdown in trade: a rating agency with misaligned incentives is not worth anything to

issuers or to the owners of the rating agency. I think what people have in mind is that the

incentives of market participants are not aligned with the goals of society; in other words, that

the invisible hand has failed. Default externalities are a perfect example. Because they do not

incorporate the costs of foreclosures on neighbors, market prices do not give lenders proper


4
    A Pigouvian tax is a tax on negative externalities, which are effects that are harmful to another person or group.


                                                            30
incentives to avoid defaults and the number of defaults in equilibrium is suboptimally high. In

a sense, by focusing on the relationship between participants in the mortgage market rather

than between the mortgage market and the rest of society Dodd-Frank, according to standard

models, does not address the central incentive misalignment problem.




                                              31
References
Adelino, Manuel, Kristopher Gerardi, and Paul S. Willen. 2013. “Why Don’t Lenders
Renegotiate More Home Mortgages? Redefaults, Self-Cures and Securitization.” Journal of
Monetary Economics 60: 835–853. Available at http://dx.doi.org/10.1016/j.jmoneco.2013.08.002

Akerlof, George A. 1970. “The Market for “Lemons”: Quality Uncertainty and the Market
Mechanism.” The Quarterly Journal of Economics 84(3): 488–500.

Bisin, Alberto, and Piero Gottardi. 2006. “Efficient Competitive Equilibria with Adverse
Selection.” Journal of Political Economy 114(3): 485–516.

Bolton, Patrick, Xavier Freixas, and Joel Shapiro. 2012. “The Credit Ratings Game.” The Journal of
Finance 67(1): 85–111.

Bubb, Ryan, and Alex Kaufman. 2009. “Securitization and Moral Hazard: Evidence from a
Lender Cutoff Rule.” Technical Report. Public Policy Discussion Papers, Federal Reserve Bank
of Boston, No. 09-5.

Foote, Christopher L., Kristopher S. Gerardi, and Paul S. Willen. 2012. “Why Did So Many
People Make So Many Ex Post Bad Decisions? The Causes of the Foreclosure Crisis.” Working
Paper 18082. Cambridge, MA: National Bureau of Economic Research.

Friedman, Milton, and Rose D. Friedman. 1980. Free to Choose: A Personal Statement. Orlando:
Harcourt Inc.

Geanakoplos, John, and Herakles M. Polemarchakis. 1986. “Existence, Regularity and
Constrained Suboptimality of Competitive Allocations When the Asset Market Is Incomplete.”
In Uncertainty, Information and Communication: Essays in Honor of Kenneth J. Arrow, Volume 3 ed.
Walter P. Heller, Ross M. Starr, and David A. Starren, 65–96. Cambridge: Cambridge University
Press.

Gerardi, Kristopher S., Harvey S. Rosen, and Paul S. Willen. 2010. “The Impact of Deregulation
and Financial Innovation on Consumers: The Case of the Mortgage Market.” The Journal of
Finance 65(1): 333–360.

Greenwald, Bruce C., and Joseph E. Stiglitz. 1986. “Externalities in Economies with Imperfect
Information and Incomplete Markets.” The Quarterly Journal of Economics 101(2): 229–264.

Gul, Faruk, and Wolfgang Pesendorfer. 2001. “Temptation and Self-Control.” Econometrica 69(6):
1403–1435.




                                               32
Holmstrom, Bengt, and Paul Milgrom. 1987. “Aggregation and Linearity in the Provision of
Intertemporal Incentives.” Econometrica 55(2): 303–328.

Keys, Benjamin J., Tanmoy Mukherjee, Amit Seru, and Vikrant Vig. 2010. “Did Securitization
Lead to Lax Screening? Evidence from Subprime Loans.” The Quarterly Journal of Economics
125(1): 307–362.

Keys, Benjamin J., Tomasz Piskorski, Amit Seru, and Vikrant Vig. 2013. “Mortgage Financing in
the Housing Boom and Bust.” In Housing and the Financial Crisis, ed. Edward Glaeser and Todd
Sinai. Chicago: University of Chicago Press.

Laibson, David. 1997. “Golden Eggs and Hyperbolic Discounting.” The Quarterly Journal of
Economics 112(2): 443–478.

Prescott, Edward C., and Robert M. Townsend. 1984. “Pareto Optima and Competitive
Equilibria with Adverse Selection and Moral Hazard.” Econometrica 52(1): 21–45.

Richardson, Matthew P., Joshua Ronen, and Marti Subrahmanyam Ingo Walter. 2010.
“Securitization Reform.” In Regulating Wall Street: The Dodd-Frank Act and the New Architecture of
Global Finance,ed. Acharya, Viral V., Thomas F. Cooley, Matthew P. Richardson, Ingo Walter .
Hoboken: Jon Wiley and Sons, Inc.

Rothschild, Michael, and Joseph Stiglitz. 1976. "Equilibrium in Competitive Insurance Markets:
An Essay on the Economics of Imperfect Information." The Quarterly Journal of Economics 90(4):
629-649.

Scitovsky, Tibor. 1954. “Two Concepts of External Economies.” The Journal of Political Economy
62(2): 143–151.

Smith, Adam. 1776. An Inquiry into the Nature and Causes of the Wealth of Nations. London:
Methuen & Co, Ltd.

Stein, Jeremy C. 1995. “Prices and Trading Volume in the Housing Market: A Model with
Down-Payment Effects.” The Quarterly Journal of Economics 110(2): 379–406.

Viner, Jacob. 1932. “Cost Curves and Supply Curves.”




                                                33
Table 1: A simple model of moral hazard in mortgage underwriting. See Section 3 for details.




Source: Author’s illustration.




                                                           34
Figure 1: A simple model of loan verification.

                              Panel A: Deadweight loss of verification




                                   Panel B: High verification costs




Source: Author’s illustration. Note: Top panel shows the deadweight loss of requiring verification when
the costs of verification exceed the benefits. Bottom panel shows sufficiently high verification costs
prevent some borrowers from getting credit. See Section 1 for details.

                                                  35
Figure 2: Graphical depiction of a simple principal agent problem based on Holmstrom
and Milgrom (1987).




Source: Author’s illustration. Note: Top left panel shows the agent’s decision to exert effort. Top right
panel shows how the principal inverts the adjacent panel to infer effort from the incentive scheme.
Bottom right panel shows the principal’s optimal choice of effort without uncertainty and the bottom
right panel shows the optimal choice of effort with uncertainty. See Section 3 for details.




                                                   36
Figure 3: Loan modifications, 2005–2011.




Source: Adelino, Gerardi, and Willen (2013) . Note: Modifications are measured over the period (one year
or two years) following the month that a loan becomes 60 days delinquent. See Adelino, Gerardi, and
Willen (2013) for a full discussion of the methodology. “Portfolio” refers to loans held on banks’ balance
sheets. “All loans” refers loans securitized by the government sponsored enterprises and loans
securitized by private firms.




                                                   37
Figure 4: Loan Renegotiation.




Source: Author’s illustration. Note: If borrowers have unobservably different willingness to repay a
mortgage, then the lender’s decision to modify is equivalent to a monopoly pricing problem. See Section
4 for details.




                                                  38
Figure 5: The effect of a tax on the sale of property in without and with physical externalities.




Source: Author’s illustration. Note: If foreclosures cause physical externalities, then a tax can increase welfare (top panel). If foreclosures cause a
pecuniary externality, for example, an increase in the supply of properties on the market, then an offsetting tax is welfare reducing (bottom right
panel). See Section 5 for details.




                                                                           39
