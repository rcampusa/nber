                                NBER WORKING PAPER SERIES




                              AMBIGUITY AND ASSET MARKETS

                                          Larry G. Epstein
                                          Martin Schneider

                                        Working Paper 16181
                                http://www.nber.org/papers/w16181


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                      July 2010




Epstein acknowledges financial support from the National Science Foundation (award SES-0917740).
We thank Lorenzo Garlappi, Tim Landvoigt, Jianjun Miao, Monika Piazzesi and Juliana Salomao
for helpful comments. The views expressed herein are those of the authors and do not necessarily reflect
the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2010 by Larry G. Epstein and Martin Schneider. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.
Ambiguity and Asset Markets
Larry G. Epstein and Martin Schneider
NBER Working Paper No. 16181
July 2010
JEL No. D01,G11,G12

                                            ABSTRACT

The Ellsberg paradox suggests that people behave differently in risky situations -- when they are given
objective probabilities -- than in ambiguous situations when they are not told the odds (as is typical
in financial markets). Such behavior is inconsistent with subjective expected utility theory (SEU),
the standard model of choice under uncertainty in financial economics. This article reviews models
of ambiguity aversion. It shows that such models -- in particular, the multiple-priors model of Gilboa
and Schmeidler -- have implications for portfolio choice and asset pricing that are very different from
those of SEU and that help to explain otherwise puzzling features of the data.


Larry G. Epstein
Department of Economics
Boston University
270 Bay State Road
Boston MA 02215
lepstein@bu.edu

Martin Schneider
Department of Economics
Stanford University
579 Serra Mall
Stanford, CA 94305-6072
and NBER
schneidr@stanford.edu
Table of Contents

1. Introduction

2. Preference

   2.1 Models of Preference: Static or One-Shot Choice Settings
      2.1.1   Ellsberg and the Formal Set Up
      2.1.2   Multiple-priors Utility
      2.1.3   The “Smooth Ambiguity” Model
      2.1.4   Robust Control, Multiplier Utility and Generalizations
   2.2 Models of Preference: Dynamic or Sequential Choice Settings
      2.2.1 Recursive Utility
      2.2.2 Updating and Learning

3. Ambiguity in Financial Markets

   3.1 Portfolio Choice
      3.1.1 One Ambiguous Asset: Nonparticipation and Portfolio Inertia at
            Certainty
      3.1.2 Hedging and Portfolio Inertia away from Certainty
      3.1.3 Multiple Ambiguous Assets: Selective Participation and Benefits
            from Diversification
      3.1.4 Dynamics: Entry & Exit Rules and Intertemporal Hedging
      3.1.5 Diﬀerences between Models of Ambiguity
      3.1.6 Discipline in Quantitative Applications
      3.1.7 Literature Notes
   3.2 Asset Pricing
      3.2.1   Amplification
      3.2.2   The Cross Section of Returns and Idiosyncratic Ambiguity
      3.2.3   Literature Notes: Representative Agent Pricing
      3.2.4   Literature Notes: Heterogeneous Agent Models



                                      2
1. Introduction
Part one of the article recalls the Ellsberg-based critique of subjective expected
utility theory and then outlines some of the models that it has stimulated. Our
coverage of preference models is selective - we focus only on models that have
been applied to finance, or that seem promising for future applications: multiple-
priors (Gilboa & Schmeidler 1989), the “smooth ambiguity” model (Klibanoﬀ et
al. 2005) as well as multiplier utility and related robust-control-inspired models
(Hansen & Sargent 2001, Maccheroni et al. 2006a).
    We provide a unifying framework for considering the various models. A con-
fusing aspect of the literature is the plethora of seemingly diﬀerent models, rarely
related to one another, and often expressed in drastically diﬀerent formal lan-
guages. Here we put several of these models side-by-side, expressed in a common
language, and we examine the properties of each with respect to implications for
both one-shot-choice and sequential choice. In particular, we provide thought
experiments to illustrate diﬀerences in behavior implied by the various models.
    Part two derives implications of the models for finance. One common theme
shared by all models is that ambiguity averse agents choose more conservative
positions, and, in equilibrium, command additional “ambiguity premia” on un-
certain assets. Ambiguity aversion can thus help to account for position and price
behavior that is quantitatively puzzling in light of subjective expected utility
(SEU) theory. A second common theme is that, in dynamic settings, ambiguity
averse agents may adjust their positions to account for future changes in ambigu-
ity, for example due to learning. This adds a new reason for positions to diﬀer by
investment horizon, and, in equilibrium, generates time variation in premia.
    Models of ambiguity aversion diﬀer in how ambiguity aversion compares with
risk aversion, and thus in how implications for portfolio choice and asset pricing
diﬀer from those of SEU. On the one hand, many of the qualitative implications of
multiplier utility and of the smooth ambiguity model are identical to those of SEU.
In all three models, with standard specifications, agents are locally risk neutral,
portfolios react smoothly to changes in return expectations and diversification
is always beneficial. Consequently, in many settings, the multiplier and smooth
models do not expand the range of qualitative behavior that can be explained
by SEU. Instead, they oﬀer reinterpretations of SEU that may be quantitatively
more appealing (for example, ambiguity aversion can substitute for higher risk
aversion).



                                         3
    On the other hand, most applications of the multiple-priors model have ex-
ploited qualitative diﬀerences from SEU. These arise because the multiple-priors
model allows uncertainty to have first order eﬀects on portfolio choice and asset
pricing. Thus the model can give rise to selective participation, optimal un-
derdiversification, and portfolio inertia at portfolios that hedge ambiguity. In
heterogeneous agent models with multiple-priors, portfolio inertia has been used
to endogenously generate incompleteness of markets and to account for markets
“freezing up” in response to an increase in uncertainty. Finally, uncertainty has a
first order eﬀect on average excess returns, which can be large even if the covari-
ance of payoﬀs with marginal utility is negligible.


2. Preference
The outline is divided into two major parts. First, we consider static or one-
shot-choice settings where all choices are made at a single instant prior to the
resolution of uncertainty. Models of preference under uncertainty are typically
formulated first for such static settings. However, just as in Epstein & Zin (1989)
which studies risk preferences, any such model of static preference can be extended
uniquely into a recursive dynamic model of preference. Therefore, the discussion of
static models is revealing also about their dynamic extensions, which are outlined
in the second part of this section. In addition, a dynamic setting, where choice
is sequential, raises new issues - dynamic consistency and updating or learning -
and these are the major focus of the subsection on dynamic models.

2.1. Models of Preference: Static or One-Shot Choice Settings
2.1.1. Ellsberg and the Formal Set Up
Ellsberg’s (1961) classic experiments motivate the study of ambiguity. In a variant
of one of his experiments, you are told that there are 100 balls in an urn, and that
each ball is either red  or blue . You are not given further information about
the urn’s composition. Presumably you would be indiﬀerent between bets on
drawing either color (take the stakes to be 100 and 0). However, compare these
bets with the risky prospect that oﬀers you, regardless of the color drawn, a bet
on a fair coin, with the same stakes as above. When you bet on the fair coin,
or equivalently on drawing blue from a second risky urn where you are told that
there are 50 balls of each color, then you can be completely confident that you

                                         4
have a 50-50 chance of winning. In contrast, in the original “ambiguous” urn,
there is no basis for such confidence. This diﬀerence motivates a strict preference
for betting on the risky urn as opposed to the ambiguous one.
    Such preference is incompatible with expected utility. Indeed, suppose you
had in mind a subjective probability about the probability of a blue draw from
the ambiguous urn. A strict preference for betting on the fair coin over a bet on
a blue draw would then reveal that your probability of blue is strictly less than
one half. At the same time, a preference for betting on the fair coin over a bet
on a red draw reveals a probability of blue that is strictly greater than one half,
a contradiction. It follows that Ellsberg’s choices cannot be rationalized by SEU.
    Ellsberg’s choices have been confirmed in many laboratory experiments. But
this is an experiment that did not need to be run in order to be convincing -
it simply rings true that confidence, and the amount of information underlying
a likelihood assessment, matter. Such a concern is not a mistake or a form of
bounded rationality - to the contrary, it would be irrational for an individual who
has poor information about her environment to ignore this fact and behave as
though she were much better informed.1 The distinction between risk and ambi-
guity is sometimes referred to alternatively as one between risk and “Knightian
uncertainty.” In terminology introduced by Hansen & Sargent (2001), Ellsberg’s
urn experiment illustrates that the distinction between payoﬀ uncertainty and
model uncertainty is behaviorally meaningful.
    We need some formalities to proceed. Following Savage (1954), adopt as prim-
itives a state space Ω, representing the set of relevant contingencies or states of
the world  ∈ Ω, and a set of outcomes  ⊂ R+ . (Little is lost by assuming that
both Ω and  are finite and have power sets as associated -algebras; however,
considerable generalization is possible.) Prior to knowing the true state of the
world, an individual chooses once-and-for-all a physical action. As in Anscombe
& Aumann (1963), suppose that the consequence of an action is a lottery over ,
an element of ∆ (). Then, any physical action can be identified with a (bounded
and measurable) mapping  : Ω −→ ∆(), which, is called an Anscombe-Aumann
(or AA) act. Thus to model choice between physical actions, we model preference
º on the set of AA acts.
    To model the Ellsberg experiment above, take Ω = { } as the state space,
where a state corresponds to a draw from the ambiguous urn. The relevant bets
are expressed as AA acts as follows:
   1
    The normative significance of Ellsberg’s message distinguishes it from that emanating from
the Allais Paradox contradicting the vNM model of preference over risky prospects.


                                              5
                       Ellsberg’s urn:             +  = 100
                                        
                        100            0                                    (2.1)
                        0¡         ¢   100
                                         ¡         ¢
                           100 12       100 12
Bets on a red and a blue draw correspond to acts  and   respectively. A bet
¡on the1 ¢fair coin corresponds to a constant AA act  that delivers same lottery
  100 2 in both states; throughout, we denote by ( ) the lottery paying  with
probability  and 0 with probability 1 − .
    Two special subsets of acts should be noted. Call  a Savage act if  () is
a degenerate lottery for every ; in that case, view  as having outcomes in 
and write  : Ω → . Both  and  above are Savage acts. For the second
subset, we can identify any lottery  ∈ ∆ () with the constant act that yields
 in every state. An example is the fair coin lottery above. Consequently, any
preference on AA acts includes in it a ranking of risky prospects. This makes clear
the analytical advantage of adopting the large AA domain, since the inclusion of
risky prospects makes it straightforward to describe behavior that would reveal
that risk is treated diﬀerently from other uncertainty. This is a major reason
that all the models of preference that we discuss have been formulated in the AA
framework.
    Another analytical advantage of the AA domain is the simple definition it
permits for the mixture of two acts. The mixture of two lotteries is well-defined
and familiar. Given any two AA acts 0 and , and  in [0 1], define the new act
0 + (1 − )  by mixing their lotteries state by state, that is,

             (0 + (1 − ) ) () = 0 () + (1 − )  () ,  ∈ Ω.         (2.2)

A key property of the Ellsberg urn is that 12  + 12  =  a mixture of the bets
on states  and  gives a lottery that no longer depends on the state.
   Ellsberg’s choices can now be written as
                              1
                                
                              2 
                                    + 12  Â  ∼  .                       (2.3)

   From this perspective, Ellsberg’s example has two important features. First,
randomization between indiﬀerent acts can be valuable. This is a violation of the
independence axiom, and thus a key departure from expected utility. Second,
randomization can be valuable because it can smooth out, or hedge, ambiguity.

                                          6
The negative comovement in the payoﬀs of the ambiguous acts  and  implies
that the act 12  + 12  is not ambiguous; it is simply risky. One can be confident
in knowing the probabilities of the lottery payoﬀs, even if one is not confident in
those of the underlying bets  and  .
    The literature has identified the first property — a strict preference for ran-
domization between indiﬀerent acts — as the behavioral manifestation of (strict)
ambiguity aversion. Accordingly, say that the individual with preference º is
(weakly) ambiguity averse if, for all AA acts 0 and ,

                          0 ∼  =⇒ 0 + (1 − )  º .                         (2.4)

For a related comparative notion, say that 1 is more ambiguity averse than 2 if:
For all AA acts  and lotteries  ∈ ∆ (),

                                  º2  =⇒  º1 .                               (2.5)

The idea is that if 2 rejects the ambiguous act  in favor of the risky prospect ,
then so should the more ambiguity averse individual 1. The uncertainty aversion
axiom (2.4) is satisfied by all the models reviewed below.
    Models of ambiguity aversion diﬀer in why randomization is valuable, in par-
ticular, whether it can be valuable even if it does not hedge ambiguity. To see
the main point, consider the following extension of the Ellsberg experiment. Let 
denote the number of dollars you are willing to pay for the bet  . Next, imagine
a lottery that delivers either the bet  or its certainty equivalent payoﬀ , each
with probability 12 . How much would you be willing to pay for such a bet? One
reasonable answer is  — randomizing between an asset (here a bet) and its own
subjective value cannot be valuable. Intuitively, if you perceive the value of an
asset to be low because you are not confident in your probability assessment of its
payoﬀ, then your confidence in your assessment should not change just because
the asset is part of the lottery. As a result, the asset, its subjective value, and the
lottery should all be indiﬀerent.
    The above view underlies the multiple-priors (MP) model of Gilboa and Schmei-
dler (1989). According to that model, preference for randomization between indif-
ferent acts is valuable only if it hedges ambiguity and thus increases confidence,
as in the Ellsberg experiment. When there is no opportunity for hedging — as
in the last example where one of the acts (the subjective value of the asset) is
constant — then randomization is not valuable. In contrast, “smooth” models
of ambiguity aversion, in particular multiplier preferences (Anderson et al. 2003)

                                          7
and the smooth ambiguity model (Klibanoﬀ et al. 2005), assume a pervasive
value for randomization. Those models can rationalize Ellsberg’s choices only if
randomizing between an asset and its subjective value is also valuable.
   We now define and compare the models in more detail.

2.1.2. Multiple-Priors Utility
Where information is scarce and a single probability measure cannot be relied
on to guide choice, then it is cognitively intuitive that the decision-maker think
in terms of a set of probability laws. For example, she might assign the interval
[ 13  23 ] to the probability of drawing a red ball from the ambiguous urn in the
Ellsberg experiment. Being cautious, she might then evaluate a bet on red by
using the minimum probability in the interval, here 13 , which would lead to the
strict preference to bet on the risky urn. Similarly for blue. In this way, the
intuitive choices pointed to by Ellsberg can be rationalized.
        More formally and generally, the multiple-priors model postulates the following
utility function on the set of AA acts:
                                                Z
                                   
                                     () = min  () .                          (2.6)
                                             ∈   Ω

Here,  : ∆ () → R is a vNM functional on lotteries that is aﬃne, that is,

                       ( + (1 − ) 0 ) =  () + (1 − )  (0 ) ,

for all lotteries  0 in ∆ ().2 The vNM assumption for  excludes risk prefer-
ences exhibiting the Allais Paradox - ambiguity is the only rationale admitted
for deviating from SEU in the multiple-priors model, as well as in all the other
models that we discuss. The central component in the functional form is the set
 ⊂ ∆ (Ω) of probability measures on Ω - the set of priors. The special case where
 is a singleton gives the Anscombe & Aumann (1963) version of SEU.
    Ambiguity aversion, as defined in (2.4), is the central assumption in Gilboa
& Schmeidler’s (1989) axiomatization of the multiple-priors functional form. An-
other important axiom is certainty independence (CI): For all AA acts 0 and 
all constant acts  and  ∈ (0 1) 

                    0 Â  ⇐⇒ 0 + (1 − )  Â  + (1 − ) .                          (2.7)
   2
     Below identify  with the degenerate lottery giving  and write  (). Also, assume that 
is strictly increasing for deterministic consumption.

                                              8
In other words, the invariance required by the independence axiom holds as long
as mixing involves a constant act. This axiom ensures that Ellsberg-type choices
are motivated by hedging. Essentially, moving from expected utility to multiple-
priors amounts to replacing the independence axiom by uncertainty aversion and
certainty independence.
    Further, comparative ambiguity aversion is simply characterized: 1 is more
ambiguity averse than 2 if and only if

                                  1 = 2 and 1 ⊃ 2 .                                  (2.8)

Thus the model aﬀords a separation between risk attitudes, modeled exclusively by
the vNM index , and ambiguity attitudes, modeled in the comparative sense by
the set of priors . Put another way, expanding  leaves risk attitudes unaﬀected
and increases ambiguity aversion.
    The multiple-priors model is very general since the set of priors can take many
diﬀerent forms. Consider briefly two examples that have received considerable
attention and that oﬀer scalar parametrizations of ambiguity aversion. Refer to
-contamination if
                           = {(1 − ) ∗ +  :  ∈  } ,                     (2.9)
where  ⊂ ∆ (Ω) is a set of probability measures, ∗ ∈  is a reference measure,
and  is a parameter in the unit interval.3 The larger is , the more weight is
given to alternatives to ∗ being relevant, and the more ambiguity averse is the
individual in the formal sense of (2.5). An act is evaluated by a weighted average
of its expected utility according to ∗ and its worst-case expected utility:
                                  Z                    Z
                                             ∗
                   () = (1 − )  ()  +  min  () .                 (2.10)
                                       Ω                 ∈   Ω

    In the second example,  is an entropy-constrained ball. Fix a reference mea-
sure ∗ ∈ ∆ (Ω). For any other  ∈ ∆ (Ω), its relative entropy is  ( k ∗ ) ∈
[0 ∞], where                            µ       ¶
                                  ∗
                                       R      
                           ( k  ) =    log ∗ ,                         (2.11)
                                       Ω     
if  is absolutely continuous with respect to ∗ , and ∞ otherwise. Though not a
metric, for example, it is not symmetric,  ( k ∗ ) is a measure of the distance
   3
    It is used heavily in robust statistics (see Huber (1981), for example). For application to
finance, see Epstein & Wang (1994). Kopylov (2009) provides axiomatic foundations.


                                              9
between  and ∗ ; note that  ( k ∗ ) = 0 if and only if  = ∗ . Finally, define

                                  = { :  ( k ∗ ) ≤ }.                              (2.12)

   The MP model is sometimes criticized on the grounds that it implies extreme
aversion, or paranoia. But that interpretation is based on the implicit assumption,
not imposed by the model, that  is the set of all logically possible priors.4 For
example, in the Ellsberg example, it is perfectly consistent with the model that
the individual use the probability interval [ 13  23 ], even though any probability in
the unit interval is consistent with the information given for the ambiguous urn.
Ultimately, the only way to argue that the model is extreme is to demonstrate
extreme behavioral implications of the axioms, something that has not been done.

2.1.3. The “Smooth Ambiguity” Model
Klibanoﬀ et al. (2005), henceforth KMM, propose the following utility function
over AA acts:
                            Z       µZ                 ¶
                 
                     () =            ( ())  ()  () .        (2.13)
                                    ∆(Ω)       Ω

Here  is a probability measure on ∆ (Ω),  : ∆ () →  is a vNM functional as
before, and  is continuous and strictly increasing on  () ⊂ R. For simplicity,
suppose that  is continuous and strictly increasing on . Identify a KMM agent
with a triple (  ) satisfying the above conditions.5
   This functional form suggests an appealing interpretation. If the individual
were certain of  being the true law, she would simply maximize expected utility
using . However, in general, there is uncertainty about the true law, or “model
uncertainty,” represented by the prior . This uncertainty about the true law
matters if  is nonlinear. In particular, if  is concave, then the individual is
ambiguity averse in the sense of (2.4); and greater concavity implies greater am-
biguity aversion in the sense of (2.5). On the other hand, ambiguity (as opposed
to the attitude towards it) seems naturally to be captured by  - hence, it is
   4
     The diﬀerence between the subjective set of priors  and the set of logically possible prob-
ability laws is nicely clarified by Gajdos et al. (2008).
   5
     The multiple-priors functional form is a limiting case - if  is the support of , then, up
to ordinal equivalence, (2.6) is obtained in the limit as the degree of concavity of  increases
without bound.



                                               10
claimed, a separation is provided between ambiguity and aversion to ambiguity.
This separation is highlighted by KMM as an advantage of their model.
    To see how the smooth model can accomodate Ellsberg’s choices, assume that
the prior puts equal weight on two possible “models” of the composition of the
ambiguous urn: the share of blue balls is either 34 or 14 . Without loss of generality,
here and below normalize  so that  (100) = 1 and  (0) = 0, where 100 and 0 are
the stakes in the bets on the urn. Then, if the agent is ambiguity averse   ¡ 3 ¢ (1 strictly
                                                                                        ¡1¢
                                                                        1
concave),
  ¡1¢        the  utility of a bet on blue from the ambiguous   urn  is 2
                                                                             4
                                                                                 +  2
                                                                                        4
                                                                                            
 2 , the utility from a bet on a fair coin.
    However, counterintuitive behavior is implied when the agent can bet directly
on what the true model is.6 To illustrate, modify the Ellsberg experiment by
adding details about how the urn is filled. In particular, suppose there is a second
urn, urn II, that is used as a tool for filling the original urn, urn I. Urn II also
contains 100 balls that are either red or blue, and no further information is given
about its composition. It is announced that a ball will be drawn from urn II, and
that its color will determine the composition of urn I: if the draw from urn II is
blue (red), then the share of blue (red) balls in urn I is 34 . In other words, the draw
from urn II describes model uncertainty — it determines which of the “models” of
urn I considered above is correct.
    Compare now betting on a blue draw from urn I and betting on a blue draw
from urn II. Both bets are ambiguous, because of the lack of information about
urn II, which aﬀects also urn I. However, since it is known that urn I contains
at least 14 × 100 = 25 blue balls (while no such information is available for urn
II), the bet on urn I is less ambiguous, and thus presumably preferable. But the
KMM model predicts the opposite ranking. That is because, according to their
model, bets on urn II are evaluated via expected utility with vNM index  ( (·))
and a uniform prior over the two colors. (This is suggested by the interpretation
above of the functional form (2.13), and is an explicit and key assumption in the
foundations they provide for the latter.) Thus a bet on drawing blue from urn II
has utility 12  (1) + 12  (0). On the other hand, bets on urn I are ranked according
to the
    ¡ 3 ¢ utility¡ 1function
                     ¢       in (2.13), which implies that the bet on blue has utility
1            1
2
     4
          +  2
                  4
                       . Thus  the counterintuitive ranking is implied if  is (strictly)
concave.
   6
    Such bets on the “true model” are an integral part of the foundations that KMM provide for
the smooth ambiguity model. The following critique is adapted from Epstein (2010) to which
the reader is referred for elaboration. See Baillon et al. (2009), and Halevy and Ozdenoren
(2008) for other criticisms of the smooth ambiguity model.



                                             11
     The smooth model is intriguing because of the separation that it appears to
aﬀord between ambiguity, seemingly modeled by , and aversion to ambiguity,
seemingly modeled by . Such separation suggests the possibility of calibrating
ambiguity aversion - if  describes the individual’s attitude alone, and thus moves
with her from one setting to another, then it serves to connect the individual’s
behavior across diﬀerent settings. For example, one might use experimental ev-
idence about choices between bets on Ellsberg urns to discipline applications to
financial markets. However, the KMM model does not justify such calibration,
or a natural notion of “separation.” A variant of the above thought experiment
makes this point.
     You are faced in turn with two scenarios, A and B. Scenario A is the one
described above, involving urns I and II. Scenario B is similar except that you
are told more about urn II, namely that it contains at least 40 balls of each
color. Consider bets on both urns in each scenario. The following rankings seem
intuitive: bets on blue and red in urn II are indiﬀerent to one another for each
scenario; and the certainty equivalent for a bet on blue (or red) in urn I is strictly
larger in scenario B than in A, because the latter is intuitively more ambiguous.
     How could we model these choices using the smooth ambiguity model? Sup-
pose that preferences in the two scenarios are represented by the two triples
(     ),  =  . The basic model does not impose any connection across sce-
narios. However, since these diﬀer in ambiguity only, and it is the same decision-
maker involved in both, one is led naturally to consider the restrictions
                                   =  and  =  .
These equalities are motivated by the hypothesis that risk and ambiguity attitudes
describe the individual and therefore move with her across settings. But with these
restrictions, the indicated behavior cannot be rationalized.7 On the other hand,
the above behavior can be rationalized if we assume that the priors  are fixed
(and uniform) across scenarios, but allow  and  to diﬀer. The preceding defies
the common interpretation that  captures ambiguity and  represents ambiguity
aversion.
    Seo (2009) provides alternative foundations for   . In his model, an indi-
vidual can be ambiguity averse only if she fails to reduce objective (and timeless)
two-stage lotteries to their one-stage equivalents. Thus the rational concern with
model uncertainty and limited confidence in likelihoods is tied to the failure to
   7
    It is straightforward to show that the behavior implies that  =  , which obviously rules
out any diﬀerence in behavior across scenarios.

                                              12
multiply objective probabilities, a mistake that does not suggest rational behav-
ior. Such a connection severely limits the scope of ambiguity aversion as modeled
by Seo’s approach.
    Both multiple-priors and the smooth model satisfy ambiguity aversion (2.4)
and thus can rationalize Ellsberg-type behavior. However, they represent distinct,
indeed, “orthogonal” models of ambiguity aversion - the only point of intersection
is SEU. One way to see this, and to highlight their diﬀerences, is to focus on
what the models imply about the value of randomization. The multiple-priors
model satisfies (because of Certainty Independence): if  ∼ , then 12  + 12  ∼
; thus mixing with a certainty equivalent is never valuable. In contrast, the
smooth model satisfies, (restricting attention to the special case where  is strictly
concave): if  ∼  ∼ 12  + 12 , then for all acts , 12  + 12  ∼ 12  + 12 ; that is, if
mixing with a certainty equivalent is not beneficial, then neither is mixing with any
other act. (To see why, argue as follows, using the functional form     R (2.13) and strict
                                                     1      1
concavity and monotonicity of : If  ∼  ∼ 2  + 2 , then Ω  ( )  =  ()
with -probability 1, and the expected utility of  is certain in spite of model
uncertainty. Thus
                                    Z       µZ                          ¶
             1
                  ¡       1
                            ¢                     1           1
                   2
                       + 2 =                   2
                                                     () + 2  ()   ()
                                     ∆(Ω)       Ω
                                    Z       µ              Z            ¶
                                              1          1
                                =          2  () + 2          ()   ()
                                     ∆(Ω)                   Ω
                                            ¡          ¢
                                =   12  + 12  .)

Finally, it is straightforward to see that the two properties together imply the
independence axiom and hence SEU.
    To illustrate the eﬀect of smoothness in applications it is helpful to briefly
abstract from risk. Assume that the agent is risk neutral, or, equivalently, restrict
attention to acts that come with perfect insurance for risk. Formally, take  to
be linear and rewrite the utilities as

                              () =   [ (  [])] 
                                () = min   [] 
                                               ∈P

For risk neutral agents, ambiguity only matters if it aﬀects means. Under the
smooth model, ambiguity about means is reflected in a nondegenerate distribution
of   [] under the prior . For a risk neutral, ambiguity averse KMM agent, an

                                             13
increase in ambiguity (in means) works like an increase in risk. Under the MP
model, ambiguity about means is reflected in a nondegenerate interval for   [].
For a risk neutral MP agent, an increase in ambiguity (in means) can thus work
like a change in the mean. The latter is a first order eﬀect.


2.1.4. Robust Control, Multiplier Utility and Generalizations
Fix a reference measure ∗ ∈ ∆ (Ω), and define relative entropy  ( k ∗ ) ∈ [0 ∞],
for any other measure , by (2.11). Multiplier utility (MU) is defined by:
                                     ∙                        ¸
                     
                                      R                     ∗
                       () = min        ()  +  ( k  ) ,               (2.14)
                                    ∈∆(Ω) Ω


where 0   ≤ ∞ is a parameter.
    This functional form was introduced into economics by Anderson et al. (2003),
who were inspired by robust control theory, and it was axiomatized by Strzalecki
(2007). It suggests the following interpretation. Though ∗ is the individual’s
“best guess” of the true probability law, she is concerned that the true law may
diﬀer from ∗ . In order to accommodate this concern with model misspecification,
when evaluating any given act  she takes all probability measures into account,
weighing more heavily those that are close to her best guess as measured by relative
entropy. Reliance on the (weighted) worst-case scenario reflects an aversion to
model misspecification, or ambiguity. In particular, multiplier utility is ambiguity
averse in the sense of (2.4), and ambiguity aversion increases with −1 in the sense
of the comparative notion (2.5). At the extreme where  = ∞, the minimum is
                                      R
achieved at  = ∗ , and   (·) =  (·) ∗ , reflecting complete confidence in
                                            Ω
the reference measure.
    A key diﬀerence between multiplier utility and other models of ambiguity is
that for choice among Savage acts — that is, acts that do not involve objective
lotteries — it is observationally indistinguishable from subjected expected utility
(SEU). Indeed, utility can be rewritten as8
                                         µ                   ¶
                       
                                          R     ¡ 1      ¢ ∗
                          () = − log     exp −   ()  .              (2.15)
                                                Ω

  8
      See Dupuis and Ellis (1997, Propn 1.4.2), or Skiadas (2009b).



                                                14
Thus, on the domain of Savage acts , for which outcomes are elements of ,
  conforms to subjective expected utility (SEU), with prior ∗ and vNM index
                                     ¡          ¢
                          () = exp − 1  () ,  ∈ .

    For Savage acts, introducing robustness (  ∞) is thus indistinguishable
from increasing risk aversion by moving from  to the more concave  .9 This
observational equivalence matters for applications since most empirically relevant
objects of choice in financial markets are Savage acts — objective lotteries are rare.
In many settings, multiplier utility may thus help reinterpret behavior that is also
consistent with SEU, but it does not expand the range of behavior that can be
rationalized. Reinterpretation can be valuable, for example, if there is an a priori
bound on the degree of risk aversion. Of course, any exercise along these lines
requires taking a stand on  or  — from choice
                                              ¡ 1 behavior
                                                       ¢     alone, one can hope to
identify at most the composite function exp −   (·) . Thus, for example, Barillas
et al. (2009) and Kleschelski & Vincent (2009), fix  () = log , and then arrive
at estimates of the robustness parameter .
    Multiplier utility has restrictive implications for choice in urn experiments.
With one ambiguous urn, it can rationalize   ¡ 1 1the
                                                   ¢ intuitive choices in Ellsberg’s
                                        ∗
experiment surrounding (2.1) - take  = 2  2 and   ∞. However, consider
an experiment with two ambiguous urns — in urn I you are told that  +  = 100
and   ≥ 40, while in urn II you are told only that  and  sum to 100.
Since there is more information about the composition of urn I, we would expect
a preference to bet on red in urn I to red in urn II, and similarly for black.
But this is impossible given multiplier utility. To see this, take the state space
 = {   } × {   }. The ranking of bets would be determined by how
multiplier utility ranks Savage acts over  - but it conforms to subjective expected
utility on the Savage domain. Thus bets would have to be based on a probability
measure  on , which assigns higher probability to  than to  , and similarly
for  and  , an impossibility.
    There is a parallel with CES utility functions in consumer theory that is use-
ful for perspective. The CES utility function is a flexible specification of cross-
substitution eﬀects between goods when there are only two goods, since then the
elasticity is a free parameter. However, when there are more than two goods it
also imposes the a priori restriction that the noted elasticity is the same for all
   9
     Observational equivalence holds in the strong sense that even if one could observe the entire
preference order over Savage acts, and not only a limited set of choices associated with more
realistic sets of financial data, one could not distinguish the two models.

                                               15
pairs of goods. While CES utility remains a useful example, applications may call
for more flexible functional forms (translog utility, for example). Analogously,
multiplier utility can rationalize intuitive choice with one risky and one ambigu-
ous urn. Once there are two or more ambiguous urn, it imposes additional a priori
restrictions that need not be intuitive in applications.
    Finally, consider briefly generalizations. Maccheroni et al. (2006a) introduce
and axiomatize the following generalization, called variational utility:
                                          ∙                  ¸
                         
                                           R
                        () = min            ()  +  () ,              (2.16)
                                   ∈∆(Ω)   Ω

where  : ∆ (Ω) → [0 ∞] is a cost or penalty function. Multiplier utility is the
special case where  () =  ( k ∗ ). The above model is very general - it even
encompasses multiple-priors utility, which corresponds to a cost function of the
form: for some set of priors  ⊂ ∆ (Ω),
                                    ½
                                        0   if  ∈ 
                             () =
                                        ∞ otherwise.

   Such a general model has no diﬃculty accommodating any number of am-
biguous urns; and Maccheroni et al. (2006a) describe a number of interesting
functional forms for  and hence utility. It remains to be seen whether they are
useful in applications.

2.2. Models of Preference: Dynamic or Sequential Choice Settings
Here we outline how the preceding models of preference can be extended to recur-
sive, hence dynamically consistent, intertemporal models. Then further extensions
to accommodate learning are discussed.

2.2.1. Recursive Utility
The formal environment is now enriched as follows. In addition to the (finite)
state space Ω, let T = {0 1   } be a time set, and {Σ }=0 a filtration, where
Σ0 = {∅ Ω} and Σ = 2Ω . Each Σ can be identified with a partition of Ω; Σ ()
denotes the partition component containing . If  is the true state, then at 
the decision-maker knows that Σ () is true. One can think of this information
structure also in terms of an event tree, with nodes corresponding to time-event
pairs ( ).

                                            16
      For simplicity, assume consumption in any single period lies in the interval
 ⊂ R+ . We are interested primarily in -valued consumption processes and
how they are ranked. However, we again enlarge the domain in the Anscombe-
Aumann way and consider the set of all ∆()-valued processes. Each such process
 is the dynamic counterpart of an AA act; it has the form  = ( ), where
 : Ω −→ ∆() is Σ -measurable.
      The new aspect of the dynamic setting is that choices can be made at all times.
To model sequential choice, we assume a preference order at each node in the tree.
Formally, let º be the preference prevailing at ( ), thought of as the ordering
conditional on information prevailing then. The primitive is the collection of
preferences {º } ≡ {º : ( ) ∈ T × Ω}. The corresponding collection of
utility functions is { } ≡ { : ( ) ∈ T × Ω}. They are assumed to satisfy
a recursive structure that we now describe.10 Define  ≡ [1 +  +  +   − ];
in the infinite horizon case, these discount terms simplify and each  is equal to
(1 − )−1 .
      To evaluate the act  from the perspective of node ( ), observe that it yields
the current consumption (lottery)  (), and a random future payoﬀ +1· ();
here · in the subscript indicates that future utility is a function of 0 ∈ Σ (), the
realized node in the the continuation of the tree from ( ). For each such node
 0 , (and only such nodes matter), let
                                                 ¡         ¢
                             +10 () = +1  +1 .
                                                         0                       (2.17)
Thus +10 is a certainty equivalent in the sense of being the (unique) level of
consumption which if received in every remaining period would be indiﬀerent,
from the perspective of ( + 1  0 ), to . Since this certainty equivalent varies
with the continuation  0 , it defines a “static” act, of the sort discussed above, and
whose utility can be computed using one of the static ambiguity models discussed
previously. Finally, the latter utility is aggregated with current felicity in the
familiar discounted additive fashion to yield  ().
    To be more precise, let ∗ denote any of the models of ambiguity preference
                           ∗
discussed above. Let {   } be a collection of utility functions conforming to the
                                                                                  ∗
model ∗, one for each node in the tree, having fixed risk preferences -          (·)
=  (·) on ∆ (), for every ( ). (Some obvious measurability restrictions are
                                ∗
also assumed.) Refer to {     } as a set of one-step-ahead utility functions. Say
  10
    For more detailed formal presentations, see Epstein & Schneider (2003) for the multiple-
priors-based model and Skiadas (2009a, Ch. 6) for the general case. In fact, Skiadas relaxes the
intertemporal additivity that we assume in (2.18) below.

                                              17
that preferences {º }, or the corresponding utilities { }, are recursive if there
                                                                            ∗
exist  : ∆ () → R aﬃne, a discount factor 0    1, and a set {        } of one-
step-ahead utilities such that, for all acts : (i)  +1· () = 0; and (ii) utilities
 () are evaluated by backward induction according to, for each ( ),
                                                      ∗
                                                         ¡  ¢
                      () =  ( ()) + +1    +1· .                (2.18)
    The primitive components of the recursive model are  (·), modeling attitudes
towards current consumption risks (and intertemporal substitutability11 ), a dis-
                                ∗                                        ∗
count factor , and the set { }. It is straightforward to see that  represents
preference, conditional on ( ), over the set of “one-step-ahead acts” - acts 
for which  (·) = +1 (·) for all   , that is,  produces a constant stream (of
lotteries) for times  + 1  + 2 , and, in particular, all ambiguity (though not
                                   ∗
risk) is resolved at  + 1. Thus    models preferences over bets on the next step.
    There are simple restrictions on preferences, specific to the dynamic setting,
that are the main axioms characterizing recursive utility. First, preference at any
node depends only on available information. Second, when evaluating  at any
node, the individual cares only about what  prescribes in the continuation from
that node - unrealized parts of the tree do not matter, an assumption that is com-
monly called consequentialism. Third, the ranking of risky prospects (lotteries)
is the same at every node - a form of state independence. Finally, the collection
of preferences is dynamically consistent - (contingent) plans chosen at any node
remain optimal from the perspective of later nodes.
    Next we discuss the recursive utility specifications corresponding to each of
the static models discussed above. All previous comments remain relevant, (they
relate to the ranking of one-step-ahead acts). We add comments that relate specif-
ically to the dynamic setting. As will become clear from the connections drawn
to the applied literature, the recursive model unifies a range of dynamic utility
specifications that have been pursued in applications. It excludes specifications
adopted in (Hansen & Sargent 2007, 2009, Barillas et al. 2009) and in several
other papers in the robust-control-inspired literature, which violate either conse-
quentialism or dynamic consistency.
    We refer also to continuous-time counterparts of the recursive models. In that
case, the recursive construction of utility functions via (2.17)-(2.18) is replaced by
  11
    The confounding of risk aversion and substitution in  can be improved upon via a common
generalization of (2.18) and Epstein & Zin (1989). The resulting model can (partially) disen-
tangle intertemporal substitution, risk aversion and ambiguity aversion. Skiadas’ (2009, Ch.6)
treatment is general enough to admit such a three-way separation. Hayashi (2005) describes
such a model where the ranking of one-step-ahead acts conforms to the multiple-priors model.

                                             18
backward stochastic diﬀerential equations (BSDEs). These were introduced into
utility theory by Duﬃe & Epstein (1992) in the risk context, and extended to
ambiguity aversion (modeled by multiple-priors) by Chen & Epstein (2002). See
Skiadas (2008) for a nice exposition, original formulations, and references to the
technical literature on BSDEs.

Recursive SEU : If one-step-ahead acts are evaluated by expected utility, then,
from (2.17)-(2.18),
                                         Z
                 () =  ( ()) +  +10 ()  ( 0 )      (2.19)
                                                Ω

where  ∈ ∆ (Ω Σ+1 ) gives ( )-conditional beliefs about the next step. This
is the standard model.

Recursive Multiple-Priors: Let  ⊂ ∆ (Ω Σ+1 ) be the set of ( )-conditional
probability measures describing
                        R        beliefs about the next step (events in Σ+1 ), and
     ∗
let  () = min∈  () , for any  : (Ω Σ+1 ) → ∆ (). Then (2.17)-
(2.18) imply:
                                              Z
                () =  ( ()) +  min     +10 () ( 0 ).       (2.20)
                                           ∈   Ω

This model was first put forth by Epstein & Wang (1994); Epstein & Schnei-
der (2003, 2007, 2008) axiomatize and apply it. The special case, where each
set  has the entropy-constrained form in (2.12), was suggested in Epstein &
Schneider (2003) and has subsequently been applied by a number of papers in
finance, described in Part 2 below. For a continuous-time formulation of recursive
multiple-priors see Chen & Epstein (2002).

                                              ∗
Recursive Smooth Ambiguity Model: Define  ◦  by (2.13), where , but not 
or , varies with ( ). One obtains:
                                  µZ    µ    Z                     ¶         ¶
                               −1         −1                     0
 () =  ( ())++1            +1 +10 ()  ( )  () .
                                    ∆(Ω)                Ω
                                                                           (2.21)
This is closely related to the recursive version of the smooth ambiguity model
described in Klibanoﬀ et al. (2009) and the specifications in the applied papers
by Chen et al. (2009) and Ju & Miao (2009).

                                           19
    Skiadas (2009b) shows that in Brownian and Poisson environments, the continuous-
time limit of the recursive smooth ambiguity model is indistinguishable from one
where the function  is linear, that is, ambiguity aversion vanishes in the limit. He
assumes that  is invariant to the length of the time interval. There may be other
ways to take the continuous-time limit, for example, by allowing the concavity
of  to increase suitably as the interval shrinks. However, keeping  fixed seems
unavoidable if one sees ambiguity aversion as (separate from ambiguity and as)
subject to calibration across settings.

(Recursive) Multiplier Utility and Generalizations: Following (2.15), define
                   ³              ´ µR       ³           ´     ¶
                        1    ∗                    1          ∗
              exp −   () =      exp −   ()              (2.22)
                                          Ω

where ∗ ∈ ∆ (Ω Σ+1 ) is the reference one-step-ahead measure. For simplicity,
and since it is assumed universally, let  = , a constant. Then (2.17)-(2.18)
imply:
                                     ∙ µ                                        ¶¸
                                           R     ¡ 1 −1              ¢ ∗      0
  () =  ( ()) + +1 log −        exp −  +1 +10 ()  ( ) .
                                              Ω

This is a special case of recursive utility as defined by Epstein & Zin (1989), where
−1 parametrizes risk aversion separately from , which models also intertemporal
substitution. In continuous time, one obtains a special case of stochastic diﬀeren-
tial utility (Duﬃe & Epstein (1992)).
    To see the connection to robustness as proposed by Hansen & Sargent (2001),
let ∗ ∈ ∆ (Ω Σ ) be the reference measure corresponding to {∗ } and  any
other measure on Σ , and denote by  and ∗ the restrictions of         and ´i
                                                                       h  ³      ∗ to
                                                                             
Σ . Define the time averaged entropy by R ( k ∗ ) = Σ≥0           ∗    , if
                                                                               
                                                   ∗                         ∗
 is absolutely continuous with respect to  for each , and R ( k  ) = ∞
otherwise. Then, (see Skiadas (2003) for a general proof for continuous-time), the
recursive utility functions above can be written alternatively in the following form
paralleling (2.14):
                         ∙                                             ¸
           
                           R¡                0
                                                 ¢      0            ∗
        0 () = min          Σ=0   ( ( ))  ( ) + R ( k  ) ,         (2.23)
                  ∈∆(Ω)   Ω

                                                         
and similar expressions obtain for conditional utility  (). This reformulation
parallels the equivalence of (2.15) and (2.14) in the static context - it permits a

                                          20
reinterpretation of existing risk-based models, (such as the Barillas et al. (2009)
reinterpretation of Tallarini (2000) in terms of robustness), but does not add new
qualitative predictions.
    To accommodate behavior towards several urns, it could be interesting to
extend the model to allow “source dependence”, that is, several driving processes
and a concern for robustness that is greater for some processes than for others.
However, this is hard to square with dynamic consistency and consequentialism.
Indeed, let Ω = Π=1 Ω , and think of  driving processes. To capture source
dependence, extend (2.23) so that for each Ω , relative entropy measures distance
between Ω -marginals with a separate multiplier  for each . However, unless
the  ’s are all identical, such a model is not recursive and thus precludes dynamic
consistency.
    This is in stark contrast to the recursive framework (2.17)-(2.18) that accom-
modates a wide range of ambiguity preferences, while having dynamic consistency
built in. For example, Skiadas (2008) formulates recursive models that feature
source dependence and that are special cases of our general framework (2.17)—
(2.18). Maccheroni et al. (2006b) axiomatize a recursive version of variational
utility that is the special case of our recursive model for which one-step-ahead
acts are evaluated using variational utility (2.16).
    Skiadas (2009b) derives continuous-time limits for a subclass of recursive vari-
ational utility containing the multiplier model (2.23). He shows that, in a Poisson
environment, (though not with Brownian uncertainty), these models, with the
single exception of multiplier utility, are distinguishable from stochastic diﬀeren-
tial utility. (This is another sense in which multiplier utility is an isolated case.)
Skiadas also suggests that some of them have tractability advantages and are
promising for pricing, particularly because of the diﬀerential pricing of Brownian
and Poisson uncertainty.

2.2.2. Updating and Learning
                                 ∗
The one-step-ahead utilities {  } are primitives in the recursive model (2.17)-
(2.18), and are unrestricted except for technical regularity conditions. Since they
represent the individual’s response to data, in the sense of describing his view
of the next step as a function of history, one-step-ahead utilities are the natural
vehicle for modeling learning. Here, for each of the specific recursive models just
                                          ∗
described, we consider restrictions on { }. Since we remain within the recursive
utility framework, dynamic consistency is necessarily satisfied. The central issue


                                         21
is whether the specification adopted adequately captures intuitive properties of
learning under ambiguity.
    Learning is sometimes invoked to criticize models of ambiguity aversion. The
argument is that since ambiguity is due to a lack of information and is resolved
as agents learn, it is at best a short run phenomenon. Work on learning under
ambiguity has shown that this criticism is misguided. First, ambiguity need not
be due only to an initial lack of information. Instead, it may be generated by
hard-to-interpret, ambiguous signals. Second, there are intuitive scenarios where
ambiguity does not vanish in the long run. We now consider a thought experiment
(based on that in Epstein & Schneider (2008)) to illustrate these points.12

A thought experiment

    You are faced with two sequences of urns. One sequence consists of risky
urns and the other of ambiguous urns. Each urn contains black () and white
( ) balls. Every period one ball each is drawn from that period’s urns and bets
are oﬀered on next period’s urns. The sequence of risky urns is constructed (or
perceived) as follows. First, a ball is placed in each urn according to the outcome
of a fair coin toss. If the coin toss produces heads, the “coin ball” placed in
every urn is black; it is white otherwise. In addition to a coin ball, each risky
urn contains four “non-coin balls”, two of each color. The sequence of risky urns
is thus an example of learning from i.i.d. signals. After suﬃciently many draws,
you will become confident about the color of the coin ball from observing the
frequency of black draws.
    Each urn in the ambiguous sequence also contains a single coin ball with color
determined as above (the coin tosses for the two sequences are independent.) In
addition, you are told that each urn contains either  = 2 or  = 6 non-coin balls
of which exactly 2 are black and 2 are white. Finally,  varies “independently”
across ambiguous urns. The ambiguous urns thus also share a common element
(the coin ball), about which you can hope to learn, but they also have idiosyn-
cratic elements (the non-coin balls) that are poorly understood and thus possibly
unlearnable.
    Ex ante, not knowing the outcome of the coin tosses, would you rather have a
bet that pays 100 if black is drawn from the first risky urn (and zero otherwise), or
a bet that pays 100 if black is drawn from the first ambiguous urn? The intuition
  12
    The literature has not provided compelling axioms, beyond those underlying recursivity
(2.17)-(2.18), to guide the modeling of learning under ambiguity. Thus we rely on the thought
experiment to assess various models.

                                             22
pointed to by Ellsberg suggests a strict preference for betting on the risky urn.13
The unambiguous nature of the bet on the risky urn can thus be oﬀset by reducing
the winning stake there. Let   100 be such that you are indiﬀerent between a
bet that pays  if black is drawn from the risky urn and a bet that pays 100 if
black is drawn from the ambiguous urn.
    Now sample by drawing one ball from the first urn in each sequence. Suppose
that the outcome is black in both cases. With this information, consider versions
of the above bets based on the second period urns. Would you rather have a bet
that pays  if black is drawn from the second risky urn or a bet that pays 100
if black is drawn second ambiguous urn? Our intuition is that, even with this
diﬀerence in stakes, betting on the risky urn would be strictly preferable. The
reason is that inference about the coin-ball is clear for the risky urn - the posterior
probability
       ¡  ¢ of a¡black
                   ¢   coin ball is 35 - and thus the predictive probability of drawing
 is 35 35 + 25 25 = 13 25
                           . In contrast, for the ambiguous urn the signal (a black
draw) is harder to interpret, leaving us less confident in our assessment of the
composition of that urn. We now elaborate on this point.
    Just as for the risky sequence, the only useful inference for the ambiguous
sequence is about the coin ball (since non-coin balls are thought to be unrelated
across urns in the sequence). But what does a black draw tell us about the coin
ball? On the one hand, it could be a strong signal of the color of the coin ball (if
 = 2 in the sampled urn) and hence also of a black draw from the second urn.
On the other hand, it could be a weak indicator (if  = 6 in the sampled urn).
The posterior probability of the coin ball being black could be anywhere between
62+1
  6+1
      = 47 and 22+1
                 2+1
                      = 23 , with a range of predictive probabilities for  ensuing.
    The diﬀerence in winning stakes,  versus 100, compensates for prior ambiguity,
but not for the diﬃculty in interpreting the realized signal. Thus a preference for
betting on the risky urn is to be expected, even given the diﬀerence in winning
prizes. By analogous reasoning, similar rankings for bets on white are intuitive,
both ex ante and ex post conditional on having drawn black balls. Indeed, the
lower quality of the signal from the ambiguous urn makes it harder to judge
any bet, not just a bet on black. This completes the description of the thought
experiment.
A multiple-priors model of learning under ambiguity
  13
     In the risky urn,  has an objective probability of 12 . For the ambiguous urn, the correspond-
ing probability is either in [ 47  23 ], or in [ 13  37 ], each with probability 12 . Averaging endpoints yields
the interval [ 19   23                  1
               42  42 ], which has 2 as midpoint. Thus ambiguity aversion suggests the preference
                  1
for the precise 2 .

                                                       23
    Epstein & Schneider (2008) propose a model of learning, within the recursive
multiple-priors framework (2.20), that accommodates the intuitive choices in the
thought experiment. It is motivated by the following interpretation of the exper-
iment. The preference to bet on the risky urn ex post is intuitive because the
ambiguous signal — the draw from the ambiguous urn — appears to be of lower
quality than the noisy signal — the draw from the risky urn. A perception of
low information quality arises because the distribution of the ambiguous signal is
not objectively given. As a result, the standard Bayesian measure of information
quality, precision, seems insuﬃcient to adequately compare the two signals. The
precision of the ambiguous signal is parametrized by the number of non-coin balls
: when there are few non-coin balls that add noise, precision is high.
    A single number for precision cannot rationalize the intuitive choices because
behavior is as if one is using diﬀerent precisions depending on the bet that is
evaluated. When betting on a black draw, the choice between urns is made as
if the ambiguous signal is less precise than the noisy one, so that the available
evidence of a black draw is a weaker indicator of a black coin ball. In other words,
when the new evidence — the drawn black ball — is “good news” for the bet to be
evaluated, the signal is viewed as relatively imprecise. In contrast, in the case of
bets on white, the choice is made as if the ambiguous signal is more precise than
the noisy one, so that the black draw is a stronger indicator of a black coin ball.
Now the new evidence is “bad news” for the bet to be evaluated and is viewed
as relatively precise. The intuitive choices can thus be traced to an asymmetric
response to ambiguous news.
    The implied notion of information quality can be captured by combining worst-
case evaluation with the description of an ambiguous signal via multiple likelihoods.
To see how, think of the decision-maker as trying to learn the colors of the two coin
balls - that is all he needs to learn for the risky sequence, and for the ambiguous
sequence, his perception of non-coin balls as varying independently across urns
means that there is nothing to be learned from past observations about that
component of future urns. For both sequences, his prior over these “parameters”
places probability 12 on the coin ball being black. (More generally, the model
admits multiple-priors over parameters.) The intuition given above for the choices
indicated in the experiment suggests clearly a translation in terms of multiple
likelihoods. Signals for the risky sequence have objective distributions conditional
on the color of the coin ball, and thus can be modeled in the usual way by single
likelihoods. However, for the ambiguous sequence, the distribution of the signal
is unknown, even conditioning on the color of the coin ball, because it varies with


                                         24
, suggesting multiple-likelihoods.


Other models of learning

    How do other models perform with respect to the thought experiment? SEU is
ruled out by the ex ante ambiguity averse ranking (the situation is ultimately anal-
ogous to Ellsberg’s original experiment). The same applies to multiplier utility
since it coincides with SEU on Savage acts. Recursive variational utility (Mac-
cheroni et al. 2006b) inherits the generality of variational utility. In particular, it
generalizes recursive multiple-priors and so can accommodate the thought exper-
iment. The question is whether the added generality that it aﬀords is useful in a
learning context. A diﬃculty is that it is far from clear how to model updating of
the cost or penalty function  (·).
    The situation is more complicated for the smooth ambiguity model. It can
accommodate the ex ante ambiguity averse choices. In order to consider also the ex
post rankings indicated it is necessary to specify updating for the recursive smooth
model (2.21). We assume that beliefs  about the true law are updated by
Bayes’ Rule. Then the recursive smooth model cannot accommodate the intuitive
behavior in the thought experiment, at least given natural specifications of the
model, that we now outline.
    Consider the functional form for utility (2.13). For the risky urns, all relevant
probabilities are given, and thus bets on the risky urns amount to lotteries, which
are ranked according to . To model choice between bets on the ambiguous urns,
we must first specify the state space Ω. Take Ω = {  } so that a state specifies
the color of the ball on any single draw.14 Then a bet on  corresponds to the act
 , with  () = 100 and  ( ) = 0. The smooth model specifies prior beliefs
 about the true probability of drawing . Here the latter is determined by the
color of the coin ball  =  or  , and by the number  = 2 or 4 of the non-coin
balls, according to                     ⎧ 2
                                        ⎪
                                        ⎪      =   = 2
                                        ⎨ 31
                                           3
                                               =   = 2
                          ( |  ) =    4                                    (2.24)
                                        ⎪
                                        ⎪      =   = 6
                                        ⎩ 37
                                           7
                                              =   = 6.
  14
    An alternative is to take the state space to be {2 4}, corresponding to the possible number
of the non-coin balls. However, it is not diﬃcult to see that with this state space, even the
(ambiguity averse) ex ante choices cannot be rationalized.


                                              25
Thus view  as a probability measure on pairs ( ). Let  be uniform over the
above four possibilities and suppose that  is strictly concave (as in all applications
of the model that we have seen). Then it is a matter of elementary algebra
(provided in the appendix) to show that the choices described in the thought
experiment cannot be accommodated.
    A final comment concerns a theme we have emphasized throughout the dis-
cussion of preference models: appearances can be misleading - the only way to
understand a model is through its predictions for behavior, whether through for-
mal axioms, or thought experiments. On the surface, what could be more natural
than to use Bayes’ Rule to update the prior as in the recursive smooth model?
There is no need to deal with the issue of how to update sets of priors as in
Epstein & Schneider (2007, 2008), for example, and one can import results from
Bayesian learning theory. The models in Hansen (2007), Chen et al. (2009) and
Ju & Miao (2009) share this simplicity - in all cases, updating proceeds exactly as
in a Bayesian model and ambiguity aversion enters only in the way that posterior
beliefs are used define preference. However, the thought experiment illustrates
what is being assumed by adopting such an updating rule - indiﬀerence to “signal
or information quality.”

3. Ambiguity in financial markets
This section illustrates the role of ambiguity in portfolio choice and asset pricing.
We consider simple 2- and 3-period setups. These are suﬃcient to illustrate many
of the eﬀects that drive more elaborate (and now increasingly quantitative) models
studied in the literature. We also focus on the multiple-priors model. This is
because the range of new eﬀects - relative to models of risk - is arguably larger for
that model. Specific diﬀerences between the multiple-priors and smooth models
are pointed out along the way.

3.1. Portfolio choice
Begin with a 2-period problem of savings and portfolio choice. An agent is en-
dowed with wealth 1 at date 1 and cares about consumption at dates 1 and 2.
There is an asset that pays the interest rate  for sure, as well as  uncertain
assets with log returns collected in a vector . The returns  could be ambiguous;
let P1 denote a set of beliefs held at date 1 about returns at date 2. The agent
chooses consumption at both dates and a vector of portfolio shares  for the 


                                          26
uncertain assets to solve
                                 max min {(1 ) +   [(2 )]}
                                 1  ∈P1
                   s.t. 2 = (1 − 1 )2
                                          X
                                          
                        2 = (exp( ) +    exp( ))
                                               =1

where 2   is the return on wealth realized at date 2.
    Now restrict attention to log utility and lognormally distributed returns. With
 () = log , the savings and portfolio choice problems separate. In particular,
the agent always saves a constant fraction (1 + ) of wealth, and he chooses his
portfolio to maximize the expected log return on wealth. With lognormal returns,
a belief in P1 can be represented by a vector  of expected (log) returns as well as
a covariance matrix Σ. Throughout, we use an approximation for the log return
on wealth introduced by Campbell & Viceira (1999),
                                    µ                   ¶
                                          1                  1
                   log 2 ≈  +   +  Σ −   − 0 Σ,
                                0                   
                                                                               (3.1)
                                          2                  2
where  Σ is a vector containing the main diagonal of Σ and  is an -vector of
ones. In continuous time, the formula is exact by Ito’s Lemma; in discrete time,
it yields simple solutions that illustrate the key eﬀects.
    It is convenient to work with excess returns. Define a vector of premia (ex-
pected log excess returns, adjusted for Jensen’s inequality) by
                                      1
                              =  + Σ −  
                                      2
Let Π1 denote the set of parameters (  Σ) that correspond to beliefs in P1 .
This set can be specified to capture ambiguity about diﬀerent aspects of the
environment. In general, the size of Π1 reflects the agents’ lack of confidence
when thinking about returns. For example, worse information about an asset
might lead an agent to have a wider interval of possible mean log returns for that
asset. In a dynamic setting, the size of the sets Π1 and P1 will change over time
with new information. Below we discuss the eﬀects of such updating by doing
comparative statics with respect to features of Π1 .
   Using the approximation (3.1), the portfolio choice problem becomes
                                                 ½                  ¾
                                                     0   1 0
            max min  [log 2 ] ≈ max min         +   −  Σ            (3.2)
              ∈P1                   ( Σ)∈Π1             2

                                          27
If there is no ambiguity — that is, (  Σ) is known and is therefore the only element
of Π1 — then we have a standard mean-variance problem, with optimal solution
 = Σ−1  . More generally, the agent evaluates each candidate portfolio under
the worst case return distribution for that portfolio.


3.1.1. One ambiguous asset: nonparticipation and portfolio inertia at
       certainty
Assume that there is only one uncertain asset. Its log excess return has known
variance  2 and an ambiguous mean that lies in the interval [̄ − ̄ ̄ + ̄]. Think
of ̄ as a benchmark estimate of the premium; ̄ then measures the agent’s lack
of confidence in that estimate. The agent solves
                                              ½              ¾
                                                     1 2 2
                      max  min                 +  −                          (3.3)
                         ∈[̄ −̄̄ +̄]          2
Minimization selects the worst case scenario depending on the agent’s position:
 = ̄ − ̄ if   0 and  = ̄ + ̄ if   0. Intuitively, if the agent contemplates
going long in the asset, he fears a low excess return, whereas if he contemplates
going short, then he fears a high excess return. If  = 0 the portfolio is not
ambiguous and any  in the interval solves the minimization problem.
    The optimal portfolio decision anticipates the relevant worst case scenario. For
a given range of premia, the agent evaluates the best nonnegative position as well
as the best nonpositive position, and then chooses the better of the two. This
leads to three cases. First, if the premium is positive for sure (̄ − ̄  0), then
it is optimal to go long. Since any long position is evaluated using the lowest
premium, the optimal weight in this case is  = (̄ − ̄)  2  0. Similarly, if
the premium is known to be negative (̄ + ̄  0), then the optimal portfolio
sells the asset short:  = (̄ + ̄)  2  0. Finally, if ̄ + ̄  0  ̄ − ̄,
then it is optimal to not participate in the market ( = 0). This is because any
long position is evaluated using the lowest premium, which is now negative, and
any short position is evaluated using the highest premium, which is positive. In
both cases, the return on wealth is strictly lower than the riskless rate and so it
is better to stay out of the market.
    Under ambiguity, nonparticipation in markets is thus optimal for many para-
meter values. In particular, for any benchmark premium ̄ , a suﬃciently large
increase in uncertainty will lead agents to withdraw from an asset market alto-
gether. This is not true if all uncertainty is risk. Indeed, the participation decision

                                           28
does not depend on the quadratic risk term in (3.3). That term becomes 2nd order
as  goes to zero, that is, agents are "locally risk neutral" at  = 0. In the absence
of ambiguity (̄ = 0), agents participate except in the knife edge case ̄ = 0.
Moreover, an increase in the variance  2 does not make agents withdraw from the
market, it only makes them choose smaller positions.
    Ambiguity averse agents exhibit portfolio inertia at  = 0. Indeed, consider
the response to a small change in the benchmark premium ̄ . For ̄  |̄|, an
ambiguity averse agent will not change his position away from zero. This is again
in sharp contrast to the risk case, where the derivative of the optimal position with
respect to ̄ is everywhere strictly positive. The key point is that an increase
in ambiguity can be locally “large” relative to an increase in risk. Indeed, the
portfolio  = 0 is both riskless and unambiguous. Any move away from it makes
the agent bear both risk and ambiguity. However, an increase in ambiguity about
means is perceived like a change in the mean, and not like an increase in the
variance. Ambiguity can thus have a first order eﬀect on portfolio choice that
overwhelms the first order eﬀect of a change in the mean, whereas the eﬀect of
risk is second order.


3.1.2. Hedging and portfolio inertia away from certainty
Nonparticipation and portfolio inertia can arise also when the portfolio  = 0 does
not have a certain return, and when the ambiguous asset can help hedge risk.15
To see this, assume that the interest ¡rate is
                                             ¢ not riskless but instead random with
                            2            
known mean  , variance   and     =     0. One interpretation is that
 is the real return on a nominal bond and  is the return on the stock market,
which is perceived to be an inflation hedge (stocks pay oﬀ more when inflation
lowers the real bond return). The agent solves

                                                             ½                                ¾
                                                                                1 2 2
  max min            [log 2 ]   ≈ max  min                                           2
                                                               + ( −    ) − (  +   ) .
          ∈P1                         ∈[̄ −̄̄ +̄]                     2
Investing in stocks is now useful not only to exploit the equity premium  , but
also to hedge the risk in a bond position. Moreover, the portfolio  = 0 (holding
  15
    It is sometimes claimed in the literature that the multiple-priors model gives rise to inertia
only at certainty. The claim is often based on examples with two states of the world, where MP
preferences exhibit indiﬀerence curves that are kinked at certainty and smooth elsewhere. How-
ever, the example here illustrates that in richer settings inertia is a more general phenomenon.

                                                     29
all wealth in bonds) is still unambiguous, but it is no longer riskless. Adapting
the earlier argument, the agent goes long in stocks if ̄ − ̄ −    0, he goes
short if ̄ + ̄ −     0, and he stays out of the stock market otherwise. For a
positive benchmark equity premium ̄  0, the degree of ambiguity (measured by
̄) required to generate nonparticipation is now larger (because of the benefit of
hedging), but the basic features of nonparticipation and portfolio inertia remain.
The key point is that investing in stocks exposes investors to a source of ambiguity
— the unknown equity premium — while investing in bonds does not.
    Portfolio inertia is a property that is distinct from, and more general than,
nonparticipation. This is because even away from certainty there can be portfolios
where a small change in a position entails a large change in the worst case belief.
To illustrate, consider an agent who believes in a one-dimensional set of models of
excess returns indexed by an ambiguous parameter  ∈ [0 ̄]. In particular, the
premium is  = ̄ +  and the variance is  2 = ̄ 2 + 2, where  is known.
Intuitively, the agent believes that risk and expected return go together, but he
does not know the precise pair (   2 ).16 He solves
                                            ½                                 ¾
                                                         1 2¡ 2         ¢
      max min  [log 2 ] ≈ max min  + (̄ + ) −  ̄ + 2 .
        ∈P1                     ∈[0̄]                  2

There are now two portfolios that are completely unambiguous,  = 0 and  = ,
and the latter yields the higher return on wealth if ̄  ̄ 2 2. If, moreover,
ambiguity is large enough so that ̄  ̄ 2 + ̄, then it is optimal to choose
 = .
    At  = , a small increase in  leads to the worst case scenario  = ̄, while a
small decrease leads to  = 0 Intuitively, risk is taken more seriously relative to
expected return at higher positions. Accordingly, the worst case scenario changes
with position size: at high positions, agents fear high risk, whereas at small posi-
tions, they fear low expected returns. At  = , the two eﬀects oﬀset.17 It follows
that, at  = , any news that slightly changes the benchmark premium ̄ has no
eﬀect on portfolio choice. Indeed, changing the portfolio to exploit news about
  16
     Illeditsch (2009) shows that such a family of models can obtain when agents receive bad
news of ambiguous precision: more precise bad news lowers both the conditional mean and the
conditional variance or returns.
  17
     The presence of an unambiguous portfolio is a knife edge case driven by the functional form
(or here by the approximation we are using). More generally, even if no portfolio makes the
objective function independent of , there can exist portfolios at which the minimizing choice
of  flips discontinuously.


                                              30
̄ would require the agent to bear ambiguity. The resulting first order loss from
increased uncertainty overwhelms the gain from a small change in ̄ .


3.1.3. Multiple ambiguous assets: selective participation and benefits
       from diversification
With multiple assets, ambiguity gives rise to selective participation. To illustrate,
consider a set of  uncertain assets such that (i) returns are known to be uncor-
related: the covariance matrix Σ in (3.2) is diagonal, and (ii) the premia  are
perceived to be ambiguous but independent:  lies in the Cartesian product of
intervals [̄ − ̄  ̄ + ̄ ],  = 1   From (3.2), it is optimal to participate in
the market for asset  if and only if 0 ∈            [̄ − ̄  ̄ + ̄ ] that is, if the premium
on asset  is nonzero and not too ambiguous. Agents thus stay away from those
markets for which they lack confidence in assessing the distribution of returns.18
     If ambiguity about premia is independent across assets, then it cannot be
diversified away. To see this, specialize further to i.i.d. risk (Σ =  2 ), as well as
i.i.d. ambiguity about premia. In particular, let all premia lie in the same interval
which is centered at ̄ = ̂ and has bounds implied by ̄ = ̂. Assume also
that it is worthwhile to go long in all markets, or ̂ − ̂  0. Symmetry implies
that the optimal portfolio invests the same share, say ̂ in each uncertain asset.
Substituting  = ̂ for all  as well as  = (̂ − ̂) in (3.2), the return on
wealth is
                                                       ½                                 ¾
                                                                                2 2
                max min  [log 2 ] ≈ max  + ̂(̂ − ̂) − ̂ .
                   ∈P1                           ̂                               2

As the number of independent uncertain assets becomes large, the quadratic term
becomes small and the eﬀect of risk on the portfolio decreases. At the same
time, the eﬀect of ambiguity on portfolio choice remains unchanged. Intuitively,
ambiguity reflects confidence in prior information about individual assets that is
perceived like a reduction in the mean. Investing in many assets does not raise
confidence in that prior information.
   Without independence, diversification may be beneficial, because assets hedge
ambiguity in other assets. For an example, retain the assumption of i.i.d. risk,
  18
    Introducing correlation among returns will change the conditions for participation, but will
not rule out selective participation. The argument is essentially the same as in the previous
subsection.


                                                  31
but suppose now the agent believes premia are  = ̂  + , for some (unknown)
 satisfying 0  ≤ 2 ;   ̂ is fixed. Intuitively, the agent perceives a common
factor in mean returns such that if one mean is very far away from the benchmark
̂ , then all others must be relatively close. The agent solves
                                                 ½                       ¾
                                                                2 2
            max min  [log 2 ] ≈ max min          + (̂  + ) −  .
                ∈P1                   0 ≤2                    2

Symmetry
     p again   implies  = ̂ for some ̂. For ̂  0, minimization yields
          0      √
 =  2  =   and the portfolio return is thus
                          ½                         ¾
                                            2 2
                     max  + ̂(̂ − √ ) − ̂ .
                       ̂                     2

The eﬀect of ambiguity on portfolio choice thus shrinks as  increases, although
the speed is slower than for risk.
    An extreme case of cross-hedging ambiguity arises when a unambiguous family
of portfolios can be constructed. Suppose, for example, that there are only two
assets with i.i.d. risk, and that 1 = ̂ +  and 2 = ̂ − , with 2 ≤ 2 . Such a
situation might arise when there is pool of assets (e.g. mortgages) with relatively
transparent payoﬀ, which has been cut into tranches in a way that makes the
payoﬀs on the individual tranches rather opaque. In this case, holding the entire
pool, or holding tranches in equal proportions hedges ambiguity. In contrast, an
agent holding an individual tranche in isolation bears ambiguity.


3.1.4. Dynamics: entry & exit rules and intertemporal hedging
To illustrate new eﬀects that emerge in an intertemporal context, consider a three
period setup with one uncertain asset. Beliefs can be described by sets of one-
step-ahead conditionals. The date 1 one-step-ahead conditionals for date 2 log
excess return are normal with variance  22 and ambiguous mean in the interval
[̄2 − ̄2  ̄2 + ̄2 ]. As of date 2, the date 3 log excess returns are again viewed as
normal, now with variance 23 . Moreover, there is a signal 2 that induces, via some
updating rule, an interval of expected log excess returns [̄3 (2 )− ̄3 (2 )  ̄3 (2 )+
̄3 (2 )]. In general, the signal can be correlated with the realized excess return 2 .
This will be true, for example, if the agent is learning about the true premium, and
the realized excess return is itself a signal. Importantly, updating will typically


                                             32
aﬀect both the benchmark mean return ̄3 and the agents’ confidence, as measured
by ̄3 .
   Portfolio choice at date 2 works just like in the one period problem (3.3) above.
The value function from that problem depends on wealth 2 and the signal 2 .
Up to a constant, it takes the form 2 (2  2 ) = log 2 +  (2 )  where
                     1 ¡                             2                               2
                                                                                         ¢
         (2 ) =        max{̄3 (2 ) − ̄ (2 )  0}  + min{̄3 (2 ) + ̄ (2 )  0}
                    223

The value function is higher for signals that move the range of equity premia away
from zero and thus permit worst case expected returns higher than the riskless
rate. For example, Epstein & Schneider (2007) show in a model of learning about
the premium with 2 = 2 that the value function is -shaped in the signal.
    Since the value function 2 is separable in 2 and 2 , the portfolio choice
problem at date 1 can still be solved separately from the savings problem. The
agent solves
                         max min {  [log 2 +  (2 )]} 
                                   ∈P1

The diﬀerence from the one shot problem (3.3) is that minimization takes into
account the eﬀect on the expected return at the optimal portfolio to be chosen
at date 2, captured by . As a result, it is possible that the choice of , and the
choice of the optimal portfolio, are diﬀerent in the 2-period problem than in the
1-period problem. In other words, an investor with a two period horizon does not
behave myopically, but chooses to hedge future investment opportunities. This
hedging is due entirely to ambiguity - it is well known that with log utility and a
single prior, myopic behavior is optimal.19
    In the intertemporal context, the (recursive) multiple-priors model delivers two
new eﬀects for portfolio choice. First, the optimal policy involves dynamic exit and
entry rules. Indeed, updating shifts the interval of equity premia, and such shifts
can make agents move in and out of the market. Second, there is a new source
of hedging demand. It emerges if return realizations provide news that shift the
interval of equity premia. Portfolio choice optimally takes into account the eﬀects
of news on future confidence. The direction of hedging depends on how news
aﬀects confidence. For example, Epstein & Schneider (2007) show that learning
  19
    In the expected utility case, hedging demand is linked to a nonzero cross derivative of the
value function 2 . With ambiguity, hedging demand can arise in the log case even though the
cross derivative is zero. The reason is that the minimization step creates a link across terms
between   [log 2 ] and   [ (2 )].


                                                33
about premia gives rise to a contrarian hedging demand if the empirical mean
equity premium is low. Intuitively, agents with a low empirical estimate know
that a further low return realization may push them towards nonparticipation,
and hence a low return on wealth (formally this is captured by a U-shaped value
function). To insure against this outcome, they short the asset.


3.1.5. Diﬀerences between models of ambiguity
This section has illustrated several phenomena that can be traced to first order
eﬀects of uncertainty under the multiple-priors model, in particular selective par-
ticipation, portfolio inertia and the inability to diversify uncertainty (at least for
some sets of beliefs). These eﬀects cannot arise under SEU, which implies local
risk neutrality at certainty, smooth dependence of portfolios on the return dis-
tribution (at least under the standard assumptions studied here) and benefits of
diversification.
    The smooth model and multiplier utility resemble SEU in the sense that they
also cannot generate the above phenomena. This is immediate for multiplier util-
ity, which is observationally equivalent to SEU on Savage acts, as explained in
Section 2.1.4. Moreover, for the smooth model, if  and  are suitably diﬀeren-
tiable, then so is   . As a result, selective participation is again a knife-edge
property. A theme that is common to smooth models and the MP model is the
emergence of hedging demand due to ambiguity.
    Some authors have argued that smoothness is important for tractability of
portfolio problems. It is true that smoothness permits the use of calculus tech-
niques. Moreover, in the expected utility case closed form solutions for dynamic
problems are sometimes available, and the same may be true for smooth models
that are close to expected utility. However, most applied portfolio choice problems
considered in the literature today are solved numerically. Even in the expected
utility case, they often involve frictions that make closed form solutions impos-
sible. From a numerical perspective, the additional one-step-ahead minimization
step does not appear excessively costly.


3.1.6. Discipline in quantitative applications
In the portfolio choice examples above as well as in those on asset pricing below,
the size of the belief set is critical for the magnitude of the new eﬀects. There


                                         34
are two approaches in the literature to disciplining the belief set. Anderson et
al. (2000) propose the use of detection error probability (see also Barillas et al.
(2009) for an exposition). While those authors use detection error probabilities in
the context of multiplier preference, the idea has come to be used also to constrain
the belief set in multiple-priors. The basic idea is to permit only beliefs that are
statistically close to some reference belief, in the sense that they are diﬃcult to
distinguish from the reference belief based on historical data.
    To illustrate, let  denote a reference belief (for example, a return distribu-
tion), and let  denote some other belief. We want to describe a sense in which
 and  are “statistically close”. Let  denote the probability, under , that
a likelihood ratio test based on the historical data (of returns, say) would falsely
reject  and accept . Define   similarly as the probability under  of falsely
rejecting  in favor of . Finally, define the detection error probability  by
 = 12 (  +   ) The set of beliefs is now constrained to include only beliefs
with  small enough. (One might also choose to make additional functional form
assumptions, for example, serial independence of returns.)
    A second approach to imposing discipline involves using a model of learning.
For example, the learning model of Epstein & Schneider (2007) allows the mod-
eler to start with a large set of priors in a learning model — resembling a diﬀuse
prior in Bayesian learning — and then to shrink the set of beliefs via updating. A
diﬀerence between the learning and detection probability approach is that in the
former the modeler does not have to assign special status to a reference model.
This is helpful in applications where learning agents start with little information,
for example, because of recent structural change. In contrast, the detection prob-
ability approach works well for situations where learning has ceased or slowed
down, and yet the true model remains unknown.


3.1.7. Literature notes
The nonparticipation result with one uncertain asset is due to Dow & Werlang
(1992). More general forms of portfolio inertia appear in Epstein & Wang (1994)
and Illeditsch (2009). Mukerji & Tallon (2003) compare portfolio inertia under
ambiguity and first order risk aversion. Garlappi et al. (2007) characterize port-
folio choice with multiple ambiguous assets. Bossaerts et al. (2010) and Ahn
et al. (2009) provide experimental evidence that supports first order eﬀects of
uncertainty in portfolio choice.


                                        35
    A large empirical literature shows that investors prefer assets that are famil-
iar to them, and that the extensive margin matters.20 Quantitative studies of
familiarity bias using the multiple-priors model thus seem a promising avenue for
future research. Cao et al. (2007) summarize the evidence and discuss ambiguity
aversion as a possible interpretation. Most applications of ambiguity to portfolio
home bias (Uppal & Wang 2003, Benigno & Nistico 2009) and own-company-
stockholdings (Boyle et al. (2003)) employ smooth models and do not focus on
the extensive margin.
    Epstein & Schneider (2007) compute a dynamic portfolio choice model with
learning, using the recursive multiple-priors approach. They derive dynamic exit
and entry rules, and an intertemporal hedging demand. They also show that,
quantitatively, learning about the equity premium can generate a significant trend
towards stock market participation and investment, in contrast to results with
Bayesian learning.21 Campanale (2010) builds a MP model of learning over the life
cycle. He shows that such a model helps to explain participation and investment
patterns by age in the US Survey of Consumer Finances. Miao (2009) considers
portfolio choice with learning and multiple-priors in continuous time.

3.2. Asset pricing
We now use the above results on portfolio choice to derive consumption-based asset
pricing formulas. Our formal examples focus on representative agent pricing, since
the literature on this issue is more mature and has proceeded to derive quantitative
results; notes on new work on heterogeneous agent models are provided below.
    In equilibrium, a representative agent is endowed with a claim to consumption
at date 2 and prices adjust so he is happy to hold on to this claim. Write date 2
consumption as 2 = 1 exp (∆) where ∆ is consumption growth. It is useful
to distinguish between consumption and dividends.22 Assume that a share 1− of
consumption consists of labor income which grows at the constant rate  and that
  20
     One candidate explanation for nonparticipation is that expected utility investors pay a per-
period fixed cost. Vissing-Jorgenson (2003) argues that this approach cannot explain the lack
of stock market participation among the wealthy in the US.
  21
     The reason lies in the first order eﬀect of uncertainty on investment. Roughly, learning
about the premium shrinks the interval of possible premia and thus works like an increases in
the mean premium, rather than just a reduction in posterior variance, which tends to be 2nd
order.
  22
     In our two period economy, we call the payoﬀ to stocks dividends. In a dynamic model, the
second period utility is a value function over wealth, and the payoﬀ on stocks includes the stock
price. The basic intuition is the same.

                                               36
a share  consists of dividends that have a lognormal growth rate ∆ with variance
 2 and an ambiguous mean  ∈ [̄ − ̄ ̄ + ̄]. Using the same approximation
as for the return on wealth above, write consumption growth as
                                         µ            ¶
                                                 1 2      1
                     ∆ = (1 − )  +  ∆ +   −  2  2 .
                                                 2        2
    The consumption claim trades at date 1 at the price  and has log return
 = log 2 − log  = ∆ − log ( 1 ). The premium on the consumption claim
is
                                                µ         ¶
                1                                     1 2
    =  [ ] +  ( ) −  = (1 − )  +   +   − log ( 1 ) −  .
                          
                2                                     2
The representative agent solves a version of problem (3.3), given wealth  =
 + 1 and a range of premia  generated by ambiguity in dividend growth  
At the equilibrium price and interest rate, he must find it optimal to choose  = 1
and 1 = ( + 1 )(1 + ). The latter condition pins down  — with log utility,
the price-dividend ratio on a consumption claim depends only on the discount
factor.
    The condition  = 1 pins down the interest rate. Since   0, minimization in
(3.3) selects the lowest premium, say  , by selecting the lowest mean dividend
growth rate ̄ − ̄. Solving the condition  = 1 for the interest rate, we obtain

                  ½                                  ¾
                                       1 2     1 2 2   1
      = − log  + (1 − )  + (̄ +   ) −    −  2  2 − ̄,
      
                                                                               (3.4)
                                       2       2       2
The interest rate depends on the discount factor, the mean consumption growth
rate (in braces), as well as on a precautionary savings term. An increase in either
risk or ambiguity makes the agent try to save more, which tends to lower the
equilibrium interest rate. If   1, an increase in risk also raises the mean growth
rate of consumption.
    The same price and interest rate would obtain in an economy where the agent
is not ambiguity averse but simply pessimistic: he believes that mean consumption
growth is ̄ − ̄ for sure. This reflects a general point made first by Epstein &
Wang (1994): asset prices under ambiguity can be computed by first finding the
most pessimistic beliefs about the consumption claim, and then pricing assets
under this pessimistic belief. We emphasize that this does not justify simply
modeling a pessimistic Bayesian investor to begin with. For one thing, the worst

                                        37
case scenario implied by a multiple-priors setup may look absurd when interpreted
as a dogmatic Bayesian belief. Moreover, a form of the Lucas critique applies: the
pessimistic investor is no more than a convenient “reduced form” — focusing on
him can give misleading answers to comparative statics (e.g. policy) questions.
    Turn now to the stock price and equity premium. If a claim to dividends
2 = 1 ∆ trades at the price  , absence of arbitrage opportunities requires
that its premium satisfy (̄ − ̄ + (12)2 − log( 1 ) −  ) = . The price-
dividend ratio on equity is thus
                                      1
                    1 = exp(̄ +  2 ) exp(− − (̄ +  2 ))
                                      2
The price is the expected level of dividends under benchmark growth ̄ (the first
term), discounted at an uncertainty adjusted rate that increases in both risk 2
and ambiguity ̄. Importantly, the degree of ambiguity ̄ aﬀects the discount
rate one-for-one, but it aﬀects the interest rate (3.4) only  for one. For small ,
changes in ambiguity (for example due to updating) have a large eﬀect on stock
prices, but only a small eﬀect on interest rates. This is important for addressing
the equity volatility puzzle.
     To discuss premia observed in the market, we need to take a stand on the
true data generating process. Suppose that dividend growth is drawn from a
distribution with mean ∗ and variance 2 . An econometrician who observes many
realizations of the economy obtains a sample of excess returns ∆ − log ( 1 ) −
 . The average premium measured by the econometrician is thus
                                         1
               ∗ − log ( 1 ) −  +  2 = 2 + ∗ − (̄ − ̄) .      (3.5)
                                         2
It consists of a risk premium and an ambiguity premium. The risk premium is the
covariance of consumption growth and stock returns. For an asset that represents
only a small share of consumption, a large risk premium thus requires large payoﬀ
volatility  2 .
    The ambiguity premium consists of the diﬀerence between true mean dividend
growth and the worst case mean used by the agent to evaluate the asset. If the
belief interval is centered around the truth (̄ = ∗ ), then the ambiguity premium
is simply equal to ̄. In any case, the share of the payoﬀ in consumption does not
matter for the ambiguity premium. If a lack of confidence in the asset is reflected
in a range of premia, it raises the premium one-for-one. Put together, models
of ambiguity aversion hold promise for resolving the equity premium and excess


                                           38
volatility puzzles, especially if the distinction between consumption and dividends
is made explicit.

3.2.1. Amplification
With multiple-priors preferences, prices may depend very strongly — in fact dis-
continuously — on fundamentals that change the representative agent’s portfolio.
This is the flip side of the portfolio inertia discussed in 3.1.2, which says that
portfolios may not respond to small changes in prices. To illustrate, consider a
family of models for the growth of stock payoﬀs similar to that used for returns
above: let  = ̄ + ( − 1) and 2 = ̄2 + 2, where  ∈ [0 ̄] is ambiguous
and  ∈ (0 1) is fixed. Intuitively, the agent believes that high growth goes along
with high volatility.23 The mean consumption growth now depends on  via the
term (1 − ) and the worst case is  = 0 if    and  = ̄ if   . If
dividends make up a small part of consumption, agents fear low growth. As the
share of dividends increases, concern with high risk eventually dominates.
   The interest rate takes the form
                                                   1
                                = − log  + ̄ −  2  2 − ̄
                                                   2
where  = 1 if   ,  = 0 if    and  ∈ [0 1] if  = . Viewed as a function
of , the interest rate thus has a discontinuity at the point  = . A small change
in fundamentals — here the share of stock payoﬀs in wealth — can thus have a large
eﬀect on asset prices. Intuitively, a small drop in the share of stock payoﬀs in
wealth redirects agents’ concern from high risk to low growth. This results in a
jump in interest rates (and thus a crash in asset prices).

3.2.2. The cross section of returns and idiosyncratic ambiguity
To examine the cross section of stock returns, assume there is no labor income,
but that the consumption claim consists of  trees of the same size with i.i.d.
lognormal dividend growth rates with mean  and variance 2 . Consumption
growth is thus
                                       µ         ¶
                                   1X         1 2    1
                              ∆ ≈       ∆ +   − 2 
                                    =1      2     2
 23
      While the log growth rate is decreasing in , the adjusted growth rate  + 12 2 is increasing.


                                                  39
Assume that dividend growth rates are perceived as ambiguous but indepen-
dent: the vector of means  is drawn from a Cartesian product of intervals
[̄ − ̄  ̄ + ̄ ]  While the center of the interval is the same for all trees, the
agent view some trees as more ambiguous than others.
     In equilibrium, tree prices  and the interest rate are determined so that the
agent is willing to hold all trees. With a true dividend growth rate ∗ = ̄ for all
trees, similar algebra as above delivers an interest rate and measured stock premia
                                                              1      1X          1
                                       = − log  + ̄ +  2 −         ̄ − 2
                                                              2                2
        ∗                          1 2       1 2
       − log (  ) −  +   =             + ̄ .
                                    2          
As the number of trees increases, the eﬀects of risk on asset prices vanish. Indeed,
both the precautionary savings term in the interest rate and the risk premium on
a tree — the covariance of the tree return with consumption growth — go to zero.
In contrast, the ambiguity premium does not depend on the number of stocks —
it depends only on the ambiguity perceived about an individual stock.

3.2.3. Literature notes: representative agent pricing
Epstein & Wang (1994, 1995) first studied representative agent asset pricing with
multiple-priors in discrete time and pointed out the possibility of amplification and
price indeterminacy. Chen & Epstein (2002) characterize pricing in continuous
time. Sbuelz & Trojani (2008) derive pricing formulas with entropy-constrained
priors. Gagliardini et al. (2008) show how to apply detection probabilities in a MP
setting. Epstein & Schneider (2008) consider the eﬀect of learning, with a focus on
the role of signals with ambiguous precision. They show that such signals induce
an asymmetric response to news — bad news is taken more seriously than good news
— and contribute to premia for idiosyncratic volatility as well as negative skewness
in returns.24 Illeditsch (2009) shows how learning from ambiguous signals can give
rise to amplification particularly in times when bad news arrives.
    Another key property of ambiguous signals is that the anticipation of poor
signal quality lowers utility. As a result, a shock that lowers the quality of future
signals can lower asset prices. In contrast, in a Bayesian setting the anticipation
of less precise future signals does not change utility or prices as long as the distri-
bution of payoﬀs has not changed. Epstein & Schneider (2008) use a quantitative
  24
    Williams (2009) provides evidence that in times of greater uncertainty in the stock market
the reaction to earnings announcements is more asymmetric.

                                             40
model to attribute some of the price drop after 9/11 to the discomfort market
participants felt because they had to process unfamiliar signals.25
    There are now a number of quantitative studies that apply the recursive
multiple-priors model to diﬀerent asset markets. Trojani & Vanini (2002) revisit
the equity premium puzzle. Sbuelz and Trojani (2008) consider predictability of
excess stock returns. Jeong et al. (2009) estimate a model of stock returns, also
with an emphasis on time variation in equity premia. Drechsler (2008) studies the
joint behavior of equity returns and option prices.26 Ilut (2009) addresses the un-
covered interest parity puzzle in foreign exchange markets using a model of regime
switching under ambiguity. Gagliardini et al. (2008) and Ulrich (2009) consider
the term structure of interest rates, focusing on ambiguity about real shocks and
monetary policy, respectively. Boyarchenko (2009) studies credit risk in corporate
bonds.
    There is also a growing literature on quantitative asset pricing with smooth
models. Barillas et al. (2009) use multiplier preferences to reinterpret the equity
premium results found by Tallarini (2000) in a model with Epstein-Zin utility.
Hansen & Sargent (2009) and Chen et al. (2009) consider the behavior of stock
returns in models with learning about hidden states, using multiplier and KMM
utility, respectively. Kleschinski & Vincent (2009) study the real term structure
in a model with robustness. Liu et al. (2005) consider the smirk in option premia.


3.2.4. Literature notes: heterogeneous agent models
Recent work has explored heterogeneous agent models where some agents have
multiple-priors. Epstein & Miao (2003) consider an equilibrium model in which
greater ambiguity about foreign as opposed to domestic securities leads to a home-
bias. Several models center on portfolio inertia as discussed above. Mukerji &
Tallon (2001) show that ambiguity can endogenously generate an incomplete mar-
ket structure. Intuitively, if ambiguity is specific to the payoﬀ on a security, as in
3.1.3 above, then no agent may be willing to take positions in a security with suf-
  25
     There is a related literature on “information uncertainty” in accounting. For example,
Autore et al. (2009) consider the failure of Arthur Anderson as an increase in (firm-specific)
ambiguity about AA’s clients and document how the price eﬀect of this shock depended on the
availability of firm-specific information.
  26
     Both Jeong et al. and Drechsler use a general specification of RMP with separate parameters
for risk aversion and substitution as in Epstein & Zin (1989) and thus allow for the interaction
of ambiguity and “long run risk”.


                                              41
ficiently ambiguous payoﬀs. Mukerji & Tallon (2004) build on this idea to explain
the scarcity of indexed debt contracts with ambiguity in relative prices. Easley &
O’Hara (2009) consider the welfare eﬀects of financial market regulation in models
where multiple-priors agents choose in which markets to participate.
     A shock to the economy that suddenly increases ambiguity perceived by market
participants can drive widespread withdrawal from markets, that is, a “freeze”.
This is why the multiple-priors model has been used to capture the increase in
uncertainty during financial crises (Caballero & Krishnamurthy 2008, Caballero
& Simsek 2009, Guidolin & Rinaldi 2009, Routledge & Zin 2009). Uhlig (2009)
considers the role of ambiguity aversion in generating bank runs.
     In heterogeneous agent models, prices generally depend on the entire distrib-
ution of preferences. An important point here is that if only some agents become
more ambiguity averse, this may not increase premia observed in the market. The
reason is that the more ambiguity averse group might leave the market altogether,
leaving the less ambiguity averse agents driving prices (Trojani and Vanini 2004,
Cao et al. 2005, Chapman & Polkovnichenko 2009, Ui 2009). Condie (2010) con-
siders conditions under which ambiguity averse agents aﬀect prices in the long run
if they interact with SEU agents.
     A number of papers have recently studied setups with ambiguity averse traders
and asymmetric information. Condie & Ganguli (2009) show that if an ambiguity
averse investor has private information, then portfolio inertia (as in 3.1.2) can
prevent the revelation of information by prices even if there is the same number of
uncertain fundamentals and prices. Ozsoylev & Werner (2009) and Caskey (2009)
study the response of prices to shocks when ambiguity averse agents interact with
SEU traders and noise traders. Mele & Sangiorgi (2009) focus on the incentives
for information acquisition in markets under ambiguity.


A. Appendix
We provide the details supporting our discussion in Section 2.2.2 regarding the
KMM model and our thought experiment concerning updating.
   The state space is Ω = {  }, corresponding to the possible colors of the ball
on any single draw. The parameter space is {( ) :  =   , and  = 2 6}.
The prior  can be viewed as a probability measure on pairs ( ). Let  be
uniform over the four possibilities. Define the likelihoods  ( |  ) by (2.24).
   A bet on  pays oﬀ either 100 or 0. Without loss of generality, normalize  so

                                        42
that  (100) = 1 and  (0) = 0. Then ex ante utility for the bet on drawing black
from the ambiguous urn is given by (where  denotes also the act corresponding
to the bet on black)
        () = Σ  ( ) (( |  )
             =  ( 2) ( 23 ) +  ( 2) ( 13 ) +  ( 6) ( 47 ) +  ( 6) ( 37 ).
For the risky urn, with winning prize  = ,
                             ¡                ¢   ¡ ¢
                    () =   12 35 +  12 52 =   12 =  ( ) .
Thus ex ante indiﬀerence for between the two bets is satisfied if and only if
               ¡ ¢
               12                                                                   (A.1)
         =  ( 2) ( 23 ) +  ( 2) ( 13 ) +  ( 6) ( 47 ) +  ( 6) ( 37 ).
By symmetry of the situation, the same  works also for bets on  .
   Next consider bets ex post, after observing a black ball on a single draw each
from both the ambiguous and risky urns. For the risky urn, the posterior of a
black coin-ball is 35 , and posterior predictive probability of drawing black on the
next draw is                           ¡ ¢ 2 ¡ 2 ¢ 13
                                   3 3
                                1 = 5 5 + 5 5 = 25 .

Therefore, given the winning prize , bets on black and white balls being drawn
next have, respectively, the conditional utilities
                                   ¡    ¢      ¡ ¡ 13 ¢¢
                      1 () =   1 =   25         , and
                                  ¡ ¡         ¢¢      ¡ ¡ ¢¢
                     1 ( ) =   1 −   1     =   12 25
                                                               .
   Turn to the ambiguous urn. Let 1 denote the Bayesian update of , and 1
the corresponding utility function. Then
      1 () = 1 ( 2) ( 23 ) + 1 ( 2) ( 13 ) + 1 ( 6) ( 47 ) + 1 ( 6) ( 37 ),
and
      1 ( ) = 1 ( 2) ( 13 ) + 1 ( 2) ( 23 ) + 1 ( 6) ( 37 ) + 1 ( 6) ( 47 ).
If, as in the intuitive behavior pointed to in the thought experiment, each bet is
less preferred to the corresponding bet on the risky urn, then
                                                                                    ¡ ¡ ¢¢
   1 ( 2) ( 23 ) + 1 ( 2) ( 13 ) + 1 ( 6) ( 47 ) + 1 ( 6) ( 37 )    13
                                                                                       25
                                                                                           ,

                                                43
and
                                                                                      ¡ ¡ ¢¢
     1 ( 2) ( 13 ) + 1 ( 2) ( 23 ) + 1 ( 6) ( 37 ) + 1 ( 6) ( 47 )    12
                                                                                         25
                                                                                             .

Add to obtain,
          ¡                 ¢            ¡                 ¢    ¡ ¡ ¢¢      ¡ ¡ ¢¢
1 ( = 2) ( 23 ) + ( 13 ) + 1 ( = 6) ( 47 ) + ( 37 )    13 25
                                                                         +   12
                                                                               25
                                                                 ¡ ¢
                                                             ≤ 2  12 .

Therefore, by (A.1),
                1
                             ¡                 ¢               ¡                 ¢
                  
                2 1
                      ( = 2) ( 23 ) + ( 13 ) + 12 1 ( = 6) ( 47 ) + ( 37 ) 

               ( 2) ( 23 ) +  ( 2) ( 13 ) +  ( 6) ( 47 ) +  ( 6) ( 37 ),
or                           ¡                 ¢               ¡                 ¢
                1
                  
                2 1
                      ( = 2) ( 23 ) + ( 13 ) + 12 1 ( = 6) ( 47 ) + ( 37 )         (A.2)
 ( 2) ( 23 )+[ ( = 2)− ( 2)]( 13 )+ ( 6) ( 47 )+[ ( = 6)− ( 6)]( 37 ).
      Since  is uniform, the posterior 1 on ( ) pairs is given by
                                         ⎧ 1
                                         ⎪
                                         ⎪       =   = 2
                                         ⎨ 31
                                            6
                                                 =   = 2
                         1 (  | ) =    2
                                         ⎪
                                         ⎪       =   = 6
                                         ⎩ 73
                                           14
                                                =   = 6,
                       1
and 1 ( = 2) =       2
                           = 1 ( = 6). Therefore, (A.2) implies the contradiction
                               ¡ 2              ¢ ¡                 ¢
                                ( 3 ) + ( 13 ) + ( 47 ) + ( 37 ) 

                                  ( 23 ) + ( 13 ) + ( 47 ) + ( 37 ).




                                                   44
References
 [1] Ahn D, Choi S, Gale D, Kariv S. 2009. Estimating ambiguity aversion in a
     portfolio choice experiment. Unpublished manuscript, Berkeley

 [2] Anderson E, Hansen LP, Sargent TJ. 2003. A quartet of semigroups for model
     specification, robustness, prices of risk and model detection. J. Europ. Econ.
     Assoc. 1: 68-123

 [3] Anscombe F, Aumann RJ. 1963. A definition of subjective probability. Ann.
     Math. Stat. 34: 199-205

 [4] Autore D, Billingsley R, Schneller M. 2009. Information uncertainty and au-
     ditor reputation, J. Banking & Finance 33: 183-92

 [5] Boyarchenko N. 2009. Ambiguity, information quality and credit risk. Un-
     published manuscript, Univ. Chicago

 [6] Baillon A, Driesen B, Wakker PP. 2009. Relative concave utility for risk and
     ambiguity. Unpublished manuscript, Maastricht Univ.

 [7] Barillas F, Hansen LP, Sargent TJ. 2009. Doubts or variability? J. Econ.
     Theory 144: 2388-418

 [8] Benigno P, Nistico S. 2009. International portfolio allocation under model
     uncertainty. NBER Working Paper 14734

 [9] Bossaerts P, Ghirardato P, Guarnaschelli S, Zame WR. 2010. Ambiguity in
     asset markets: theory and experiment. Rev. Finan. Stud. 23: 1325-59

[10] Caballero R, Krishnamurthy A. 2008. Collective risk management in a flight
     to quality episode. J. Finance 63: 2195-230

[11] Caballero R, Simsek A. 2009. Fire sales in a model of complexity. Unpublished
     manuscript, MIT

[12] Campanale C. 2010. Learning, ambiguity and life-cycle portfolio allocation.
     Rev. Econ. Dyn. In press

[13] Campbell J, Viceira L. 1999. Consumption and portfolio decisions when ex-
     pected returns are time varying. Quart. J Econ. 114: 433-95


                                        45
[14] Cao HH, Wang T, Zhang, HH. 2005. Model uncertainty, limited market par-
     ticipation, and asset prices. Rev. Finan. Stud. 18: 1219 - 51

[15] Cao HH, Han B, Zhang HH, Hirshleifer D. 2007. Familiarity and fear of the
     unknown, Unpublished manuscript, UNC

[16] Caskey J. 2009. Information in equity markets with ambiguity averse in-
     vestors. Rev. Fin. Studies 22: 3595-3627

[17] Chapman D, Polkovnichenko V. 2009: First-order risk aversion, heterogeneity
     and asset market outcomes. J. Finance 64: 1863-1887

[18] Chen Z, Epstein LG. 2002. Ambiguity, risk and asset returns in continuous
     time. Econometrica 70: 1403-43

[19] Chen H., Ju N, Miao J. 2009. Dynamic asset allocation with ambiguous return
     predictability. Unpublished manuscript, Boston Univ.

[20] Condie S. 2010: Living with ambiguity: prices and survival when investors
     have heterogeneous preferences for ambiguity. Econ Theory In press

[21] Condie S, Ganguli J. 2009. Ambiguity and partially-revealing rational expec-
     tations equilibria. Unpublished manuscript, U. Cambridge

[22] Dow J, Werlang SR. 1992. Uncertainty aversion, risk aversion and the optimal
     choice of portfolio. Econometrica 60: 197-204

[23] Drechsler I. 2008. Uncertainty, time-varying fear, and asset prices. Unpub-
     lished manuscript, Stern School of Business, New York Univ.

[24] Duﬃe D, Epstein LG. 1992. Stochastic diﬀerential utility. Econometrica 60:
     353-94 (Appendix C with Skiadas)

[25] Dupuis P, Ellis RS. 1997. A Weak Convergence Approach to the Theory of
     Large Deviations. New York: Wiley

[26] Easley D, O’Hara M. 2009. Ambiguity and nonparticipation: the role of
     regulation. Rev. Finan. Stud. 22: 1817-43

[27] Ellsberg D. 1961. Risk, ambiguity and the Savage axioms. Quart. J. Econ.
     75: 643-69


                                       46
[28] Epstein LG. 2010. Three paradoxes for the “smooth ambiguity” model of
     preference. Unpublished manuscript, Boston Univ.

[29] Epstein LG, Miao J. 2003. A two-person dynamic equilibrium under ambi-
     guity. J. Econ. Dyn. Control 27: 1253-1288

[30] Epstein LG, Schneider M. 2003. Recursive multiple-priors. J. Econ. Theory
     113: 1-31

[31] Epstein LG, Schneider M. 2007. Learning under ambiguity. Rev. Econ. Stud.
     74: 1275-303

[32] Epstein LG, Schneider M. 2008. Ambiguity, information quality and asset
     pricing. J. Finance 63: 197-228

[33] Epstein LG, Wang T. 1994. Intertemporal asset pricing under Knightian un-
     certainty. Econometrica 62: 283-322

[34] Epstein LG, Wang T. 1995. Uncertainty, risk-neutral measures and security
     price booms and crashes. J. Econ. Theory 67: 40-82

[35] Epstein LG, Zin S. 1989. Substitution, risk aversion and the temporal behav-
     ior of consumption and asset returns: a theoretical framework. Econometrica
     57: 937-69

[36] Gagliardini P, Porchia P, Trojani F. 2009. Ambiguity aversion and the term
     structure of interest rates. Rev. Finan. Stud. 22: 4157-88

[37] Gajdos T, Hayashi T, Talon JM, Vergnaud JC. 2008. Attitude towards im-
     precise information. J. Econ. Theory 140: 27-65

[38] Garlappi L, Uppal R, Wang T. 2007. Portfolio selection with parameter and
     model uncertainty: a multi-prior approach. Rev. Finan. Stud. 20: 41-81

[39] Gilboa I, Schmeidler D. 1989. Maxmin expected utility with non-unique pri-
     ors. J. Math. Econ. 18: 141-53

[40] Guidolin M, Rinaldi F. 2009. A simple model of trading and pricing risky
     assets under ambiguity: any lessons for policy makers. Unpublished manu-
     script, FRB St. Louis



                                       47
[41] Halevy Y, Ozdenoren E. 2008. Ambiguity and compound lotteries: calibra-
     tion. Unpublished manuscript, Univ. British Columbia

[42] Hansen LP. 2007. Beliefs, doubts and learning: valuing macroeconomic risk.
     Amer. Econ. Rev. 97: 1-30

[43] Hansen LP, Sargent TJ. 2001. Robust control and model uncertainty. Amer.
     Econ. Rev. 91: 60-6

[44] Hansen LP, Sargent TJ. 2007. Recursive robust estimation and control with-
     out commitment. J. Econ. Theory 136: 1-27

[45] Hansen LP, Sargent TJ. 2009. Fragile beliefs and the price of uncertainty.
     Unpublished manuscript, Univ. Chicago

[46] Hayashi T. 2005. Intertemporal substitution, risk aversion and ambiguity
     aversion. Econ. Theory 25: 933-956

[47] Huber PJ. 1981. Robust Statistics. New York: Wiley

[48] Illeditsch P. 2009. Ambiguous information, risk aversion and asset pricing.
     Unpublished manuscript, Wharton

[49] Ilut CL. 2009: Ambiguity aversion: implications for the uncovered interest
     rate parity puzzle. Unpublished manuscript, Duke Univ.

[50] Jeong D, Kim H, Park Y. 2009. Does ambiguity matter? estimating asset
     pricing models with multiple-priors recursive utility. Unpublished manuscript,
     Texas A&M

[51] Ju N, Miao J. 2009. Ambiguity, learning and asset returns. Unpublished man-
     uscript, Boston Univ.

[52] Kleschelski I, Vincent N. 2009. Robust equilibrium yield curves. Unpublished
     manuscript, Washington Univ.

[53] Klibanoﬀ P, Marinacci M, Mukerji S. 2005. A smooth model of decision mak-
     ing under ambiguity. Econometrica 73: 1849-92

[54] Klibanoﬀ P, Marinacci M, Mukerji S. 2009. Recursive smooth ambiguity pref-
     erences. J. Econ. Theory 144: 930-76


                                        48
[55] Kopylov I. 2009. Choice deferral and ambiguity aversion. Theor. Econ. 4:
     199-225

[56] Liu J, Pan J, Wang T. 2005: An equilibrium model of rare-event premia and
     its implication for option smirks. Rev. Finan. Stud. 18: 131-64

[57] Maccheroni F, Marinacci M, Rustichini A. 2006a. Ambiguity aversion, malev-
     olent nature, and the variational representation of preferences. Econometrica
     74: 1447-98

[58] Maccheroni F, Marinacci M, Rustichini A. 2006b. Dynamic variational pref-
     erences. J. Econ. Theory 128: 399-424

[59] Mele A, Sangiorgi F. 2009. Ambiguity, information acquisition and price
     swings in asset markets. Unpublished manuscript, LSE

[60] Miao J. 2009: Ambiguity, risk and portfolio choice under incomplete infor-
     mation. Annals Econ. and Finance 10: 257-79

[61] Mukerji S, Tallon JM. 2001. Ambiguity aversion and incompleteness of finan-
     cial markets, Rev. Econ. Stud. 68: 883-904

[62] Mukerji S, Tallon JM. 2003. Ellsberg 2-color experiment, portfolio inertia and
     ambiguity. J. Math Econ. 39: 299-316.

[63] Mukerji S, Tallon JM. 2004. Ambiguity aversion and the absence of indexed
     debt. Econ. Theory 24: 665-685

[64] Ozsoylev H, Werner J. 2009. Liquidity and asset prices in rational expecta-
     tions equilibrium with ambiguous information, Unpublished manuscript, U.
     Minnesota

[65] Routledge B, Zin S. 2009. Model uncertainty and liquidity. Rev. Econ. Dyn.
     12: 543-66

[66] Sbuelz A, Trojani F. 2008. Asset prices with locally-constrained-entropy re-
     cursive multiple-priors utility. J. Econ. Dyn. Control 32: 3695-717

[67] Schmeidler D. 1989. Subjective probability and expected utility without ad-
     ditivity. Econometrica 57: 571-87



                                        49
[68] Schroder M, Skiadas C. 1999. Optimal consumption and portfolio selection
     with stochastic diﬀerential utility. J. Econ. Theory 89: 68-126

[69] Seo K. 2009. Ambiguity and second-order belief. Econometrica 77: 1575-605

[70] Skiadas C. 2003. Robust control and recursive utility. Fin. and Stochast. 7:
     475-89

[71] Skiadas C. 2008. Dynamic porfolio choice and risk aversion. In Financial En-
     gineering, Vol. 15, ed. JR Birge, V Linetsky, pp. 789-843. New York, Elsevier

[72] Skiadas C. 2009a. Asset Pricing Theory. Princeton, NJ: Princeton Univ. Press

[73] Skiadas C. 2009b. Smooth ambiguity aversion toward small risks and
     continuous-time recursive utility. Unpublished manuscript, Kellogg School,
     Northwestern Univ.

[74] Strzalecki T. 2007. Axiomatic foundations of multiplier preferences. Unpub-
     lished manuscript, Harvard Univ.

[75] Tallarini TD. 2000. Risk-sensitive business cycles. J. Monet. Econ. 45: 507-
     532

[76] Trojani F, Vanini P. 2002. A note on robustness in Merton’s model of in-
     tertemporal consumption and portfolio choice. J. Econ. Dyn. Control 26:
     423-35

[77] Trojani F, Vanini P. 2004. Robustness and ambiguity aversion in general
     equilibrium. Rev. Finan. 8: 279-324

[78] Uhlig H. 2009. A model of a systemic bank run. Unpublished manuscript, U.
     Chicago

[79] Ui, Takashi. 2009. The ambiguity premium vs the risk premium under limited
     market participation, Unpublished manuscript, Yokohama Natl.Univ.

[80] Ulrich M. 2009. Inflation ambiguity and the term structure of arbitrage-free
     U.S. government bonds. Unpublished manuscript, Columbia Univ.

[81] Uppal R, Wang T. 2003. Model misspecification and underdiversification. J.
     Finance 58: 2465-86


                                       50
[82] Vissing-Jorgensen A. 2003. Perspectives on behavioral finance: does "irra-
     tionality" disappear with wealth? evidence from expectations and actions.
     NBER Macroeconomics Annual

[83] Williams C. 2009. Asymmetric responses to good and bad news: an empirical
     case for ambiguity. Unpublished manuscript, U. Michigan




                                      51
