I.     Introduction

       Academic thinking about monetary economics—as well as macroeconomics more

generally—has altered drastically since 1971-1973 and so has the practice of monetary

policy. The former has passed through the rational expectations and real-business-cycle

revolutions into today’s “new neoclassical synthesis” whereas policymaking has

rebounded, after a bad decade following the breakdown of the Bretton Woods system,

into an era of low inflation that emphasizes the concepts of central bank independence,

transparency, and accountability while exhibiting substantial interest in the consideration

of alternative rules for the conduct of monetary policy.1

       My assignment in this paper is to consider the roles of economic theory and

empirical evidence in bringing about these changes—in particular, changes in policy

formulation. Have they been driven primarily by theoretical reasoning or by accumulated

evidence? As a related matter, has the evolution reflected health or sickness in the

macro-monetary branch of economic science?

       In discussing actual monetary policymaking, there is a difficulty stemming from

the possibility that in practice policy choices are dominated by responses to current

political pressures, with economic reasoning of any form playing a strictly subordinate

role in the thought processes of voting members of policy-making bodies such as the

United States Federal Open Market Committee. There is reason to believe, however, that

economic analysis has been playing an increasing role in monetary policy considerations

and, in any event, there would be little for economists to discuss if we were to conclude

that actual policy is independent of such analysis. Consequently, most of the discussion

below will take writings of central bank economists, together with official publications




                                             1
such as inflation reports, as providing some indication of actual monetary policy

practices.

       Also, it should be admitted at the outset that evaluation of the relative

contributions of theory and evidence is extremely difficult. In fact, a proper quantitative

evaluation is probably impossible, since economic science evolves by way of a

complicated back-and forth interaction of theoretical and empirical considerations.

Moreover, these considerations are often combined in the work of a single analyst; for

example, most of the researchers listed below in Table 1 rely on such a combination in

their own work. Consequently, some of this back-and-forth takes place within the minds

of individual researchers and thus may not show up at all in the exposition of papers

written to report results. Under such circumstances, it is clear that measurement of the

relative contributions of theory and evidence must be highly problematic, at best.

Accordingly, what is presented in this paper might be regarded more as a number of

observations relevant to the issue, rather than as an actual evaluation. My hope is that

these observations will shed some light on the evolution of monetary analysis while

establishing that both theory and evidence have played important roles.

       The outline of the paper is as follows. In Section 2, general analytic trends in

macroeconomics will be briefly outlined as a background. Then Section 3 takes up the

evolution of monetary policymaking in practice and Section 4 does the same for the

formal analysis of monetary policy. Section 5 treats a special topic and Section 6

concludes.




                                             2
2.     Trends in Macroeconomics, 1973-1998

       The years 1971-1973 make a good starting point for our discussion because they

mark sharp breaks in both macroeconomic thinking and in institutional arrangements

relevant to the conduct of monetary policy. In terms of institutions, of course I have in

mind the breakdown of the Bretton Woods exchange rate system, which was catalyzed by

the United States’s decision of August 1971 not to supply gold to other nations’ central

banks at $35 per ounce. This abandonment of the system’s nominal anchor naturally led

other nations to be unwilling to continue to peg their currency values to the (overvalued)

U.S. dollar, so the par value exchange-rate agreements disintegrated. New par values

were painfully established in the December 1971 meeting at the Smithsonian Institution,

but after a new crisis in February 1973 the par-value system crumbled in March 1973 and

has not been reassembled as of 1998.2

       In terms of macroeconomics, the years 1971-1973 featured the publication of six

papers that initiated the rational expectations revolution. The most celebrated of these,

certainly, is Lucas’s (1972a) “Expectations and the Neutrality of Money,” but his (1972b)

and (1973) were also extremely influential as were Sargent’s (1971) and (1973).

Curiously, however, the first publication to use rational expectations in a macro-monetary

analysis was none of these but rather Walters (1971), which has apparently had almost no

influence.3

       At first there was much resistance to the hypothesis of rational expectations,

partly because in macroeconomics it was initially associated rather strongly with the

policy-ineffectiveness proposition.4 There were also several other misconceptions, one of

which continues today in the argument that it is implausible that all of an economy’s




                                             3
agents would believe in the particular model of the economy being used by the analyst.5

Actually, that is not the assumption required for rational expectations. The latter

presumes instead that agents form expectations so as to avoid systematic expectational

errors in actuality, which implies that they behave as if they knew the structure of the

actual economy. Then expectations will agree with the analyst’s model of the economy,

but the reason is that this model is by construction the analyst’s best attempt to depict the

true structure of the economy (otherwise, he/she would use a different model).

          Be that as it may, the hypothesis of rational expectations (RE) gradually swept the

field in both macroeconomics and microeconomics, a major reason being that it is almost

certainly unwise for policy to be conducted under the presumption that any particular

pattern of expectational errors will prevail in the future—and ruling out all such patterns

implies that expectational errors are orthogonal to information sets (i.e., implies rational

expectations). During the late 1970s there was much interest in alternative specifications

of price adjustment behavior, since with RE some but not all forms of price adjustment

behavior will lead to policy ineffectiveness. Around 1980, however, such research

virtually ceased (which is not to say that work with models including slow price

adjustments—e.g., Taylor (1989)—ceased). Other topics involving consumption/saving

and labor supply behavior became popular for a while, notable contributions including

Hall (1978), Hansen and Singleton (1982), and Mankiw, Rotemberg, and Summers

(1985).

          Then shortly following the appearance of Kydland and Prescott (1982), the era of

real-business-cycle (RBC) analysis began.6 For the next dozen years, a large fraction of

all research by leading macroeconomic analysts involved RBC reasoning or issues in one




                                               4
way or another, pro or con.7 In standard RBC analysis it is assumed that price

adjustments take place very quickly so that, for practical purposes, there is continuous

market clearing for all commodities—including labor—in which case monetary policy

actions will in most models have little or no effect on real macroeconomic variables at

cyclical frequencies. Typically, moreover, the RBC models imply that cyclical

fluctuations that are observed in real variables are the consequence of technology shocks,

not real shocks to preferences or government fiscal variables. Now, of course this has

been a highly controversial hypothesis and I am on record as finding it quite dubious

(McCallum, 1986, 1989). But it would be wrong to be altogether negative about RBC

analysis because much of it has been devoted to the development of new tools of

theoretical and empirical analysis, tools that can be employed without any necessary

adherence to the RBC hypothesis about the source of cyclical fluctuations.

       In recent years, moreover, these tools have been applied in precisely this fashion.

Thus a major movement has been underway to construct, estimate, and simulate models

in which agents are depicted as solving dynamic optimization problems and interacting

on competitive—or, more often, monopolistically competitive—markets, but with some

elements of nominal price or wage “stickiness” built into the structure. The match

between these models and actual data is then investigated, often by quasi-RBC

procedures, for both real and nominal variables and their interaction. Thus the objective

of this line of work is to combine the theoretical discipline of RBC analysis with the

greater empirical veracity made possible by the assumption that nominal prices do not

adjust instantaneously.8 Basically, the attempt is to develop a model that is truly




                                             5
structural, and therefore immune to the Lucas (1976) critique of econometric policy

analysis.

        The mere description of these developments in macroeconomics makes it

apparent that they have been driven by a combination of theoretical and empirical

impulses. The rational expectations onslaught was primarily theoretical in origin,

building upon recognition of the fact that all other expectational hypotheses permit

systematic (hence correctable) expectational errors. But the logical basis for the upsurge

of the RBC movement can be viewed as principally empirical.9 Here the point is that

RBC models are in essence equilibrium business cycle models of the type promoted by

Lucas (1972a, 1975) but with the monetary shocks eliminated and technology shocks

emphasized. And this change in emphasis came about, it can be argued, largely because

empirical analysis of various types suggested that the cyclical real effects of monetary

policy shocks were in fact very small in relation to the overall variability of output and

employment. Some crucial studies providing such evidence were Sims (1980), Litterman

and Weiss (1989), Eichenbaum and Singleton (1986), and Nelson and Plosser (1982).10

        Then there came the more recent movement to incorporate gradual price

adjustment—“sticky prices” — into optimizing macro models. By its very nature, the

impetus for this movement must have been mainly empirical. For there is no body of

theory that tells us that price behavior is sticky; to the contrary it is rather difficult to

incorporate sticky prices in a model that stresses optimizing general equilibrium theory. 11

Thus it has to be the force of evidence that has brought about this important change.

Moreover, I think it is only fair to recognize that the RBC movement has itself been




                                                6
strongly concerned with empirical veracity, even though in that regard its preferred

measures have been quite different from those used in orthodox time series econometrics.

       With respect to these measures a few brief words may be appropriate before we

move on. The “standard” set of RBC measures was established in the famous Kydland-

Prescott (1982) paper, which focused on three sets of second moments for variables that

had been “detrended.” These were: (i) variances of important real variables including

output, labor input, average labor productivity, consumption, investment, and capital; (ii)

correlations with output of the other variables listed in (i); and (iii) autocorrelations and,

to a lesser extent, lead and lag correlations with output.12 Thus the RBC empirical

verification program has been to assess the conformity of these measures as generated by

RBC models with actual values pertaining to quarterly data for the USA and other

economies.

       It has been argued by many analysts that these measures provide an inadequate

basis for judging the veracity of a macroeconomic model. One problem is that a model

may match the data nicely according to the second-moment measurers (i), (ii), and (iii)

and yet fail dramatically to fit the data in other respects, as illustrated by Altug (1989)

and Watson (1993). In this regard there now exists a sizeable literature on the topic of

“calibration vs. estimation.”13 A different type of concern is that the production function

residuals (e.g., Prescott, 1986), on which the RBC analysis relies, may not be measures of

technology shocks at all, but may instead reflect primarily phenomena of an entirely

different origin. Some evidence pointing rather strongly in that direction has been

presented by Evans (1992), Basu (1996), and Gali (1997). Also, Cogley and Nason

(1995) and others have shown that the dynamic properties of typical RBC models come




                                               7
almost entirely from the properties of the stochastic process assumed to generate the

technology shocks, rather than from the modeled behavior of agents.

3.     Developments in Monetary Policy

       The 1971-73 collapse of the Bretton Woods system created, for the first time in

history, a situation in which the world’s leading central banks were responsible for

conducting monetary policy without an externally-imposed monetary standard (often

termed a “nominal anchor”). Previously, central banks had normally operated under the

constraint of some metallic standard (e.g., a gold or silver standard), with wartime

departures being understood to be temporary, i.e., of limited duration. Some readers

might not think of the Bretton Woods system as one incorporating a metallic standard,

but by design it certainly was, since the values of all other currencies were pegged to the

U.S. dollar and the latter was pegged to gold at $35 per ounce.14 In practice, United

States officials—Treasury and Federal Reserve—did not treat the $35/oz standard as if it

were a constraint. This was possible initially because the large devaluation of the dollar

relative to gold in 1933-34 had left the dollar undervalued, so several years of postwar

inflation could therefore take place before the dollar became overvalued relative to

gold—i.e., until the free market dollar price of gold began to significantly exceed $35/oz.

But the effects of these years of mild inflation did gradually accumulate and by 1961 the

market price of gold had risen (the value of the dollar had fallen) to about $35/oz.

Various patch-up attempts were made to permit the U.S. to continue to conduct policy

without conforming to the requirements of the official standard, but another 10 years of

slow but steady U.S. inflation generated an unsustainable position—so the system

collapsed.




                                             8
       Faced with the responsibility of establishing a monetary standard of their own

design, the world’s central banks did not perform well at first and inflation reached levels

that were unprecedented for a sustained period without any widespread war. Germany

and Japan began to get inflation under control by the middle 1970s but it remained high

in the other G-7 nations. In the U.S. and the U.K. there was a tendency for central banks

to deny that their own behavior was an essential ingredient to the inflation process15 and

considerable importance was attached by central banks to employment, output, and other

real macroeconomic objectives. The exact nature of central bank thinking during these

years is a matter of dispute,16 but I am myself inclined to share the judgment of Taylor

(1996), who depicts central bankers as acting under the influence of 1960s academic

ideas that posited the existence of a long-run and exploitable Phillips-type tradeoff

between inflation and unemployment rates. 17

       During the 1970s, there was considerable discussion of policy regimes featuring

money growth targets. In Germany, the Bundesbank adopted a monetary targeting

strategy that has, with some modifications, been officially employed ever since. The

other large-nation central bank that was most successful in avoiding inflation in the late

1970s and 1980s, the Bank of Japan, also apparently gave some emphasis to monetary

targets (although in this case the extent of dedication to this strategy was apparently

smaller). In the United States, monetary growth targets were given official status by the

Humphrey-Hawkins Act of 1975, but evidently played a rather small role in actual

policymaking until October 1979. 18 Then on October 6 the Fed began its so-called

“monetarist experiment,” i.e., the period (ending in July 1982) during which M1 targets

were actively pursued by means of a new operating procedure that featured a




                                              9
nonborrowed reserves instrument. Interest rates quickly rose dramatically, but the effort

foundered during 1980 as a result of the selective credit controls that were imposed and

then quickly removed. Finally, a period of genuine monetary stringency was begun at the

end of 1980 and maintained until the middle of 1982. In response, inflation fell quite

rapidly—as did output and employment.19

       From 1983 until 1990, U.S. inflation fluctuated gently around a midpoint of about

4 or 4.5 percent per year. A monetary tightening during 1989 interacted with the Persian

Gulf oil crisis of 1990 to begin another recession that was mild but lengthy. By late

1992, U.S. inflation had declined further to the 2-3 percent range that has persisted since.

Whether the Fed was deliberately seeking a reduction in the trend inflation rate during

1989-1990 is a matter of some dispute.

       In terms of operating procedures, the Fed gradually reverted after August 1982 to

a scheme that centers on the Federal funds rate as its instrument (or “operating target”).

In addition, interest rates have come to receive more attention—via the term structure but

also long-term rates in an unaugmented state—as indicators of monetary conditions.

Thus monetary aggregate growth rates have been downgraded in policymaking

significance to the point that the biannual congressional hearings, because they

legislatively require reference to these figures, always include a few minutes of distinct

awkwardness in the Fed’s testimony.

       Outside the USA, a major development has been the emergence of the European

Monetary Union. Partly because of the so-called convergence criteria needed to qualify

for participation in the single-currency Euro scheme, to be guided by the ECB (European




                                             10
Central Bank), inflation rates across Europe have fallen remarkably, averaging close to

1.0 percent for the most recent years (1996-98).

       Also highly noteworthy has been the arrival of inflation targeting as a new

framework for the conduct of monetary policy. Actually, most central banks, among

those that are not constrained by formal exchange rate commitments, do not adhere to

any clear-cut and announced procedures in conducting monetary policy. But of those that

have adopted explicit policy frameworks, virtually all have opted for targets expressed in

terms of inflation rates, not money stock or nominal income growth rates. 20 Most

notable, probably, is the arrangement in New Zealand, which came first and which

stipulates that the central bank governor can be removed if the agreed-upon 0-2%

inflation target band is not met.21

       Overall, the most fundamental change since the 1970s has been the assumption of

responsibility by central banks for performance in terms of inflation rates. In 1998, it

would be extremely surprising to run across a central bank statement that discussed

medium-term inflation prospects in a manner suggesting that these are unaffected by

monetary policy behavior. So, even though we are here discussing practice and not

analysis, one could ask whether theory or evidence has been more responsible for the

change in opinion. In this regard there is a “multicollinearity problem” because, as it

happens, both theory and evidence have pointed strongly in the same direction, i.e.,

toward the proposition that there is no permanent stimulus to real variables from

monetary leniency so that sustained easy conditions will produce just inflation, without

any lasting boost to output or employment. There is of course some formal econometric

evidence in this regard, 22 but even more influential to policy makers, probably, was the




                                            11
informal perception of the 1970s as a decade of experience with high inflation

accompanied by no enhancement in terms of output and employment. Thus we have

theory, formal evidence, and informal “experimental” evidence all pointing in the same

direction—toward the idea that from a long-term perspective monetary policy’s main

influence is on growth of the price level with little or no lasting effect on real output’s

level or growth rate. From this conception it is a natural step to view inflation prevention

as the main macroeconomic duty of a modern central bank, with a secondary objective of

dampening cyclical fluctuations, and today’s general policy climate falls into place.

4.     Monetary Policy Analysis

       We now turn to the topic of central concern in this paper, analysis of monetary

policy arrangements by economists—i.e., by monetary economics specialists in

universities, central banks, and other analytical organizations. 23 In that regard it is quite

gratifying to report that in recent years there has been a large amount of interaction

between central bank and academic analysts, so that today (August 1998) one would be

hard-pressed to tell, for many research papers, whether a particular one had been written

by members of one group or the other. 24 To illustrate that point, as well as others to be

made below, it will be useful to refer to two major conferences held in the first half of

1998. The first of these is an NBER conference on “Monetary Policy Rules” held

January 15-17 in Islamorada, Florida, and the second is a Riksbank-IIES conference

“Monetary Policy Rules” held June 12-13 in Stockholm. Since the conference titles are

the same, they will be referred to below as the NBER and Riksbank conferences. The

former was organized by John B. Taylor (Stanford University), the latter by Claes Berg




                                              12
(Sveriges Riksbank) and Lars E.O. Svensson (Institute for International Economic

Studies, Stockholm University).

       Paper authors, discussants, and panelists at these two conferences are listed in

Table 1. It will be noted that there is some overlap in the lists. More importantly, it will

be noted that there is substantial participation by both academic and central bank

economists in both conferences, especially the Riksbank’s.25 To verify the similarity in

concerns and techniques exhibited by central bank and academic authors, the reader is

invited to sample the papers themselves. They are forthcoming in an NBER conference

volume and an issue of the Journal of Monetary Economics; as of August 1998 virtually

all the papers could be downloaded from NBER or IIES home pages on the world wide

web.

       The situation just described is vastly different from that obtaining as recently as

the middle 1980s, when academic and central bank economists had much less interaction

and much less similarity of viewpoint. 26 If one introspects about reasons for the change,

one can easily think of several contenders, among which are some that involve

adjustments on the part of both groups. One fact is that several (regional) Federal

Reserve Banks have, since the late 1970s, employed academic economists as consultants,

a practice that makes each group more familiar with research assumptions held to be

essential by the other—e.g., academics have become more knowledgeable about realistic

operating procedures while central bank economists have become more comfortable with

analysis utilizing rational expectations. Conferences held by Federal Reserve Banks and

some by academics (e.g., NBER and Carnegie-Rochester conferences) have brought




                                             13
                                     Table 1

               Programs for NBER and Riksbank-IIES Conferences



A.   NBER Conference, January 15-17, 1998

     1. Bennett McCallum and Edward Nelson, Carnegie Mellon Univ.,
     “Performance of Operational Policy Rules in an Estimated Semi-Classical
     Structural Model.”
     Discussant: Mark Gertler, New York Univ.

     2. Julio Rotemberg, Harvard University, and Michael Woodford, Princeton
     Univ., “Interest Rate Rules in an Estimated Sticky-Price Model.”
     Discussant: Martin Feldstein, Harvard Univ.

     3. Laurence Ball, Johns Hopkins Univ., “Policy Rules for Open Economies.”
     Discussant: Thomas Sargent, Stanford Univ.

     4. Andrew Haldane and Nicoletta Batini, Bank of England, “Forward Looking
     Rules for Monetary Policy.”
     Discussant: Donald Kohn, Federal Reserve Board

     5. Glenn Rudebusch, FRB of San Francisco, and Lars Svensson, Institute for
     International Economic Studies, “Policy Rules for Inflation Targeting.”
     Discussant: James Stock, Harvard Univ.

     6. Andrew Levin, Volcker Wieland, and John Williams, Federal Reserve Board,
     “Are Simple Monetary Rules Robust to model Uncertainty?”
     Discussant: Lawrence Christiano, Northwestern Univ.

     7. John Taylor, Stanford Univ., “An Historical analysis of Monetary Policy
     Rules,”
     Discussant: Richard Clarida, Columbia Univ.

     8. Robert King, University of Virginia, and Alexander Wolman, FRB of
     Richmond, “What Should Monetary policy Do When Prices are Sticky?”
     Discussant: Benjamin Friedman, Harvard Univ.

     9. Arturo Estrella, FRB of New York, and Frederic Mishkin, Columbia Univ.,
     “The Role of NAIRU in Monetary Policy: Implication of Uncertainty and Model
     Selection.”
     Discussant: Robert Hall, Stanford Univ.




                                        14
                                (Table 1 continued)



B.   Riksbank-IIES Conference, June 12-13, 1998

     1. Frederic Mishkin, Columbia Univ., “International Experiences with Different
     Monetary Policy Regimes.”
     Discussant: Charles Goodhart, London School of Economics and Bank of
     England

     2. John Taylor, Stanford Univ., “The Robustness and Efficiency of Monetary
     Policy Rules as Guidelines for Interest Rate Setting by the European Central
     Bank.”
     Discussant: Leonardo Leiderman, Bank of Israel

     3. Jürgen von Hagen, Mannheim Univ., “Money Growth Targeting.”
     Discussant: Stephen Cecchetti, FRB of New York

     4. Bennett McCallum and Edward Nelson, Carnegie Mellon Univ., “Nominal
     Income Targeting in an Open-Economy Optimizing Model.”
     Discussant: Glenn Rudebusch, FRB of San Francisco

     5. Dale Henderson with Christopher Erceg and Andrew Levin, Federal Reserve
     Board, “Output-Gap and Price Inflation Volatilities: Reaffirming Tradeoffs in an
     Optimizing Model.”
     Discussant: Stefan Gerlach, Bank for International Settlements

     6. Lars Svensson, IIES, “Inflation Targeting as a Monetary Policy Rule.”
     Discussant: Alan Blinder, Princeton Univ.

     7. Claes Berg, Sveriges Riksbank, and Lars Jonung, Stockholm School of
     Economics, “Pioneering Price Level Targeting: the Swedish Experience 1931-
     37.”
     Discussant: Mervyn King, Bank of England

     8. Panel Discussion
      Alan Blinder, Princeton Univ.; Donald Brash, Reserve Bank of New Zealand;
     Otmar Issing, European Central Bank; Mervyn King, Bank of England; and
     Guido Tabellini, Bocconi Univ.




                                        15
central bank and academic researchers together more often. Ph.D. graduates of leading

universities have taken positions at the Federal Reserve Board and regional Feds and

have played crucial roles in the development of Fed models and procedures. 27 The

“Economic Review” publications of Federal Reserve Banks have become more open to

articles of a nearly academic style, which has fostered increased understanding in both

directions, and more Federal Reserve Banks have encouraged their research staff

members to publish in academic publications. And there are still more channels of

communication, not as open or as regularly used during the 1960s and 1970s, that could

in principle be listed. Also, Taylor’s paper (1993) succeeded brilliantly in interesting

central bankers in the consideration of rule-guided policy making.

        The typical method for conducting monetary policy analysis in the NBER and

Riksbank conferences can be summarized as follows. An analytical macroeconomic

model is developed that includes three major components: (i) a monetary policy rule that

specifies quarterly settings for an interest rate instrument, (ii) an IS-type relation or set of

relations that specifies how interest rate changes affect aggregate demand and output, and

(iii) a price-adjustment equation or set of equations that specifies how inflation behaves

in response to output (measured relative to capacity) and expectations regarding the

future. Typically, these models feature rational expectations. They may be estimated by

various strategies including the estimation procedure termed “calibration” but, whatever

the strategy, an attempt is made by the researcher to develop a quantitative model in

which parameter values (including disturbance term variances, covariances, and

autocovariances) are consistent with actual time series data. Frequently, some effort is

taken to make the policy rule operational, i.e., one that is based on a feasible specification




                                               16
of the instrument variable and plausibly available information. Furthermore, in many

(but not all) cases the model utilized is obtained by consideration of optimal choices by

individual agents in a dynamic and stochastic environment. Then stochastic simulations

are conducted using the specified model and alternative policy rules, with summary

statistics calculated to represent performance in terms of average values28 of various

macroeconomic measures such as the mean or variability of inflation, the output gap, 29

interest rates, etc.30 Some models are constructed so that each simulation implies a related

utility level for a representative individual agent; in such cases, utility-based performance

measures can be calculated.

       Having outlined the dominant manner in which monetary policy analysis is

currently being conducted, our task now is to discuss changes from the research style or

styles prevalent in 1971-73 and then to attempt to attribute these changes to the influence

of theory or evidence. Perhaps the most fundamental difference between the procedure

outlined above and standard practice as of 1971-73 is the incorporation of rational

expectations. Expectations are important in any dynamic analysis, of course, but if these

are rational rather than conforming to some fixed distributed-lag structure then they must

be treated quite differently in the study of policy rules, as was emphasized in Lucas’s

famous critique paper (1976). 31 In particular, the model’s equations must not muddle

together lagged values from forecasting (expectational) relations and lags in variables due

to other causes, such as adjustment costs. This distinction is necessary since, with

rational expectations, the coefficients in the forecasting rules will be different with

different policy rules—and so cannot be held fixed in comparisons of alternative policy

rules. The same is not true of adjustment-cost parameters.




                                              17
       Now clearly the switch from the fixed-lag to the rational expectations hypothesis

was the consequence primarily of theoretical, rather than empirical, analysis. At the time

it seemed a rather drastic step, but after the fact it has come to be recognized as an

entirely natural extension of the usual approach of neoclassical economic analysis to an

area of economic activity (expectation formation) that had previously been treated in a

non-standard manner. Today, many economists trained after 1980 appear, empirically, to

have difficulty in even contemplating any other expectational hypothesis. Also, it should

be remembered that Lucas’s critique itself was not new, but merely a (brilliantly

persuasive) application of Marschak’s (1953) fundamental insight that policy analysis

requires a structural (as opposed to reduced-form) model.

       There have recently been a few attempts to argue that, whatever the theoretical

attractions of rational expectations, evidence suggests that the Lucas critique is of little or

no consequence empirically. The most extensive and prominent such argument is

perhaps that of Hendry and Ericsson (1991) and Ericsson and Irons (1995), who

document that an estimated model of money demand shows no symptoms of parameter

change (due to coefficient changes in forecasting equations) across periods with different

monetary policy rules in effect. A detailed analysis of these studies is beyond the scope

of the present paper, but a basic objection to the Hendry-Ericsson-Irons argument can be

presented very briefly. It is simply that money demand relations provide an inappropriate

laboratory for the study of Lucas-critique effects. The reason is that standard theoretical

analysis of money demand behavior, as represented by, e.g., McCallum and Goodfriend

(1987), Lucas (1988), Woodford (1995), Walsh (1998, Ch. 3), and many others, indicates

that forecasting (i.e., expectational) relations are not involved in the optimality conditions




                                              18
(Euler equations) that are typically termed “money demand functions.” 32 In other

words, these relations are ones that are not predicted to shift with policy changes, under

Lucas critique reasoning. Thus a failure to shift with policy changes is irrelevant to the

issue. A much better laboratory for consideration of this issue would be Phillips-curve

relationships, in which expectational variables are prominent. 33

       A related but somewhat different empirical criticism of rational expectations

analysis has recently been put forth by Fuhrer (1997). In an analysis based upon a price

adjustment (Phillips Curve) relation that is formulated so as to nest expectational

(forward looking), inertial (backward looking), and mixed specifications, Fuhrer finds

that the expectational terms provide statistically insignificant explanatory power: “I find

that expectations of future prices are empirically unimportant in explaining price and

inflation behavior” (Fuhrer, 1997, p. 349). This would appear to strike a significant blow

to the hypothesis of rational expectations, suggesting that expectations are instead formed

as fixed-weight distributed lags of past values. My own response to this argument may

not be widely accepted, but it has been held for many years (see McCallum, 1980,

p.718).34 It is that the incorporation of the rational expectations hypothesis is much more

important for policy evaluation than at the estimation stage of the research project. It is

fairly plausible that systematic expectational errors can be found in data for past years,

distant or recent. But it would be unwise—as mentioned above—to expect any given

pattern of expectational errors to prevail in the future, especially if policy is designed to

exploit this error pattern. But to conduct policy analysis without assuming rational

expectations is to design policy in a manner that attempts to do precisely that, i.e., to

exploit a particular pattern. Thus it is desirable to design policy under the assumption of




                                              19
rational expectations even if one has utilized some other expectational hypothesis in

estimating the model utilized. Interestingly, Fuhrer himself often uses rational

expectations models in his own policy-analysis studies (e.g., Fuhrer 1996).

        Another apparent change in monetary policy analysis since 1971-73 is that such

analysis is now typically conducted in terms of a choice among alternative policy rules,

as contrasted with the choice of policy actions to be taken in a particular episode. But

this change is basically a necessary concomitant of the rational expectations assumption

and therefore needs no separate discussion.

        Rational expectations does not itself imply the absence of a long-run tradeoff

between inflation and unemployment. But analysts, like the policymakers mentioned

above, moved during the 1970s to near-unanimous acceptance of the Friedman-Phelps-

Lucas view that there is no exploitable long-run tradeoff between inflation and output or

employment (measured relative to capacity). Undoubtedly, this move was influenced by

the same brute experiences as those seen by policymakers, but for analysts there was also

some formal econometric work that probably played a role. Thus it was the case that

Solow (1969), Tobin (1969), Gordon (1970), and others began quickly to conduct

standard tests based on time series regression estimates very promptly after receiving the

challenge of Friedman (1966, 1968) and Phelps (1967). These first studies suggested, as

veterans of the period will recall, that long-run tradeoffs, did exist—that the long-run

Phillips curve was not vertical. But after Sargent (1971) and Lucas (1972b) pointed out

the logical flaw that invalidates these studies if expectations are rational, other tests

conducted in more appropriate ways by Sargent (1973), McCallum (1976), and Barro

(1977) indicated that long-run tradeoffs were not present—a position subscribed to in




                                              20
subsequent studies by Gordon (1975). Thus empirical evidence (of various types) was

probably dominant in bringing about a crucial change in analytical views.

        The foregoing should not be taken to imply that there are no remaining

disagreements concerning long-run relationships between real and monetary variables.

Indeed, there are major differences implied by various types of price adjustment models

that are currently in use. For example, the type of price adjustment scheme most

frequently discussed in practical policy-making circles is that of NAIRU models, where

the name is an acronym for non-accelerating-inflation rate of unemployment. In

nontechnical publications—even including a symposium in Economic Perspectives

(Winter 1997)—models of the NAIRU type are often discussed as if they reflected the

property known as the natural rate hypothesis (NRH). But the latter, as formulated by

Lucas (1972b), asserts that there is no time path of the price level (or the money stock)

that would (if maintained) keep output permanently away from its market-clearing

natural-rate path. Thus if yt denotes the log of output and y t is its market-clearing or

natural-rate value, the NRH asserts that the unconditional expectation E(yt - y t) will be

unaffected by the selection among monetary policy regimes. Not only will a high

inflation rate fail to keep E(yt - y t) above zero, but so will an increasing (often termed

“accelerating”) inflation rate or one with an increasing second (or nth!) difference in pt,

the log of the price level.    By contrast, models of the NAIRU type typically possess

the implication that a maintained increase in the inflation rate, such as ∆pt = ∆pt-1 + δ for

δ > 0, will keep E(yt - y t) > 0. Indeed, the very name NAIRU suggests this property, for

it suggests a stable relationship between the increase in inflation and yt - y t. But that




                                              21
implies that a properly chosen ∆pt pattern can keep yt - y t above zero permanently, in

contradiction to the NRH. 35

       Another prominent class of price adjustment model is the staggered contracts

class typified by Calvo (1983), Rotemberg (1982), and Taylor (1980). These also fail to

possess the NRH property, but in the opposite direction: they imply that an ever-

increasing inflation rate will tend to keep output permanently low! While I personally

consider this violation to be a mark against these models, one that suggests the presence

of some dynamic misspecification, the implications are not nearly so dangerous from a

policy perspective as those of the NAIRU class. One price adjustment model that does

satisfy the NRH is the “P-bar model” used by McCallum and Nelson (1998). Its main

weakness is that it fails to produce strong positive serial correlation in inflation rates—

i.e., sticky inflation—which seems to be a feature of quarterly data in the U.S. and

elsewhere. However, the only compact model known to me that does tend to generate

inflation persistence is that of Fuhrer and Moore (1995), which fails to satisfy the NRH

(although it fails by less than the others mentioned above).

       A striking feature of the typical models in the NBER and Riksbank conferences is

that they include no money demand equations or sectors. That none is necessary can be

understood by reference to the following simple three-equation system.

(1)    yt = α0 + α1 Etyt+1 + α2 (Rt – Et∆pt+1) + α3 (gt – Etgt+1) + vt

(2)    ∆pt = Et∆pt+1 + α4 (yt - y t) + ut

(3)    Rt = µ0 + µ1 (∆pt - ∆p*) + µ2(yt - y t) + et

Here equations (1) – (3) represent an expectational IS equation, a price-adjustment

relationship, and a Taylor-style monetary policy rule, respectively. The basic variables



                                              22
are yt = log of output, pt = log of price level, and Rt = nominal one-period interest rate, so

∆pt represents inflation, Rt – Et ∆pt+1 is the real interest rate, and yt – y t ≡ ~
                                                                                  y t is the

fractional output gap (output relative to its capacity or natural rate value, whose log is

y t). Also, gt represents the log of government purchases, which for present purposes we

take to be exogenous. In this system, Et denotes the expectations operator conditional on

information available at time t, so Et ∆pt+1 is the rational expectation formed at t of ∆pt+1,

the inflation rate one period in the future.

        The basic point at hand is that with gt and y t exogenous, and expectations formed

rationally, the three equations (1) – (3) are sufficient in number to fully determine the

time paths of the model’s three endogenous variables, namely, yt (or ~
                                                                     y t), ∆pt, and Rt.

Thus there is no need for a money-demand equation.36 If nevertheless one such as

(4)     mt – pt = γ0 + γ1 yt + γ2 Rt + εt

were appended to the system, it would not be inconsistent with (1) – (3) but would be

irrelevant in the sense that it would play no role in determining the behavior of yt, ∆pt, or

Rt. Its role would be merely to determine the amount of money (mt, in log terms) that

would be demanded and which would therefore necessarily be supplied by the central

bank in the process of setting interest rates in conformity with the policy rule (3).

        It can be seen that the absence of any money demand function—or any money

stock variable!—in the prototype system (1) – (3) reflects two properties of the latter.

These are that no “real balance” term mt – pt appears in the IS relation (1) and that the

interest rate Rt is used as the policy instrument. So we ask, what are the methodological

precepts that lead to those two aspects of (1) – (3)?




                                                23
       In the case of the second aspect, that Rt is specified as the instrument variable, the

rationale is almost entirely empirical. The fact is that actual central banks in industrial

countries conduct monetary policy in a manner that is much more accurately depicted by

writing Rt rather than mt (even if interpreted as the monetary base) as the instrument or

operating-target variable. Thus, such policy rules are studied even by economists who

might be regarded as possessing “monetarist” tendencies and possibly even believing that

policy might be improved if central banks used mt as their instrument (e.g., McCallum

and Nelson, 1998).

       The first aspect of the system (1) – (3), that no “money” term appears in the IS

function (1), is by contrast of an a priori origin. Traditionally, of course, it has been

usually presumed in analysis of an IS-LM style that IS functions do not include real

balance terms.37 But in recent work, the IS relationship has often been of the

expectational variety that includes Et yt+1 as in Kerr and King (1996), McCallum and

Nelson (1997), and Rotemberg and Woodford (1997). Such relations are obtained from

explicit optimization analysis of the dynamic choice problems faced by individual agents,

so they have arguably greater claim to theoretical validity than traditional specifications.

But in such analyses, the absence of any monetary real-balance variable depends upon the

common assumption that separability obtains in the indirect utility function that reflects

the transaction-facilitating properties of the medium of exchange (i.e., money). There is,

however, no compelling theoretical basis for that assumption, which is presumably made

for analytical convenience. Indeed, it could be argued that separability is not very

plausible. Accordingly, the absence of any real balance term in (1), and the omission of

monetary variables from model (1) – (3), hinges on the presumption that




                                              24
nonseparabilities of the relevant type are quantitatively unimportant—i.e., that the

marginal utility of consumption is (for a given rate of consumption) virtually independent

of the level of real money balances. The justification for that presumption has not been

explicitly discussed in the studies cited.

       It has been mentioned that the NBER and Riksbank conferences featured

considerable agreement among participants concerning research strategy. Furthermore,

Taylor (1998, pp. 4-5) argues that there exists a fair amount of substantive agreement;

specifically that model simulations at the NBER conference “show that simple policy

rules work remarkably well in a variety of situations; they seem to be surprisingly good

approximations to fully optimal policies…” and “simple policy rules are more robust than

complex rules across a variety of models.” Also, “introducing information lags as long as

a quarter does not affect the performance of the policy rules by very much.” In addition,

Taylor mentions other issues about which these studies do not reflect agreement,

including: the value of interest-rate “smoothing” terms in the rules; whether responses

should be geared to expected feature values rather than currently-observed values; and

about measurement of potential or natural-rate output.

       One area of disagreement among researchers concerns the distinction between

“optimal control” and “robustness” approaches for the design of monetary policy rules.

For some analysts, the task of policy rule design is to develop an appropriate

macroeconomic model of the economy and then conduct an optimal control exercise to

determine what the best policy rule would be for the economy in question. Neither step

is trivial, but both represent rather straightforward scientific problems. There would

remain the task of convincing actual policy makers to implement this rule, of course, but




                                             25
that is a matter of persuasion rather than scientific investigation. Notable examples of

this approach are Feldstein and Stock (1994) and Svensson (1997). To other economists,

by contrast, a crucial feature of the policymaking process is the lack of professional

agreement concerning the appropriate specification of a model suitable for monetary

policy issues. Various members of this group would emphasize different portions of a

macro model, 38 but to all in this group it seems hard to avoid the conclusion that

agreement upon model specification is predominately absent—and that different models

give rise to different alleged implications for policy. Thus these latter economists believe

that in practice the optimal control strategy collapses in response to the question, “What

is the appropriate model specification?” As a consequence, the approach favored by

these analysts is to search for a policy rule that possesses robustness in the sense of

yielding reasonably desirable outcomes in policy simulation experiments conducted with

a wide variety of models.39 It is not necessary that the collection of models all be

designed and simulated by a single researcher or research team; the work of Bryant et al

(1993) and Taylor (1998) represent studies by over a half-dozen research teams each.

       In evaluating candidate policy rules, it would clearly be desirable to have at hand

an established specification of the appropriate ultimate goals of monetary policy. In that

regard there are several important issues, including whether a CB should keep actual

inflation or expected inflation close to some normative value; what that normative value

should be (or should it change over time?); and how heavily the variability of output—or

is it output relative to capacity (measured how?) or consumption?—should be weighted

in relation to the inflation criterion. Of course in optimizing models that are specified at

the level of individuals’ utility and production functions, the answers to such questions




                                             26
are implicit to the solution to the optimal control problem. But again the fundamental

difficulty mentioned above intrudes in a crucial manner, for these answers must depend

significantly upon the model’s specification. Thus the absence of agreement regarding

model specification implies that there can be at present no consensus as to the precise

goals that are appropriate. In practice, nevertheless, there seems currently to be a

substantial amount of agreement about actual CB objectives; namely that most CBs

desire to keep realized inflation close to zero (allowing for measurement error) and to

keep output (or employment) close to a capacity or natural-rate value that grows with the

capital stock, the labor force, and technical progress. As a matter of logic it cannot be

rigorously established that these objectives are optimal (from the perspective of

individuals’ preferences), but it seems a reasonable judgment that they probably provide

an appropriate specification of CB macroeconomic goals.

       A related research-design issue that has attracted some attention involves the

distinction between “instrument rules” and “target rules,” in the language of Svensson

(1997). Rules of the former type, exemplified by Taylor (1993) and presumed in my

foregoing comments, specify period-by-period settings of a controllable instrument

variable as in equation (3) above. The latter type of rules, by contrast, specify target

values for some variable or combination of variables that the CB can influence but not

directly control, with these values obtained (at least in the work of Svensson) by optimal

control exercises on the basis of a designated model and objective function. Thus the

specification of a target rule amounts logically to the selection by the analyst of a model

and an objective function, whereas an instrument rule reflects the analyst’s hypothesis




                                             27
that the CB would (whatever its model and objectives) achieve satisfactory results if it

were to implement the rule.40

        It has been emphasized that models represented by the system (1)-(3) specify

slowly adjusting price levels. Thus central-bank policy actions, represented by changes

in Rt., typically have effects on real output, yt. It is of some importance to ask, then, what

is the scientific justification for models of this type in preference to ones (including RBC

models) in which monetary policy actions have no systematic effects on real variables. Is

it theory or empirical evidence that indicates that prices are sticky and monetary policy

able to influence output?41

        Here the argument is much the same as that of Section 2 above—the answer must

be empirical evidence since neoclassical theory certainly does not entail price stickiness.

But then the question becomes, what type of evidence has indicated strongly and clearly

that sticky prices and monetary effects on real variables are a feature of actual

economies? For it is unclear how to look for the former, empirically, and there is no

shortage of empirical studies that fail to find major effects of the latter type (e.g.,

Eichenbaum and Singleton (1986)). Regarding sticky prices per se there is some survey

evidence provided by Blinder (1994) and studies of particular commodities by others but

it is my impression that most analysts have judged these to be non-compelling. More

influential, I believe, has been the perception that sharp major changes in monetary

policy conditions (e.g., in the United States during 1981) have in fact had major real

effects in the same direction, together with the belief that price stickiness provides the

most satisfactory means of rationalizing that fact. Ironically, the empirical study that has




                                               28
probably attracted the most support for this viewpoint is Romer and Romer (1989), a

study that, like Hoover and Perez (1994), I find rather unsatisfactory.42

       One source of difficulty in formal empirical studies of monetary policy effects on

real variables has been the common practice of focusing attention on real responses to

policy innovations—i.e., unexpected components —in vector autoregression (VAR)

studies. Although Christiano, Eichenbaum, and Evans (1998) have reported effects of

this type in an extensive study, they are not quantitatively large in many VAR studies.

But the VAR approach seems inherently to miss the major effects, because the measured

innovation component of policy-variable fluctuations is extremely small relative to the

systematic component in terms of variability. Thus, for example, the systematic

component’s variability is about 16 times as large as for the innovation component in an

estimated interest rate policy rule for the U.S., 1955-1996 (quarterly data). One way of

making the relevant point is by consideration of an extreme case. Suppose that a central

bank’s policy rule is activist but entirely systematic, i.e., is devoid of random

components. Then a well-designed VAR study would attribute no importance to

monetary policy in affecting output—or inflation!—although it could be that the

systematic component of policy was in fact very important.

       A related point concerns the way in which empirical evidence works in

persuading specialists in monetary economics (and, probably, other areas). In that regard

it is almost never the case that an analyst’s view on some important hypothesis is

crucially dependent upon the results of a formal econometric study—no single study is

decisive. This is in part because conclusions about crucial properties of macroeconomic

systems almost always require identification of structural parameters in a well-specified




                                              29
model, yet both identification and “correct specification” are exceedingly difficult to

achieve in the macroeconomic context, for there is usually some highly dubious feature

of any manageable model. Instead, it is the cumulative effect of several econometric

studies and/or various bits of evidence obtained in more informal ways, all taken

together, that is usually persuasive to an analyst.

        This section has argued that monetary policy analysis, like macroeconomics more

generally and the practice of monetary policy, has been significantly influenced over the

last 25 years by both theoretical and empirical developments. That such is the case is

certainly desirable, I would think. Indeed, there is an important sense in which

significant scientific progress inevitably requires both theoretical and empirical inputs.

Evidence is necessary, obviously, because theories with content may by construction be

untrue, i.e., grossly inconsistent with relevant facts. But theory too is necessary, for one

can only make sense of facts and measurements within the disciplining context of a

theoretical structure that gives these facts some coherence and delineates what is and is

not relevant, etc.

V.      Cointegration and Monetary Analysis

        In this section, I would like to take up an issue that is highly pertinent to this

paper’s theme although it failed to find a place in the above evolutionary discussion.

This issue concerns a claim, which appears occasionally in the literature, to the effect that

a failure of real money balances, real income, and nominal interest rates to be

cointegrated implies the absence of any long run relationship of the type that is necessary

for the validity of traditional monetary economics. Cuthbertson and Taylor (1990, p.

295), for example, have expressed the claim as follows: “If the concept of a stable, long-




                                              30
run money demand function is to have any empirical content whatsoever, then mt [i.e.,

log money]… must be cointegrated with log prices, log income, and interest rates.”

Engle and Granger (1987) presented evidence contrary to the cointegration hypothesis;

several other researchers have reached the opposite conclusion but only after accepting

the presumption that cointegration is necessary for standard monetary analysis.

        My objective here is to argue that this presumption is basically mistaken. Of

course there is a technical sense in which it is correct: if mt – pt, yt, and Rt are all

integrated (difference stationary) of order one43 but not cointegrated, then the disturbance

entering any linear relation among them must by definition be nonstationary, so mt – pt

and any linear combination of yt and Rt can drift apart as time passes. But it is highly

misleading to conclude that in any practical sense a long-run relationship is therefore

nonexistent. The following argument is entirely interpretive; it includes no suggestion of

technical error in the literature discussed. But that does not diminish its importance.

        To develop the argument, let us consider again the example of a traditional money

demand function of the form (4). Suppose that mt – pt, yt, and Rt are all I(1) variables and

that each has been processed by the removal of a deterministic trend. Then the

cointegration status of relationship (4) depends upon the properties of the disturbance

term εt: if its process is of the difference-stationary type that includes a unit AR root, then

the variables in (4) will not be cointegrated.

        But the traditional view of money demand theory, as represented by the studies

cited above, provides no reason for believing that εt would instead be trend stationary

(i.e., would possess no AR unit root component). Indeed, it would seem almost to

suggest the opposite—for the theoretical rationale for (4) is built upon the transaction-



                                               31
facilitating function of money, but the technology for effecting transactions is constantly

evolving. And since technical progress cannot be directly measured by available

variables, the effects of technical change (not captured by a deterministic trend) show up

in the disturbance term, εt. But the nature of technological progress is such that changes

(shocks) are typically not reversed. Thus one would expect a priori there to be an

important permanent component to the εt process, making it one of the integrated

type—and thereby making mt – pt not cointegrated with yt and Rt.

        In such a case, however, the “long-run” messages of traditional monetary analysis

could easily continue to apply. Provided that the magnitude of the variance of the

innovation in εt is not large in relation to potential magnitudes of ∆mt values, it will still

be true that inflation rates will be principally determined, over long periods of time, by

money growth rates. And even without that proviso, long-run monetary neutrality may

still prevail, superneutrality may be approximately but not precisely valid, etc. That the

disturbance εt is of the difference-stationary class is simply not a source of

embarrassment or special concern for supporters of the traditional theory of money

demand, some of whom have estimated money demand relations like (4) after assuming

that εt is a pure random walk!44

VI.     Conclusion

        The picture painted in the preceding discussion is one that attributes major

changes in the analysis and practice of monetary policy over the years 1973-1998 to a

combination of theoretical and empirical influences. This is not a very dramatic

conclusion; indeed, one might say that it is almost empty. It would be possible to add a

bit of debatable content, by asserting that the mixture of influences has been reasonably



                                              32
appropriate—about the right amount of theory and empirics—but I would not feel

comfortable in doing so. Partly that is because I would have preferred that models with

complete price flexibility had not been quite so dominant during the years (say) 1982-

1992, although the surge of work with sticky price models in recent years may have

largely made up for their previous neglect. But an equally important reason stems from

the question: what type of evidence could be presented in support of a “reasonably

appropriate” contention? Unfortunately, I know of no satisfactory way of making such a

determination, especially since most influential studies involve a blend of theory and

evidence. For example, the rather abstract theoretical analysis of Lucas (1972a) was not

actually devoid of empirical content in the sense that its theorizing was specifically

designed to rationalize a set of broad facts that were (and are) of genuine, fundamental

importance. Consequently, I am left with the rather limp conclusion with which this

paragraph began.

       In conclusion, then, it may be appropriate to add the opinion that the current state

of monetary economics is not as highly unsatisfactory as has been claimed over the past

decade or so by various commentators at conferences and seminars. The type of claim

that I have in mind does not often make it into print, so I cannot provide citations, but I

am confident that many readers can supply examples from their own experiences. In any

event, the state of monetary economics seems to me to be about as healthy as that of

economic analysis in general. The contrary opinion is rather widely held for three

reasons, I would suggest, none of which is sound. First, much of the negative opinion has

been put forth by economists who are themselves proponents of an entirely unsatisfactory

theory of money demand, one involving overlapping generations models in which the




                                             33
asset termed “money” plays no role as a (transaction facilitating) medium of exchange.

Since this role provides the defining characteristic of money, as distinct from other assets,

it is not surprising that proponents of such a theory would find it unsatisfactory. Second,

rather inconsequential differences among proponents of the transaction-facilitating

approach to money demand theory—e.g., cash-in-advance, money-in-utility function,

shopping time, or transaction-cost-in-budget constraint models—have tended to obscure

the fundamental similarity of principles and implications among the variants of this

approach. Third, the profession’s poor level of understanding of the precise nature of the

dynamic connection between monetary and real variables—i.e., of price adjustment

relations—has tended to reflect discredit upon monetary economics, although this

relation belongs to the realm of macroeconomics more broadly. In that regard, moreover,

it is an illusion to believe that macroeconomics is itself in poor condition in relation to

microeconomics, an illusion generated by the fact that applied macro features a much

more ambitious agenda than applied micro—the understanding of quarter-to-quarter

dynamic movements in variables rather than just steady state values. Correcting for that

difference, the extent of disagreement seems about the same in the two sub-disciplines.




                                              34
                                        References

Alogoskoufis, G.L., and R. Smith (1991) “The Phillips curve, the persistence of inflation,

       and the Lucas critique,” American Economic Review 81, 1254-1275.

Altug, S. (1989) “Time-to-build and aggregate fluctuations,” International Economic

       Review 30, 889-920.

Axilrod, S.H. (1983) “A comment on Brunner and Meltzer,” Carnegie-Rochester

       Conference Series 18, 105-112.

Barro, R.J. (1977) “Unanticipated money growth and unemployment in the United

       States,” American Economic Review 67, 101-115.

Barro, R.J., and D.B. Gordon (1983) “A positive theory of monetary policy in a natural

       rate model,” Journal of Political Economy 91, 589-610.

Basu, S. (1996) “Procyclical productivity: increasing returns or cyclical utilization,”

       Quarterly Journal of Economics 111, 719-751.

Bernanke, B.S., and F.S. Mishkin (1997) “Inflation targeting: A new framework for

       monetary policy?”

Blinder, A.S. (1994) “On sticky prices: academic theories meet the real world,” Monetary

       Policy, ed. N.G. Mankiw. Chicago: Univ. of Chicago Press.

Brayton, F., A. Levin, R. Tryon, and J.C. Williams (1997) “The evolution of macro

       models at the Federal Reserve Board,” Carnegie-Rochester Conference Series

       on Public Policy 47, 43-81.

Broaddus, A., and M. Goodfriend (1984) “Base drift and the longer-run growth of M1:

       Experience from a decade of monetary targeting,” Federal Reserve Bank of

       Richmond Economic Review 70 (Nov./Dec.), 3-14.




                                             35
Brunner, K., and A.H. Meltzer (1983) “Strategies and tactics for monetary control,”

       Carnegie-Rochester Conference Series 18, 59-104.

Burns, A. (1979) “The real issues of inflation and unemployment,” Federal Reserve

       Readings on Inflation. Federal Reserve Bank of New York.

Bryant, R.C., P. Hooper, and C.L. Mann (1993) Evaluating Policy Regimes: New

       Research in Empirical Macroeconomics. Washington: Brookings Institution.

Calvo, G. A. (1983) “Staggered prices in a utility prices in a utility maximizing

       framework,” Journal of Monetary Economics 12, 383-398.

Christiano, L.J., and M. Eichenbaum (1995) “Liquidity effects, monetary policy, and the

       business cycle,” Journal of Money, Credit, and Banking 27, 1113-1136.

Christiano, L.J., M. Eichenbaum, and C.L. Evans (1998) “Monetary policy shocks: What

       have we learned and to what end?” NBER Working paper 6400. Forthcoming in

       Handbook of Macroeconomics, ed. J.B. Taylor and M. Woodford.

Cochrane, J.H. (1994) “Shocks,” Carnegie-Rochester Conference Series 41, 295-364.

Cogley, T., and J.M. Nason (1995) “Output dynamics in real-business cycle models,”

       American Economic Review 85, 492-511.

Cuthbertson, K., and M.P. Taylor (1990) “Money demand, expectations, and the forward-

       looking model,” Journal of Policy Modeling 12, 289-315.

Eichenbaum, M., and K. J. Singleton (1986) “Do equilibrium real business cycle theories

       explain postwar U.S. business cycles?” NBER Macroeconomic Annual 1986.

       Cambridge, MA: MIT Press.

Engle, R.F., and C.W.J. Granger (1987) “Co-integration and error correction:

       representation, estimation, and testing,” Econometrica 55, 251-276.




                                            36
Ericsson, N., and J. Irons (1995) “The Lucas critique in practice: Theory without

       measurement,” in Macroeconometrics: Developments, Tensions, and Prospects,

       ed. by K.D. Hoover. Boston: Kluwer Academic Press, 263-312.

Evans, C.L. (1992) “Productivity shocks and real business cycles,” Journal of Monetary

       Economics 29, 191-208.

Feldstein, M. and J.H. Stock (1994) “The use of a monetary aggregate to target nominal

       GDP,” Monetary Policy, ed. N.G. Mankiw. Chicago: Univ. of Chicago Press.

Friedman, M. (1966) “Comments,” Guidelines, Informal Controls, and the Marketplace,

       ed. G.P. Schultz and R.Z. Aliber. Chicago: Univ. of Chicago Press.

___________ (1968) “The role of monetary policy,” American Economic Review 58,

        1-17.

Fuhrer, J.C. (1997) “The (Un)importance of forward-looking behavior in price

       specifications,” Journal of Money, Credit, and Banking 29, 338-350.

___________ (1995) “The persistence of inflation and the cost of disinflation,” New

       England Economic Review, Jan/Feb, 3-16.

Gali, J. (1997) “Technology, employment, and the business cycle: Do technology shocks

       explain aggregate fluctuations? NBER Working Paper 5721.

Goodfriend, M. (1997) “Monetary policy comes of age: A 20th century odyssey,” Federal

       Reserve Bank of Richmond Economic Quarterly 83 (Winter), 1-22.

Goodfriend, M., and R.E. King (1997) “The new neoclassical synthesis and the role of

       monetary policy,” NBER Macroeconomics Annual 1997, 231-282.

Gordon, R.J. (1970) “The recent acceleration of inflation and its lessons for the future,”

       Brookings Papers on Economic Activity, No. 1, 8-41.




                                            37
__________ (1975) “The impact of aggregate demand on prices,” Brookings Papers on

       Economic Activity, No. 3, 613-662.

Haldane, A.G., ed. (1995) Targeting Inflation. Bank of England.

Hall, R.E. (1978) “Stochastic implications of the life-cycle-permanent income

       hypothesis: theory and evidence,” Journal of Political Economy 86. 971-987.

Hansen, L.P., and K.J. Singleton (1982) “Generalized instrumental variables estimation

       of nonlinear rational expectations models,” Econometrica 50, 1269-1286.

Hendry, D.F. and N.R. Ericsson (1991) “Modeling the demand for narrow money in the

       United Kingdom and the United States,” European Economic Review 35,

       833-886.

Hoover, K.D. (1995) “Facts and artifacts: calibration and the empirical assessment of real

       business cycle models,” Oxford Economic Papers 47, 24-44.

Hoover, K.D., and S.J. Perez, (1994) “Money may matter, but how could you know?”

       Journal of Monetary Economics 34, 89-100.

Kerr, W. and R.G. King (1996) “Limits on interest rate rules in the IS-LM model,”

       Federal Reserve Bank of Richmond Economic Quarterly 82 (Spring), 47-75.

King, R.E. (1990) “Money and business cycles,” Working Paper.

       Forthcoming in Journal of Monetary Economics.

King, R.E., and M.W. Watson (1994) “The post-war U.S. Phillips curve: a revisionist

       econometric history,” Carnegie-Rochester Conference Series 41, 157-219.

Kydland, F.E., and E.C. Prescott (1980) “A competitive theory of fluctuations and the

       feasibility of stabilization policy,” in Rational Expectations and Economic Policy,

       ed. S. Fischer. Chicago: Univ. of Chicago Press.




                                            38
___________________________ (1982) “Time to build and aggregate fluctuations,”

       Econometrica 50, 1345-1370.

____________________________, “The workweek of capital and its cyclical

       implications,” Working paper.

Leiderman, L., and L.E.O. Svensson, eds. (1995) Inflation Targets. London: Centre for

       Economic Policy Research.

Litterman, R.B., and L. Weiss (1989) “Money, real interest rates, and output: a

       reinterpretation of postwar U.S. data,” Econometrica 53, 129-156.

Lucas, R.E., Jr. (1972a) “Expectations and the neutrality of money,” Journal of Economic

       Theory 4, 103-124.

____________ (1972b) “Econometric testing of the natural-rate hypothesis,” The

       Econometrics of Price Determination, ed. O. Eckstein. Washington, D.C. Board

       of Governors of the Federal Reserve System.

____________ (1973) “Some international evidence on output-inflation tradeoffs,”

       American Economic Review 63, 326-334.

____________ (1975) “An equilibrium model of the business cycle,” Journal of

       Political Economy 83, 1113-1144.

____________ (1976) “Econometric policy evaluation: a critique,” Carnegie-Rochester

       Conference Series 1, 19-46.

____________ (1988) “Money demand in the United States: a quantitative review,”

       Carnegie-Rochester Conference Series 29, 137-167.

Mankiw, N.G., J.J. Rotemberg, and L. Summers (1985) “Intertemporal substitution in

       macroeconomics,” Quarterly Journal of Economics 100, 225-251.




                                           39
Marschak, J. (1953) “Economic measurements for policy and prediction,” Studies in

       Econometric Method, ed. W.C. Hood and T.J. Koopmans. New York: John

       Wiley.

McCallum, B.T. (1980) “Rational expectations and macroeconomic stabilization policy,”

       Journal of Money, Credit, and Banking 12, 716-746.

_____________ (1976) “Rational expectations and the natural rate hypothesis: some

       consistent estimates,” Econometrica 44, 43-52.

_____________ (1986) “On ‘real’ and ‘sticky-price’ theories of the business cycle,”

       Journal of Money, Credit, and Banking 18, 397-414.

_____________ (1989) “Real business cycle models,” Modern Business Cycle Theory,

       ed. R.J. Barro. Cambridge, MA: Harvard Univ. Press.

_____________ (1994) “Comment on ‘Federal Reserve Policy: Cause and Effect’ by

       M.D. Shapiro,” Monetary Policy, ed. N.G. Mankiw. Chicago: Univ. of Chicago

       Press for NBER.

_____________ (1999) “Issues in the design of monetary policy rules,” Handbook of

       Macroeconomics, ed. J.B. Taylor and M. Woodford. Amsterdam: North-Holland

       Pub. Co.

McCallum, B.T., and M. S. Goodfriend (1987) “Demand for money: theoretical studies,”

       The New Palgrave, ed. J. Eatwell, M. Milgate, and P. Newman. New York:

       Stockton Press.

McCallum, B.T., and E. Nelson (1998) “Nominal income targeting in an open-economy

       maximizing model,” NBER Working paper 6675.

_________________________ (1997) “An optimizing IS-LM specification for monetary




                                           40
       policy and business cycle analysis,” NBER Working paper 5875. Forthcoming in

       Journal of Money, Credit, and Banking.

Nelson, C.R., and C.I. Plosser (1982) “Trends and random walks in macroeconomic time

       series,” Journal of Monetary Economics 10, 139-162.

Nelson, E. (1998) “Sluggish inflation and optimizing models of the business cycle,”

       Journal of Monetary Economics 42, 303-322.

Patinkin, D. (1965) Money, Interest, and Prices, 2nd ed. New York: Harper & Row.

Phelps, E.S. (1967) “Phillips curves, expectations of inflation, and optimal

       unemployment overtime,” Economica 34, 254-281.

Prescott, E.S. (986) “Theory ahead of business cycle measurement,” Carnegie-Rochester

       Conference Series 25, 11-44.

Romer, C.D., and D. Romer (1989) “Does monetary policy matter? A new test in the

       spirit of Friedman and Schwartz,” NBER Macroeconomics Annual 1989,

       121-170.

Rotemberg, J.J. (1982) “Monopolistic price adjustment and aggregate output,”

        REStud 44, 517-531.

Rotemberg, J.J., and M. Woodford (1997) “An optimization based econometric

       framework for the evaluation of monetary policy,” NBER Macroeconomics

       Annual 1997, 297-345.

Sargent, T.J. (1971) “A note on the accelerationist controversy,” Journal of Money,

       Credit, and Banking 3, 50-60.

__________ (1973) “Rational expectations, the real rate of interest, and the natural rate

       of unemployment,” Brookings Papers on Economic Activity, No. 2, 429-472.




                                            41
Sargent, T.J., and N. Wallace (1975) “’Rational’ expectations, the optimal monetary

        instrument, and the optimal money supply role,” Journal of Political Economy

       83, 241-254.

Sims, C.A. (1980) “A comparison of interwar and postwar business cycles: monetarism

       reconsidered,” American Economic Review Papers and Proceedings 70, 250-257.

Solow, R.M. (1969) Price Expectations and the Behavior of the Price Level. Manchester:

       Manchester Univ. Press.

Svensson, L.E.O. (1997) “Inflation forecast targeting: implementing and monitoring

       inflation targets,” European Economic Review 41, 1111-1146.

Taylor, J.B. (1980) “Aggregate dynamics and staggered contracts,” Journal of Political

       Economy 88, 1-23.

__________ (1989) “Monetary policy and the stability of macroeconomic relationships,”

       Journal of Applied Econometrics 4, S161-178.

__________ (1993) “Discretion versus policy rules in practice,” Carnegie-Rochester

       Conference Series 39, 195-214.

__________ (1996) “How should monetary policy respond to shocks while maintaining

       long-run price stability—conceptual issues,” Achieving Price Stability, Federal

       Reserve Bank of Kansas City.

__________ (1998) “The robustness and efficiency of monetary policy rules as

       guidelines for interest rate setting by the European Central Bank,” Working paper.

Tobin, J. (1969) “Discussion,” Inflation: Its Causes, Consequences, and Control, ed. S.W.

       Rousseas. New York: New York University.

Walsh, C.E. (1998) Monetary Theory and Policy. Cambridge, MA: MIT Press.




                                           42
Walters, A.A. (1971) “Consistent expectations, distributed lags, and the quantity theory,”

       Economic Journal 81, 273-281.

Watson, M.W. (1993) “Measures of fit for calibrated models,” JPE 101, 1011-1041.

Woodford, M. (1995) “Price-level determinacy without control of a monetary aggregate,”

       Carnegie-Rochester Conference Series 43, 1-46.




                                            43
                                          Endnotes




1
  A different (but not incompatible) account of post-Bretton Woods developments in
monetary analysis is provided by Goodfriend and King (1997), who coined the term “new
neoclassical synthesis.”
2
    A very brief analysis of the source of the collapse is given below in Section 3.
3
  One reason, perhaps, is that Walters used a different term, namely, “consistent
expectations.” His paper’s first footnote states in part: “What I call consistent
expectations is formally similar to Richard Muth’s rational expectations.” Actually, of
course, Richard F. Muth—at the time a leading scholar in the field of housing
economics—is the brother of John F. Muth.
4
    On the latter, see McCallum (1980).
5
 A variant is the claim that it is implausible that all agents would believe in the same
model of the economy. But, first, this is an objection to macroeconomics, not rational
expectations, and second, there are some rational expectations models in which agents’
expectations are not all alike.
6
  This statement oversimplifies greatly, in several respects. First, Kydland and Prescott
(1982) was clearly previewed by Kydland and Prescott (1980). Second, there were
important early contributions by other RBC analysts, including King, Long, Plosser, and
Rebelo—and, as stated below, RBC analysis developed out of earlier work by Lucas,
Barro, Sargent, and others. Third, the rise of RBC analysis was somewhat more gradual
than the exposition in the text indicates.
7
  A partial exception was work involving unit-root or cointegration analysis, which was
quite popular. But this work lay more in the domain of econometrics than
macroeconomics, and besides there were prominent issues concerning this topic’s
relation to RBC analysis—see, e.g., Nelson and Plosser (1982).
8
  The first of these papers of which I am aware is King (1990). Other notable efforts with
publication dates prior to 1997 include Benassy (1995), Cho (1993), Cho and Cooley
(1995), Cooley and Hansen (1995), Hairault and Portier (1993), Kimball (1995), King
and Watson (1996), Rotemberg (1996), Ohanian, Stockman, and Kilian (1995), and Yun
(1996). For references and a useful review, see Nelson (1998). Some more recent
studies will be mentioned below.
9
   This statement has been disputed by several readers, and I must confess that the
following argument is not entirely straightforward. But I continue to believe that the




                                              44
leaders of the RBC movement were not Keynesians who were won over by arguments for
theoretical purity, but instead were adherents of the Lucas-Barro equilibrium approach
who discovered that it was very difficult empirically to assign much importance to
monetary shocks.
10
   This is not to imply that these studies are immune to criticism; in fact I have quarreled
with some of them myself. But the point is that, rightly or wrongly, they were influential.
11
    One reader has suggested that it is illogical for me to cite “evidence” as providing
stimulus for the rise and also the decline of RBC analysis. But I contend that this is not
illogical, for different types of evidence were predominant during the two phases of
intellectual development.
12
   Actually, the lead and lag correlations appeared somewhat later, in Kydland and
Prescott (1986).
13
   See, for example, Hoover (1995) and the symposium, with articles by Kydland and
Prescott, Hansen and Heckman, and Sims, in the Winter 1996 issue of the Journal of
Economic Perspectives.
14
   The other nations at Bretton Woods would never have agreed to a system based on a
paper dollar standard.
15
     An interesting document in this regard is Burns (1979), a speech given in 1975.
16
  One account that is more detailed but basically consistent with the one given here is
Goodfriend (1997).
17
  In my opinion it is entirely clear that the above-optimal inflation of the 1970s cannot
plausibly be attributed to the time-inconsistency motivation depicted in the famous
analysis of Barro and Gordon (1983); for this model requires that central bankers believe
that the public forms its expectations rationally. In fact, central bank policymakers and
economists both exhibited considerable hostility to the hypothesis of rational expectations
until the middle 1980s.
18
  Targets were announced for several money stock measures, which often gave
conflicting signals, and target misses were treated as irrelevant bygones during the 1970s.
19
   For additional discussion of the 1979-1982 period, including a tabulation of the
adjusted M1 growth rates that the FOMC was using at the time (which reveal the
tightening during 1981 more clearly than unadjusted values), see Broaddus and
Goodfriend (1984).




                                              45
20
  Among the reviews of inflation targeting are Haldane (1995), Leiderman and
Svensson (1995), and Bernanke and Mishkin (1997).
21
     Since the election of 1996, the target band has been widened to 0-3 percent.
22
     See, for example, King and Watson (1994).
23
     Such as the IMF or the economic policy institutes of (e.g.) Germany.
24
  This is a slight exaggeration, since reference to simulation results obtained with Fed
models will signal a Federal Reserve author, etc. But the methods and the general
characteristics of the models used are extremely similar.
25
  It might also be noted that Alan Blinder and Frederic Mishkin are listed as professors
but would recently have been categorized as central bank officials.
26
 In this case one bit of evidence is provided by the interchange between Brunner and
Meltzer (1983) and Axilrod (1983).
27
  Special mention might be made of former students of John Taylor, including Joseph
Gagnon, Andrew Levin, Volker Wieland, and John Williams.
28
     Averaged over numerous replications for each model plus rule specification.
29
   By the output gap I mean the percentage (or fractional) difference between output and
its market-clearing, natural-rate, or capacity value. These concepts are subtly but
significantly different from model to model.
30
   The King-Wolman and Henderson-Erceg-Levin papers have models compact enough
that analytical solutions are used rather than stochastic simulations.
31
   The point had been made earlier—e.g., in Lucas (1972a) and Sargent (1971)—but was
brought out forcefully and at length in Lucas (1976).
32
   More precisely, these conditions that relate real money balances to a transaction
quantity variable and an opportunity cost variable are obtained by combining first-order
optimality conditions with respect to current consumption and money holdings. There is
another construct that could more properly be termed a money demand function, but it
would include an infinite sequence of expected future values of all variables taken
parametrically by the household, so has a very different specification. On all this, see
McCallum and Goodfriend (1987).
33
   Using the Phillips curve as its laboratory, Alogoskoufis and Smith (1991) find
dramatic confirmation of Lucas critique effects.




                                              46
34
   Another response is that model mispecifications are likely to yield results spuriously
suggesting the importance of lagged variables.
35
  It should be mentioned, perhaps, that a failure to satisfy the NRH is not the same thing
as the absence of monetary superneutrality.
36
    Indeed, the Fed’s major new quarterly econometric model was constructed without
any money demand function or any reference to any monetary aggregate—see Brayton et
al (1997).
37
  More accurately, it has been assumed that real balance terms should be included in
principle but are of negligible importance practically; the classic reference on this is
Patinkin (1965).
38
   My own candidate for the weakest component in a macroeconomic model is the price-
adjustment (Phillips curve) sector. In McCallum (1999, fn. 14) the argument is stated as
follows. “It is not just that the economics profession does not have a well-tested
quantitative model of the quarter-to-quarter dynamics, the situation is much worse than
that: we do not even have any basic agreement about the qualitative nature of the
mechanism. This point can be made by mentioning some of the leading theoretical
categories, which include: real business cycle models; monetary misperception models;
semi-classical price adjustment models; models with overlapping nominal contracts of
the Taylor variety or the Fischer variety or the Calvo-Rotemberg type; models with
nominal contracts set as in the recent work of Fuhrer and Moore; NAIRU models; Lucas
supply function models; MPS-style markup pricing models; and so on. Not only do we
have all of these basic modeling approaches, but to be made operational each of them has
to be combined with some measure of capacity output—a step that itself involves
competing approaches—and with several critical assumptions regarding the nature of
different types of unobservable shocks and the time series processes generating them.
Thus there are dozens or perhaps hundreds of competing specifications regarding the
precise nature of the connection between monetary policy actions and their real short-
term consequences. And there is little empirical basis for much narrowing of the range of
contenders.”
39
     Some representatives are Bryant et al (1993), McCallum (1999), and Taylor (1998).
40
   There is also a major controversy as to whether a CB can implement a rule of the
“committed” or “non-discertionary” type. Since my own affirmative position on this
issue (e.g., McCallum, 1999) is somewhat unorthodox, I propose not to discuss it in the
present paper.




                                             47
41
    There is small but significant school of thought that attributes real effects of policy to
financing constraints in flexible-price models, e.g. Christiano and Eichenbaum (1995).
Discussion of this position is beyond the scope of the present paper.
42
    It is obvious that the Romer and Romer (R&R) dummy variable is not exogenous, for
it reflects actions taken in response to recently-prevailing macroeconomic conditions.
Thus my own summary statement (McCallum, 1994, p. 334) is that their study differs
from previous attempts to measure monetary policy effects primarily as follows: “the
R&R dummy reflects changes in only one direction, does not reflect the intensity of
policy actions, and is based on statements rather than actions. Thus one is led to wonder
how use of this dummy, instead of a traditional measure, constitutes an improvement
over prior practice.”
43
  A time-series variable is integrated of order one, written I(1), if it must be differenced
once to obtain a variable that is covariance stationary. This will be the case for an
ARMA variable if its autoregressive parameter has a unit root.
44
   More generally, I would a priori expect cointegration among basic variables—ones
that enter utility or production functions, not their differences—to be quite rare. for
behavioral relations typically include disturbance terms that represent unobservable (and
thus omitted) variables, which include shocks to preferences and technology. But these
shocks would seem likely to include significant random-walk components, as argued
above. Thus disturbance terms in behavioral relations should, according to this
argument, typically possess unit-root components.




                                              48
