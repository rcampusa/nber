                     NBER WORG PAPER SERIES




                 OPTIMAL ADAPTIVE CONTROL METHODS

                 FOR STRUCTURALJ.JY VARYING SYSTEIS


                       Alexander H. Sar'ris
                         Michael Athans

                    Working Paper No.      2t.




  COMPUTER RESEARCH CENTER FOR ECONO{LCS AND 11ANAGEMENT SCIENCE
            National Bureau of Economic Research, Inc.
                      575 Tecbno1oi Square
                  Canridge, Massachusetts 02139


                          Deceiiüer 1973



                 Preliminary: not for quotation
     NBER working papers are distributed infoniully and in limited ni.rrbers
for corrments only. They should not be quoted without written permission.
     This report has not undergone the review acccrded official NBER
publications; in particular, it has not yet been submitted for approval by
the Board of Directors.

Massachusetts Institute of Technoioj and NBER Computer Research Center.
Research supported in part by National Science Foiidation Grant GJ-ll54X2
to the National Bureau of Economic Research, Inc.
*'CMassachusetts Institute of Technoloj. Research supported in part by
NASA Grant NGL- 22 0091214 to   MIT.
                            Abstract

        The problem of simultaneously identifying arid controlling a time-
varying, perfectly-observed linear system is posed. The parameters are
assumed to obey a Markov structure and are estimated with a Kalman filter.
The problem can be solved conceptually by dynamic programning, but even
with a quadratic loss function the analytical computations cannot be
carried out for rrcre than one step because of the dual nature of the
optimal control law. All approximations to the solution that have been
proposed in the literature, and two approximations that are presented
here for the first time, are analyzed. They are classified into dual
and non-dual methods. ialytical comparison is untractable; hence
Monte Carlo siirailations are used. A set of experiments is presented in
which five non-dual methods are compared. The numerical results indicate
a possible ordering anong these approximations.


                         Acloiowledgement

       The authors would li]ce to thank Ms. Sophia A. Zalk for her excellent
typing work.




                                                                               .3-
1. Introduction

2. Statement of the Problem

3.

.




7.
     Bayesian




     Dual




Appendix
         6. L   Open
                                   .
                                   Contents




                Estirrtion of the Varying Parameters
     Solution via Dynamic Pro'arrriing
5. Optirrul Control with Perfectly Known Parameters
6. Non-Dual Suboptirru.1 Methods
         6.1 Wouters' Mininn Variance Controls
         6.2 Wieslander s and Wittenrrurk' S Control
         6.3 Sequential Stochastic Control
                       Loop Feedback Optima]. (OLFO) Control
            Suboptirnal Methods
         7.1 One-Measurement-Optimal Feedback Control
         7.2 Adaptive Covariance Method
         7.3 Two-Step Optimal Adaptive Control
8. Numerical Comparisons
9. Sunrry and Conclusions



Appendix C.
            A. Solution of the Adaptive Covariance Control Problem
Appendix B. Soma Useful Matrix Irivatives
                Computation    of the Two-step Adaptive Control
                                                                  .




                                                                   16

                                                                   17



                                                                   18
                                                                       1



                                                                       8

                                                                      10

                                                                      13




                                                                      17



                                                                      22

                                                                      26

                                                                      26

                                                                      29

                                                                      3
                                                                      38

                                                                      5L




References


                                    Tables


Table 1. List of Monte Carlo Experimants                              39

Table   2. List of Average Cost in Experints                          39
                             Figures

Figure 1.    Control Gains for El
Figure 2.    Estirrates of at in El    t3
Figure 3.    Estimates of     in El    LL


Figure       Control Gains for E2      L5


Figure 5.    Estirrates of at in E2
Figure 6.    Estirrates of bt in E2    L7

Figure 7.    Control Gains for E3      Lt8


Figure 8.    Estiirtes of at -' E3     L9

Figure 9.    Estiirates of     in E3   50

Figure 10.   Control Gains for ES      51

Figure 11.   Estirrates of at in ES    52

Figure 12.   Estimates of      in E5   53    /
1. INTRODUCTION


            Economic science attempts to ui-iderstand the economic behaviour of
individual units like the household and the finn as well as their aggregates.
There is huge diversity in the ways of people and firTrs, hence there is a
lot of uncertainty inherent in any economic system. The difficulty of
understanding economic behaviour is compounded by the fact that attitudes
change, and technological innovations and political factors tend to always
change the status quo. We live in a changing wcirld and we rrn.ist find ways
to understand, describe, and deal with these changes.
            To date nost quantitative economic res.earch has dealt with system
no1e1s in which the structure is completely fixed and is             not allzed to

change.    There has been a lot of worc, under the name of econometrics,
that has dealt with constant parameter estirrtion of econometric rrcdels.
A very good indicator of the state of the art is the book by Theil (1971).
            Recently there has been some research into the development of
methods of describing and estimating changing parameters. The work of
Rosenberg   (1968), Cooley (1971) and         Sarris (1973) are representative of
the research   to   date.

            This paper      deals   with   policy in the presence   of structLa'al

uncertainty as    evidenced by parameter variations. There           has been    some

research   into   the problem   of policy forrmilation     in the presence of

constant   but unknocin     system parameters.     Prescott (1967)   was   the   first
                                —2—




economist to deal with such an "adaptive" problem. Since then McRai
(1972), Poporic     (1972), Rauser   and Freebairn (1973), and Chc.z (1973)
have also dealt with the same problem.
      The problem of controlling a plant with unknown parameters is
not new to engineers. Fel'dbaum (1960 a, b, 1961 a, b) was the first
one to analyze the complexities of "learning while controlling," i. e. the
dual nature of control.      Since then there have been rnnnerous bcoks
(Sworder (1966), Fel 'dbaum (1966), Poki (1967) ) and papers (see ref. 16
for an extensive bibliography) dealing with policy in the presence of
uncertain parameters. Hciever, there have been very few papers,
addressing therrselves specifically to the problem of controlling a system
whose parameters are varying in a random fashion. Exceptions are the
papers by Wieslander and Wittenmerk (1971) and Wouters (1972), in which
some nirical results were given. The papers by Bar-Shalom and S ivan
(1969), Tse and Athans (1972), Tse et. al. (1973 a,b) also treated time
varying parameters althou the nunerical results reported were for
systeirs with constant parameters.
       In this paper we attempt to unify inst of the methods available
for controlling systerrs with parameter adaptation. To this end we shall
consider only systeirs with perfect state inforrration. We shall extend
the   methods   that have been developed for the constant parameter case, to
include the varying parameter case. We shall also propose some new
                                  —3—




methods. In section 2 we present the problem to be tackled. Section
3 analyzes the estintion technique for the time varying parameters.
Section '4 presents the general method of solution and indicates the
difficulties of applying it to our problem. In section 5, we present
the ideal case of )cn parameters and one control technique based on
it. In section 6 we present four non-dual control methods and try
to indicate their shortcomings. In section 7 we present three dual
methods, one of which is presented here for the first time. Section
8 presents some Monte Carlo comparisons of the non-dual methods, and
in secdon 9 we sunimerize the results and indicate directions for
further research.
                                       --
2. STATEMENT OF TI-I PBLIEM


          Our purpose is to analyze and compare various methods so we
shall try to keep the complexity of the systerr to be analyzed, miniiral.
Generalizations of the methods to nre complicated probleirs are straight
forward in rrcst cases. We shall confine ourselves to discrete time linear
systeme described by the folling equations.
                                                         (1)
          xt+iAtxt+Btut+CtZt+€t                          (2)
                  Hx      +
                              Vt
where
              -is the niobservable state vector at time t
          Ut - is a vector of policy or control variables at time       t
          z-      is a vector of exogenous variables


          '   - is the vector of state measurements at time t
                  v - are vectors of system and measurement noises respectively.
          The rrodel as stated in (1) and (2) is general enough to include
many engineering ncdels of interest and also reduced form econometric
nodels. Hiever, it is still too general for our purposes. Therefore,
we shall consider the folliing nodel composed of the rrost elementary
building blocks.
          y+iat+btut+t                                   (3)
where
              - is the perfectly observed scalar state
              -    is   a scalar   control
              - is scalar system noise.
The irodel in (3) is a special case of airrost every nodel that has been
dealt with in the literature.          Hence we can compare many methods at this
 level.
                                                  — 5—




                The state
                    will be measured exactly. Let us denote by yt
 u the foUcdng quantities


             ut-.
               =                                                          (5)
                         {u0,u1          u}

                   •


 The controls          {ut} will be restricted to the follcwing form.
             u           (y,u )
                               t t-l                                      (6)
where        is   a function       to be   chosen. Let Y denote the set in which
the state at      time t is restricted to lie, and V the set of allcxjable
ut's.
         Then        is a function from Y0 x Y1.. .x Y V x V1 . . .V1 -'
V. For the purses of               this    paper Y =           V     R for all   i.
             At   tine zero we         shall assusne         that the   folling quantities
are ]CKWn;
                                                         N
            y0,        p(c0, C1         , e)                       N(O,a 2)*
                               N
            p(a0,b0)
                                              0
                                   Lo
            The    obj ective is to chaos e the functions                   y, l•.' 1N-l
such that the folliing cost criterion is minimized.
            V(y0) =        E                             +
                               {
                                   :       y?                                    (6a)




* p(.)   denotes   a probability density and N (a ,b)                   denotes a norl density
 with    mean   a and variance b.
                                         —6—




          Notice that the problem is still not completely forjnilated because
                                                     shall impese the
we do not kncii hci a and bt are going to vary. We
follciiflg a-priori probabilistic structure on the pararrterS.


                  ati [at       +   [0                           (7)
                  btj   Lbtlj            j
or if we denote by Pt           [a bt' *       and   w=     n


                                                                  (8)
                          +
                              w1
s is the stcture propes ed by s eerg (1968) and S ais (1973).
             In order for the problem to be completely specified the joint
                                       must be given. Since we do not
 probability density of W0,        WN

 know a-priori how the parameters vary it is not trivial to specify this
 quantity. For the purposas of this paper we shall ke the following
 assumption                               N
                                          E N(O,R)                (9)
             p(W0, W1           w)       1=1

 where

              R                                                   (10)

                                o\
 The choice    of appropriate R will not be          discussed   in this paper.

  It   is discussed     sorrjhat by Sarris (1973).
              The problem can       now be stated in full.


  *    (') denotes transposition
                                            —7—




Find the optirrnn V*(y0) where


                                                  1
           V*(y0) =     mm         E { 'E             yj +       + r'u    )   }   (11)
                                        1         0


subject   to the stochastic constraints,
                 +
                               +
                                   btut +                          (12)



                        Pt =       -i   +                          (13)



where
        c}    and            are series of white nonr1 random variables with the
properties
           p( ct) =     N(O,a)                                     (1')
           p(Wt)        N(O, R)                                    (15)

                        = ç(                                        (16)
                               c)P(w)
and the system initial conditions are,
            y0
                  -   kncn                                              (17)

             p(p0)      N (    , M0)                                    (17a)


                                            abuse the notation a little by writing
    l
             In the sequel we will

             UN_i in place of Io,Yi
                 ,                                           1N-i 1Ii   (ii).
wiU be done for the reader's convenience.
                                           —8—




3. BAYESIPN   TIMAITON OF THE VAR'ING PARAMFE

           As    will be seen scon, the solution of the prthlem stated in
section 2 will require the kn.iiedge of the joint conditional distribution
of the parameters at and bt, conditioned on the data up to the time t.
In this section we shall examine a way of obtaining this distribution,
which we shall denote        by p( P1Y ,ut_l).

            The   distribution at time zero is nonmal as seen in (17 a). Assir
that the conditional distribution p(                   ut_i) is nonral with mean
denoted by                and symmetric covariance matrix denoted by Mt_itt_i.
The relevant equations for the next stage are
                         +
            Pt               w1                          (18)



                     zp +                                (19)

where   we have denoted

            z N'-        u                               (20)


We can use    standard Bayesian     analysis to find the density
                                                                        p(pt/yt+,ut)

            p(p /yt41,ut)
                                                 ,u
                                                               '             (21)
                                  [p(y/p,y ,u )p(p/y ,u )cpt

            m (18) we see that the density             p(p/ytut) = p(pttyt,ut)
is   normel with mean     equal to P-i--.                    and covariance matrix

                     =
                         Nt_itt_i   + R                                      (22)
            Mt,t_i
            yt Ut) is also nonrl          from (19).   The   density   in   (21) is there-

fore normal. Its mean and coyariance matrix, after some calculations,
                                           —9—




are   given by the fo11ing fonnulas.

            tit        Mt,t [M_1
                                                 +
                                                       1z     (23)


                                + 1z' z                       (24)
                                           t


The   folliing imatrix inversion lemma will help us render (23) and (24)
identical   to the standard Kalmen filter equations.
Lemma 1. (Matrix Inversion Lenma). If
                                       —
            s            +   AR 1B]             then
            S      M-   MA   [R + BMAJ
                                           -l    BM.

Proof. The proof is by direct compctation and is omitted.
            With the help of this len (24) can be rewritten.

            Mt,t
                   =                  ,r2
                       Mt,ti - Mt,t iZt L + ZtMt,tiZtJ ztMt,t_i (25)
                                                    I—i-

This along with (22) are the well kncwn updating equations for the
ovariances of the Kalmen filter adapted to our problem. We notice
that since Mt,t_i is symmetric then Mt is also srtric. We nai
substitute in (23) the expression for Mtit foiffld in (25). We obtain
after some menipulation

            t,t        Pt,t-i
                                +   Nt,tiz( + ztMt,tizTt)_l(yt÷i -   zpi1)        (26)



Which is the standard KaJ.jman updating formula. Equations (23)      and   (24)
will   be useful later.
                                       —10—




4. SOLIJftON VIA DYNAMtC PROGR1ING


            The problem that was stated in section 2 can in principle be
solved via dynamic programming. We state nci the form that the stochastic
dynamic prograiming uations take. We can write:

                                                N-i
                         min            E'       E        (y2     + ru/yN_l,uN_    (27)
             V*(y0)
                       u0,   u1       u11       i     0     1+1
                                                                      1


We shall ni state a theorem, which can be found in strm (1970, oh. 8),
that will be crucial.
Theorem 1.       Let E [./y denote the conditional mean given y. Assune
that the function f(y,u)         E[l(x,y,u)/y') has a unique miniam with
                                  =


respect   to ucV for all ycY. Let u°(y) denote the value of u for which
the minimum is achieved. Then


          n El(x,y,u)          E1(x,y,u°(y))        E' in E [1(x,y,u)/y]
          u(y)                                      yu
                                                   N-i
            Using this theorem and noticing that E [ E (y? + + ru2) N-i ,u
                                                   i= 0          i/y N-2
is quadratic with respect to                therefore having a uuque minimi.ni we
can write
                                                      N-i
            V*(y0)     mm
                      U0,U1,... UN2
                                       E' nin E[
                                              UN2           0
                                                                  i=l
                                                                (y?       i"
                                                                        ru' N—l N_23
                                                                                ,u   }(28)
                                               —11—




NcMwe invoke the principle of optimality, and noticing that the first
N-i texirs in the si.mtion of (28) do not involve UN1 , we write:
                                               N-2
       V*(y0)
                 =    mm                 E { E (y1 + ru?) + mm EJ + ruNlIy,uJ}
                     UOUi,...UN_2              1=0                       UN_i

          ntin
         Uo,Ul,...UN2
                               E' { E
                                       it   (y?1 +     ru) + v*yN_l)      }         (29)


where we have denoted:
                                                  N-i
       V*(yt)         mm                     E{    E            +   ru)/yt,ut_l}
                     Ut,Ut+l,...UN_l

             By the reasoning used above it is quite straightforward ncw
to prove the folling recursive relation:

      V*(yt) =             E   '{ y÷1 + ru + V*(yt)/yt,ut_l}                       (30)
                      Ut

Equation (30) is the well kricwn recursive relation of stochastic dynamic
programming. If we can solve it then our problem will be solved.
             At time N-i (30) becomes:

      V.. (yN—l) =   mm
                       .
                               E
                                   2
                                        + r1/y
                                          2
                                               ,u
                                             N—i N—2
                                                            }

                      UN-i

      min E {(_1y_1 + b 1u21 +                             + 2a lbN iUN       l'Nl +
      UN_i
                                                                              =
                      N-i + 2_lUN_icN_l) + 1iN_i,N_2}
                                            —12—




  -
  -
        .
       nun   r       2
             LYN_1E(_lh1' U
                           2     N—i N—2
                                           ) +
                                                 2       2
                                                 uiE(bNi/y
                                                              N—i N—2
                                                                  ,U    ) +


 +           + 2lyNiE(lbN_iIyN_i,uN_2)
                                                         +
                                                             _]               (31)


The   miniiami of the above expression is easy to find since the                quantity   inside
the brackets is a quadratic in UN1•

                       r         2   N-i N—2 i —i                      N—i N-2
                 =    — 1r +   E(bNl/y     ,u    )j      E(aNibNi/y      U       N1   (32)



                                                                              (33)
             v*(y) KN1 'N1 +
where


  KN_i       E(1/yN_l,u2)
                                     -
                                         [r + E(b/y',u2)J _(11/yN_i,uN2)2                           (3)

                                                                               (35)




Equation     (33) might icok like a quadratic y but a quick iook at (3t4.)
will convince the reader that KN1 is a quite complicated function of

(c.f.   uations (25)(26)). It thus                   becomes impossible to carry the
backward induction any further than already done.
             It is our purpose in this paper to examine and compare sioptirr1
techniques to solve the problem posed in section 2. This will be done in
the   next   fei sections.




                                                                                                          0
                                     —13—




5.   OF1IMAL CONTROL WITH PEFFECLY KMCI4N PARAMETEI



              In this sectial we shall assi.nne that the parameters a ,bt are
kricn with certainty during the whole interval tO,NJ. Equation (30) at
time N-i becomes:
                                2   N—i N—2
      V*(y
           N—i
                 ) mm. E "N2+ ruNl/y   ,u


      mm     E' {   1y1 + b11 + 2_1bN_l_iyN_1                     +




      21N1N1 + 2b _1CN_i + 1iN_i,N_2                     }


                       +   b11 + 21bNi1yN1 +                 +
                                                                      J   (36)


The above equation is a quadratic in UN1 so its minimum is easily foumd.

                        r
                      - [I'     2 1—1
                            +   -1i  _1bN_1yN_1

                                      + FN_l                              (38)
                            HNy
where
                       2     r      2  i—i 2 2
              HN1 aNl      - L r + bNl j  aNlbNl
              FNl 0
              Let V*(y) H+121 +                   Then at time tj the dynairdc
progr'armiing recursion becomes
                                         — 14-




        V*(yJ)          mm   E[y?÷1 +    ru      +




        mm [ci      +
                        H.1)(a?y?
                                    + b?u?           +
                                                         2ab.uY
                                                                  +   + ru J       ('tO)



The   miniraim of the above equation is again easily fomd:

        u-          Cr + (1 +
                                 H+1)b]
                                            -l    (1
                                                         +Hj+1)abY
                                                                         (141)



          V*(yj)             +                                           (142)

where

      H
             (1 +
                    H.1)a
                              -
                                  [r +   (1 +
                                                 H1)b J -1(1 + H1)2ab            (43)


                                  (1 +
                        F1 +             H1)cm
                                                                                 (144)



The equations (141)-.(4Lt) along with the initial conditions FN:O and

H :0 are the solution to the problem.
  N
         A suboptiil technique of solving the original problem is
based on (4l)-(144) and is usually referred to in the literate by the
name of certainty equivalence or enforced separation (from here on
abbreviated as CE).          It is the    follring,

a) At time k we are given the data and k_l hence the folling
quantities can be computed via the results of
                                              section 3:


             k-1 I /k-l ,bkli                        and
                                                 '

                                                           Ik-l
                                    —15—




b)   Equation ('+3) is solved bac]<ward    from   time N until time   k+l   with   the

fo1ling conventions:
         1)   a ak/k_i)
                                  forallk4 <j<         N-i
              b
               j - /k-l)

       2)
Denote the solution by

c) The control at time k is found by the follci..ing equation:
                  +   (1      )b,kiJ _l(l    +                              ('+

              This   soptiirl technique is usually the one against which           rrst

people   compare their suboptim1 methods. It is one of the simplest and
fastest suboptinal techniques and therefore it is attractive. It will
be compared with other suboptini1 methods at a later section. It is
interesting to see that if the parameters are ]<ncwn exactly CE reduces to
the true ntrol         l (141).
                                —16—




6. NON-DUAL SUBOPTIMAL MEIHOt6.

          In this section we shall examine various suboptima]. techniques
that have been suggested in the literature. All these techniques will be
non-dual, in the sense that they calculate the control la.i at   t k under
the assumption that there will be no further measurements after tinie k.
          There are three rrain elements of a dual control. The first
which can be called the controlling element has to do with the effect of
the control on the criterion function and is the element that characteriz
all optimLnn controls, dual or not. The second characteristic is a
learning one, namely the infoxration that is accumulated over past controlling
stages is utilized to ijirove the present }aledge of the system. In
section 3 we analyzed the way that optimel learning will be achieved
in our problem. The third element, which we shall term the dual effect,
has to do with the experimental nature of the control. Choices of present
controls affect the futine probability densities of the urijczncwn parameters.
Hence a dual control can affect not only the present but also the
future learning of the system. It will be this element that will be
missing from the suboptimel methods presented in this   section. In all
subsequent methods, learning will occur via the method descrised in
section 3.
                                       —17—




6.1   Wouters' Minirr&nrt Variance Control.

            This method was proposed by Wouters (1972). It is quite simple.
The logic is the following. Suppose that the objective is to minimize
the index;
                     N
             him   1 E     y2(k)                            (146)
           N-'° Nkl
then   the control suggested by Wouters (to be denoted by the letter W) is
                      —   ak/]<]                             (147)
                          bk/K_1

             Notice that (146) is quite different than our objective (6).

It   does not,   for example, include penalty for the     control.   Wouters

used   this technique to control systerrs with tirr varying parameters.
He showed via Monte Carlo experiments that the method is better than
no control    at   all.

6.2    Wies lander's and Wittenmerk      's Control.



             This method     (hereby   denoted as WW) was proposed by Wieslander
and Witterumrk (1971). Their idea is the following. Since the reciasive
equation (30) cannot be solved analytically for rrre than one step,
assume that the next step is the final one. The index to be minimized
in their paper was Ey2(t). The control that they derived is the same
                                   —18—




one   as in (32) with r 0

                    -
                        [Eb,yk,(u) k_i)]   _(bk/yk,(u)k_l)yk


           In    the experiments that they did they   compared this control

law   to no control at all, and it performed better. Since it is not
obvious that any control will perform better than no control, their
method deserves some attention. This as well as the previous method
ignores penalty in the control. Hever, in this case it is quite easy
to introduce control penalty. In fact the rrdified control law (to be
denoted by WM) is identical to the one in (32).

      u         -
                    [r + E(/yk,(u)k_l)      E(ab/yk,( )k_l)y (9)
            It   is interesting to notice that none of the previous three
methods reduce to the true control law, derived in section 5 (equation
(l)), when the pararrters are krown exactly. We nc examine a method
that has this desirable property.
6.3 Sequential Stochastic Control.

            The logic for this method is that at time k all future
infortion is neglected. Hcwever, it is recognized that the pararrters
will be changing. The assiunption then is that the distribution of the
future values of the parameters will not be affected by the future
measurements. This assumption is similar to the one that assumes the•
future   parameters to be random drawings from a distribution which
depends only on inforniation up to time k. The difference here is that
                                                         -19-




the   distribution is different at every point in time. This method has
been mentioned by Yoshida and                Nakamura (1973),             but they have not analyzed
it carefully.         We nc.i derive         it in detail (the method will be abbreviated
by Si).
                                                                      kk-l
                Assume that     we are at time k and we have observed y ,u
Hence we have computed /k1 and MK,.kl with the help of the Bayesian
foniniias   developed in section 3. The problem ncw is the foflcx'zing.
(loose                  . . u1   so as to        minimize

                         N-i                             k
       V(y )
            k
                     E' { E    (y
                                 2
                                         +       2
                                             ru.)Iy          k     1
                                                                                          (50)
                         jk j+l
subject to

                                     +
                yi+l zP
                                                             j >k                         (Si)
                p.     =p.
                         j-l+w.j—i
         The assumption that we are iiking can na. be stated precisely.
The vector p of parameters at time j > k will be assumed to be a random
dr'iing from a         Gaussian      density with mean

                                                         =                                (52)
                j/k-l         j-l/k-l                        (/k-1

and   covariance matrix
                                             +       R       •..               + (j—k)R          (53)
                Mj,k_l        Mj_l/k_l                                 Mk/kl
                                                          —20—




                              j       j—l )                          k k—i
Thus we approxirrte p (P /y ,u                 by p( p /y ,u                 ).   The dynaniic     prograrrining
recursion nci can be analyzed. At the fisial tiir (30) becomes

      V*(YN_1)                    +
                                       -i  2
                                                     /
                                                           N-i N-i }
                                                                     ,u

                                  2
           E {
                 a-1y2
                    N-i    + b2
                              N_1UN_l
                                      +
                                                          N i        + 2_ibN_1_iyN_i       +




                      +
                          2bNiicN_i                  +
                                                          Ni'   2         N-i N—2
                                                                            U         }


                          2       k k-i )
         m [y1 E(aNlIy ,u                            +
                                                          1E(1/yk,ui) + a                      +


                                  k    k-i
                                               ) +       i'i2
                                      ,u



          Let us nci decorripos e the           matrix N.     as foiiais:
                                                        J/k—l



          Nj/ki                                                                                         (55)




Referring to   (10) and   (55),    (5'4) reduces                    to

       V(y1)               [y2Ni(a2Nl/ki +                           -iIk-i       +
                                                                                      u1[r +
                                                                                                               (56)
       (bl,kl     +                    + a2          +
                                                           2iYNi(i/kibNl/kl                         +
                                                                                                        -i/k- J
                                                          —21—




The   control minimizing the above expression is

                   - [r +         (b11 -l/k-lJ -l (& llbNl_l + -lc-lN-l
      V*(yN_1) =                              +                                         (58)

where
                  (aNlfk.l *                   N1fkl +
                                              N-l/k-l       —
                                                                Lr +                     N-1/k-1
                            N-l/k-l-l-l + _1_l)2                                         (59)
              =                                                                          (60)
                       C

             If we nci assm that
            v*(yL)                H.1y2.÷1 +                                            (61)

then by     an analysis           identical to that of section 5 we derive the following:
                                                                                   -l
        u          -
                           {r +   (1      +
                                              H41)(bp_1
                                                                 +
                                                                       /k-lJ            (1 +
                                                                                                H÷1).

                                      +
                                          /k1 y                                         (62)


                       =                  +                                             (63)
        V*(yj)               Hy
where
                                                  +              -
                  (1 +
                            H+l)(a,kl                 M(k_l)
                                                                       -1
             + (1:4         H+l)(b,kl +                                     (1 +
                                                                                   H1)2(a 1b + jIk-l
                             +    (1 +
                                              H÷1)    c                                 (65)


              =                   0                                                     (66)
                    FN
                                                   —22—




              The   optimal       control     at   time   k is chosen as folics:

                                                                      (67)

          *
where  u is derived recursively as above. After this control is applied
k+l is observed and the cycle is repeated to choose       and so on
until time N-i. It is interesting to note that when the parameters
are knc.in exactly the control derived by this method is reduced to
the true optimal control described in section 6. When R =                          0   or
equivalently when we assume that the parameters are constant, then
Si reduces to a method that has been analyzed anng others by oki
(1967),    Bar-Shalom       and Sivan         (1969), and    Prescott (1967).

6.    Open Loop          Feedback Opt irral (OLEO) Control.

              This   method has been analyzed by Tse and Athans (1972) and
Ku and Athans (1973). The assumption under which the control at tune
k is found is that the sequence Uk ,Uk+l                        UN1 will not depend
on any future data and hence can be found at time k by solving an
open loop control problem. Let us make this assunrption inure precise.
The problem to be solved at time k' is the following.
                                                                     - +r          u2. 1 (68)
     V (y )         irdn                 '{   E(        y.1/y   ,u            E
                Uk,Uk+l               UN_i        j4z                        j:k



subject   to
                                   +
                           zip.        c      2
                     =            +                             k                           (69)
                                           —23—




Notice   that the expectation in (68) does not include the control teni.
This is because they are to be chosen in an open loop fashion. The
solution to this prcblem is quite complicated. We shall present here
an outline of it and we shall irntion the simplifications that were
employed by Tse and Athans, and Ku and Athans.

            The problem in (68) and (69) can be solved via detenrilnistic
dynamic proarrming as folls. Denote by V (J) the quantity

         Vy)                              E { Nl (v?+l +
                                    ,UN1        1-J
                     UU4.1
                               E{                                 (70)

           uu+1
                mm
                                     ij     (y?÷1+    ru}Ik—l}


Then   the dynamic pr graming recursion is


       V*(yj)        mm   E          +     ru     +   V(yIk—l )   (71)
                     Uj•
Notice   that since E(.Ik—l) is kricwn at time k, (71) is a deterministic
dynamic prograning recursion.
            At the final step we obtain
          *N_l )
         V (y         =   mm
                                     2
                                E(yN +
                                                  2
                                    —24—




          min       E(1y1 +                + 2lbNlUN1yNi         +2_lYN_iCN_l +
          UN-i

                  + r1/k-l)
    rnin{ E(a1y1/k-1) + u1 [r              +   E(b1/k-l)J   +

    UNl
     2uN1E(aNibNlyNl/k_i) +                }                         (72)


The optin.i OLFO uNl is

    *          —1
   UN_i       EN-i   N-l                                             (73)


where
              r +
                    E(b1/k-l)                                        (74)


     N-1 = E(aNlbNlyNl/k)                                            (75)



                 =
                     E(a2N      1/k-i) -   D1 f1      +              (76)

          Notice     an interesting phenomenon. Since in the state equations

(69) a, b, and   y   are coupled in a nonlinear rrnner one cannot separate

E(a_1y1/k-l) for example into E(a1/k-l)E(y1/k-l). Hence no

interesting   cancellations will occur in the      steps prior to the last.

To illustrate this paint we will shi without proof (which is straight-
forwani) the OLFO control and the cost at time N-2.

                 —D N—2N—2

        r + E(b2       +
                           12/k-l) DlE2(llbN2_l) (78)
                                       -




 N-2    E(2bN2yN2 + l2bN2yN2/k_1) -

                             E(aMlbNlbN2fk_l )                        (79)
                                            —25—




       *N._2           2    2       2   2    2          - D—12
      V (y     ) E(aN2yN2       +
                                    a1a2y2/k_l)               N_1E (aN   ibM laN 2N 2/k-l) -

       t:     f_2
                                                                (80)



              Thus   we can see that the exact solution for the 0120 control
at time k becomes increasingly laborious as we proceed in the bac3iards
induction. The problem arises because we have assiied that aj as well
as b are random, and this introduces the nonlinearity in (69). Tse
and Athans (1972) assumed that only b is random while a is not. In such
a case
                                             +
             E(÷1/k—l)          aE(Ik—l)           uE(b/k)
                                                                  (81)
              E(b. /k-i)        E(b.Ik-1)
                 J+1                J


and   therefore the conditional expectations evolve linearly, rrking the
bac1.iards induction of. reproducible form from step to step. Ku and
Athans (1973) on the other hand have used the approximation
                                                 +                        (82)
   E(Y+1Ik1)               E(a./k-i)E(Ik-1)          uE(bIk-1)

Their    extensive 1bnte Carlo results shed that OLFO in conjifflction with
(82)    performed    slightly better than CE (or enforced separation, as they
called CE), for stable systerrs, but considerably worse than CE for uistable
aies.
                                        —26—




7.    DUAL SUBOPINAL MEIHOLS.


              Dual methods assume explicitly that the choice of the present
control will affect the future probability densities of the parameters.
Hence the control is inevitably a nonlinear fumction of the present state

and in rrcst cases quite a conplicatéd one too. We shall analyze three
quite different dual methods, the last one appearing here for the first
time.

7.1 One-Measurement-Optime]. Feedback Control.

              This   measurement   was developed          by Curry (1969-1970), and

has been      recently used by Tse et.al. (1973), Tse and Bar—Shalom (1973),

Iausser   and Freebaim (1973),          and    further analyzed        by Early and   Early
(1973). The idea is the fol1cxiing.


               Suppese   we chose uk                .   Then we could find the   covariance   of


k given {k ,k_i                   via (25). We could also assert that the
average value of k+1 would be


                  k+i        k+l/k-l       a/_i               +
                                                                  bk/k 1
                                                                                      (83)


We could      then consider     the problem

                                               N-i        2          2 k—      k-i—
        k—,              -

                      iian             E   {    E   (y11 + ru)/y Yk+lU ,uk}
     V(y ,y1)
                     Uk+l        ,UN1          ik+l
                                           —27—




with initial conditions

                                                                (8k)
                        "k+l/k-l
                                                                (85)
          k/k            k/k—l

                           —l
          M—l       -
                    —     M        +   ,     ,                  (86)
             k/k           k/k-i            ZkZk


where

                                                                (87)
                   LYk']
The above problem is solved via the OLFO rrthod and the following ninther
is computed.

             V(yk,)                    +
                                            ri     +
                                                       VoLFO(yk,k÷l)
                                                                         (88)




             Now   a n value for                 is chosen and the whole procedure is
repeated. The usual procedure is to start with the CE control and then
search in the neighborhood so as to find a better control. The control
minimizing V(yk ,) is applied and the nthod is started an&i in the ne'c
tine step.
             The nthod has at least one advantage, namely that it guarantees
a better control than the starting one which can be the CE one. Tse and
Bar-Shalom (1973) have shown numerical results in which this method was
better than CE by one order of magnitude.
                               —28—




          The rrin disadvantage of it is that in general it involves a
search in a rn-dimensional space, where m is the dtrrnsi-i of the ccntrol
vector. Unless the control space is bounded, this search will result
in a local rrn mum of V(yk) with respect to Uk. In addition, as was
seen in section 6. 4, the exact OLFO control is hanl to find and approxi-
n.tions might be used. In such cases the quantity V0 in (88) is
substituted by an approxinute one. Therefore, the minimization of (88)
with respect to     will be an approxite one.

          Modifications of this method are easy to visualize. One which
seens to us particularly appealing is to substitute for VOLFO in (88) the
quantity V1, namely the cost computed with the Si method analyzed in
section 6. 3. Without some numerical studies it is quite difficult to
assert a-priori which method would perform better.


          The dual nature of the one-measurement-optimal feedback method
is menifested by the fact that the covariances of the parameters at time
k+l are explicit functions of the control applied at time k. The dependence
of the future covariances on the present control is nonlinear and quite
complicated. Thus since it is hard to compute the explicit dependence
analytically numerical evaluations have to be made. For on line
applications this can be quite costly.
                                        —29—




7.2   Adaptive Covariance thod.

           This quite interesting rrthod was proposed by McRae (1972).
Here we shall present the mJn idea, and we shall extend her results
to our problem, and give them a shape suitable for ninrrical computation,
which she has not done.


           Suppose we are at tirr k and we have observed    and k_1.
We would like to choose u ,uk,... ,uNl so as to rninize the
quantity

                                  N-i   2
           V(yk)         E {
                                    (y11
                                            +   /yk,Uk_l}
                        N-i       ik
                E{       E (y1 + r4)/k—l           }           (89)
                        i=k
subject   to

                         +                         j> k
               zp             g                                (90)



        p(pk/k_i)
                    =
                         N(pk/kl,M,k           l               (91)

Our fut 1aledge of the parameters p will be governed by the posterior
density of p given future data. From section 3 we kncw that the future
posterior densities of p will be norrr.l with means and covariances
evolving by the formulas:
                                            —30—




                                            +
             M1 [M-,_1P,_1                      lz!y1J            (92)




    N'       =     N'         + 1 ZTZ                             (93)
      i/i                       GC

              =                                                   (9k)
    pj/j_1        P_l/_l
    N..
    J/J_l
              =11.
                   Ji/J'l
                         .     +R                                 (95)


for j > k with initial conditions given in (91).

            In vi of (90) the constraints (92)-(93) are stochastic. We
mike the folling appro±rtion similar to McRae '5, that renders the.m
deterministic.        We asstune that the evolution of means and covariances
will be deterministic and given by the fo11iing formulas.


            pj,j M1 [M_1p,_1 + E(lzty/k-l)]                          (96)


                      N'        +
                                        E[1 z'z
                                                                     (97)
             j/j                             j j/k_1J
                        =                                            (98)
                             p.1151
            N. .        = M.        .     +R                         (99)
             Jim.-1          J—l/Jl
Thus the future means and covariances are fiiictions of quantities that
are to be calculated at time k, i.e. Uk,Uk÷1...
                                          —31—




Let   us analyze (96)        a little further.



   E(1 z'y
      2£      jj     /k-i)     1 Ez'E( /y,u)/k-l
                                c

       1 E 1z'zE(p/yJuJ)/k_1]

             E        p                                          (100)
                              1k—i]
       (ye
                   JJJ/J_i
                     is deterministic it can be factored out of (100).
Since
         p.,.1
Therefore, (96) becomes




       p.,.          M5,5 [1/j_1
                                         +   E(lztz/k_l)J                (101)




Equation         (97) nci    implies that

         pj/j        Pi/il          Pu/u         = •• k/k-1              (102)


Thus implicit in assumptions (96)-(99) is the fact that the future
mean is not affected by the controls but the future covariance is via
 (97).       The problem that we solve is        the foi1cing.
                 Minimize V(yk) in(89) with respect to

subject          to the   stochastic   constraints (90), and given that the   future

densities of the parameters have means given by (102) and covariances
                                                         —32—




by   (97). The problem that we pose is both stochastic and deterministic
because half the constraints are stochastic, namely (90), and half
deterministic, naily (97). We solve it, foUaiing McRae, by applying
dynamic proairoiii.ng to a criterion which is (89) aunted by products
of the deterministic constraints and deterministic Laange multipliers.

               The complete analysis is given in appendix A.                                    The result is
that the controls u, ,u                          ,uMl are linear fiuictions of k
     'N-l respectively with gains given by the solution of a two-point-
boundry-value (TPBV) problem. The complete set of equations is the folliing
(For prcof see appendix A).

          u.
           J
                   —G1F
                     j        ii y
                                                                                          b
                                                                                                  (103)

                                             )(b 2                            )       1 L
          G.
           J
                  r + (1 + K
                                       j+1       i/i—i
                                                           +
                                                                   i/i—i          —       j
                                                                                                  (lOLt)




                   (1    +
                              K.1)(a.1 1b.1.
                                                                   +                  -   1L      (105)



                                                     +                 )   - —1       - GT1F
          K.
           J
                  (1 +       K.
                              j+l
                                     )(a?
                                        jlj—l
                                             .
                                                          3/3—1
                                                               .
                                                                                  j       j j
                                                                                                  (106)

                                                                              C


          L.      (I + RN3/3•)1 L. (I + M1.R)1 - M. .P. N. .x.                                             (107)
           J                    j+1     j/j       3/] 3+1 J/] j+l


          P.                 1         -GF.
                                                                                                   (108)
                         —GF.           GT2F2
                                  3]     J




                                                                                                                   I
                                    —33—




 x.   E(y?/k—l) + x         ti'   P (p       p'         +   M
                                                            j—l/j—2
                                                                      )}   (109)
                         j—1      j—1 j—1/j—2 j—l/j—2



             [a] jiji
               3/3
                                    pjl/jl         =
                                                       /k-1                (110)


        =            +1                                                    (111)
                           Px

               M.11.1 +     R                                              (112)
  N.,.1


The bounda contions are            0, l 0,                      /k1 and


            The solutions of the above equations must be carried at each
step k and only uk applied to the system. Then a nz measurement is
taken and the procedure must be repeated. What is interesting about
this method is that the future controls are linear and influence all the
future covariances. We have not as yet examined nnnerical ways to
solve the above TPBV problem.
7.3 o—Step Optirrl Adaptive Control.


              This method, to o kncledge has not been suggested before. The
idea is the follci.dng. Msir that we are at time k having observed
k,k_l. Then assune that optimization is to be done only for two rrcre
periods. Also assiniie that the one future value of the parameter b is
and equal to bk/k l Then carry out the two-step backward dynamic
pxgranining recursion. The assi.niiption that bk+l is constaiit and equal
to bk/k is sufficient to render the minimization with respect to
Uk equivalent
              to minizatim of a quadratic function of Uk.


             v(yk)   =   min E        +   ru + v*(yk),k_l]     (113)

                          Uk

where

             V*(y)         rain   E [+2 + ru1/k                (114)


At time k+l the minimization (ll'l) is straightforward. We obtain

                                                               (115)

where
                  Cr +                                         (116)

        !c    +
     V(y                                                        117
                         k+l


                                                                              CY
                                               —35—




where



       H ak+1/k +              +1/k
                                      - (r + b+)           +lak+l/k
                                                                                   (118)




                 C                                                                 (119)


             At tine    k we    have

         (y )         mm   E [(1 +
                                   H)yk+i+
                                               2
                                                      r 2 + F/k_i]                    (120)




From   section 3 we     kncw that



                 c/k s/k-i
                                       +
                                           /k-1kkk/k-1            +
                                                                      aE)   k+1
                                                                                  -
                                                                                      k-ik         -bk/k_K)

                                                                                       (121)

                                           -                                                  (122)
  +1/k /k                       /kT1

If we substitute for                  in (12!) the innovation becomes




                                               bk/k 1)Uk +
                            +
              a]</)y]            (b<
                                           —
                                                             Ck
                                                                                          (123)




We   nake the assl2llption
             —              =    0                                                        (12'4)
       (bk       bk/k_i)
which   is what      will render      the prob1n tractable.
                                        —36—




Of course,   if bk    is a—priori kncn then           the     assumption (12'-i.) will       be

a true fact,   and    not   an   approximation.


             By substituting for ak+l/k,M+i/k in H, via                      (12l)-(122)      and


substituting for k+1 in (120) we arrive at an expression whose con-
ditional expectation is easy to take. In addition the resulting

expression is quadratic in uk. The calculations are lengthy but
straightforward and they. are shcwn in appendix C. The optimizing

is   *           -l                                                                  (125)
    Uk        -D kk

where
                                                                                                        ()
             r+   (1 +   +i/k/k-l /k-l     +                  +       r          {a2k,kl
                                                               r +
                                                                      bk/k   1


         (bkl +       /k-l       +
                                     X{E E(ak - K/k_l)hJ y +

                      + /k-1                                                         (126)



         =
             k    { (1 +
                            ÷l,k1kP                   +           r
                                                                          L/k_1akbk_1)
                                                                                                    +

                                                       r + /k1
                                                  +
         L yE [akbk(ak - ak/kl)/klJ                   E(ak/k_l)]                 +




    2l)kE                            - akfl)k1}           +
                                          —37-.




                                     -                       +                          (126)
                                           k/k_l)/k_Jc           2ak/k_lbk/k_lX1o)
         2
 r +
        bk/k_i


where


      Xk       c—lk>'k/k—i +               2)l                                  (127)




             The control Uk   is   thus   a highly nonlinear function of
We can also    see   that even   if we rrke the assuntion that bk
to bkl/12        it is impossible to carry out one rrre recursive
dynamic pro'anining step because of the           complex nonlinear    dependence
of   V (y ) on


             This   control 1 is      dual   and it takes into account futi.ae
adaptation     of the mean but     not the   variance   of   a. It is quite   simple
to   compute   since it does not involve the solution of any iterative
system of    equations   like the previous methods.
                                        —38—




8. NUMERICPJJ COIARISONS


            In this section we sh the results of some initial Monte Carlo
comparisons of all the non-dual methods mentioned before except the
OLFO one, for which exact corrtputations are tedious as seen in section 6. Li.
and   inexact computations give strange results (cf. Ku and Athans (1973)).
            The methods compared are denoted by the fo11aiing initials:
            T - Control with perfectly kricwn parameters (cf. section 5)
            CE - Certainty equivalence method (cf. section 5)
            W —   Wouters' method   (cf. section 6.1)
                 -   Wieslander's and Wittennrk's method          (cf. section 6.2)

            WM —     f'bdified WW   (cf. equation (L1.9))

            Si   —   Sequential     stochastic control   (cf.   section 6.3)

For all   the   methods   except    T, which   does not involve learning, the

parameter   updating was done        with the Kalman   filter analyzed    in   section   3.



            We n state the results for four experiments that were
conducted. Table 1 simrizes the conditions of each experiment. The
first colunui denotes a code name for the experiment. The second coli.nrn
denotes a code name for the tn.ie parameters used in generating the data.
The third coluun lists the covariances of the system error. The random
nibers that were created had the indicated covariances and were normal.
The N0 colurrm lists the initial covariance nitrix of the parameters. For
every run the     initial   values of the parameters were chosen by random
sampling from a normal density with mean p0, listed in the last colnm,
and covariance matrix       M0.
                                    The colunn labeled R lists the covariance
ntrices used for the error ter in the parameter equations (cf. (7) and
0                                                             fl
                                  Table 1.         List of Monte Carlo Experinnts
    EXPERIMENT         TRUE COEF.                   M              R       No.   of    RUNS              r
                                                                                                Y0

                          AB1          .25                   l0I                 20             3        .3   (.8,.2)
        E1                                        1o_212

                                       .25                             0         20             3        .3   (—.63,.083)
                                                  lo_212    [.09

                                                            [o .01
                          J33          .25        10212      io_2i               20             3        .3   (.8,.3)
        E3


                          AB'4         .25                   io_2i               20             3        .3   (.6,—.2)
        E5                                        lo_212


                                                                                                                             CA)
                                                                                                                             (0
                                 Table 2.         List of Average Cost in Experirrents
                           T                 CE                    W             Wv1                WM                  Si
             MErHOD:
    EXPERIMENT
                         20.158         20.237              93.444            61.258             20.507            20.189
        E1

                         29.524        625.557             5185.37         23584.1            3.386 X           64009.4
        E2


                         19.661         20.921              272.849           31.333             21.997            20.76
        E3

                         16.412         17.99                47.485           27.421             20.552            18.257
        E5
                                   —[10—




(10)). The rerrining three coluirns list the nuither of runs, the initial
value of y0 and the control penalty r respectively. All runs were for
30 periods.

          In   experiment   El the true parameter at was constant and the
true bt was a sl.i trend. In E2 the true at and bt were generated
using equation (7) with initial values (-.63,.083), as shn in the
last column of Table 1, and normel random errors with zero    means   and

covariances o .09 and                 .01. In E3 the true parameters were
both tine varying with some trends and sudden jumps. In E5 both
the parameters were constant with at equal to .7 and bt equal to - 4•

          In Table 2 we shc the average cost for the 20 runs. The
first thing that we notice is that the       method performe quite well,
surpassed at some experiments only by Sl. We see that the W and WW
methods which are minimum variance ones involve excessively high
control cost. In experiment E2 the parameter at was umstable for
half of the controlling period, and we see that all suboptiinal methods
perfonn poorly. This is a disturbing fact and was also observed by
Ku and Athans (1973) in their simulations of the OLFO method.


          Figures 1-12 shi the average control gains and the
average parameter estirrted resulting from the 20 Monte Carlo rums
of each experiment. it is interesting to notice that for E2 in
which, as seen in Table 2, none of the methods gave good controls,
                                                                            U
                                  —tl—




nevertheless the estirrates of the parameters are quite satisfactory.
In general W, M, and WM give the worst results with CE and Si aays
superior to those three. The experiments, hcever, did not result
in a distinct ordering of CE and Si.


          There is still a lot of work to be done in arrtparing these
methods and corrparing them with the dual methods described in section 8.
The dual methods should give better results than the non-dual ones.
On the other hand the dual ones are all, with the exception of the
one described   in section 7.3, quite costly.
 0.0



—1.5




                                      16


  TIME Bout IC'S:     I TO O
 SYMBOL         .A.LE I44ME

       .•        *1    E1_TG

       '        #1
                *1
                *1
                      E1_C;G
                      El_LJG
                      El


-cj.




—0.




—0.70




— .90
            1


   TItlE E:OIJt11r     1 TO O
   SYMBOL .CkLE

        I.
        U        *1    ELIC
                 *1    El .1iC
                 *1    El      1C




                                                        -)
                      Figure 1. Control Gains for El.
                                           ...t. 3—.




o 780




o 74Ct


     I IME EOIJtl[i:-    1 Iii ?."
     SVt1E)L .I. HLE tIHME
                  *1
         •        W1     El _':F':_ci
         •        *1     F. _WC...C I
                  *1     E I ._LUIFCJ 1



0




0.




    TItlE F:riI.I,lCr   1 T'' )
    (tiEOL        LE    fr ir1E
        ••       $1
                 *1     F _1.11FC....C 1
        •        *1     E1_:IrC1




                  Figure 2. Estirra-tes of             in El.
                                           _1.ltl-.




rU.




0. 1'

      I tilE E:OIJt t'     1 TO 13
      SYT1EIL      iLE PIHIIE
         0          01
          •         *1     E1_'F'C_C2
          •         *1     E t_NFC•_C2
                    *1     £ 1 _LJLJP:_C




  0. 220




  0.1951

       TIME        ''IC'    I TO
       SYMBOL SC L.E
              ••     01     HE1.C.
                     *1     Cl _WUFC_C2
              •      *1     E1_IFC_C2




                         Fig'e 3. Estin±es of bt in El.
                                   —'t 5—


 2t3.




  0.




-20.

 TIME             I TO 3
 SYOL ';CLE       U-iIiE
    S
    ••      *1
            *1
                  E2_TG
                  ECG
            *1    E_W(
            *1    E.WL.ii..


 4.0




 i.e




        I         t.          It            21    26   31


 TIME 6OIJtID 1 TO O
 S?I1EOL kLE
    ••      *1
            *1    £ ...WflG
        •   *1




                 Figure . Control Gains for E2.
                                           —'46—




 U




                   6                 11      16          26    31


Ti ME E:Ot [t:     I TO
smEi:'L JHLE tIiME
   .     Ui   iF:2_Ct
  6
     '   #1
         $ 1.
              E..iPC_C1
              L JJFI_C I
             II     E_MWFC_C



3.0




 1.0




-1.0                   6              11       16   21    26    31


 TIME EOU(iS        I      IC'   0
 S'/I1EOL SCLE IIktlE
         a
         •    *1       Ejn1P':_CI
         •    In       E..1p1:_c1




                   Figure 5. EstimateS of at in E2.
-0.20




—0.60
        1



  TIME EOut•40S 1 TO        Li
  SYMBOL iLE       tlHr1E
    ••      *1      E2.C 2
            $1      E:_C FC _C2
     •      $1      E2_WFCC 2
            Ii      E2_WIIPC.C2




-0.20




-o.,0                              11      16      21        26   31


  TItlE EClIHC,.    1 10 31)
  SYMPJ)L        LE NH1E
        •    41     ,.4F;:_c2
        •           E2_1fliFI_C.
        •            E2_S I FC_0




                   Figure 6.        Estimates of bt in E2.
                                 — 8—


1.0




—4.0




                                                      31



 I I ME ROUt         1 TO 30
 SYMBOL     C:LE     4H1E
    S          *1    E_TG
               *1    ECG
               *1    E3JIG
    a                EJMG




—0.25




-€1.75




—1 .25



  TIME E;C'IJlCS      1 TO 30

  SYTIBOL .Cr-I.E N-r1E
        •       1 E3_TG
        •       *1     ETJr1G
        •       Ii     E?_S1G




                    Figure 7. Control Gains for E3.
                                               —t 9—

I . (it)




0.50




0.




                                          11           16   21   26   31


 TIME E:01IHD 1 TO O
 SYMBOL !LE
       •                   E:3...C I
       •            *1     E_CFC_C 1
       •            *1     E3_WPC_C
       N            *1     E3_wI•IP':...: i


     .00




(i50



     @13




-0.50


   TIME         E;OIJUOS   1 TO
   SYMBOL cc.,LE           I h-i? E
           ••       III
                    *1
           •        *1      E3.1FC_C1




                      Figure 8. Estimates of at in E3.
                                                    —50—



Ci.




0.40




—0.40
             1
                               -
                               D               11          16   21         26   31


  TIME BOIJnO,                 1 TO 30
  SYMBOL SCALE I1-fiE
                               i.E:_C2
         .
         U           $1
                     *1        E_C:PC_C2
                     *1        E3_IIPC_C2
         a           *1        E_fl4PC_C

  0




  0.40




      ci .00




        TIME flIJpciS              1   TO 30
        S\IIBOL SCALE
                 U        *1       B_C2
                 .        *1       E.3...UMPC_C2
                          *1       E3_S1PC_C2




                               Figure 9. Estintes of bt in           E3.
                                         —51—


2.




                         *                                  - --
                  4- -S 4 I- -5- .- -b    -S 4 •   4


         1        6             11                     21          3'

 TIME EUL:L3      1 TO   O
 SYMBOL
     S       $1   E5_TG
                  E5.. I.UG
     S
     U       hi   E5_S 1 G



3.25



2.25



I 25



8.251

 TIME BOUHOS 1 TO 30
 SYMBOL SCALE MAfIE
     °       *1    E5_T
     •       *1    E_CG
             1     E5_t1G




                  Figure 10. Cono1 Gains for E5.
                                      —52—




0.600




  TIME fiJ,:         1.10 .3i
  SYPOL SCLE t1t1E
     ••       *1     84_C 1
              *1     E5..CF'C_C 1
     •        *1     E_LPC.C I
     •        *1     E5..L'4WPC_C 1



0. 72




 0. 625




 0.5?5


   TI ME jJc:         1 TO 10
   SY?IBOL SCALE W4ME
          o    $1
          •    #1      E5J1PC:_ r t
          •    *1      E5_SIFC_C 1




                    Figure II. Estiirates of at in E5.
                                                —& 3—




—O 2S0




—6. •350




—6.450
           1              6              11             16    21       26

    TIME BOUNDS           I TO 30
    SYMBOL SCALE t1ME
       o
       •                  4_C2
                          E3_CPC_C2
                 #1       E5_kJPC_C2
                 *1       E5_WWPC_C:2




  —0.100




  —0. 200




  -e.:3e0



                ..    U
                              b            11            16    21       26   31


      TIME BOUNDS             1 10 30
      SYME:OL   £CLE MME
           ••    *1
                  *1
           •      *1
                              E5...I4MF'C_C2
                              ES_S 1PC_C2




                      Figure 12. Estimates of                 in ES.
                                  — 5i—




9.    SUMMARY AND CONCLW IONS.



            In this paper we have examined the problem of controlling a
system with parameters varying in a fashion unkncin to the controller.
We have surveyed all methods available for the solution of such problems
and we have extended some to fit our framework. We have also suggested
and analyzed two methods for the first time. One is a non-dual one (Si)
and the   other is a dual   one (see section 7.3). We have   also   presented
a    numerical comparison of the non-dual methods, in which Sl was     foumd,

along   with enforced separation, superior to other non-dual methods
that have been suggested elsewhere.


            A mejor problem with all the methods is that a-priori there is
complete ignorance about the evolution of the parameters.           From

figures 5 and 6    it was   seen that if the parameter variation happens to
be of the same form as the one assumed, then these parametErs are
estinted satisfactorily. Otherwise, we do not have large hope of
identifying them. This raises the whole issue of robust estintion for

some particular kind of parameter variation, it is not clear whether
it will give good results if the parameters evolve according to a
different structure. The ultirate goal, of course, is to optimize
the criterion. The interaction between identification and control might
be somewhat umderstood in the case of constant but urJin parameters,
                                  —55—




but it is not at all clear in the case of time varying parameters.
There is still a lot of research to be done in this area beginning with
mDre ecterisive comparisons of the dual and the non-dual methods,
extens ions to higher order systen, and examination of the interaction
between identification and control.
                                   APPENDIX A



          SOLUTION OF ThE ADAPTIVE COVARIANCE CONOL PROBLEM



               In this appendix we present the solution to the problem posed
in              The solution procedure foilcs the analysis of McRaé
     section 7.2.

(1972). The problem is the foilcx.ing.
Find
          uk,... ,UN1 where
        *k
       V (y )          mm
                                           N-1
                                            Z
                                    E' {
                                              (y1 + ru)/Jc-l}           (A.1)
                  UkU]c+l14N_i             ik
subject   to
            =
                zp       +   .                  j>k                     (A.2)



     independent       zero mean white noise with covariance

                                                                       (A.3)


                   -             - 1/1      =
                                                      kIk-1            (A.)
            Ms,.                                              j   >k   (A.5)
                        M,.1+ Eji z'z/k_l]
                                  +R                          i    k   (A.6)


            z      [y,u                                       j >k     (A.7)

            We define a set of N-k+1 matrix Lange multipliers
k-i <j     <N-i where L are all symmetric 2x2 matrices. We n form
the foiling Hamiltonian quantity.
                                                   -A2-




                          N-i
          H(yk)          E{ (y1               +    ru?)/k—i}     +

                          1k
          E   t{ L1                       -
                                              (M.1111
                                                            +   RY1   - E( 1 z'z/k—l)] I




                                                                              }
              E[y ru     +                 ltr(L1zz)/k-l] +
                                                      11
                                                                          .       +



                                      -
                                           Lk1M1/k1]

where

                                                  - L(M1111           +   R)]          (A.9)



              We   shall apply stochastic dynamic prograiruiing to the augented
criterion (A. 8). We shall be careful, hcwever, to simultaneously irripose
the constraints

              aH(y') =       0            k   <j    <N—i                              (A.lO)

                   3/3
              3Hyk)          0            k <j      <N—i                              (A.ll)



(A. 10)   and (A. ii) correspcnd to the state-costate equations for
              The dynamic proaJTming recursion can now be written as follows

              H*(yj)             min { E fw.         +    H*(y)/j_iJ +                (A.12)
                                 Ui
for
              k    <j <N—i
                                               -A3-




with
         * N                          —1                          —1
        H (y
                          E-1-i/N_i                      -i-l/k-l1
        w y1 + ru?                    1tr(Lz'z)                                (A.l'4)
                                  —




                                           -   L. (N.             +            (A.15)
             tr[L1M111
        E {.ii_iJ         E                                                    (A.16)


            The interesting thing about this arrangement is that we shall
be able to satisfy (A.iO) recursively as we proceed backwards.
          At time N we have the cost H(yN) given in (A.13). We can
differentiate it with respect to Ml/Nl since this quantity will
appear only in H* (N)• Using (B. ) of appendix B, we have

 3H(y )            H(y )               L1 +                  - DIAG(LN1)   0   (A.17)

       N—i/N—i

since the        are synetric (A. 17) is equivalent to
                                                                               (A.18)
                      *       N        -                -l                     (A.19)
                    H (y )
                                           trlk    1M k-i/k-i
            At time N-i the recs ion (A. 12) becomes

       H(y1)         mm '{ E          [y +                   - 1tr(Ll1NizNl) +
                      UN_i                                       cl
                              I_2MN_2/N_2                    -
                                                                 -1-2/N-2 + R)'J}   (A.2o
                                             -A4-




Only the first three terns in (A.20) in1ve                             We paxtition the
ntrices L. and N. as follows


                   L
                                L            L                                 (A.21)
                                LJ           LJ
                                             J



                               1M.
                                 J/J
                                             1
                                             J/J
                                                                               (A.22)
                   N.,.3]       M1).I?.
                                                    I

                                J/J  3/]


         We nc expand (A. 20)


                        N-l-l/N2 +               -l/N-2         +
                                                                    2yNl1(aN1/N_2bN_1/N_2+
                 UNl

         +
             1(r        +
                            b2Nl,I2      +
                                             -l/N-2         +         1 (1y1 +            (A.23)
                                                                       6

                                                   +                       -   -l-2/N-2 +
2L1y1_1 +                           +   H(yN)             [_2M_2/N_2


         By differentiation we find                    that the minimizing UN1 is


             *          —l
                       -G                                                  (A.2L)
                            N_lFN_l7N_1
where
                       r + -l/N-2        +
                                             -l/N-2 -           1          (A.25)
p


                                            -AS-




                        _l/N_2bN_1/N_2 +      -1/N-2 -       1                    (A.26)
                                                             a2
                                                               C


               We nc.i write H(yk) in   a form that will help the differentiation
    with respect to             dictated by (A.lO)



      H(yk)    E y/k_l] +      [    2M      2/N 2
                                                    -              + R)_1] +


            (ter not involving L2/N2)
                                        +   tr [2M2/N2 - -l-2/N-2 + R)J

        +   (te without -2/N-2 E-l/N-2N-l/N-2 + -2/N-2                             R)




        • E(11/k-l) +          tr                       -
                                                            -l-2-2    +
                                                                          RY'J     +



            (tern without M2/N2)                                         (A.27)



               With the help of (B. 5) and    (B. 6) we have


                                                                     +
                       o
                             _22/N2E(l_l/k_l)2/N2
        ThN2/N2

                                                                             +
            DIAG {_2/N_2E 11 2/N2] _22 + DIAG(2)
                                    -A6-




             2(1 +
                     N-2/N-2 -l +

             DIAG    [1 +   N-2/N-2 -l + M2/N_2R)'J                   (A.28)




             Since   all the ritrices are synutric, (A. 28) is equivalent to
the foflciing

               +
                      N-2/N-2 -l + K_2/N_2R) - 2/N_2E               [1c_i)
                                                                     (A.29)
        MN   2/N 2


                            *
             The st H (yN—i ) becous

  H*(yN_l)          2            H*(yN) + 2M2/N2 -l2-2 R) (A. 30)
where
                            -
             -l/N-2 + -l/N-2 2          _i   -
                                                 G1F1                     (A.31)



             So H(yM_l) is a quadratic in N1 and the recursion can continue.
Notice that the nonlinear dependence of           on UN2            has   dissappeared
                                                               Uk
with the introduction of the multiplier matrices. it is easy ncxi to
ite the eress ions for u.

             u -GFy                                                       (A. 32)
                                                    -A7-




where
                   r + (1 + K+1)(b,_1 + /j—1                                     —
                                                                                      :                     (A.33)


                   (1 +                                          +
                                                                         M,,51)
                                                                                          —   I             (A.3't)




          K.      (1 + K.
                              j+1
                                    )(a?
                                       j/j—l
                                            .            +           .
                                                                 j/j—l
                                                                         )   —   1 L —
                                                                                 — j              GF
                                                                                                   jj       (A.35)
                                                                                  a
                                                                                      C


          L       (I +
                         RM,.)L.1(I                  +                   - M1.E(z.1z.÷1/k-1)M.1. (A.36)


The initial      nditions are

                     'h1I—1°                                                                               (A.37)


               Along with (A. 4),          (A. 5) and (A. 6) the above equations define

a   complicated two-çxint-boundary-value (TPBV) problem. In order to define
the problem completely we need a way to evaluate
           E(z:z./k-1  for alik —<j —<N-i
              JJ
We non   provide such a recursion.

                          1         G1F
    E(z.z.fk—1)                      ii                      2                        2
                                                     E (y.Ik—l) E            P.E(y.Ik-l)                (A.38)
                            —i    —22
                          -G .F. G. F.
                               3] 3             3




    E(y/k-1) a +
              +                      +                          (A.39)
                    [P 1( l/j 2j                    E(y1/k-l)

Since E(y/k-l) y (A,39) is a well defined recursion. The TPBV
problem is now complete.
                              APPENDIX B


                   SOFT USEFUL MiTRIX DERIVATIVES



           In this appendix we develop certain matrix derivatives that are
useful in the proofs of appendix A. Many formulas for matrix derivatives
have been rexr'ted by Athans and Schweppe (1965), and Athans (1967).
Hcever, those derivatives were applicable only to matrices whose elerents
are independent. Here we derive sorre formulas for synTnetric matrices.

           Define the operator DIAG which operates on a square matrix A
and creates the fo11iing matrix



                  DIAG (A)          a11    0

                                    o
                                           a22
                                                              (B.1)

                                    0



Let X be a ni matrix and let f(X) denote a scalar valued function of
                                          .
the   n2elements of X. Then the matrix
                                    .
                                       derivative of f is defined by

                      af(X) =   f(X) 1                        (B.2)
                                {   3X)
so the matrix derivative of f is a matrix. We n state the fofldng
thorerr.
Theorem. Let X,B be synuietric nxi matrices. Then the foUing equalities
are tie
                                                -B2—




                       atrX =   I                                                 (B.3)




                   a   trAX   = A    +      A    - DIAG(A)                        (B.'4)
                 ax

   a trA(X   +   B)1      -(X +     B)1A(X       +      B) - (X    +   B)A(X +    B)       +
  ax

                   DIAG [cx +      BYA(X        +   B)']                          (B.5)




   atrA    [x' +   B]
                        -1          +   BX)A(I          +   ))_1   +   (I + BX)'A (I + )_1     -
  ax

                 DIAG [(I +     BX)A(I          +                                 (B.6)

Before   we proceed with the proofs we state for corrarison the corresponding
formulas for rr.trices whose elements are independent


                 3trX I                                                           (B.7)


                 a tx =       A'                                                  (B.8)
              ax
              atrA(X + BY1              =
                                            -X      +   aA(X +     B)]            (B.9)


              3trA( X1        + B) 1            fci + BXY1A(I          +
                                                                           )Y'7    (B.1Q)
'A




                                                       —B3—




     Proof.        (B.3)   is trivial and we omit              its    proof.




     (B.4):                                                          0
                            trAX trA             X       trA
                                                xij                  1..
                                                                      31         0


                           a.. +       a..                    Q.E.D.
                           13              Ji

     (B.5):
                  trA(X         + B)            trA    (X +     B)
                                                                     1
                                                                           -trA(X +    BY   X(X +
                  Xij                                 aXij                                  Xij

               -trA'                   +                                   (   {j,i}   1.2.,. .,n.)
     where

               xx+ B)_1]
              -tr'A'   <jkx1i

              -    E
                  1l kl         a(X'              +



              —   {cx + B)1A(X             +   BY     + Cx +   BY-i A(X + B)_1]                   Q.E.D.
                                 -B'-



(8.6):       DtrA(X1     +   B)_1 = trA a (X1   + B)'
            ax..                           ax..
              1J                               1J


             -trA(X + B)1ax1(x + BY-
                                ax..
                                  1]

                    + B)XXX(X + B)
                               ax..
                                 1J


            trA(I   +   XB)' X(I +      BXY1        and the analysis of
                             ax..
                               1J

the   prf of (B.5) carries over.
                                               APPENDIX C

                     COUTATION OF ThE IWO-STEP ADPFI'IVE CONTROL



          In this appendix we carry out the                     calculations   called for in
section 7.3. The problem is

                          2             2           2                  1
       V (y )      mm E           +
                                      r'u + Hyk+l           +    F/k-i j                (C. 1)




We substitute (121) and        (122)   into (118) keeping in mind              the   assi.n-ription

(12'4). We obtain



  H          ____              22a
               2 /k-l + '' k/k-lkk'/k-1
                                           2
                                                                    + -21
                                                                       L -lk +
                  1k+1
         2
              +                        2
                                                     +   2ir           -                  +         +
   k]                                                    G€

      + Iv+1/k                                                                         (C.2)



              We notice from (122) that
                                                  +1/k      does     not   depend on          and   is
a function of
                     kk-1 ) so we will not expand it further. To facilitate
                   (y ,u

the   notation we shall define the quantity

                  Xk_ /k-lkk/k-1 + 2)-1                                                 (C.3)


Xk is a function of           k k-i
                          (y ,u       ).


V(yk) ncw becorrs
                                                     -C2-




V(yk)        E'{ru + F                   +(aqY +               bu +c +                          2abkykuk +


              + 2c k                                 +
                                                             +1(    +


                                                                                            2
  r                          +                           -
                                                             c/k-1k         +
                                                                                    £k]
                                                                                                 +




                                                    k k-i } -
[(ak
        -
              /k-1k              +               }Iy,u                  -




            +F         +         { (1 +              '+1/kk/k-i                 +
                                                                                        /k-i         +




  r
              r2    Ik-i     2               +                  +
                                                                            fyE         ja(ak        -
                                                                                                             ak_1)(_1 +
r+            L_1_1

 a    bk/k-i +             /k-i1         +
                                                 2ak,klykE [(ak                     - /k_l_1 }                    +




                                                         /k-i       +               r                                 +
        {   (1 +   +1/kk/k-i                     +
                                                                            r + b1              [a2k,klb,k1


                   +
                            [E
                                                 -
                                                                             y          +
                                                                                                 (b/kl ÷       /k-iJ +



  (i + +l/k)a +                      r                   [a_i +                     t/k-ik               +        +


                                 r   +
                                               -C3-



                { (1 +
                           +l,k)E(akbk/k_1)        +           r           [,k_lE(abk1k_1) +
                                                          r   +
                                                                  b1÷1



  X fy [ak1ak -              ak/k_i)     1k-i] +       GE(akbk/k_1)              +




     2aK/klXKYkE tk(ak -                ak/k_i_1J         } +


                 r
                           [2E [ak(ak - ak/k_i)Ik_1Jae                     k +                     +
     2Ykt r +



  2(r                    >kE                 - ak/k_i)_hics            +
                                                                           2ak/k1bk/kla            (C.)
        (r +    b+i
                Equation   (C. if) is   a quadratic       in u,    so its minimization        is
straightforward.          We find



        *
      u     =   -D 1
                     k                                                                (C.5)

where   (remembering that               was assd equal to bk,,kl)

         r+     (1 +
                         +i,k)(bk_l +          k-1         +           r             ak/kl(bk/kl
                                                                  r+

      /k-1                               -            2
 +                   +
                           [E                ak/k-i       /k-iy            +
                                                                               ccIk-1 +       /k-1J       (C.6)
                                   _CL-




 fk: k {(i +
                                          +       r         [1E/k-i) +
                                              r + bk/k
                                                   2
                                                       1



 X2k fyE kbk<          1)2,k_il       +




                                                    +
 2,klykE [akbk( - ak/k 1)/k_1] }

                     ykE [bkak -   1)_i]a               +
                                                            ak   lbk_lXk (C.7)

 r      k/k-i



The expectations appearing in        and      k   are straightforward to compute


from   the   joint gaussian density of ak
                                              and
                                                    bk given (k ,k_1.
                                    REFERENCES



  1.   Aoki, M. (1967), "Optimization of Stochastic Systerrs," Academic
       Press, 1967.

  2. strSni, K. J. (1970), Introduction to Stochastic Control      Theory,
      Academic Press, 1970.

  3. Athans, M. (1967), "The Matrix Minimum Principle," Infontion
      and Control, Vol. II, Nos. 5 and 6, Novejrber-Decernber 1967.

  4. Athans, M. and F. C. Schweppe (1965), "Gradient    Matrices
       and Matrix Calculations ," IffT Lincoln Lab. Technical Note
       1965-53, Lexington, Massachusetts.
 5.    Bar-Shalom,   Y. and S ivan, R. (1969), "On the Optfral Control of
       Discrete-Time Linear Systesrs with Random Parameters ,'  IE
       Trans actions on Autorratic Control, Vol. AC- 1L, No. 1, February 1969.
 6.    Chc.i, G. C. (1973),   Private Corrmunication.

 7. Cooley, T. F. (1971), "Estirration in the Presence  of Sequential
       Parameter Variation," Ph. D. Thesis, Department of Economics,
       University of Pennsylvania, 1971.
 8. Curry, R. E. (1969), "A N.i Algorithm for Suboptimal Stochastic
     Control ," IEEE Transactions on Automatic Control, Vol. AC_1L,
     No. 5, October 1969.



                                                          I
 9.    Curry, R. E. (1970), Estirration and Control with Quantized
       Measurements, IffT Press 1970.
10.    Early, R. H. and B. M. Early (1973), "On the Relative Perfonrance of
       the Optirral Control System with N Measurements ,"
       Transactions on Automatic Control, Vol. AC-l7, No. 1, August, 1973.
U. Fel'dbaum,     A. A. (1960a), "Dual Control Theory 1," Automation
       and Resrote Control, Vol. 21, No. 11, September 1960.
12.    Fel'dbaum,A. A. (1960b), "Dual Control Theory 2,"     Automation
       and Rencte Control, Vol. 21, No. 11, November 1960.
                                     —2—




       Pel'dbaum, A. A. (1961a), "Dual Control Theory
                                                       3," Autorrtiofl
13.                                                 1961.
       and Rerrote Control, Vol. 22, No. 1, January
                                                               Automation
     Fel' dbaurn, A. A. (196Th), "Dual Control Theory ,"
                                                   1961.
itt.
     and Rerrcte Control, Vol. 22, No. 2, February
                                                          Academic
15. Fel'dbaUrfl, A. A. (1966), "Optimal Control Systens,"
     Press, N.i York, 1966.
16. IEEE Transactions on Automatic Control, "Special Issue on
                                              Vol. AC—l6, December 1971.
       LneaQuaatiC_Gauan Problem,"
                                                   Control of Linear
17. Ku, R. and M. AthanS (1973), "On the Adaptive
                                         0ptBraJ- Approach," IEEE
     Systens Using the Open_L op—Feedba Vol. AC-l8, No. 5, October
     Transactions on Automatic Control,
       1973.
 18. McRae, E. C. (1972), "Linear Decision with Experimentation,"
                                                         1972.
      Annals of Economic and Social Measurement, October
 19.              (1972), "Analytic Solutions to Some Stochastic
        Popevic, B.
        Adaptive, and Dual Optima]- ControlUniversity
                                           ProbleiTs for Economic
                                                       of Illinois,
        Decision Making," Ph. D. Thesis,

                 E. C. (1967), "Adaptive Decision Rules for Macro
 20.
        Economic Planning," Ph. D. Thesis, Graduate School of 1967.
        Prescott,

        Industrial Aninistrati0n, Carnegie-Mellon UniversitY,
  21. Rauss er,           J. W. Freebai-rn (1973), "Comparison
                    G. C. and
                                                                 of
                              Control Solution to U. S. Beef Trade
        Approximate Adaptive       second NBER Conference on Stochastic
        Policy," Presented at the                                 1973.
        Control and Economics, University of Q-iicago, June 7-9,
                                                      Estimation," Ph. I).
  22. jsenberg,       B. (1968), uVarying_Parameter
                                 Economics, Harvari University 1968.
         Thesis, Department of
                                 "A Bayesian Approach to
                                                         Estimation of
   23. Sarris, A. H. (1973),       Coefficients," Annals of Economic and
         Time-Varying ReesS ion
         Social Measurement, October 1973.
                                        of Econometr. John Wiley, 1971.
   2LL Theil,   H. (1971), Principles




                                                                             I
                                   —3—




25. Tse, E. and M. Athans (1972),_"Adaptive Stochastic Control for a
     Class of Linear SysteriE ," IIk Transaction on Airtorratic Control,
      Vol.   AC-17, No. 1, February 1972.

26.   Tse, E., Y. Bar—Shalom and L. Meier, III (1973a), "Wide Sense
      Adaptive Dual Control for Nonlinear Stochastic Systerrs," IEEE
      Transactions on Automatic Control, Vol. AC-l8, No. 2, April 1973.
27.   Tse, E. and Y. Bar-Shalom (l973b), 'Wi Activity Adaptive Control
      for Linear Systems with Random Parameters via the Dual Control
      Approach," IEEE Transaction on Automatic Control, Vol. AC-18
      No.   2, April 1973.
28. Wieslander, J. and B. Wittenrrrk (1971), "An Approach to Adaptive
     Control Using Real Time Identification," Autorratica, Vol. 7,
      May 1971.

29. Wouters, W. (1973), "Adaptive Minimum Variance Control for
     Linear Discrete Time Systems," Proceedings of the 1972 IEEE
     Conference on Decision and Control, December 13-15, 1972.
30. Yoshida, Y. and Nakarnura, K., (1973), "Learning Dual Control
    with Complete State Infonmation," Research Reports of Automatic
     Control Laboratory Faculty of Engineering, Nagoya Lhiversity,
      Japan, Vol. 20, June 1973.
