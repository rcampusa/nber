                           NBER WORKING PAPER SERIES




                           THE BAYESIAN FOUNDATIONS
                             OF LEARNING BY DOING




                                    Boyan Jovanovic
                                     Yaw Nyarko




                                 Working Paper No. 4739




                   NATIONAL BUREAU OF ECONOMIC RESEARCH
                            1050 Massachusetts Avenue
                              Cambridge, MA 02138
                                   May 1994




We thank the C.V. Starr Center for Applied Economics at New York University for technical
and financial help, and Chung Tse for help with the research. This paper is part of NBER's
research program in Productivity. Any opinions expressed are those of the authors and not
those of the National Bureau of Economic Research.
                                                                    NEER Working Paper #4739
                                                                                   May 1994


                              THE BAYESIAN FOUNDATIONS
                                OF LEARNING BY DOING

                                          ABSTRACT

       This paper explores a one-agent Bayesian model of learning by doing and technological

choice. To produce output, the agent can choose among various technologies. The beneficial

effects of learning by doing are bounded on each technology, and so long-run growth in output

can take place only if the agent repeatedly switches to better technologies.

       As the agent repeatedly uses a technology, he learns about its unknown parameters, and

this accumulated expertise is a form of human capital. But when the agent switches technologies,

part of this human capital is lost. It is this loss of human capital that may prevent the agent from

moving up the quality ladder of technologies as quickly as he can, since the loss is greater the

bigger is the technological leap.

       We analyze the global dynamics. We find that a human-capital-rich agent may find it

optimal to avoid any switching of technologies, and therefore to experience no long-run growth.

On the other hand, a human-capital-poor agent, who because of his lack of skill is not so attached

to any particular technology, can find it optimal to switch technologies repeatedly, and therefore

enjoy long-run growth in output. Thus the model can give rise to overtaking.



Boyan Jovanovic                                                     Yaw Nyarko
Department of Economics                                             Deparunent of Economics
New York University                                                 New York University
269 Mercer Street                                                   269 Mercer Street
New York, NY 10003                                                  New York, NY 10003
and NBER
                                     Table of Contents

I. Introduction                                                                1


II. Model....                                                                  2

III. The Transfer of Human Capital                                             3
       a. The Human Capital Transition Equation
       b. The Parente and LPSY Conditions.                                     7
       c. Switching Constraints                                               11

IV. Myopically Optimal Time Paths in the "No Jump Case.                       12

V. Myopically Optimal Time Paths in the "Full-Menu" Model                     24

VI. Dynamically Optimal Policies in the No-Jump Model                         35
      a. The Basic Structure and Notation                                     35
      b. Dynamic Paths for Small x and for large x                            38
      c. Dynamic Paths for large ö                                            39
      d. Dynamic Paths for Small ô                                            42

VII. Positive Discount Factor in Full-Menu Model                              46

           1. The Proofs                                                      46
Appendix
Appendix   2. Verification that all the CASES I-fl' are non-empty             62
Appendix   3. Proof that the Conditions in Proposition 6.8 Rule Out Case IV
Appendix   4. The No-Recall Assumption

References                                                                    68

                                       List of Figures

Figure 1: The Mappings h1, h2 and h                                            5
Figure 2: LPSY Fails for Large x                                               9
Figure 3: LPSY Holds for all x                                                 9
Figure 4: The Payoffs to Using the Current or the New Technologies            14

Figure 5: The Four Possible Regimes                                           14
           Graph of Case hA                                                   17
           Graph of Case fiB                                                  18
Figure 6: A Two-Period Cycle                                                  19
           Graph of Case LIlA                                                 21
           Graph of Case BIB                                                  21
Figure 7: Full Menu Model in Case I                                           28
Figure 8: Full Menu Model in Case II                                          29
Figure 9: Full Menu Model in Case III                                         30
Figure 10: The g Functions                                                    31
I. Introduction
       This paper explores a one-agent Bayesian model of learning-by-doing and technological
choice. In thisframework, the more a technology is used, the more productive it gets. Once
the productivity gains on a given technology have been achieved, further improvement can be
had only by switching to a new technology.
       After the switch, how useful an agent's prior experience will be on the new activity will
depend on how similar the new activity is to the old. In the Bayesian framework, this depends
on how correlated their respective uncertain parameters are. Information that is in this sense
transferable fits the notion of general human capital, while information about an unknown
parameter that is independent of other unknowns, is exactly like specific human capital.
       Our model is like that of Parente (1991), but his formulation is not information theoretic,
and he, like Chari and Hopenhayn (1991). looks only at constant growth paths. The outcome
that in our model corresponds to steady-state growth is the situationin which the agent switches

to a new technology at equally-spaced intervals, and in which the size of the jump (measured
in vintages) is the same each time.
       An agent can also get stuck in an old technology for ever, and experience no long run
growth in output. As in Chari's and Hopenhayn's model, each new technology dominates the
previous one at any given level of expertise of its users. The crucial difference is that here, the
more remote one's current knowledge is from "frontier knowledge", the less expertise one has
with the frontier technology. So, even though the frontier technology keeps getting belier,
expertise shrinks. Generally, this prevents the agent from upgrading his technology too fast.
And if successively better technologies differ enough in the type of expertise needed to operate
them properly, an agent will understand them so poorly that he will stick with the old one he
understands well. Paradoxically, the type of agent to whom this may happen is one that has
learned a particular technology so well that he will not switch to a new, untried one. Such an
agent may in the long run be overtaken by an agent that is initially less productive dn the
technology at hand, and who therefore is more willing to try a new one.



                                                1
                                               2
H. Model
        A risk-neutral agent can produce a good with one of several technologies indexed by n
=   1, 2       If he uses technology n at date t, a decision z yields net output q via the
production functio&



                                  q=     yft[1(yz)9.                                       (1)



Here ye,, is a random variable that acts as an unknown "target", and is observed after z is
chosen. Since y 1, a larger n denotes a better technology. Let E) denote the conditional
expectation at date t. The decision that maximizes E1(q) in (1) is



                                        z=     E1(,y_)   .                                 (2)




The random target fluctuates around a technology-specific parameter O:



                                           = o+w             .                             (3)




The agent does not know O. He can observe y1, but only if at date t he uses technology n!
Assume that w is an i.i.d variate, with mean zero and variance o.          Since   E(w,) =   0.

equation (2) implies that the optimal decision is




      This type of production function has been analyzed by Prescott (1972) and Wilson (1975).

    2 The information that the agent gets depends on what vintage he chooses to operate, but not
on the value of z. Therefore equation (2) holds even in a multi-period maximization problem.
                                                         3


                                            z       =                                       (4)
                                                            E(O) ,



and (1), (3) and (4) imply that expected net output is




                               E(q) = yD l              —
                                                             Var1(00)
                                                                            —
                                                                                uj ,        (5)



where Var1() denotes the conditional variance. If he uses technology n, he also observes y
and learns more about O, which allows him to make a better decision z. This reduces
Var1(OJ, and raises his expected net output. However this learning process is bounded: Using
technology n forever allows the agent to learn O completely so that E(q) —.             -

which is finite for fixed n.


III. The Transfer of Human CapitaJ.
There is no direct cost of switching to a different technology, and no adjustment costs in z.
The only link between technologies is informational. Let



                                                =                + n+i


for all n, where      is an i.i.d. normal variate with mean zero and variance a2. If the agent

has not yet tried technologies n+ 1, n+2                    equation (6) implies that



                                Var1(O,1)       = aVar,(8)              +   '4   .          (7)



       The earlier equations in the model allow us to think of the posterior precision on O as
                                                4
an index of human capital. Equation (6) adds a further dimension and lets us evaluate some
hypotheses that are connected to human capital — general and specific. If a = 1 and a
= 0, the correlation coefficient between 0 and °k is unity, for all k, which corresponds to
the case where human capital is general and freely transferable across technologies. But if a
= 0, human capital is technology-specific.
         We choose the AR-i formulation in (6) to model the transfer of knowledge because by

varying a, we capture many types of evolution of technologies:
i.       When O<a< 1, note that the 0 process has a tendency toward zero;
ii.      When a=1 then                so the technology parameter tends to where it was in the

         previous vintage.
iii.     When a> 1 then there is drift towards infinity.
         Notice that a has the interpretation of a human capital transfer parameter. For let;'
denote the variance of the parameter 0. Then       from (6), o8+i'—aa02+oI. We may therefore
write aa+j'=czàan2 where Au? represents a "change in a,,." Hence a unit change in human
capital on technology n results in a units of change in the human capital on technology n+1.
         We assume that the prior over O at date 1 is normally distributed. Eqs. (3) and (6), and
the normality assumptions made on wN imply that the posterior belief at each       date   over the

parameter of any vintage, 0, will also be normally distributed.
         We define the following functions of x:


                h1(x)    a2x/(a + x);        (updating)
                h2(x)    ax+a42; and         (transfer of knowledge)
                h(x) = h1(h,(x)).            (tmnsfer and updating)


These functions have the following interpretations: Suppose that vintage n is the newest
vintage that the agent has worked with at the      of date t and suppose the agent has a
posterior of ;, over O. Then h,(x.) is the agent's pjjg1 at date t over O.           Suppose the

agent   uses vintage n at date t+1. The agent will then observe y,1+1 after which the posterior
                                                  5

 variance over vintage n becomes, via Bayesian updating, h1(x0J. Suppose instead that at date

 t+l the agent chooses vintage n+1. The agent will then observe             The agent's posterior
 variance over 0,.,' will then be LI(X,,J.
          We define i to be the fixed point of the Li2 map. This fixed point exists and is unique

 whenever a C        1;   when a1 we take Ito be +.        We defme x1"' to be the fixed point of
 the h map.         Since h is as drawn in Figure 1 (i.e., since h(O)>O and h is bounded and
concave), x exists and is unique.




                            +

                                                             2             x

                                Figure 1: The Manninzs h1, Li, and h.


         The following property of h will be used later: Suppose that at the end of date t the
agent has a posterior over a "status quo" vintage n equal to x0. Suppose further that at each
date he switches to the next technology. Then his posterior over the most recent vintage is given
by iterates of h from x0. That is, his posterior over 00+1 at the end of date t+1 is x1 =
h(x0),   his posterior over 0a+k at the end of date t+k is the k-tb iterate of h, ; =
h(h(. . .(h(x0))   (k-times), and so on. For any ;, the sequence {xk}k_I converges
monotonically to xt.


a. The Human Capital Transition Equation. Several authors have discussed the question of
how human capital at date t depends on the nature of prior experience, and on the content of
                                                6

previous human capital. The specific functional form implied by our model depends in a crucial
way on how we define things.
       One way to think of this equation is in linking per unit productivity at date t+ 1 when
vintage n4-1 is being used for the first time, with the history of outputs from dates 1 through
t.   This is, formally speaking, the approach in Lucas (1993). Since in our model there is a
one-to-one relationship between productivity and variance this is equivalent to looking at the way
in which the variances at those dates relate to each other.     In our model the relationship is
Markov. The date t+ 1 variance of vintage n+l is a function of only the variance at date
of vintage n. In particular the date t variance of vintage n+1 is related to the history of the
variances of all previous vintages by the Markov relationship x11=h2(x,1).
        An alternative way of thinking about the human capital transition equation is look for the
function linking the experience in previous vintages to the productivity on the current vintage.
This is the language Lucas actually uses. In particular suppose that at some date T, vintage 1
was used for the first r periods, then vintage 2 was used for the next 2 periods              and

vintage n-i was used for r1 periods. Then the human capital equation will have the
productivity on vintage n equal to a function of the numbers t through TD.1:

            Variance on Vintage n =    x,=h2(l?' (h2(hT.2 (... h2(h' (x1))))),                 (8)


where x1 is the initial date 1 prior variance over the date 1 status quo technology, and where.
via Bayes' rule


                                      h17(x) = c1xJ[a2 + Tx]                                   (9)


gives the effect of r units of experience on the variance of a vintage.
        We now show that a geometrically-declining weights model can be obtained as an
approximation of our model.Although in this exercise r is an integer, h( is defined for all r
in [O,oo). Now differentiate (8) with respect to; where h1t is as in (9). This differentiation
                                                  7
 exercise asks: if we raise by a unit the experience level on vintage k, what is the effect on the
 human capital level (or more appropriately, the variance of) vintage n?



                         dxjOrk = a.hiT (x,,.i).hT2 (x).. .h' (xJ,                               (10)

 where Xr is the argument of h17' in (10) above and denotes the variance of vintage r when vintage

r is just about to be used for the first time. Suppose that to a first approximation,


                        TkTk.1... =r,      and xk=xk+l=...=x(=x say).



Then from (9) . b1T(x) is equal to a constant, E say, for all r. So from (10) we obtain ôx,J3;
= (aE)°.      This in turn implies that, to a first approximation,


                                     ;=    r1,- (aE)°'r1

Hence the productivity measure for vintage a is a function of the experience levels of agents

with geometrically declining weights. This is of a form similar to that of eq. (4.7) of Lucas
(1993). We obtain the same general formulation as in Lucas if (aE)c 1. Here, however, aE
can exceed unity, in which case vintages further in the past have a stronger effect on today's

output than more recent vintages. This of course can happen only when a> 1.


b. The Parente and LPSY Conditions. Parente (1991) assm.i that when an agent switches
to jy other activity, his human capital depreciates, and the bigger is the jump the greater is the
fall in human capital. In our framework if x is the posterior varianceon the current technology
(vintage n, say) then h2k(x) (the k-th iterate of the function h2) is the prior variance over vintage
n+k. The depreciation of human capital is therefore given by
                                                  8

                                          D(k) = h2k(x)x.


From figure 1 whenever x <1, D(k) >0 for all k= 1,2,... Further, D(k) is bigger the bigger
is k. Hence the Parente assumption is equivalent to the following:


Uefn: The Parente condition, or condition P. holds at x if xci.


If we define x_5t,then condition P holds at each
       Lucas (1993), Parente (1991), Stokey (1991) and Young (1993) emphasize a different
condition - that human capital in some future vintage will be larger if today a higher rather than
a lower vintage is chosen. For example, suppose that N>n2>n1 and tomorrow an agent will
be using vintage N. Then human capital in vintage N tomorrow will be higher if vintage n1 is
used today than if vintage n1 is used. Surprisingly, this is not always true in our model. Fix
an n and   set n1 = n and n1 =n+ 1.    Consider two agents with the sante knowledge in the sense
that each has Var((Ofl) = x. We shall call them agent S and agent F (for 'Slow" and 'Fast"
resp.). Assume that in period t+ 1 agent S operates technology n while agent F operates
technology n+1. Which agent will be better prepared for technology n+2 in period t+2?
Well, let 5(x) (resp, $Ø))       be   the variance of agent S's (resp. agent F's) beliefs over O,+:


                          h2(h1(x)) and 4,(x)         h1(h2(x)).


DeEn: The Lucas-Parente-Stokey-Young, or condition LPSY, holds at x if 4i(x) > 4(x). We
also define XLpy = Sup {x0 the LPSY condition holds at x}.


       When LPSY holds, agent F is better prepared for technology n+2 from x. The shapes
of the 4 and 4F functions and xy are illustrated in figures 2 and 3 below and described in the
lemma below. Surprisingly, we see that it is indeed possible for condition LPSY to fail.
                            9




w

                 I Ill III Ill       Ill Ill        II

      22
     UwUe
      +

                x                                        x


            Figure 2: LPSY Fails for Lane x.




                                               45

    aa÷a
       a
       w




                                                    x


            Figure 3: LPSY Holds for all x.
                                                  10

Lemma 3.t.
(I)     When iCc,), Ocx12< , the LPSY condition holds at each x<xL and is violated
        at each XXLnY.
(ii)    When ia,),        and   hence in particular when      Xijy= and the LPSY condition
        holds at each xO.
(iii)   £ c x1.   In particular the LPSY condition holds at each x    j.


        We may refer to our earlier condition LPSY as a "one-step ahead LPSY," since it
involved comparisons of the use of a vintage n with a vintage n+ 1. Below is the "many-step"
ahead version - a kind of first-order dominance resultin vintage levels - which is implied by
condition LPSY:


Proposition 3.2. Suppose that at date 1 agents S and F both start from the same prior variance
over the initial date 1 status quo technology, and this obeys the LPSY condition. Suppose
                                                                                   that

at each of dates t= 1,2     T, agent S chooses a technology of lower (or equal) vintage than agent
F, and suppose that their choice differs at least in one period. Let N be any technology of
vintage greater than or equal to the maximum that any of the two agents have chosen by date
T. Then at date T+1 agent F will have more human capital (i.e., lower posterior variance) on
vintage N than does agent S.


        From any given x, neither condition P nor LPSY necessarily holds. (See fig. 2).
However, part (iii) of lemma 3.1 means that Condition P implies Condition LPSY.
(Equivalently, xP,FCxWY.) The reverse claim, namely that condition LPSY implies condition
P. is false — as figure 2 shows.
        In summary we see that if a C 1 and x is large both the Parente and the LPSY condition
fail. 1fa1 thenbothx andxequal sothetwoconditionsholdateachfiflitex. Let
us now pursue the Parente condition a little further. When x> I (which can only happen when
cx< 1) iterates of the h2 map from any x are decreasing. This means that the prior variances
                                                 11

 over later vintages are decreasing the further out is the vintage. The agent has higher human
 capital on vintages which are further away! This of course is precisely the meaning of the
 violation of the Parente condition.
         One may be dissatisfied with our framework because it allows for this potentially non-
 intuitive feature. However, in that case, it should be stressed that what one is really dissatisfied
 with is the assumption that a < I and x is large. For note what this implies: When x is large,
 the variance of e, a,1, is relatively small so for each n, O1=a"2O0 approximately. A large x
 implies that O is large relative to its mean. Hence when a< 1,          is a fraction of O so with
 high probability will be much smaller than O so will have a smaller variance. The assumption
 that a< 1 implies that the process O1=a"2O+u42 has a tendency toward zero when the noise
term     is small. This explains the non-intuitive feature mentioned earlier. When a         1   the
process no longer tends towards zero and the non-intuitive feature (i.e., the violation of the
Parente condition) disappears. Further, although condition P does not hold for x >        i, the set
of beliefs [0, k] is in fact absorbing — starting from any initial belief in this set and following
      policy implies that beliefs always remain in this set. Moreover, since x** is strictly less
than *, it is also easily shown that under io policy, starting instead from any initial beliefs
exceeding A, beliefs will enter the set [O,A] in fmite time, and remain in it thereafter.     (This
can be seen by observing the shapes of the h1, h2 and h maps and noting that the beliefs of any
vintage at any date are iterates of some combinations of these maps.)


c. Switching Constraints. We now study the dynamics of our model. There are at least three
interesting ways of constraining technological switches:
i.      (No Jump Model) The first is to assume that the agent can not skip intermediate
        vintages when switching, so that if he wishes to advance from vintage n, he must use
        vintage n+1 before he can use any higher vintage. We shall refer to this as the "No
        Jump Case". This case is the easiest to analyze, but it begs the question of why it is
        impossible to skip vintages when switching.
ii.     (Chari-Hopenhayn Mode!) The second type of constraint on switching allows jumps,
                                               12

       but only up to some frontier that advances exogenously. This is the case that Chari and
       Hopenhayn analyzed. This switching constraint is only partially satisfactojy in that the

       exogenous outward movement of the frontier, similar to the Solow growth model, is left
       unexplained.
iii.   (Full-Menu Model) The third approach is to leave the choice of vintage unconstrained.
       This is the approach that Pat-ente took, and we refer to it as the "Full Menu Case".
       Although the rate of growth is endogenous in all three cases, only this third case is free
       of any arbitrarily imposed constraint on the rate at which future technologies are chosen.




       Section IV will cover the "No Jump Case", section V will take up the Full Menu Case",
and section VI reports results that relate the two cases. Both cases will be analyzed under the
following constraint:


The no recall constraint: Once a vintage has been passed over for a higher vintage, it is never
recalled. Hence an agent who chooses a vintage n at date t, can not choose a lower vintage
n' <n at any future date t' > t.

We prove in the appendix that, at least for the myopic and the two-horizon versions ofthe
model, it is actually pj optimal to ever exercise such a recall option.


IV. Myopically Optimal Time Paths In the "No Jump" Case.
This section analyzes the optimal behavior of a myopic agent who can upgrade his vintages only
one at a time -   the No Jump model.      Our reason for starting the analysis with myopically
optimal policies and time-paths is that first, they are the simplest to characterize, and that
second, they share similar broad features with dynamically optimal policies and time-paths.
        At any date the agent has a status ouo technology - the most recent one that he tried.
Define the status quo technology for the initial period, date 1, to be vintage 1. At each date
                                                  13

 there also is a frontier technology, one vintage higher than the status quo vintage. That is, if
 the status quo technology is vintage n, the frontier technology is vintage n+ 1. We refer to
 the decision to use the status quo technology as "NO SWITCH", and the decision to move to
 the frontier technology as "SWITCH". At each date the agent must choose between the status
quo vintage and the frontier vintage. He can not recall vintages earlier than the status quo
vintage. "The variance of vintage a" will mean the variance of 9. At the beginning of date
 1 the agent has a posterior variance x over vintage 1. This is his "prior belief" about vintage
one.
           Define


                     t(x)    1- x -     ,   and   r(x)    yfi - ax   -
                                                                         o?   - ai.


Once   chosen, the optimal "organization" of a vintage is given in (4). Therefore when he has
a prior belief x over vintage n, y"t(x) is the agent's expected net output on vintage n, and
y°r(x) is his expected net output on vintage n+i. Let x denote his posterior variance over
O at date t. Let x" be the unique point where 1(x) crosses r(x); i.e., 1(x*) = r(x*).
     The immediate gain to switching technologies is


                 A=     r(x) - t(x) = y-1 + (1-ay)x -        - (j).2
There are two parameters -- a and a12 -- that positively affect the depreciation of human capital
by raising the variance of 0 on the frontier technology, and each parameter indeed does reduce
a.   The   third parameter that reduces a is a_2. One certainly would have expected an increase
in this parameter to slow down the rate at which the frontier technology is learned, and therefore
to reduce the dynamic incentive to switch, but it is somewhat surprising that thisparameter
                                                   14




               Expected Payoff



                      2
              1-
                                                                              lv

                                                    (x)



                                                                              Ill
                                                                       4ntagen payoff




                                                                                        x
                                                          " II



            Figure 4: The Payoffs to Using the Current or the New Technolo2ies,



                                                ya>1
1 -
      2
           > y(l -        2          I                               Ill
      a,                                     Choose Old Vintage             Initial Beliefs Affect
                                             Always                        Long-Run Growth

                          2     2    II                              IV
1 -        < 'y(l —           — a)
                                                                            Switch to Next
                                             Cycles or
                                          eventually always switch          Vintage at Each Date




                                 Figure 5: The Four Possible Re2irnes.
                                                15

 should reduce the immediate returns too. The reason why it does so in our model is that the

amount by which a rise in u,2 reduces the expected output of a technology is greater for the
frontier technology than for the status quo technology. So the immediate and the dynamic effects
of a rise in a2 both work in the same direction.
     When y increases, the effect on t is ambiguous. This is because a higher y raises expected
net output at lower levels of x, but it actually lowers expected net output at high levels of x.
An increase in y therefore raises the incentive to switch at low levels of x and lowers it at high
levels of x.
     Finally, the effect of a rise in x on   is also ambiguous, and depends entirely on whether
ay bigger or less than unity. This condition determines whether high human capital (i.e., a tow
x) makes switching more attractive, and the answer is that it does
                                                                only if ay exceeds one.
                                                                     so

When this condition is met, an extra unit of human capital raises output on the frontier
technology by more than it raises the output on the status quo technology. Whether this condition
is likely to be met in a given technological area will depend on how technologically linked the
successive vintages are -- this determines the magnitude of a. For example, if each generation
of computer chips is defmed as a different technological vintage, then because each generation
of chip builds on the previous one, a should be high.
       With these remarks out of the way, we can now analyze myopically optimal paths.
There are lour regimes; the parameters determined which one will prevail. These regimes are
determine by whether ay is less than or greater than one, and whether r(O) is greater than or
less than 1(0). In Figure 4, the solid line is 1(x), while the dashed lines depict four possible
schedules for r(x).    (In all of this discussion we ignore the non-generic cases where ay= 1
and/or t(0)=r(0).)


Analysis of the Four Cases for the No Jump Myopic Model:
Case I (Agent is stuck at old vintage): In this case, 1(x) > r(x) for all x 0, so that
whatever the value of x at the end of date t, vintage n yields a higher expected profit than
vintage n + 1. He therefore chooses vintage n which causes ; to decrease. But, since 1(x)
                                                16

> r(x) for all x, vintage n will remain preferred over vintage n+1 at date t+1, and indeed
in each subsequent period. Hence the agent will choose the older vintage n at each date, and

;• converges to zero.
Case IV (Agent always "switches"): In this case, r(x) > 1(x) for all x 0, so that whatever
the posterior variance, x, over the parameter 8, of y vintage a at the end of           date t,
vintage n+1 yields a higher expected net output than vintage a. Hence he will always switch
to the newest vintage at each date, and x converges to x"4'. Log output will then have a trend
on In y, and its deviations of around this trend will be i.i.d.


Case IT. In this case, x C x's' implies 1(x) < r(x). and x > x' implies 1(x) > r(x).
Suppose that at date t, the agent must choose between a status quo vintage n and a frontier
vintage n+1, and let ,ç, be his posterior over 6,.
        First, let    > x". Then he chooses vintage n. He then sees y, which lowers his
posterior variance over O. He optimally uses vintage a until the variance over vintage n
falls below x, which it eventually must. Suppose that this occurs after r periods, at date
T = t+r. Since the posterior over O        is then less than x's, he chooses vintage n+I at that

date.
       Second, let x, C x's. Then he chooses vintage n+1 immediately at t. This is
equivalent to the setup of the previous paragraph when r = 0 so that T = t. So from now
onwemaysupposethatweareatadate T with xa< P. with T=t+r, andwhere r
is an integer and may be zero.
        To determine what happens in the subsequent periods, i.e., from date T+ 1 on. we
consider two sub-cases: P C x, and P > x'.
                                               '7
Case HA: x >        x   (Use inferior technoloay for r         0 Deriods. then "switch" forever.)
Assume x" > x. We saw earlier that at some date T the agent will have a posterior, x,7,
over 8   smaller   than x". He then chooses vintage n+1, sees y+' and his posterior over
O÷ becomes x1,11 = h(x,). Since iterates of h converge monotonically to the x,
;11.1 is closer to x than Xa,T was. Since both  and ;T are less than x', so is




                              %(r(x)
                                                    9(x)


                                                                                 x
                           switch                    stick




                                     Graph of Case HA


;+L,T+I Hence, at the end of T+1 he switches to the frontier technology, n+2. Repeating
this logic we see that at each subsequent date he switches to the newest frontier technology.
       To summarize Case HA: There is an integer           r   (which could be zero) such that the
agent chooses the inferior vintage   n for r periods. Thereafter he switches to the frontier
technology at each date.
                                                l8
Case IIB:   x C x' ("Cycles")



                                  r(x)


                                                     (x)



                                                                             'C


                        switch

                                         Graph of Case fiB


Again, at date T the agent's posterior over O        is X.,T C   xt. He then switches to vintage
n + 1, and the posterior over O+ is Xn+IT4I = h(x.4T). Since iterates of h converge
                                           ;T. If Xn+IT+l is still less than xt he
monotonically to x4"', this means that ;+IT+l >
switches to vintage n+2, and ;+2.T+2 = h(x11) is even closer to x. He will keep
switching until the posterior gets larger than x which it eventually must since iterates of h
converge to x.
       He then begins to forsake frontier technologies and stays with the relatively inferior
vintage. But then we are back where we started in CASE II: he stays with the inferior
technology until its variance falls below x. He then switches to the frontier technology. He
then keeps switching to each latest frontier technology, the variance of which continually
increases towards xa and eventually exceeds x". So we get "cycling": The agent "sticks"
with an inferior technology for a while, then continually "switches" to the newest frontier one,
then "stays" with an inferior one for a while, then continually "SWitches" to the newest one, etc,
etc, ad infinitum.
     An example with parameter values that satisfy the restrictions of case II is described in
                                                      19

figure 6. In this example, x" = 0.129, and therefore for any smaller value of x it is optimal to
SWITCH. In particular, this is optimal at the value x0 =                .0896. Having used the new

technology, say technology n+ 1 for one period, it remains optimal for the agent to use it for
one additional period, because h(xnj exceeds x, as shown in figure 6. But after two periods
of using technology n+ 1 • the agent's posterior variance on n+ 1 is once again ;, and so it
is now optimal for him to switch to technology n +2, where the whole process repeats itself,
and so on3.




    h1(x)      h(x)
    0.3




    0-25



    Di

   0.15


    0.1



   0.05



      0                                                                                         x
           0          0.03   0.08     0.08    0.12    0.16    0.13   0.21   0.24   0.27   0.3
                                    x0-.0898 x'-.129 h(x0)a.139




                                       Figure 6: A Two-Period Cycle.



      The parameter values underlying this example were o = a2 = 0.25,              y=    1.54 and
a = 0.75.
                                               20
Case III. In this case, x > x" implies t(x) C r(x) and x C x implies t(x) > r(x).
Suppose that at t, the frontier vintage is n+1, and the "staWs quo" vintage is n. Let ;,
again be the posterior over O•
       First, let ;, C x. Then the agent chooses vintage n, sees y,         and   his variance on

O falls and therefore remains below x. Hence he uses vintage n for ever even though
vintage n+l is always available.
       Second, let ;, > x.         Then he uses the frontier vintage n+1, and then sees y0+1.
Let x1 be the posterior over 00+1          at the end of date t+1. What happens then depends

on whether             remains   larger than x' or not. This in Wru depends on the map of h.
We need to consider two sub-eases:




Case lIlA: x C     x' (Beliefs affect lon2 run growth catastrophicallv.
Suppose x0. >     x so that at t the agent switches to the frontier technolo'. Now ;++
= h(xJ is closer to x than x, was. Since x1, and x exceed x", so does x111+1
= h(x0J. Hence at the end of date t+1, after using vintage n+1, he switches to vintage
n+2. Repeating this logic we see that if x,, > x, he will at each date switch to the newest
frontier technology.
       To summarize Case lIlA: If initial beliefs are less than x, the agent chooses the
inferior technology at each date. But if they exceed x, he will at each date switch to the
newest frontier technology. This is a bifurcation or a catastrophe situation: radically different
long-run behavior occurs depending on whether initial posterior variance is less than or greater
than x4.
                       21




        D(x)




stick                       switch




               Graph of Case lilA




    P (x)




                                     xx

stick                       switch




           Graph of Case TUB.
                                                22
Case IIJB: x" > x'"' (Switch for r 0 periods then "stick" with a vinta2e).
Suppose that XflL > x". Since t(x1) C r(x,,j, the agent will then choose vintage n + I at
date t+l. The posterior variance of the agent is given by h, whose iterates from ;.
decrease    monotonically to x. Hence he switches to the frontier vintages for a finite number
of periods r 1, after which the posterior variance falls below xt. The date will then be
T = t+r and the vintage N = n+r will have just been used. But when x C x, 1(x) >
r(x), so he will prefer vintage N = n+r to vintage N+1 at date T+1. The posterior
variance on vintage N then decreases, and so remains below x". Hence he will use vintage
N at T+2 as well. Repeating this logic we see that he will use vintage N in each subsequent
period.
          To summarize case JIIB: Depending upon the initial belief, the agent will "switch" to
a new frontier technology in each of a finite number of periods r         0. If the initial belief is
in the set [0, xt), then r = 0. Otherwise r >        0.   Afterthe r   periods, he will remain with
the status quo technology at that date (vintage n+r) forever thereafter. Hence there is some
initial "growth" in the vintages, after which there is "no growth" in the vintages.


Summary of all the Cases.
          We now list the types of behavior that arise, roughly in increasing order of long-mn
growth rates. At the extremes, staying with the oldest vintage is the "slowest growth rate" while
always switching is the "highest."

Case I                  "Stick" to an old vintage forever.

Case TuB                "Switch" for r    0   periods then "stick" with a vintage.

Case LIlA               Beliefs affect long run growth. When initial posterior variance is low
                        agent is stuck with initial old vintage; when initial posterior is high, he
                        switches to the frontier technology at each date.

Case JIB               "Cycles." Stay with a technology for a finite number of periods, then
                       continually switch to the frontier technology at each date for a finite
                       number of periods, then stay with a technology for a finite number of
                                                23

                        periods, etc.

Case hA                 Use inferior technology for r       0 periods then "switch" to frontier
                        technology at each subsequent date.

Case IV                 Agent always "switches" to the frontier technology at each date.



Discussion of the Results.
    Cases I and IV are straightforward. In case one, new vintage technologies do not represent

an improvement that is big enough to offset the loss of informational human capital that
switching to them entails, and therefore there is no switching, and no growth. In case IV,
exactly the reverse is true.
    Cases   II and Ill, on the other hand, are a mix of cases I and IV in the above sense. At some
levels of human capital, a switch pays, and for others it does not. Case II obtains when it is the
human capital-rich agent that will switch, white in case Ill it is the human capital-poor agent that
will do so. The latter is perhaps counter-intuitive in that human capital is usually thought of as
being conducive to growth.
    The most complicated dynamics arise in case JIB where cycles occur. We have illustrated
a two-period cycle in figure 6, but we have not ruled out other more complicated ones. The most
interesting, substantively, is probably case lIlA. Here, small differences in initial beliefs can
have huge effects on long run outcomes, and perpetually widening inequality can arise among
agents that are initially not too dissimilar.
                                                24
V. Myopically Optimal Time Paths in the "Full-Menu" Model
In section III we remarked that there were three possible switching constraints one could impose.
In the previous section we analyzed the first of those switching constraints - the NO JUMP
model, where the agent may only choose between vintage between n and n+l. The NO-JUMP
model is the most restrictive of the three switching constraints defined in section 3. We now
study the 'full-menu" model where at each date the agent may choose between a vintage n and

vintages n+j for j = 1,2,3   and where j is referred to as the jump size. All technologies are
therefore always available, and the agent is aware of their existence, even though he may
understand most of them extremely poorly in the sense that he may know virtually nothing about
the relevant 0's. The full-menu model is the least restrictive of the switching constraints of
section III.


Terminology and Assumptions. Recall the definition of h2 in section III. Fix any date and
refer to the status quo vintage at that date as vintage 0. If x is the posterior variance on the
status quo vintage then h1(x) is the prior variance on vintage 1. The k-th iterate of h2 from x,
i.e., h2k(x), gives the prior variance on vintage k.
        Define G(x,k) to be the return from initial posterior variance x when a jump of size k
is chosen. Note that G(x,O) is the return to choosing the status quo vintage and is equal to what
was earlier referred to as e(x). G(x,l) is the return to switching to the next vintage, with a jump
of one; it is equal to what was earlier referred to as r(x). It should be easy to verify that


                      G(x,k) = y"[1-a2-h(x)] and
                              = yk[l_aZkx.hik(0)]


where h2k(O) is the k-th iterate of h2 from 0 and where h20(x)=x.
        To make the problem interesting we shall impose the following assumptions:


A.!     la,,,2>O.
                                                   25

A.2. 1-cç-2CO.


       If A. 1 is violated the return in each period, regardless of the jump size, is negative. The
surnof expected discounted returns will then be negative regardless of the strategy chosen. A. 1
rules this out. Condition £2 states that as the agent upgrades his technology, his human capital
depreciates fast enough to prevent him from attaining an arbitrarily large net output by choosing
a large jump size. Indeed, suppose that A.2 is violated and in particular that 1-a,2-k>0. Since
i is the fixed point of the map h2, from i iterates of h2 remain at 1. The return to a jump of
size k from initial posterior k will be yk(1.at.h?(k)] =7k(10jj -. oc as k-soc. Hence when
£2 is violated it is possible to choose a jump size to obtain arbitrarily high return. Even the
myopic problem is not well-defined that case. Condition A.2. together with A.!, ensure that
the myopic problem is well-defined. (We will later on impose additional conditions to ensure
that the infinite-horizon problem is also well defmed.)
       From assumption A. 1, G(0,0) = 1-ç >0 so there is at least one integer k such that
G(O,k)>0. Now h2k(O) converges inonotonically from below to i as k—c'. Hence from A.2,
there exists a unique K< oc such that 1-a2-h?(0)>0 for all kK, and                           for all
k>K. In particular, G(0,k) is positive for kK and is non-positive for k>K. Since h2t(0)
is monotone non-decreasing in k,


1-a2-h21(0) >0 1-a2-h2"''(0)> .. > l-cç1-h2'"(0)> 1-ci2-h21"'(0)> - . -


Since -y>   1   this in turn implies that


                  0 G(0,K+1)> ... > G(0,K+j) > G(0,K+j+1)> ...                                 (11)


       For each k= 1,2            G(x, Ic-!) and G(x, Ic) are linear in x and have slopes which are
respectively (a-y) and (a.y)k.         Hence   so long as ay 1, the two functions will have an
intersection point (which may be negative). Define Xk to be the point of intersection of the two
                                               26

functions of x, G(x,k-1) and O(x,k); i.e.,


                   a   the   unique x such that G(x,k-1)G(x,k).


Notice that x is what in the NO JUMP model we referred to as x".


The Optimal Myopic Policy.
Recall that CASES I-IV were defmed in section IV. The optimal policy functions for these cases
in the NO JUMP model are as in fig. 4. We now provide, in the propositions below and in
figures 7-9, the equivalent in the full-menu model. The reader may find it useful to compare
fig. 4 with the corresponding figures 7-9. (As in section IV we ignore the knife-edge situations
where either ay=1 or r(O)=t(O).)


Proposition 5.1. (CASE I). Suppose that we are in CASE I. Then the payoff functions are
as in fig. 7. In particular, G(O.k)>G(O,k-l-1) for all k. Hence the optimal myopic action is
to choose a jump size of zero (i.e., NO SWITCH) at each date from each initial pdsterior
variance.


Proposition 5.2. (CASE H). Suppose that we are in CASE II. Then the payoff functions are
as in fig. 8. In particular, there exists an integer ME{1 K} such that
I.     G(O,O)<G(O,1)<... <G(O,M); and
ii.    G(O,k)G(O,M) for all k>M.
iii.   The following jump sizes are optimal for the myopic problem from initial posterior
       variance xO:
       a.      choose jump size 0 (i.e., action NO SWITCH) for x in [x1,);
       b.     jump size m if xE[xmti*.x_*] for some m=1,2          M-1; and

       c.     jump size M if xE[O,x1,]. So,
iv.    The agent will never choose a jump size greater than M.
                                               27



Proposition 5.3. (CASE ifi). Suppose that we are in CASE Ill. Then the payoff functions are
as in fig. 9. In particular,
I.       G(O,k)>G(O,k+1) for all kO; and
ii.      x<xL*cx2*<...,andlml...Sxk=co.
Hence,
iii.     the optimal myopic action from any xO is to choose a jump size k=O,1,2          where
         k is any integer such that xE[xk*,xk+Ii (where x0teO); and
iv.      for any x and x' with xx          the optimal myopic jump size from initial posterior
         variance x is no less than the optimal myopic jump size from initial posterior variance




Proposition 5.4. (CASE IV). Under assumption A.l CASE IV can not occur.
                               28




   0(0,0)

   0(0, 1)
   0(0,2)


     .
   0(0, P9
                                                                        x


0(0, K + I)


0(0, K + 2)


3(0, K + 3)                                                   G(x. 0)

      S

      S

      S




                                                     30c I)




              Figure 7: Full Menu Model in Case I.
                                       29




  0(0,m)
  G(O,ru-I)
  0(0,m-2)


       .




   0(0,1)

   0(0,0)

   a(0,Iq
                                                                          x
                                                   xl

0(0, K + I)


0(0, 1< + 2)


0(0, K -+ 3)




                                                             G(x, m -2)
                             G%m)           GQc,m•l)


               0(x, K 4 I)

               .0(x,K+2)

               0Cc, K +3)




                     Figure 8: Full Menu Model in Case II.
                                    30




    0(0,0)
    0(0,1)
    0(0,2)




 0(0, K-I)




    G(0, ig




                                                xIc+I XKfl Sc.,
                                                                  I'



G(O, K +   1)


6(0, K + 2)


0(0, K + 3)




                            GQçl)
                OCXC)




                                                                  — I)




                Figure 9: Full Menu Model in Case III.
                                                  31

Dynamics in the Myopic Full-Menu Model
        Define for k1,


                              g(x) a h1(h(x)).


An agent with initial posterior variance x who chooses a jump size k will after using the new
technology have a posterior variance of &(x) over the new status quo technology. The map h1
is concave while h2k is linear so g(x) is concave in x. It is clearly increasing in x. Further,
g(O) >0. Further, since h1(x) a,2, g(x) o,, for all x. Hence &(x) has a unique positive
fixed point which we shall refer to as xk**. Note that what we referred to in section IV as xt
is what we are now referring to as x1.


Lemma 5.6: i.      Xk**<Xk+1**       forallk1;     and ii.          =   h1(k).


Corollary 5.7.: From any x > h1(k) the posterior variance of the status quo technology in the
next period will be less than x.



                                                                          45°




                                                                                 x


                                   Figure 10: The 2.. Functions.
                                                32
       We now describe the dynamics in the full-menu model using the classification of CASES
that was used in the NO JUMP model. Our results will be very similar to the results in the
analogous cases. We state our results in a collection of propositions. The proofs should be
obvious from the figure (fig. 7-9) of the optimal policy corresponding to the case.
Proposition 5.8. (CASE I). Suppose that we are in CASE I. Then the optimal myopic action
is to choose a jump size of zero (i.e., NO SWITCI-l) at each date from each initial posterior
variance.
Proof: Follows immediately from fig. 7. •


CASE hA': x1 <x11 ("eventually always choose positive jump size")
Recall that what we referred to in the NO JI.JMP MODEL as x' (resp.x**) is what we now refer
to as x1    (resp.   x1**). In the NO JUMP model we referred to CASE HA as the case where
  ** <x1   . In   the NO JUMP model we showed that in this case eventually the agent will always
choose to SWITCH. We now impose a condition slightly stronger than this. In particular, let
M be as in Proposition 5.2 (or fig. 8); we assume that XM'C x1".     If M= I then this condition
is the same as what was previously called CASE HA. It is a stronger condition when M> 1.
 We shall call this stronger condition CASE HA' to distinguish it from the previous condition
in section IV. Under this condition we shall show that the agent will (for all but perhaps
finitely many periods) choose in each period a jump size greater than or equal to one. Hence
we obtain a result in the same spirit as the analogous case in the NO JUMP model. However.
whereas in the NO JUMP MODEL eventually the jump size is exactly one, here eventually the
jump size is at each date greater than or equal to one and may vaiy over time. Formally we
have the following:


Proposition 5.9. (CASE HA'): Suppose that we are in CASE HA' (i.e., x,4**<x1*). Then
for all but possibly finitely many periods the agent wiu choose at each date t a jump size which
is greater than or equal to one (and may depend on the date). In particular for all but perhaps
finitely many periods, the action NO SWITCH will not be chosen.
                                                33



 CASE 11Th x15<X15 ("Cycles")
 What was in the NO JUMP model referred to as CASE JIB is the situation where x1<x1.
 In the NO JUMP model the dynamics were characterized by "cycles." We now show that
under the same condition we obtain cycles in the Full menu model as well. The only difference
is that whereas in the NO JUMP model the cycles are between NO SWITCH and jump size 1,
the cycles in this case will be between NO SWITCH and jumps of sizes j 1.


Proposition 5.10. (Case HE):        Suppose that we are in CASE HE (x15<x155). Then the
dynamics are characterized by cycles: In particular, the action NO SWITCH is chosen for some
time, then the agent decides to choose positive jumps for a while (with possibly time-varying
jump sizes greater than or equal to one) then NO SWITCH is again chosen for a while then
positive jumps occurs for a while, etc.




CASE lIlA: XIS <x1° (Beliefs affect long run). We now impose the condition used in
defining case lilA in the NO JUMP model: x15<x155. In the NO JUMP model we obtained
the conclusion that beliefs matter catastrophically.   in particular, in the NO JUMP model for
initial posterior variance x in [O,;J it is optimal to choose the action NO SWITCH at each date
while for x in (x1*, ) then it is optimal to SWITCH (or jump size one) at each date. Under
the same condition we shall show that in the FULL MENU model a very similar result is
obtained: for initial posterior variance x in [O.x15] it is optimal to choose the action NO
SWITCH at each date; and for x in (x15,00) it is optimal to choose a jump size, j, greater than
or equal to one at each date.




Proposition 5.11. (CASE WA): Suppose that we are in CASE mA. (I) If the initial posterior
variance lies in [O,x,j the optimal action is NO SWITCH (or jump size of zero) at each date.
                                                34
(ii) lithe initial posterior variance lies in (x1*,oo) the optimal action is a jump size of one or
greater at each date (with the size of jump possibly dependent on the date).




CASE 1MB': h1(*) <XIS (Switch for r periods then "stick" with a vintage).
Recall that CASE 11Th in the NO JUMP model was the condition that XI**<XI*. We now
define a stronger condition and refer to this as CASE TUB': h1(k)<x15. Recall from lemma 5.6
that Xk55 converges from below to x,. =h1(i). Hence case IIIB' is the condition that
lim,L.ext**<xI* and is in general stronger than CASE TUB, x155<x,5. For the NO JUMP
model in case fuR we showed that for all but possibly finitely many periods the agent will
choose the action NO SWITCH. The posterior variance therefore converges to zero. We shall
show that in the full-menu model the same result is true under the stronger condition of CASE
111W.



Proposition 5.12. (CASE 11Th'): Suppose we are in CASE TUB' (i.e., h,(i)<x1).
(I)     From (x1*.) the posterior variance of the agent will enter the set [0,;'] in finite time.
(ii)    Once the posterior variance is in the set [0,;'] the optimal action is to choose jwnp size
        0 (or action NO SWITCH) in each and every period.
                                                35

vi.   DynainicaHy Optimal Policies in the No-Jump Model.
      We now treat the case where the future matters, and in particular the agent's discount factor
is positive. We will begin with the No-Jump model. We show that optimal policies exist, and
are stationary in two senses: First, they do not depend on calendar time, and second, whether
or not the agent holds on to his current (status quo) technology or switches to the next vintage
does not depend on the numerical value of the vintage, in other words, whether or not the agent
stays with vintage n or switches to n+ 1 depends only on his beliefs about vintage n, and is
independent of the numerical value of n. We then characterize the dynamics under the positive
discount factor assumption.


a. The Basic Structure and Notation.
 At any date t the agent will have a history of previous vintages chosen and the observations

associated with their use. A oolicv is a sequence r =                  where      ; maps the initial date
o variance and the observed history at t into a date I decision SWITCH or NO SWITCH.
         Fix a policy ii-. Let m(t) be the vintage chosen at t under r. At the start of date
t+ I the agent chooses between the status quo vintage in(t) and the frontier vintage m(t) +
 1. If the policy prescribes the action SWITCH at date H-i then m(t+1) = m(t) + 1; and
if the action is NO SWITCH then m(t+1) m(t). The agent has a discount factor 6 in
(0,1). From initial posterior variance x, a policy r generates a sum of discounted expected
payoffs given by


                           V1(x) = g,.1°'ot'f'°(l        - Var1
                                                                O$)   - a1)   ,                     (12)


where


                             Var1   O=               -           I x, r]
                                               36

isthe variance of O) under the agent's initial belief and policy r, which has expectations
operator given by ft I x,r] with initial posterior variance x over U. We let P denote
the set of all policies. A policy ir is said to be optimal if it attains supremum of SUPrit VT(X)
forall   x 0.
         From initial posterior variance x=x'", the strategy of switching in every period results
in a sum of discounted net outputs equal to r(xt4)/[1-yâ] whenever 6<1/7 and is infinite
whenever 6 iJy. To ensure that the sum of discounted payoffs in (12) is bounded, we impose
the following


bound on the discount factor: 6 < 1/y.


         Implicit in the Bayes' rule mapping is the following bound on the variances over time.
Fix any initial posterior variance over the status quo vintage in the first period. If the agent
decides NO SWITCH in the first period then the posterior variance of the status quo vintage
becomes h,(x). If the agent decides to SWITCH then the status quo vintage becomes vintage
2 and will have a posterior variance given by h(x). More generally, the future posterior
variances of the status quo vintage at that date will be given by iterates of the maps h1() and
h(S). The precise order and number of the iterates depends upon the decisions, SWITCH or NO
SWITCH, chosen by the agent. Since h1(x) x for all x, iterates of the map h1 cause the
posterior variance over the status quo vintage to fall. We defmed earlier x4' to be the fixed
point of the h mapping and indicated that iterates of this map converge inonotonically to x.
If x1 is the date 1 posterior variance over the date 1 status quo technology, vintage 1, then
it should be clear that any number of iterates of h and h1 from x1 will be bounded above
by the maximum of x1 and x. In particular, we obtain the following bound on the posterior
variances over time:


                             Var O          Max {x1, x**) for all t.
                                                  37
        Next we show that optimal policies exist by casting our model into a standard dynamic
programming framework. The action space is (SWiTCH, NO SWITCH}. Under the no recall
assumption stated at the end of section III, the state variable is the pair (ii, x) made up of the
vintage, n, of the current status quo technology and the posterior variance x over the
parameter 0,, of the status quo technology. The transition function from the date t state
variable (n, x) space and the action "SWITCH" or "NO SWITCH" into the date t+1 state
variable - either (n+1, h(x)) or (n, h1(x)) - is continuous since h1 and h are continuous.
Hence standard dynamic programming arguments ensure the existence of an optimal policy under
our boundedness assumptions.
       When technology n is the status quo technology, the payoffs to any policy are
proportional to if. This means that the optimal policies will not depend on n, and that the value
of the optimized objective will be proportional to if. This is the content of the next lemma.
        Let V,(x) be the value, under the optimal policy, of the sum of discounted payoffs when
the status quo vintage is vintage a.


Proposition 6.1 (Stationarity)
(1) The optimal policy may be chosen to be independent of the numerical value of the status quo
vintage and to depend only upon the variance of the status quo vintage.
(ii)           V1(x) = yV(x).
Proof: Obvious.


        Under this proposition, V,(x) = y1V1(x) for all n. Let V(x) denote V1(x), the value
function in the "first" period, when the status quo technology is vintage one. Defme


                  L(x) a   1(x)   +   SV(h1(x))   and R(x) a r(x) ÷ &yV(h(x)).

L(x) (resp. R(x)) is the sum of discounted payoffs when the initial posterior variance over
vintage 1 is x, when the action NO SWITCH (resp. SWITCH) is taken at date 1 and from
                                                38

 date 2 onwards the optimal decision is chosen. The functional or Bellman equation is:


                                   V(x) = Max {L(x), R(x)}.


       We now have the following:


Proposition 6.2 (Convexity). L(x), R(x) and V(x) are each downward-sloping, convex and
continuous in x.


b. Dynamic Paths for Small x and for Large x.
       In cases H and IV, for low values of x it is myopically optimal to switch, as shown in
Figure 4. The proposition that one may have hoped to prove is "whenever it is myopically
optimal to switch (i.e., whenever r(x) 1(x)) then it is also dvnwnkally optimal to switch." The
next proposition proves a somewhat weaker claim, but one that is in the same spirit.


Proposition 6.3: Fix any initial posterior variance x and suppose that r(x) 1(x) and x 1.
Then from x the strategy of choosing the action NO SWITCH at th               is g optimal. In
particular there exists an x' E (O,x) such that from x' the optimal action is SWITCH.


       All that this proposition is ruling out is the possibility that the agent chooses action NO
SWITCH at fQcfr          It however allows for NO SWITCH at some date so long as the agent
also chooses SWITCH at some other date. A stronger claim however is true when x=O:


Corollary 6.4. Suppose that r(O)t(O). (Note that this occurs in CASES Hand IV.) Then
the optimal action from x=O is SWITCH.


Remark:     It should be clear from the proof of Corollary 6.4 that the corollary can be made
to hold even when r(O) <1(0) so long as r(0) is not "too much smaller than" 1(0). By
                                               39

continuity, the action SWITCH is taken in a neighborhood of x = 0.


       The previous two results provide some insight into the dynamics for small values of x,
the initial posterior. We now say something about the large x situation. The next proposition
follows from a property illustrated in figure 1: h1 and h are both bounded above by a2. This
means that the informational value of current decisions is bounded. And since the current payoffs
are unbounded as x gets large, this means that for large enough x, current considerations will
dominate relative to future ones, and they alone will determine the optimal action. This is the
content of the next proposition, although it should be taken with some restraint since for large
x the value function is negative so perhaps production will not even take place!




Proposition 6.5: Fix a discount factor 6>0. There exists an 1>0 sufficiently large such that
           i
for all x > the optimal action for the infinite horizon 6>0 problem is the same as that of the
myopic problem.


c. Dynamic Paths for Large S
     When the discount factor gets large, the critical feature of the model becomes the value of
r(x**). Since x** is the limit of x for an agent who switches technologies in every period,
this means that if an agent switches at the maximal rate, this policy will sustain a positive net
output oniy if r(x**) is positive. In this case, a policy that maximizes the rate of growth will
indeed be optimal for large enough discount factors, and this is the content of proposition 6.6.
     But when r(x**) is negative, switching at the maximal rate yields negative long run net
output, and can not be optimal. To sustain positive long-mn output, the agent must pause after
switching, at least occasionally. Corollary 6.4 implies that it may not be optimal to pause
forever, in which case there will be cycles (in the same sense as case UB), and this is the content
of proposition 6.8.
       It is straightforward (but tedious) to show that
                                                    40



                        r(x**) =     0         as            =   1   -
                                                                         (l+a)u2 + aa.,1.


 In particular, r(x**) can be either positive or negative depending upon the values ofa, °? and
 Mf2




Proposition 6.6: Assume that r(x**) > 0.             Fix , 2 <      Then there exists a 6 in
(0, l/y) such that for all 6€ (6,1/y), the optimal action from any initial posterior variance
x in [0, 9        is SWITCH.



       The restriction that r(xt)         0 can in fact coexist with all six cases: I, HA, JIB, lilA,
HID, and IV. That is, the set of parameters for which r(x**) 0 has a non-empty intersection
with each of the six subsets of the parameter space. Appendix 2 reports six combinations of
parameters, one for each of the six cases, each of which satisfies the restriction r(x**) 0.
This means that when r(x**) is positive, optimal policies behave very differently when 6 is
large compared to how they look when 6 is small or zero. When S is small, continual
switching is optimal only when we are in case IV, whereas when S is large, switching is
optimal for all parameters satis'ing r(x**) 0.
       One of the differences between the myopic model and the dynamically optimal (i.e.
positive discount factor) model is the following. In the myopic model we have:


Proposition 6.7: For the myoDic model the agent's expected output is an increasing function
of time.


           The proof of this proposition is the following: Suppose that at date t the agent chooses
a vintage ii and obtains an expected output level of Y1. At date t+1 if the same vintage n is
chosen, since the agent will have better information on it, the output level from the use of
                                                 41

 vintage n at date t+1, Y'1+1 say, will be higher than Y1.        For the myopic model, at date
t+1 the agent will only choose a vintage different from vintage n if that vintage yields a higher
expected output.      This means that the date t+l output level can not be less than Y'1÷1.
Combining these arguments shows that                  Y1.   In summary, for the myopic model an
agent either sticks to the same vintage (which because of declining variances results in higher
expected output) or switches to another vintage if that vintage results in a yet higher expected
output. In either case expected outputs must rise over time.
         This is not the case when the discount factor is positive. In particular, in the positive
discount factor model an agent may sacrifice current output in order to attain experience with
a better vintage. This is an important difference between the positive discount factor and zero
discount factor models. We now illustrate this possibility with the aid of Proposition 6.6.
         Suppose that r(x**) >0. Choose the discount factor sufficiently large so that Proposition
6.6 holds from all posterior variances x Ct. In particular for such a discount factor it will
be optimal for the agent to SWITCH at each and every date from any beginning of period
posterior variance x C4. Consider an agent who begins with initial posterior variance on
the status quo vintage, vintage 1, equal to zero. Under the optimal policy the dates one and
two expected output levels will be


                y1 = y[1-a2-a,11 and        Y2 = y2[1-cç1-ah1(a2)-a9.


Define




It is easy to verify that for <y, y1 > y2. In particular as long as the parameter is not too
large, for this agent the optimal strategy will initially result in a reduction in output over time!
         Of course these declines in output can not persist over time. Indeed, let Y, denote the
date t expected output and let ; denote the date t posterior variance of vintage chosen at date
                                                    42
 t. Then the difference in expected output levels is given by


                              -            = yr(x11) - r(x.,)   -. (y-1)r(x) > 0 as t-. .

 Hence   in the limit the expected output, 'Y, increases at the rate .
         We provide a result which shows what may happen when r(x**) <0.




Proposition 6.8: Suppose that r(0)> 1(0)                 r(x**) < 0. Then there exists a 6 in (0,
 1/y) such that for all ôE(ô,1/y), from any initial posterior variance, the process of actions of
agents will be characterized by cycles: The agent will choose NO SWITCH for a while, then
SWITCH for a while, then NO SWITCH for a while, etc.



         Proposition 6.8 assumes the restriction r(0) >1(0), which rules out cases I and ifi. The
additional restriction r(x**) < 0 also rules out case IV. This last assertion is proved in
Appendix 3. After an extensive computer search, we suspect that these restrictions also rule out
case hA, although we have not proved this claim. We do know, however, that the restrictions
hold on a non-empty subset of parameters satisf'ing case UB. A point in this subset is the vector
(a2 = 0.5, a2 =     0.28,   a=    0.9,   y = 2.3). Therefore, as far as we can tell, Proposition 6.8
applies only to a subset of case ILk, and here the outcome is 'cycling" for large 6 just as it
was for small 6.


d. Dynamic Paths for Small 6
       If the discount factor is strictly positive but small, one would expect that the dynamically
optimal policies and time-paths will resemble the myopically optimal ones. This section shows
that this is indeed so.
         To avoid uninteresting details, in the proposition below we suppose that the parameter
values (a,-y,a1,c12) are in the generic set
                                               43

              G {(a,y,aw2,a): a 1 and [1 - uJ                  'y[1 - a12 -



Let a&*(x) denote the optimal current period action, either SWITCH or NO SWITCH, for the
infinite horizon problem with discount factor & > 0 when the initial posterior variance over
the current status quo technology is x. Let         denote the optimal current period action for
the myopic problem from the initial posterior variance x.


Proposition 6.9. (Small 6).
(i)    Suppose thatwe are 1nCASEIorCASEIV. Thenthereexistsa 6>0 suchthatfor
       all 6 in [0, 6) and for all x          0, ;*(x) = ii*(x);   i.e., the optimal action from
       beginning of period posterior variance x with discount factor 6 is the same as the
       optimal current period action in the myopic problem with beginning of period posterior
       variance x.
(ii)   Suppose that we are in either CASE II or CASE HI. Then for all E > 0 there exists
       a6>     0   such that for all 6 in [0, 6) and for all x0 outside of the neighborhood
       (x* - E,x* + E) of x,   a5t(x) =   a0*(x).




       The proposition above merely states the optimal action in the current period for the small
discount factor problem is the same as that of the myopic or zero discount factor problem. It
does not say what happens over time. The proposition is true only for a set of initial posterior
variances in a subset, [0, x* - E]U[x* + E, ), of the real line. If the dynamics of the
problem never cause the posterior variance of any vintage at any date to enter the set (x4 -E.
x* + E) then we may conclude that the entire dynamic process for the small discount factor
problem is the same as that of the myopic problem. This is the case in the situations listed
below. Hence in these situations the myopic model and the small discount factor problem have
identical actions at each and every date. We omit the proofs as these may be easily verified
from observing the figures associated with each of the cases mentioned.
                                                  44

Corollary 6.10 (Dynamics with small ). Let x denote the initial date one posterior variance
over the initial technology, vintage 1. Fix any E > 0. Then there exists a 6 > 0 such that
for all    6   in [0, 6) the infinite horizon problem with discount factor 6 and the myopic
problem result in the same optimal decisions at each date in each of the following situations:
(I)  lnCASEIorIVforalI x 0;
(hA) In CASE hA for all x x" -               E. However, even when x >         x-    E.   the myopic
          problem and the small discount factor can differ in optimal actions for only finitely many
          periods. The long run behavior of the two models is the same (and in particular in all
          periods except for possibly finitely many initial periods, the agent will SWITCH in each
          period).
(lilA) In Case lIlA for all x in [0, xt - E]L.'[x4 + E. oo) (where we suppose E              may be
          chosen sufficiently small so that x" > x" + ).
(IIIB) In CASE IIIB for all x x* - E. (However, even when x > x* - E. the myopic
          problem and the small discount factor can differ in optimal actions for only finitely many
          periods. The long run behavior of the two models are the same. In particular in all
          periods except for possibly finitely many initial periods, the agent will choose NO
          SWITCH in each period).


          The only situation where the corollary above does not apply' is in CASE IIB. Note that



      The corollary does not deal with the non-generic case, which may be handled as follows:
Suppose that the parameter values are outside of the set 0. Then either a = 1 or [1 - a.?]
= y[l - a2 - a,,2]. We consider the three possibilities: (i) Suppose fast that ya = 1 &zd
[1 - c)] = y[l - a? - a2J. l'hen 1(x) = r(x) for all x 0, and so both actions SWITCH
and NO SWITCH are optimal for the myopic problem. The conclusions of the corollary
therefore hold trivially for all x 0. (II) Next suppose that ya = I and [1 - a9 y[1 -
     -
 a,2 a9• It is straightforward to check that the proof of Part (1) of Proposition 6.9 only used
the requirement that [1 - a._]    i'll - a2 - a,,9. So the corollary above holds in this situation.
 (lii) Finally, suppose that ya 1 and [1 -           = 7(1 -      - o,,]. The intersection of r(x)
and 1(x) is now x* = 0. We therefore necessarily have x xtI. Hence we are essentially
inCASEIIB(if ya > 1)0rCASEfflA(if cry < 1),butwith xt = 0. Part(ii) of the
Proposition then applies but for x in (x* + E. co). Also, and the analogous parts of the
                                                  45

the problem is that in the neighborhood of radius E around        the intersection x" of 1(x) and
r(x), the optimal current period actions of the myopic and the infinite horizon problem may
differ. In case   118   it is in principal possible that from some given initial posterior variance x
> 0, the subsequent posterior variances will visit that neighborhood infinitely often and hence
in principle it is possible that the myopic and infinite horizon optimal actions may differ at
infinitely many dates.


Remark. The one real difference we have noticed between the myopic case and the small 6>0
case   is the following: Suppose we are in CASE ifi and suppose that xt<i. In the myopic
model, from initial posterior variance equal to x it is optimal to choosethe action NO SWITCH
at each and every date. However, from Proposition 6.3 we know that so long as the discount
factor is positive, however small that might be, it is           optimal to choose the action NO
SWITCH at each and every date.




corollary then hold.
                                                46
 VII. Positive Discount Factor in Full-Menu Model
 Boundedness of the Value Function:
 Recall that from the definition of K in (11), l-a2-h21"1(O)O. Define t:R—.R           by

               t(x)                            and




We impose the following two assumptions:
A.3. fr.1K+I<l; and
A.4.    l_a2.h2K*I(O)+o#yx4xt<o.


It should be clear that A.3 will hold when 6 is small. Also since 1-a2-h'(O)O, A.4 will
also hold for sufficiently small 6. Under A.3 the function t(x) is a linear function with slope
less than one and with unique fixed point x.
       Define VT(x) to be the value function of the T-horizon problem when the current
posterior variance is x and the status quo technology is vintage 0. Note that if instead the status
quo vintage is some vintage k then the T-horizon value function becomes y'VT(x).


Lemma 7.1 (Bound on Value Function). VT(x) x. for all T and for all x.


Since the value function for the infmite horizon model is equal to the limit as T-.oo of the T-
horizon value functions, the above result implies the boundedness of the former.


Appendix 1. The Proofs.
Proof of Lemma 3.1.: We begin by proving a stronger version of (iii):


Claim 3.1.1. For all n=l,2           and for all xi, h1(h?(x))<lQ'(h1(x)).
                                                47

Proof of Claim 3.1.1. Fix any n= 1,2,..., and define Ø0(x) e h1(h20(x)) and 4'5(x) a l½a(h(x))
It should be clear that $,(O) h1(h110)) C ht(O) = $O). Also, taking derivatives we
conclude that #F.,(x) —tf'h'(h (x)) and i5'(x) =a'h1 '(x). For x 1, h(x) x. Since h1
is strictly concave this implies that for                         with strict inequality for x<i.
This proves that for x *, Ffl(x)               I
Proof of Lemma 3.1 (cont'd): We shall prove this lemma in reverse order.
(iii)   Part (iii) is the same as claim 3.1.1 above with n=1.

(ii)    From part (iii) we know that condition LPSY holds for all xk. So it remains only to
show that the condition holds at any x> it. So fix such an x. Then by definition of 1, x> h2(x)

so



                       h1(x)>h1(h2(x))aØ,(x).                                                (13)


Since               when ka,2 we conclude that h1(x)1; i.e., h1(x) lies to the "left" of the
fixed point * of the h2 map. Hence h,(x) h2(h1(x)) 5(x). (13) therefore implies that
condition LPSY holds at x.

(i) It is easy to check that (with obvious abuse of notation)         (co)=h2(h1(.))=h2(a_2)=
aa2+a.2 and F(oo)=hl(hZ(co))=aW2.           Hence under the hypothesis of this part of the lemma,
                so s(co)ChF(o3).       Hence x1,< . Since *>O we conclude from part (iii)
that xL}SY>O. Hence O<x1251< .
        Next, fix any x x1. Now, 4'(x)=ah1t(h2(x)) and ,'(x)=ah1'(x). Part (iii) of this
lemma implies that for x>x, x>i. This in turn implies that x>h2(x). Since h1 is concave
this implies that F'(x)>S'(x) at each x>x. Since                                we conclude that

F(x)>tS(x) for all x>x1. •

Proof of Proposition 3.2. We proceed via two lemmas:
Lemma 3.2.1. Fix any x<x. Then for each n1,2
                                                 48
 Proof: Fromclaim3.1.1 intheproofofLemma3.1 we knowthatthislemma is trueforxj.
 So fix any x in the interval (i,xL).   Since   iterates of the h2 map are decreasing for any x>i,
 if x <x then so too is hf(x) <XLnY. In particular condition LPSY holds at h?(x) so
 (h2(x)) < 5(h2(x)) or


                       h1 (h2(h2(x)) C h2(h1(h?(x)).


We proceed by induction. The lemma is trivially true for n1 since this is implied by the
definition of         Suppose that the conclusion of this lemma holds for some n. In particular
suppose that for some n, h1(h2(x)) <hf(h1(x)). Applying the h2 operator to both sides of this
inequality implies that
                              h2(h1(h20(x))) < h2(h(h1(x))).


The previous two inequalities imply that h1(h2"'(x)) Ch2 '(h1(x)), so the lemma holds for n+ 1.
Hence by induction the lemma is true for all n.


Lemma 3.2.2. Fix any two agents A and B. Suppose that the date 1 variance on vintage 1
obeys condition LPSY. Fix any date T and any vintage ii. Suppose that at the beginning of
date T neither agent has sampled any technology of vintage nii. Let VarA O           and   Var5 O
denote   the beginning of date T posterior variances over vintage of the two agents A and B
respectively. Suppose that VarA O       Var3 O. Fix any two vintages n' and n" with
Suppose that at date T agent A samples vintage a" while agent B samples the "lower" vintage
n'.   Fix any N n". Let Var                Cu'>] and Var5 [°N I <ii'>] denote the posterior
variances of agents A and B respectively over vintage N. Then


                      VarA EON   I <n'>] Var5 [O I <n'>],

with strict inequality if either VarA Oj < Var5 O- or n'   <a'.
                                                    49

Proof of Lemma 3.2.2.: It is easy to verify that


VarA [O" I <n">] = hL(h((VarA O))=hi(h[°'(m.)) where mA=hl (VarA Of); and


Var3 [On"   I   Ca'>) = h2'(h1(h(°(Var8 Oj))) =h2''(h1(m5)) where m3=h2'°( Var3 03.

Now, VaIA 0 VarB          0 implies that              Hence we may apply lemma 3.2.1 to conclude

the proof of this lemma. (The application of lemma 3.2.1 requires condition LPSY to hold for
the date T variances. Note that since [0,1] C [O,x.,1, the latter interval is a stable set in the
sense that if the date 1 variances of vintage 1 lie in this set, so too will all subsequent variances
of all subsequent technologies.          Since this lemma assumes date 1 variances obey condition
LPSY. the same will be true of the date T variances.)


Proof of Proposition 3.2 (cont'd): We shall prove this by induction on the date. The case for
T = 1 is handled by the Lemma 3.2.2. So assume that this proposition is mie for some T for any
individuals F and S satisfying the hypotheses of this proposition. Since the posterior variance
at date T+ I of any agent is independent of the order in which the vintages were sampled, we
may suppose that agents sample vintages in a non-decreasing order so that the vintage chosen
at any date t is no less than that chosen at date t-1. Let i denote the vintage chosen at date T
by agent F. Let n" (resp. a') be the vintage chosen by agent F (resp. 5) at date T+1. From
the induction hypothesis, the date T variance over vintage i of agent F, Var F,T        will be less
than or equal to that of agent S. Var        O-.   Suppose   tim that if n. Then from lemma 3.2.2
above, Var          0,.    Var   S.T+I   °u' which is the induction hypothesis for T+ 1. Suppose
instead that n' <ii. Consider another agent, who we shall call agent who behaves like agent
S in periods 1 through T, but at date 1+1 chooses vintage ii. From the argument we just made
above we know that for agent S.


                                 Var F.T+I         Var   LT+I On-.
                                                  50

 However from Lemma 3.2.2 we may conclude that


                          Var      0,. < Var

Hence Var F.T+I O,, < Var s,T+l On., which again is the induction hypothesis for T+1. Hence
by induction the proposition is true for all 1.        (It should be clear how we obtain the strict
inequality asserted in this proposition from the strict inequalities obtained in Lemma 3.2.2.) I


Proofs of Propositions 5.1-5.4: We begin with the following lemma:
Lemma 5.5. Assume
i.       Then for each k= 1,2         ;*=hj(x1*). In particular, ; is the (k-1)-th iterate of the
         inverse of the function h2 from x1.
ii.      If ;0 for some k, then ;.<O for all lc'>k.
Proof:       (i) By definition x1" is the unique point of intersection of the functions G(x,O) and
G(x,1). Fix any integer k. From the definition of;, G(x,k-l)=G(;,k). Hence from the
definition of the G(x,k) functions, [1_aW2_hz(xk*)] =y[1g2_h2(h2k(;*))] In particular, at
x=htl(xt*) we have G(x,0)=G(x,l). Hence h(xt*)=x1*, from which part (i) of this lemma
follows.
('ii) From   (i) we know that the ;*'s are iterates of the map hj'. The slope of the latter is 1/cr.
When cr< 1, lIcz>1 so iterates from any x4'O converge monotonically to -.               If a=1 the
h' mapping has slope of one but is everywhere below the 45 degree line. Again, iterates from
any ;'O converge monotonically to -. Finally, ii a> 1, the fixed point of h24 is the point
a,2/(l-a) which is negative. From ;0, iterates of hi' converge monotonically to this point.
In either case, part (ii) of the lemma follows. I


Proof of Proposition 5.1. (CASE 1). In case I cry> 1. Also O(O,O)=t(0) >r(0)=G(0.1).
So x,*<O.        From    lemma 5.5(u) this implies that ;*<0 for all k. If for some k
G(0,k) G(0,k+ 1) then, since the absolute value of the slope of G(x,k+ 1) exceeds that of
                                                 51

G(x,k) when cry>!, their point of intersection, xk+i*, will bepositive. This is a contradiction.
 Hence G(O,k) > G(0,k + I) for all k from which the proposition follows. •


Proof of Proposition 5.2. (CASE II).       In case II ay>1 and G(0,O)=t(O)<r(O)=G(O,!).
Hence     x1 * >0. Define M to be the largest integer m such that G(0,k-1) <G(O,k) for
k= 1,2       m. From the defmition of M, G(O,M) G(O,M+1). Since the absolute values of the
slopes of the G(x,k) functions are increasing in k when cry>!, this implies that xM+l*O.
From lemma 5.5(11) this in turn implies that ;*0 for all k>M. Suppose, per absurdem, that
for some k>M, G(O,k)>G(0,M).                     Let k' be the          first   such k.     Then
G(0,k'-l) G(0,M) <G(0,k'). This then implies that ;.*, the point of intersection of G(x,k'-l)
and G(0,k'), is positive. This contradicts our earlier assertion that ;* O for all k> M. Hence
G(O,k)G(O,M) for all k>M. Since the slope of G(x,k) is greater in absolute value than the
that of G(x,M), we conclude that                      for allxO. This proves the Proposition. I



Proof of Proposition 5.3. (CASE llfl. In case Ill cry< 1, so the absolute values of the slopes
of the G(x,k) functions are decreasing in k. If for some k, G(O,k)          G(O,k-l) then ;*O.
Lemma 5.5(u) would then imply that ;*<O for all large k. However, from (1!) for all large
Ic   G(0,k) G(0,k-l), so ;*O for all large It. This is a contradiction. Hence we conclude
that G(O,k) < G(O.k-!) for all k=!,2         This proves part (i) of the lemma.
         Since ay< 1, a< lIy <1. From Lemma 5.5(i) the x4 's are iterates of the hj'
function. This function has fixed point i = a12f(!-a) >0. and slope 1/a> I. From the definition
of x1 it is easy to check that x can never be equal to 1. Iterates of this function from any
x1'      converge monotonically to either + oo   or -.    Since   we have just shown that the ;*'s
are positive for all large k, we conclude that the monoconic convergence is to + .   from which
part (ii) of the proposition follows. The remaining parts of the proposition then follow
immediately. •
                                                52

 Proof of Proposition 5.4. (CASE IV). In CASE IV ay < i and G(0,O) =t(O) c r(O,O)=G(0, 1).
 Hence x1t must be negative. From Lemma 5.5(u) this implies that ;* is negative for all Ic.
 However from (11), G(0,lc) G(O,k-l) for all large Ic. Since the slopes of the functions G(x,k)
are decreasing in k this implies that x is positive for all large k. This is a contradiction.
Hence case 4 is incompatible with our assumptions (and in particular assumption A.2, from
which (11) was derived).


Proof of Lemma 5.6: (i)        Since for all Ic, g(k) =h1(h2(k)) =h1(I) <k and g(O) >0, we
conclude that xk**c(O,i). However, for any x in (0,t), gk(x)<g1(x). It is easy to see that this
implies that Xk**<XtI**. This proves the first part of the lemma.
(ii) We argued in the previous paragraph that ;*+€(O,*) for all Ic. Hence k(x$*) Ci which
implies that ;** hi(h2k(x**)) <h1(k) for all           Ic,   so lim_ ;** h1(i).            Also,
    = h1(h2k(x**)) h(h2k(0)), and IiWk.. h2k(O) =, so li1nk. ;** h1(k). Combining our
results shows that limk. ;**=h(A) •


Proof of Proposition 5.9: If the initial posterior variance lies in [x1*,00) the action NO
SWITCH will be chosen. The posterior variance will in finite time enter the set [0,xt*). From
lemma 5.6 and the hypothesis of CASE HA', ;**XMxI* for all                       Hence once the
posterior variance process enters the set [O,;), it will stay there forever after. In the set
[O,x1*) the optimal jump size is greater than or equal to one.


Proof of Proposition 5.10. (Case IIB): Under CASE II, and lemma 5.6 above
x1*cx1**<x2**<x3**<... Whenever the posterior variance is inthe set Ex1*,oo) the action
NO SWITCH is chosen. This causes the posterior variance to decrease monotonically. After
some finite date the posterior variance will fall below x1'. At this time a jump of size j equal
one or larger will be chosen. This causes the posterior variance to move toward ;fl. Since
    > x1 for all j 1, evenwally the posterior varaince will enter again the set [;*, cc), and the
process described above is repeated; ad infinitum. •
                                                 53

Proof of Proposition 5.11. (CASE lilA): (i) This should be obvious from fig. 9 of CASE III.
(ii) If the initial posterior variance lies in the set (x1,00), a jump size of j   1 will be chosen.
 The hypothesis of CASE lilA and lemma 5.6 imply that x<xt for all k. Hence if the
initial posterior variance lies in the set (x1, oo) andj 1 is chosen the posterior variance process
will remain in the set (x1*,00). By induction we see that the posterior variance process will
indeed be in the set (x1*.) for each date and hence a jump size greater than or equal to one
will be chosen at each date. I



Proof of Proposition 5.12. (CASE 0W'): (1) Under the assumptions of CASE ifiB' and
lemma 5.6 Xk h1(i) < x for all Ic. Hence from any initial posterior variance, the posterior
variance wilt enter the set [O.;9 in finite time. (ii) It should be obvious from fig. 9 that if the
initial posterior variance lies in [0, x1 ] the optima] action is NO SWITCH (or jump size of zero)
at each date.    I

Proof of Proposition 6.2.: The continuity of L(x), R(x) and V(x) follow from the dynamic
programming arguments mentioned earlier and the continuity of h(x), h1(x), e(x) and r(x).
       To prove the other parts of the proposition we adapt the following arguments from
Nyarko (1994). Let a *poljcv to be a policy which is independent of both the date one posterior
variance x and the history of observations at date t; a *.policy may however depend upon the
date. (In particular,a *_policy is a deterministic rule for choosing actions as a function of the
date.) Recall that t is the set of all policies. Let 'I's be the set of all *.policies. Since
V(x) = Sup,1. V(x). and since W c 'p.


                                     V(x) Sup. V(x).                                           (14)


       We showed in proposition 6.1 that the optimal decision at each date may be chosen to
be a deterministic function of the status quo vintage and posterior variance of that vintage at each
                                                 54

date. But the Dosterior variance over any vintage at any date is a deterministic function of the
initial posterior variance x, and the sequence of decisions chosen up to that date. Hence the
optimal decision at any date is a deterministic function of the initial date one variance, x, over
vintage 1. Hence if we LIA a posterior variance x over initial vintage 1, there will exist a -
policy which attains the same sum of discounted returns as the optimal policy. Hence for each
x, V(x) Sup. VT(X). Combining this with (14) implies that


                                      V(x) =    SUPTit.   V(x).                                 (15)


        The use of any *..policy,     r, results in a fixed deterministic sequence of decisions
SWITCH or NO SWITCH over time and hence a fixed deterministic sequence of vintages
chosen at each date. This sequence is independent of the date one posterior variance x. The
sequence of variances of the chosen vintages at each date is a sequence of iterates of the maps
h() and h1() defined earlier. Now, both h(x) and h1(x) are strictly increasing and strictly
concave functions of x. Hence any finite sequence of iterates of h and h1 are also strictly
increasing and strictly concave in x. Hence, the same is true of the variance of the vintage,
m(t), used at any given date t under the -policy r, Var, O. Now, the payoff at each date
  is y"[1 - VarL Oi) - a2].      The discounted sum of payoffs, V(x) is a strictly convex and
strictly decreasing function of x. Eq. (15) therefore implies that V(x) is the supremum of a
collection of strictly convex and strictly decreasing functions of x. It is easy to verify that since
the supremum in (15) is attained for each x, V(x) is therefore also a strictly convex and
strictly decreasing function of x.
       Next define ,p*L (resp. t*Jt) to be the set of all *..policies which choose the action NO
SWITCH (resp. SWITCH) at date 1. Following the previous arguments it is easy to show that




            L(x) = Sup {VT(x): r e t'} and            R(x) =   Sup   VT(x): r e
                                                    55

and   so L(x) and R(x) are each strictly decreasing and strictly convex in x.


Proof of Proposition 6.3.:     Let x and 6 be as in the proposition. Let r denote the policy of
choosing the action NO SWITCH in each period, and let V(x) denote the return from this
policy. Let ?T' denote the policy where the action SWITCH is chosen at date 1, but where in
each subsequent period the action NO SWITCH is chosen. Let V.(x) denote the return from
this policy. Clearly it suffices to show that VT<Vr.
        Under the policy ir, the date t priQr variance over the date t status quo technology
(which of course is vintage 1) is h1tA(x) where h10(x)x and h1'(x) is the t-1 times iterate of the
function h1 from x. Under the policy 1, the date 1 prior over vintage 2 is ax+a2. The date
2 prior variance over vintage 2 is h(ax+a1); and the date t prior variance over vintage 2 is
h1'1(ax+a2). Hence the difference in discounted payoffs of the two policies is


             = E ; 61A where


\ y[ I awZhjt1(ax +a.2)][1az_h1H(x)] = (y_l)(1_a2) + [h1E1(x)yh1l(ax +a,1)]


Note that r(x)-e(x)=1,            so     £S1 0 by assumption.            We will now show that
[h1'1(x)-yh1''(cix+a,2)] (which   is   negative) is strictly monotone increasing in t (so is becoming
less negative as t increases). This will imply that A>0 for alit>          1. This in turn will prove
that Vr(X)Vr(X) >0 which will prove this proposition.                        Now, we may write
[hi(x)yhjt(ax + a,2)] =A1+B1 where A1             [h1'(x)-h1"(x+a)1 and B1
Since h1 has slope everywhere less than one, I            I   is non-increasing in t.   Since for xi,
hiL(x) C h1'(ax+a2) we conclude that A, is non-decreasing in t. Since h1(ax+a,2) is strictly
decreasing in t, B1 is strictly increasing in t. Hence A,+B, is strictly increasing in t.      •

Proof of corollary 6.4: If from x=O the action NO SWITCH is chosen then the posterior
                                                                  56

variance of the status quo technology will be x=O in the next period as well. Hence from the
stationarity of the problem, if from x =0 it is optimal to choose the action NO SWITCH at date
1, then it is optimal to choose that action in each and every subsequent date. However
Proposition 6.3 implies that it is iii optimal to choose the action NO SWITCH in each period.
Hence the optimal action from x=O is SWITCH. •




Proof of Proposition 6.5: The variance from period 2 onwards always lies between zero and
as). Hence the discounted future sum of returns (from dates 2 and onwards) is bounded between
V(0) and V(a2). However, as x-" the difference between the current period rewards, r(x) and
t(x) goes to infinity. Hence, there exists an i such that for all x>i,                         r(x)-f(x) j > Sup1
 I   ÔV(h1(x))-V(h(x))   I   . Using the Bellman equation therefore proves the proposition. •


Proof of Proposition 6.6: Recall that a Icpolicy is nothing other than a sequence of decisions,
SWITCH or NO SWITCH, for each date, with the decisions being made as a function of the
date but independently of the posterior variance at that date. We begin with the following claim:


Claim: Define M 1/[1 - Max{a,                        1I'y}]. Fix       any two initial date I posterior variances x'
and x". i. For any fixed *.policy r,                          VT(x') - V1(x")    I       M x' - C       I
                                                                                                               and
ii. V(x')-V(x") -M x'-x"
Proof of Claim:     (i) Let ir, x' and C be as in the claim. Let m(t) denote the vintage of
the technology chosen at date t and let a1'2 (resp. oy'2) be the prior variance at the beginning
of date t of the vintage chosen at date t under the *..policy r from initial date 1 posterior
variance x' (resp. x").               Define for each t,


                             I   (1   —
                                          a1'2 — a..)) — (1   —
                                                                  0n2 — a.)) I   =           I aj2 — a1u12 I




Suppose    that at date t the action SWITCH is chosen. Then m(t+l) = m(t) + 1.                                   Also,
                                                        57

        =   ah1(a1'2)   + a12 and a1.1"2 =      ah1(a1"2)    + a,, so       01+112 —   u1i"2   I
                                                                                                                 °' —
a"2         Hence


        w=                      a1.1'2 - o1j'2 = a(&y)ö''y°'          cr1'2 — "2          Max {a, lIy}.w1,


where we use the fact that fry < I for the last inequality above. Alternatively, suppose that
at date t the action NO SWITCH is chosen. Then m(t+1) = m(t). Also, o"2                            = h1(cr1'2)    and
        =   h1(a1"2)    so (since 0h1(x)IOx <1),    I         — o+N2 I           I '2 — Q"2        .   Hence



                    6L7Th(LIM   a1.1'2   - ai"2 = ö.&y'           a1'2 — cr1"2       Max {a, 1/}.w1

where   again we use the fact that ô < lIy for the last inequality. We therefore see that
regardless of the decision chosen at date t. w141               Max {a, 1/y}.w1. Hence, w1 (Max
(a. 1/y})twi for all t > 1, so


                                            S w1/[1 - Max {a, 1/y}] = w1M.


Now w1 =                 a1'2 - a1"2      If the decision NO SWITCH was chosen at date 1 then m(I)
= I, a'2 = x' and al2 = C so w1 = Ix' -x"                         If the decision SWITCH was chosen

atdatelthen m(1)=2, g1'2=ax' +a, and                         a1"=ax" +a sow1 alx'-x"I
S x'-x". Ineithercaseweseethat                           w1 Ix'-x"I.              Puttingthisintheabove
equation and recalling the definition of w1 implies the conclusion of part (i) the claim.
(ii) Let r be the *.policy which is optimal from initial posterior C. Then V(x') V,(x') and
V(x") =V(x"). Hence V(x')-V(x")                V.(X')Vr(C). An application of part (I) of this lemma
therefore proves part (ii). •


Proof of Proposition 6.6 (cont'd): Since x 0, h(x) S a2 and                                and since VC) is
                                                               58

monotone decreasing,
                                V(h(x)) - V(h1(x))       V(a2) -      V(O).                                               (16)


Part (ii) of the claim above implies that V(a2) - V(O) -Ma2. (16) therefore implies that
forall x           0,



                                         V(h(x))
                                                    - V(h1(x))      -Mcç.                                                 (17)


Fix any ? > Q2 Define

                                         M = Maxflt(x)-r(x)I: xE [0,9}.                                                   (18)


Then        M < .
            Suppose     that   r(x**) > 0.      Then there exists    a E   >0      sufficieutiy small such that         r(x**
+ E) > . We now                compute the return     to the   policy, irncn,        of switching in each       period from

initial     posterior x=cç2. Let {x.}1             be the associated posterior        variance process from        7H•
Since x, —.        x',     there exists a T C Co such that for all t > T, ; C                     x"' + E.         so     r(x.)

>      E.    If   M is as in (18) above, the discounted sum                     of   returns to this policy will then


necessarily exceed -TM + E1,1(67)'E = -TM                            + E(&y)TI(1 - &y) 'This tends to infinity as
5 —'    1/')'. Hence V(a2) tends to infinity as S — 1/y.
            Since for all x         0,   h(x)    a,2, V(h(x))         V(a,,2)     so V(h(x)) tends   to         as S —'   lly.
Hencewemaychoosea 5< 1/y suchthatforall S                                     &    andforall x        0,




                                   -
                                       1)V5(h(x))    >    Ma2 + M,                                                        (19)




where       we subscript the value function V            by S to emphasize its         dependence on       5,   and where
M and M are as in (17) and (18), respectively, (and are independent of 6). Using (17) and
                                               59

(18) in (19) implies that for all such 6, and for all x      (0, 9,

           -
ö'yV5(h(x)) 6V6(h1(x))
                         =   ô(y - 1)V6(h(x)) ÷ &[V3(h(x)) - V3(h1(x))]   > M + 6Ma2 - 6Ma2
                                                                           = M > 1(x) -
so

               R(x) = r(x) + &yV5(h(x)) > 1(x) + 6V(h1(x)) = L(x).

Hence the optimal action from such & and x is SWITCH. •


Proof of Proposition 6.8: It suffices to show that from any initial posterior variance the agent
chooses each action, SWITCH and NO SWITCH, infinitely often.
        Suppose that from initial posterior variance x the optimal action is SWITCH. Then
since the posterior variance in the next period will remain at xt, it will be optimal to SWITCH
in each and every period. Since r(x**) C 0, this will result in a negative payoff in each
period. As 6 converges to 1/y this payoff can be easily seen to converge to -.         If on the
other hand the agent chooses the action NO SWITCH in each period, the agent will have a
return of at least f(x**)I(lô) which converges to the finite number 1(x**)/(l1/y) as &-'lIy.
Hence   there will exist a 6 in (0, lI-j) such that for all 6E(Ô,lIy) it is not optimal to SWITCH
from x. Under obvious continuity of the L(x) and R(x) functions the optimal action
within a neighborhood of x4 is also NO SWITCH. If the agent chooses the action SWITCH
for all but finitely many periods, the variance process will converge to x**. This will
contradict the earlier assertion that from a neighborhood of x** the optimai action is NO
SWITCH. Hence the agent will choose the action NO SWITCH infinitely often.
        Using Corollary 6.4. from initial posterior variance x = 0, and hence from a
neighborhood of c = 0, the optimal action is SWITCH. If from some initial posterior variance
x1 > 0 the agent chooses the action NO SWITCH for all but finitely many dates then the
posterior variance process will converge to zero. This will contradict the fact that from a
neighborhood of zero the optimal action is SWITCH. Hence the action SWITCH will be chosen
                                                            60

infinitely often.
         In summary we have shown that from any initial posterior variance the optimal policy
will choose both actions, SWITCH and NO SWITCH, infinitely often. Hence we have
"cycles." I



Proof of Proposition 6.9. (small 6): We prove part (ii) first. Fix any E > 0.                     Define


                                          ,c(x)         I   1(x)-r(x)   I     forall x       0.


Under the assumption that the parameter values lie in the generic set G both 1(x) and r(x)
are linear functions with different slopes and different intercepts and with a strictly positive
intersection x'. It is therefore easy to see that


  x(x)      ,c(x*+E) = ic(x-E) > Oforall xE [0,x*_E)U(x*+E. oa).                                           (20)



Now, hL(x) = a2xJ(x + a2) ct,,,2              and      hence h(x) = h1(h2(x)) a,,,,2. Hence regardless
of the current period decision, SWITCH or NO SWITCH, the next period posterior variance will
be bounded above by a2. This will be true for the posterior variance at each date. Hence
absolute value of the expected payoff in each period is uniformly bounded, by some number
K say. Hence        I   V5(h1(x))   I   K/(1 -    6)   and       yVa(x)) I          yK/(1 - 6), where we now
index the value function by the subscript S to denote its dependence on 6. This in turn implies
that Sup10ô V/h1(x))-1V3(h(x))l -0 as 6—0. Inparticularwemaychoosea S > 0
such that


               S I V6(h1(x))    - 7V6(h(x))   I   < ,c(x' - E)/2            for all S < 5.                 (21)


Combining this with (20) above implies that
                                                          61

 p1(x) - r(x)   I
                      > 6I   V6(h1(x)) -   yV(h(x))   j    vô C Ôand Yx in [0, x - flU(x* + E.      oo).


It is then easily verified that this in turn means that


        1(x) > r(x) implies       that 1(x) + 5V6(h1(x)) > r(x) ÷ yV3(h(x)) and

        1(x) < r(x) implies that 1(x) + 6V3(h1(x)) C r(x) + yV8(h(x)).                              (22)


Note that L(x) = f(x) + 6V6(h1(x)) (resp. R(x) = r(x) + yV5(h(x))) is the return to the agent
that chooses the action NO SWITCH (resp. SWITCH) in the current period and behaves
optimally in each subsequent period. (22) therefore implies that the decision which maximizes
the myopic return also maximizes the infinite horizon return with discount factor 6. This of
course is part (ii) of the proposition.
Part (1): To prove part (i) of the proposition observe that 4x) s           1(x) - r(x)      is monotone
non-decreasing in x in CASES land IV. Further, [1 - a9 ,#Ei - a? -                        ic(O)
- r(0) > 0. Hence we may replace (20) with sc(x) a J 1(x) - r(x)                 I        sc(O) > 0. and
proceed analogously to the proof of part (ii) above to obtain the proof of part (i) of the
proposition. •


Proof of Lemma 7.1.: In the myopic problem from initial posterior variance x=0 the agent
will never choose a jump size greater than K+ I since this will result in a negative payoff while
choosing no jump in each period results in a payoff of 1a2>0 in each period. The return to
choosing a jump size of kK+1 results in a payoff no greater than y'"'[1-c,2]. From the
definition of x it is easy to see that y[1-aj]x. Hence
        We proceed by induction: suppose that for some T=1.2                     we have shown that
VT(O)   x.   The value function of the T+ 1 horizon problem from initial posterior variance x=0
is:



                    VT+ '(0) = Max_012• .yk{ 1-a2-h(O)+öW(h,(h21(O))}.
                                             62
Ifajump size of k>K+1 is optimal for this T+i horizon problem from x=O, then the return
will be no greater than yk{lawZh(o)+&VT(0)}, which from the induction hypothesis is no
greater than 7k{ 1-aj-h"(O)+bx.j.    This latter expression is, from (21), negative for all
k>K+l. However, if a jump size of zero is chosen at each date the return at each date will
be l-cj which is positive. Hence it is not optimal to choose a jump size k>K+1. With this
result we may conclude from the definition of w a above that


                VT'(0) yK#l(lo2)+frYK+IiT(O) B t(V1O)).

Since VT(O)     x,, we conclude from the obvious properties of 'P that t('V'O)) x. So
V1(O)x. •

Appendix 2. Verification that all the CASES I-IV are non-empty.
It should be obvious that there exist parameter values such that CASES I and IV hold.
Set al =        = 0.25. Then


[(1 - a - ç_2) - (1 - a2)] = [O.5y -0.75] =       [2y - 3]/4 and


    = [y(l - a,2 - a2) - (1 - a2)]/['ya - 1] = [2y - 3]/[4(ya - 1)].


Also,


        = [a..)(ax"' + a,2)]/[a2 + (** + al)]


Hence    a2a2/(a2 +       a) x** ,2 S

1/8 x'             1/4.                                                                 (23)
                                                     63

CASE      hA x > x". Fix any a. Let y tend to infmity. Then x = 0.25[2y - 3]/[c.ry -
11   l/(2a). Hence for any fixed a C 1, we may choose a 7 sufficiently large so that (ay)
     —.


> 1, 0.25[2y - 3] > 1 and xt > 1/(2a) > 1/4 >                x,
                                                     so that we are in CASE hA.



CASE HB x C          x'4t.   Take a sequence {7k}kl converging to 3/2 from above. Let a
be any sequence converging to 3/4 from above. Then akyk —' 9/8 > 1 and O.25(27t - 3) >
0 for all k. Hence we are in CASE II for all k sufficiently large. Further, ;* =        -

3]/[crkyk - II —. 0 so xk* C 1/8 C     x
                                     for all k sufficiently large, which implies CASE RB.


Case hlL&; x < x. Now consider a sequence {7t}k-a converging to 3/2 from below.
Define ak = "27k' in which case c converges to 1/3. Also at'y& =                1/2   C   1   and 2Tk -
3    converges to zero from below so for all k sufficiently large we are in CASE III. Now, in
this case x' =               - 3]/[akyk - 1]   -.0 so for k sufficiently large x' C 1/8 C       x   so
we are in CASE lilA.


Case RIB: x > x. Fix any a C                   1.   Pick any sequence of y's converging to one from
above. Then eventually, (ay) < I and [y(1 - a - 2) - (1 - a2)] = O.25[2y - 3] < 0 so
we are indeed in case III. Also x" = O.25(2y - 3]/(ay - 1) converges to 0.25/(1 - a) >
0.25, so from equation (23) we conclude that x > x' so we are in CASE IJIB.


          Each of the above cases can coexist with the restriction, made in proposition 6.6, that
r(x**) 0. The following six sets of parameters do the job:


Case I:   a2 = 0.30, a2 = 0.25, a = 0.75,7 = 1.55.
Case HA: a,2 = 0.25, 2 = 0.25, a = 0.75, y = 1.55.
Case hIB: cc2 = 0.25, a? = 0.25, a = 0.75, y = 1.54.
Case lilA: a) = 0.20, a? = 0.30, a = 0.50, y 1.55.
Case hUB: a) = 0.20,         a
                         = 0.30, a = 0.60, y = 1.55.
                                                             64
 Case IV:      a2 =      0.10,   a2 =    0.30,    a = 0.60, y =        1.55.



 Appendix 3. Proof that the Conditions in Proposition 6.8 Rule Out Case IV. It is enough
 to show that r(x") C 0 and y(l      - a12) > (1 - a2) is impossible when ay C 1. First,
 note that



                                                          aXax ' + a)
                                          x        =     _________
                                                             + (ax"      +   a)

the solution of which is



                     -     { —(a     +        —
                                                  aa,)   +   [(at, + a   -   a,a)2   +4a4a]Ih2 }
                                                                  2a


The negative root is inadmissable because x 0. Now r(x") = 7(1 - a2 -                              - ax") C 0
implies that   1   - a,2 - a2     < ax'. Substitution for C into the above inequality and (very
tedious) rearrangement gives



                   y(l -          - a) C          ycw,(1 — o,)
                                           C aAl-c4)                         since a < 1.
                                              (1—a)                          since a,  1.
(We assume     a21 since otherwise net outputs are always negative.) So r(0)<f(0). •


Appendix 4. The No-Recall Assumption:
The analysis of this paper assumed the following no-recall constraint: An agent who chooses
a vintage nat date t,     can    not choose a lower vintage n'<nat any future date t'>t. We now
proceed to show that if we are in the myopic model, it is never optimal to exercise the recall
                                                  65

option and choose a vintage that was previously passed over. Our conjecture is that the same
result is true in the positive discount factor problem. Our conjecture is given support by the fact
that we have a proof that it is not optimal to exercise the recall option in the two-horizonversion

of the problem with positive discount factors.
       To proceed we will require some notation:          Suppose that at date 1 the variance-
covariance matrix over (01,02....)   is   given by E=({xJ4..12J.



Lemma A4.O: Then alter observation of y=0+w1 the posterior variance of °k is given by
                                Var (O I        = xx2/[x+aw1.


Proof': Let St denote the posterior variance-covariance matrix after observation of Ym=Om+W.
Then from Chow (1983, p. 13), S*=S_SI2Ej%It, where S12 is the matrix of covariances
between Ym and (01,02,0     )   and where S, is the variance of y,,,. Now. Var y,,, =
 for any j = 1,2     Coy (0.y,J=E[(O-E0)(y-EyJ] =E[(Oj-EO)(Om+wm-EOJ] =x. Hence
applying the formula we see that
                                Et=S(Xirui,Xzm,. .             I[x+c9.

The (k,k) element of this matrix can easily be seen to be x-xfr/(x,,,,,+u_2). I


          Let q and        denote the dates 1 and 2 output levels respectively.                Let

Q1( C k> ) = E[q1 I <k> I denote the expected date 1 output level if vintage k is chosen at date
1. Let Q2( C k1,k1> ) =       <lc1,k>] denote the date 2 output level if vintage k1 is chosen
at date 1 and vintage Ic2 is chosen at date 2. Let R(<k11k2>)Q1(<k1>)+SQ(<ki,kz>)be
the discount sum of net outputs when vintage k1 is chosen at date 1 and vintage 1c2 is chosen at
date 2.


Lenuna 44.1: Suppose that it is optimal to choose vintage nat date 1 and vintage 1 at date 2.
                                             66

Then R(<n,1>)-R(<1,n>)0.
Proof: Suppose agent A chooses vintage n followed by vintage 1 • while agent B does the
reverse and chooses vintage 1 followed by vintage n. If each began with the same date 1 prior
each agent will have at the beginning of date 3 the same variance-covarianee matrix since they
receive the same information, although in different orders. In the no-jump model each agent
will also have at the beginning of date 3 the same maximal vintage chosen. Hence from date
3 onwards the decision problems of the two agents will be identical.      Suppose each agent
chooses the optimal policy from dates 3 onwards. By hypothesis of the lemma, agent Ks policy
is optimal. Since agents A and B will have the same return from dates 3 onward, agent A's
return in the first two periods can not be less than that of B's in the first two periods. The
conclusion of the lemma follows from this observation. •




Lemma A4.2: R( Cn,1 >)-R(< l,n>)=[1-b+ôfl[Q(<n>)-Q(C 1 >)1-o(X'-1)


where                             >0.


Proof: Since
Var [O    <1 >]=x    - xi/(xii+orl) fl,j
Var [O    <n>]=x1 -     x102I(x,,,+c2), one may easily verify that


R(<n,1>) = X0l{1_a2_xj        + S{1-a_2-x11+ xi,?I(x.,,+a2)} and
R( <1 ,n> ){1-a2-x11} + öX'{1ow2x,m+ x1,,I(x,,,+u2)}


from which the lemma follows immediately. •


LemniaA43: R(<n,1>)-R(<1,n>)O implies that
Proof: This follows immediately from lemma A4.2. •
                                                67

Lemma A4.4: Q1(<n>)Q1(<1>) implies that Q2(Cn,n>)>Q(<n,1>).
Proof:
Q2(<n,n>)-Q2(<n,1>)=X°4{1-a2- x + x.$/(x,.0+u2)} - {1-a' - x11 + x12/(x+o2)}.
The Cauchy-Schwartz inequality implies that X122X,aXlj. Hence the above is




  (X°- 1)( 1-a.)) - (A'1x-x1.1)(1- xJ(x+a.)))                                              (1

= Q1( C n > )-Qi( <1>) + (X'x,s-xll)xJ(xM+t7W2).                                          (**)


If (X"'x,-;1) O then the RHS of (*) is non-negative from which the lemma follows. If (X'iç,,-
x1j>O then the lemma follows from (**)• •


Proposition A4.5 (No Recall): Suppose that we are either in the (a) myopic model or (b) two-
horizon model. Then an agent will never use the recall option.
Proof: If the agent uses the recall option then (by rescalling) we may assume that at some date
I the agent uses a vintage n> 1. and at date T-l-1 uses vintage 1.
(a)      Suppose we are in the myopic model. Then at date T the return from using vintage n,
         QT(<n>), must exceed that of using vintage 1, Qc1>). From lemma A4.4 this
         implies that the date T+1 return from using vintage n, Q1(Cn,n>), exceeds that of
         using vintage 1, Q,+1(<n,1 >). However, for the myopic model, this implies that
         vintage n is used in period T+1, which contradicts our earlier assertion.
(b)      Now suppose that we are in the two period model. Then R(<n,1>)R(<1,n>).
         Lemmas A4.3 and A4.4 imply that 04(<n,n>)>Q(<n,i>). But this in turn implies
         that for the two period model, at date T+1 vintage n is chosen. This contradicts our
         earlier assertion. •
                                             68
References:

Chari, V.V., and Hugo Hopenhayn, "Vintage Human Capital," Journal of Political Economy
       99, no. 6 (December 1991): 1142-1165

Chow, Gregory, Econometrics, New York, N.Y.: McGraw Hill (1983).

Lucas, Robert F    Making a Miracle," &otjo,netrica 61, no. 2 (March 1993): 251-72.

Nyarko, Yaw, "On the Convexity of the Value Function in Bayesian Optimal Control
       Problems," Economic Theory, (1994).

Parente, Stephen. "Technology Adoption, Learning by Doing, and Economic Growth,"
       unpublished paper, Northeastern University, October 1991.

Prescott, Edward, "The Multi-Period Control Problem Under Uncertainty," Econometrica 40,
       no. 6 (November 1972): 1043-58.

Stokey, Nancy, "Human Capital, Product Quality, and Growth," Quarterly Journal of Economics
       106 (1991): 587-616.

Wilson, Robert, "Informational Economies of Scale," Bell Journal of Economics (Spring 1975):
      184-95.

Young, Alwyn, "Invention and Bounded Learning by Doing," Journal of Political &onomy 101,
      no. 3 (June 1993): 443-72.
