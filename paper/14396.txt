                                NBER WORKING PAPER SERIES




       PARTIAL PRESCRIPTIONS FOR DECISIONS WITH PARTIAL KNOWLEDGE

                                         Charles F. Manski

                                        Working Paper 14396
                                http://www.nber.org/papers/w14396


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     October 2008




This research was supported in part by NSF Grant SES-0549544. I have benefitted from the comments
of Ken Binmore, Larry Blume, Buz Brock, Dan Hausman, Francesca Molinari, Jörg Stoye, and Alex
Tetenov. The views expressed herein are those of the author(s) and do not necessarily reflect the views
of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2008 by Charles F. Manski. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to
the source.
Partial Prescriptions For Decisions With Partial Knowledge
Charles F. Manski
NBER Working Paper No. 14396
October 2008
JEL No. D81

                                             ABSTRACT

This paper concerns the prescriptive function of decision analysis. I suppose that an agent must choose
an action yielding welfare that varies with the state of nature. The agent has a welfare function and
beliefs, but he does not know the actual state of nature. It is often argued that such an agent should
adhere to consistency axioms which imply that behavior can be represented as maximization of expected
utility. However, our agent is not concerned the consistency of his behavior across hypothetical choice
sets. He only wants to make a reasonable choice from the choice set that he actually faces. Hence,
I reason that prescriptions for decision making should respect actuality. That is, they should promote
welfare maximization in the choice problem the agent actually faces. I conclude that any decision
rule respecting weak and stochastic dominance should be considered rational. Expected utility maximization
respects dominance, but it has no special status from the actualist perspective. Moreover, the basic
consistency axiom of transitivity has a clear normative foundation only when actions are ordered by
dominance.


Charles F. Manski
Department of Economics
Northwestern University
2001 Sheridan Road
Evanston, IL 60208
and NBER
cfmanski@northwestern.edu
1. Introduction



        I consider here the prescriptive function of decision analysis, which is to develop constructive rules

for decision making. I suppose that an agent—perhaps a firm, an individual, or a planner—must choose an

action yielding welfare that depends on the state of nature. The agent has a welfare function and beliefs,

which I take as primitives. Formally, the agent knows that the choice set is C, the feasible states of nature

are S, and the objective is to maximize a function w(@, @): C × S 6 R1 mapping actions a 0 C and states s 0 S

into welfare. For example, w(@, @) may be the profit function of a firm, the utility function of a consumer, or

the welfare function of a social planner. The problem is to choose an action without knowing the actual state

of nature.

        Decision analysis has long distinguished two polar versions of this problem. In choice under

uncertainty, the agent only knows (C, S, w). In choice under risk, he also knows that the states of nature form

a probability space (S, Ù, P) and that the actual state of nature will be drawn at random from distribution P.

In both cases, the prevalent prescription has been that the agent should maximize expected utility.

Expectations under risk are taken with respect to P. In the case of uncertainty, the agent is called upon to

form a subjective probability space, say (S, Ùu, Pu) and take expectations with respect to Pu.

        Why should an agent maximize expected utility? A standard response has been to cite representation

theorems deriving the expected utility criterion from consistency axioms on hypothetical choice behavior,

famously Von Neumann and Morgenstern (1944) for risk and Savage (1954, 1972) for uncertainty. However,

the N-M and Savage theorems, as well as subsequent work in axiomatic decision theory, do not prescribe

how an agent should behave when facing an actual choice problem. Rather, these theorems consider an agent

who has formed a complete binary preference ordering over a specified class Á of actions and, thus, who

knows how he would behave if he were to face any choice set D d Á. The theorems show that if the

preference ordering has certain properties, then the agent may be represented as maximizing expected utility.

Thus, the theorems of axiomatic decision theory are interpretative rather than prescriptive.
                                                       2

        Why then are the N-M and Savage theorems regularly considered to be prescriptive? Decision

theorists often assert that an agent should form a complete binary preference ordering on the class Á of

actions and that preferences should have the properties assumed in the theorems. If one accepts these

assertions, the theorems imply that the agent should behave in a manner representable as maximization of

expected utility. Thus, the theorems are prescriptive if one considers their consistency axioms to be

compelling.

        Why should one consider the N-M or Savage axioms to be compelling? No theorem answers this

question. Instead, decision theorists call for introspection. Savage (1954, 1972, p. 7) put it this way:

        I am about to build up a highly idealized theory of the behavior of a “rational” person with respect

        to decisions. In doing so I will, of course, have to ask you to agree with me that such and such

        maxims of behavior are “rational.” In so far as “rational” means logical, there is no live question;

        and, if I ask your leave there at all, it is only as a matter of form. But our person is going to have to

        make up his mind in situations in which criteria beyond the ordinary ones of logic will be necessary.

        So, when certain maxims are presented for your consideration, you must ask yourself whether you

        try to behave in accordance with them, or, to put it differently, how you would react if you noticed

        yourself violating them.

Similarly, in lecture notes for a Ph.D. course in decision theory, Kreps (1988, p. 5) counseled an agent

contemplating application of the N-M theorem that he must first “Decide that you want to obey the axioms

because they seem reasonable guides to behavior.”

        I write this paper to report the results of my own introspection on rational behavior when facing

decision problems under risk and uncertainty, as well as intermediate problems with a partially known

probability distribution on the states of nature. No theorem can prove that my introspection is superior or

inferior to that of any axiomatic decision theorist. Why then might someone other than myself find what I

have to say to be of interest? I develop two arguments, speaking first to decision making agents and then to
                                                      3

decision theorists.

        In Section 2, I speak to an agent who faces the choice problem described in the first paragraph of this

paper: the agent wants to maximize w, but he does not know the actual state of nature. I argue that the

standard axiomatic decision theory rationale for expected utility maximization is largely irrelevant to this

agent. Standard theory embeds the agent in a world with a class Á of potential actions and asks him to

determine how he would behave if he were to face any choice set D d Á. The theory begins with the basic

axiom that the agent forms a complete binary ordering on Á and then places further consistency axioms on

behavior across different choice sets. However, our agent is not concerned with a class of potential actions

or with the consistency of his behavior across hypothetical choice sets. He just wants to make a reasonable

choice from the choice set that he actually faces. Hence, I reason that prescriptions for decision making

should respect actuality. That is, they should promote welfare maximization in the choice problem the agent

actually faces.

        Restricting attention to the actual choice problem, I first consider risk and uncertainty and then

extend the discussion to intermediate cases. Under uncertainty, I reason that only one prescription is so

compelling as to warrant universal acceptance. That is, the agent should not choose an action that is weakly

dominated. Under risk, I propose that a reasonable decision rule should respect both weak and stochastic

dominance. Intermediate are choice problems in which the agent knows that the actual state of nature will

be drawn from some distribution P, but only knows that P 0 Ø, where Ø is a given set of probability

distributions on (S, Ù). In such settings, I propose that a reasonable decision rule should respect weak

dominance and should respect stochastic dominance when the latter property is determinate.

        Respect for weak and stochastic dominance are uncontroversial prescriptions for decision making.

Both prescriptions respect actuality. However, my position that no other prescription warrants universal

acceptance contrasts with the widespread view that an agent should maximize expected utility. The expected

utility criterion respects stochastic dominance and it is a minor extension to require respect for weak
                                                       4

dominance. However, I do not see a compelling reason to give this criterion special status. I consider any

choice that respects weak and stochastic dominance to be rational. Thus, I offer only partial prescriptions

for decisions with partial knowledge.

         Section 3 speaks to axiomatic decision theorists who may not accept or appreciate the sharp

distinction I draw between hypothetical and actual choice problems. Axiomatic theory is sometimes

described as a form of revealed preference analysis, which studies actual choice data rather than statements

about preference. However, the enormously rich choice data contemplated in the N-M or Savage axioms are

essentially never available in practice. Hence, decision theorists perform thought experiments. Referring

to two actions labeled f and g, Savage (1954, 1972) wrote (p. 17): “I think it of great importance that

preference, and indifference, between f and g be determined, at least in principle, by decisions between acts

and not by response to introspective questions.”

         From my perspective, the critical phrase in this sentence is “at least in principle.” The collection of

choices contemplated in the Savage and other axiom systems are hypothetical. They are not observed in

practice. This has been pointed out repeatedly over the years, at least as early as Sen (1973). Nevertheless,

axiomatic decision theorists persist in referring to their subject as revealed preference analysis.

         Section 3 attempts to interpret decision theoretic consistency axioms in terms of actual choice

problems, focusing on the axiom that binary choices should be transitive. I observe that the three binary

choice problems of a standard transitivity axiom have at least three interpretations—these problems could

be mutually exclusive, or the agent could face them simultaneously or sequentially. Considering the first two

interpretations, I find that binary choices should be transitive when actions are ordered by dominance but

need not be otherwise. I do not formally study sequential choice, but I do discuss the unusual version of

sequential choice set forth in the famous “money pump” story, which has often been used to argue for

transitivity.

         Section 4 makes concluding remarks.
                                                        5

2. Choice with an Indeterminate Objective Function



2.1. Basic Considerations: Respect for Actuality



        The agent under consideration aspires to maximize the objective function w(@, r), where r denotes

the actual state of nature. He knows that r lies in a set S of feasible states of nature. If there exists no a 0 C

that uniformly maximizes w(@, s) for all s 0 S, his objective function is indeterminate.

        Before going further, I should call attention to the fact that research in decision analysis exhibits two

starkly different perspectives on objective functions.         In axiomatic theory, objective functions are

mathematical constructs derived from an agent’s preference ordering on the class A of potential actions. In

applied decision analysis, objective functions are psychological constructs that agents use to make choices.

I necessarily take the psychological realist position here. If objective functions are constructs inferred from

preferences, then prescriptions for decision making are unnecessary as the agent has already determined how

he would behave.

        The psychological realist perspective is evident in the standard economic theory of the firm. The

theory of the firm does not derive a firm’s objective function from a preference ordering on potential actions.

It assumes that the firm wants to maximize profit.

        Throughout this paper I will repeatedly cite a problem of firm decision making that emphasizes the

practical nature of my concerns. I will consider a farmer who must choose what crop to plant on a plot of

land; the feasible actions may, for example, be to plant corn, soy, or let the land lie fallow. The farmer

aspires to maximize profit parOar ! Kar, where Kar is the cost of planting and harvesting crop a in state of

nature r, Oar is the resulting output, and par is the price obtained per unit of output. Then w(c, r) = pcrOcr !

Kcr is the actual value of the objective function when c is chosen. Suppose, as is realistic, that the farmer

must choose a crop with incomplete knowledge of costs, outputs, and prices. Then his objective function
                                                        6

is indeterminate.

        Say that the farmer explains his situation and asks for advice on decision making. My thinking on

how to respond begins with an idea that a practical decision maker may think so self-evident as not to require

mention, but which I will give a formal name:



Respect for Actuality (RA): Any prescription for decision making should promote welfare maximization in

the choice problem the decision maker actually faces.



In the context of this paper, respect for actuality implies that any prescription for decision making should

refer only to the potential values of the agent’s objective function, these being [w(a, s), a 0 C, s 0 S], and to

available probabilistic information concerning S. It should not refer to other choice sets or other sets of

states of nature. After all, our agent wants to maximize w in the choice setting he actually faces.1

        Consider, for example, the farmer planting a crop. The farmer wants to maximize actual profits,

whose potential values are (pasOas ! Kas, a 0 C, s 0 S). A prescription for planting respects actuality if it

refers only to these potential profits, not to profits that the farmer might realize if he were to face a different

menu of crops or if he were to have different knowledge of costs, outputs, and prices.

        With the exception of a brief discussion of sequential choice in Section 3, this paper restricts

attention to one-shot choice problems. Readers concerned with sequential choice should not interpret respect

for actuality as demanding that agents be myopic. If an agent faces a sequence of choice problems and his

welfare depends on the entire sequence, consideration of potential future choices is germane to the choice

that the agent makes today and, hence, does respect actuality.



        1
         Respect for actuality resembles, but is formally distinct from, the conditionality principle espoused
by Bayesian decision theorists. They argue that statistical inference should be conditioned on observed data
alone and should not rest on thought experiments that contemplate how an inferential procedure would
perform in hypothetical repeated sampling. See, for example, Berger (1985), Chapter 1.
                                                       7

Respect for Actuality and Consistency Axioms

        I think it essential to explicitly name Respect for Actuality because this idea is deeply at odds with

standard axiomatic decision theory, which poses consistency axioms on behavior across hypothetical choice

sets. Decision theorists consider adherence to consistency axioms to be a virtue per se. It is revealing to

recall how Savage (1954, 1972) viewed the matter. After discussing the positive role of logic in guiding

actual human behavior, he wrote (p. 20):

        The principal value of logic, however, is in connection with its normative interpretation, that is, as

        a set of criteria by which to detect, with sufficient trouble, any inconsistencies there may be among

        our beliefs, and to derive from the beliefs we already hold such new ones as consistency demands.

        It does not seem appropriate here to attempt an analysis of why and in what contexts we wish to be

        consistent; it is sufficient to allude to the fact that we often do wish to be so.

Then, addressing his basic postulate P1, which assumes that the agent places a complete binary preference

ordering on all potential actions, he wrote

        Pursuing the analogy with logic, the main use I would make of P1 and its successors is normative,

        to police my own decisions for consistency and, where possible, to make complicated decisions

        depend on simpler ones. Here it is more pertinent than it was in connection with logic that

        something be said or why and when consistency is a desideratum, though I cannot say much.

He went on to describe a hypothetical conversation with a critic of his theory but, in truth, his brief attempt

to motivate his strong concern with consistency does not say much. Considering transitivity, Savage says

this to his hypothetical critic (p. 21):

        “when it is explicitly brought to my attention that I have shown a preference for f as compared with

        g, for g as compared with h, and for h as compared with f, I feel uncomfortable in much the same

        way that I do when it is brought to my attention that some of my beliefs are logically contradictory.

        Whenever I examine such a triple of preferences on my own part, I find that it is not at all difficult
                                                       8

        to reverse one of them. In fact, I find that on contemplating the three alleged preferences side by

        side that at least one among them is not a preference at all, at any rate not any more.”

This passage appears to describe a psychological process in which Savage uses transitivity as a cognitive tool

to learn his own preferences. Sugden (1990) alludes to such a process when he writes (p. 762): “One of the

main ways in which we come to know our own preferences is by noting how we in fact choose, or by

constructing hypothetical choice problems for ourselves and monitoring our responses.”

        Savage also seems to have viewed his consistency axioms as a cognitive tool to learn one’s beliefs.

A decision maker adhering to the Savage axioms is representable as placing a subjective probability

distribution on the states of nature. Binmore (2008, Section 7.5) interprets Savage as having in mind a

“massaging process,” in which a decision maker modifies his hypothetical decisions until he feels

comfortable that the implied subjective distribution adequately expresses his beliefs. The idea appears to

be that a person holds coherent probabilistic beliefs internally but is psychologically unable to express them

directly. Contemplating hypothetical choice problems helps the person discover his internal beliefs.

        It is difficult to reconcile this psychological argument with the formal structure of axiomatic decision

theory. The theory contemplates a being who arrives with a complete preference ordering, not a cognitively

challenged creature who uses thought experiments with hypothetical choice problems to learn about itself.

Thus, efforts to motivate adherence to consistency axioms as tools for cognition lie entirely outside of

axiomatic theory.

        I take no position on the usefulness for cognition of contemplating hypothetical choice problems.

In particular, I am agnostic on the usefulness of decision-theoretic consistency axioms as a cognitive tool.

To shed light on this requires serious empirical research on cognition; casual introspection does not suffice.

        In any case, this paper concerns an agent who knows that he wants to maximize the objective

function w(@, r) on C, Our agent does not know the state of nature r that will be realized within the feasible

set S. His problem is partial knowledge of the external world, not incomplete understanding of himself.
                                                           9



Respect for Strict Actuality

        I have written that a prescription for decision making that respects actuality should refer only to the

potential values of the agent’s objective function, namely [w(a, s), a 0 C, s 0 S]. Observe that this is an

unordered set of welfare values. Thus, I have not required respect for the actual bundling of welfare values

into action-specific vectors [w(a, s), s 0 S], a 0 C. To recognize this distinction, I will henceforth say that

a prescription respects strict actuality if it refers only to the welfare vectors [w(a, s), s 0 S], a 0 C. The

prescriptions to be offered in Section 2.2 respect strict actuality.

        To illustrate the difference between respect for actuality and strict actuality, consider the minimax-

regret criterion. An agent using this decision criterion chooses an action that solves the problem



                          min max {[max w(a, s)] ! w(c, s)}.
                          c0C   s0S    a0C




Here max a 0 C w(a, s) is the maximum welfare attainable in state s and max a 0 C w(a, s) ! w(c, s) is the regret

of action c in this state. Construction of regret requires unbundling the action-specific welfare vectors to

form the state-specific ideal points max     a 0 C   w(a, s), s 0 S. Thus, the minimax-regret criterion respects

actuality, but it does not respect strict actuality.2

        I do not view respect for strict actuality as a sine qua non for a reasonable decision criterion. Hence,

I will not use this concept to argue against the minimax-regret criterion. To the contrary, in Section 2.3 I will

cite minimax regret as one of various decision criteria that an agent might reasonably use to choose among

the actions that remain after applying the prescriptions of Section 2.2.3


        2
            I am grateful to Larry Blume for raising this issue with me.
        3
          Chernoff (1954) argued against minimax regret because the criterion violates the consistency axiom
called independence of irrelevant alternatives (IIA). The IIA axiom holds that if an agent is not willing to
choose a given action from a hypothetical choice set, then he should not be willing to choose it from any
                                                      10

2.2. Respect for Weak and Stochastic Dominance



        The remainder of this paper explores the nature of a decision theory grounded in respect for actuality.

I first ask what prescriptions for decision making respect actuality and are so compelling as to warrant

universal acceptance as tenets of rational behavior. I consider choice under uncertainty and risk to begin,

and then broaden the discussion to settings with partial knowledge of a probability distribution on the set of

states of nature.



Choice under Uncertainty and Risk

        In problems of choice under uncertainty, the only prescription that I think warrants universal

acceptance is respect for weak dominance. By definition, action c 0 C is weakly dominated if there exists

a d 0 C such that w(d, s) $ w(c, s) for all s 0 S and w(d, s) > w(c, s) for some s 0 S. The prescription is



Respect for Weak Dominance (RWD): The agent should not choose a weakly dominated action.



Respect for weak dominance respects strict actuality. The prescription is uniquely compelling because weak

dominance defines the circumstances in which an agent wanting to maximize w knows that choice of one

action improves on choice of another. If c is undominated, no action surely improves on c. I view choice




larger hypothetical choice set; thus, for any c 0 D d E, an agent who would not choose c from D should not
choose c from E. Chernoff wrote (p. 426):
        A third objection which the author considers very serious is the following. In some examples, the
        min max regret criterion may select a strategy d3 among the available strategies d1 , d2 , d3 , and d4 .
        On the other hand, if for some reason d4 is made unavailable, the min max regret criterion will select
        d2 among d1 , d2 , and d3 . The author feels that for a reasonable criterion the presence of an
        undesirable strategy d4 should not have an influence on the choice among the remaining strategies.
This passage is the totality of Chernoff’s argument. He introspected and concluded that any reasonable
decision criterion should adhere to IIA, without explaining why he felt this way. He did not argue that
minimax-regret decisions have adverse welfare consequences.
                                                      11

of any such action as rational.

        In problems of choice under risk, the first question is whether to exploit the known probability

distribution on the states of nature. An agent might reason that he wants to achieve high welfare ex post and,

hence, should base decisions only on definite knowledge of ex post welfare. If so, he would ignore all

probabilistic information. This reasoning is coherent and I would resist calling it irrational. Indeed, a person

making a maximin decision behaves in this manner, and I would not call such a person irrational.

        Nevertheless, I will presume that our agent uses available probabilistic information, reasoning that

he should seek to maximize the ex ante probability of achieving high welfare ex post. If so, the agent should

choose an action that respects stochastic dominance. By definition, action c 0 C is stochastically dominated

if there exists a d 0 C such that P[w(d, s) # x] # P[w(c, s) # x] for all x 0 R1 and P[w(d, s) # x] < P[w(c, s)

# x] for some x 0 R1. The prescription is



Respect for Stochastic Dominance (RSD): The agent should not choose an action that is stochastically

dominated.



        Respect for stochastic dominance respects strict actuality. Presuming probabilistic information is

to be used at all, the prescription is uncontroversial. Stochastic dominance defines the circumstances in

which choice of one action probabilistically improves on choice of another. If c is not stochastically

dominated, no other action uniformly improves on c probabilistically. I view choice of any such action as

rational.

        When welfare takes only two values, RSD implies a complete binary ordering of actions. Without

loss of generality, let the two feasible values of w be zero and one. Then action c is stochastically dominated

by d if and only if P[w(d, s) = 1] > P[w(c, s) = 1]. Hence, the agent should choose an action that maximizes

P[w(@, s) = 1] and should be indifferent among actions that attain the maximum.
                                                      12

        When welfare takes multiple values, RSD generally implies a partial rather than complete ordering

of actions. Diverse decision criteria may be used to choose among the actions that are not dominated.

Proponents of expected utility maximization argue that only this criterion should be used. The expected

utility criterion respects strict actuality, but the decision theoretic arguments made for its supremacy concern

consistency of behavior across hypothetical choice problems. These arguments have no standing here. From

the perspective of this paper, expected utility maximization is an acceptable decision criterion, but it has no

special status. For example, an agent might just as well maximize quantile utility, a criterion studied in

Manski (1988).

        It is well known (e. g., Hanoch and Levy, 1969) that distribution F stochastically dominates

distribution G if and only if Iu(x)dF(x) $ Iu(x)dG(x) for every increasing function u(@) and Iu(x)dF(x) >

Iu(x)dG(x) for some increasing u(@). This result might be thought to imply a conceptual connection between

stochastic dominance and expected utility maximization. However, the result is only one of various

representation theorems for stochastic dominance. Let Qá (F) and Qá (G) denote the á-quantiles of F and G.

Another representation theorem (e. g. Levy and Kroll, 1978) is that F stochastically dominates G if and only

if Qá (F) $ Qá (G) for every á 0 (0, 1) and Qá (F) > Qá(G) for some á 0 (0, 1). Thus, stochastic dominance is

no more closely tied to expected utility maximization than it is to quantile utility maximization.

        It is worth noting that the RWD and RSD prescriptions are invariant with respect to ordinal

transformations of the objective function w(@). From the perspective of this paper, invariance to ordinal

transformations is not a property of inherent value—our agent wants to maximize w(@), not some

transformation of w(@). Nevertheless, the property deserves mention given the important role that ordinality

has played in decision theory.
                                                      13

Choice with Partial Probabilistic Knowledge

        Discussions of choice under risk have traditionally supposed that distribution P is completely known

to the agent. Decision theoretic expositions refer to lotteries, coin tosses, balls drawn at random from urns

of known composition, and other explicit randomizing devices. Economic applications refer to cross-

sectional frequency distributions, such as the distribution of demand among heterogeneous consumers, or

to stochastic processes, such as the distribution of unanticipated shocks in a macroeconomic model. In such

applications, an agent who knows P is said to have rational expectations.

        It is straightforward to extend the RSD prescription for choice under risk to settings in which P is

an objective probability distribution whose identity is partially known to the agent. Suppose the agent knows

that P 0 Ø, where Ø is a given set of distributions on (S, Ù). Then RSD extends as follows.



Respect for Stochastic Dominance (RSD): The agent should not choose an action that is stochastically

dominated under all feasible distributions on the states of nature.



        The extended RSD prescription generically yields only a partial ordering of actions, even when

welfare takes just two values. If c is stochastically dominated by d for all P 0 Ø, the agent knows that d

probabilistically improves on c. If c is stochastically dominated for some feasible P but not for others, he

cannot conclude that another action probabilistically improves on c. I view choice of any such action as

rational.

        A classic decision theoretic exposition of a choice problem with partial knowledge of P was given

by Ellsberg (1961), who supposed that balls may be drawn at random from one urn of known composition

or another urn of unknown composition. In the simplest of Ellsberg’s thought experiments, balls have two

colors, say red (R) and black (B), and there are 100 balls in each urn. The set of feasible states of nature is

S = {R, B} × {R, B}, where the first and second bracketed expressions denote the possible colors of balls
                                                       14

drawn from the first and second urn, respectively. The objective probability distribution on S is P = P1 × P2 ,

where P1 and P2 are the distributions of colors in each urn. The agent is told P1 , where 0 < P1 (R) < 1, but he

is not told P2 . Hence, Ø = P1 × Ø2 , where Ø2 are the 101 feasible distributions placing probabilities P2(R)

0 {0, 1/100, 2/100, . . . , 99/100, 1} on drawing a red ball from the second urn. The agent chooses an urn

from which to draw a ball. He receives a positive payoff if one color, say red, is drawn and zero payoff

otherwise. In this setting, neither action stochastically dominates the other for all P 0 Ø; it may be that P1 (R)

> P2 (R) or P1 (R) < P2 (R). Hence, the RSD prescription places no restriction on behavior. I view choice of

either urn as rational.

        Although the RSD prescription has no bite in the Ellsberg setting, it does in other problems with

partial probabilistic knowledge. To illustrate, I return to the farmer’s planting decision.



Illustration: Consider the farmer with potential profits (pasOas ! Kas, a 0 C, s 0 S). At the time of the planting

decision, the farmer may know costs but not outputs and prices. Outputs, which are determined primarily

by weather conditions, may have a known objective probability distribution. However, the farmer may feel

unable to place a probability distribution on prices, which are determined by poorly understood world market

conditions. Hence, the farmer may place a partial probability distribution on profits.

        As earlier, let the three feasible actions be to plant corn (action c), plant soy (action d), and let the

land lie fallow (action e). Let action e be known to have zero cost, output, and price. Let actions c and d

have known costs Kcr = Kdr = 1, and known uniform output distributions POc = U[0, 1] and POd = U[0.5, 1].

Regarding prices, the farmer only knows that they lie in the bounded range (pc, pd ) 0 [2, 4] × [2, 3].

        In this setting, the farmer has enough information to conclude that planting soy stochastically

dominates letting the land lie fallow. The profit distribution for planting soy is one of the uniform

distributions U[0.5pd ! 1, pd ! 1], pd 0 [2, 3]. All of these distributions stochastically dominate the profit

distribution for letting the land lie fallow, which places probability one at zero profit. Hence, by RSD, the
                                                     15

farmer should not let the land lie fallow.

        Planting corn and soy are undominated actions. The profit distribution for planting corn is one of

the uniform distributions U[!1, pc ! 1], pc 0 [2, 4]. In the worst case, U[!1, 1], planting corn is surely

stochastically dominated by planting soy. However, in the best case, U[!1, 3], planting corn is not

stochastically dominated by any of the feasible profit distributions for soy.   ~



Choice with Subjective Probabilistic Knowledge

        It remains to discuss choice with subjective probabilistic knowledge. As with objective functions,

research in decision analysis exhibits two perspectives on subjective probability distributions. In the

axiomatic theory of Savage (1954), subjective distributions are mathematical constructs derived from an

agent’s preference ordering on the class of potential actions. In applied decision analysis, subjective

distributions are psychological constructs that agents use to make choices. Arguing for the psychological

realism of subjective probabilities, Tversky and Kahneman (1974, p. 1130) made plain the difference

between the two perspectives, writing:

        It should perhaps be noted that, while subjective probabilities can sometimes be inferred from

        preferences among bets, they are normally not formed in this fashion. A person bets on team A rather

        than on team B because he believes that team A is more likely to win; he does not infer this belief

        from his betting preferences. Thus, in reality, subjective probabilities determine preferences among

        bets and are not derived from them, as in the axiomatic theory of rational decision.

As with objective functions, I take the psychological realist position.4

        Suppose then that our agent holds the subjective belief that the actual state of nature is drawn at

random from a distribution Pu lying in a set Øu of such distributions. In traditional Bayesian thinking Øu is


        4
          I should acknowledge that I take the psychological realism of subjective probability distributions
very seriously, having devoted considerable effort to measuring expectations probabilistically in survey
research (Manski, 2004).
                                                       16

a singleton, but a diverse literature considers settings in which Øu is a set of distributions; see Walley (1991).

Suppose that the agent uses his probabilistic beliefs in decision making, reasoning that he should seek to

maximize the subjective probability of achieving high welfare. Then, just as in the case of risk, the agent

should choose an action that respects stochastic dominance. I consider any such choice to be rational.



2.3. Choosing an Undominated Action



        Suppose that the agent has eliminated from consideration all actions that are weakly or stochastically

dominated. How might he choose among the remaining undominated actions? I write “might” rather than

“should” because RWD and RSD exhaust the prescriptions that I believe warrant universal acceptance.

        Proponents of Bayesian decision theory counsel the agent to maximize expected utility. Rejecting

this as a universal prescription, I could say that a decision analyst should simply list the actions that respect

weak and stochastic dominance, and leave it at that. However, I think that decision analysis can be most

useful to decision makers if, beyond listing the undominated actions, it seeks to describe in neutral terms the

properties of a menu of alternative criteria that have well-understood properties.

        I envision using a decision criterion only to choose among the subset of actions that remain after

dominated actions have been eliminated. Decision theorists often study the use of a criterion to choose

among the complete choice set C. It is then common to find that a criterion may yield multiple potential

choices, some of which are dominated. For example, a weakly dominated action maximizes expected utility

if the set of states on which strict dominance occurs has probability zero. A weakly dominated action is a

maximin choice if the set of states on which strict dominance occurs do not minimize welfare. Such

pathological properties are prevented by using a criterion only to choose among undominated actions.

        An example of what I have in mind is my own study (Manski, 1988) of the quantile utility model,

where the agent maximizes a specified quantile of the distribution of utility, and the utility mass model,
                                                         17

where he maximizes the probability that utility exceeds a specified threshold. Comparison of these decision

criteria with expected utility maximization is revealing. Whereas the latter criterion is invariant only to

cardinal transformations of the objective function, the former are invariant to ordinal transformations.

Whereas the latter conveys risk preferences through the shape of the utility function, the former do so

through the specified quantile or utility threshold, with higher values conveying more risk preference.

Although I find the quantile-utility and utility-mass criteria to be intellectually interesting and worthy of

consideration in practice, I was careful not to claim them to be superior to other criteria. Instead, I put it this

way (p. 82): “I do not think of the ordinal utility models studied here as dominating the expected utility

model. Expected utility, quantile utility, and utility mass should, I feel, be thought of as three tightly

specified models. Each illuminates a possible mode of rational behavior under uncertainty.”

           I similarly find it intellectually interesting and potentially useful for practice to study criteria that

use no probabilistic information, such as the maximin and minimax-regret criteria, and hybrids that use

partial probabilistic information, such as the maximin expected utility (aka Ã-maximin) and minimax

expected regret (aka Ã-minimax regret) criteria. The goal should be to provide agents facing actual choice

problems with a menu of criteria for their consideration. For example, Manski (2006) studied a reasonably

realistic social planning problem with partial knowledge. I first showed how to identify weakly dominated

policies and then characterized Bayesian, maximin, and minimax-regret policies.

           Offering an agent a menu of decision criteria asks him to face a second-order choice problem.

Whereas the first-order problem is to choose an action from the set C, now the agent needs to choose a

criterion to apply to this first-order problem. It is tempting to offer guidance to the agent on how he might

approach the second-order problem. I will not do so here. The first-order choice problem specified at the

beginning of this paper states what the agent wants to accomplish and what he knows about the actual state

of nature. However, it does not provide a foundation to advise an agent how to choose among undominated

actions.
                                                      18

        Consider, for example, the farmer who knows that the profit distribution for planting corn is one of

the distributions U[!1, pc ! 1], pc 0 [2, 4], and that for planting soy is one of the distributions U[0.5pd ! 1,

pd ! 1], pd 0 [2, 3]. As I see it, the farmer could rationally plant either crop. A decision analyst might

usefully describe to the farmer the potential profit implications of using different decision criteria to make

the choice. However, I do not think that the decision analyst should prescribe a particular criterion.




3. Actualist Interpretations of Transitivity



        I have sharply differentiated an agent’s actual choice problem from the hypothetical problems of

axiomatic decision theory. To make sense of axiomatic theory from the perspective of this paper, one needs

to interpret decision theoretic thought experiments in terms of actual choice problems. This is not a

straightforward matter. Attempting to deconstruct the abstract mathematical statements of standard

consistency axioms, I have found that they do not specify essential aspects of the choice problems under

consideration. Hence, the axioms have multiple interpretations.

        To explain, I consider the venerable axiom that binary choices should be transitive. The analysis in

this section shows that transitivity is not a universally compelling prescription when framed in terms of an

actual choice problem of the type considered in this paper. A rational decision maker should exhibit

transitivity when actions are ordered by dominance. However, transitivity is optional otherwise.

        Here is a standard choice-function statement of transitivity: If an agent would uniquely choose c from

set (c, d) and would uniquely choose d from (d, e), then he should uniquely choose c from (c, e). Although

the transitivity axiom seems straightforward, the thought experiment contemplating three binary choice sets

(c, d), (d, e), and (c, e) has multiple interpretations in terms of an actual choice problem. These include
                                                      19

Simultaneous Binary Choice Problems: The agent simultaneously faces all three choice sets and chooses an

action from each one.



Mutually Exclusive Binary Choice Problems: The agent will face one of the three choice sets. He must

commit to choose an action from each set, should it be the one he will face.



Sequential Binary Choice Problems: The agent sequentially faces the three choice sets, the sequence being

(c, d), (d, e), (c, e). This interpretation encompasses multiple informational cases. When the agent faces set

(c, d), he may or may not know that he will later face (d, e) and (c, e). At the time of each later choice, he

may or may not have new knowledge of the state of nature.



The first two interpretations are formally representable in terms of the choice problem studied in this paper.

Moreover, one informational case of sequential choice is equivalent to simultaneous choice. In what follows,

I flesh out each interpretation in turn. For simplicity, I assume below that the agent has no probabilistic

information concerning the set of states of nature.



3.1. Simultaneous Binary Choice Problems



        Simultaneous choice from multiple choice sets is equivalent to a single choice problem where actions

have multiple components. To formalize the problem, let the choice set be C = (c, d) × (d, e) × (c, e). Thus,

C contains eight feasible actions, each being a three-element vector of sub-actions.

        With C defined this way, the analysis of Section 2 holds as given. The set of states of nature is S,

the objective function is w(@, @): C × S 6 R1 , and the agent wants to maximize w. The agent should choose

an action that respects weak dominance. Any such action is rational.
                                                            20

         Adherence to transitivity means that the agent does not choose action (c, d, e) or (d, e, c). If the

welfare function is non-separable in the sub-actions, there is no reason to expect transitivity. I will therefore

suppose that w has the additively separable form5



                                    w[(i, j, k), s] = g(i, s) + g(j, s) + g(k, s),



where (i, j, k) 0 C and g(@, @): (c, d, e) × S 6 R1 .

         For example, consider the farmer’s planting decision. Suppose that the farmer has three identical

fields. In one he can plant either corn (c) or soy (d). In the second he can plant soy or let the land lie fallow

(e). In the third he can plant corn or let the land lie fallow. The farmer wants to maximize total profit. Then

g is the profit function per field, and g(i, s) + g(j, s) + g(k, s) is the total profit associated with action (i, j, k)

in state of nature s.

         Suppose first that g(c, s) $ g(d, s) $ g(e, s) for all s 0 S, g(c, s) > g(d, s) for some s 0 S, and g(d, s)

> g(e, s) for some s 0 S. Then, for all (i, j, k)       (c, d, c), we have w[(c, d, c), s] $ w[(i, j, k), s] for all s 0 S

and w[(c, d, c), s] > w[(i, j, k), s] for some s 0 S. Hence, action (c, d, c) weakly dominates all other actions.

The agent should therefore choose (c, d, c), which is transitive.

         The agent should similarly choose action (d, e, e) if g(e, s) $ g(d, s) $ g(c, s) for all s 0 S, g(e, s) >

g(d, s) for some s 0 S, and g(d, s) > g(c, s) for some s 0 S. This choice also is transitive.

         The above specifications for g are special—the agent knows enough to determine a welfare-

maximizing action. It appears difficult to obtain a succinct characterization of weak dominance for other

specifications of g. However, it is easy to determine dominance computationally when the set S is finite.

Consideration of a simple case with two feasible states of nature suffices to show that intransitive actions


         5
           Additivity simplifies some computations but is not essential. The discussion below applies if w
has the non-additive form w[(i, j, k), s] = F[g(i, s), g(j, s), g(k, s)], where (i, j, k) 0 C, g(@, @): (c, d, e) × S 6 R1 ,
and F(@, @, @): R3 6 R1 is strictly increasing in each argument.
                                                                     21

may be undominated.



A Farming Illustration

           Consider the farmer’s planting decision with three identical fields, as described above. Let there be

two feasible states of nature, with s = 1 being advantageous for planting corn and s = 2 for planting soy. In

particular, let the field-specific profit function be:




               g(c, 1) = 2                                    g(d, 1) = !1                                     g(e, 1) = 0
              g(c, 2) = !1                                       g(d, 2) = 2                                   g(e, 2) = 0



Then the total profit function is




 w[(c, d, c), 1]   w[(c, d, e), 1]   w[(c, e, c), 1]   w[(c, e, e), 1]   w[(d, d, c), 1]   w[(d, d, e), 1]   w[(d, e, c), 1]   w[(d, e, e), 1]

       3                 1                 4                 2                 0                !2                 1                !1
 w[(c, d, c), 2]   w[(c, d, e), 2]   w[(c, e, c), 2]   w[(c, e, e), 2]   w[(d, d, c), 2]   w[(d, d, e), 2]   w[(d, e, c), 2]   w[(d, e, e), 2]

       0                 1                !2                !1                 3                 4                 1                 2



Inspection of the total profit function shows that action (c, e, e) is dominated by (c, d, c) and that (d, e, e) is

dominated by (d, d, c). The remaining six actions are undominated. Hence, from the perspective of this

paper, the farmer can rationally make any planting decision among these six.

           I have previously cited the maximin and minimax-regret criteria as possible approaches to choice

among undominated actions. In this illustration, use of either criterion implies that the farmer chooses one

of the intransitive actions (c, d, e) or (d, e, c). The maximin result is easy to see—the worst-case profit for

the intransitive actions is 1, while the worst-case profits for all other actions are non-positive. Computation
                                                       22

of regret shows that the maximum regret of the intransitive actions is 3 and that all other actions have larger

maximum regret.6

         Choice of (c, d, e) or (d, e, c) is not pathological in this illustration. These actions are appealing

because they diversify the farmer, planting corn in one field, soy in another, and letting the third field lie

fallow. Indeed, diversification provides a broad rationale for choice of an intransitive action in a

simultaneous choice problem.7



3.2. Mutually Exclusive Binary Choice Problems



         Mutually exclusive choice with commitment, like simultaneous choice, is equivalent to a single

choice problem where actions have three components. Again let the choice set be C = (c, d) × (d, e) × (c, e).

Now choice of action (i, j, k) means that the agent commits to choose i if he should face set (c, d), j if (d, e),

and k if (c, e).

         Mutually exclusive choice problems may not be as easy to envisage as simultaneous choice

problems, which are ubiquitous. However, they arise routinely when agents encode contingent decision rules

as algorithms to be executed by automated systems such as industrial robots or financial trading procedures.

Such algorithms commit the automated system to behave in specified ways should it face alternative choice

problems.



         6
          In general, maximin and minimax-regret are distinct criteria yielding different choices. However,
these criteria are algebraically equivalent when the same maximum welfare is achievable in each state of
nature. This is so in the present illustration, where maximum profit in both states of nature equals 4.
         7
         Diversification can also rationalize seemingly incoherent decisions, where an agent makes different
choices in identical settings. In Manski (2007, Chapter 11; 2008) and elsewhere, I have studied a class of
simultaneous choice problems in which a planner with partial knowledge of treatment response chooses a
treatment for each observationally identical member of a large population. When there are two treatments
and the optimal treatment is not determinate, the minimax-regret treatment rule always diversifies, randomly
assigning one treatment to some persons and the other treatment to the rest of the population.
                                                           23

         With C defined as above, we can construct a choice problem of the type studied in Section 2. To do

so, we need to augment the original definition of a state of nature by adding a trinary indicator variable R such

that R = 1 if the agent will actually face set (c, d), R = 2 if he will face (d, e), and R = 3 if (c, e). Then the set

of feasible states of natures is S* / S × (1, 2, 3), where S is the original set of Section 2. Now let the

objective function w(@, @): C × S* 6 R1 be



                      w[(i, j, k), (s, R)] = 1[R = 1]@g(i, s) + 1[R = 2]@g(j, s) + 1[R = 3]@g(k, s),



where (i, j, k) 0 C and g(@, @): (c, d, e) × S 6 R1 . Thus, welfare is g(i, s) if R = 1, g(j, s) if R = 2, and g(k, s) if

R = 3. Observe that I do not let R be an argument of g(@, @). If it were, welfare would be choice-set specific

and there would be no reason to expect transitivity.

         As with simultaneous choice, the welfare maximizing choice is determinate if g(c, s) $ g(d, s) $

g(e, s) for all s 0 S, g(c, s) > g(d, s) for some s 0 S, and g(d, s) > g(e, s) for some s 0 S. Then the agent

should choose action (c, d, c), which weakly dominates all other actions. The agent should similarly choose

action (d, e, e) if g(e, s) $ g(d, s) $ g(c, s) for all s 0 S, g(e, s) > g(d, s) for some s 0 S, and g(d, s) > g(c, s)

for some s 0 S. These choices are transitive.

         As with simultaneous choice problems, intransitive actions may be undominated when the welfare

maximizing choice is indeterminate. Consider again the planting decision of Section 3.1, modified so that

the farmer will be permitted to plant in only one of the three fields, determined by the realization of R. With

g as specified earlier, the total profit function is
                                                                                             24

 w[(c, d, c), (1, 1)]   w[(c, d, e), (1, 1)]   w[(c, e, c), (1, 1)]   w[(c, e, e), (1, 1)]     w[(d, d, c), (1, 1)]   w[(d, d, e), (1, 1)]   w[(d, e, c), (1, 1)]   w[(d, e, e), (1, 1)]


         2                      2                      2                      2                       !1                     !1                     !1                     !1
 w[(c, d, c), (2, 1)]   w[(c, d, e), (2, 1)]   w[(c, e, c), (2, 1)]   w[(c, e, e), (2, 1)]     w[(d, d, c), (2, 1)]   w[(d, d, e), (2, 1)]   w[(d, e, c), (2, 1)]   w[(d, e, e), (2, 1)]


        !1                     !1                     !1                     !1                        2                      2                      2                      2
 w[(c, d, c), (1, 2)]   w[(c, d, e), (1, 2)]   w[(c, e, c), (1, 2)]   w[(c, e, e), (1, 2)]     w[(d, d, c), (1, 2)]   w[(d, d, e), (1, 2)]   w[(d, e, c), (1, 2)]   w[(d, e, e), (1, 2)]


        !1                     !1                      0                      0                       !1                     !1                      0                      0
 w[(c, d, c), (2, 2)]   w[(c, d, e), (2, 2)]   w[(c, e, c), (2, 2)]   w[(c, e, e), (2, 2)]     w[(d, d, c), (2, 2)]   w[(d, d, e), (2, 2)]   w[(d, e, c), (2, 2)]   w[(d, e, e), (2, 2)]


         2                      2                      0                      0                        2                      2                      0                      0
 w[(c, d, c), (1, 3)]   w[(c, d, e), (1, 3)]   w[(c, e, c), (1, 3)]   w[(c, e, e), (1, 3)]     w[(d, d, c), (1, 3)]   w[(d, d, e), (1, 3)]   w[(d, e, c), (1, 3)]   w[(d, e, e), (1, 3)]


         2                      0                      2                      0                        2                      0                      2                      0
 w[(c, d, c), (2, 3)]   w[(c, d, e), (2, 3)]   w[(c, e, c), (2, 3)]   w[(c, e, e), (2, 3)]     w[(d, d, c), (2, 3)]   w[(d, d, e), (2, 3)]   w[(d, e, c), (2, 3)]   w[(d, e, e), (2, 3)]


        !1                      0                     !1                      0                       !1                      0                     !1                      0



             All actions are undominated. Hence, the farmer can rationally make any planting decision. All

actions are maximin choices, as all have worst-case profit equal to !1. All actions are minimax-regret

choices, as all have maximum regret equal to 3.



3.3. Sequential Choice Problems



             Sequential choice is equivalent to simultaneous choice if the agent knows ex ante that he will face

all three choice problems and if he receives no new information during the choice process. For example, the

farmer with three fields may have a labor or equipment constraint that enables him to plant only one field

at a time. Then he may physically plant the three fields sequentially but view planting as a simultaneous

multi-field decision problem.

             Sequential choice differs from simultaneous choice in other informational settings. When the agent

faces later stages of the choice sequence, he may obtain new knowledge that enables him to update his beliefs

about the feasible states of nature. When he faces the first choice set (c, d), he may not know that he will
                                                        25

later face (d, e) and (c, e). Moreover, the term “not know” has two interpretations. First, the agent may be

aware from the outset that he may potentially face later choice problems, but not know whether he will in

fact do so. Second, he may believe that he will face no future choice problems and then be surprised when

they appear.

        The first interpretation of “not know” can be formalized by augmenting the original definition of a

state of nature, as we did to specify mutually exclusive choice problems. Here one would add an indicator

variable to denote the future choice problems that may possibly arise. The second interpretation requires

modification of the concept of a state of nature to permits the agent to find himself in a situation that he

earlier thought infeasible. I will not speculate on how to go about this, as decision theorists have long

struggled with the question. See, for example, Blume, Brandenburger, and Dekel (1991).

        I will not attempt to formalize the numerous possible interpretations of sequential choice here. I will

only give an example to illustrate the need for care.

        The famous “money pump” argument warning against intransitivity contemplates a sequential choice

problem. Binmore (2008) describes the money pump argument this way, referring to a hypothetical decision

maker Pandora (p. 11):

        Why should we expect Pandora to reveal transitive preferences? The money pump argument says

        that if she doesn’t, other people will be able to make money out of her. Suppose that Pandora’s

        reveals the intransitive preferences apple  orange  fig  apple when making pairwise comparisons.

        A trader now gives her an apple. He then offers to exchange the apple for an orange, provided she

        pays him a penny. Since her preference for the orange is strict, she agrees. The trader now offers

        to exchange the orange for a fig, provided she pays him a penny. When she agrees, the trader offers

        to exchange the fig for an apple, provided she pays him a penny. If Pandora’s preferences are stable,

        this trading cycle can be repeated until Pandora is broke. The inference is that nobody with

        intransitive preferences will be able to survive in a market context.
                                                      26

Although this familiar argument states that the three trades are offered sequentially, it does not state whether

Pandora knows at the time of the first trade that she will later face the second and third ones. Pandora

apparently believes that each trade is a one-shot choice problem and does not update this belief when the

trader appears a second and third time. When the trading cycle is repeated, Pandora acts as if there was no

previous history of trades and there will be no future trades.

        It is clear that Pandora’s behavior is awfully stupid. However, the money pump argument is just a

story about a strangely memoriless and myopic sequential choice process. If a decision maker recognizes

that she faces a sequence of trades, she should view herself as facing a simultaneous choice problem rather

than isolated binary choice problems. Pandora’s poor fate results from her inability to contemplate the future

or learn from the past. It is not remotely a general argument for transitivity.




4. Conclusion



        I have long felt uneasy about the prescriptive assertion that decision makers should maximize

expected utility. I could appreciate the mathematical creativity of the N-M, Savage and related representation

theorems, but I could not understand why many decision theorists view the consistency axioms of these

theorems to be normative. It has long been a mystery to me that the deductive logic of the theorems could

be so tight, yet the introspective arguments offered for the axioms could be so loose.

        I have occasionally voiced my concerns to close friends, but I have until now not expressed them in

writing, other than in brief remarks in Manski (1988). It took this long for me to reach the conclusion that

I have something worth writing on the subject. Now I have, the central idea being respect for actuality.

        When I began work on this paper, I did not anticipate that I would find it difficult to motivate the

prescriptive use of such a basic consistency axiom as transitivity. However, this is the way it has worked
                                                        27

out. Supposing that an agent has no probabilistic information on the state of nature, I have found that

transitivity has a clear normative foundation only when actions are ordered by weak dominance. It would

be valuable to examine other consistency axioms in the same manner.

        I stated at the outset and have repeated that this paper concerns the prescriptive function of decision

analysis. Nevertheless, it is natural to ask in conclusion whether the work has implications for prediction

of behavior. Most economists and some other behavioral scientists maintain the premise in their research

that humans aim to be rational in practice. To such researchers, the manner in which prescriptive analysis

conceptualizes rationality is relevant to prediction.

        An adherent of standard axiomatic theory would predict that real agents maximize expected utility.

In contrast, a person who finds respect for actuality to be compelling would predict that agents respect weak

and stochastic dominance, but would not take a stand on the empirical prevalence of expected utility

maximization. The former person would predict that real agents make transitive binary choices. The latter

one would not take a stand on the empirical prevalence of transitivity in settings where actions are

undominated. In these and other ways, the present work would thus have implications for prediction of

behavior. I cautiously write “would” rather than “does” because this is not the place to evaluate the empirical

validity of the premise that humans respect weak and stochastic dominance.
                                                   28

References


Berger, J. (1985), Statistical Decision Theory and Bayesian Analysis, New York: Springer-Verlag.

Binmore, K. (2008), Rational Decisions, Princeton: Princeton University Press, forthcoming.

Blume, L., A. Brandenburger, and E. Dekel (1991), “Lexicographic Probabilities and Choice under
Uncertainty,” Econometrica, 59, 61-79.

Chernoff, H. (1954), “Rational Selection of Decision Functions,” Econometrica, 22, 422-443.

Ellsberg, D. (1961), “Risk, Ambiguity, and the Savage Axioms.” Quarterly Journal of Economics, 75, 643-
669.

Hanoch, G. and H. Levy (1969), “The Efficiency Analysis of Choices Involving Risk,” Review of Economic
Studies, 36, 335-346.

Kreps, D. (1988), Notes on the Theory of Choice, Boulder: Westview Press.

Levy, H. and Y. Kroll (1978), “Ordering Uncertain Options with Borrowing and Lending,” Journal of
Finance, 33, 553-574.

Manski, C. (1988), “Ordinal Utility Models of Decision Making Under Uncertainty,” Theory and Decision,
25, 79-104.

Manski, C. (2004), “Measuring Expectations,” Econometrica, 72, 1329-1376.

Manski, C. (2006), “Search Profiling with Partial Knowledge of Deterrence.” Economic Journal, 116, F385-
F401.

Manski, C. (2007), Identification for Prediction and Decision, Cambridge, Mass.: Harvard University Press.

Manski, C. (2008), “Adaptive Partial Policy Innovation: Coping with Ambiguity through Diversification,”
Department of Economics, Northwestern University.

Savage, L. (1954), The Foundations of Statistics, New York: Wiley.

Savage, L. (1972), The Foundations of Statistics, New York: Dover.

Sen, A. (1973), “Behaviour and the Concept of Preference,” Economica, 40, 241-259.

Sugden, R. (1990), “Rational Choice: A Survey of Contributions from Economics and Philosophy,” The
Economic Journal, 101, 751-785.

Tversky, A. and D. Kahneman (1974), “Judgement Under Uncertainty: Heuristics and Biases,” Science, 185,
1124-1131.
                                                 29

von Neumann, J. and O. Morgenstern (1944), Theory of Games and Economic Behavior, Princeton: Princeton
University Press.

Walley, P. (1991), Statistical Reasoning with Imprecise Probabilities, Chapman & Hall: London.
