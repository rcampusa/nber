                                 NBER WORKING PAPER SERIES




                            THE OPTIMAL DEGREE OF DISCRETION
                                   IN MONETARY POLICY

                                             Susan Athey
                                            Andrew Atkeson
                                            Patrick J. Kehoe

                                         Working Paper 10109
                                 http://www.nber.org/papers/w10109


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                     November 2003




The authors thank Kathy Rolfe for excellent editorial assistance and the NSF for generous assistance. The
views expressed are those of the authors and not necessarily those of the Federal Reserve Bank of
Minneapolis or the Federal Reserve System. The views expressed herein are those of the authors and not
necessarily those of the National Bureau of Economic Research.

©2003 by Susan Athey, Andrew Atkeson, and Patrick J. Kehoe. All rights reserved. Short sections of text,
not to exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.
The Optimal Degree of Discretion in Monetary Policy
Susan Athey, Andrew Atkeson, and Patrick J. Kehoe
NBER Working Paper No. 10109
November 2003
JEL No. E5, E6, E52, E61, E58

                                           ABSTRACT

How much discretion should the monetary authority have in setting its policy? This question is

analyzed in an economy with an agreed-upon social welfare function that depends on the randomly

fluctuating state of the economy. The monetary authority has private information about that state.

In the model, well-designed rules trade off society's desire to give the monetary authority discretion

to react to its private information against society's need to guard against the time inconsistency

problem arising from the temptation to stimulate the economy with unexpected inflation. Although

this dynamic mechanism design problem seems complex, society can implement the optimal policy

simply by legislating an inflation cap that specifies the highest allowable inflation rate. The more

severe the time inconsistency problem, the more tightly the cap constrains policy and the smaller

is the degree of discretion. As this problem becomes sufficiently severe, the optimal degree of

discretion is none.

Susan Athey                                           Patrick J. Kehoe
Department of Economics                               Research Department
Stanford University                                   Federal Reserve Bank of Minneapolis
Stanford, CA 94305-6072                               90 Hennepin Avenue
and NBER                                              Minneapolis, MN 55480-0291
athey@stanford.edu                                    and NBER
                                                      pkehoe@res.mpls.frb.fed.us
Andrew Atkeson
Bunche Hall 9381
Department of Economics
UCLA
Box 951477
Los Angeles, CA 90095-1477
and NBER
andy@atkeson.net
      How much discretion should the monetary authority have in setting its policy? The
conventional wisdom from policymakers is that optimal outcomes can be achieved only if
some discretion is left in the hands of the monetary authority. Starting with Kydland and
Prescott (1977), most of the academic literature has contradicted that view. In summarizing
this literature, Taylor (1983) and Canzoneri (1985) argue that when the monetary authority
does not have private information about the state of the economy, the debate is settled: there
should be no discretion; that is, the best outcomes can be achieved by rules that specify the
action of the monetary authority as a function of observables. The unsettled question in
this debate is Canzoneri’s: What about when the monetary authority does have private
information? What, then, is the optimal degree of monetary policy discretion?
      To answer this question, we use a model of monetary policy similar to that of Kydland
and Prescott (1977) and Barro and Gordon (1983). The model includes an agreed-upon
social welfare function that depends on the random state of the economy. We begin with
the assumption that the monetary authority observes the state and individual agents do not.
In the context of our model, we say that the monetary authority has discretion if its policy
varies with its private information.
      The assumption of private information creates a tension between discretion and time
inconsistency.1 Tight constraints on discretion mitigate the time inconsistency problem in
which the monetary authority is tempted to claim repeatedly that the current state of the
economy justifies a monetary stimulus to output. However, tight constraints leave little
room for the monetary authority to fine tune its policy to its private information. Loose
constraints allow the monetary authority to do that fine tuning, but they also allow more
room for the monetary authority to stimulate the economy with a surprise inflation. These
constraints may vary with observables, but the relevant question is, how tight should they
be? How much discretion should be allowed?
      Our purpose here is to answer this question by finding the constraints on monetary
policy that, in the presence of private information, optimally resolve the tension between

  1
    For some potential empirical support for the idea that the Federal Reserve possesses some nontrivial
private information, see the work of Romer and Romer (2000).
discretion and time inconsistency. Formally, we cast this problem as a dynamic mechanism
design problem. Canzoneri (1985) conjectures that because of the dynamic nature of the
problem, the resulting optimal social contract with regard to monetary policy is likely to
be quite complex. We find that, in fact, it is quite simple. For a broad class of economies,
the optimal social contract is static and can be implemented by setting an inflation cap, an
upper limit on the permitted inflation rate.
     More formally, our model can be described as follows. Each period, the monetary
authority observes one of a continuum of possible privately observed states of the economy.
These states are i.i.d. over time. In terms of current payoﬀs, the monetary authority prefers
to choose higher inflation when higher values of this state are realized and lower inflation
when lower values are realized. Here a mechanism specifies what monetary policy is chosen
each period as a function of the history of the monetary authority’s reports of its private
information. We say that a mechanism is static if policies depend only on the current report
by the monetary authority and dynamic if policies depend also on the history of past reports.
     Our main technical result is that, as long as a monotone hazard condition is satisfied,
the optimal mechanism is static. We also give examples in which this monotone hazard
condition fails and the optimal mechanism is dynamic.
     We then show that our result on the optimality of a static mechanism implies that the
optimal policy has one of two forms: either it has bounded discretion, or it has no discretion.
Under bounded discretion, there is a cutoﬀ state: for any state less than this, the monetary
authority chooses its static best response, which is an inflation rate that increases with the
state, and for any state greater than this cutoﬀ state, the monetary authority chooses a
constant inflation rate. Under no discretion, the monetary authority chooses some constant
inflation rate regardless of its information.
     We then show that we can implement the optimal policy as a repeated static equilibrium
of a game in which the monetary authority chooses its policy subject to an inflation cap and
in which individual agents’ expectations of future inflation do not vary with the monetary
authority’s policy choice. In general, the inflation cap would vary with observable states,
but to keep the model simple, we abstract from observable states, and the inflation cap is a


                                                3
single number. Depending on the realization of the private information, sometimes the cap
will bind, and sometimes it will not.
     These results imply that the optimal constraints on discretion take the form of an
inflation cap. The monetary authority is allowed to choose any inflation rate below this
cap but is constrained from choosing an inflation rate above it. As we vary the underlying
parameters so that the time inconsistency problem becomes more severe, the optimal inflation
cap drops and is more likely to bind. If the problem is suﬃciently severe, then the cap is set
suﬃciently low that it binds for all realizations of the private information, and the resulting
policy has no discretion.
     One interpretation of our work is that we solve for the optimal inflation targets. As
such, our work is related to the burgeoning literature on inflation targeting. (See the work
of Cukierman and Meltzer (1986), Bernanke and Woodford (1997), and Faust and Svensson
(2001), among many others.) In terms of the practical application of inflation targets,
Bernanke and Mishkin (1997) discuss how inflation targets often take the form of ranges
or limits on acceptable inflation rates that are broadly similar to the optimal inflation cap
which we have derived.
     Here we have assumed that the monetary authority maximizes the welfare of society.
As such, the monetary authority is viewed as the conduit through which society exercises
its will. An alternative approach is to view the monetary authority as an individual or an
organization motivated by concerns other than that of society’s well-being. If, for example,
the monetary authority is motivated in part by its own wages, then, as Walsh (1995) has
shown, it is possible to implement the full-information, full-commitment solution. Hence,
with such a setup, there are no binding incentive problems in monetary policy to begin with.
As Persson and Tabellini (1993) note, there are a host of reasons such contracts are either
diﬃcult or impossible to implement, and the main issue for research following this approach
is why such contracts are, at best, rarely used.
     Our work is related to several literatures. It is related to some work on private informa-
tion in monetary policy games. (See, for example, that of Backus and Driﬃll (1985); Ireland
(2000); Da Costa and Werning (2001); Sleet (2001); Angeletos, Hellwig, and Pavan (2003);


                                              4
Sleet and Yeltekin (2003); and Stokey (2003).) The most closely related of these is the work
of Sleet (2001), who considers a dynamic general equilibrium model in which the monetary
authority sees a noisy signal about future productivity before it sets the money growth rate.
Sleet finds that, depending on parameters, the optimal mechanism may be static, as we find
here, or it may be dynamic.
      Our work is also related to a large literature on dynamic contracting. Our result on
the optimality of a static mechanism is quite diﬀerent from what is typically found in this
literature, namely, that static mechanisms are not optimal. (See, for example, Green (1987),
Atkeson and Lucas (1992), and Kocherlakota (1996).) We discuss the relation between our
work and both of these literatures in more detail after we present our results.
      At a technical level, we draw heavily on the literature on recursive approaches to
dynamic games. We use the technique of Abreu, Pearce, and Stacchetti (1990), which has
been applied to monetary policy games by Chang (1998) and is related to the policy games
studied by Phelan and Stacchetti (2001), Albanesi and Sleet (2002), and Albanesi, Chari,
and Christiano (2003). The mechanism design problem that we study, at an abstract level,
is related to some work on supporting collusive outcomes in cartels by Athey, Bagwell, and
Sanchirico (forthcoming), some work on risk-sharing with nonpecuniary penalties for default
by Rampini (2003), and some work on the tradeoﬀ between flexibility and commitment in
savings plans for consumers with hyperbolic discounting by Amador, Angeletos, and Werning
(2003).


1. The Economy
A. The Model
      Here we describe our simple model of monetary policy. The economy has a monetary
authority and a continuum of individual agents. The time horizon is infinite, with periods
indexed t = 0, 1, . . . .
      At the beginning of each period, agents choose individual action zt from some compact
set. We interpret z as (the growth rate of) an individual’s nominal wage and let xt denote
the (growth of the) average nominal wage. Next, the monetary authority observes the
current realization of its private information about the state of the economy. This private

                                              5
information θt is an i.i.d., mean 0 random variable with support θ ∈ [θ, θ̄], with a strictly
positive density p(θ) and a distribution function P (θ). Given this private information, the
monetary authority chooses money growth µt in some large compact set [µ, µ̄].
      The monetary authority maximizes a social welfare function R(xt , µt , θt ) that depends
on the average nominal wage xt , the monetary growth rate µt , and a privately observed shock
θt . We interpret θt to be private information of the monetary authority regarding the impact
of a monetary stimulus on social welfare in the current period. Throughout, we assume that
R is strictly concave in µ and twice continuously diﬀerentiable.
      As a benchmark example, we use this function:

                               1h                             i
(1)    R(xt , µt , θ t ) = −     (U + xt − µt )2 + (µt − θt )2 .
                               2

We interpret (1) as the reduced form that results from a monetary authority which maxi-
mizes a social welfare function that depends on unemployment, inflation, and the monetary
authority’s private information θ. Each period, inflation π t is equal to the money growth
rate µt chosen by the monetary authority. Unemployment is determined by a Phillips curve.
The unemployment rate is given by

(2)    ut = U + xt − µt

where U is a positive constant, which we interpret as the natural rate of unemployment.
Social welfare in period t is a function of ut and π t and the shock θt . Our benchmark
example is derived from a quadratic objective function which has the form

           u2t   (π t − θt )2
(3)    −       −
           2          2

similar to that used by Kydland and Prescott (1977) and Barro and Gordon (1983). Using
(2) and π t = µt in (3), we obtain (1). Here the monetary authority’s private information is
about the social cost of inflation, but we develop our model for general specifications of the
social welfare function R(xt , µt , θt ) which subsume (1) as a special case.
      Throughout, a policy for the monetary authority in any given period, denoted µ(·),
specifies the money growth rate µ(θ) for each level of the shock θ. For any x, we define the


                                                     6
static best response to be the policy µ∗ (θ; x) that solves Rµ (x, µ(θ), θ) = 0. We assume that
      R
if x = µ(θ)p(θ) dθ, then
       Z
(4)        Rx(x, µ(θ), θ )p(θ) dθ < 0.


B. Two Ramsey Benchmarks
      Before we analyze the economy in which the monetary authority has private informa-
tion, it is useful to consider two alternative economies. We think of the optimal policies in
these economies as benchmarks for that in the private information economy.
      One benchmark, the Ramsey policy, denoted µR (·), yields the highest payoﬀ that can
be achieved in an economy with full information. The gap between that Ramsey payoﬀ and
the payoﬀ in the economy with private information measures the welfare loss due to private
information.
      The other benchmark, the expected Ramsey policy, denoted µER , is the optimal policy
when the policy is restricted to not depend on private information. In our environment, there
is no publicly observed shock to the economy; hence, this policy is a constant. The expected
Ramsey policy is a useful benchmark because it is the best policy that can be achieved by
a rule which specifies policies as a function only of observables. This policy is analogous to
the strict targeting rule discussed by Canzoneri (1985).
      For the Ramsey policy benchmark, consider an economy with full information with the
following timing scheme. Before the shock θ is realized, the monetary authority commits to a
schedule for money growth rates µ(·). Next, individual agents choose their nominal wages z
with associated average nominal wages x. Then the state θ is realized and the money growth
rate µ(θ) is implemented. The optimal allocations and policies in this economy solve the
Ramsey problem:
                Z
       max          R(x, µ(θ), θ)p(θ) dθ
       x,µ(·)
                     R
subject to x =           µ(θ)p(θ) dθ. For our example (1), the Ramsey policy is µR (θ) = θ/2. Note
that the Ramsey policy has the monetary authority choosing a money growth rate which is
increasing in its private information. Thus, with full information, it is optimal to have the
monetary authority fine tune its policy to the state. This feature of the environment leads to

                                                    7
a tension in the economy with private information between allowing the monetary authority
discretion for fine tuning and experiencing the resulting time inconsistency problems.
          For the other benchmark, consider an economy in which the monetary authority is
restricted to choosing money growth µ that does not vary with its private information. The
equilibrium allocations and policies in the economy with these constraints solve the expected
Ramsey problem:
                  Z
(5)        max
           x,µ
                      R(x, µ, θ)p(θ) dθ

subject to x = µ. For our example (1), the expected Ramsey policy is µER = 0.
          For our example (1), the Ramsey policy obviously yields strictly higher welfare than
does the expected Ramsey policy. More generally, when Rµθ (x, µ, θ) > 0, the Ramsey policy
µR (·) is strictly increasing in θ and yields strictly higher welfare than does the expected
Ramsey policy.

C. The Dynamic Mechanism Design Problem
          To analyze the problem of finding the optimal degree of discretion, we use the tools of
dynamic mechanism design. Without loss of generality, we formulate the problem as a direct
revelation game. In this problem, society specifies a monetary policy, the money growth rate
as a function of the history of the monetary authority’s reports of its private information.
Given the specified monetary policy, the monetary authority chooses a strategy for reporting
its private information. Individual agents choose their wages as functions of the history of
reports of the monetary authority.
          A   monetary          policy      in   this       environment     is       a   sequence   of   functions
n     ³       ´                 o∞                ³         ´
 µt ht , θ̂ t | all ht , θ̂ t         , where µt ht , θ̂t       specifies the money growth rate that will be
                                t=0
                                                                ³                ´
chosen in period t following the history ht = θ̂0 , θ̂1 , . . . , θ̂t−1 of past reports together with
the current report θ̂t . The monetary authority chooses a reporting strategy {mt (ht , θt )| all
ht , θt }∞
         t=0 in period 0, where θ t is the current realization of private information and mt (ht , θ t )

∈ [θ, θ̄] is the reported private information in t. As is standard, we restrict attention to public
strategies, those that depend only on public histories and the current private information,



                                                                8
not on the history of private information.2 Also, from the Revelation Principle, we need only
restrict attention to truth-telling equilibria in which mt (ht , θt ) = θt for all ht and θt .
       In each period, each agent chooses the action zt as a function of the history of reports
ht . Since agents are competitive, the history need not include either agents’ individual past
actions or the aggregate of their past actions.3
       Each agent chooses nominal wage growth equal to expected inflation. For each history
ht , with monetary policy µt (ht , ·) given, agents set zt (ht ) equal to expected inflation:
                     Z
(6)     zt (ht ) =       µt (ht , θ)p(θ) dθ

where we have used the fact that agents expect the monetary authority to report truthfully,
so that mt (ht , θ t ) = θ t . Aggregate wages are defined by xt (ht ) = zt (ht ).
       The optimal monetary policy maximizes the discounted sum of social welfare:
                  ∞ Z
                  X
(7)     (1 − β)            β t R(xt (ht ), µt (ht , θ t ), θt )p(θt ) dθt
                  t=0

where the future histories ht are recursively generated from the choice of monetary policy
µt (·, ·) in the natural way, starting from the null history. The term 1 − β normalizes the
discounted payoﬀs to be in the same units as the per-period payoﬀs.
       A perfect Bayesian equilibrium of this revelation game is a monetary policy, a reporting
strategy, a strategy for wage-setting by agents {zt (·)}∞                               ∞
                                                        t=0 , and average wages {xt (·)}t=0

such that (6) is satisfied in every period following every history ht , average wages equal
individual wages in that xt (ht ) = zt (ht ), and the monetary policy is incentive-compatible
in the standard sense that, in every period, following every history ht and realization of
the private information θt , the monetary authority prefers to report mt (ht , θt ) = θ t rather
than any other value θ̂ ∈ [θ, θ̄]. Note that since average wages xt (ht ) always equal wages of
individual agents zt (ht ), we need only record average wages from now on.
       Note that this definition of a perfect Bayesian equilibrium includes no notion of op-
timality for society.         Instead, it simply requires that in response to a given monetary

   2
     For a discussion of the large class of environments for which this restriction does not alter the set of
equilibrium payoﬀs, see Fudenberg and Tirole (1991).
   3
     For details of why this is true, see the work of Chari and Kehoe (1990).



                                                              9
policy, private agents respond optimally and truth-telling for the monetary authority is
incentive-compatible. The set of perfect Bayesian equilibria outcomes are the set of incentive-
compatible outcomes that are implementable by some monetary policy.
       The mechanism design problem is to choose a monetary policy, a reporting strategy,
and a strategy for average wages the outcomes of which maximize social welfare (7) subject
to the constraint that these strategies are incentive-compatible.

D. A Recursive Formulation
       Here we formulate the problem of characterizing the solution to this mechanism design
problem recursively. The repeated nature of the model implies that the set of incentive-
compatible payoﬀs that can be obtained from any period t on is the same that can be obtained
from period 0. Thus, the payoﬀ to any incentive-compatible outcome for the repeated game
can be broken down into payoﬀs from current actions for the players and continuation payoﬀs
that are themselves drawn from the set of incentive-compatible payoﬀs. Following this logic,
Abreu, Pearce, and Stacchetti (1990) show that the set of incentive-compatible payoﬀs can
be found using a recursive method that we exploit here.
       In our environment, this recursive method is as follows. Consider an operator on sets of
the following form. Let W be some compact subset of the real line, and let w̄ be the largest
element of W . The set W may be interpreted as a candidate set of incentive-compatible
levels of social welfare. In our recursive formulation, the current actions are average wages
x and a report θ̂ = m(θ) for every realized value of the state θ. For each possible report θ̂,
there is a corresponding continuation payoﬀ w(θ̂) that represents the discounted utility for
the monetary authority from next period on. Clearly, these continuation payoﬀs cannot vary
directly with the privately observed state θ.
       We say that the actions x and µ(·) and the continuation payoﬀ w(·) are enforceable by
W if

(8)     w(θ̂) ∈ W for all θ̂ ∈ [θ, θ̄]
             Z
(9)     x=       µ(θ)p(θ) dθ



                                                10
and the incentive constraints

(10)    (1 − β)R(x, µ(θ), θ) + βw(θ) ≥ (1 − β)R(x, µ(θ̂), θ) + βw(θ̂)

are satisfied for all θ and all θ̂, where µ(θ) ∈ [µ, µ̄]. Constraint (8) requires that each con-
tinuation payoﬀ w(θ̂) be drawn from the candidate set of incentive-compatible payoﬀs W,
while constraint (9) requires that average wages equal expected inflation. Constraint (10)
requires that for each privately observed state θ, the monetary authority prefer to report the
truth θ rather than any other message θ̂. That is, the monetary authority prefers the money
growth rate µ(θ) and the continuation value w(θ) rather than a money growth rate µ(θ̂) and
its corresponding continuation value w(θ̂).
       The payoﬀ corresponding to x, µ(·), and w(·) is
                                    Z h                                 i
(11)    V (x, µ(·), w(·)) =             (1 − β)R(x, µ(θ), θ ) + βw(θ) p(θ) dθ.

Define the operator T that maps a set of payoﬀs W into a new set of payoﬀs


(12)    T (W ) =        {v | there exist xv , µv (·), wv (·) enforceable by W
                                   s.t. v = V (xv , µv (·), wv (·))}.


As demonstrated by Abreu, Pearce, and Stacchetti (1990), the set of incentive-compatible
payoﬀs is the largest set W that is a fixed point of this operator:

(13)    W ∗ = T (W ∗ ).

       For any given candidate set of incentive-compatible payoﬀs W, we are interested in
finding the largest payoﬀ that is enforceable by W, or the largest element v̄ ∈ T (W ). We
find this payoﬀ by solving the following problem, termed the best payoﬀ problem:
                             Z h                                    i
(14)    v̄ =     max           (1 − β)R(x, µ(θ), θ) + βw(θ) p(θ) dθ
               x,µ(θ),w(θ)


subject to the constraint that x, µ(·), and w(·), are enforceable by W , in that they satisfy (8)—
(10). Throughout, we assume that µ(·) is a piecewise, continuously diﬀerentiable function.



                                                           11
       The best payoﬀ problem is a mechanism design problem of choosing an incentive-
compatible allocation x, µ(·), w(·) which maximizes utility. Following the language of mech-
anism design, we refer to θ as the type of the monetary authority, which changes every
period. When we solve this problem with W = W ∗ , (13) implies that the resulting payoﬀ is
the highest incentive-compatible payoﬀ. We will prove our main result in Proposition 1 for
any W. Hence, we will not have to solve the fixed-point problem of finding W ∗ .
       To prove our results, we need only focus on the best payoﬀ problem, which gives the
highest payoﬀ that can be obtained from period 0 onward. For completeness, notice that
given some w0 (θ) from the best payoﬀ problem, a period 1 policy and continuation value,
µw0 (θ) (·) and ww0 (θ) (·), that satisfy
                   Z h                                                i
(15)    w0 (θ) =      (1 − β)R(xw0 (θ) , µw0 (θ) (z), z ) + βww0 (θ) (z) p(z) dz

exist by the definition of T. Equation (15) is sometimes referred to as a promise-keeping
constraint. Proceeding recursively, we can generate the whole sequence of policies µt (ht , ·).


2. Characterizing the Optimal Mechanism
       Now we solve the best payoﬀ problem and use the solution to characterize the optimal
mechanism. Our main result here is that under two simple conditions, a single-crossing
condition and a monotone hazard condition, the optimal mechanism is static. To highlight
the importance of the monotone hazard condition for this result, we give two examples which
show that if the monotone hazard condition is violated, the optimal mechanism is dynamic.

A. Preliminaries
       We begin with some definitions. In our recursive formulation, we say that a mechanism
is static if the continuation value w(θ) = w̄ for (almost) all θ. We say that a mechanism is
dynamic if w(θ) < w̄ for some set of θ which is realized with strictly positive probability.
       Our characterization of the solution to the best payoﬀ problem does not depend on the
exact value of β. Hence, to simplify the notation, we suppress explicit dependence on β and
think of the term β as being subsumed in the w function and 1 − β as being subsumed in
the R function.


                                                    12
        We assume that the preferences satisfy a standard single-crossing assumption, that

(A1) Rµθ (x, µ, θ) > 0.

This implies that higher types have a stronger preference for current inflation. Notice that
the single-crossing assumption, together with the strict concavity of R, implies that the static
best response is strictly increasing in θ, or that

         ∂µ∗ (θ; x)    Rµθ (x, µ(θ), θ)
(16)                =−                  > 0.
            ∂θ         Rµµ (x, µ(θ), θ)
        Under the single-crossing assumption (A1), a standard lemma lets us replace the global
incentive constraints (10) with some local versions of them. We say that an allocation is
locally incentive-compatible if it satisfies three conditions: µ(·) is nondecreasing in θ;

                           dµ(θ) dw(θ)
(17)     Rµ (x, µ(θ), θ)        +      =0
                            dθ    dθ

wherever dµ(θ)/dθ and dw(θ)/dθ exist; and for any point θi at which these derivatives do
not exist,

(18)     lim R(x, µ(θ), θi ) + w(θ) = lim R(x, µ(θ), θi ) + w(θ).
         θ%θi                                        θ&θi


Standard arguments give the following result: under the single-crossing assumption (A1), the
allocation (x, µ(·), w(·)) satisfies the incentive constraints (10) if and only if the allocation
is locally incentive-compatible. (See, for example, Fudenberg and Tirole’s (1991) text.)
        Given any incentive-compatible allocation, we define the utility of the allocation at θ
to be

         U(θ) = R(x, µ(θ), θ) + w(θ).

Local incentive-compatibility implies that U(·) is continuous and diﬀerentiable almost every-
where, with derivative U 0 (θ) = Rθ (x, µ(θ), θ). Integrating U 0 (·) from θ up to θ gives that
                           Z       θ
(19)     U(θ) = U(θ) +                  Rθ (x, µ(z), z ) dz
                               θ

while integrating U 0 (·) from θ̄ down to θ gives that
                             Z         θ̄
(20)      U (θ) = U (θ̄) −                  Rθ (x, µ(z), z ) dz.
                                   θ

                                                                   13
With integration by parts, it is easy to show that for interval endpoints θ1 < θ2 ,
        Z   θ2                                                          Z   θ2
(21)             U (θ)p(θ) dθ = P (θ2 )U (θ2 ) − P (θ 1 )U (θ 1 ) −              Rθ (x, µ(θ), θ )P (θ) dθ.
          θ1                                                             θ1
                                                                                              R θ̄
Using (19) and (21), we can write the value of the objective function                          θ     U(θ)p(θ) dθ as
                     Z    θ̄                                                 Z θ̄
                               1 − P (θ)                                          P (θ)
(22)    U(θ) +                           Rθ (x, µ(θ), θ )p(θ) dθ or U (θ̄) −            Rθ (x, µ(θ), θ)p(θ) dθ.
                      θ          p(θ)                                         θ p(θ)

       Next we make some joint assumptions on the probability distribution and the return
function. Assume that, for any action profile x, µ(·) with µ(·) nondecreasing,
          1 − P (θ)
(A2a)               Rθµ (x, µ(θ), θ ) is strictly decreasing in θ
            p(θ)
          P (θ)
(A2b)           Rθµ (x, µ(θ), θ) is strictly increasing in θ.
          p(θ)


We refer to assumptions (A2a) and (A2b) together as (A2) and, in a slight abuse of ter-
minology, refer to them as the monotone hazard condition. In our benchmark example (1),
Rθµ (x, µ(θ), θ) = 1, so that (A2) reduces to the standard monotone hazard condition fa-
miliar from the mechanism design literature, that [1 − P (θ)]/p(θ) be strictly decreasing and
P (θ)/p(θ) be strictly increasing.

B. Showing That the Optimal Mechanism Is Static
       Here we show that the optimal mechanism is static. In the next section, we characterize
the optimal static mechanism.

       Proposition 1. Under assumptions (A1) and (A2), the optimal mechanism is static.

       The approach we take in proving Proposition 1 is diﬀerent from the standard approach
used by Fudenberg and Tirole (1991, Chapter 7.3) for solving a mathematically related
principal-agent problem. To motivate our approach, we first show why the standard approach
does not work for our problem.
       The best payoﬀ problem can be written as follows: Choose µ(θ) to maximize social
welfare
                     Z    θ̄   1 − P (θ)
        U(θ) +                           Rθ (x, µ(θ), θ )p(θ) dθ
                      θ          p(θ)

                                                             14
                                                           R
subject to the constraints that (i) x = µ(θ)p(θ) dθ, (ii) µ(θ) is nondecreasing, and (iii) the
continuation values defined by
                                Z       θ
        w(θ) ≡ U (θ) +                       Rθ (x, µ(z), z ) dz − R(x, µ(θ), θ)
                                 θ


satisfy w(θ) ≤ w̄ for all θ. Alternatively, we can write the best payoﬀ problem as choosing
µ(θ) to maximize
                  Z    θ̄   P (θ)
        U(θ̄) −                   Rθ (x, µ(θ), θ)p(θ) dθ
                   θ        p(θ)

subject to the constraints (i), (ii), and (iii), the continuation values defined by
                                Z       θ̄
        w(θ) ≡ U (θ̄) −                      Rθ (x, µ(z), z ) dz − R(x, µ(θ), θ)
                                    θ


satisfy w(θ) ≤ w̄ for all θ.
       The standard approach to solving either version of this problem is to guess that the
analog of constraints (ii) and (iii) do not bind, take the corresponding first-order conditions
of either of these problems to find the implied µ(·), and then verify that constraints (ii) and
(iii) are in fact satisfied at that choice of µ(·). If we take that approach here, we see that it
fails. The first-order conditions with respect to µ(θ) are

        1 − P (θ)
(23)              Rθµ (x, µ(θ), θ ) = λ
          p(θ)

for the first version of the best payoﬀ problem and

            P (θ)
(24)    −         Rθµ (x, µ(θ), θ ) = λ
            p(θ)

for the second version of the best payoﬀ problem, where λ is the Lagrange multiplier on
constraint (i). The solution to these first-order conditions (23) and (24), from the relaxed
problem in which we have dropped constraints (ii) and (iii), implies a decreasing µ(·) sched-
ule. To see why, note, for example, that the left side of equation (23) is the increment to
social welfare from marginally increasing µ(·) at some particular θ and adjusting the con-
tinuation values w(·) for θ0 ≥ θ to preserve incentive-compatibility, while the right side is
the cost in terms of welfare from raising expected inflation x. Under assumption (A2a), the
benefits of raising µ(·) are higher for low values of θ than for high values of θ. Thus, in


                                                                 15
the relaxed problem, it is optimal to have a downward-sloping µ(·) schedule. Similar logic
applies to (24). Clearly, then, the solution to the relaxed problem violates at least one of
the dropped constraints (ii) or (iii), and hence, we cannot use this standard approach.
     We also cannot use the ironing approach designed to deal with cases in which the
monotonicity constraint (ii) binds, because in our problem, the constraint that binds is
constraint (iii), which is not dealt with in that approach. Instead, in the proof of Proposition
1 that follows, we use a variational argument to show that constraint (iii) binds for all θ at
the solution to the best payoﬀ problem.
     The key feature of our problem that leads to the failure of the standard approach is
that the continuation value enters positively into the payoﬀ of both society and the monetary
authority. Mathematically, these continuation values are analogous to the transfers between
the principal and the agent in the standard principal-agent problem presented by Fudenberg
and Tirole (1991, Chapter 7.3). In that problem, the transfers enter positively into the
agent’s problem but negatively into the principal’s problem. This diﬀerence between our
problem and the principal-agent problem is the key reason the standard approach doesn’t
work and, at some deep level, is the whole reason we obtain our main result.
     Before proving Proposition 1, we sketch our basic argument. Our discussion of the
first-order conditions of the relaxed problem (23) and (24) suggests that given any strictly
increasing µ(·) schedule, a variation that flattens this schedule will improve welfare if it is
feasible in the sense that the associated continuation value satisfies constraint (iii). Our
proof of Lemma 1 formalizes this logic.
     Our objective is to show that the optimal continuation value w(·) is constant at w̄.
We prove this by contradiction. We start with the observation that w(·) is piecewise-
diﬀerentiable since µ(·) is piecewise-diﬀerentiable and (17) holds. We first show that w(·)
must be a step function. If not, there would be some interval over which w0 (θ) is nonzero,
and hence, from local incentive-compatibility, µ(·) is strictly increasing. In Lemma 2, we
show that a variation that flattens µ(·) over that interval is feasible. From Lemma 1, we
know it is welfare-improving.
     We next show that w(·) must be continuous, and since it is a step function, it must be


                                              16
constant. We prove this by showing that if w(·) is discontinuous at some point θ, then (18)
implies that µ(·) must be increasing in the sense that it jumps up at that point. In Lemma
3, we show that a variation that flattens µ(·) in a neighborhood of that point is feasible, and
again from Lemma 1, we know that it is welfare-improving.
       It is convenient in the proof to use a definition of increasing on an interval which covers
the cases we deal with in Lemmas 2 and 3. This definition subsumes the case of Lemma 2
in which dµ(θ)/dθ > 0 for some interval and the case of Lemma 3 in which µ(·) jumps up at
θ̃. We say that µ(·) is increasing on (θ 1 , θ2 ) if µ(·) is weakly increasing on this interval and
there is some θ̃ in this interval such that µ(θ) < µ̃ for θ < θ̃ and µ(θ) > µ̃ for θ > θ̃, where
µ̃ is the conditional mean of µ(·) on this interval, namely,
               R θ2
                θ1µ(θ)p(θ) dθ
(25)    µ̃ =                      .
               P (θ 2 ) − P (θ1 )
In words, on this interval, the function µ(·) is weakly increasing and is strictly below its
conditional mean µ̃ up to θ̃ and strictly above its conditional mean after θ̃.4 Throughout,
we will also say that the policy µ(·) is flat at some particular point θ if the derivative µ0 (θ)
exists and equals zero at that point.
       Consider now some dynamic mechanism (x, µ(·), w(·)) in which the policy µ(·) is in-
creasing on some interval, say, (θ1 , θ2 ). In our variation, we marginally move the function µ(·)
toward its conditional mean on this interval and adjust the continuation values to preserve
incentive-compatibility. In particular, our variation moves our original policy µ(·) marginally
toward a policy µ̃(·) defined by
                                       
                
                 µ̃ if θ ∈ (θ 1 , θ2 )
                                        
(26)    µ̃(θ) =                         .
                
                 µ(θ) otherwise

This policy µ̃(·) diﬀers from the original policy µ(·) only on the interval (θ1 , θ2 ), and there
the original policy µ(·) is replaced by the conditional mean µ̃ of the original policy over
the interval. Clearly, the expected inflation under µ̃(·) is the same as the expected inflation
under the original policy.

   4
    Observe that this definition of increasing is stronger than the definition of a function being weakly
increasing on an interval because our definition rules out a function that is constant over the interval. But
our definition is weaker than the definition of a function being strictly increasing over an interval because
ours allows for subintervals over which µ(·) is constant.

                                                     17
       We let (x(a), µ(·; a), w(·; a)) and U(·; a) denote our variation and the associated utility.
The policy µ(·; a) in our variation is a convex combination of the policy µ̃(·) and the original
policy µ(·) and is defined by

(27)    µ(θ; a) = aµ̃(θ) + (1 − a)µ(θ)

for a ∈ [0, 1] . (For a graph of µ(·; a), see Figure 1.) Clearly, the expected inflation in our
variation x̃(a) equals that of the original allocation x for all a ∈ [0, 1] .
       The delicate part of the variation is to construct the continuation value w(·; a) so as to
satisfy the feasibility constraint w(θ; a) ≤ w̄ for all θ, in addition to incentive-compatibility.
It turns out that we can ensure feasibility if we use one of two ways to adjust continuation
values. In the up variation, we leave the continuation values unchanged below θ1 and pass
up any changes induced by our variation in the policy to higher types by suitably adjusting
the continuation values to maintain incentive-compatibility. In the down variation, we leave
the continuation values unchanged above θ 2 and pass down any changes induced by our vari-
ation in the policy to lower types by suitably adjusting the continuation values to maintain
incentive-compatibility.
       In the up variation, we determine the continuation values by substituting U (θ; a) =
R(x, µ(θ; a), θ) + w(θ; a) into (19) to get that w(θ; a) is defined by
                             Z       θ
(28)    w(θ; a) = U (θ) +                 Rθ (x, µ(z; a), z ) dz − R(x, µ(θ; a), θ).
                             θ


In the down variation, we use (20) in a similar way to get that w(θ; a) is defined by
                             Z       θ̄
(29)    w(θ; a) = U (θ̄) −                Rθ (x, µ(z; a), z ) dz − R(x, µ(θ; a), θ).
                                 θ


By construction, these variations are incentive-compatible. In the following lemma, we show
that, if either variation is feasible, it improves welfare.

       Lemma 1. Assume (A1) and (A2), and let (x, µ(·), w(·)) be an allocation in which
µ(·) is increasing on some interval (θ1 , θ2 ). Then the up variation and the down variation
both increase the objective function (22).




                                                             18
       Proof. To see that the up variation improves welfare, use (22) to write the value of
the objective function under this variation as
                            Z       θ̄   1 − P (θ)
(30)     V (a) = U (θ) +                           Rθ (x, aµ̃(θ) + (1 − a)µ(θ), θ)p(θ) dθ.
                            θ              p(θ)

To evaluate the eﬀect on welfare of a marginal change of this type, take the derivative of
Ṽ (a) and evaluate it at a = 0 to get

         dV (0) Z θ̄ 1 − P (θ)
(31)           =               Rθµ (x, µ(θ), θ) [µ̃(θ) − µ(θ)] p(θ) dθ
          da     θ     p(θ)

which, with the form of µ̃(·), reduces to

         dV (0) Z θ2 1 − P (θ)
(32)           =               Rθµ (x, µ(θ), θ) [µ̃ − µ(θ)] p(θ) dθ.
          da     θ1    p(θ)

If we divide (32) by the positive constant P (θ2 ) − P (θ 1 ), then we can interpret (32) to be
the expectation of the product of two functions f (θ) ≡ {[1 − P (θ)]/p(θ)}Rθµ (x, µ(θ), θ) and
g(θ) ≡ µ̃−µ(θ), where the density is p(θ)/[P (θ2 )−P (θ1 )]. The function f is strictly decreasing
by assumption (A2a). Because the function µ(θ) is increasing on the interval (θ 1 , θ2 ), the
function g is decreasing on this interval in the sense that g(θ) is weakly decreasing and lies
strictly below its conditional mean for θ < θ̃ and strictly above its conditional mean for θ > θ̃.
By the definition of a covariance, we know that Ef g = cov(f, g) + (Ef )(Eg), where the
expectation is taken with respect to the density p(θ)/[P (θ2 ) − P (θ 1 )]. By the construction of
µ̃ in (25), we know that Eg = 0, so that Ef g = cov(f, g), which is clearly positive because
f is strictly decreasing and g is decreasing on the interval (θ1 , θ2 ). Thus, (32) is strictly
positive, and the variation improves welfare.
       The down variation also improves welfare. The value of the objective function under
this variation is
                            Z       θ̄   P (θ)
         V (a) = U (θ̄) −                      Rθ (x, aµ̃(θ) + (1 − a)µ(θ), θ)p(θ) dθ.
                                θ        p(θ)

Hence,

         dV (0) Z θ2 P (θ)
(33)           =           Rθµ (x, µ(θ), θ) [µ(θ) − µ̃] p(θ) dθ > 0
          da     θ1 p(θ)

by arguments similar to those given before. Q.E.D.

                                                             19
       To gain some intuition for how these variations improve welfare, consider the up vari-
ation and the expression for the change in welfare (32). We show how the total eﬀect on
welfare resulting from this flattening of the inflation schedule can be thought of as arising
from two eﬀects: a positive eﬀect that comes from raising inflation for low types and a nega-
tive eﬀect that comes from lowering inflation for high types. Our assumption (A2a) ensures
that the positive eﬀect outweighs the negative eﬀect.
       For any type, the flattening aﬀects both the current payoﬀ R and the continuation
value w. The impact of increasing a on the current payoﬀ for type θ is

        Rµ (x, µ(θ), θ) [µ̃(θ) − µ(θ)] .

In the up variation, the impact of increasing a on the continuation value for this type is
                      Z
        dw̃(θ; 0)             θ
(34)              =               Rθµ (x, µ(z), z ) [µ̃(z) − µ(z)] dz − Rµ (x, µ(θ), θ) [µ̃(θ) − µ(θ)] .
           da             θ


Hence, the impact on the utility of type θ is simply the sum of these pieces and is given by

        dŨ (θ; 0) Z θ
(35)              =    Rθµ (x, µ(z), z ) [µ̃(z) − µ(z)] dz.
           da       θ


Notice from (35) that any change in the policy for some particular type z aﬀects the utility
of all types θ above z. Thus, each term

(36)    [1 − P (z)]Rθµ (x, µ(z), z ) [µ̃(z) − µ(z)]

in the integral (31) can be thought of as the sum of the change in utility for all types z
and above resulting from the change in the inflation schedule for the type z. Under our
single-crossing assumption, Rθµ (x, µ(θ), θ) > 0, so the impact of changing the policy at θ
depends on the sign of µ̃(θ) − µ(θ). Recall that outside the interval (θ1 , θ2 ), µ̃(θ) = µ(θ), so
that the value of (36) is zero. Inside the interval (θ1 , θ2 ), µ̃(θ) = µ̃, where µ̃ is the conditional
mean on this interval. By definition of the type θ̃, on the interval (θ1 , θ̃), µ̃ − µ(θ) > 0, and
on the interval (θ̃, θ2 ), µ̃ − µ(θ) < 0. Therefore, our variation has both a positive eﬀect and
a negative eﬀect on welfare.
       The positive eﬀect of flattening the inflation schedule comes from increasing the policy
of those types θ below θ̃ and then passing this change up to higher types. The negative

                                                            20
eﬀect of the flattening comes from decreasing the policy for those types θ above θ̃. Under
assumption (A2a), the positive eﬀect outweighs the negative eﬀect.
       In the down variation, the intuition for the derivative (33) is the same as that for (32),
except that, in this variation, a change in the inflation rate chosen by type θ aﬀects the
continuation value of all types below θ.
       The following lemma proves that if w(·) is not a step function, then µ(·) is increasing
on some interval, and there is a feasible variation that flattens µ(·) and improves welfare.

       Lemma 2. Under (A1) and (A2), in the optimal mechanism, the continuation value
function w(·) is a step function.

       Proof. Since by assumption µ(·) is piecewise-diﬀerentiable, we know from (17) that
w(·) is too. By way of contradiction, assume that w(·) is not a step function. Hence,
there is an interval over which w0 (θ) exists and does not equal zero. Clearly, then, there
is a subinterval (θ1 , θ2 ) over which w0 (θ) is either strictly positive or strictly negative, and
w(θ) ≤ w̄ − ε for some ε > 0. From local incentive-compatibility, we know that

                            dµ(θ) dw(θ)
        Rµ (x, µ(θ), θ)          +      =0
                             dθ    dθ

so that regardless of the sign of w0 (θ), we have that µ0 (θ) > 0 on this interval. Hence, µ(·)
is increasing on (θ1 , θ2 ) in the sense defined above. From Lemma 1, we know that, if the up
and down variations are feasible, then they both improve welfare.
       To complete the proof, we need to show that either the up variation or the down
variation is always feasible. Under the up variation, (27) and (28) imply that w(θ; a) equals
w(θ) for θ ≤ θ1 and

        w(θ) + ∆(a)

for θ ≥ θ2 , where
                 Z   θ2
(37)    ∆(a) ≡            [Rθ (x, µ(z; a), z ) − Rθ (x, µ(z), z )] dz.
                 θ1


       See Figure 2 for a graph of w(θ; a) in the up variation. This graph illustrates several
features of w(θ; a): it coincides with w(θ) for θ ≤ θ1 , it diﬀers from w(θ) by the constant

                                                        21
∆(a) for θ ≥ θ2 , and it jumps at both θ1 and θ 2 . This last feature follows from (18) and the
fact that µ(θ; a) jumps at these points. Notice in the graph that w(θ) ≤ w̄ −ε for θ ∈ (θ1 , θ 2 ).
       Under the down variation, (27) and (29) imply that w(θ; a) equals

(38)    w(θ) − ∆(a)

for θ ≤ θ1 and w(θ) for θ ≥ θ2 . See Figure 3 for a graph of w(θ; a) in the down variation.
       To ensure that the continuation value satisfies feasibility, we do the following. We use
the up variation when term ∆(a) ≤ 0 and the down variation when that term is positive.
By doing so, we ensure that outside the interval (θ1 , θ 2 ) the continuation value under this
variation is no larger than the original continuation value w(θ), which, by assumption, is
feasible. We know that inside the interval (θ1 , θ2 ), w(θ) ≤ w̄ − ε. Since R is continuous in µ,
we can choose a small enough to ensure that w(θ; a) ≤ w̄. Q.E.D.

       In the next lemma, we show that the optimal policy w(θ) is continuous. Since we know
from Lemma 2 that w(·) is a step function, we conclude that w(·) is a constant. Optimality
implies that this constant is w̄.

       Lemma 3. Under (A1) and (A2), w(θ) is continuous for all θ.

       Proof. In Appendix A, we prove that w(·) is continuous by contradiction. We show
that if w(·) jumps at some point θ̃, then the same up variation and down variation we used
in Lemma 1 will improve welfare. The only diﬃcult part of the proof is showing that when
the appropriate interval (θ1 , θ2 ) is selected that contains the jump point θ̃, the associated
continuation values are feasible. Here it may turn out that the feasibility constraint binds
inside the interval (θ1 , θ2 ), in that the original allocation has w(θ) = w̄ for some θ in (θ1 , θ 2 ).
Thus, we cannot simply shrink the size of the weight a in the variation to ensure feasibility
on (θ1 , θ2 ), as we did in the proof of Lemma 2. Instead we show that the variation is feasible
inside the interval (θ1 , θ2 ) by direct calculations that we relegate to Appendix A. Q.E.D.

       Together Lemmas 2 and 3 establish Proposition 1, that under our assumptions, the
optimal mechanism is static. Our characterization of optimal policy relied on the monotone
hazard assumption (A2). Under this assumption, we showed that the dynamic mechanism

                                                  22
design problem has a static solution. In Appendix B, we give two simple examples in which
the monotone hazard condition is violated at only one point, yet the dynamic mechanism
design problem does not have a static solution.

3. The Optimal Degree of Discretion
         So far we have demonstrated that the optimal mechanism is static. Now we characterize
the optimal static mechanism. We show three results: The optimal policy has either bounded
discretion or no discretion. A policy with either bounded discretion or no discretion can
be implemented by society setting an upper limit, or cap, on the inflation rate which the
monetary authority is allowed to choose. And the optimal degree of discretion is decreasing
in the severity of the time inconsistency problem.

A. Characterizing the Optimal Policy
         In the optimal static mechanism, the monetary policy µ(·) maximizes
          Z
(39)          R(x, µ(θ), θ )p(θ) dθ
                                             R
subject to the constraints that x =              µ(θ)p(θ) dθ and R(x, µ(θ), θ) ≥ R(x, µ(θ̂), θ) for all
θ, θ̂.
         We say that a monetary policy µ(·) has bounded discretion if it takes the form
                                                     
                   
                          ∗
                         µ (θ; x) if θ ∈ [θ, θ ) ∗    
                                                      
(40)      µ(θ) =
                   
                    µ∗ = µ∗ (θ∗ , x) if θ ∈ [θ∗ , θ̄] 
                                                       
                                                                    R
where µ∗ (θ; x) is the static best response given wages x = µ(θ)p(θ) dθ. Thus, for θ < θ∗ , the
monetary authority chooses the static best response, and for θ ≥ θ∗ , the monetary authority
chooses the upper limit µ∗ . A policy has no discretion if µ(θ) = µ for some constant µ, so
that regardless of θ, the monetary authority chooses the same growth rate. Clearly, the best
policy with no discretion is the expected Ramsey policy.5
         We show that the optimal policy has either bounded discretion or no discretion. Here,
as before, we can replace the global incentive constraint in (39) with the local incentive

    5
    Note that the best policy with no discretion, the Ramsey policy, will not typically be a special case of a
policy with bounded discretion. Specifically, when θ ∗ = θ, the form (40) yields one particular policy with no
discretion, namely, µ(θ) = µ∗ (θ; x) for all θ. But this policy does not typically coincide with the expected
Ramsey policy µER since the best response of the lowest type is not typically the expected Ramsey policy.

                                                       23
constraints, with the restriction that w(θ) = w̄. In particular, (18) implies that µ(·) is
continuous, while (17), namely, Rµ dµ/dθ = 0, implies that for all θ, µ(θ) is either flat or
equal to the static best response. Clearly, if µ(·) is flat everywhere, it is a constant; hence,
it equals the expected Ramsey policy, which by definition is the best constant policy. If µ(·)
is not flat everywhere, then it must be of the following form for some θ1 and θ2 :
                                                      
                
                          ∗
                
                 µ 1 =  µ   (θ 1 ; x) if θ ∈ [θ ,θ  )
                                                    1 
                
                                                      
                                                       
(41)     µ(θ) =      µ∗ (θ; x) if θ ∈ [θ1 , θ2 ]      
                                                       
                
                                                      
                
                
                 µ = µ∗ (θ ; x) if θ ∈ (θ , θ̄]
                      2         2               2

             R
where x = µ(θ)p(θ) dθ. In words, the policy must be constant up to some point θ1 ≥ θ and
equal to the static best response of type θ 1 ; it must be equal to the static best response of
each type θ ∈ [θ1 , θ2 ] with θ2 ≤ θ̄; and then it must be constant and equal to the static best
response of type θ 2 .
       In the following proposition, we show that if the optimal policy is not the expected
Ramsey policy, then it must be of the form (41) with θ1 equal to θ, so that the policy’s form
reduces to the bounded discretion form in (40).

       Proposition 2. Under assumptions (A1) and (A2), the optimal policy µ(·) has either
bounded discretion or no discretion.

       Proof. We have argued that if the optimal policy is constant, then it must be an
expected Ramsey policy, which has no discretion. If the optimal policy is not constant, then
it must be of the form (41). But µ(θ) having the form (41) with θ1 > θ cannot be optimal.
To see this, observe that an alternative policy µ̃(θ) of the same form would exist with θ̃1 < θ 1
and θ̃2 = θ2 . We illustrate this alternative policy in Figure 4. This alternative policy µ̃(θ)
                                                                                R
would be closer to µ∗ (θ, x) wherever it diﬀers from µ(θ) and would satisfy         µ̃(θ)p(θ) dθ <
R
    µ(θ)p(θ) dθ = x. Hence, this alternative policy µ̃(θ) would be strictly preferred to µ(θ);
the change from µ(θ) to µ̃(θ) directly improves welfare for all types θ < θ1 , with x held
fixed. The change also reduces x, which by (4) contributes to improving total welfare. More
formally, observe that the marginal impact on welfare of a marginal reduction in θ1 is given



                                                      24
by
               Z        (                                       )
                   θ1
                                     ∗             ∂µ∗ (θ1 ; x)
       dṼ =                 Rµ (x, µ (θ1 ; x), θ)              ∆θ1 p(θ) dθ
               θ                                       ∂θ
                   Z    θ̄   n                   o
               +              Rx (x, µ(θ), θ )∆x p(θ) dθ > 0
                    θ

where the inequality follows from the facts that Rµ (x, µ∗ (θ1 ; x), θ) < 0, ∂µ∗ (θ1 ; x)/∂θ > 0,
∆θ1 < 0, ∆x < 0, and (4). Q.E.D.

B. Implementing the Optimal Policy with an Inflation Cap
     We have characterized the solution to a dynamic mechanism design problem. We
now imagine implementing the resulting outcome with an inflation cap, a highest level of
allowable inflation π̄. We imagine that society legislates this highest allowable level and that
doing so restricts the monetary authority’s choices to be µt ≤ π̄. If this cap is appropriately
set and agents simply play the repeated one-shot equilibrium of the resulting game with
this inflation cap, then the monetary authority will optimally choose the outcome of the
mechanism design problem. In this sense, the repeated one-shot game with an inflation cap
implements the policy that solves the best payoﬀ problem.
     The intuition for this result–that a policy with either bounded discretion or no discre-
tion can be implemented by setting an upper limit on permissible inflation rates–is simple.
In our environment, the only potentially beneficial deviations from either type of policy are
ones that raise inflation. Under bounded discretion, the types in [θ, θ∗ ) are choosing their
static best response to wages and, hence, have no incentive to deviate, whereas the types
in (θ∗ , θ̄] have an incentive to deviate to a higher rate than π̄. Similarly, from Proposition
3 (stated and proved below), we know that if the expected Ramsey policy is optimal, then
at this policy all types have an incentive to deviate to higher rates of inflation. Hence, an
inflation cap of π̄ = µER implements such a policy. (For completeness, we formalize this
argument in Appendix C.)


C. Linking Discretion and Time Inconsistency
     So far we have shown that the optimal policy has either bounded discretion or no
discretion. Here we link the optimal degree of discretion to the severity of the time incon-

                                                          25
sistency problem. We show that the more severe that problem is, the smaller is the optimal
degree of discretion.
      The literature using general equilibrium models to study optimal monetary policies
suggests a qualitative way to measure the severity of the time inconsistency problem. In this
literature, either the time inconsistency problem is so severe that the static best response
of the monetary authority is at the highest feasible inflation rate µ̄ or the problem is less
severe, so that the static best response is typically some interior inflation rate. Examples of
the models with the more severe problems include those of Ireland (1997); Chari, Christiano,
and Eichenbaum (1998); and Sleet (2001). In these models, while expected inflation has a
cost, surprise inflation does not; thus, the monetary authority is always tempted to generate
a monetary surprise. Examples of the models with the less severe problems include those of
Chang (1998), Nicolini (1998), and Albanesi, Chari, and Christiano (2003). In these models,
surprise inflation does have a cost, which leads the static best response of the monetary
authority to be interior.
      In our reduced-form model, we can mimic the general equilibrium models with the more
severe problems by choosing a payoﬀ function R for which the resulting static best response
is always the highest feasible inflation rate µ̄. We show that then the optimal policy has no
discretion. We can mimic the general equilibrium models with the less severe problems by
choosing a payoﬀ function for which the static best response is typically interior. The optimal
policy then depends on parameters. Here we show one qualitative result and fully analyze
the policy for our benchmark example. Our qualitative result is that if the lowest type θ
wants to lower inflation when x equals the expected Ramsey inflation rate, then bounded
discretion is optimal. At an intuitive level, our condition on the lowest type captures the
idea that the incentives to generate surprise inflation are mild.
      More formally, we have the following:

      Proposition 3. Assume (A1) and (A2). If the static best response has µ∗ (θ, x) = µ̄
for all θ and x, then the optimal policy has no discretion. If the static best response has
µ∗ (θ, µER ) lower than the expected Ramsey policy µER , then the optimal policy has bounded
discretion.

                                              26
        Proof. Under (A1) and (A2), the optimal mechanism is static, and thus, from local
incentive-compatibility, for every θ, µ(θ) is either flat or equal to the static best response.
Under the assumption that µ∗ (θ, x) = µ̄, the static best response is itself flat. Thus, µ(θ) is
flat everywhere and by optimality must equal the expected Ramsey policy.
        Assume next that µ∗ (θ, µER ) < µER , but that the optimal policy has no discretion. The
variation used in Proposition 2 immediately implies that such a policy cannot be optimal.
Thus, the optimal policy must have bounded discretion. Q.E.D.

        We now turn back to the benchmark example (1). Here we think of the nonnegative
parameter U as indexing the severity of the time inconsistency problem. When U equals zero,
there is no such problem, and as U increases from zero, the problem gets worse. To see why,
note that with this objective function, the static best response is µ∗ (θ; x) = (U + x + θ)/2.
Notice that for any given x and θ, increasing U shifts out the static best response of that
type θ. This measure of the severity of the time inconsistency problem is also reflected in the
diﬀerence between the expected inflation rate in the static Nash equilibrium and that in the
Ramsey equilibrium. To see this, note that the static Nash equilibrium inflation rate can be
found by solving for the fixed point in x from
               Z
                    ∗                U +x 1Z
(42)     x=        µ (θ; x)p(θ) dθ =     +   θp(θ) dθ.
                                       2   2
        R
Since       θp(θ) dθ = 0, we have that the Nash inflation rate is xN = U , and the Nash policies
are µ∗ (θ; U ) = U + (θ/2). The Ramsey inflation rate is xR = 0, and the Ramsey policies are
µR (θ) = θ/2. Thus, for each type θ, the Nash policies are simply the Ramsey policies shifted
up by U. As U gets smaller, the Nash policies converge to the Ramsey policies. When U is
zero, the Nash and Ramsey policies coincide.
        When the objective function satisfies (1), the condition µ∗ (θ; µER ) < µER in Proposi-
tion 3 reduces to U < −θ, where θ is a negative number. Proposition 3 thus implies that
bounded discretion is optimal when the time inconsistency problem is suﬃciently small, in
that the static best response for the low types is below the expected Ramsey allocation. To
get a more precise link between the severity of the time inconsistency problem and the opti-
mal degree of discretion, we characterize the optimal mechanism more fully in this parametric

                                                 27
case.
        For policies of the bounded discretion form (40), we think of θ∗ as indexing the degree
of discretion. If θ ∗ = θ̄, then all types θ are on their static best responses, and, hence, we say
there is complete discretion. As θ∗ decreases, fewer types are on their static best responses,
and, hence, we say there is less discretion. The following proposition thus links the severity
of the time inconsistency problem, indexed by U, and the degree of discretion, indexed by
θ∗ :

        Proposition 4. Assume (1), (A1), and (A2a). If U = 0, then the optimal policy has
complete discretion. If U ∈ (0, −θ) , then that policy has bounded discretion with θ∗ < θ̄.
The optimal degree of discretion θ∗ is decreasing in U. As U approaches −θ, the cutoﬀ θ ∗
approaches θ . If U ≥ −θ, then the optimal policy is the expected Ramsey policy with no
discretion.

        We prove this proposition by direct calculations that we provide in Appendix D. Figure
5 illustrates the proposition for two economies with diﬀerent degrees of severity of time
inconsistency problems, UH > UL . In these two economies, we denote the optimal policies
by µH (·) indexed by θ∗H and µL (·) indexed by θ ∗L , along with the inflation caps π̄ H and π̄ L .


4. Comparison to the Literature
        Our result on the optimality of a static mechanism is quite diﬀerent from what is
typically found in dynamic contracting problems, namely, that static mechanisms are not
optimal. Using a recursive approach, we have shown how our dynamic mechanism design
problem reduces to a simple quasi-linear mechanism design problem. Our results are thus
also directly comparable to the large literature on mechanism design with broad applications,
including those in industrial organization, public finance, and auctions. (See Fudenberg
and Tirole’s 1991 book for an introduction to mechanism design and its applications.) In
this comparison, the continuation values in our framework correspond to the contractual
compensation to the agent in the mechanism design literature. Our result that the optimal
mechanism is static, so that the continuation values do not vary with type, stands in contrast
to the standard result in the mechanism design literature that under the optimal contract,

                                                28
the compensation to the agent varies with the agent’s type. In this sense, our result is also
quite diﬀerent from what is found in the mechanism design literature as well.
     One reason for the diﬀerence between our results and those in these literatures is
that in our model, the monetary authority maximizes the welfare of society, so that there
is no inherent conflict between the monetary authority and society except for the time
inconsistency problem. In contrast, in both the dynamic contracting literature and the
mechanism design literature, there is an inherent conflict between the agents in the economy.
For example, in a principal-agent model, higher payments to the agents leave less money
for the principal. Likewise, in a dynamic social insurance problem, a higher continuation
value for one type of agent implies, through the resource constraint, a lower continuation
value for some other agent. In either of these literatures, incentives can be provided by
redistributing resources among agents. In our model, in order to provide dynamic incentives,
the continuation payoﬀs for all agents in the model must be lowered.
     This distinction about the nature of the conflict in the model seems to be necessary for
our result, but not suﬃcient, for at least two reasons. First, even in our model, we have given
examples in which the optimal mechanism is dynamic when our monotone hazard condition
is violated. Second, the information structure seems important. In our model, private agents
receive direct information about the state. If private agents receive a noisy signal about the
state before the monetary authority takes its action, then our results go through pretty much
unchanged; the noisy signal is just a publicly observed variable upon which the inflation cap
is conditioned. If, however, private agents receive a noisy signal about the information the
monetary authority received after the monetary authority takes its action, then dynamic
mechanisms in which continuation values vary with this signal may be optimal.
     Sleet (2001) considers such an information structure and shows that the optimality of
the dynamic mechanism depends on the parameters governing the noise. He finds that when
the public signal about the monetary authority’s information is suﬃciently noisy, it is not
optimal to have the monetary authority’s action depend on its private information; hence,
the optimal mechanism is static. In contrast, when this public signal is suﬃciently precise,
the optimal mechanism is dynamic. The logic of why a dynamic mechanism is optimal is


                                              29
roughly similar to that in the literature in industrial organzation following Green and Porter
(1984) on optimal collusive agreements that are supported by periodic reversion to price
wars, even though these price wars lower all firms’ profits.
     Our work here is also related to some of the repeated game literature in industrial
organization about supporting collusion in oligopolies. Athey and Bagwell (2001) and Athey,
Bagwell, and Sanchirico (forthcoming) solve for the best trigger strategy-type equilibria in
games with hidden information about cost types. Athey and Bagwell (2001) show that, in
general, the best equilibrium is dynamic (nonstationary). In this equilibrium, observable
deviations by some firm from a prescibed path lead to that firm getting a lower discounted
value of profits from then on. Athey, Bagwell, and Sanchirico (forthcoming) show that when
strategies are restricted to treat deviators symmetrically with nondeviators, a diﬀerent result
emerges. In particular, under some conditions, the best equilibrium is stationary and entails
pooling of all cost types. When those conditions fail, and when firms are suﬃciently patient,
there may be a set of stationary and nonstationary equilibria that yield the same payoﬀs.
(The latter result relies heavily on the Revenue Equivalence Theorem from auction theory.)


5. Conclusion
     What is the optimal degree of discretion in monetary policy? For economies with severe
time inconsistency problems, it is zero. For economies with less severe time inconsistency
problems, it is not zero, but bounded. More generally, the optimal degree of discretion is
decreasing in the severity of the time inconsistency problem. And whatever the severity of
that problem, the optimal policy can be implemented by enforcing a simple inflation cap.
     In our simple model, the optimal inflation cap is a single number because there is no
publicly observed state. If the model were extended to have a publicly observed state, then
the optimal policy would respond to this state, but not to the private information. To achieve
this, society would specify a rule for setting the inflation cap with public information. We
interpret such a rule as a type of inflation targeting.




                                              30
References

Abreu, Dilip; Pearce, David; and Stacchetti, Ennio. 1990. Toward a Theory of Discounted
     Repeated Games with Imperfect Monitoring. Econometrica 58(5, September), 1041—
     63.
Albanesi, Stefania; Chari, V. V.; and Christiano, Lawrence. 2003. Expectation Traps and
     Monetary Policy. Review of Economic Studies 70(4, October), 715—42.
Albanesi, Stefania, and Sleet, Christopher. 2002. Optimal Policy with Endogenous Fiscal
     Constitutions. Manuscript, Fuqua School of Business, Duke University.
Amador, Manuel; Angeletos, George-Marios; and Werning, Iván. 2003. Optimal Commit-
     ment. Manuscript, Massachusetts Institute of Technology.
Angeletos, George-Marios; Hellwig, Christian; and Pavan, Alessandro. 2003. Coordination
     and Policy Traps. Manuscript, Massachusetts Institute of Technology.
Athey, Susan, and Bagwell, Kyle. 2001. Optimal Collusion with Private Information. RAND
     Journal of Economics 32(3, Autumn), 428—65.
Athey, Susan; Bagwell, Kyle; and Sanchirico, Chris. Forthcoming. Collusion and Price
     Rigidity. Review of Economic Studies.
Atkeson, Andrew, and Lucas, Robert E., Jr. 1992. On Eﬃcient Distribution with Private
     Information. Review of Economic Studies 59(3, July), 427—53.
Backus, David, and Driﬃll, John. 1985. Inflation and Reputation. American Economic
     Review 75(3, June), 530—38.
Barro, Robert J., and Gordon, David B. 1983. Rules, Discretion and Reputation in a Model
     of Monetary Policy. Journal of Monetary Economics 12(1, July), 101—21.
Bernanke, Ben S., and Mishkin, Frederic S. 1997. Inflation Targeting: A New Framework
     for Monetary Policy? Journal of Economic Perspectives 11(2, Spring), 97—116.
Bernanke, Ben S., and Woodford, Michael. 1997. Inflation Forecasts and Monetary Policy.
     Journal of Money, Credit, and Banking, Part 2, 39(4, November), 653—84.
Canzoneri, Matthew B. 1985. Monetary Policy Games and the Role of Private Information.
     American Economic Review 75(5, December), 1056—70.
Chang, Roberto. 1998. Credible Monetary Policy in an Infinite Horizon Model: Recursive

                                             31
     Approaches. Journal of Economic Theory 81(2, August), 431—61.
Chari, V. V.; Christiano, Lawrence J.; and Eichenbaum, Martin. 1998. Expectation Traps
     and Discretion. Journal of Economic Theory 81(2, August), 462—92.
Chari, V. V., and Kehoe, Patrick J. 1990. Sustainable Plans. Journal of Political Economy
     98(4, August), 783—802.
Cukierman, Alex, and Meltzer, Allan H. 1986. A Theory of Ambiguity, Credibility, and Infla-
     tion under Discretion and Asymmetric Information. Econometrica 54(5, September),
     1099—1128.
Da Costa, Carlos, and Werning, Iván. 2001. On the Optimality of the Friedman Rule with
     Heterogeneous Agents and Non-Linear Income Taxation. Manuscript, Massachusetts
     Institute of Technology.
Faust, Jon, and Svensson, Lars E. O. 2001. Transparency and Credibility: Monetary Policy
     with Unobservable Goals. International Economic Review 42(2, May), 369—97.
Fudenberg, Drew, and Tirole, Jean. 1991. Game Theory. Cambridge, Mass.: MIT Press.
Green, Edward J. 1987. Lending and the Smoothing of Uninsurable Income. Contractual
     Arrangements for Intertemporal Trade, 3—25. Minnesota Studies in Macroeconomics
     series, vol. 1. Minneapolis: University of Minnesota Press.
Green, Edward J., and Porter, Robert H. 1984. Noncooperative Collusion under Imperfect
     Price Information. Econometrica 52(1, January), 87—100.
Ireland, Peter N. 1997. Sustainable Monetary Policies. Journal of Economic Dynamics and
     Control 22(1, November), 87—108.
Ireland, Peter N. 2000. Expectations, Credibility, and Time-Consistent Monetary Policy.
     Macroeconomic Dynamics 4(4, December), 448—66.
Kocherlakota, Narayana R. 1996. Implications of Eﬃcient Risk Sharing without Commit-
     ment. Review of Economic Studies 63(4, October), 595—609.
Kydland, Finn E., and Prescott, Edward C. 1977. Rules Rather Than Discretion: The
     Inconsistency of Optimal Plans. Journal of Political Economy 85(3, June), 473—91.
Nicolini, Juan Pablo. 1998. More on the Time Consistency of Monetary Policy. Journal of
     Monetary Economics 41(2, April), 333—50.


                                            32
Persson, Torsten, and Tabellini, Guido. 1993. Designing Institutions for Monetary Stability.
     Carnegie-Rochester Conference Series on Public Policy 39(December), 53—84.
Phelan, Christopher, and Stacchetti, Ennio. 2001. Sequential Equilibria in a Ramsey Tax
     Model. Econometrica 69(6, November), 1491—1518.
Rampini, Adriano A. 2003. Default and Aggregate Income. Manuscript, Kellogg School of
     Management, Northwestern University.
Romer, Christina D., and Romer, David H. 2000. Federal Reserve Information and the
     Behavior of Interest Rates. American Economic Review 90(3, June), 429—57.
Sleet, Christopher. 2001. On Credible Monetary Policy and Private Government Informa-
     tion. Journal of Economic Theory 99(1—2, July—August), 338—76.
Sleet, Christopher, and Yeltekin, Sevin. 2003. Credible Monetary Policy with Private Gov-
     ernment Preferences. Manuscript, Kellogg School of Management, Northwestern Uni-
     versity.
Stokey, Nancy L. 2003. “Rules versus Discretion” After Twenty-Five Years. In NBER
     Macroeconomics Annual 2002, vol. 17, ed. Mark Gertler and Kenneth Rogoﬀ, 9—45.
     Cambridge, Mass.: MIT Press.
Taylor, John B. 1983. Rules, Discretion and Reputation in a Model of Monetary Policy:
     Comments. Journal of Monetary Economics 12(1, July), 123—25.
Walsh, Carl E. 1995. Optimal Contracts for Central Bankers. American Economic Review
     85(1, March), 150—67.




                                            33
                                           Appendix A: Proof of Lemma 3

         Proof. By way of contradiction, suppose that w(·) jumps at some point θ̃. Since w(·)
is a step function, w0 (θ) = 0 in some interval (θ1 , θ2 ) containing θ̃. Clearly, this implies that
either w(θ) < w̄ for all θ in (θ 1 , θ̃) or w(θ) < w̄ for all θ in (θ̃, θ2 ). We know from (17) that
at any point θ in the intervals (θ1 , θ̃) and (θ̃, θ2 ), either µ0 (θ) = 0, so that µ(·) is flat, or
Rµ (x, µ(θ), θ) = 0, so that µ(θ) equals the static best response. By continuity of the static
best response, we can choose the points θ1 and θ2 to be close enough to θ̃ so that µ(·) either
is constant on the interval (θ 1 , θ̃) or equals the static best response on this interval, and
similarly for the interval (θ̃, θ2 ).
         Consider first the hard case, namely, when µ(·) is constant on both (θ1 , θ̃) and (θ̃, θ 2 ).
Let (µ1 , w1 ) denote the allocation on (θ1 , θ̃) and (µ2 , w2 ) denote the allocation on (θ̃, θ2 ). By
the continuity of Rµ , we can choose this interval (θ1 , θ2 ) small enough so that if Rµ (x, µ1 , θ̃)
is strictly positive, then so is Rµ (x, µ1 , θ1 ), and if Rµ (x, µ2 , θ̃) is strictly negative, then so is
Rµ (x, µ2 , θ2 ).
         Suppose that for the chosen interval (θ1 , θ2 ), the term ∆(a), defined in (37), is negative
for small a. If the up variation is feasible, then we know it improves welfare, based on the
same logic as in the proof of Lemma 2. By construction, the up variation is incentive-
compatible. This variation is feasible outside the interval (θ 1 , θ2 ), based on the logic of the
proof of Lemma 2. We complete the proof for this case by showing that the variation is also
feasible inside the interval (θ1 , θ2 ).
         Suppose, initially, that R(x, µ1 , θ̃) > R(x, µ2 , θ̃). From (18) we have that w1 < w2 , and
from the feasibility of the original allocation that w2 ≤ w̄. This case is illustrated in Figure
6a. For θ ∈ (θ1 , θ̃), we thus know that w(θ; a) ≤ w̄ for suﬃciently small a.
         For θ ∈ (θ̃, θ 2 ), if w2 < w̄, then since a is suﬃciently small, w(θ; a) ≤ w̄. If w2 = w̄, we
show that ∂ w̃(θ; 0)/∂a is negative for θ ∈ (θ̃, θ2 ) as follows. Diﬀerentiate (28) to obtain that
∂ w̃(θ; 0)/∂a equals
                        Z   θ̃                                     Z    θ2
(43)       (µ̃ − µ1 )            Rθµ (x, µ1 , z) dz + (µ̃ − µ2 )             Rθµ (x, µ2 , z) dz − Rµ (x, µ2 θ)(µ̃ − µ2 ).
                        θ1                                         θ̃
           R θ2
Using       θ̃
                  Rθµ (x, µ2 , z) dz = Rµ (x, µ2 , θ2 ) − Rµ (x, µ2 , θ̃) and an analogous expression for
R θ̃
 θ1    Rθµ (x, µ1 , z) dz, we can write (43) as

(44)       [Rµ (x, µ1 , θ̃) − Rµ (x, µ1 , θ1 )](µ̃ − µ2 ) − Rµ (x, µ2 , θ̃)(µ̃ − µ2 ).

         We will show that (44) is negative. To do so, we begin by noting that ∆0 (0) < 0. This
is true because ∆(0) = 0, and we have assumed that ∆(a) is negative for small a. Using the


                                                               34
form of µ(θ) on the interval (θ1 , θ 2 ), we have that
                              Z   θ̃                                     Z    θ2
        ∆0 (0) = (µ̃ − µ1 )            Rθµ (x, µ1 , θ) dθ + (µ̃ − µ2 )             Rθµ (x, µ2 , θ) dθ < 0.
                              θ1                                         θ̃

Substituting for the integrals, we can write this inequality as

(45)    [Rµ (x, µ1 , θ̃) − Rµ (x, µ1 , θ1 )](µ̃ − µ1 ) + [Rµ (x, µ2 , θ2 ) − Rµ (x, µ2 , θ̃)](µ̃ − µ2 ) < 0.

Comparing the inequality in (45) with the expression in (44), we can see that a suﬃcient
condition for (44) to be negative is that

(46)    Rµ (x, µ2 , θ 2 )(µ̃ − µ2 ) > 0.

       We now show that (46) holds. Note that since µ(·) is increasing on the interval
(θ1 , θ2 ), it follows by definition that µ̃ < µ2 , since, by construction, µ̃ is the conditional
mean of µ(θ) on this interval. Thus, (46) is positive if Rµ (x, µ2 , θ2 ) is negative. To see
that Rµ (x, µ2 , θ2 ) is negative, note that since w1 ≤ w̄ and w2 = w̄, the incentive constraint
R(x, µ1 , θ̃) + w1 = R(x, µ2 , θ̃) + w̄ implies that R(x, µ1 , θ̃) ≥ R(x, µ2 , θ̃). Since µ2 > µ1 and R
is strictly concave, we know that Rµ (x, µ2 , θ̃) < 0. By our construction of the interval, since
Rµ (x, µ2 , θ̃) is strictly negative, so is Rµ (x, µ2 , θ2 ). Thus, for this case, the up variation is
feasible, incentive-compatible, and welfare-improving. An analogous argument holds when
R(x, µ1 , θ̃) < R(x, µ2 , θ̃) and w̄ ≥ w1 > w2 , as in Figure 6b.
       So far we have considered the case when µ(·) is constant on both sides of θ̃ and the
term ∆(a) is negative for small a. In the case when µ(·) is constant on both sides of θ̃ but
the term ∆(a) is positive for small a, we use the down variation and an analogous argument.
       The case when µ(·) is constant on one side of θ̃ and equal to the static best response
on the other side of θ̃ is the easy case. Suppose, for example, that µ(·) equals the static
best response for θ on some interval (θ1 , θ̃). Here we simply take the relevant interval to be
(θ1 , θ̃), from some point θ1 just below the jump point θ̃ up to the jump point θ̃. Clearly, µ(·)
is increasing on the interval (θ 1 , θ̃). We claim that w(·) is uniformly bounded below w̄, and
so Lemma 2 immediately applies.
       We prove that w(·) is uniformly bounded below w̄ on (θ1 , θ̃) as follows. Since µ(·)
jumps up at θ̃, it lies strictly above the static best response for some interval (θ̃, θ2 ), so that
limθ%θ̃ R(x, µ(θ), θ̃) > limθ&θ̃ R(x, µ(θ), θ̃). Hence, from condition (18) in local incentive-
compatibility, we know that limθ%θ̃ w(θ) < limθ&θ̃ w(θ). Thus, for θ ∈ (θ 1 , θ̃), w(θ) is uni-
formly bounded below w̄.
       With an analogous argument, we can rule out the case in which µ(θ) equals the static
best response for θ on the other side of the jump point, on some interval (θ̃, θ2 ). Q.E.D.


                                                          35
                    Appendix B: Optimal Policy without Monotone Hazards

       Here we give two examples in which our monotone hazard condition is violated and
in which the optimal mechanism is dynamic. In both examples, we assume that the hazard
[1 − P (θ)]/p(θ) is decreasing in θ at all points except the point θ1 , where the hazard jumps
up. We also assume that P (θ)/p(θ) is increasing throughout.
       At the point θ 1 , we assume that
        Z                        Z θ̄
             θ1   1 − P (θ)           1 − P (θ)
(47)                        dθ <                  dθ.
         θ          P (θ1 )       θ1 1 − P (θ 1 )

To interpret this inequality, note that the left side is the conditional mean of the function
[1 − P (θ)]/p(θ) over the interval [θ, θ1 ] while the right side is the conditional mean of this
function over the interval (θ1 , θ̄]. Clearly, for any distribution for which [1 − P (θ)]/p(θ) is
decreasing throughout [θ, θ̄], this inequality is reversed.
       It is easy to show that a two-piece uniform distribution with p(θ) = ρ1 if θ ≤ θ1 and
p(θ) = ρ2 if θ > θ1 will satisfy (47) if ρ2 is chosen to be suﬃciently small relative to ρ1 . In
this case, illustrated in Figure 7, the function [1 − P (θ)]/p(θ) will jump up suﬃciently at θ 1
so that the conditional mean of this function over the higher interval [θ1 , θ̄] is larger than
the conditional mean over the lower interval [θ, θ1 ).
       In the first example, the linear example, we make the calculations trivial by assuming
that R(x, µ, θ) = (θ − θ)µ + r(x) with r(x) = −x2 /2. In the second example, which is the
benchmark example of (1), we assume that
                             1h                        i
(48)    R(x, µ, θ) = −          (U + x − µ)2 + (µ − θ)2 .
                             2
       Both of these examples satisfy the single-crossing property (A1). In both of them,
Rθµ = 1, so that the conditions (A2) reduce to the standard monotone hazard conditions.
Note that for either example, any distribution that satisfies (47) is inconsistent with the
monotone hazard condition (A2a).

The Linear Example
       Notice that any solution to the mechanism design problem must have the two-piece
form
                                                  
                        (µ , w ) for θ ∈ [θ, θ )
                           1   1               1
(49)    (µ(θ), w(θ)) =                             .
                        (µ , w ) for θ ∈ [θ , θ̄]
                           2   2            1

This follows because the arguments used in Lemmas 1 and 2 can be applied separately to
the intervals [θ, θ1 ) and (θ1 , θ̄] and because for any θ > θ, the static best response to any x in
the interval [µ, µ̄] is a constant, namely, the upper limit µ̄. Since this policy must satisfy the

                                                        36
incentive constraint (θ1 − θ)µ1 + w1 = (θ 1 − θ)µ2 + w2 , the monotonicity condition µ1 ≤ µ2
implies that w1 ≥ w2 . Thus, we know that w1 = w̄ and that the constraint w2 ≤ w̄ will be
automatically satisfied by any monotonic policy.
       The mechanism design problem then reduces to the linear problem of choosing µ1 , µ2 ,
and x to maximize
                            Z     θ1                          Z θ̄
                                       1 − P (θ)                   1 − P (θ)
        r(x) + w̄ + µ1                           p(θ) dθ + µ2                p(θ) dθ
                              θ          p(θ)                  θ2    p(θ)
subject to the constraints that µ ≤ µ1 ≤ µ2 ≤ µ̄ and that x = P (θ1 )µ1 + [1 − P (θ1 )]µ2 .
If (47) holds and if the lower and upper limits µ, µ̄ include the expected Ramsey policy,
then the optimal policy will have either µ = µ1 < µ2 or µ1 < µ2 = µ̄. To see this, consider
spreading out the policy by decreasing µ1 by ∆1 and increasing µ2 by ∆2 so that the change
in expected inflation [1 − P (θ1 )]∆2 − P (θ1 )∆1 is zero. The associated welfare change can be
written as
        "    Z                       Z θ̄                    #
                 θ1   1 − P (θ)           1 − P (θ)
(50)     −                      dθ +                  dθ P (θ1 )∆1 > 0
             θ          P (θ1 )       θ2 1 − P (θ 1 )


where the inequality follows from (47). Hence, the solution must have µ1 < µ2 , and from the
incentive constraint, we then know that w2 < w1 = w̄. Thus, the solution to the mechanism
design problem is necessarily dynamic.

The Benchmark Example
       Assume that the policy µ(·), which solves the static mechanism design problem, has
bounded discretion and that θ1 > θ ∗ , so that the jump point in the hazard occurs on the
flat portion of that policy. (We can construct a numerical example in which this assumption
holds.) We will show that there is a dynamic mechanism that improves on the optimal static
mechanism. The basic idea is to use a variation that spreads out the policy as a function of
type instead of flattens it as we did in Lemmas 1 and 2.
       This variation is similar to the one in the linear example. Consider an alternative
policy that lowers inflation for types at or below θ1 , raises it for types above θ1 , and keeps
expected inflation constant:
                                                    
                 µ(θ) − ∆                 if θ ≤ θ1 
                           0
        µ̃(θ) =
                 µ(θ) + ∆                 if θ > θ1
                                       1

with ∆0 , ∆1 > 0 and [1−P (θ1 )]∆1 −P (θ1 )∆0 = 0, so that expected inflation is constant. Note
that this alternative policy µ̃(·) is monotonically increasing since µ(·) must be monotonically




                                                            37
increasing. Our variation is a marginal shift from µ(·) toward µ̃(·) defined as µ(θ; a) =
aµ̃(θ) + (1 − a)µ(θ) for each θ. Welfare is given by
                                                    Z     θ̄   1 − P (θ)
        V (a) = R(x, µ(θ; a), θ) + w̄ +                                  Rθ (x, µ(θ; a), θ)p(θ) dθ.
                                                      θ          p(θ)
The impact of this variation on welfare is given by
                                           Z θ1
        ∂V (0)                                  1 − P (z)
(51)           = −∆0 Rµ (x, µ(θ), θ) − ∆0                  Rθµ (x, µ(z), z )p(z) dz
         ∂a                                  θ     p(z)
                      Z θ̄
                           1 − P (z)
                 + ∆1                Rθµ (x, µ(z), z )p(z) dz.
                       θ1    p(z)

Since µ(θ) has bounded discretion, Rµ (x, µ(θ), θ) = 0. In our quadratic example,
Rθµ (x, µ(z), z ) = 1; hence, (51) reduces to (50), which we know from (47) is positive.
       It is straightforward, but somewhat tedious, to show that the associated continuation
values w(θ; a) defined by
                                        Z   θ
        R(x, µ(θ; a), θ) + w̄ +                 Rθ (x, µ(z; a)) dz − R(x, µ(θ; a), θ)
                                        θ

have ∂w (θ; 0) /∂a ≤ 0 for all θ and ∂w (θ; 0) /∂a < 0 for θ > θ1 . To do so, we use the facts
that Rµ (x, µ(θ), θ) = 0 and that θ1 > θ ∗ , so that µ(θ) = µ(θ1 ) for θ ≥ θ1 . These results imply
that this variation both improves welfare and is feasible. Thus, the optimal mechanism must
be dynamic.
       Note that if µ(·) has no discretion, then we need a diﬀerent condition on the distribution
to show that the static mechanism is not optimal. This is because when µ(·) has no discretion,
we can have Rµ (x, µ(θ), θ) > 0, and the above argument that ∂w (θ; 0) /∂a ≤ 0 for all θ does
not go through. When µ(·) has no discretion, the analog of the condition (47) is that at
x = µ = µER , there exists a θ1 such that
                               Z   θ1                  Z θ̄
                                        1 − P (z)           1 − P (z)
        Rµ (µER , µER , θ) +                      dz <                  dz.
                               θ          P (θ1 )       θ1 1 − P (θ 1 )

With this condition, the optimal mechanism is dynamic rather than static. Note that, in our
linear example, this distinction did not come up because in the linear example, our utility
function is such that Rµ (x, µ(θ), θ) = 0 with no discretion.


                  Appendix C: Implementation with an Inflation Cap

       Here we prove that the equilibrium outcome in an economy with an inflation cap is the
optimal outcome of the mechanism design problem. We show this result formally using the
following one-shot game in which we drop time subscripts.

                                                                   38
       With an inflation cap of π̄ in the current period, the problem of the monetary authority
at a given θ is as follows: Given aggregate wages x, choose money growth µ(θ) for this state
θ to maximize R(x, µ, θ) subject to µ(θ) ≤ π̄. The private agents’ decisions on wages are
                         R
summarized by x = µ(θ)p(θ).
       An equilibrium of this one-shot game consists of aggregate wages x and a money growth
                                                                                   R
policy µ(·) such that (i) with x given, µ(·) satisfies µ(θ) ≤ π̄, and (ii) x =         µ(θ)p(θ). We
                                                             ∗
denote the optimal choice of the monetary authority as µ (·; x, π̄). This notation reflects the
fact that the monetary authority is choosing a static best response to x given that its choice
set is restricted by π̄, which we call the inflation cap.
       To implement the best equilibrium in the dynamic game, we choose π̄ as follows.
Whenever the expected Ramsey policy is optimal, we choose the inflation cap to be

(52)    π̄ = µER .

Whenever bounded discretion is optimal, we choose the cap π̄ to be the money growth rate
chosen by the cutoﬀ type θ∗ :

(53)    π̄ = µ∗ (θ∗ , x∗ )

where x∗ is the equilibrium inflation rate with this level of bounded discretion.

       Proposition 5. Assume (A1), (A2), and that the inflation cap π̄ is set according to
(52) and (53). Then the equilibrium outcome of the one-shot game with the inflation cap
for each period coincides with the optimal equilibrium outcome of the dynamic game.

       Proof. To establish this result, we first show that the monetary authority will choose
the upper bound π̄ = µER when the expected Ramsey policy is optimal in the dynamic
game. Note that Proposition 3 implies that whenever the expected Ramsey policy is optimal,
µER ≤ µ∗ (θ; µER ). Also, recall that the single-crossing assumption (A1) implies that the best
response is strictly increasing in θ, so that (16) holds. Thus, µ∗ (θ; µER ) ≤ µ∗ (θ; µER ) for all
θ. Hence, at the expected Ramsey policies and the associated inflation rate, all types want
to deviate by increasing their inflation above µER ; hence, the constraint π̄ = µER binds, and
all types choose the expected Ramsey levels.
       We next show that if bounded discretion is optimal in the dynamic game, then in
the associated static game with the inflation cap, all types choose the bounded discretion
policies. For all types θ ≤ θ ∗ , the policies under bounded discretion are simply the static
best responses, and these clearly coincide with those in the static game. For all types
θ above θ∗ , the policies under bounded discretion are the static best responses of the θ ∗


                                                39
type, namely, µ∗ (θ; x∗ ), where x∗ is the equilibrium expected inflation rate under bounded
discretion. Under assumption (A1), the static best responses are increasing in the type, so
that the best response of any type θ ≥ θ∗ is above µ∗ (θ; x∗ ). Thus, in the one-shot game with
the inflation cap, the constraint (53) binds for such types. Thus, the equilibrium outcomes
of the two games coincide. Q.E.D.


                                             Appendix D: Proof of Proposition 4

       We prove Proposition 4 by computing the optimal cutoﬀ θ∗ under bounded discretion
as a function of the parameter U in the function (1). Under the bounded discretion policy
µ(θ) = µ∗ (θ; x) for θ ≤ θ∗ and µ∗ (θ∗ ; x) for θ > θ∗ , welfare and expected inflation equal
                                                       Z       θ∗
                                ∗
             R(x, µ (θ; x), θ ) +                                        Rθ (x, µ∗ (θ; x), θ)[1 − P (θ)] dθ
                                                           θ
                                                       Z       θ̄
                                              +                ∗
                                                                    Rθ (x, µ∗ (θ∗ ; x), θ)[1 − P (θ)] dθ
                                                           θ

             Z    θ∗                                                 Z       θ̄
(54)    x=                 ∗
                       µ (θ, x)p(θ) dθ +                                     ∗
                                                                                  µ∗ (θ ∗ ; x)p(θ) dθ.
              θ                                                          θ

Plugging in the form of the bounded discretion policy and simplifying gives us
                        Z       θ̄
(55)    x=U−                         (θ − θ∗ )p(θ) dθ.
                            θ∗

The first-order conditions for the problem of maximizing welfare with respect to θ∗ subject
to (54) can be reduced to
                                                           Z        θ̄
                            ∗
(56)    −[1 − P (θ )] (U + x) +                                          [1 − P (θ)] dθ = 0.
                                                               θ∗

(We derive this first-order condition at the end of this appendix.) We can then use (55) to
rewrite the first-order condition (56) as
                                    "         Z                                                 #    Z
                                                      θ̄                                                 θ̄
                       ∗                                                          ∗
(57)    [1 − P (θ )] −2U +                            ∗
                                                        (θ − θ )p(θ) dθ +                                     [1 − P (θ)] dθ = 0.
                                                  θ                                                  θ∗


For values of θ∗ < θ̄, 1 − P (θ∗ ) > 0, so (57) is equivalent to
                   Z       θ̄                                                Z        θ̄
                                         ∗                                                 1 − P (θ)  p(θ)
(58)    −2U +                (θ − θ )p(θ) dθ +                                                                 dθ = 0.
                       θ   ∗                                                      θ∗          p(θ) 1 − P (θ∗ )
       There is at most one interior solution to (58) in θ∗ . To see this, observe that the second
                  R θ̄
term of (58),          θ∗ (θ         − θ∗ )p(θ) dθ, is strictly decreasing in θ∗ . In addition, the third term of
                                                                                                                                    h   i
this expression is the conditional mean of [1 − P (θ)]/p(θ) over the interval θ ∗ , θ̄ . Under


                                                                                                40
(A2a), [1 − P (θ)]/p(θ) is strictly decreasing, so its conditional mean must also be strictly
decreasing in θ∗ . Hence, the expression in (58) is strictly decreasing in θ∗ .
          These observations prove that (58), and hence (56), has at most one interior solution.
Moreover, the derivative of our objective with respect to θ∗ is positive for θ∗ less than the
solution to (58) and negative for θ∗ greater than this solution, so this interior solution also
satisfies the second-order conditions to be a local maximum. Also note that this solution to
(58), if it exists, is decreasing in U. This follows immediately from the fact that the expression
in (58) is declining in both U and θ ∗ .
          To show that an interior solution to (57) exists given U , we must show that this
expression is negative for θ∗ close to θ̄ and positive for θ∗ = θ. Note that as θ∗ → θ̄, the term
R θ̄                                                                                             h   i
 θ∗    (θ−θ ∗ )p(θ) dθ → 0 and, since we have assumed that p(θ) > 0 on θ, θ̄ , [1−P (θ)]/p(θ) → 0.
Therefore,
           Z    θ̄   1 − P (θ)  p(θ)
                                         dθ → 0.
            θ   ∗       p(θ) 1 − P (θ∗ )
These facts imply that for U > 0 and θ∗ close enough to θ̄, the expression in (58) is strictly
less than zero, and hence, the expression in (57) is too. In the limit, at θ∗ = θ̄, the expression
in (58) is no longer defined, but we do have that θ∗ = θ̄ is a solution to (57). This solution
to (57) does not characterize a local maximum, however, because the expression in (57) is
strictly negative for θ ∗ < θ̄ in the neighborhood of θ̄.
          Note that at θ∗ = θ, the expression in (57) reduces to −2U − 2θ, which is greater than
or equal to zero for U ∈ (0, −θ) . This result follows from the fact that
           Z    θ̄                      Z       θ̄                       Z   θ̄                          Z   θ̄
(59)                 [1 − P (θ)] dθ =                d{θ[1 − P (θ)]} −            θd[1 − P (θ)] = −θ +            θp(θ) dθ = −θ.
            θ                               θ                            θ                               θ

Hence, there must be an interior solution to (58) in this case. From Proposition 3, we have
that when µ∗ (θ, µER ) < µER , the optimal policy has bounded discretion. In terms of our
parametric example, this occurs when U +θ < 0, or when U < −θ. Hence, the optimal policy
has bounded discretion in this case, and, as we have shown above, the optimal θ∗ is strictly
decreasing in U. In contrast, when U > −θ, it is not possible to have an interior solution to
(58). Hence, no discretion must be optimal.
          To complete the proof, observe that when U = 0, the Ramsey policy is incentive-
compatible and is, hence, the optimal policy.

Derivation of the First-Order Condition (56)
          Here we derive (56). The first-order conditions determining the optimal choice of θ ∗



                                                                    41
                                                              hR                              i
                                                                 θ̄
are given by the equalities that d                                θ    U(θ)p(θ) dθ /dθ∗ equals
                  "                                                                                             #
                                        ∂                                     dx
                   Rµ (x, µ (θ; x), θ) µ∗ (θ; x) + Rx (x, µ∗ (θ; x), θ)
                                   ∗
                                       ∂x                                     dθ∗
                    Z θ∗
                                                           ∂            dx
                  +      Rθµ (x, µ∗ (θ; x), θ)[1 − P (θ)] µ∗ (θ; x) ∗ dθ
                     θ                                    ∂x            dθ
                    Z θ∗
                                                          dx
                  +      Rθx (x, µ∗ (θ; x), θ )[1 − P (θ)] ∗ dθ
                     θ                                    dθ
                    Z θ̄                                  "                                  #
                                                             ∂             dx      ∂
                  + ∗ Rθµ (x, µ∗ (θ∗ ; x), θ)[1 − P (θ)]       µ∗ (θ∗ ; x) ∗ + ∗ µ∗ (θ ∗ ; x) dθ
                     θ                                      ∂x             dθ     ∂θ
                    Z θ̄
                                                          dx
                  + ∗ Rθx (x, µ∗ (θ∗ ; x), θ)[1 − P (θ)] ∗ dθ
                     θ                                    dθ
and
                      Z                               Z θ̄                       "                                                          #
       dx                 θ∗   ∂ ∗        dx               ∂ ∗ ∗       dx   ∂
           =                      µ (θ, x) ∗ p(θ) dθ + ∗      µ (θ , x) ∗ + ∗ µ∗ (θ∗ , x) p(θ) dθ.
       dθ∗            θ        ∂x         dθ           θ   ∂x          dθ  ∂θ
By the definition of µ∗ , we have that Rµ (x, µ∗ (θ; x), θ ) = 0. From our quadratic example,
we know that µ∗ (θ, x) = (U + x + θ)/2. Therefore,
                                                                                                   Ã                !
                      ∗                               U +x−θ              ∗
       Rx (x, µ (θ; x), θ ) = −[U + x − µ (θ; x)] = −
                                                         2
and ∂µ∗ (θ, x)/∂x = 1/2 , ∂µ∗ (θ∗ , x)/∂θ∗ = 1/2, Rθµ (x, µ, θ) = 1, and Rθx (x, µ, θ) = 0.
Hence, our derivatives come down to
                                                                  Ã              !Z
       dx     1 Z θ∗        dx   1                                     dx                    θ̄
          ∗ =        p(θ) dθ ∗ +                                            +1                    p(θ) dθ
       dθ     2 θ           dθ   2                                     dθ ∗              θ∗
                                                      hR                             i
                                                         θ̄
or dx/dθ∗ = 1 − P (θ∗ ). Also, d                          θ       U (θ)p(θ) dθ /dθ∗ equals
                                                         Z                                          Ã               !Z
                          dx   1                                  θ∗                    1 dx     1                       θ̄
                          ∗
       Rx (x, µ (θ; x), θ) ∗ +                                         [1 − P (θ)] dθ +      ∗ +                              [1 − P (θ)] dθ = 0.
                          dθ   2                              θ                         2 dθ     2                      θ∗

This can be simplified to
                               "                                                                            #
                          ∗            ∗ 1 Z θ̄                  1 Z θ̄
       [1 − P (θ )] Rx(x, µ (θ; x), θ) +        [1 − P (θ)] dθ +        [1 − P (θ)] dθ = 0.
                                         2 θ                     2 θ∗
Note that integration by parts gives that
       Z    θ̄                         Z       θ̄                                    Z       θ̄                                 Z    θ̄
                 [1 − P (θ)] dθ =                   d{θ[1 − P (θ)]} −                             θd[1 − P (θ)] = −θ +                    θp(θ) dθ.
        θ                                  θ                                             θ                                       θ

Hence, our first-order condition can be written as
                                                     Z   θ̄
       −[1 − P (θ∗ )] (U + x) +                               [1 − P (θ)] dθ = 0
                                                      θ∗

with x given as above. This is equation (56). Q.E.D.

                                                                               42
     µ                                         µ(θ; a ) = µ(θ)
                                               for θ > θ2


                                                                 µ * (θ, x)


                          ~
                          µ
               µ(θ; a )
                                   µ(θ)




            µ(θ; a ) = µ(θ)
            for θ < θ1

θ                             θ1          θ2            θ           θ

    Figure 1: A Welfare-Improving Variation in µ
                  w
                                                       w(θ, a )        w(θ)
  w



w −ε


                                             w(θ)   ∆(a)
                                                           {      w(θ, a )

                      w(θ; a ) = w(θ)
                      for θ < θ1




      θ                                 θ1                   θ2    θ          θ

          Figure 2: The Continuation Value in the Up Variation
                  w                                          w(θ; a ) = w(θ)
                                                 w(θ, a )    for θ > θ1
  w


w −ε


                                      }   ∆(a)   w(θ)




                          w(θ, a )




      θ                              θ1                 θ2       θ        θ

          Figure 3: The Continuation Value in the Down Variation
µ
                                        µ * (θ, x)

                                        µ * (θ, x )
           µ(θ)

       µ (θ)


                  θ 1   θ1   θ2        θ θ



    Figure 4: A Welfare-ImprovingVariation
π




πH                                             µ H* (θ) for U = U H



πL                                             µ L* (θ) for U = U L

     θ L*                    θ H*                                     θ




     Figure 5: Optimal Discretion with Differing Severity
          of Time Inconsistency Problems (UH > UL)
       µ(θ)
         µ2                                         µ*(θ;x)




         µ1
                    θ1             θ        θ2          θ
                    *



                                        w2
       w(θ)
         w




                              w1

                    θ1             θ        θ2          θ
                    *
Figure 6: Ruling Out Discontinuous Continuation Values

Figure 6a: When w1 < w2 ≤ w
µ(θ)
                                     µ*(θ;x)
 µ2




  µ1
          θ1          θ       θ2       θ
          *



                 w1
w(θ)
 w




                w2

          θ1          θ       θ2      θ
          *
       Figure 6b: When w ≥ w1 > w2
                        p(θ)




θ                              θ1                        θ   θ
                      The Density

                        P(θ)




θ                              θ1                        θ θ
             The Corresponding Distribution


                   1 − P (θ)
                     p (θ)




θ                              θ1                        θ θ
                The Corresponding Hazard

    Figure 7: A Distribution With a Nonmonotone Hazard
