                            NBER WORKING PAPER SERIES




      ADDRESSING CROSS-NATIONAL GENERALIZABILITY IN EDUCATIONAL
                         IMPACT EVALUATION

                                     Eric A. Hanushek

                                    Working Paper 25460
                            http://www.nber.org/papers/w25460


                    NATIONAL BUREAU OF ECONOMIC RESEARCH
                             1050 Massachusetts Avenue
                               Cambridge, MA 02138
                                   January 2019




Laura Talpey and participants at the Conference on Rigorous Impact Evaluation in Europe
provided many helpful comments and suggestions. The views expressed herein are those of the
author and do not necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2019 by Eric A. Hanushek. All rights reserved. Short sections of text, not to exceed two
paragraphs, may be quoted without explicit permission provided that full credit, including ©
notice, is given to the source.
Addressing Cross-National Generalizability in Educational Impact Evaluation
Eric A. Hanushek
NBER Working Paper No. 25460
January 2019
JEL No. H4,I2,J00

                                         ABSTRACT

The evaluation of educational programs has accelerated dramatically in the past quarter century.
While such evaluations were once almost exclusively conducted in the U.S., they have broadened
dramatically across many countries of the world. At the same time, the methodology has
improved, strengthening considerably the internal validity of various studies. We must now
consider what conclusions can be drawn from the growing wealth of international results. In
particular, available cross-national studies on a variety of topics suggest using caution when
generalizing results, because the results vary systematically with a number of institutional
characteristics of the different countries that are not explicitly considered in within-country
analyses.


Eric A. Hanushek
Hoover Institution
Stanford University
Stanford, CA 94305-6010
and NBER
hanushek@stanford.edu
          Countries around the world exhibit widely different educational outcomes, and these
differences lead directly to the skills of their future labor forces and have clear implications for future
economic performance. Understanding what drives these differences could have large impacts on
policies and profoundly improve future economic well-being. Yet, most educational policy discussions
and related policy evaluations take place within individual countries and have unclear implications for
countries other than the one that generated the evaluation. Existing evidence from cross-national
studies of education suggest significant and systematic heterogeneity of impact responses according to
aggregate institutional differences.
          There has been an international seminar on the economics of education in Munich for over a
decade, and the research reported there illustrates the explosion of work from people around the globe
attempting to evaluate educational practices in different countries. 2 What is the effect of the starting
age of schools? What is the effect of different class sizes? How do different forms of school
accountability affect achievement? What are the implications of greater school choice for overall
student outcomes?
          As the results come in from these studies, one must ponder their generalizability. How much of
what we know about starting age in the Netherlands should someone take home to the U.S.? Does class
size reduction in India mean the same as it does in Germany? Does the growth of randomized control
trials (RCTs) in developing countries provide us with relevant conclusions for policy in other developing
countries, let alone in developed countries?
          Most current policy discussions and related policy evaluations take place within countries, and
thus within the overall institutional structure of that country. The macro-institutions - institutions that
apply to the entire country - cannot themselves be easily addressed and yet may interact with the way
specific programs impact learning. For example, a single application system for choice of schools may
have a very different impact on schooling patterns in the Netherlands (where there is a long history of
free choice among alternative school providers) than in the U.S. (where there is more recent and more
limited choice through charter schools). Or, allowing for more local decision making in schools may have
quite a different impact in the U.S., where there has been a national school accountability system under
No Child Left Behind (NCLB), than in a country with no standardized accountability system. A major




2   https://www.cesifo-group.de/ifoHome/research/Network/Areas/Area-EE-Economics-of-Education.html

                                                      1
issue in accumulating this kind of evidence is that the marginal impacts of interventions may differ in
different settings.
        This paper provides some selective evidence to demonstrate that institutional differences across
countries condition policy outcomes. Though it is not entirely clear how such institutional differences
play into policy outcomes, the examples warn us against taking the evaluation results from one country
to another without carefully considering how fundamental differences in the schools and environment
of different countries may impact policy results.
        This line of inquiry is not unique; others have pursued various parts of this. Pritchett and
Sandefur (2013, 2015) have considered how to interpret results from experiments that involve different
environmental factors. Deaton and Cartwright (2017) have voiced similar concerns in the context of
research into economic development. The contribution here is the provision of specific evidence of how
different macro-institutions interact – in ways that cannot be inferred from the normal evaluation
analysis – with a range of educational policies to give very different outcomes,.



Some Background
        There is growing availability of test information about student performance in many countries
(Bergbauer, Hanushek, and Woessmann (2018)). This testing has been developed and used for a variety
of purposes, but one is to monitor and manage the educational system in each country. The growth of
testing has also led to greater evaluation and research within individual countries, including the rise of
field experiments that assess cognitive skills of students.
        The Programme for International Student Assessment (PISA) and the Trends in International
Mathematics and Science Study (TIMSS) now allow researchers to compare student performance across
countries. 3 These data have been increasingly used not only to study how student achievement affects
national economic and social outcomes, but also to understand the specific factors that might affect
student performance (Hanushek and Woessmann (2011)). These international surveys show not only
what performance levels are possible by students but also how widely student performance varies
across countries. Thus, they also potentially point to policies that might be improved in order to get



3
  The OECD has conducted PISA tests in mathematics, science, and reading every three years since 2000 (OECD
(2016)). The PISA testing is now conducted in over 70 countries. The International Association for the Evaluation
of Educational Achievement (IEA), provider of the current TIMSS, has published assessments in mathematics and
science since the mid-1960s. TIMSS is conducted every four years and covered over 50 countries in 2015 (Mullis,
Martin, Foy, and Hooper (2016)).

                                                        2
higher achievement. Furthermore, they allow us to analyze things that cannot be analyzed within a
single country. Structures like labor market institutions, cultural values, and the enforcement of
property rights are constant within a country, making it is impossible to analyze their effects on behavior
and policies using within-country data. Cross-national observations, on the other hand, provide
indications of how different aggregate factors affect policy outcomes – and implicitly how they affect
the generalizability of policy evaluations that currently exist.
        The use of cross-country performance data also comes at a cost, because it is necessary to deal
analytically with the many ways in which countries might differ and might affect educational outcomes.
This trade-off is of course central to this paper and will be discussed below.

Achievement Differences Matter
        The main focus of this paper is on the interpretation of country-specific evaluation analyses, but
we will begin with a more fundamental issue. Such evaluations frequently use test scores to measure
the immediate impact of a policy. Do test scores reflect an important object of policy? Some recent
discussions of testing, particularly when used for accountability, have essentially argued that
standardized tests do not really matter.
        The most direct way to address this question is to look to how the labor market treats
differences in test scores. This approach has not been very common, in part because of limited data and
in part because the lack of test data has not been viewed as a serious issue. Since the seminal work on
human capital by Jacob Mincer (1970, 1974), there has been a focus on the level of schooling and the
experience of a worker in characterizing differences in human capital. 4 The availability of these
measures, and particularly school enrolment or school attainment, has been ubiquitous and has
provided some optimism that workers can be compared within and across countries using common
census and survey data. In fact, the reliance on years of schooling as a measure of individual skill
differences is so common that the term human capital is almost synonymous with school attainment.
        Particularly in an international context, the ubiquitous reliance on measures of school
attainment is highly suspect. For the direct comparisons to hold, one must believe that a year of
schooling in Brazil has the same learning and skill content as a year in Portugal. Of course, it is just on




4 One on-going discussion surrounding analyses of human capital has focused on whether schools produce greater
skills or simply select people with more skills (Spence (1973) or more recently Caplan (2018)). The selection or
signaling model is more relevant when human capital discussions are centered on years of schooling or school
attainment as opposed to cognitive skills measures where there is ample evidence that schools change outcomes.

                                                       3
this point where the PISA assessments provide direct information. In 2015, the average Brazilian fifteen-
year-old was over one standard deviation behind an average fifteen-year-old in Portugal.
         Differences in levels of performance by themselves might not be too damaging if, for example,
years of schooling was a good index of the cognitive skill differences found in the population.
Unfortunately, as noted this is not the case, yielding significant problems with the common reliance on
years of schooling. Work on educational production functions, starting with Coleman et al. (1966), has
uniformly shown that families and factors outside of the school have a strong influence on individual
achievement and skills (see Hanushek (2002)). Beyond that, focusing on years of schooling ignores any
differences in school quality and severely limits policy discussions.
         As data become more available, it is increasingly clear that focusing on school attainment leads
to significant distortions in the perceived cognitive skills of a population, and that direct measures of
skills found in standardized assessments provide superior information – at least in terms of economic
outcomes. Test scores summarize cognitive skill differences in individuals, regardless of what led to the
scores. Consistent with the now extensive literature on educational production functions (Hanushek
(1979)), they can be viewed as a direct measure of a large component of human capital differences.
         The value of directly measuring cognitive skills can be seen in the economic impacts of
differences in test scores. The OECD’s Programme for International Assessment of Adult Competencies
(PIAAC) ascertains the demographic and labor market experiences of a representative sample of adult
workers along with giving them literacy and numeracy tests. Using data for survey takers from PIAAC,
one can estimate the earnings returns to individual skills. 5 Hanushek, Schwerdt, Wiederhold, and
Woessmann (2015, 2017) provide evidence of strong and statistically significant estimates of the impact
of cognitive skills within each of the 32 countries that participate in PIAAC. On average, individuals with
greater measured cognitive skills earn more throughout their lifetime; across countries, a one standard
deviation higher test score is associated with a 20 percent higher wage over the lifetime. (As discussed
below, these returns vary substantially across countries.) 6
         A second way to recognize the value of standardized assessment measures is to examine how
aggregate test scores for countries help to explain differences in long run growth rates of GDP per


5
  The PIAAC surveyed 5,000 or more adults in 32 countries in either 2012 or 2015. (Data for Indonesia, an
additional sampled country, included just Jakarta and are not used). See http://www.oecd.org/skills/piaac/.
6 One standard questions is why people with more education earn more? The simplest answer is not that they are

more dexterous or that they can work faster on the production line. It is that they are better able to adapt to
changes. One of the first real tests of that hypothesis comes from comparing the rates of return to cognitive skills
with the annual growth rate in GDP. Indeed, the faster the growth rate in GDP, where presumably jobs are
changing more rapidly, the higher the return to skills (Hanushek, Schwerdt, Wiederhold, and Woessmann (2017)).

                                                         4
capita. Over the past three decades, economists have intensively examined how to explain country
differences in growth rates. Much of this – similar to the analysis of individual earnings – has focused on
how a country’s human capital measured by school attainment affects growth (Pritchett (2006),
Hanushek and Woessmann (2008)). This focus leads to significant problems (see, for example, Levine
and Renelt (1992) or Levine and Zervos (1993))
        However, there is strong evidence that achievement scores, rather than school attainment,
better explain differences in long run growth of GDP across countries. Specifically, three-quarters of the
variation in growth rates across 50 countries between 1960 and 2000 can be explained by just the initial
GDP levels and the skills of the population measured by international assessment scores (Hanushek and
Kimko (2000), Hanushek and Woessmann (2015a)). 7 In contrast, years of schooling by itself can explain
just one-quarter of the variation in long run growth rates and is insignificant once learning, as measured
by these test scores, is included in the analysis.
        Moreover, the relationship between growth rates and cognitive skills is strong enough that,
according to historical patterns, improvements in the schools of a country have had huge effects on
future economic well-being (Hanushek and Woessmann (2015b)). For example, the difference in
international test scores between Canada and U.S. would, according to historical data, yield an increase
in U.S. long term growth rate of one percent per year. In short, there is strong justification for focusing
on student test scores, which in the aggregate are labelled knowledge capital, in evaluating educational
policies.



“Case Studies” in Cross-Country Institutional Features
        With this background, we can now turn to the challenges of generalizing from various country
evaluation studies that typically look at policy impacts on test scores. 8 It will be, of course, difficult to
arrive at general conclusions about when, where, and to what extent generalizations can be made
across the variety of policy evaluations found in different countries. On the other hand, some insights




7
  Initial GDP levels are included to reflect the fact that countries starting behind can grow fast by copying what
countries near the technological frontier do, while technologically leading countries have to invent new production
processes and new technologies. There is, of course, debate about whether the impact of differences in cognitive
skills are causally related to cross-sectional growth rates. The analysis in Hanushek and Woessmann (2012)
provides strong evidence for a causal interpretation, but open questions remain.
8 For the reasons just discussed, evaluation studies that focus on years of schooling, school completion rates, and

the like have obvious limitations when one considers generalizing across countries, and such studies are not
considered here.

                                                        5
can be gained by looking at evidence on cross-country achievement differences and how they are
affected by macro-institutional factors.
           The thought experiment is that we have a study with high internal validity, say from a well-
structured RCT or a particularly compelling natural experiment, and we want to use the conclusions to
inform policy in a different country. This issue has become increasingly relevant because field
experiments tend to be quite expensive, particularly when done in high income countries. Thus, for a
variety of reasons, relatively more experiments have been conducted in developing countries where
they are easier and cheaper to run.
           This paper considers a set of “case studies” that assess how macro-institutional factors interact
with specific aspects of country school systems in affecting student outcomes. The macro-institutional
factors we examine through case studies are: use of testing and accountability; policies of local school
autonomy in decision making; varying country labor markets for skilled workers; overall country
differences in the selection of teachers; emphasis on vocational versus general education; and early
tracking in schools. Our intention is not to provide the details behind each of the case studies. Instead,
we aim to summarize their results and discuss how macro-institutional factors relate to marginal policy
impacts, and thus enter into how generalizable specific evaluation efforts actually are.


Case Study 1: Testing and Accountability9
           The previous discussion described the significance of test scores in explaining economic
outcomes, but testing itself is the subject of policy discussions and of research. Specifically, the extent
and purpose of student testing have become areas of heated debate in many countries, both developed
and developing. Some express the view that high-stakes tests – meaning assessments that enter into
reward and incentive systems for some individuals – are inappropriate (Koretz (2017)). Others argue
that testing and accountability systems are essential for the improvement of educational outcomes
(World Bank (2018)) and, by extension, for the improvement of economic outcomes (Hanushek and
Woessmann (2015a); Hanushek, Schwerdt, Wiederhold, and Woessmann (2015)).
           Most applications of student assessments used for accountability purposes have not been
adequately evaluated, largely because they have been introduced in ways that make identification of
impacts difficult. National testing programs often lack suitable comparison groups, creating fundamental




9   The underlying analysis for this section can be found in Bergbauer, Hanushek, and Woessmann (2018).

                                                         6
analytical issues. A key question is, when can student assessments be used in ways that promote higher
achievement?
         The six waves of the PISA assessments between 2000 and 2015 permit country-level panel
estimation that relies on within-country, over-time analysis of country changes in assessment practices.
Bergbauer, Hanushek, and Woessmann (2018) combine data across 59 countries to estimate how
varying testing situations and applications affect student outcomes. The results indicate that
accountability systems that use standardized tests to compare outcomes across schools and students
produce greater student outcomes (as measured by PISA scores) than those that simply report the
results of standardized tests. They also produce greater achievement results than systems relying on
localized or subjective information that cannot be readily compared across schools and classrooms, and
that have little or negative impact on student achievement. 10
         Moreover, rewards for better outcomes directed both at schools and at students result in
greater student learning (i.e., higher national PISA scores). General comparisons of standardized testing
at the school level appear to lead to somewhat stronger results than direct rewards to students that
come through sorting across educational opportunities and subsequent careers. However, rewards to
both are significant.
         Most interestingly from an international perspective is the finding that testing and
accountability systems are most important for school systems that are performing poorly. It appears
that school systems with strong testing results know more about how to boost student performance and
are less in need of strong accountability systems. Figure 1 shows confidence intervals for the estimated
impact of the different kinds of accountability systems as a function of the initial levels of student
performance. This figure indicates that standardized external comparisons have declining impacts
according to the overall level of country achievement, and that the impacts are cease being significantly
different from zero at about 500 points, the mean student score on PISA for the OECD countries.
         Comparative testing appears to create incentives for better performance and allows rewarding
those who are contributing most to educational improvement efforts. It may thus interact directly with
other educational policies. The interaction of testing with the overall functioning of the school system
suggests that any interactions of educational policies with testing and accountability policies may also
differ markedly with the macro-institutional structure of the schools. Yet, in terms of assessing policy

10 The analysis in Bergbauer, Hanushek, and Woessmann (2018) uses country-level panel analysis, extensive micro-
level controls, and direct analysis of alternative country policies to separate the causal impact of testing regimes as
opposed to other country differences. The estimates, which rely upon country changes in testing policies over
time, thus have a plausible causal interpretation

                                                          7
evaluations across countries, any such interactions with accountability policies are generally not
identified in the policy evaluations.

Case Study 2: Local Autonomy in Decision Making 11
           Local autonomy has been a policy discussed intensively in both developing and developed
countries. Interestingly, while many countries have decentralized processes such as the hiring of
teachers or the choosing of curriculum over time, others have actually made decision-making more
centralized.
           Autonomy in school decision making may be conducive to student achievement in school
systems with strong surrounding structures that ensure high common standards. On the other hand,
school-based decision-making may in fact hurt student achievement in low-performing systems that lack
basic standards and local capacity. Existing micro-studies of autonomy in decision making include a
variety of randomized studies, but there still exists considerable variation in results. Reviews by Patrinos
(2011) and Galiani and Perez-Truglia (2014) of decentralized decision making in developing countries
suggest that methodology of the underlying studies is important: A clear focus on identification (such as
the use of random control trials or various instrumental-variable applications), while currently limited,
influences the results of program evaluations but cannot explain all of the different results. The review
by Arcia, Macdonald, Patrinos, and Porta (2011) concludes that “the empirical evidence from Latin
America shows very few cases in which SBM [school based management] has made a significant
difference in learning outcomes (Patrinos (2011)), while in Europe there is substantial evidence showing
a positive impact of school autonomy on learning (Eurydice (2007)).” Cross-sectional evidence from
international achievement tests concerning school autonomy has similarly been quite mixed (Hanushek
and Woessmann (2011)), but these studies may also be particularly plagued by identification issues.
           In the first use of the international PISA tests as a country panel, Hanushek, Link, and
Woessmann (2013) combine different waves of the international assessments by pooling the individual
data of over one million students in 42 countries in the four PISA waves from 2000 to 2009. To avoid
bias from unobserved cross-country differences such as those arising from culture and other
government institutions, they incorporate country fixed effects in their estimation using the individual
level data. 12 They exploit the fact that many countries have reformed their school systems to become
more or less autonomous over time.



11   The underlying analysis for this section can be found in Hanushek, Link, and Woessmann (2013).
12   The analytical approach in this study motivated the previous analysis of the impacts of testing.

                                                           8
        They find that school autonomy has a significant effect on student achievement, but that this
effect varies systematically with the level of economic and educational development: The effect of
greater school autonomy on student achievement is strongly positive in developed and high-performing
countries, but strongly negative in developing and low-performing countries. Countries with otherwise
strong institutions gain considerably from decentralized decision-making in their schools, while
countries that lack such a strong existing structure may actually be hurt by decentralizing decision-
making. 13
        Hanushek, Link, and Woessmann (2013) also find a significant positive interaction between
changes in school autonomy and (initial) external exit exams – that is, introducing autonomy is more
beneficial in school systems that have accountability through external exams. The overall results across
countries is shown in Figure 2. Impacts of greater autonomy, measured on the vertical axis, rise with the
level of economic development and are shifted higher with accountability.
        The heterogeneity of institutional effects again show that understanding the institutional
structures in a country’s school system is important for assessing the generalizability of the more
common within-country evaluations.


Case Study 3: The Market for Skilled Labor 14
        Teachers and administrators are often the ones most directly involved in carrying out an
educational intervention, but many other “human inputs” enter into the process as well. Because most
educational interventions require the work of real people, it is not difficult to believe that the success of
an intervention depends somewhat on the quality of the people involved in implementing it. While any
such people differences might be adequately accounted for through randomization within a specific
evaluation, differences in levels across countries in general are not an analytic factor that can be directly
considered.
        It is generally difficult to compare the quality of workers internationally, but the PIAAC data
permit analyzing how labor markets vary around the sample of 31 countries described above. The
easiest summary is to estimate a “modified Mincer Model” as described in the prior section, where skills




13 Note that this interaction of institutional development and estimated impact of autonomy is entirely consistent
with the empirical finding of differences between Latin America and Europe described above.
14 The underlying analysis for this section can be found in Hanushek, Schwerdt, Wiederhold, and Woessmann

(2015, 2017).

                                                        9
are measured by the PIAAC literacy and numeracy assessments. From this, one can look at how the
rewards to worker skill vary across countries and what factors could be underlying this variation.
        Figure 3 portrays the range of returns to math skills across countries. 15 The most obvious result
is that these returns vary widely – from 11 percent higher wages for one standard deviation higher math
scores in Greece to 45 percent in Singapore. The U.S. has returns of 25 percent for one standard
deviation higher math scores (Hanushek, Schwerdt, Wiederhold, and Woessmann (2017)).
        The more subtle facet of this figure is that the returns vary systematically with differences in the
structure of the labor force and the characteristics of the economy. Though attaching a causal
interpretation is not possible, there is a distinct relationship between returns to skills and significant
country differences in union density, employment protection, and the portion of the population in the
public sector (Hanushek, Schwerdt, Wiederhold, and Woessmann (2015)).
        Given that labor markets operate in such very different ways across countries, these different
rewards for skills and the subsequent impact on workers can clearly lead to significant variations across
countries in impacts of a given policy with a substantial people element.


Case Study 4: Differences in Teacher Cognitive Skills 16
        From the PIAAC sample, we can identify all individuals employed as teachers and then
compare the test scores of teachers across countries. The cross-country differences in measured
teacher skills are very large. Figure 4 provides a comparison of the numeracy skills of the
college educated population in each country. The bars represent the interquartile range of test
scores for college graduates. The vertical line in each bar shows where the median teacher falls
in the cognitive skill distribution of college graduates.
        The figure makes clear that two things are important in determining the skills of teachers
in any country. One is the quality of the pool of potential teachers. If a country has a better pool
of college graduates (i.e., the bar for the interquartile range is farther to the right), it is likely to
have teachers with greater numeracy skills. Second is where teachers are drawn out of that pool.
Finland has roughly the best pool, but it also draws the median teacher from the 62nd percentile
of the distribution of college graduates. Farther down the figure is the U.S.: it has a poorer pool

15
   The returns to skills are the coefficient estimates on numeracy score (standardized to std. dev. Equal 1 within
each country) in a regression of log gross hourly wage on numeracy, gender, and a quadratic polynomial in age for
the sample of full-time employees aged 35–54. Hollow bars in the figure indicate first-round PIAAC countries, black
bars indicate second-round PIAAC countries.
16 The underlying analysis for this section can be found in Hanushek, Piopiunik, and Wiederhold (forthcoming).



                                                        10
of college graduates than Finland, and it also draws teachers from the 47th percentile of the
college graduates.
         If one relates the test scores of teachers to student achievement scores, it becomes
apparent that smarter teachers yield smarter kids. 17 Teacher cognitive skills do not determine all
of the differences in teacher effectiveness, but they are significant – explaining a substantial
portion of the variation in average PISA scores across countries.
         Importantly, the pattern of teacher selection and of teacher cognitive skills varies across
time and across macro-institutional policy regimes. We can identify two things that determine
the skill differences of teachers across countries and over time. First, if women have more
opportunities outside of teaching, the quality of teachers measured by test scores is lower.
Historically in the U.S., women were concentrated in teaching and nursing, but this has
obviously changed over time and has impacted the supply of teachers (in terms of cognitive
skills). The relationship between the skills of teachers and the employment opportunities of
women holds over time and across countries.
         The second determining factor of teacher quality is the premium paid for being a teacher
in a given country. Using PIAAC data it is possible to estimate a simple earnings function based
on cognitive skills, experience, and gender (similar to that done in the previous section).
Holding these attributes constant, the estimated earnings function indicates the earnings of an
average teacher compared to a similar worker in other occupations. As shown in Figure 5,
teachers in the U.S. earn 22% less than similar workers in other professions.
         The teacher wage premium essentially predicts where the median teacher will fall in the
distribution of cognitive skills in Figure 4. Furthermore, these wage premiums carry into the
achievement of students.
         Thus, another way that evaluations of educational programs could differ across countries
might be related to varying teacher quality. This concern is actually a specialized issue about
how labor markets differ across countries as identified in Case Study 3. The potential interaction
of policy impacts and teacher quality enters into the potential transfer of policy results across
countries but cannot be readily included in the individual studies themselves.



17 The analysis pursues a variety of approaches designed to support a causal interpretation of the country
differences in teacher cognitive skills. These include while holding constant individual student fixed effects and
analyzing a range of specifications and of placebo tests.

                                                         11
Case Study 5: Vocational versus General Education 18
        A major organizational decision that is mostly made at the national level is the balance between
general education and more vocationally oriented education. These discussions intensified after the
2008 recession when youth unemployment skyrocketed in many countries, leading to discussions about
whether education more directed to the demands of industry would help smooth the school-to-work
transition. The fact that Germany, a country with some of the most extensive vocational schooling,
weathered the recession better than most European countries added fuel to a push toward more
vocational schools.
        Countries have actually made very different choices about the extent of vocational education.
Germany, Switzerland, Austria, and Denmark, for example, have developed extensive apprenticeship
programs where students split their time between formal schooling and work/training at firms. On the
other hand, at least until recently the United States has essentially dismantled its vocational education
system, largely on the argument that the vocational skills would become quickly obsolete with
technological change. But, like many other countries, the U.S. began reconsidering vocational training
when the Trump administration proposed re-igniting the vocational system as a way of giving
employable skills to youth that had done poorly in the traditional schools. 19
        Analysis of the impacts of vocational education have mainly been aimed at understanding its
impact on job entry of youth. Such analysis has been difficult, however, because students entering into
vocational programs typically look different from those staying in general education. This fact makes
development of an adequate control group difficult.
        Hanushek, Schwerdt, Woessmann, and Zhang (2017) address the comparison issue in the
context of broadening the focus to consider life-cycle employment effects of vocational training. A
central concern with vocational education is that those trained in very specific skills may not be able to
adapt to changing demands for skills as production technologies changes. Data from the International
Adult Literacy Survey (IALS) – an early precursor of the PIACC sample – provide detailed information
about skills and labor market attributes of representative samples of adult workers in 11 countries with
varying intensity of vocational training. They compare the employment patterns of workers with
different types of education. To address the concern of selection into different types of education, they


18The underlying analysis for this section can be found in Hanushek, Schwerdt, Woessmann, and Zhang (2017).
19
   See, for example, “Remarks by President Trump in Meeting with Cabinet Members,” July 18, 2018
(https://www.whitehouse.gov/briefings-statements/remarks-president-trump-meeting-cabinet-members/),
accessed January 7, 2018.


                                                      12
employ a difference-in-differences framework, comparing labor-market outcomes across different ages
for people with general and vocational education. Under the assumption that conditional selectivity
into education types does not vary over time, this approach allows them to identify how relative labor-
market outcomes of different education types vary with age cohorts.
        The pattern of employment for the most vocationally intensive countries (Germany,
Switzerland, and Denmark in their data set) shows an initial employment advantage to vocational
training but one that declines over the life-cycle and that tends to reverse at ages in the late 40’s (see
Figure 6). This results is confirmed with the PIAAC data by Hampf and Woessmann (2017).
        The important aspect for this discussion is that the life-cycle employment patterns differ
dramatically across countries and that these patterns follow the intensity of vocational training.
Countries with less intensive vocational education see less differentiation in the life-cycle employment
patterns. In contrast to apprenticeship countries, the U.S. with limited vocational education sees little
life-cycle employment difference based on type of education. Thus, analysis of employment patterns
within an individual country may not generalize to countries that have inherently different structures to
their vocational training. But the impact of these aggregate institutional differences on the labor market
results cannot be ascertained within evaluations conducted in an individual country.

Case Study 6: Early Tracking 20
        Countries also vary in the extent to which students are tracked into different school types by
ability. No country has differing-ability schools in the early grades of primary school, but some countries
such as Austria and Germany track students into different-ability schools as early as age 10. Many other
countries maintain a comprehensive school system (although perhaps with some streaming within
schools) through the end of high school. A common concern is that early tracking, perhaps because of
the relative increase of parental influences or because of peer effects, may increase inequality as lower-
achieving groups are tracked into lower-ability schools. But similar to the other case studies, this
phenomenon cannot be readily analyzed within any given country when the structure of schools is set
nationally.
        Hanushek and Woessmann (2006) employ an identification strategy that compares achievement
changes from primary to later schooling across tracked and untracked countries. Different country-level
assessments provide information about inequality in scores at different grade levels. 21 Using a

20 The underlying analysis for this section can be found in Hanushek and Woessmann (2006).
21 Available tests for varying years include data for several pairs of achievement tests of the Progress in
International Reading Literacy Study (PIRLS), the Trends in International Mathematics and Science Study (TIMSS),
and the PISA study. PIRLS is an assessment of reading skills conducted by the IEA.

                                                       13
differences-in-differences model, they find that early tracking significantly increases the inequality in
countries’ achievement outcomes.
        Figure 7 shows how the standard deviation of scores changes between primary and secondary
schools across countries that participated in the 2003 PISA and PIRLS tests. The largest increases in
standard deviations are found in Germany, Greece, the Czech Republic, and Italy – all countries with
early tracking. The largest decreases in standard deviations are found in Turkey, New Zealand, Canada,
and the United States – all countries with no early tracking. Hanushek and Woessmann (2006) do not
find a consistent effect of early tracking on the level of achievement. Interestingly, simple cross-
sectional estimation with its attendant concerns about missing variable bias does not indicate the
association of tracking with educational inequality found in the difference-in-differences analysis,
showing the importance of careful attention to identification issues.
        Building on these findings, Ruhose and Schwerdt (2016) find that early tracking negatively
affects migrant students of the first generation as well as those second-generation migrant students
who do not speak the host-country language at home.
        Again, because the amount of tracking is largely a national educational decision, schools (and
policies) within countries are conditioned by these structural factors. The differences in student
inequality is conditioned by underlying (but unmeasured) institutional features.

Some Implications
        We can now return to the original thought experiment. We have a well-conceived evaluation of
a school policy that has high internal validity. We want to consider whether this work can be readily
generalized to a similar policy issue in a different country.
        The previous case studies have a common theme. If we look across countries at how national
institutional factors enter into policy decisions, we quite consistently see heterogeneity in effects. This
finding sends up a series of warning signals about how small-scale evaluations can be generalized to
other settings.
        This discussion pulls together a number of strands of literature that directly relate to
educational policy evaluations. The underlying theme is that a wide range of macro-institutional factors
are likely to affect the micro-level evaluations, but these institutions cannot readily be considered in the
micro-level evaluations.
        It might be tempting to think of the world as being linear and additive such that the macro-
institutions do not affect the marginal policy choices being evaluated at the micro-level. If so, it might
be possible to transport the lessons about marginal policy effects to other environments.

                                                      14
        But the kinds of macro-institutions considered here appear to go deeper. Because the
institutions condition the impact of, say, salary policies that enter into personnel inputs in a wide range
of policies, it is not obvious that they can be ignored. Policies whose effects interact with the level of
economic development or the initial quality of the school system as a whole have marginal effects that
are both more complicated than would be found in any single environment and that are very difficult to
analyse or understand within a given environment.
        This suggests that learning about policy choices may be more expensive than previously
thought. While careful, well-constructed experiments may yield very powerful findings within a given
institutional structure, the findings may not travel well to other institutional structures. Moreover, to
the extent that the institutional structure is constant across all of the subjects of the policy evaluation, it
is not obvious how one guards against possible interactions with the marginal policy effects.




                                                      15
References

Arcia, Gustavo, Kevin Macdonald, Harry A. Patrinos, and Emilio Porta. 2011. School autonomy and
         accountability. System Assessment and Benchmarking for Education Results. Washington, DC:
         World Bank.
Bergbauer, Annika B., Eric A. Hanushek, and Ludger Woessmann. 2018. "Testing." NBER Working Paper
         24836. Cambridge, MA: National Bureau of Economic Research (July).
Caplan, Bryan. 2018. The case against education: Why the education system is a waste of time and
         money. Princeton, NJ: Princeton University Press.
Coleman, James S., Ernest Q. Campbell, Carol J. Hobson, James McPartland, Alexander M. Mood,
         Frederic D. Weinfeld, and Robert L. York. 1966. Equality of educational opportunity. Washington,
         D.C.: U.S. Government Printing Office.
Deaton, Angus, and Nancy Cartwright. 2017. "Understanding and Misunderstanding Randomized
         Controlled Trials." NBER Working Paper No. 22595. Cambridge, MA: National Bureau of
         Economic Research (October).
Eurydice. 2007. School autonomy in Europe: Policies and measures. Brussels: Eurydice (December).
Galiani, Sebastian, and Ricardo Perez-Truglia. 2014. "School management in developing countries." In
         Education Policy in Developing Countries, edited by Paul Glewwe. Chicago: University of Chicago
         Press: 193-241.
Hampf, Franziska, and Ludger Woessmann. 2017. "Vocational vs. general education and employment
         over the life cycle: New evidence from PIAAC." CESifo Economic Studies 63, no. 3: 255-269.
Hanushek, Eric A. 1979. "Conceptual and empirical issues in the estimation of educational production
         functions." Journal of Human Resources 14, no. 3 (Summer): 351-388.
Hanushek, Eric A. 2002. "Publicly provided education." In Handbook of Public Economics, Vol. 4, edited
         by Alan J. Auerbach and Martin Feldstein. Amsterdam: North Holland: 2045-2141.
Hanushek, Eric A., and Dennis D. Kimko. 2000. "Schooling, labor force quality, and the growth of
         nations." American Economic Review 90, no. 5 (December): 1184-1208.
Hanushek, Eric A., Susanne Link, and Ludger Woessmann. 2013. "Does school autonomy make sense
         everywhere? Panel estimates from PISA." Journal of Development Economics 104: 212-232.
Hanushek, Eric A., Marc Piopiunik, and Simon Wiederhold. forthcoming. "The value of smarter teachers:
         International evidence on teacher cognitive skills and student performance." Journal of Human
         Resources.
Hanushek, Eric A., Guido Schwerdt, Simon Wiederhold, and Ludger Woessmann. 2015. "Returns to skills
         around the world: Evidence from PIAAC." European Economic Review 73: 103-130.
Hanushek, Eric A., Guido Schwerdt, Simon Wiederhold, and Ludger Woessmann. 2017. "Coping with
         change: International differences in the returns to skills." Economic Letters 153(April): 15-19.
Hanushek, Eric A., Guido Schwerdt, Ludger Woessmann, and Lei Zhang. 2017. "General education,
         vocational education, and labor-market outcomes over the life-cycle." Journal of Human
         Resources 52, no. 1: 48-87.
Hanushek, Eric A., and Ludger Woessmann. 2006. "Does educational tracking affect performance and
         inequality? Differences-in-differences evidence across countries." Economic Journal 116, no. 510
         (March): C63-C76.
Hanushek, Eric A., and Ludger Woessmann. 2008. "The role of cognitive skills in economic
         development." Journal of Economic Literature 46, no. 3: 607-668.
Hanushek, Eric A., and Ludger Woessmann. 2011. "The economics of international differences in
         educational achievement." In Handbook of the Economics of Education, Vol. 3, edited by Eric A.
         Hanushek, Stephen Machin, and Ludger Woessmann. Amsterdam: North Holland: 89-200.


                                                   16
Hanushek, Eric A., and Ludger Woessmann. 2012. "Do better schools lead to more growth? Cognitive
         skills, economic outcomes, and causation." Journal of Economic Growth 17, no. 4: 267-321.
Hanushek, Eric A., and Ludger Woessmann. 2015a. The knowledge capital of nations: Education and the
         economics of growth. Cambridge, MA: MIT Press.
Hanushek, Eric A., and Ludger Woessmann. 2015b. Universal basic skills: What countries stand to gain.
         Paris: Organisation for Economic Co-operation and Development.
Koretz, Daniel. 2017. The testing charade: Pretending to make schools better. Chicago: University of
         Chicago Press.
Levine, Ross, and David Renelt. 1992. "A sensitivity analysis of cross-country growth regressions."
         American Economic Review 82, no. 4 (September): 942-963.
Levine, Ross, and Sara J. Zervos. 1993. "What we have learned about policy and growth from cross-
         country regressions." American Economic Review 83, no. 2 (May): 426-430.
Mincer, Jacob. 1970. "The distribution of labor incomes: a survey with special reference to the human
         capital approach." Journal of Economic Literature 8, no. 1 (March): 1-26.
Mincer, Jacob. 1974. Schooling, experience, and earnings. New York: NBER.
Mullis, Ina V. S., Michael O. Martin, Pierre Foy, and Martin Hooper. 2016. TIMSS 2015 International
         Results in Mathematics. Boston: Boston College.
OECD. 2016. PISA 2015 results: Policies and practices for successful schools. Vol. Volume II. Paris:
         Organisation for Economic Co-operation and Development.
Patrinos, Harry A. 2011. "School-Based Management." In Making schools work: New evidence on
         accountability reforms, edited by Barbara Bruns, Deon Filmer, and Harry A. Patrinos.
         Washington, D.C. : The World Bank: 87-140.
Pritchett, Lant. 2006. "Does learning to add up add up? The returns to schooling in aggregate data." In
         Handbook of the Economics of Education, edited by Eric A. Hanushek and Finis Welch.
         Amsterdam: North Holland: 635-695.
Pritchett, Lant, and Justin Sandefur. 2013. "Context matters for size: Why external validity claims and
         development practice don’t mix." Journal of Globalization and Development 4, no. 2
         (December): 161-197.
Pritchett, Lant, and Justin Sandefur. 2015. "Learning from Experiments When Context Matters."
         American Economic Review 105, no. 5: 471-75.
Ruhose, Jens, and Guido Schwerdt. 2016. "Does early educational tracking increase migrant-native
         achievement gaps? Differences-in-differences evidence across countries." Economics of
         Education Review 52: 134-154.
Spence, A. Michael. 1973. "Job market signalling." Quarterly Journal of Economics 87, no. 3 (August):
         355-374.
World Bank. 2018. World Development Report 2018: Learning to realize education's promise.
         Washington, DC: World Bank.




                                                  17
Figure 1: Effect of student assessments on math performance by initial achievement levels




                Standardized external comparison                                                      Standardized monitoring




                            Internal testing                                                        Internal teacher monitoring
Notes: Average marginal effects of student assessments on PISA math score by initial country achievement, with 95 percent confidence intervals.
Source: Bergbauer, Hanushek, and Woessmann (2018)


                                                                             18
Figure 2: Effect of autonomy reforms on student achievement by level of development
 Effect of autonomy on PISA test score




                                                                                                                                                   Norway
                                                                                                                                                  Japan
  80




                                                                                               United Kingdom

                                                                                                                Sweden
  60




                                                                        Australia
  40




                                                                                                                                  United States
                                                                                      Canada
                            With central exit exams




                                                                                    Germany
  20


   0
       0                  5,000     10,000           15,000   20,000                     25,000                          30,000   35,000      40,000
             Thailand
           Indonesia




                                                                                                                                      GDP per capita
 -20
                                                              Italy
                                                    Spain




 -40
                                         Portugal




                                                                      Without central exit exams
 -60
                         Mexico
                         Chile
                        Brazil




 -80

Notes: Estimated effect of academic-content autonomy (scaled 0-1) on PISA math test score (scaled with standard
deviation 100) depending on initial GDP per capita (in 2000) and on the existence of central exit exams, estimated
in a panel model of PISA tests 2000-2009. Example countries illustrate initial level of GDP per capita. Own
depiction based on Hanushek, Link, and Woessmann (2013), Table 9.
Source: Hanushek and Woessmann (2015a)




                                                                19
Figure 3. Returns to Cognitive Skills




Notes: Coefficient estimates on numeracy score (standardized to std. dev. 1 within each country) in a regression of
log gross hourly wage on numeracy, gender, and a quadratic polynomial in age, sample of full-time employees
aged 35–54. Regressions weighted by sampling weights. Pooled specification includes country fixed effects and
gives same weight to each country. Hollow bars indicate first-round countries, black bars indicate second-round
countries. aJakarta only.
Source: Hanushek, Schwerdt, Wiederhold, and Woessmann (2017)




                                                        20
Figure 4. Numeracy Scores of Teachers




                                     Finland
                                       Japan
                                  Germany
                                    Belgium
                                    Sweden
                            Czech Republic
                                Netherlands
                                 Singapore
                                     Norway
                                      France
                                      Austria
                                   Australia
                              New Zealand
                                      Ireland
                                   Denmark
                           Slovak Republic
                                   Slovenia
                                    Canada
                            United Kingdom
                                       Korea
                                   Lithuania
                                     Estonia
                              United States
                                        Spain
                                     Greece
                                      Poland
                                          Italy
                         Russian Federation
                                        Israel
                                      Turkey
                                         Chile
                                              200   250               300     350
                                                       Numeracy skills




Note: Gray bars give the 25-75 percentile range of college graduates; Red marker indicates score of the median
teacher.
Source: Hanushek, Piopiunik, and Wiederhold (forthcoming)




                                                       21
Figure 5. Teacher Wage Premiums around the World




            50%

            40%

            30%

            20%

            10%

              0%

           −10%

           −20%




Notes: Estimated higher earnings for teachers given their test scores, experience level, and gender.
Source: Hanushek, Piopiunik, and Wiederhold (forthcoming)




                                                        22
Figure 6. Life-cycle Employment Rates by Education Type for Apprenticeship Countries




                                         Apprenticeship Countries (3)
                1
   Percentage Employed, Male
      .4       .6
                .2      .8




                               20       30              40        50            60
                                                        Age

                                    General Education          Vocational Education




Notes: Smoothed plots of employment rates by age for “apprenticeship” countries (Denmark, Germany,
and Switzerland). Sample includes all males who finished secondary education or the first stage of
tertiary education and are not currently enrolled in school.

Source: Hanushek, Schwerdt, Woessmann, and Zhang (2017)




                                                          23
Figure 7. Early Tracking and Inequality


                PIRLS (Primary school)                                       PISA 2003 (Secondary school)
              New Zealand
                                                        0.8




                      Turkey                            0.6
                                                                                               Germany
             United States

                     Norway                             0.4                                   New Zealand
                                                                                              Greece

                                                                                              Norway
                                                        0.2                                   United States
                                                                                              Italy
                      Iceland
                    Greece                                                                    Iceland
                  Canada                                                                      France
                                                        0.0                                   Sweden
                       Italy                                                                  Czech Rep.
                   France                                                                     Turkey
               Slovak Rep.                                                                    Slovak Rep.
               Germany                                                                        Russian Fed.
                                                                                              Hungary
         Hungary Sweden                                -0.2
            Russian Fed.
             Czech Rep.                                                                       Latvia
                                                                                              Canada
             Hong Kong
                  Latvia                               -0.4
                                                                                              Hong Kong
                                                                                              Netherlands

               Netherlands                             -0.6
                                                              Standard Deviation




Notes: Standard deviations of test scores for countries with early tracking (black with solid lines) and without early
tracking (red with dotted lines). The fourth grade variation on the 2003 Progress in International Reading Literacy
Study (PIRLS) is linked to the eighth grade variation on the 2003 PISA reading assessment.
Source: Hanushek and Woessmann (2006)




                                                         24
