                             NBER WORKING PAPER SERIES




                        AGENDA-SETTER POWER DYNAMICS:
                       LEARNING IN MULTI-ISSUE BARGAINING

                                        Renee Bowen
                                        Ilwoo Hwang
                                         Stefan Krasa

                                      Working Paper 27981
                              http://www.nber.org/papers/w27981


                    NATIONAL BUREAU OF ECONOMIC RESEARCH
                             1050 Massachusetts Avenue
                               Cambridge, MA 02138
                                   October 2020




We thank Nageeb Ali, Georgy Egorov, Roger Myerson, Juan Ortner for helpful comments and
Xiameng Hua for excellent research assistance. We also thank the seminar audiences at the Harris
School of Public Policy, University of British-Columbia and the Virtual Seminar in Economic
Theory, as well as the participants at the POLECONUK conference and the 2nd ETH Workshop
on Democracy: Theoretical Political Economy. The views expressed herein are those of the
authors and do not necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2020 by Renee Bowen, Ilwoo Hwang, and Stefan Krasa. All rights reserved. Short sections of
text, not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.
Agenda-Setter Power Dynamics: Learning in Multi-Issue Bargaining
Renee Bowen, Ilwoo Hwang, and Stefan Krasa
NBER Working Paper No. 27981
October 2020
JEL No. C78,D72,D74,D83

                                            ABSTRACT

We study a dynamic bargaining model between a fixed agenda-setter and responder over
successive issues. If the responder rejects the setter's proposal, the setter can attempt to assert her
will to implement her ideal and will succeed with a probability that depends on her "personal
power". The players learn about the setter's power as gridlock persists. Gridlock occurs when the
setter's perceived power is either too high or too low, and the players reach compromise in an
intermediate interval of beliefs. The presence of "difficult" issues can induce more compromise
as the players have incentives to avoid learning.


Renee Bowen                                        Stefan Krasa
Department of Economics and                        University of Illinois
School of Global Policy and Strategy               Department of Economics
University of California, San Diego                217 David Kinley Hall
9500 Gilman Dr. #0519                              Urbana, IL 61801
La Jolla, CA 92093-0519                            skrasa@illinois.edu
and NBER
trbowen@ucsd.edu

Ilwoo Hwang
University of Miami
Department of Economics
Coral Gables, FL 33124
ihwang@bus.miami.edu
"Macht bedeutet jede Chance, innerhalb einer sozialen Beziehung den eigenen Willen auch
gegen Widerstreben durchzusetzen[. . . ]" (Power means every chance within a social relation-
ship to assert one's will even against opposition[. . . ]) - Weber (1922)



1 Introduction
What does it mean for a decision maker to have power? To answer this question, the theoret-
ical literature has focused on the ability of agenda-setting at least since the seminal work by
Romer and Rosenthal (1979). In this work, the power of agenda-setter is derived from his insti-
tutional position -- for example, in both the US House of Representatives and the UK House
of Commons, the agenda is controlled by the party in power, and a bill that is not supported
by a majority of that party is virtually never put on the agenda (Cox, 2001). However, there is
another source of power which, like agenda-setting power, is derived from the decision maker's
institutional position, but has not been investigated in the literature. It is the ability to cajole,
lobby, persuade, or "go above the responder's head" to get a proposal passed. Unlike agenda-
setting power, it is derived mostly from the decision maker's personal attributes and abilities.
The management literature has defined it as personal power to contrast it from the power de-
rived from the position, or position power (Yukl, 1989). In this paper, we provide a theoretical
framework of personal power and investigate its effect on decision-making processes.
   Lincoln's effort to get the 13th amendment passed in the House of Representatives is an ex-
ample of the interplay between position power and personal power. As Burlingame (2013) re-
ports, in mid-January 1865, Lincoln told a pair of house members that additional votes "needed
to be obtained by hook and crook" to obtain the required two-thirds majority. Opponents under-
stood Lincoln's power of forcing representatives to vote in favor of the amendment: "The wish
or order of the president is very potent. He can punish and reward." In terms of the opening
quote of Max Weber, Lincoln was very effective at using power in the sense of "assert[ing]
[his] will even against opposition". While one part of Lincoln's power was clearly based on his
position as president, a president's personal ability to exercise power also matters. In contrast,
his predecessor James Buchanan had the same position power, but was not as skilled in using
the power of the office. Using the above terminology, his personal power was low and he is




                                                 1
therefore consistently ranked among the least effective presidents in U.S. history.1
       A crucial characteristic of personal power is that there exists uncertainty surrounding its
strengths. This uncertainty implies that the perception of a decision maker's personal power is
inherently dynamic. The managerial literature on leadership points out that solving problems
successfully increases the perceived power of the leader, while failure reduces it (Hollander,
1978). Moreover, when choosing whether or not to force a decision, a decision maker must
take into account its effect on the dynamics of perceived power, which in turn affects future out-
comes. Given these observations, we are interested in addressing the following questions: How
does personal power affect the political decision-making process? What is the effect of the play-
ers' incentives to learn about the power on the equilibrium dynamics? How does the existence
of tough policy issues, in which conflict necessarily occurs, affect the future outcomes?
       We consider a stylized model of dynamic bargaining with a hierarchical difference between
players. An agenda-setter (setter hereafter) and a responder bargain over successive issues. A
motivating example is the chair of an academic department making proposals to faculty. At
each meeting, a curriculum change, hire, promotion, or other issue may arise and must be
bargained over. Time is continuous and a new issue arises with some probability in an interval
of time. Each issue has at most three possible outcomes: The setter's ideal, the status quo
(the responder's most preferred outcome), and a compromise outcome (second most preferred
outcome for both players). We call a policy issue "easy" if all three outcomes are possible; In
contrast, an issue is "difficult" if the compromise outcome does not exist. Once an issue arrives,
the setter puts a proposal on the table. The responder can accept at any point in time, or simply
wait, which we refer to as rejection. While a proposal is not accepted, the setter can assert her
will by pressuring the responder to accept, which may or may not succeed. The period in which
the responder rejects and the setter fails to force to acceptance is referred to as gridlock. At any
point in time, the setter can replace the existing proposal by another one. Time runs out when a
new issue arrives, in which case the status quo prevails.
       A key assumption in the model is that upon rejection of a proposal by the responder, the
setter has an opportunity to assert her will and have her ideal implemented. Whether or not she
is successful at asserting her will depends on her unknown personal power. A setter's personal
   1
       Siena College Research Institute, Siena's 6th Presidential Expert Poll 1982-2018, Retrieved from
https://scri.siena.edu/2019/02/13/sienas-6th-presidential-expert-poll-1982-2018



                                                    2
power can only be known in the context of a particular institution, and the position power that
this institution provides to the setter. For example, prior to Lincoln becoming president, it was
unknown whether or not he would be able to use the power of the office effectively. Consistent
with this observation, we assume both the setter and responder are symmetrically unaware of
the setter's power at the start of the game. Whenever the setter asserts her will, symmetric
learning about the setter's power occurs. A powerful setter will succeed in asserting her will
with some probability, while a powerless setter will never be successful.
   Learning about the setter's power to successfully assert her will is modeled in the spirit of
the exponential bandit literature (Keller et al., 2005). There is a common prior belief that the
setter is powerful. While the setter is attempting to assert her will, the belief decreases as long
as she has not been successful. If the setter succeeds in asserting her will (by implementing her
ideal), then the setter and responder know that she is powerful for certain and the belief jumps
to one. We refer to the belief that the setter is powerful as the setter's level of (personal) power.
The setter's power evolves over time as players learn during the period of gridlock.
   We first analyze a game in which all issues are easy (i.e., there are three possible bargaining
outcomes). We show that there is a unique Markov perfect equilibrium in which players choose
to compromise on issues for an intermediate range of beliefs. That is, compromise is possible
if the setter is neither too powerful nor too powerless. As is standard in the bandit literature, the
upper bound on the belief is driven by the setter's "exploitation" versus "exploration" tradeoff.
In equilibrium, the responder accepts the compromise offer when the level of power is high, in
which case the compromise endogenously becomes a "safe" alternative for the setter. The safe
alternative may be exploited, or the risky alternative (proposing her ideal) may be explored. The
lower bound on the belief is driven by the responder's incentives. When the setter is sufficiently
powerless, the responder knows it is unlikely that the setter can implement her ideal. Therefore,
the responder never accepts a compromise proposal, effectively eliminating the "safe" alterna-
tive of the setter. Given this, the setter seeks to assert her will on every issue, because she has
nothing to lose ­ there is a small probability that she is successful, and discovers that she is
powerful.
   When the compromise interval of beliefs is strictly inside [0, 1] this leads to the following
dynamics. If the setter is very powerful (i.e. the belief about the setter's personal power level
is close to one) at the beginning of the game, then the setter is unwilling to compromise and


                                                 3
gridlock occurs. If the setter is unsuccessful in using her personal power, the belief about the
setter's power decreases. When that belief hits the upper bound of the compromise region, then
the setter switches to the compromise offer, which will be immediately accepted. If the setter is
sufficiently powerless at the beginning, then there will be long-run gridlock. The belief about
the setter's power will either continue to decline towards zero, or move to one, if the setter is
ever able to overturn a rejection.
   We then consider a model in which difficult issues arise with some probability. Recall that
an issue is difficult if the compromise outcome does not exist, and thus the players must agree on
either the status quo or the setter's ideal. In this case, we show that two types of equilibria exist.
In both types of equilibria, behavior under the easy issues does not change: the players agree on
the compromise outcome when the setter's power is in the intermediate range. Under difficult
issues, however, the equilibrium behavior differs qualitatively between the two equilibria, which
we call gridlock equilibrium and avoiding-the-issue equilibrium.
   In the gridlock equilibrium, the setter always proposes her ideal so there is always gridlock
(and learning) when a difficult issue arrives. Therefore, even if beliefs are in the interval where
compromise is implemented for easy issues, the players eventually move out of the compromise
region, and from this point onward gridlock ensues even for easy issues. This helps to explain
why gridlock may arise for issues that may have once been resolvable: As the setter's power
becomes more conclusive during the difficult issue, the players no longer wish to compromise.
In this case, the belief tallies the past periods of disagreement, and once the tally is full, there
is no longer a chance of compromise. In contrast, in the avoiding-the-issue equilibrium, the
setter stops demanding her ideal at the lower bound of the compromise interval. Since the setter
knows that further gridlock will push the belief out of the compromise interval--and leading
to gridlock even for easy issues--she decides to "avoid the current issue" and propose the
responder's ideal. As a result, long-run compromise ensues once the belief hits the compromise
boundary.
   While one may expect that the presence of difficult issues always makes compromise harder,
this is not always the case. In fact, we show that bundling easy and difficult policy issues can
result in less gridlock for both types of issues, as doing so provides additional incentives to avoid
learning. Most surprisingly, the presence of difficult issues can induce more compromise even
for the easy issues. To see this, observe that compromise on the difficult issues results in the


                                                  4
responder's most preferred outcome. Thus, even if the belief about the setter's personal power
is low, the responder may be willing to compromise on easy issues, because by not doing so
he would lose out on the benefit's of compromise when difficult issues arise. Further, bundling
helps to generate compromise for the difficult issues. If all issues were difficult, permanent
gridlock would arise as the players have no reason to compromise. However, the prospect of
future easy issues provides the setter an incentive to compromise on difficult issues in order to
remain in the compromise region, and avoid permanent gridlock.

   Literature Review
   There is an extensive literature on dynamic legislative bargaining, now summarized in
Eraslan et al. (2020). As in Diermeier and Fong (2011) (and Romer and Rosenthal (1979) in
a static setting), we assume that there is a designated agenda setter. This assumption allows us
to focus on learning about the type of only one of the players. In contrast, Baron and Ferejohn
(1989, 1987) consider the case of a decentralized committee in which each member can be
selected to be the agenda setter. These models have been extended to multidimensional pol-
icy spaces by Banks and Duggan (2000, 2006), and to dynamic bargaining (c.f., Baron (1996),
Kalandrakis (2004), Duggan and Kalandrakis (2012), Bowen and Zahran (2012)). To link poli-
cies over time, these models assume that once a policy is enacted it determines the status quo
for the next period. In our model, the status quo payoff is exogenous and fixed, but the belief
about the setter's type links issues through time. This allows us to clearly identify the effects of
learning in the bargaining process.
   The choice between a risky proposal (the setter's ideal) and a safe alternative (the com-
promise) is modeled as a bandit problem in the spirit of Keller et al. (2005). In this sense, this
project is related to the growing literature on collective experimentation and voting rules, includ-
ing Strulovici (2010), Anesi and Bowen (forthcoming) and Gieczewski and Kosterina (2019).
Like ours, these papers study the interaction between collective choice and experimentation,
however, what is uncertain in our paper is the bargaining ability of the setter. In equilibrium,
the setter's ideal action can be considered the risky alternative, while the compromise is the safe
alternative. Interestingly, the setter and responder have opposing incentives to experiment. This
generates the possibility for an intermediate interval of beliefs such that the safe alternative is
implemented. In this interval experimentation is too risky for the setter, while not conveying
enough information for the responder to trigger it. Other papers considering policy exper-

                                                 5
imentation and collective choice include Majumdar and Mukand (2004), Volden et al. (2008),
Cai and Treisman (2009), Callander (2011), Callander and Hummel (2014), Millner et al. (2014),
Hirsch (2016) and Freer et al. (2018). Callander and Hummel (2014) consider a case in which
a political party preemptively experiments on policy to affect future decisions of the opposition
party. Our paper differs because in our model agents do not learn the type of the policy, but the
strength of the setter which endogenously determines the future outcome.
   The existing literature on bargaining with incomplete information (Fudenberg et al., 1985;
Abreu and Gul, 2000; Deneckere and Liang, 2006; Lee and Liu, 2013) typically focuses on the
effect of private information of bargainer(s). In these models, a rejection by the informed bar-
gainer signals that the bargainer has a higher reservation value. In contrast, in our paper players
are symmetrically uninformed about the setter's ability and their conflicts over policy induces
social learning. Uncertainty about the bargaining strength of agents has been previously pro-
posed as a rationale for delay in bargaining. This has been explored in the seminal works of
Admati and Perry (1987), Cramton (1992) and more recently by Friedenberg (2019). We do not
seek to explain delay in this paper, but rather we seek to explain when we expect compromise
to arise, or when we expect a challenge to ensue. Our model features delay in the sense that
gridlock exogenously implies some delay relative to agreeing to a policy proposal immediately.
   Theoretically our paper is also related to a rich literature in continuous time bargaining
models, including Ortner (2019); Perry and Reny (1993). Ortner (2019) is closely related as,
similar to us, the effect of evolving setter power on bargaining outcomes is considered. Ortner
(2019) considers a single issue, whereas we consider multiple. In addition, unlike Ortner (2019),
our model features endogenous evolution of proposal power as gridlock is chosen. The setter
and responder must therefore consider the trade-off between fighting for their preferred issue
(which will imply learning about setter strength) and settling for a less preferred outcome. In
earlier work, Powell (2004) also takes up the question of endogenous evolution of setter power,
but in a discrete time setting with effectively a single issue being considered.
   The remainder of the paper is organized as follows. Section 2 presents the baseline dynamic
bargaining model and Section 3 calculates dynamic payoffs for setter and responder for two
benchmark outcomes. Section 4 characterizes the equilibrium of the dynamic model and estab-
lishes existence of the compromise interval of beliefs. Section 5 extends the baseline model to
include the possibility of difficult issues and shows that these can introduce learning that forces


                                                6
players into permanent gridlock or permanent compromise. Section 6 concludes. All proofs are
relegated to the Appendix.



2 Model
We present a stylized model of bargaining over an infinite sequence of issues between an
agenda-setter S (House Speaker or department chair) and a responder R (speaker's party or
faculty). We assume that time is continuous t  [0, ) and new issues arise at random times. In
particular, in any interval of time [t, t + dt), a new issue arrives with probability 1 - e-dt   dt.
Since  governs the speed at which new issues arrive, we interpret this as the velocity of the
institution. At most one issue is bargained over at any time. Therefore, if a new issue arrives
while the present issue is not resolved, then the status quo is implemented for the present issue,
which is then abandoned.
       The game proceeds as follows. At each instant, the setter makes a proposal x  X 
{ x0 , xc , xs } for the issue at hand. We denote x0 as the exogenous status quo position, xc as
the compromise outcome, and xs as the setter's preferred option. After a proposal is made, the
responder chooses to accept or reject the proposal. If the proposal is accepted, it is implemented
immediately and the players receive payoffs. If the proposal is rejected, then the setter can
choose to assert her will or allow the status quo to be implemented immediately.2 If there is no
unresolved issue at hand, then players simply wait for a new issue to arise.
       We model the outcome of the setter's attempt to assert her will as an exponential bandit
in the spirit of Keller et al. (2005). If the setter chooses to assert her will, then her success at
implementing her ideal xs depends on her type   {0, 1}. We say that if the setter is powerful
or  = 1, then she is successful at asserting her will with probability 1 - e-dt  dt over time
interval [t, t + dt). If the setter is powerless then she is never successful at asserting her will.
Note that  governs the setter's probability of success conditional on being powerful. We thus
think of  as related to institutional features (such as access to powerful committees), and thus
captures position power.3 The common prior probability that the setter is powerful is p0 . We
   2
       The terminology of "asserting one's will" is from Weber (1922), quoted in the beginning of the introduction
of this paper.
    3
      In the case of House Speaker, Cooper and Brady (1981) describe how leadership style moved from hierarchical
to bargaining, suggesting that  may have decreased over time.


                                                         7
refer to the posterior pt as the setter's level of perceived personal power (or simply power) at
time t.4
       Players receive payoffs uS ( x) and uR ( x) when position x is implemented for each issue. We
assume that R strictly prefers x0 to xs , and, similarly, S strictly prefers xs to x0 . We assume that
uS ( x0 ) = uR ( xs ) = 0.5 Also, let uS ( xs ) = u
                                                  ¯ , uS ( xc ) = uc , uR ( x0 ) = v
                                                                                   ¯ and uR ( xc ) = vc , where
0 < uc < u              ¯.6 Note that xc is considered a compromise proposal because it is
         ¯ and 0 < vc < v
the second-ranked outcome for both players. Note also that in this setting vc + uc > max{u, v}
is sufficient for compromise to be efficient.7 Finally, utility is discounted at a rate r > 0 and
players maximize discounted sums of payoffs from all issues bargained over.


Learning        If the responder accepts the setter's offer, or if the setter decides not to assert her
will, then there is no learning about the setter's type and beliefs are unchanged. If the responder
rejects the offer and the setter attempts to assert her will, the belief changes depending on the
outcome of the attempt. If the setter succeeds in asserting her will, then her perceived power
jumps to one and there is no learning thereafter. In other words, "good" news is conclusive.
As the setter attempts to assert her will without success, then players become more pessimistic
about the setter's power. Formally, while the setter is asserting her will (and there is gridlock),
the belief that the setter is powerful changes on the time interval [t, t + dt) via Bayes' rule:
                                                        pt (1 - dt)
                                        pt+dt =                           .                                       (1)
                                                  pt (1 - dt) + (1 - pt )
Simplifying (1) implies that the power dynamics during gridlock follows d p = - p(1 - p)dt.


Markov Strategies           We restrict attention to stationary Markov strategies where the state of
the game at period t is given by the setter's power pt . Denote an offer strategy for the setter as
   4
       The way we model "asserting her will" parallels Lee and Liu (2013). They also assume the setter has two
types and a powerful setter has higher probability of successfully extracting higher outside payment in the event
of no disagreement. Lee and Liu (2013) focus on one-sided learning, whereas we focus on two-sided learning in a
simpler setting.
   5
     The results of this paper are robust to the case in which uS ( x0 ) and uR ( x s ) are not too high. If either is
sufficiently high, then the players may agree on their worst outcome to reduce the bargaining delay.
     6
       Note that commonly used utility functions satisfy these minimal assumptions. For example ui ( x) = -( x - xi )2
with x  R, x0 < x s , xR = x0 , xc  ( x0 , x s ).
   7
     The necessary and sufficient condition for compromise to be always efficient is uc + vc > max{(u + v)/(r +
 + ), v/(r + )}. This is because of the loss due to delay when there is gridlock.

                                                          8
 : [0, 1]  X which maps a power level pt into a proposal in X . An acceptance strategy for the
responder is a correspondence A : [0, 1]  X that gives the set of proposals which the responder
will accept given the state pt . Finally the setter's strategies of whether or not to "assert his will"
is given by  : [0, 1] × X  {0, 1}, where 1 indicates that the decision to to assert his willing
against opposition.
   We consider Markov perfect equilibria which are subgame perfect equilibria in which play-
ers use Markov strategies. We refer to a Markov perfect equilibrium with the above restrictions
as simply an equilibrium.



3 Benchmark outcomes
Before proceeding to the equilibrium analysis we consider two benchmark outcomes and corre-
sponding dynamic payoffs. It is yet to be determined that these outcomes occur in equilibrium.
For now we construct the payoffs and later in Section 4 show that these are equilibrium payoffs
for some values of p.


3.1 Long-run gridlock
First consider the case in which there is long-run gridlock. In this outcome, the setter proposes
her ideal xs at each instant, this is rejected by the responder, and the setter then chooses to assert
her will. Gridlock induces learning in this outcome. If the setter is successful, then both players
know the setter is powerful and learning ceases, and the setter continues to assert her will. We
denote by Vi,d ( p) the value function under the long-run gridlock for player i  {R, S }.
   Suppose first that the setter is known to be powerful, i.e., p = 1. Fix a time interval [t, t + dt)
with a small dt > 0. If the gridlock occurs in the time interval [t, t + dt), the setter succeeds in
asserting her will with probability dt, in which case the setter and the responder obtain payoffs
¯ and 0, respectively, and the players wait for the next issue. When players are simply waiting
u
for a new issue we say that the previous issue is resolved. If the setter is not successful, then
with probability  dt the issue is replaced with a new one, in which case S and R obtain payoffs




                                                  9
of 0 and v
         ¯, respectively. Therefore,

                       VS ,d (1) = dt(¯ ^ S ,d (1)) + (1 - dt)e-rdt VS ,d (1),
                                      u+V
                                    ^ R,d (1) + (1 - dt)( dtv
                       VR,d (1) = dtV                       ¯ + e-rdt VR,d (1)),

where V^ i,d (1) is player i's value function when the previous issue has been resolved and the
players wait for a new issue. To derive the value of V ^ i,d ( p) for any p  [0, 1], note that a new
issue arrives with probability  dt in the time interval [t, t + dt). Therefore, for i = S , R,

                           ^ i,d ( p) = e-rdt ( dtVi,d ( p) + (1 -  dt)V
                           V                                           ^ i,d ( p)).

                                                                               ^ i,d ( p) =
Using 1 - rdt  e-rdt , dropping the higher orders of dt and simplifying yields V
 Vi,d ( p)/(r +  ). Using this, we derive the value of Vi,d (1), which are given by
                                      (r +  )                              (r +  )
                      VS ,d (1) =               ¯,
                                                u          VR,d (1) =               v
                                                                                    ¯.
                                    r(r +  +  )                         r(r +  +  )
When the setter is powerless (i.e., p = 0), she never succeeds in asserting her will (that is,  = 0
in the above equations). Therefore, the value functions are given by
                                                                     
                                     VS ,d (0) = 0,        VR,d (0) = v¯.
                                                                     r
   Now consider any intermediate level of power p  (0, 1). Observe that player i's value
function Vi,d ( p) is a convex combination of Vi,d (1) and Vi,d (0). To understand this, note that the
players' never change their actions in the future, regardless of the outcome ­ S always proposes
xs which R rejects. Therefore,
                                                                   (r +  )
                    VS ,d ( p) = pVS ,d (1) + (1 - p)VS ,d (0) = pu
                                                                  ¯          ,                    (2)
                                                                 r(r +  +  )
                                                              v¯         p
                    VR,d ( p) = pVR,d (1) + (1 - p)VR,d (0) =     1-           .                  (3)
                                                              r        r++
Note that both value functions are affine linear in power p. The setter's function is increasing in
p, while the responder's is decreasing in p.


3.2 Long-run compromise
The second important benchmark is where players compromise for all future issues. In this
case, the setter offers the compromise xc , and the responder immediately accepts the offer.

                                                      10
No learning occurs, and hence the payoffs do not depend on power p. Let Vi,c be player i's
continuation utility under the long-run compromise. Then the value functions can be written as

                                                                    ^ S ,c),
                            VS ,c = uc + e-rdt ( dtVS ,c + (1 -  dt)V
                                                                  ^ R,c),
                            VR,c = vc + e-rdt ( dtVR,c + (1 -  dt)V

where V^ i,c is player i's value function when the players wait for a new issue. The same argument
used to derive V  ^ i,d shows that V
                                   ^ i,c =  Vi,c /(r +  ). Therefore, the above equations simplify to

                                          r+                        r+
                               VS , c =      uc ,        VR , c =      vc .                      (4)
                                           r                         r


4 Bargaining with Easy Issues
In this section, we analyze equilibria for the model in which all policy issues have three possible
outcome { x0 , xc , xs }. We refer to these as easy issues as players can compromise on the outcome
xc . Later, we introduce difficult issues in which only the two extreme outcomes are feasible.
   The next result, Proposition 1, describes a Markov perfect equilibrium of the game. We first
explain the players' behavior and equilibrium dynamics under the profile in Proposition 1. Then
we establish the uniqueness of equilibrium under a mild criterion.

Proposition 1 There exists a p, p with 0  p  p such that:

   1. There exists an equilibrium in which compromise occurs in an interval of beliefs, i.e.
                                                            
                                                            
                              xc if p  [ p, p]              { x0 , xc } if p  p
                                                            
                     ( p) =                       A ( p ) = 
                              xs otherwise,                 { x0 }      if p < p,
                                                            

      if and only if
                                 vc            uc   
                                     max    1-    ,   .                                          (5)
                                 v¯      r+    u¯ r++
   2. There exists an equilibrium in which no compromise occurs, i.e.
                                                             
                                                             { x0 , xc }
                                                                               if p  p
                   ( p) = xs for any p  [0, 1],     A( p ) = 
                                                             
                                                             
                                                             { x0 }            if p < p,
                                                             

      otherwise.

                                                    11
Moreover, the setter always asserts her will after a rejection, i.e., ( p, x) = 1 for all p  [0, 1]
and x  X.

   Proposition 1 states that if compromise occurs in equilibrium (i.e., if (5) holds), then it
occurs when the perceived power is within the interval [ p, p]. In other words, compromise
occurs when the players have a moderate perception of the agenda-setter power. If the setter
is perceived to be too powerful, then the setter prefers to take the risk and induce gridlock,
believing that he would succeed in asserting her will. On the contrary, when the setter is too
weak, the responder refuses to compromise, as he finds gridlock more beneficial.
   Gridlock induces learning on the setter's power, leading to various equilibrium dynamics
depending on the setter's initial power. If the setter is initially very powerful ( p0 > p), then
gridlock occurs in the beginning of the game. If the setter succeeds in asserting her will, then
the power jumps to one and the setter continues to induce gridlock. If the setter cannot assert
her will, however, then the power gradually drifts down, and when p reaches p the setter offers
xc to make a compromise. If the setter's power is moderate ( p0  [ p, p]), then the players
compromise for all future issues and no learning occurs. For an initially weak setter ( p0 < p),
the power either jumps to one or gradually drifts down, resulting in permanent gridlock.
   The complete proof of Proposition 1 is provided in the Appendix. Here we provide a heuris-
tic argument to derive the lower and upper bound of the compromise set. First, the value of p is
derived from the responder's incentives. Note that if p  (0, 1), then the responder is indifferent
between long-run compromise and long-run gridlock at p = p. A single deviation to reject xc
would lead to permanent gridlock. Therefore, it must be that VR,c = VR,d ( p). From (3) and (4),
it follows that the responder is indifferent when
                                         r++    r +  vc
                                   p=        1-         .                                      (6)
                                                   v  ¯
   Note that the above formula is less than 1 if and only if vc /v
                                                                 ¯  /(r +  +  ), which is
necessary for compromise to occur in equilibrium. In order for compromise to occur at p = p,
the setter must also prefer to compromise (by offering xc ) than inducing long-run gridlock (by
offering xs ) at p = p. This condition is given by

                                                    vc        uc
                       VS , c  VS , d ( p )                1-    .
                                                    v¯  r+    u¯
The above arguments imply that compromise occurs at p = p  [0, 1] if and only if (5) holds.

                                                 12
   The setter's incentive determines the upper bound p of the compromise set. Specifically, if
the compromise region is a nondegenerate interval (i.e., p > p) and p < 1, then the setter is
indifferent between gridlock and compromise at p = p. Therefore, the value matching condition
(Dixit (2002)) gives
                   r+                   ^ S ,d (1)) + (1 -  pdt)e-rdt r +  uc .
                        uc =  pdt(¯u+V
                     r                                                   r
Simplifying yields
                               r++                     ruc
                          p=                                         .                           (7)
                                          (r + )¯   u - (r +  +  )uc
Note that the above formula is greater than one if and only if uc /u   ¯  /(r +  +  ). In this case,
the setter prefers to compromise for all p > p.
   Figure 1 illustrates the parameters such that the equilibrium in Proposition 1 admits com-
promise. The green region represents the set of parameters such that (5) holds, and thus the
equilibrium in this region features compromise at some p  [0, 1].

                             Responder: vc /v
                                            ¯
                              1



                              
                            r +

                                               compromise


                                    gridlock
                             
                          r ++




                              0                                              1
                                                            r ++
                                                             Setter: uc /u
                                                                         ¯

Figure 1: An illustration of the equilibrium described in Proposition 1. For parameters in col-
ored regions, compromise occurs for some power level. Labels in each colored region indicate
the locations of the compromise set.

   It is straightforward to see that the compromise occurs for a broader range of power as the
players' payoff from compromise increases. For the responder, we check from (6) that p is

                                                  13
decreasing in vc /v
                  ¯. If vc /v
                            ¯ > /(r +  ), then p = 0 and the compromise occurs for all low p.
Similarly, (7) implies that p is increasing in uc /u
                                                   ¯ , and p = 1 If uc /u
                                                                        ¯ > /(r +  +  ), leading to
compromise for all high p.


Uniqueness     We next show that for any fixed parameter values, the equilibrium described in
Proposition 1 is the unique Markov perfect equilibrium under two mild conditions. Let C = p 
[0, 1] ( p)  A( p) be the set of beliefs in which compromise is reached in equilibrium. We
call C a compromise set of a Markovian profile. Observe that for the equilibrium in Proposition
1, the compromise set is either empty or [ p, p] depending on the parameter values.

Assumption 1 C is closed.

    We argue that the closedness of the compromise set is necessary for the equilibrium profile
to be a limit of a corresponding discrete-time game. To understand this, consider a profile in
which the players reach a compromise for p  ( p1 , p2 ] for some p1 , p2 . Note that whenever
the belief is in the compromise set, after having gridlock for an instant, the belief never drifts
below the compromise set--it either jumps to one or stay in the compromise set. However, this
profile cannot be a limit of a discrete-time game: For any small discrete time interval, if the
belief is sufficiently close to p1 , then gridlock for one `period' leads the belief to jump below
p1 . Assumption 1 is a necessary condition to rule out such cases.

Assumption 2 If A( p)  { x0 }, then the proposer proposes xs .

    To see why Assumption 2 is mild, it applies only in the case when the responder would
reject both xc and xs and hence proposing xs does not change the equilibrium outcome.

Proposition 2 Suppose Assumption 1 is satisfied, then all equilibria are outcome equivalent.
If, in addition, Assumption 2 is satisfied, then the equilibrium is unique.


Comparative Statics      We next explore how the compromise interval changes with parameter
values. Given the simple expressions for the bounds on power for compromise to occur, we can
do straightforward comparative statics.

Proposition 3 Suppose that p < p
                               ¯ < 1. Then in the equilibrium described in part 1 of Propo-
sition 1,

                                                14
      ¯ increases in r; p decreases in r;
   1. p

           ¯ and p decrease in ; p
   2. both p                     ¯ - p decreases in ;

           ¯ and p increase in  .
   3. both p

                   ¯ and p are the beliefs at which the setter and responder, respectively, are indif-
       Recall that p
ferent between compromise and conflict. Increasing the discount rate r increases the costs of
delay. This means that both players are more willing to compromise, which in turn implies that
¯ increases and p decreases. Of course, this also implies that raising r increases the size of the
p
                ¯ - p, at which compromise can occur.
set of beliefs, p
       Increasing  means that the setter's position power is increased. Hence, the setter is less
willing to compromise, i.e., p
                             ¯ decreases. At the same time, the responder is more willing to
compromise, which means that p also decreases. Overall, however, compromise can occur for
                                         ¯ - p when  is increased.
a smaller set of beliefs, as measured by p
       Finally, recall that  is that the rate at which a new issue arises, or the velocity of the insti-
tution. If the current issue has not been resolved, then the status quo is retained. Thus, raising
 benefits the responder versus the setter. As a consequence, the responder is less willing to
compromise, thereby raising p, while the setter is more willing to compromise, which raises p
                                                                                            ¯.
                               ¯ - p itself is in general not monotone.
The size of the compromise set p


Value of information To provide further intuition for the result, we use the value functions to
determine the value of information for any level of power p. The value of information is simply
the expected informational benefit from gridlock.8 For the setter, the benefit is in learning that
she is powerful, and for the responder, the benefit is learning that the setter is powerless. The
value of information for player i = S , R in the interval [t, t + dt) is given by

                                 VIi ( p) =  p(Vi (1) - Vi ( p)) - Vi( p) p(1 - p),                 (8)

where Vi ( p) is player i's value function. The first term in the expression is the expected benefit
from learning that the setter is powerful for certain. The second term is the loss to the setter if
no success occurs, or the benefit to the responder if no success occurs. Figure 2 graphs the value
of information and the value functions for a parametric example. We describe these below for
each interval of p.
   8
       This is similar to the value of playing the risky alternative in Keller et al. (2005).

                                                             15
                   2.5                                                                            0.10

                                                                                                  0.05
                   2.0                                                                            0.00




                                                                          Value of Information
                                                                                                 -0.05
  Value Function




                   1.5
                                                                                                 -0.10

                                                                                                 -0.15
                   1.0
                                                                                                 -0.20

                   0.5                                                                           -0.25

                                                                                                 -0.30

                   0.0                                                                           -0.35
                     0.0   0.2   0.4               0.6   0.8   1.0                                   0.0   0.2   0.4               0.6   0.8   1.0
                                       Belief, p                                                                       Belief, p



Figure 2: Utility and the value of information for the responder (red) and the setter (blue):
 = 0.2, r = 0.1,  = 0.7, vc = 0.55, uc = 0.6, v
                                              ¯=u
                                                ¯ = 1.



         For p < p we have Vi ( p) = Vi,d ( p) from equations (2) and (3). Simplifying (8) shows that the
value of information is zero as illustrated in Figure 2 right panel. The reason is that information
will not change players' strategies, as gridlock will ensue even if there is new information.
         If p  [ p, p], then the long-run compromise arises. Thus, Vi ( p) = Vi,c from (4), which
implies that Vi( p) = 0. For the responder VR (1) < VR ( p) if and only if vc /v
                                                                               ¯ > /(r +  +  ). For
the setter, VS (1) > VS ( p) if and only if uc /u
                                                ¯ < /(r +  +  ), which is the condition under which
p < 1. In this case the value of information is strictly positive and strictly increasing for the
setter, and strictly negative and strictly decreasing for the responder in the compromise region.
This reflects the fact that as p gets smaller, the setter's value of experimenting is decreasing,
as there is less the setter is able to do. From the responder's perspective, her benefit from
information is increasing as beliefs drift down, because she approaches the region of beliefs
such that she rejects the compromise.
         In the Appendix, Section 7.1 we show that if p > p then the setter's and responder's value
functions are convex as illustrated in Figure 2, left panel. If we start with some belief p > p at
time t and learning occurs, then the belief at t + dt remains above p. By (8), the strict convexity
of Vi ( p) implies that the value of information is strictly positive for both players. That is, both
players have the ability to modify actions based on information arrival. Note that the setter's
value of information is continuous at p, but the responder's is discontinuous at that point. The
reason is that it is the setter who chooses to switch from proposing gridlock, to compromise.


                                                                     16
When the setter does this the responder's value of information becomes negative--information
can only hurt the responder by causing the setter to revert to gridlock.



5 Difficult issues
The previous analysis showed how power dynamics can result in long-run compromise out-
comes, but it is often the case in practice that a pre-existing compromise is disrupted. In this
section, we explore one possibility why this might occur. In the organizational or political
bargaining process, an issue without a compromise option often arises. For example, the Af-
fordable Care Act was a difficult issue for which compromise was not possible. For the speaker
Nancy Pelosi, passage was a signature moment demonstrating her personal power. Regarding
bargaining with these "all-or-nothing" policy issues, we ask the following questions: Would
any bargaining party ever concede to the opponent's extreme position? Do the outcomes from
the all-or-nothing issues affect the outcomes in the normal issues? We answer both questions in
the affirmative.
   To model such an environment, we modify our main model and assume that a difficult policy
issue may arise. Formally, with probability  > 0, a policy issue with no compromise alternative
arises, and the setter can only propose either xs or x0 . With the complementary probability, the
easy policy issue (with three possible outcomes) arises. Let e (resp. d ) be the offer strategy
for the setter if the current issue is easy (resp. difficult). Similarly, let A and  ( = e, d ) be
the acceptance strategy for the responder and the setter's strategy to assert her will.
   In this section, we focus on the parameter range where

                             vc                            uc     
                            < <    ,                 and      <     .                          (9)
                        r++  v¯ r+                         u¯   r++
The condition on vc /v
                     ¯ guarantees that the value of p defined in Proposition 1 is in the interior
of [0, 1], and the condition on uc /u
                                    ¯ ensures that gridlock occurs at p = 1 regardless of the issue
type. In the equilibria constructed in this section, the players' behavior under the easy policy
issue remains qualitatively the same.
   We construct two types of equilibria exhibiting qualitatively different behavior under the
difficult issues. First, there exists an equilibrium in which players never concede under difficult
issues. We call this equilibrium a gridlock equilibrium. Second, there exists an equilibrium in


                                                17
which the setter concedes by offering x0 to avoid a long-run gridlock. We call this an avoiding-
the-issue equilibrium.
   The next proposition formally states the gridlock equilibrium and the parametric conditions
for its existence. The proofs for the next two propositions are in the Online Appendix.

Proposition 4 (gridlock equilibrium) Suppose that (9) holds, and

                                 uc vc        (1 - ) uc
                              1-          1-            .                                     (10)
                           r+    u¯ v¯ r+      r+ u   ¯

Then for some p  [ p, 1], there exists an equilibrium in which
                                                                 
                             if p  [ p, p ],                     { x0 , xc }   if p  p,
                                                                 
                      xc
                                                                 
             e                                           e
              ( p) =                                    A ( p) = 
                      xs     otherwise,                          { x0 }        if p < p,
                                                                 

            d ( p) = xs     for all p,                 Ad ( p) = { x0 }   for all p.

Moreover, the setter always asserts her will after a rejection, i.e.,  ( p, x) = 1 for all  = e, d,
p  [0, 1] and x  X.

   In the gridlock equilibrium, the equilibrium behavior eventually features permanent grid-
lock. Even when the prior belief sits in the intermediate range so that compromise is initially
maintained on easy issues, difficult issues arise and gridlock over those issues leads to learning.
Learning makes the belief either jump to one or drift below p, and thus the belief moves out of
the compromised region. There is permanent gridlock thereafter in equilibrium.
   This helps to explain why gridlock can arise on seemingly easy, non-contentious issues,
for which there was no gridlock before. Learning over gridlock for the difficult issues leads to
more extreme level of perceived personal power, which in turn provides either the setter or the
responder greater incentives to reject compromise proposals.
   The next proposition describes another type of equilibrium in which the setter concedes to
avoid future gridlock.

Proposition 5 (avoiding-the-issue equilibrium) Suppose that (9) holds, and

                               vc     (1 - )        uc
                                               1-      .                                      (11)
                               v¯  r +  (1 - )    r+ u
                                                     ¯



                                                18
                                  ^  p, such that for any p  [ p , p
                        ^ with p  p
Then there exists p and p                                          ^ ], there is an
                          0                     0                                                    0
equilibrium in which
                                                                             
                                   if p  [ p , p ],                          { x0 , xc }       if p  p ,
                                                                             
             e
                    xc                                               e
                                                                             
                                                                                                         
            ( p) =                                                  A ( p) = 
                                                                             
                                                                             
                    xs             otherwise,                                { x0 }            if p < p ,
                                                                             
                                                                                                         
                   
                   
             d
                    xo
                                   if p = p ,
            ( p) =                           
                                                                    Ad ( p) = { x0 }    for all p.
                   
                   
                    xs
                                   otherwise,

Moreover, the setter always asserts her will after a rejection, i.e.,  ( p, x) = 1 for all  = e, d,
p  [0, 1] and x  X.9

       In the avoiding-the-issue equilibrium, gridlock ensues on difficult issues until the belief
reaches the lower bound of the compromise region for the easy issues ( p = p ). At the lower
                                                                                                     
bound, the setter concedes to the responder by proposing the status quo. There is permanent
compromise thereafter for both types of issues, and the belief stays at p . The setter has an
                                                                                                
incentive to concede because doing so would avoid further learning that leads to a long-run
gridlock even for the easy issues.
       Figure 3 describes the parameter regions under which each type of equilibrium exists. In
general, the gridlock equilibrium (shaded region) exists for the lower values of vc /v
                                                                                     ¯ compared to
the avoiding-the-issue equilibrium (yellow region). Intuitively, higher values of the compromise
payoff gives the setter a stronger incentive to concede for the current difficult issue to avoid a
long-run gridlock.
       Note that for vc /v  /(r +  ) there exists a trivial equilibrium in which for easy issues
there is gridlock for p  p and compromise otherwise. In this equilibrium, there is always
gridlock for difficult issues. Combining with Propositions 4 and 5, the condition to sustain an
equilibrium with the possibility of compromise when there are difficult issues is
                                        uc    (1 - )        uc                                   
           vc /v
               ¯  max min            1-    ,           1-                                  ,       .                 (12)
                                  r+    u¯ r +  (1 - )    r+ u
                                                             ¯                                 r++
Comparing condition (12) to condition (5) in Proposition 1, it is straightforward to see that the
set of parameters that admits a possibility of compromise with difficult issues, includes those
   9
       There exists at least one other equilibrium that yields the same equilibrium outcome described in Proposition 5.
In this equilibrium, the setter offers her most preferred outcome under a difficult issue when the belief hits the lower
bound of the compromise set (d ( p ) = x s ) but chooses not to assert her will after a rejection (d ( p , x s ) = 0).
                                                                                                            


                                                           19
                            Responder: vC /v
                                           ¯
                             1



                             
                           r +




                            
                         r ++




                             0                                            1
                                                        r ++
                                                          Setter: uc /u
                                                                      ¯

Figure 3: Parameter range for the equilibrium in Propositions 4 and 5 when  = 0.5. The shaded
region (resp. yellow region) represents the parameter space in which a gridlock equilibrium
(resp. an avoiding-the-issue equilibrium) exists. The red dotted triangle depicts the parameter
region where compromise never occurs when there is no difficult issue.


parameters that admit compromise when there are no difficult issues. Indeed, the additional
parametric region is precisely those indicated with red dots in Figure 3.
   We thus conclude that by bundling difficult and easy issues, compromise on easy issues
becomes possible in more environments. Moreover, whereas difficult issues alone would result
in perpetual gridlock, agreement on the status quo is possible when difficult issues are combined
with easy issues. This results from the unwillingness of the setter to yield power that can be
valuable when easy issues arise.



6 Concluding Remarks
In this paper, we provide a model that predicts the dynamics of bargaining when agenda-setter
power evolves endogenously. We show that agents will compromise when the setter is neither
too powerful nor too powerless. A powerful setter is never willing to offer a compromise, while
the responder is never willing to compromise when the setter is too powerless. The incentive

                                               20
constraints of both the setter and responder determine an intermediate range of beliefs such that
compromise occurs. In this interval, the setter believes she is too powerless to assert her will
successfully, and the responder prefers to compromise rather than learn about the setter's type.
       We seek to understand how the evolution of power may explain puzzling bargaining out-
comes. That is, observing gridlock on issues that may have previously been a relatively easy
issue to settle. We show that when difficult issues arise that force the agents into gridlock, these
issues also forces learning about the setter's strength. If the setter learns either that she is pow-
erful with certainty, or becomes too powerless, then gridlock ensues on every issue. On the
other hand, we also show the existence of an equilibrium where the setter accommodates the
responder on difficult issues when the belief about her type is too low. This avoids learning and
allows the compromise to be sustained for easy issues. We think this helps explain instances
where the setter "avoids the issue".
       We believe that our model is a first step in analyzing the effect of personal power in politi-
cal decision-making processes, and that there are several interesting future research directions.
First, one can consider a model with endogenous sequence and timing of easy and difficult is-
sues. If either the setter or the responder is allowed to choose the issue sequence, their choice
would be certainly affected by its effect on learning.10 Second, it is possible that the policy
issues have various degrees of importance, and it may affect the players' incentive to create
gridlock and learn about the personal power. Thus, it would be fruitful to analyze a case in
which issues have heterogeneous payoffs. Third, while a perfect good news model is a natural
representation of the evolution of personal power, one can consider a model with generalized
information structures, in which gridlock may generate either a good or bad news. Finally, the
model lends itself naturally to empirical or experimental tests. One can test if compromise oc-
curs more often with higher position power than lower position power, or if compromise occurs
more often when difficult issues are bundled with easy issues as opposed to in isolation.


References
Abreu, D. and Gul, F. (2000). Bargaining and Reputation. Econometrica, 68 (1), 85­117.

Admati, A. and Perry, M. (1987). Strategic delay in bargaining. The Review of Economic Stud-
  ies, 54 (3), 345­364.
  10
       Some of these questions are explored in a companion paper (Hwang and Krasa, 2020).


                                                       21
Anesi, V. and Bowen, T. (forthcoming). Policy Experimentation in Committees: a Case Against
  Veto Rights Under Redistributive Constraints. American Economic Journal: Microeco-
  nomics.

Banks, J. S. and Duggan, J. (2000). A bargaining model of collective choice. American Political
  Science Review, 94 (1), 73­88.

-- and -- (2006). A general bargaining model of legislative policy-making. Quarterly Journal
  of Political Science, 1 (1), 49­85.

Baron, D. P. (1996). A Dynamic Theory of Collective Goods Programs. The American Political
  Science Review, 90 (2), 316­330.

-- and Ferejohn, J. A. (1987). Bargaining and agenda formation in legislatures. American Eco-
  nomic Review, 7 (2), 303­309.

-- and -- (1989). Bargaining in Legislatures. The American Political Science Review, 83 (4),
  1181­1206.

Bowen, T. R. and Zahran, Z. (2012). On Dynamic Compromise. Games and Economic Behav-
  ior, 76, 391­419.

Burlingame, M. (2013). Abraham Lincoln: A Life, vol. 2. JHU Press.

Cai, H. and Treisman, D. (2009). Political Decentralization and Policy Experimentation. Quar-
  terly Journal of Political Science, 4 (1), 35­58.

Callander, S. (2011). Searching for Good Policies. American Political Science Review, 105,
  643­662.

-- and Hummel, P. (2014). Preemtive Policy Experimentation. Econometrica, 82 (4), 1509­
  1528.

Cooper, J. and Brady, D. (1981). Institutional Context and Leadership Style: The House from
  Cannon to Rayburn. American Political Science Review, 75 (2), 411­425.

Cox, G. W. (2001). Agenda setting in the us house: A majority-party monopoly? Legislative
  Studies Quarterly, pp. 185­210.

Cramton, P. (1992). Strategic Delay in Bargaining with Two-Sided Uncertainty. The Review of
  Economic Studies, 59 (1), 205­225.

Deneckere, R. J. and Liang, M. Y. (2006). Bargaining with interdependent values. Economet-
  rica, 74 (5), 1309­1364.



                                              22
Diermeier, D. and Fong, P. (2011). Legislative bargaining with reconsideration. The Quarterly
  Journal of Economics, 126 (2), 947­985.

Dixit, A. (2002). The Art of Smooth Pasting. Routledge.

Duggan, J. and Kalandrakis, T. (2012). Dynamic legislative policy making. Journal of Eco-
  nomic Theory, 147 (5), 1653­1688.

Eraslan, H., Evdokimov, K. and Zapal, J. (2020). Dynamic Legislative Bargaining. Working
  Paper.

Freer, M., Martinelli, C. and Wang, S. (2018). Collective Experimentation: A Laboratory
  Study. Working Paper.

Friedenberg, A. (2019). Bargaining Under Strategic Uncertainty: The Role of second-Order
  Optimism. Econometrica, 87 (6), 1835­1865.

Fudenberg, D., Levine, D. and Tirole, J. (1985). Infinite-Horizon Models of Bargaining with
  One-Sided Incomplete Information. In A. E. Roth (ed.), Game-Theoretic Models of Bargain-
  ing, Cambridge University Press, pp. 73­98.

Gieczewski, G. and Kosterina, S. (2019). Endogenous Experimentation in Organizations. Work-
  ing Paper.

Hirsch, A. V. (2016). Experimentation and Persuasion in Political Organizations. American
  Political Science Review, 110 (1), 68­84.

Hollander, E. P. (1978). Leadership dynamics: A practical guide to effective relationships.
  Free Pr.

Hwang, I. and Krasa, S. (2020). Leadership Ability and Agenda Choice. Working Paper.

Kalandrakis, T. (2004). A three-player dynamic majoritarian bargaining game. Journal of Eco-
  nomic Theory, 116 (2), 294­314.

Keller, G., Rady, S. and Cripps, M. (2005). Strategi Experimentation with Exponential Bandits.
  Econometrica, 73 (1), 39­68.

Lee, J. and Liu, Q. (2013). Gambling Reputation: Repeated Bargaining with Outside Options.
  Econometrica, 81 (4), 1601­1672.

Majumdar, S. and Mukand, S. W. (2004). Policy Gambles. The American Economic Review,
 94 (4), 1207­1222.

Millner, A., Ollivier, H. and Simon, L. (2014). Policy experimentation, political competition,
 and heterogeneous beliefs. Journal of Public Economics, 120, 84­96.

                                             23
Ortner, J. (2019). A continuous-time model of bilateral bargaining. Games and Economic Be-
  havior, 113, 720­733.

Perry, M. and Reny, P. (1993). A Non-cooperatiive Bargaining Model with Strategically Timed
  Offers. Journal of Economic Theory, 59, 50­77.

Powell, R. (2004). Bargaining and Learning While Fighting. American Journal of Political
  Science, 48 (2), 344­361.

Romer, T. and Rosenthal, H. (1979). Bureaucrats versus voters: On the political economy of
  resource allocation by direct democracy. The Quarterly Journal of Economics, 93 (4), 563­
  587.

Strulovici, B. (2010). Learning While Voting: Determinants of Collective Experimentation.
  Econometrica, 78 (3), 933­971.

Volden, C., Ting, M. M. and Carpenter, D. P. (2008). A Formal Model of Learning and Policy
  Diffusion. The American Political Science Review, 102 (3), 319­332.

Weber, M. (1922). Grundriss der Sozialökonomik, III. Abteilung, Wirtschaft und Gesellschaft.
 J.C.B. Mohr: Tübingen.

Yukl, G. (1989). Managerial leadership: A review of theory and research. Journal of Manage-
  ment, 15 (2), 251­289.




                                            24
7 Appendix
7.1 Proof of Proposition 1
In this proof, we show that there exists an equilibrium described in Proposition 1. Define p and
p as
                       
                         r++             r +  vc             
                                                    if vv       and u       
                       
                                     1-                 c
                                                          < r+        c
                                                                        < r+  ,
                       
                                                        ¯           u¯      +
                       
                                              v¯
                       
                                     
                               ¯ - r+
                       
                         r+v           v
                       
                  p =                                                                       (13)
                       
                                     c                       
                                                    if vv
                                                        c
                                                        ¯
                                                          < r+
                                                                and u
                                                                    u¯
                                                                      c
                                                                         r+ 
                                                                            +
                                                                              ,
                                 v
                                 ¯ - vc
                                                             
                                                    if vv
                       0
                                                        c
                                                        ¯
                                                           r+ 
                                                               ,

             ^ , p}, where
and p = max{ p

                        r++          ruc
                       
                                                                             uc          
                                                                        if   u¯
                                                                                  <   r ++
                                                                                           ,
                    ^ =
                    p
                            (r + )¯
                                  u - (r +  +  )uc                                                   (14)
                                                                             uc
                                                                                         
                       1                                                if                 .
                       
                                                                             u¯       r ++

Note that these are precisely the values calculated in (6) and (7) when vv
                                                                         c
                                                                         ¯
                                                                            (/(r +  +  ), /(r +  ))
and uc /u
        ¯ < /(r +  +  ). Recall that C = { p  [0, 1] : ( p)  A( p)} is the compromise set of a
Markovian profile. Then under the strategy profile described in Proposition 1 we have C for the
following cases:
                                          uc          
   · Case A: condition (5) holds and      u¯
                                               <   r ++
                                                        .   In this case, C = [ p, p] where p < 1.
                                          uc          
   · Case B: condition (5) holds and      u¯
                                                   r ++
                                                        .   In this case, C = [ p, 1].

   · Case C: condition (5) does not hold. In this case, C = .

In what follows, we first derive the players' value functions under the conjectured strategy pro-
file in each case. Then, we complete the proof by verifying each player's incentive conditions.

Value Functions Case A: First consider the profile in Case A, with C = [ p, p] where p < 1.
Observe that the belief dynamics imply that whenever p < p, the players will never reach a
compromise in the future and long-run gridlock occurs. Thus, the players' value functions are
Vi ( p) = Vi,d ( p) for any p < p. Moreover, for any p  [ p, p], the players always compromise at
the moment a new issue arrives, and thus Vi ( p) = Vi,c ( p), where Vi,c ( p) is the player i's payoff
under no gridlock. Therefore, it remains to derive the value functions for p > p.
     First, consider the setter's value function VS ( p) for p > p. In the interval [t, t + dt), the
probability that the setter successfully asserts is given by dt. In this case, the issue is resolved
and the setter receives utility u ¯ . In addition, the setter's type is now known to be high, i.e., the
belief jumps up to 1. With the complementary probability, the issue is not resolved in [t, t + dt),

                                                     25
and the belief drifts down to p + d p following Bayes' rule given by (1). Therefore, VS ( p) is
determined recursively by the equation

                                                     ^ S (1)) + (1 - pdt)e-rdt VS ( p + d p).
                     ¯ + e-rdt ( dtVS (1) + (1 -  dt)V
       VS ( p) = pdt u

                    ^ i ( p) is the dynamic payoff for player i after an issue has been resolved and
   As in Section 3, V
players await a new issue. By the same arguments, it follows that

                                         ^ i ( p) =    
                                         V               Vi ( p),
                                                      r+
for any p  [0, 1].
                                         
    Note that VS ( p + d p) = VS ( p) + VS ( p)d p, e-rdt  1 - rdt, and the belief dynamics in (1)
simplifies to d p = - p(1 - p)dt. Therefore,

       (1 - (1 - pdt)(1 - rdt))VS ( p) = pdt u                                  ^ S (1))
                                             ¯ + (1 - rdt)( dtVS (1) + (1 -  dt)V
                                                                 
                                            - (1 - pdt)(1 - rdt)VS ( p) p(1 - p)dt.

Note that we use 1 - rdt  e-rdt . Dropping terms with order of dt2 or higher, and substituting
             ^ S (1) yields the differential equation
the value of V

                                                                          
                   (r + p)VS ( p) = pu
                                     ¯ 1+                     -  p(1 - p)VS ( p).
                                                  r(r +  +  )

Solving the differential equation we get
                                                           r
                                           (1 - p)1+ 
                                VS ( p ) =      r     KS + VS ,d ( p),                           (15)
                                               p

where KS is the constant of integration. The boundary condition is given by VS ( p) = VS ,c , which
is the value matching condition at p = p.
     We now determine the responder's value function VR ( p) for p > p. Using a similar argument
as for the setter, the responder's value function is defined recursively as follows:

                                             ^ R (1)) + (1 - pdt)  dtv
     VR ( p) = pdte-rdt ( dtVR(1) + (1 -  dt)V                       ¯ + e-rdt VR ( p + d p) .

Simplifying the above equation yields the following differential equation

                                            p 2 v
                                                ¯                    
                      (r + p)VR ( p) =               + v
                                                       ¯ -  p(1 - p)VR ( p).
                                         r(r +  +  )
Solving the differential equation yields
                                                           r
                                           (1 - p)1+ 
                                VR ( p ) =      r     KR + VR,d ( p),                            (16)
                                               p

                                                      26
where KR is the constant of integration. Similar to the setter's case, the boundary condition that
determines KR is given by the value-matching condition at p = p, which is VR ( p  ¯ ) = VR , c .
Case B: Next, consider the strategy profile in Case B, in which C = [ p, 1]. For p  p, it
is straightforward that Vi ( p) = Vi,c for i = S , R. For p < p, the setter's value function is
recursively written as

                                                      ^ S ,c) + (1 - pdt)e-rdt VS ( p + d p).
                       ¯ + e-rdt ( dtVS ,c + (1 -  dt)V
         VS ( p) = pdt u

Note that if the setter successfully asserts her will, then the belief jumps to one and the players
compromise for all future issues. Simplifying the above equation yields

                        (r + p)VS ( p) = p(¯ ^ S ,c ) -  p(1 - p)VS
                                           u+V                    
                                                                    ( p).

Solving the differential equation yields
                                                     r
                                       (1 - p)1+             ^ S , c ) p,
                            VS ( p ) =      r     KS +    (¯
                                                           u+V
                                           p           r+

where KS is an integration constant. Since the boundary condition is VS (0) = VS ,d < , it must
be that KS = 0, and thus the
                                                         ^ S , c ) p.
                                     VS ( p ) =     (¯
                                                     u+V                                   (17)
                                                r+
    Similar to the setter's case, the responder's value function is recursively written as

                                             ^ R (1)) + (1 - pdt)  dtv
     VR ( p) = pdte-rdt ( dtVR(1) + (1 -  dt)V                       ¯ + e-rdt VR ( p + d p) ,

which simplifies to

                                           ^ R,c +  v
                         (r + p)VR ( p) = pV                      
                                                    ¯ -  p(1 - p)VR ( p).

Solving the differential equation and applying the boundary condition VR (0) = VR,d <  yield
                                                      ^ R , c p.
                                VR ( p ) = v¯-      v
                                                    ¯-V                                           (18)
                                          r    r+ r

Case C: The players' value functions in Case C--part 2 of Proposition 1--are straightforward.
Since the players never reach a compromise in the future,

                               Vi ( p) = Vi,d ( p)        for any p  [0, 1],

where Vi,d ( p) is player i's expected payoff under the long-run gridlock given in (2) and (3).




                                                         27
Equilibrium verification We are ready to verify the optimality of the candidate equilibrium
profile in each case.

Case A: Consider the candidate equilibrium profile in Case A. We proceed our analysis in each
of four belief regions: (i) p < p; (ii) p = p; (iii) p  ( p, p]; and (iv) p > p.

Case A1: p < p. In this case, the responder rejects any offer from the setter, and the setter
offers xs . Given the responder's behavior, the setter's incentive condition is trivially satisfied.
Therefore, it suffices to check if the responder rejects a compromise offer xc if the setter deviates
and makes such proposal. This requires that
                                                          ^ R,d ( p).
                                          VR,d ( p)  vc + V

This inequality simplifies to

                                    VR , d ( p )  VR , c        for any p < p.                          (19)

Since VR,d ( p) is decreasing in p, the above inequality is satisfied if and only if

                                                VR , d ( p )  VR , c .                                  (20)
                       
From (6) if vv¯
               c
                  ( r+     ,  ), then p is such that VR,d ( p) = VR,c , so this is satisfied. If vv
                        + r +
                                                                                                  c
                                                                                                  ¯
                                                                                                       r+
                                                                                                          +
                                                                                                            ,
                                                                             (r +)      r +        vc    
then p  1. At p = 1 using (3) and (4) we have (20) simplified to r(r++) v           ¯  r vc or v    ¯
                                                                                                       r++
                         vc    
so this is satisfied. If v¯
                              r+ , then p = 0 and the case of p < p does not exist.

Case A2: p = p. We check two incentive conditions for the responder: (a) incentive to accept
xc ; and (b) incentive to reject xs .
     If the responder accepts the setter's offer xc , then the belief stays the same and there will be
an agreement at xc for all future periods. If the responder rejects the offer, then learning occurs.
With probability pdt the setter is successful and the issue is resolved with position xs . With
the complementary probability, however, the setter is not successful, in which case the current
issue continues and the belief declines. Therefore, the responder is better off accepting the offer
xc if
                                          ^ R (1)) + (1 - pdt)  dtv
   VR ( p)  pdte-rdt ( dtVR(1) + (1 -  dt)V                       ¯ + e-rdt VR ( p + d p) .             (21)

Since p = p, if the responder rejects xs and the setter fails to overturn, then the belief goes out
of the compromise region, after which the players engage in the permanent gridlock. Therefore,
the incentive condition (21) becomes
                                          ^ R(1)) + (1 - pdt)  dtv
      VR,c  pdte-rdt ( dtVR(1) + (1 -  dt)V                      ¯ + e-rdt VR,d ( p + d p) .

Dropping the terms with orders of dt and higher, we have

                                                VR,c  VR,d ( p).                                        (22)

                                                           28
                      
As before if vv
              ¯
               c
                  ( r+   ,  ), then p is such that VR,d ( p) = VR,c , so this is satisfied. If vv
                       + r +
                                                                                                c
                                                                                                ¯
                                                                                                   r+  
                                                                                                        +
                                                                                                          ,
                                                       vc     
then p  1, so this does not apply for Case A. If v      ¯
                                                            r+ , then p = 0 and (22) simplifies to
r +               vc   
    v  v
  r c
          ¯/r or v ¯
                      r+ .
     We also need to check that the responder prefers to reject xs when it is offered by the setter,
i.e., xs A( p). The responder's payoff from accepting xs is given by V      ^ R ( p), and her payoff from
rejecting xs is identical to the right-hand side of (21). Therefore, VR ( p) must satisfy

     ^ R ( p)  pdte-rdt ( dtVR(1) + (1 -  dt)V
     V                                       ^ R (1)) + (1 - pdt)  dtv
                                                                     ¯ + e-rdt VR ( p + d p) .

Dropping the terms with order of dt and higher from the above inequality, we have

                                            ^ R ( p)  VR ( p),
                                            V

which is trivially satisfied.
    Next, consider the setter's incentive at p = p. Given that the responder accepts xc , the setter
prefers to offer xc rather than to offer xs if

                                         ^ S ,d (1)) + (1 - pdt)e-rdt VS ,d ( p + d p).
                               u + e-rdt V
                    VS ,c  pdt(¯

Dropping the terms with orders of dt and higher yields VS ,c  VS ,d ( p), or

                                          vc        uc
                                                 1-    .                                              (23)
                                          v¯  r+    u¯
This is satisfied since condition (5) holds.
    Also, note that the argument in Case 2 shows the necessity of condition (5): If (5) does
not hold, then either (22) or (23) would be violated, and thus the candidate profile in part 1 of
Proposition 1 cannot be an equilibrium.

Case A3: p  ( p, p]. Next, we analyze the players' incentive condition in the "compromise
interval" ( p, p]. Note that this interval exists only if p < p.
    First observe that the responder's incentive condition to accept xc for p  ( p, p] is identical
to (21). However, in contrast to Case 2, the belief after the setter's failure for a small period of
time is still in the compromise region. Therefore, (21) becomes

                                                ^ R,d (1)) + (1 - pdt)  dtv
         VR,c  pdte-rdt ( dtVR,d (1) + (1 -  dt)V                         ¯ + e-rdt VR,c .

Dropping terms with orders of (dt)2 and higher, we get

                                               ^ R,d (1) + rVR,c   v
                                   p  VR , c - V                   ¯.                                 (24)

   A simple calculation shows that (24) holds for all p > p as long as p < 1 which is the case
when p  ( p, p]. Furthermore, the responder's incentive condition to reject xs is identical to the
one in Case 2, and thus is trivially satisfied.

                                                    29
    Next, consider the setter's incentive constraints for p  ( p, p], in which the setter must prefer
offering xc (which is immediately accepted) to offering xs (which is rejected). Since the belief
after the setter's failure remains in the compromise set, then we require
                                                          ^ S ,d (1) + (1 - pdt)e-rdt VS ,c .
                       ¯ + e-rdt ( dtVS ,d (1) + (1 -  dt)V
            VS ,c  pdt u

Eliminating terms with orders of dt2 and higher and reorganizing yield
                                                         uc             uc
                            p (r + ) - (r +  +  )            r(r +  +  ) .                             (25)
                                                         ¯
                                                         u              ¯
                                                                        u
It is easy to check that (25) holds if and only if p  p    ^ , where p
                                                                     ^ is defined in (14). Since Case 3
assumes the case where p  ^=p  ¯ , it follows that the setter's incentive is satisfied for any p  ( p, p¯ ].
     Equations (13) and (14) imply that given that (5) holds (so that p < 1), p < p       ^ if and only if
                                                                       u
                                  vc      (r + ) - (2r +  +  ) u   ¯
                                                                    c

                                     >                                .                                (26)
                                  v¯   r +  (r + ) - (r +  +  ) u
                                                                u¯
                                                                  c



Therefore, the compromise region is a nondegenerate interval (i.e., p < p) if and only if (26)
holds.

Case A4: p > p. First, observe that the integration constraints KS and KR in equations (15)
and (16) must be nonnegative. To see this, note that it is straightforward to show KR  0 from
(16): At p = p, the boundary condition is given by VR ( p) = VR,c ; but VR,c is no less than than
VR,d ( p) since p  p. Similarly, one can easily check that VS ,c  VS ,d ( p), which implies that KS
is nonnegative.
    For p > p, the responder accepts xc when it is offered. Therefore, her incentive condition is
vc + V ^ R ( p)  VR ( p), or
                                  VR,c  VR ( p) for all p > p.                                 (27)
This condition is immediately satisfied since KR is nonnegative, which implies (from (16)) that
VR ( p) is decreasing and strictly convex for p > p. Given the responder's strategy, the setter
                                                                               ^ S ( p)  VS ( p), which
prefers to offer xs rather than to offer xc . This incentive condition is uc + V
is equivalent to
                                    VS ,c  VS ( p) for all p > p.                                  (28)
Again, the fact that KS is nonnegative implies that the incentive condition is satisfied.
Case B: Next, we consider the case in which (5) holds and uc /u    ¯  /(r +  +  ), and check
the optimality of the candidate profile that C = [ p, 1]. Much of our analysis here will be based
on the results in Case A. First, consider the responder's incentive. The analysis in Cases 1A
and 1B imply that the responder's incentives at p < p and p = p are satisfied if and only if
VR ( p) = VR,c . From (18), we have
                                                       
                                                ¯ - r+
                                              r+v     c
                                                        v
                                           p=             ,
                                                  v
                                                  ¯ - vc

                                                    30
which is identical to (13). For the setter's incentive, it suffices to check if the setter prefers to
offer xc than to offer xs when p = 1. This condition is given by
                                                         ^ S ,c + (1 - dt)e-rdt VS ,c .
                          ¯ + e-rdt ( dtVS ,c + (1 -  dt)V
                VS ,c  dt u

Cancelling out terms with orders of dt or higher and simplifying yields uc /u
                                                                            ¯  /(r +  +  ),
and thus the setter's incentive is satisfied.
Case C: It remains to verify that if (5) is violated, the candidate profile in Case C is optimal
for each player. Note that the argument in Case A1 implies that the responder accepts xc if and
only if p  p. For the setter, her incentive condition for p < p is trivial (and identical to that of
Case A). Therefore, it remains to verify the setter's incentive condition for p  p.
    For p  p, the setter prefers to offer xs than to offer xc if

                               ^ s, d ( p )  VS , d ( p )
                          uc + V                                    V s, d ( p)  V s, c .

Since VS ,d ( p) increases in p, it suffices to check the condition at p = p. Plugging in p = p yields
the condition (23) with the reversed inequality. Therefore, the setter's incentive condition holds
if (5) is violated.


7.2 Proof of Proposition 2
Recall that a compromise set of a Markovian strategy profile is defined as C  { p  [0, 1]|( p) 
A( p)}. We first prove the following lemma.

Lemma 1 In any Markov perfect equilibrium, the following is satisfied:

   1. For any p  [0, 1], x0  A( p) and xs              A( p);

   2. For any p  C, ( p) = xc and A( p) = { x0 , xc };

   3. For any p     C, ( p) = xs ; A( p) = { x0 , xc } if VR ( p)  VR,c and A( p) = { x0 } otherwise.

Proof of Lemma 1. Item 1: First we show that x0  A( p) for any p  [0, 1]. For any p  C,
accepting x0 is obviously the responder's optimal choice. For p C, the responder prefers to
accept x0 if v
             ¯+V ^ R ( p)  VR ( p), or VR ( p)  (r +  )¯
                                                       v/r. This inequality is always satisfied, since
the responder's best possible payoff is (r +  )¯  v/r (when x0 is implemented without any delay).
    To show that xs A( p) for any p, suppose to the contrary that there exists a Markov perfect
equilibrium in which xs  A( p) for some p. Then it must be optimal for the setter to offer xs ,
since doing so would yield the best possible payoff for him. Therefore VR ( p) = 0, and thus
rejecting the offer is a profitable deviation for the responder.
Item 2: Given the behavior of the responder in Item 1, the setter would never offer x0 for any
p, since doing so would yield a payoff of zero to him. Then it follows trivially that whenever
p  C (i.e., ( p)  A( p)), it must be that (( p), A( p)) = ( xc , { x0, xc }).

                                                            31
Item 3: Consider any p          C. It is straightforward that ( p) = xs if A( p) = { x0 , xc }). If
A( p) = { x0 }), then the proposer is indifferent between proposing xc and xs , then our equilibrium
requirement implies that he proposes xs .
    For the responder, he prefers to accept xc for any p C if and only if

                                              ^ R ( p)  VR ( p),
                                         vc + V

which is equivalent to VR ( p)  VR,c .

    Given the result in Lemma 1, we focus on finding the equilibrium compromise set C, which
enables us to characterize the equilibrium profile. The next lemma is the first step in character-
izing the equilibrium C.

Lemma 2 If a Markov perfect equilibrium has non-empty compromise set C, it must be that
inf C = p, where p is given in (13).


Proof of Lemma 2. Let p = inf C. Since C is closed, it follows that p  C. Then by Lemma
1, ( p ) = xc and ( p) = xs for all p < p . Then the responder's incentive conditions at p < p
and p = p are given by (20) and (22), respectively, with p replaced with p . Therefore, it must
be that VR,c = VR,d ( p ), which implies that p = p.

    Lemma 2 implies that the compromise set of any Markov perfect equilibrium must be one
of the following three types: (1) C = ; (2) C = { p}; and (3) C { p} and inf C = p. Below,
we show that there exists a unique candidate equilibrium profile for each type, and derive the
parametric conditions for existence of each type of equilibrium.
Case 1: C = . In this case, Lemma 1 implies that x( p) = xs for any p. Since the equilibrium
features a permanent gridlock, the players' value functions are Vi ( p) = Vi,d ( p). Then by the
definition of p (equation 13), VR ( p)  VR,c if and only if p  p. Therefore, by Lemma 1,
A( p) = { x0 , xc } for p  p and A( p) = { x0 } for p < p, providing the unique candidate equilibrium
profile. Note that this profile is the one analyzed in the proof of Proposition 1. The proof shows
that this profile exists if and only if (5) does not hold.
Case 2: C = { p}. Next, consider a strategy profile with C = { p}. By Lemma 1, x( p) = xc
if p = p and x( p) = xs otherwise. Then the responder's value function under this profile is
given by VR ( p) = VR,d ( p). Then by the same logic as Case 1, A( p) = { x0 , xc } for p  p and
A( p) = { x0 } for p < p, which provides the unique candidate equilibrium profile. Again, the
existence condition for this equilibrium profile is analyzed in the proof of Proposition 1: The
unique candidate profile in Case 2 exists if and only if (5) holds and (26) is violated.
Case 3: C { p} and inf C = p. We claim that in Case 3, there exists a unique equilibrium
compromise set, which is an interval [ p, p    ^ ] where p
                                                         ^ is given in (14).
                                      
    Let p = sup C > p, then p  C since C is closed. Since the players never reach an
agreement for any p > p , the responder's value function for p > p is given by (16), with the

                                                   32
boundary condition VR ( p ) = VR,c . Since p > p, it must be that VR,d ( p ) < VR,c . Therefore,
it follows from (16) that KR > 0 and that VR ( p) < VR,c for all p > p . Then Lemma 1 implies
that A( p) = { x0 , xc } for p  p . Since the responder's behavior is constant for p  [ p , 1], the
setter's value function VS ( p) must satisfy both value-matching and smooth-pasting conditions
at p = p . Since the setter's value function for p > p is given by (15), The value-matching
and smooth-pasting conditions are given by
                                               r
                                    (1 - p )1+ 
                           VS , c =         r    KS + VS ,d ( p ),
                                       (p ) 
                                               r
                                      (1 - p )   r                         
                              0 = -  1+ r p +                KS + VS ,d ( p ),
                                       (p )            
respectively. Solving above system shows that
                                     r++          ruc
                             p =                                ,
                                         (r + )¯
                                               u - (r +  +  )uc
which coincides with p   ^ given in (14). If the above formula is above one, then the boundary
conditions do not hold at any p  [0, 1] and it must be that p = 1.
    Next, we finish our claim by showing that there does not exist p  ( p, p) such that p
C. Suppose to the contrary that there exists such p . Then the closedness of C implies that
( p - , p +  )  [0, 1] \ C for sufficiently small  > 0. Let p be an infimum of a connected
interval in [0, 1] \ C which contains p . Then since p  p, the same logic used to show p = p
implies that the responder should accept xc for p  ( p - , p ], which in turn implies that the
setter's value function must satisfy the both value-matching and smooth-pasting conditions at
p = p . But then it implies that p = p ^ , leading to a contradiction.
    This argument provides the unique candidate equilibrium profile in Case 3:
                                                               
                            xc if p  [ p, p
                                              ^]               { x0 , xc } if p  p
                                                               
                    ( p) =                           A ( p ) = 
                            xs otherwise,                      { x0 }      if p < p.
                                                               

Again, this profile is analyzed in proof of Proposition 1; this profile exists if and only if both (5)
and (26) hold.


7.3 Proof of Proposition 3
First, it is straightforward from (13) and (14) that p and p
                                                           ¯ is continuous in all parameters. Define
                                                                        
                          r++    r +  vc                         ¯ - r+
                                                               r+v     c
                                                                         v
                      p =     1-         ,                 p =             ,
                       a            v  ¯                    b      ¯ - vc
                                                                   v
and
                                     r++          ruc
                              ^a =
                              p                                 ,
                                         (r + )¯
                                               u - (r +  +  )uc

                                                   33
Then we show the desired results by analyzing the comparative statics of p , p , and p    ^a.
                                                                               a   b
Item 1: Consider the comparative statics with respect to r. First, p^ a is strictly increasing in r,
because
                      p^ a uc (((r + )2 + )¯   u - (r +  +  )2 uc )
                           =                                         > 0.                      (29)
                       r                 u - (r +  + )uc )2 
                                  ((r + )¯
In particular, (29) is strictly positive because

                                        uc        (r + )2 + 
                                           <                   .
                                        u¯   r++   (r +  +  )2
Taking derivatives of p and p with respect to r yields
                        a           b

                                                2r +2+                                2r ++
                            p           v
                                        ¯-          
                                                       vc            p           v
                                                                                 ¯-       
                                                                                            vc
                                a                                        b
                                    =                       ,                =                   .
                            r                    v
                                                 ¯                   r           (¯
                                                                                  v - vc )
Both derivatives are strictly negative since (5) implies that vc /v
                                                                  ¯ > /(r +  + ).
Item 2: It is straightforward that p and p are strictly decreasing in . For p ^a,
                                            a         b

                     ^ a ruc ((r +  +  )2 uc - ((r + )2 + (2 + r) u
                     p                                            ¯ ))
                        =                                  2 2
                                                                       < 0,                          (30)
                                  ((r + )¯
                                         u - (r +  + )uc ) 
because
                            uc (r + )2 +  (r + )2 + (2 + r)
                               <                            .
                            u¯   (r +  +  )2  (r +  +  )2
Item 3: Taking the derivatives with respect to  yields
                                p           r(r + )vc +  2 (¯
                                                            v - vc )
                                    a
                                        =             2
                                                                     > 0,
                                                    v
                                                    ¯ 
                                p      r(r + )
                                    b
                                        =           > 0,
                                      2(¯ v - vc )
                                p
                                ^a            uc u¯ r(r + )
                                   =                             > 0,
                                     ((r + )¯u - (r +  + )uc )2 


showing the desired results.




                                                                34
Online Appendix: Proof of Propositions 4 and 5
We first derive the players' value functions in each type of equilibrium. Observe that the two
types of equilibrium differ only in the behavior at p = p . Therefore, the differential equations
                                                         
underlying both value functions are identical, and they differ only in the boundary conditions at
p = p . After obtaining the value functions, we verify each type of equilibrium by investigating
      
the players' incentive conditions.

Value functions Let Vi ( p), i = S , R be the value function under the easy issues, and let Wi ( p)
be the value function under the difficult issues. Also, for notational simplicity, define Zi ( p) to
be the value function when the new issue arises, and define Z ^i ( p) as the value function when the
current issue is resolved (but the new issue has not yet appeared). Then it is straightforward that

                               Zi ( p) = (1 - )Vi ( p) + Wi ( p),                                 (31)
                               ^i ( p) =  (1 - )Vi ( p) + Wi ( p) .
                               Z                                                                  (32)
                                         r+
     Observe that for p < p , regardless of the issue type, permanent gridlock occurs in equilib-
                            
rium. Therefore, Vi ( p) = Wi ( p) = Vi,d ( p).
     Next, we derive the value functions for p  ( p , p ]. Consider first the setter's value func-
                                                        
tion. Under the easy issue, the setter offers xc and the responder accepts the offer. Therefore,
VS ( p) satisfies
                                                                     ^ S ( p) .
                          VS ( p) = uc + e-rdt  dtZS ( p) + (1 -  dt)Z
Cancelling the terms with order dt or higher, applying (31) and (32) and simplifying yield
                                                  rVS ,c + WS ( p)
                                     VS ( p ) =                    .                              (33)
                                                         r + 
Under the difficult issue, the setter offers xs and the responder rejects the offer. Therefore, WS ( p)
satisfies
                                                                ^ S ,d (1))
                             ¯ + e-rdt ( dtVS ,d (1) + (1 -  dt)V
               WS ( p) = pdt u
                                                                                                  (34)
                         + (1 - pdt)e-rdt  dtZS ( p + d p) + (1 -  dt)WS ( p + d p) .

Cancelling the terms with order dt2 or higher, applying (31) and (32), and reorganizing yields
                  
         p(1 - p)WS ( p) = p(¯ ^ S ,d (1)) +  (1 - )VS ( p) - ( p + r +  (1 - ))WS ( p).
                             u+V

Plugging in (33) and solving the differential equation yield
                                                          g-b
                                  WS ( p) = f ( p)KS +        p + b,                              (35)
                                                          µ+1


                                                     35
where
                       (1 - p)µ+1          r(r +  )           ^ S ,d (1),                ^ S ,c
            f ( p) =              ,   µ=            ,    g=u
                                                           ¯ +V                b = (1 - )V        (36)
                           pµ              (r + )
and KS is an integration constant.
    Now consider the responder. Similar to (33), the responder's value function under the easy
issues are given by
                                              rVR,c + WR ( p)
                                   VR ( p ) =                 .                           (37)
                                                   r + 
Under the difficult issues, the setter offers xs and the responder rejects the offer. Therefore,
WR ( p) satisfies

                                                     ^ R,d (1))
          WR ( p) = pdte-rdt ( dtVR,d (1) + (1 -  dt)V
                                      ¯ + e-rdt  dtZR ( p + d p) + (1 -  dt)WR ( p + d p) .
                       + (1 - pdt)  dtv

Cancelling the terms with order dt2 or higher, applying (31) and (32), and reorganizing yields
                  
         p(1 - p)WR         ^ R,d (1) +  v
                    ( p) = pV            ¯ +  (1 - )VR ( p) - ( p + r +  (1 - ))WR ( p).

Solving this equation with (37) gives

                              1              r +                   ^ R,c + V
                                                                           ^ R,d (1) p ,
     WR ( p) = f ( p)KR +        (µ + 1 - p)      VR,d (0) + (1 - )V                              (38)
                             µ+1              r+

where KR is an integration constant.
     For p > p , gridlock arises in both the easy and the difficult policy issues. For the setter,
VS ( p) satisfies

                                                                 ^ S ,d (1))
                              ¯ + e-rdt ( dtVS ,d (1) + (1 -  dt)V
                VS ( p) = pdt u
                            + (1 - pdt)e-rdt  dtZS ( p + d p) + (1 -  dt)VS ( p + d p) ,

and WS ( p) satisfies (34). Simplifying, we have
                        
               p(1 - p)VS ( p) = g p + WS ( p) - ( p + r + )VS ( p).
                        
                                                                                                  (39)
               p(1 - p)WS ( p) = g p +  (1 - )VS ( p) - ( p + r +  (1 - ))WS ( p),

where g is defined in (36). Similarly, VR ( p) and WR ( p) jointly solve
                
       p(1 - p)VR        ^ R,d (1) p +  v
                  ( p) = V              ¯ + WR ( p) - ( p + r + )VR ( p).
                                                                                                  (40)
                         ^ R,d (1) p +  v
       p(1 - p)WR ( p) = V              ¯ +  (1 - )VR ( p) - ( p + r +  (1 - ))WR ( p).




                                                    36
Solving the systems (39) and (40) yield the value functions
                                                          
                VS ( p) = KS 1 h1 ( p) + KS 2 h2 ( p) +       gp                                    (41)
                                                       r+
                              -1                                
               WS ( p) = KS 1        h1 ( p) + KS 2 h2 ( p) +         gp                            (42)
                                                              r+
                                                               ^ R,d (1) -  v         
               VR ( p) = KR1 h1 ( p) + KR2 h2 ( p) +           V               ¯ p+ v   ¯           (43)
                                                       r+                    r        r
                              -1                                       ^ R,d (1) -  v     
               WR ( p) = KR1         h1 ( p) + KR2 h2 ( p) +           V             ¯ p+ v ¯,      (44)
                                                              r+                   r      r
where KS 1 , KS 2 , KR1 , KR2 are integration constants and

                               (1 - p)+1             (1 - p)+1     r+    r
                     h1 ( p) =       
                                         , h2 ( p) =       
                                                               , =    , = .
                                   p                     p               

Equilibrium Verification: Gridlock Equilibrium In the first type of equilibrium--gridlock
equilibrium--the setter induces gridlock for any p when the current policy issue is a difficult
one. Therefore, if players currently face a difficult policy issue and p = p , there will be
                                                                               
permanent gridlock. Thus, the boundary conditions for Wi are given by Wi ( p ) = Vi,d ( p ). Then
                                                                                         
from (33) and (37), we have
                                                     rVS ,c + VS ,d ( p )
                                                                           
                                      VS ( p ) =                              ,                     (45)
                                                           r + 
                                                     rVR,c + VR,d ( p )
                                                                           
                                      VR ( p ) =                              .                     (46)
                                                                  r + 
Given this boundary condition, let us verify the incentive constraints of each player.

Case 1: p < p . In this case, we only need to verify the responder's incentive condition to
                 
reject xc under easy issues. Same as the benchmark model, this condition is given by

                                   VR , c  VR , d ( p )           for any p < p .
                                                                                  

Since VR,d ( p) is decreasing in p, the above inequality holds if and only if

                                                      p  p,                                         (47)
                                                          

where p is given in equation (13).

Case 2a: p = p under a easy policy issue. First, consider the responder's incentives. Under
                 
easy issues, the responder must accept xc at p = p . This condition is given by
                                                                  

                                             ^ R,d (1)) + (1 - pdt)  dtv
  VR ( p )  pdte-rdt ( dtVR,d (1) + (1 -  dt)V                         ¯ + e-rdt VR,d ( p + d p) .
                                                                                                 



                                                             37
Deleting terms with order dt or higher and reorganizing yield
                                
                        vc +      ((1 - )VR ( p ) + WR ( p ))  VR,d ( p ).
                               r+                                      


Plugging in WR ( p ) = VR,d ( p ) and (46), and simplifying yield
                                

                                   VR , c  VR , d ( p )           p  p.                            (48)
                                                                  

Combining (47) and (48) implies that
                                                r++    r +  vc
                                   p =p=            1-         .                                   (49)
                                                          v  ¯
     Since the setter prefers to offer xc than to offer xs at p = p under easy issues, the setter's
incentive condition is given by VS ( p)  VS ,d ( p). By (45), this condition simplifies to VS ,c 
VS ,d ( p), or
                                        vc               uc
                                                     1-      .                                (50)
                                         v
                                         ¯    r+          ¯
                                                          u
Note that (50) is identical to (23), the corresponding condition in the benchmark case.

   Given the result of (49), we denote p instead of p in the remaining of the proof.
                                                               

Case 2b: p = p under a hard policy issue. The responder must prefer to reject xs than to
accept the offer, and thus her incentive condition is given by
                                              r
                             VR , d ( p )       ((1 - )VR ( p) + WR ( p)).
                                             r+
                                                                                               ^ R,c ,
Since (49) implies that VR ( p) = WR ( p) = VR,d ( p), the above condition simplifies to VR,c  V
which is trivially satisfied.
    Consider the setter's incentive to offer xs at p = p. Because she must prefer offering xs to
offering x0 , her incentive condition is given by

                                                                     ^ S ( p)).
                            VS ,d ( p)  e-rdt ( dtZS ( p) + (1 -  dt)Z

Plugging in (45) and (49), and simplifying yield
                                       vc         (1 - ) uc
                                              1-            ,                                      (51)
                                       v¯  r+      r+ u   ¯
which is given by condition (10) in Proposition 4.

Case 3a: p  ( p, p ] under a easy policy issue. In this case, the responder prefers to accept xc
than to reject. Therefore, her incentive condition is

                   ^ R,d (1) + (1 - pdt)( dt(¯
 VR ( p)  pdte-rdt V                         v + e-rdt ZR ( p + d p)) + (1 -  dt)e-rdt VR ( p + d p)).

                                                          38
Simplifying yields
                                   ^ R,d (1) +  v
               (r + p + )VR ( p)  pV                                    
                                                ¯ + WR ( p) -  p(1 - p)VR ( p)

Using (33), we reorganize the condition as

                ^ R,d (1) - VR,c) -  v                     p ^                                
  rVR,c - p(V                        ¯   VR,d (0) - VR,c +    (VR,d (1) - WR ( p) - (1 - p)WR  ( p)) .
                                                            r
                                                                                                   (52)
Note that if  = 0, (52) becomes identical to (24), which is the corresponding incentive condi-
tion in the benchmark model. Then the corresponding argument in the proof of Proposition 1
(page 29) shows that (24) is satisfied for all p > p. Moreover, a calculation shows that the right
side of (52) is negative for all p > p, implying that (52) is satisfied for all p > p. Intuitively, the
responder has a stronger incentive to accept xc when  > 0 compared to the case with  = 0,
because rejecting might lead to the replacement of a difficult policy issue.
    Next, consider the setter's incentive condition. Since the setter prefers to offer xc then to
offer xs , her incentive condition is given by
                           ^ S ,d (1)) + (1 - pdt)e-rdt ( dtZS ( p + d p) + (1 -  dt)VS ( p + d p))
                 u + e-rdt V
    VS ( p)  pdt(¯

Simplifying and plugging in (33), we have
                                                    p                         
              rVS ,c - p(g - VS ,c )   -VS ,c +        (g - WS ( p) - (1 - p)WS ( p)) ,             (53)
                                                     r
                                                             
where g is defined in (36). From (35), g - WS ( p) - (1 - p)WS ( p) = f ( p) µ K +
                                                                             p S
                                                                                            µ
                                                                                           µ+1
                                                                                               (g   - b).
Therefore, (53) becomes
                                                     r+             g-b
                rVS ,c - p(g - VS ,c ) +  VS ,c -        f ( p)KS +     p          0.               (54)
                                                    r +             µ+1
We show that the left side of (54) is concave. First, observe that f ( p) is convex. Second, note
that KS must be positive. If KS is negative, then VS ( p) must be concave by (33), but this leads
to a negative value of information under a easy policy issue. This is a contradiction because
there cannot be any loss of learning from the belief drifting down but there exists the upside
gain when the belief jumps to one. Therefore, if (54) is satisfied at p = p, then there exists
p  ( p, 1] such that (54) is satisfied for p  ( p, p ]. If (54) is not satisfied at p = p, then (since
(50) holds) the players compromise only at p = p.

Case 3b: p  ( p, p ] under a hard policy issue.
   In this case, the responder's incentive condition to reject xs is identical to that in Case 2b.
given by
                                                                 ^ R ( p)).
                           WR ( p)  e-rdt ( dtZR ( p) + (1 -  dt)Z
Cancelling out terms with orders of dt or higher, plugging in (33) and reorganizing yield
                                                       ^ R,c ,
                                        WR ( p)  (1 - )V

                                                  39
which is trivially satisfied. The setter's incentive condition to propose xs is

                                                                  ^ S ( p)).
                            WS ( p)  e-rdt ( dtZS ( p) + (1 -  dt)Z

Plugging in value functions and simplifying yields

                                                        ^ S ,c .
                                         WS ( p)  (1 - )V

The analysis in Case 2b shows that the above condition holds at p = p if and only if (51) is
satisfied. Then since WS ( p) is strictly decreasing in p, it follows that the above condition is
satisfied for all p  ( p, p
                          ¯  ] if (51) holds.

Case 4: p > p . Let us consider the setter's incentive condition under the easy issue. He must
prefer to offer xs than xc .

                                                                     ^ S ( p)).
                          VS ( p)  uc + e-rdt ( dtZS ( p) + (1 -  dt)Z

Similar to above, cancelling out terms with order of dt or above and reorganizing yield

                                  (r + )VS ( p) - WS ( p)  rVS ,c .                               (55)

Plugging in (41) and (42) and reorganizing yield
                                         r              
                         KS 1 g( p) +      KS 2 h( p) +    g p  uc .                              (56)
                                        r+              +r
     We claim that (56) holds for all p  p                         ¯  < 1. Note that by (33) and the
                                                     ¯  given that p
continuity of VS ( p) and WS ( p) at p = p      ¯  , (55) holds with equality at p = p
                                                                                     ¯  . Therefore, it
suffices to show that the left-hand side of (56) is increasing in p.
                          ¯  ) > WS ( p
     Note that since VS ( p           ¯  ), it follows from (41) and (42) that KS 1 > 0. Now suppose
to the contrary that the left-hand side of (56) is strictly decreasing at p = p > p         ¯  . Since
KS 1 > 0, it must be that KS 2 < 0. Then comparing the left-hand side of (56) and VS ( p) in
(41) implies that VS ( p) must be strictly decreasing at p = p . However, VS ( p) must be strictly
increasing for all p > p¯  since having a higher p does not incur any cost to the setter, leading to
a contradiction.

Equilibrium Verification: Avoiding-the-issue Equilibrium In the avoiding-the-issue equi-
librium, the setter offers x0 to induce compromise at p = p under difficult policy issues. Then
                                                              
the value of VS ( p ) and WS ( p ) satisfy the following system of equations:
                                

                                             
                         VS ( p ) = u c +      (1 - )VS ( p ) + WS ( p )
                                            r+                        

                                         
                         WS ( p ) =        (1 - )VS ( p ) + WS ( p )
                                        r+                        



                                                   40
Similarly, VR ( p ) and WR ( p ) jointly solve
                              

                                         
                          VR ( p ) = vc +   (1 - )VR ( p ) + WR ( p )
                                        r+                         

                                         
                         WR ( p ) = v
                                    ¯+     (1 - )VR ( p ) + WR ( p )
                                       r+                         


Solving the above systems yields the boundary conditions at p = p :
                                                                          

                                  (1 - )                               
                VS ( p ) = u c +          uc ,         VR ( p ) = vc + ((1 - )vc + v¯),
                                     r                                 r
                            (1 - )                                    
                WS ( p ) =           uc ,              WR ( p ) = v
                                                                  ¯ + ((1 - )vc + v¯).
                               r                                      r

Case 1: p < p . For p < p , the players' incentive conditions are identical to those in the
                             
gridlock equilibrium. Therefore, the profile must satisfy (47), or equivalently,

                                                 p  p,                                          (57)
                                                    

where p is defined in Proposition 1.

Case 2b: p = p under a easy policy issue. First, the responder must prefer to accept xc at
               
p = p . Same as the gridlock equilibrium, this condition is given by
      

                                             ^ R,d (1)) + (1 - pdt)  dtv
  VR ( p )  pdte-rdt ( dtVR,d (1) + (1 -  dt)V                         ¯ + e-rdt VR,d ( p + d p) .
                                                                                          

Deleting terms with order dt or higher, plugging in the value of WR ( p ) and VR ( p ) and simpli-
                                                                                    
fying yields
                                        
                                 VR,c + (¯  v - vc )  VR,d ( p ).                             (58)
                                         r                    

Note that the above incentive condition is strictly weaker than the corresponding condition in
the gridlock equilibrium (equation 48). Solving for p , we have
                                                             

                                       r++          r +  (1 - ) vc
                         p p               (1 - ) -                .                            (59)
                                   0                            v¯

It is straightforward to check that p < p for any  > 0.
                                      0
     For the setter, she must prefer to offer xc than to offer xs at p = p , and thus her incentive
                                                                          
condition is
                                         VS ( p )  VS ,d ( p ).
                                                                

As we shall see, this condition is strictly weaker than the corresponding condition under the
hard policy issue (equation 60).


                                                       41
Case 2b: p = p under a hard policy issue. In this case, the responder prefers to accept x0 ,
                   
and thus her incentive condition is given by WR ( p )  VR,d ( p ). It is straightforward to show
                                                                 
that this condition is strictly weaker than (58).
    Next, consider the setter's incentive to offer x0 at p = p . Since she must prefer offering x0
                                                              
than offering xs , her incentive condition is given by

                                      rWS ( p )  VS ,d ( p ).                                (60)
                                                          

Reorganizing with respect to p yields
                               

                                          r +  +   (1 - ) uc
                                p p
                                  ~              ·                                           (61)
                                                    r+ u   ¯
Combining (57), (59), and (61) implies that p  [ p , min{ p, p
                                                             ~ }]. Such p exists if and only if
                                                  0                      
p p ~ , or
 0
                              vc      (1 - )           uc
                                               1-              ,
                              v¯   r +  (1 - )       r+ u  ¯
which is the binding condition in Proposition 5.

Case 3 & 4: p > p . For each p  [ p , min{ p, p      ~ }], an argument identical to that for the
                                           0
gridlock equilibrium shows that the incentive conditions for p > p are satisfied.
                                                                    




                                                42
