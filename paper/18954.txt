                                NBER WORKING PAPER SERIES




                             IMPROVING GDP MEASUREMENT:
                          A MEASUREMENT-ERROR PERSPECTIVE

                                         S. Bora«ßan Aruoba
                                         Francis X. Diebold
                                          Jeremy Nalewaik
                                         Frank Schorfheide
                                            Dongho Song

                                        Working Paper 18954
                                http://www.nber.org/papers/w18954


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                      April 2013




For helpful comments we thank Bob Chirinko, Don Harding, Greg Mankiw, Adrian Pagan, John Roberts,
Matt Shapiro, Chris Sims, Mark Watson, Justin Wolfers and Simon van Norden. For research support
we thank the National Science Foundation and the Real-Time Data Research Center at the Federal
Reserve Bank of Philadelphia. The views expressed herein are those of the authors and do not necessarily
reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

¬© 2013 by S. Bora«ßan Aruoba, Francis X. Diebold, Jeremy Nalewaik, Frank Schorfheide, and Dongho
Song. All rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without
explicit permission provided that full credit, including ¬© notice, is given to the source.
Improving GDP Measurement: A Measurement-Error Perspective
S. Bora«ßan Aruoba, Francis X. Diebold, Jeremy Nalewaik, Frank Schorfheide, and Dongho
Song
NBER Working Paper No. 18954
April 2013
JEL No. E01,E32

                                          ABSTRACT

We provide a new and superior measure of U.S. GDP, obtained by applying optimal signal-extraction
techniques to the (noisy) expenditure-side and income-side estimates. Its properties ‚Äì particularly
as regards serial correlation ‚Äì differ markedly from those of the standard expenditure-side measure
and lead to substantially-revised views regarding the properties of GDP.


S. Bora«ßan Aruoba                                Frank Schorfheide
Department of Economics                          University of Pennsylvania
University of Maryland                           Department of Economics
3105 Tydings Hall                                3718 Locust Walk
College Park, MD 20742-7211                      Philadelphia, PA 19104-6297
aruoba@econ.umd.edu                              and NBER
                                                 schorf@ssc.upenn.edu
Francis X. Diebold
Department of Economics                          Dongho Song
University of Pennsylvania                       University of Pennsylvania
3718 Locust Walk                                 Department of Economics
Philadelphia, PA 19104-6297                      3718 Locust Walk
and NBER                                         Philadelphia, PA 19104
fdiebold@sas.upenn.edu                           donghos@sas.upenn.edu

Jeremy Nalewaik
Federal Reserve Board
20th and C, NW
Washington, DC 20551
jeremy.j.nalewaik@frb.gov
1       Introduction
Aggregate real output is surely the most fundamental and important concept in macroe-
conomic theory. Surprisingly, however, significant uncertainty still surrounds its measure-
ment. In the U.S., in particular, two often-divergent GDP estimates exist, a widely-used
expenditure-side version, GDPE , and a much less widely-used income-side version, GDPI .1
Nalewaik (2010) and Fixler and Nalewaik (2009) make clear that, at the very least, GDPI
deserves serious attention and may even have properties in certain respects superior to those
of GDPE . That is, if forced to choose between GDPE and GDPI , a surprisingly strong case
exists for GDPI . But of course one is not forced to choose between GDPE and GDPI , and
a GDP estimate based on both GDPE and GDPI may be superior to either one alone. In
this paper we propose and implement a framework for obtaining such a blended estimate.
    Our work is related to, and complements, Aruoba et al. (2012). There we took a forecast-
error perspective, whereas here we take a measurement-error perspective.2 In particular, we
work with a dynamic factor model in the tradition of Geweke (1977) and Sargent and Sims
(1977), as used and extended by Watson and Engle (1983), Edwards and Howrey (1991),
Harding and Scutella (1996), Jacobs and van Norden (2011), Kishor and Koenig (2011), and
Fleischman and Roberts (2011), among others.3 That is, we view ‚Äútrue GDP ‚Äù as a latent
variable on which we have several indicators, the two most obvious being GDPE and GDPI ,
and we then extract true GDP using optimal filtering techniques.
    The measurement-error approach is time honored, intrinsically compelling, and very dif-
ferent from the forecast-combination perspective of Aruoba et al. (2012), for several reasons.4
First, it enables extraction of latent true GDP using a model with parameters estimated with
exact likelihood or Bayesian methods, whereas the forecast-combination approach forces one
to use calibrated parameters. Second, it delivers not only point extractions of latent true
GDP but also interval extractions, enabling us to assess the associated uncertainty. Third,
the state-space framework in which the measurement-error models are is embedded facili-
tates exploration of the relationship between GDP measurement errors and the economic
environment, such as stage of the business cycle, which is of special interest. Fourth, the
    1
     Indeed we will focus on the U.S. because it is a key egregious example of unreconciled GDPE and GDPI
estimates.
   2
     Hence the pair of papers roughly parallels the well-known literature on ‚Äúforecast error‚Äù and ‚Äúmeasure-
ment error‚Äù properties of of data revisions; see Mankiw et al. (1984), Mankiw and Shapiro (1986), Faust
et al. (2005), and Aruoba (2008).
   3
     See also Smith et al. (1998), who take a different but related approach.
   4
     On the time-honored aspect, see, for example, Gartaganis and Goldberger (1955).
state-space framework facilitates real-time analysis and forecasting, despite the fact that
preliminary GDPI data are not available as quickly as those for GDPE .
    We proceed as follows. In section 2 we consider several measurement-error models and
assess their identification status, which turns out to be challenging and interesting in the most
realistic and hence compelling case. In section 3 we discuss the data, estimation framework
and estimation results. In section 4 we explore the properties of our new GDP series. We
conclude in section 5.


2         Five Measurement-Error Models of GDP
We use dynamic-factor measurement-error models, which embed the idea that both GDPE
and GDPI are noisy measures of latent true GDP . We work throughout with growth rates
of GDPE , GDPI and GDP (hence, for example, GDPE denotes a growth rate).5 We assume
throughout that true GDP growth evolves with simple AR(1) dynamics, and we entertain
several measurement structures, to which we now turn.


2.1         (Identified) 2-Equation Model: Œ£ Diagonal
Here we assume that the measurement errors are orthogonal to each other and to transition
shocks at all leads and lags. The model has a natural state-space structure, and we write

                                   "            #       "       #            "         #
                                       GDPEt                1                    Et
                                                    =               GDPt +                   (1)
                                       GDPIt                1                    It


                                       GDPt = ¬µ(1 ‚àí œÅ) + œÅGDPt‚àí1 + Gt ,

where GDPEt and GDPIt are expenditure- and income-side estimates, respectively, GDPt is
latent true GDP , and all shocks are Gaussian and uncorrelated at all leads and lags. That
is, (Gt , Et , It )0 ‚àº iid N (0, Œ£), where
                                              Ô£Æ
                                              2
                                                                        Ô£π
                                             œÉGG            0        0
                                         Œ£=Ô£∞ 0            2
                                                         œÉEE         0 Ô£ª.                    (2)
                                           Ô£Ø                            Ô£∫
                                                                     2
                                              0           0         œÉII
    5
        We will elaborate on the reasons for this choice later in section 3.



                                                            2
This model has been used countless times. As is well known, the Kalman filter delivers opti-
mal extractions of GDPt conditional upon observed expenditure- and income-side measure-
ments. Moreover, the model can be easily extended, and some of its restrictive assumptions
relaxed, with no fundamental change. We now proceed to do so.


2.2     (Identified) 2-Equation Model: Œ£ Block-Diagonal
The first extension is to allow for correlated measurement errors. This is surely important,
as there is roughly a 25 percent overlap in the counts embedded in GDPE and GDPI , and
moreover, the same deflator is used for conversion from nominal to real magnitudes.6 We
write
                           "          #      " #          "      #
                              GDPEt            1             Et
                                          =        GDPt +                                (3)
                              GDPIt            1             It


                                GDPt = ¬µ(1 ‚àí œÅ) + œÅGDPt‚àí1 + Gt ,

where now Et and It may be correlated contemporaneously but are uncorrelated at all other
leads and lags, and all other definitions and assumptions are as before; in particular, Gt and
(Et , It )0 are uncorrelated at all leads and lags. That is, (Gt , Et , It )0 ‚àº iid N (0, Œ£), where

                                       2
                                        Ô£Æ                     Ô£π
                                      œÉGG           0      0
                                  Œ£=Ô£∞ 0            2       2
                                                  œÉEE     œÉEI Ô£ª.                                      (4)
                                    Ô£Ø                         Ô£∫
                                                   2       2
                                       0          œÉIE     œÉII

Nothing is changed, and the Kalman filter retains its optimality properties.


2.3     (Unidentified) 2-Equation Model, Œ£ Unrestricted
The second key extension is motivated by Fixler and Nalewaik (2009) and Nalewaik (2010),
who document cyclicality in the statistical discrepancy (GDPE ‚àí GDPI ), which implies
failure of the assumption that (Et , It )0 and Gt are uncorrelated at all leads and lags. Of
particular concern is contemporaneous correlation between Gt and (Et , It )0 . Hence we allow
the measurement errors (Et , It )0 to be correlated with GDPt , or more precisely, correlated
   6
    See Aruoba et al. (2012) for more. Many of the areas of overlap are particularly poorly measured, such
as imputed financial services, housing services, and government output.



                                                    3
with GDPt innovations, Gt . We write
                              "              #       "       #            "         #
                                  GDPEt                  1                    Et
                                                 =               GDPt +                    (5)
                                  GDPIt                  1                    It

                                  GDPt = ¬µ(1 ‚àí œÅ) + œÅGDPt‚àí1 + Gt ,

where (Gt , Et , It )0 ‚àº iid N (0, Œ£), with
                                         Ô£Æ 2          2           2
                                                                     Ô£π
                                          œÉGG        œÉGE         œÉGI
                                        Ô£Ø 2           2           2
                                    Œ£ = Ô£∞ œÉEG        œÉEE         œÉEI Ô£ª.                    (6)
                                                                     Ô£∫
                                           2          2           2
                                          œÉIG        œÉIE         œÉII

In this environment the standard Kalman filter is rendered sub-optimal for extracting GDP ,
due to correlation between Gt and (Et , It ), but appropriately-modified optimal filters are
available.
    Of course in what follows we will be concerned with estimating our measurement-equation
models, so we will be concerned with identification. The diagonal-Œ£ model (1)-(2) and
the block-diagonal-Œ£ model (3)-(4) are identified. Identification of less-restricted dynamic
factor models, however, is a very delicate matter. In particular, it is not obvious that the
unrestricted-Œ£ model (5)-(6) is identified. Indeed it is not, as we prove in Appendix A. Hence
we now proceed to determine minimal restrictions that achieve identification.


2.4     (Identified) 2-Equation Model: Œ£ Restricted
The identification problem with the general model (5)-(6) stems from the fact that we can
                                          2
make true GDP more volatile (increase œÉGG    ) and make the measurement errors more volatile
           2        2
(increase œÉEE  and œÉII ), but reduce the covariance between the fundamental shocks and the
                               2        2
measurement errors (reduce œÉEG    and œÉIG ), without changing the distribution of observables.

2.4.1    Restricting the Original Parameterization

But we can achieve identification by slightly restricting parameterization (5)-(6). In par-
ticular, as we show in Appendix A, the unrestricted system (5)-(6) is unidentified because
the Œ£ matrix has six free parameters with only five moment conditions to determine them.
Hence we can achieve identification by restricting any single element of Œ£. Imposing any
such restriction would seem challenging, however, as we have no strong prior views directly


                                                         4
on any single element of Œ£. Fortunately, the problem is made tractable by a simple re-
parameterization.

2.4.2    A Useful Re-Parameterization

Define
                                                       1
                                                         œÉ2
                                                     1‚àíœÅ2 GG
                                      Œ∂=       1                           .              (7)
                                                 œÉ 2 + 2œÉGE
                                             1‚àíœÅ2 GG
                                                           2          2
                                                                   + œÉEE
Then, rather than fixing an element of Œ£ to achieve identification, we can fix Œ∂, about which
                                                                                   2
we have a more natural prior view. In particular, at first pass we might take œÉGE      ‚âà 0, in
                                                                                     2
which case 0 < Œ∂ < 1. Or, put differently, Œ∂ > 1 would require a very negative œÉGE , which
seems unlikely. All told, we view a Œ∂ value less than, but close to, 1.0 as most natural. We
take Œ∂ = 0.80 as our benchmark in the empirical work that follows, although we explore a
wide range of Œ∂ values both below and above 1.0.


2.5      (Identified) 3-Equation Model: Œ£ Unrestricted
Thus far we showed how to achieve identification by fixing a parameter, Œ∂, and we noted
that our prior is centered around Œ∂ = 0.80. It is of also of interest to know whether we can
get some complementary data-based guidance on choice of Œ∂. The answer turns out to be
yes, by adding a third measurement equation with a certain structure.
    Suppose, in particular, that we have an additional observable variable Ut that loads on
true GDPt with measurement error orthogonal to those of GDPI and GDPE . In particular,
consider the 3-equation model
                        Ô£Æ       Ô£π   Ô£Æ   Ô£π Ô£Æ     Ô£π        Ô£Æ      Ô£π
                          GDPEt       0       1            Et
                        Ô£∞ GDPIt Ô£ª = Ô£∞ 0 Ô£ª + Ô£∞ 1 Ô£ª GDPt + Ô£∞ It Ô£ª                          (8)
                        Ô£Ø       Ô£∫   Ô£Ø   Ô£∫ Ô£Ø     Ô£∫        Ô£Ø      Ô£∫

                           Ut         Œ∫       Œª            U t

                                  GDPt = ¬µ(1 ‚àí œÅ) + œÅGDPt‚àí1 + Gt ,

where (Gt , Et , It , U t )0 ‚àº iid N (0, ‚Ñ¶), with
                                       Ô£Æ                                   Ô£π
                                             2      2         2      2
                                           œÉGG     œÉGE       œÉGI   œÉGU
                                             2      2         2
                                   Ô£Ø                                       Ô£∫
                                   Ô£Ø       œÉEG     œÉEE       œÉEI     0     Ô£∫
                                 ‚Ñ¶=Ô£Ø         2      2         2
                                                                           Ô£∫.             (9)
                                   Ô£Ø
                                   Ô£∞       œÉIG     œÉIE       œÉII     0     Ô£∫
                                                                           Ô£ª
                                           œÉU2 G    0         0    œÉU2 U

                                                         5
Note that the upper-left 3x3 block of ‚Ñ¶ is just Œ£, which is now unrestricted. Nevertheless,
as we prove in Appendix B, the 3-equation model (8)-(9) is identified. Of course some of the
remaining elements of the overall 4x4 covariance matrix ‚Ñ¶ are restricted, which is how we
achieve identification in the 3-equation model, but the economically interesting sub-matrix,
which the 3-equation model leaves completely unrestricted, is Œ£.
    Depending on the application, of course, it is not obvious that an identifying variable
Ut with measurement errors orthogonal to those of GDPE and GDPI (i.e., with stochastic
properties that satisfy (9)), is available. Hence it is not obvious that estimation of the 3-
equation model (8)-(9) is feasible in practice, despite the model‚Äôs appeal in principle. Indeed,
much of the data collected from business surveys is used in the BEA‚Äôs estimates, invalidating
use of that data as Ut since any measurement error in that data appears directly in either
GDPE or GDPI , producing correlation across the measurement errors. Moreover, variables
drawn from business surveys similar to those used to produce GDPE and GDPI , even if they
are not used directly in the estimation of GDPE and GDPI , might still be invalid identifying
variables if the survey methodology itself produces similar measurement errors.7
    Fortunately, however, some important macroeconomic data is collected not from surveys
of businesses, but from samples of households. A sample of data drawn from a universe of
households seems likely to have measurement errors that are different than those contami-
nating a data sample drawn from a universe of businesses, especially when the ‚Äúuniverses‚Äù of
businesses and households are not complete census counts, as is the case here. For example,
the universe of business surveys is derived from tax records, so businesses not paying taxes
will not appear on that list, but individuals working at that business may appear in the
universe of households.
    Importantly, very little data collected from household surveys are used to construct
GDPE and GDPI , so a Ut variable computed from a household survey seems most likely to
meet our identification conditions. The change in the unemployment rate is a natural choice
(hence our notational choice Ut ). Ut arguably loads on true GDP with a measurement error
orthogonal to those of GDPE and GDPI , because the Ut data is being produced indepen-
dently (by the BLS rather than BEA) from different types of surveys. In addition, virtually
all of the GDPE and GDPI data are estimated in nominal dollars and then converted to real
dollars using a price deflator, whereas Ut is estimated directly with no deflation.
    All told,we view ‚Äú3-equation identification‚Äù as a useful complement to the ‚ÄúŒ∂-identification‚Äù
   7
     For example, if the business surveys used to produce GDPE and GDPI tend to oversample large firms,
variables drawn from a business survey that also oversamples large firms may have measurement errors that
are correlated with those in GDPE and GDPI , absent appropriate corrections.


                                                   6
                               Figure 1: Divergence Between Œ£ÃÇŒ∂ and Œ£ÃÇ3




Notes: We show the Frobenius-norm divergence D(Œ∂) between Œ£
                                                          b Œ∂ and Œ£
                                                                  b 3 as a function of Œ∂. The optimum
is Œ∂ = 0.82. See text for details.


discussed earlier in section 2.4. All identifications involve assumptions. Œ∂-identification in-
volves introspection about likely values of Œ∂, given its structure and components, and that
introspection is of course subject to error. 3-equation identification involves introspection
about various measurement-error correlations involving the newly-introduced third variable,
which is of course also subject to error. Indeed the two approaches to identification are
usefully used in tandem, and compared.
    One can even view the 3-equation approach as a device for implicitly selecting Œ∂. In
particular, we can find the Œ∂ implied by the 3-equation model estimate, that is, find the Œ∂
that minimizes the divergence between Œ£ÃÇŒ∂ and Œ£ÃÇ3 , in an obvious notation.8 For example,
using the Frobenius matrix-norm to measure divergence, we obtain an optimum of Œ∂ ‚àó = 0.82.
We show the full surface in Figure 1, and the minimum is sharp and unique. The implied
Œ∂ ‚àó of 0.82 is of course quite close to the directly-assessed value of 0.80 at which we arrived
earlier, which lends additional credibility to the earlier assessment.


3       Data and Estimation
We intentionally work with a stationary system in growth rates, because we believe that
measurement errors are best modeled as iid in growth rates rather than in levels, due to
BEA‚Äôs devoting maximal attention to estimating the ‚Äúbest change.‚Äù9 In its above-cited
    8
    We will discuss subsequently the estimation procedure used to obtain Œ£ÃÇŒ∂ and Œ£ÃÇ3 .
    9
    For example, see ‚ÄúConcepts and Methods in the U.S. National Income and Product Accounts,‚Äù available
at http://www.bea.gov/national/pdf/methodology/chapters1-4.pdf.


                                                  7
                           Figure 2: GDP and Unemployment Data




Notes: GDPE and GDPI are in growth rates and Ut is in changes. All are measured in annualized percent.

‚ÄúConcepts and Methods ...‚Äù document, for example,the BEA emphasizes that:

      Best change provides the most accurate measure of the period-to-period move-
      ment in an economic statistic using the best available source data. In an annual
      revision of the NIPAs, data from the annual surveys of manufacturing and trade
      are generally incorporated into the estimates on a best-change basis. In the cur-
      rent quarterly estimates, most of the components are estimated on a best-change
      basis from the annual levels established at the most recent annual revision.

The monthly source data used to estimate GDPE (such as retail sales) and GDPI (such as
nonfarm payroll employment) are generally produced on a best-change basis as well, using a
so-called ‚Äúlink-relative estimator.‚Äù This estimator computes growth rates using firms in the
sample in both the current and previous months, in contrast to a best-level estimator, which
would generally use all the firms in the sample in the current month regardless of whether
or not they were in the sample in the previous month. For example, for retail sales the BEA

                                                  8
notes that:10
         Advance sales estimates for the most detailed industries are computed using a
         type of ratio estimator known as the link-relative estimator. For each detailed
         industry, we compute a ratio of current-to-previous month weighted sales using
         data from units for which we have obtained usable responses for both the current
         and previous month.
Indeed the BEA produces estimates on a best-level basis only at 5-year benchmarks. These
best-level benchmark revisions should drive only the very-low frequency variation in GDPE ,
and thus probably matter very little for the quarterly growth rates estimated on a best-
change basis.


3.1       Descriptive Statistics
We show time-series plots of the ‚Äúraw‚Äù GDPE and GDPI data in Figure 2, and we show
summary statistics in the top panel of Table 1. Not captured in the table but also true is that
the raw data are highly correlated; the simple correlations are corr(GDPE , GDPI ) = 0.85,
corr(GDPE , U ) = ‚àí0.67, and corr(GDPI , U ) = ‚àí0.73. Median GDPI growth is a bit higher
than that of GDPE , and GDPI growth is noticeably more persistent than that of GDPE .
Related, GDPI also has smaller AR(1) innovation variance and greater predictability as
measured by the predictive R2 .11


3.2       Bayesian Analysis of Measurement-Error Models
Here we describe Bayesian analysis of our three-equation model, which of course also includes
our various two-equation models as special cases. Bayesian estimation involves parameter
estimation and latent state smoothing. First, we generate draws from the posterior distribu-
tion of the model parameters using a Random-Walk Metropolis-Hastings algorithm. Next,
we apply a simulation smoother as described in Durbin and Koopman (2001) to obtain draws
of the latent states conditional on the parameters.

3.2.1      State-Space Representation

We proceed by introducing a state-space representation of (8) for estimation. Let yt =
[GDPEt , GDPIt , Ut ]0 , C = [0, 0, Œ∫]0 , st = [GDPt , Et , It , U t ]0 , D = [¬µ(1 ‚àí œÅ), 0, 0, 0]0 , t =
  10
       See http://www.census.gov/retail/marts/how_surveys_are_collected.html.
  11
       On this and related predictability measures, see Diebold and Kilian (2001).

                                                     9
                          Table 1: Descriptive Statistics for Various GDP Series

                                  xÃÑ     50%     œÉÃÇ         Sk     œÅÃÇ1      œÅÃÇ2   œÅÃÇ3   œÅÃÇ4    Q12       œÉÃÇe     R2     VÃÇe
  GDPE                           3.03    3.04   3.49 -0.31 .33 .27 .08 .09                    47.07     3.28 .06 12.12
  GDPI                           3.02    3.39   3.40 -0.55 .47 .27 .22 .08                    81.60     2.99 .12 11.43
  GDPM      2-eqn,   Œ£ diag      3.02    3.22   3.00       -0.56   .56     .34    .21   .09   108.25    2.48     .18   8.92
  GDPM      2-eqn,   Œ£ block     3.02    3.35   2.64       -0.64   .70     .45    .28   .13   170.08    1.89     .29   6.90
  GDPM      2-eqn,   Œ∂ = 0.65    3.02    3.32   2.61       -0.64   .67     .43    .27   .12   157.56    1.92     .26   6.73
  GDPM      2-eqn,   Œ∂ = 0.75    3.02    3.30   2.77       -0.63   .65     .41    .26   .11   148.23    2.08     .25   7.60
  GDPM      2-eqn,   Œ∂ = 0.80    3.02    3.29   2.87       -0.62   .64     .39    .25   .11   141.14    2.19     .24   8.16
  GDPM      2-eqn,   Œ∂ = 0.85    3.02    3.31   2.89       -0.64   .66     .41    .28   .12   153.27    2.15     .25   8.29
  GDPM      2-eqn,   Œ∂ = 0.95    3.02    3.26   3.02       -0.64   .66     .40    .28   .12   149.61    2.27     .25   9.07
  GDPM      2-eqn,   Œ∂ = 1.05    3.01    3.22   3.12       -0.65   .67     .40    .28   .12   155.60    2.30     .26   9.69
  GDPM      2-eqn,   Œ∂ = 1.15    3.04    3.34   3.07       -0.67   .76     .47    .31   .15   201.15    1.99     .35   9.46
  GDPM      3-eqn                3.02    3.37   3.02       -1.14   .63     .37    .21   .03   141.79    2.33     .23   9.03
  GDPF                           3.02    3.29   3.30       -0.51   .46     .29    .19   .07   78.28     2.92     .12   10.80

Notes: The sample period is 1960Q1-2011Q4. In the top panel we show statistics for the raw data. In the
middle panel we show statistics for various posterior-median measurement-error-based (‚ÄúM ‚Äù) estimates of
true GDP , where all estimates are smoothed extractions. In the bottom panel we show statistics for the
forecast-error-based (‚ÄúF ‚Äù) estimate of true GDP produced by Aruoba et al. (2012). xÃÑ, 50%, œÉÃÇ and Sk are
sample mean, median, standard deviation and skewness, respectively, and œÅÃÇœÑ is a sample autocorrelation at a
displacement of œÑ quarters. Q12 is the Ljung-Box serial correlation test statistic calculated using œÅÃÇ1 , ..., œÅÃÇ12 .
           œÉÃÇ 2
R2 = 1 ‚àí œÉÃÇe2 , where œÉÃÇe denotes the estimated disturbance standard deviation from a fitted AR(1) model, is
                                                                                                        œÉÃÇe2
a predictive R2 . VÃÇe is the unconditional variance implied by a fitted AR1 model, VÃÇe =               1‚àíœÅÃÇ2 .



[Gt , Et , It , U t ]0 and
                                                                    Ô£Æ              Ô£π
                                 Ô£Æ                     Ô£π                   œÅ 0 0 0
                                1         1 0 0                 Ô£Ø                  Ô£∫
                                                                Ô£Ø          0 0 0 0 Ô£∫
                            Z=Ô£∞ 1         0 1 0 Ô£ª,            Œ¶=Ô£Ø                  Ô£∫.
                              Ô£Ø                 Ô£∫
                                                                Ô£Ø          0 0 0 0 Ô£∫
                                Œª         0 0 1
                                                                Ô£∞                  Ô£ª
                                                                           0 0 0 0

Our state-space model is
                                                      yt = C + Zst                                                      (10)

                                       st = D + Œ¶st‚àí1 + t ,             t ‚àº N (0, ‚Ñ¶).
                                                 2     2     2     2     2     2     2
We collect the parameters in (10) in Œò = (¬µ, œÅ, œÉGG , œÉGE , œÉGI , œÉEE , œÉEI , œÉII , œÉGU , œÉU2 U , Œ∫, Œª).




                                                              10
3.2.2   Metropolis-Hastings MCMC Algorithm

Now let us proceed to our implementation of the Metropolis-Hastings MCMC Algorithm.
Denote the number of MCMC draws by N. We first maximize the posterior density

                                  p(Œò|Y1:T ) ‚àù p(Y1:T |Œò)p(Œò)                             (11)

to obtain the mode Œò0 and construct a covariance matrix for the proposal density, Œ£Œò , from
the inverse Hessian of the log posterior density evaluated at Œò0 . We also use Œò0 to initialize
the algorithm. At each iteration j we draw a proposed parameter vector Œò‚àó ‚àº N (Œòj‚àí1 , cŒ£Œò ),
where c is a scalar tuning parameter that we calibrate to achieve an acceptance rate of 25-
30%. We accept the proposed parameter vector, that is, we set Œòj = Œò‚àó , with probability
                      ‚àó     ‚àó
                1:T |Œò )p(Œò )
min 1, p(Yp(Y
                                            j
             1:T |Œò j‚àí1 )p(Œòj‚àí1 ) , and set Œò  = Œòj‚àí1 otherwise. We adopt the convention that
p(Œò‚àó ) = 0 if the covariance matrix ‚Ñ¶ implied by Œò‚àó is not positive definite. The results
reported subsequently are are based on N = 50, 000 iterations of the algorithm. We discard
the first 25,000 draws and use the remaining draws to compute summary statistics for the
posterior distribution.

3.2.3   Filtering and Smoothing

The evaluation of the likelihood function p(Y1:T |Œò) requires the use of the Kalman filter.
The Kalman filter recursions take the following form. Suppose that

                            st‚àí1 |(Y1:t‚àí1 , Œò) ‚àº N (st‚àí1|t‚àí1 , Pt‚àí1|t‚àí1 ),                (12)

where st‚àí1|t‚àí1 and Pt‚àí1|t‚àí1 are the mean and variance of the latent state at t ‚àí 1. Then the
means and variances of the predictive densities p(st |Y1:t‚àí1 , Œò) and p(yt |Y1:t‚àí1 , Œò) are

                    st|t‚àí1 = D + Œ¶st‚àí1|t‚àí1 ,          Pt|t‚àí1 = Œ¶Pt‚àí1|t‚àí1 Œ¶0 + ‚Ñ¶
                    yt|t‚àí1 = C + Zst|t‚àí1 ,        Ft|t‚àí1 = ZPt|t‚àí1 Z 0 ,

respectively. The contribution of observation yt to the likelihood function p(Y1:T |Œò) is given
by p(yt |Y1:t‚àí1 , Œò). Finally, the updating equations are

                                                    ‚àí1
                      st|t = st|t‚àí1 + (ZPt|t‚àí1 )0 Ft|t‚àí1
                                                                        
                                                         yt ‚àí yÃÇt|t‚àí1
                     Pt|t = Pt|t‚àí1 ‚àí (ZPt|t‚àí1 )0 (ZPt|t‚àí1 Z 0 )‚àí1 (ZPt|t‚àí1 ),


                                                 11
leading to
                                      st |(Y1:t , Œò) ‚àº N (st|t , Pt|t ).                    (13)

We initialize the Kalman filter by drawing s0|0 from a mean-zero Gaussian stationary distri-
bution whose covariance matrix, P0|0 , is the solution of the underlying Ricatti equation.
    Because we are interested in inference for the latent GDP , we use the backward-smoothing
algorithm of Carter and Kohn (1994) to generate draws recursively from st |(St+1:T , Y1:T , Œò),
t = T ‚àí 1, T ‚àí 2, . . . , 1, where the last iteration of the Kalman filter recursion provides the
initialization for the backward simulation smoother,

                                                      ‚àí1
                            st|t+1 = st|t + Pt|t Œ¶0 Pt+1|t
                                                                               
                                                           st+1 ‚àí D ‚àí Œ¶st|t                 (14)

                                                             ‚àí1
                                   Pt|t+1 = Pt|t ‚àí Pt|t Œ¶0 Pt+1|t Œ¶Pt|t

                            draw st |(St+1:T , Y1:T , Œò) ‚àº N (st|t+1 , Pt|t+1 ),

t = T ‚àí 1, T ‚àí 2, ..., 1.


3.3     Parameter Estimation Results
Here we present and discuss estimation results for our various models. In Table 2 we show
details of parameter prior and posterior distributions, as well as statistics describing the
overall posterior and likelihood, for various 2-equation models, and in Table 3 we provide
the same information for the 3-equation model.
    The complete estimation information in the tables can be difficult to absorb fully, how-
ever, so here we briefly present aspects of the results in a more revealing way. For the
2-equation models, the parameters to be estimated are those in the transition equation and
those in the covariance matrix Œ£, which includes variances and covariances of both transi-
tion and measurement shocks. Hence we simply display the estimated transition equation
and the estimated Œ£ matrices. For the 3-equation model, we also need to estimate a factor
loading in the measurement equation, so we display the estimated measurement equation as
well. Below each posterior median parameter estimate, we show a the posterior interquartile
range in brackets.
    For the 2-equation model with Œ£ diagonal, we have

                       GDPt = 3.07 (1 ‚àí 0.53) + 0.53 GDPt‚àí1 + Gt ,                         (15)
                                 [2.81,3.33]               [0.48,0.57]




                                                     12
Table 2: Priors and Posteriors, 2-Equation Models, 1960Q1-2011Q4

                                    Diagonal               Block Diagonal
                 Prior              Posterior                 Posterior
             (Mean,Std.Dev)     25%    50%      75%      25%     50%      75%
    ¬µ           N(3,10)          2.81    3.07    3.33    2.77    3.06    3.34
    œÅ           N(0.3,1)         0.48    0.53    0.57    0.57    0.62    0.68
     2
   œÉGG         IG(10,15)         6.39    6.90    7.44    4.39    5.17    5.95
     2
   œÉGE          N(0,10)             -       -       -       -       -       -
      2
    œÉGI         N(0,10)             -       -       -       -       -       -
     2
   œÉEE         IG(10,15)         2.12    2.32    2.55    3.34    3.86    4.48
      2
    œÉEI         N(0,10)             -       -       -    0.96    1.43    1.95
      2
    œÉII        IG(10,15)         1.52    1.68    1.85    2.25    2.70    3.22
 posterior         -          -984.57 -983.46 -982.60 -986.23 -985.00 -984.01
likelihood         -          -951.68 -950.41 -949.43 -950.70 -949.49 -948.60
                                    Œ∂ = 0.75                 Œ∂ = 0.80
                 Prior              Posterior                Posterior
             (Mean,Std.Dev)     25%    50%      75%      25%    50%      75%
    ¬µ           N(3,10)          2.75    3.03    3.31    2.79    3.08    3.35
    œÅ           N(0.3,1)         0.53    0.59    0.64    0.51    0.57    0.62
     2
   œÉGG         IG(10,15)         5.78    6.31    6.92    6.54    7.09    7.70
     2
   œÉGE          N(0,10)         -0.76   -0.29    0.15   -1.15   -0.69   -0.29
      2
    œÉGI         N(0,10)         -0.34    0.01    0.34   -0.74   -0.38   -0.04
     2
   œÉEE         IG(10,15)         3.08    3.88    4.75    3.14    3.90    4.77
      2
    œÉEI         N(0,10)          0.73    1.23    1.78    0.80    1.29    1.85
      2
    œÉII        IG(10,15)         1.94    2.30    2.76    1.98    2.36    2.82
 posterior         -          -982.50 -980.99 -979.87 -982.48 -981.05 -979.91
likelihood         -          -950.93 -949.55 -948.40 -950.85 -949.44 -948.41
                                    Œ∂ = 0.85                 Œ∂ = 0.95
                 Prior              Posterior                Posterior
             (Mean,Std.Dev)     25%    50%      75%      25%    50%      75%
    ¬µ           N(3,10)          2.72    2.96    3.14    2.84    3.03    3.25
    œÅ           N(0.3,1)         0.51    0.56    0.60    0.49    0.54    0.60
     2
   œÉGG         IG(10,15)         6.67    7.19    7.76    7.69    8.43    9.28
     2
   œÉGE          N(0,10)         -2.17   -1.98   -1.77   -2.88   -2.73   -2.50
      2
    œÉGI         N(0,10)         -0.97   -0.80   -0.53   -1.99   -1.58   -1.22
     2
   œÉEE         IG(10,15)         5.36    5.79    6.28    5.64    6.10    6.39
      2
    œÉEI         N(0,10)          2.04    2.33    2.63    2.43    2.64    2.93
      2
    œÉII        IG(10,15)         2.36    2.65    3.04    2.45    3.22    3.81
 posterior         -          -982.62 -981.40 -980.48 -984.09 -982.80 -981.57
likelihood         -          -949.42 -948.25 -947.49 -950.19 -948.84 -947.81
                                    Œ∂ = 1.05                 Œ∂ = 1.15
                 Prior              Posterior                Posterior
             (Mean,Std.Dev)     25%    50%      75%      25%    50%      75%
    ¬µ           N(3,10)          2.85    3.07    3.33    2.55    2.89    3.21
    œÅ           N(0.3,1)         0.48    0.53    0.58    0.52    0.56    0.61
     2
   œÉGG         IG(10,15)         8.92    9.57   10.25    9.07    9.88   10.73
     2
   œÉGE          N(0,10)         -4.04   -3.88   -3.70   -5.61   -5.50   -5.22
      2
    œÉGI         N(0,10)         -3.09   -2.65   -2.29   -4.38   -4.21   -4.01
     2
   œÉEE         IG(10,15)         6.74    7.13    7.41    8.51    9.07    9.30
      2
    œÉEI         N(0,10)          3.23    3.46    4.13    5.29    5.52    5.89
      2
    œÉII        IG(10,15)         3.27 133.66     4.43    5.68    6.00    6.31
 posterior         -          -984.89 -983.63 -982.49 -988.63 -987.18 -986.32
likelihood         -          -949.31 -948.30 -947.53 -949.82 -948.51 -947.67
        Table 3: Priors and Posteriors, 3-Equation Model, 1960Q1-2011Q4

               Parameter           Prior                    Posterior
                                (Mean, Std)             25%    50%                75%
                   ¬µ              N(3,10)                2.60    2.78    2.95
                   œÅ              N(0.3,1)               0.54    0.58    0.63
                    2
                  œÉGG            IG(10,15)               6.73    6.96    7.35
                    2
                  œÉGE             N(0,10)               -1.27   -1.10   -0.84
                     2
                   œÉGI            N(0,10)               -1.03   -0.82   -0.59
                    2
                  œÉEE            IG(10,15)               4.17    4.57    4.79
                     2
                   œÉEI            N(0,10)                1.70    1.95    2.12
                     2
                   œÉII           IG(10,15)               2.54    3.07    3.27
                    2
                  œÉGU             N(0,10)                1.27    1.46    1.66
                  œÉU2 U          IG(0.3,10)              0.50    0.59    0.71
                    Œ∫             N(0,10)                1.53    1.62    1.71
                    Œª            N(-0.5,10)             -0.55   -0.52   -0.50
                posterior            -                -1251.1 -1249.6 -1248.3
               likelihood            -                -1199.0 -1197.5 -1196.2


                            Ô£Æ                                                Ô£π
                                  6.90            0                 0
                      Ô£Ø         [6.39,7.44]                                  Ô£∫
                      Ô£Ø                                                      Ô£∫
                    Œ£=Ô£Ø              0          2.32                0        Ô£∫.         (16)
                      Ô£Ø                       [2.12,2.55]                    Ô£∫
                      Ô£∞                                                      Ô£ª
                                     0            0              1.68
                                                               [1.52,1.85]


For the 2-equation model with Œ£ block-diagonal, we have

                GDPt = 3.06 (1 ‚àí 0.62) + 0.62 GDPt‚àí1 + Gt ,                            (17)
                            [2.77,3.34]                     [0.57,0.68]



                            Ô£Æ                                                Ô£π
                                  5.17            0                 0
                      Ô£Ø         [4.39,5.95]                                  Ô£∫
                      Ô£Ø                                                      Ô£∫
                    Œ£=Ô£Ø              0          3.86             1.43        Ô£∫.         (18)
                      Ô£Ø                       [3.34,4.48]      [0.96,1.95]   Ô£∫
                      Ô£∞                                                      Ô£ª
                                     0          1.43             2.70
                                              [0.96,1.95]      [2.25,3.22]


For the 2-equation model with benchmark Œ∂ = 0.80, we have




                                                 14
                     GDPt = 3.08 (1 ‚àí 0.57) + 0.57 GDPt‚àí1 + Gt ,                                                         (19)
                                     [2.79,3.35]                         [0.51,0.62]


                             Ô£Æ                                                                    Ô£π
                                         7.09               ‚àí0.69                ‚àí0.38
                        Ô£Ø            [6.54,7.70]        [‚àí1.15,‚àí0.29]         [‚àí0.74,‚àí0.04]       Ô£∫
                                      ‚àí0.69                  3.90                 1.29
                        Ô£Ø                                                                         Ô£∫
                      Œ£=Ô£Ø                                  [3.14,4.77]          [0.80,1.85]
                                                                                                  Ô£∫.                      (20)
                        Ô£Ø        [‚àí1.15,‚àí0.29]                                                    Ô£∫
                        Ô£∞                                                                         Ô£ª
                                      ‚àí0.38                  1.29                 2.36
                                 [‚àí0.74,‚àí0.04]             [0.80,1.85]          [1.98,2.82]


   Finally, for the 3-equation model, we have
                                     Ô£Æ                  Ô£π      Ô£Æ                        Ô£π
                                             0                            1
                 Ô£Æ           Ô£π                                                                         Ô£ÆÔ£π
                   GDPEt                                                                           Et
                         Ô£∫ Ô£Ø                                              1
                                                        Ô£∫ Ô£Ø                             Ô£∫
                 Ô£∞ GDPIt Ô£ª = Ô£Ø
                 Ô£Ø                           0          Ô£∫+Ô£Ø                             Ô£∫ GDPt + Ô£Ø
                                                                                                 Ô£∞ It Ô£ª
                                                                                                        Ô£∫
                                                                                                                          (21)
                             Ô£∞                          Ô£ª Ô£∞                             Ô£ª
                    Ut                      1.62                         ‚àí0.52                     U t
                                          [1.53,1.71]               [‚àí0.55,‚àí0.50]


                     GDPt = 2.78 (1 ‚àí 0.58) + 0.58 GDPt‚àí1 + Gt ,                                                         (22)
                                     [2.60,2.95]                         [0.54,0.63]


                     Ô£´                Ô£Æ                                                                              Ô£πÔ£∂
      Ô£Æ          Ô£π       Ô£Æ       Ô£π              6.96               ‚àí1.10                 ‚àí0.82             1.46
                                             [6.73,7.35]       [‚àí1.27,‚àí0.84]           [‚àí1.03,‚àí0.59]   [1.27,1.66]
          Gt       Ô£¨        0     Ô£Ø                                                                                 Ô£∫Ô£∑
                                              ‚àí1.10                 4.57                  1.95              0
      Ô£Ø          Ô£∫  Ô£¨Ô£Ø           Ô£∫ Ô£Ø                                                                                 Ô£∫Ô£∑
      Ô£Ø   Et    Ô£∫  Ô£¨Ô£Ø
                 Ô£∫‚àºNÔ£¨        0   Ô£∫ Ô£Ø
                                 Ô£∫,Ô£Ø       [‚àí1.27,‚àí0.84]         [4.17,4.79]            [1.70,2.12]
                                                                                                                     Ô£∫Ô£∑
                                                                                                                          (23)
      Ô£Ø                                                                                                              Ô£∫Ô£∑
                    Ô£¨Ô£Ø           Ô£∫ Ô£Ø                                                                                 Ô£∫Ô£∑
      Ô£Ø
      Ô£∞   It    Ô£∫
                 Ô£ª  Ô£¨Ô£Ø
                    Ô£¨Ô£∞       0   Ô£ª Ô£Ø          ‚àí0.82                 1.95                  3.07              0        Ô£∫Ô£∑
                                   Ô£Ø       [‚àí1.03,‚àí0.59]         [1.70,2.12]            [2.54,3.27]                  Ô£∫Ô£∑
          U t      Ô£≠        0     Ô£∞                                                                                 Ô£ªÔ£∏
                                                1.46                     0                    0            0.59
                                             [1.27,1.66]                                               [0.50,0.71]


    Many aspects of the results are noteworthy; here we simply mention a few. First, every
posterior interval in every model reported above excludes zero. Hence the diagonal and block
diagonal models do not appear satisfactory.
    Second, the Œ£ estimates are qualitatively similar across specifications. Covariances are
always negative, as per our conjecture based on the counter-cyclicality in the statistical
discrepancy (GDPE ‚àí GDPI ) documented by Fixler and Nalewaik (2009) and Nalewaik
                                          2      2      2
(2010). Shock variances always satisfy œÉÃÇGG  > œÉÃÇEE > œÉÃÇII .
    Finally, GDPM is highly serially correlated across all specifications (œÅ ‚âà .6), much more
so than the current ‚Äúconsensus‚Äù based on GDPE (œÅ ‚âà .3). We shall have much more to say
about these and other results in the next section.




                                                              15
                           Figure 3: GDP Sample Paths, 1960Q1-2011Q4




Notes: In each panel we show the sample path of GDPM in red together with a light-red posterior in-
terquartile range, and we show one of the competitor series in black. For GDPM we use our benchmark
estimate from the 2-equation model with Œ∂ = 0.80.


4        New Perspectives on the Properties of GDP
Our various extracted GDPM series differ in fundamental ways from other measures, such
as GDPE and GDPI . Here we discuss some of the most important differences.


4.1       GDP Sample Paths
Let us begin by highlighting the sample-path differences between our GDPM and the obvious
competitors GDPE and GDPI . We make those comparisons in Figure 3. In each panel we
show the sample path of GDPM in red together with a light-red posterior interquartile range,
and we show one of the competitor series in black.12 In the top panel we show GDPM vs.
GDPE . There are often wide divergences, with GDPE well outside the posterior interquartile
range of GDPM . Indeed GDPE is substantially more volatile than GDPM . In the bottom
panel of Figure 3 we show GDPM vs. GDPI . Noticeable divergences again appear often,
with GDPI also outside the posterior interquartile range of GDPM . The divergences are
not as pronounced, however, and the ‚Äúexcess volatility‚Äù apparent in GDPE is less apparent
  12
       For GDPM we use our benchmark estimate from the 2-equation model with Œ∂ = 0.80.


                                                   16
                       Figure 4: GDP Sample Paths, 2007Q1-2009Q4




Notes: In each panel we show the sample path of GDPM in red together with a light-red posterior in-
terquartile range, and we show one of the competitor series in black. For GDPM we use our benchmark
estimate from the 2-equation model with Œ∂ = 0.80.


in GDPI . That is because, as we will show later, GDPM loads relatively more heavily on
GDPI .
    To emphasize the economic importance of the differences in competing real activity as-
sessments, in Figure 4 we focus on the tumultuous period 2007Q1-2009Q4. The figure makes
clear not only that both GDPE and GDPI can diverge substantially from GDP , but also that
the timing and nature of their divergences can be very different. In 2007Q3, for example,
GDPE growth was strongly positive and GDPI growth was negative.


4.2    Linear GDP Dynamics
                                                             2
In our framework, population true GDPt is simply a pair (œÉGG   , œÅ). In Figure 5 we show those
pairs across MCMC draws for all of our measurement-error models, and for comparison we
show (œÉ 2 , œÅ) values corresponding to AR(1) models fit to GDPE alone and GDPI alone. In
addition, in Table 1 we show a variety of statistics quantifying the properties of our various
GDPM measures vs. those of GDPE , GDPI and GDPF .
    First consider Figure 5. Across measurement-error models M , GDPM is robustly more


                                                17
                                            2
                           Figure 5: (œÅÃÇ, œÉÃÇGG ) Pairs Across MCMC Draws




                                  2
Notes: Solid lines indicate 90% (œÉGG , œÅ) posterior coverage ellipsoids for the various models. Stars indicate
posterior median values. The sample period is 1960Q1-2011.Q4. For comparison we show (œÉ 2 , œÅ) values
corresponding to AR(1) models fit to GDPE alone and GDPE alone.


serially correlated than both GDPE and GDPI , and it also has a smaller innovation variance.
Hence most of our models achieve closely-matching unconditional variances, but they are
composed of very different underlying (œÉ 2 , œÅ) values from those corresponding to GDPE .
GDPM has smaller shock volatility, but much more shock persistence ‚Äì roughly double that
of GDPE (œÅ of roughly 0.60 for GDPM vs. 0.30 for GDPE ).
    Now consider Table 1. The various GDPM series are all less volatile than each of GDPE ,
GDPI and GDPF , and a bit more skewed left. Most noticeably, the GDPM series are much
more strongly serially correlated than the GDPE , GDPI and GDPF series, and with smaller
innovation variances. This translates into much higher predictive R2 ‚Äôs for GDPM . Indeed
GDPM is twice as predictable as GDPI or GDPF , which in turn are twice as predictable as
GDPE .




                                                     18
4.3     Non-Linear GDP Dynamics
In Table 4 we show Markov-switching AR(1) model results for a variety of GDP series. The
model allows for simultaneous switching in both mean and serial-correlation parameters.
The model switches between high- and low-growth states, with low-growth states generally
including recessions as defined by the National Bureau of Economic Research‚Äôs Business
Cycle Dating Committee (see also Nalewaik (2012)). The most interesting aspect of the
results concerns the estimated low- and high-state serial-correlation parameters (œÅÃÇ0 and œÅÃÇ1 ,
respectively).
    First, always and everywhere, œÅÃÇ0 > œÅÃÇ1 ; that is, a disproportionate share of overall se-
rial correlation comes from low-growth states. This interesting result parallels recent work
indicating that a disproportionate share of stock market return predictability comes from
recessions (Rapach et al. (2010)), as well as work showing that shocks to business orders for
capital goods are more persistent in downturns (Nalewaik and Pinto (2012)).
    Second, comparison of GDPI to GDPE reveals that they have identical œÅÃÇ0 values (0.55),
but that œÅÃÇ1 is much bigger for GDPI than for GDPE (0.31 vs. 0.14). Hence the stronger
overall serial correlation of GDPI comes entirely from its stronger serial correlation during
expansions.
    Finally, comparison of GDPM to GDPE reveals much bigger œÅÃÇ0 and œÅÃÇ1 values for GDPM
than for GDPE , regardless of the particular measurement-error model M examined. The
general finding of œÅÃÇ0 > œÅÃÇ1 is preserved, but both œÅÃÇ0 and œÅÃÇ1 are much larger for GDPM than for
GDPE . In our benchmark 2-equation model with Œ∂ = 0.80, for example, we have œÅÃÇ0 = 0.78
and œÅÃÇ1 = 0.55.


4.4     On the Relative Contributions of GDPE and GDPI to GDPM
It is of interest to know how the observed indicators GDPE and GDPI contribute to our
extracted true GDP. We do this in two ways; in section 4.4.1 we examine Kalman gains, and
in section 4.4.2 we find the convex combination of GDPE and GDPI closest to our extracted
GDP .

4.4.1   Kalman Gains

The Kalman gains associated with GDPE and GDPI govern the amount by which news
about GDPE and GDPI , respectively, causes the optimal extraction of GDPt (conditional
on time-t information) to differ from the earlier optimal prediction of GDPt (conditional


                                               19
                Table 4: Regime-Switching Model Estimates, 1960Q1-2011Q4

                                                                          2
                                        ¬µÃÇ0   ¬µÃÇ1         œÅÃÇ0   œÅÃÇ1     œÉÃÇH    œÉÃÇL2   pÃÇ00   pÃÇ11
         GDPE                        1.31     4.71    0.55      0.14   16.55   4.81   0.81   0.88
         GDPI                        1.28     4.87    0.55      0.31   12.07   5.51   0.82   0.87
         GDPM    2-eqn, Œ£ diag   1.76 5.12 0.73 0.41                   9.81    3.37 0.83 0.85
         GDPM    2-eqn, Œ£ block 1.75 4.72 0.83 0.63                    6.22    2.41 0.81 0.86
         GDPM    2-eqn, Œ∂ = 0.80 1.79 4.95 0.78 0.55                   7.96    3.04 0.82 0.85
         GDPM    3-eqn           1.88 5.32 0.88 0.39                   7.85    2.95 0.80 0.85
         GDPF                        1.51     4.93    0.64      0.30   13.20   4.17   0.82   0.87

Notes: In the top panel we show posterior median estimates for two-state regime-switching AR(1) models
fit to raw data. In the middle panel we show posterior median estimates for Regime-switching models fit
to GDPM , and in the bottom panel we show posterior median estimates for regime-switching models fit to
GDPF . We allow for a one-time structural break in volatility in 1984 (the ‚ÄúGreat Moderation‚Äù).


on time-(t ‚àí 1) information). Put more simply, the Kalman gain of GDPE (resp. GDPI )
measures its importance in influencing GDPM , and hence in informing our views about latent
true GDP .
    We summarize the posterior distributions of Kalman gains in Figure 6. Posterior median
GDPI Kalman gains are large in absolute terms, and most notably, very large relative to those
for GDPE . Indeed posterior median GDPE Kalman gains are zero in several specifications.
In any event, it is clear that GDPI plays a larger role in informing us about GDP than does
GDPE . For our benchmark Œ∂-model with Œ∂ = 0.80, the posterior median GDPI and GDPE
Kalman gains are 0.59 and 0.23, respectively.

4.4.2    Closest Convex Combination

The Kalman filter extractions average not only over space, but also over time. Nevertheless,
we can ask what contemporaneous convex combination of GDPE and GDPI , ŒªGDPE + (1 ‚àí
Œª)GDPI , is closest to the extracted GDPM . That is, we can find Œª‚àó = argminŒª L(Œª), where
L(Œª) is a loss function. Under quadratic loss we have

                                  T
                                  X
                  Œª‚àó = argminŒª          [(ŒªGDPEt + (1 ‚àí Œª)GDPIt ) ‚àí GDPM t ]2 ,
                                  t=1




                                                     20
                       Figure 6: (KGE , KGI ) Pairs Across MCMC Draws




Notes: Solid lines indicate 90% posterior coverage ellipsoids. Stars indicate posterior median values.

where GDPM t is our smoothed extraction of true GDPt . Over our sample of 1960Q1-
2011Q4, the optimum under quadratic loss is Œª‚àó = 0.29. The minimum is quite sharp, as
we show in Figure 7, and it puts more than twice as much weight on GDPI than on GDPE .
That weighting accords closely with both the Kalman gain results discussed above and the
forecast-combination calibration results in Aruoba et al. (2012). It does not, of course, mean
that time series of GDPM will ‚Äúmatch‚Äù time series of GDPF , because the Kalman filter does
much more than simple contemporaneous averaging of GDPE and GDPI in its extraction of
latent true GDP .


4.5     A Final Remark on the Serial Correlation in GDPM
Obviously a key result of our analysis is the strong serial correlation (persistence, forecasta-
bility, smoothness, ...) of our extracted GDPM , regardless of the particular specification.
One might perhaps wonder whether this is a spurious artifact of our extraction method,
which effectively amounts to a Kalman ‚Äúsmoother.‚Äù We hasten to add that the answer is
no. Indeed optimal extractions of covariance stationary series (in our, case latent true GDP
growth) must be less variable than the series being extracted, because the optimal extraction


                                                    21
                                Figure 7: Closest Convex Combination




                                           P2011Q4                                             2
Notes: We show quadratic loss, L(Œª) =               [(ŒªGDPEt + (1 ‚àí Œª)GDPIt ) ‚àí GDPM t ] , as a function
                                             t=1960Q1
of Œª. We obtain GDPM t    from the 3-equation model.


is a conditional expectation.13 Given our models, with Gaussian errors and under quadratic
loss, any other GDP extractions are sub-optimal and hence inferior.


5      Concluding Remarks and Directions for Future Re-
       search
We produce several estimates of GDP that blend both GDPE and GDPI . All estimates
feature GDPI prominently, and our blended GDP estimate has properties quite different
from those of the ‚Äútraditional‚Äù GDPE (as well as GDPI ). In a sense we build on the
literature on ‚Äúbalancing‚Äù the national income accounts, which extends back almost as far as
national income accounting itself, as for example in Stone et al. (1942). We do not, however,
advocate that the U.S. publish only GDPM , as there may at times be value in being able
to see the income and expenditure sides separately. But we would advocate the additional
calculation of GDPM and using it as the benchmark GDP estimate.
    Many interesting extensions are possible, including (1) Allowing for richer GDP dynam-
ics. We might want to add GDPt‚àí1 to the unemployment equation in addition to GDPt ,
because unemployment tends to lag GDP ; (2) Allowing for serially correlated unemployment
  13
    The forecast-error approach of Aruoba et al. (2012) also has optimality properties, but of a different sort,
and there is no reason why in the forecast-error framework the optimal combination should be smoother
than latent true GDP growth. Instead it could go either way, depending on the correlation of the forecast
errors in GDPE and GDPI .


                                                        22
measurement errors. We might want to allow the unemployment measurement errors to be
serially correlated, because they are really more than just measurement errors, in contrast
to the GDPE and GDPI measurement errors; (3) Including additional identifying variables,
which could be used alternatively or in addition to unemployment. The Michigan consumer
confidence index, for example, is released before GDPE and GDPI , which are not based on
it in any way. Another possibility is non-U.S. GDP .
    Perhaps the two most interesting directions for future work, however, concern forecasting
and real-time analysis. First consider forecasting. When forecasting a ‚Äútraditional‚Äù GDP
series such as GDPE , we must take it as given (i.e., we must ignore measurement error).
The analogous procedure in our framework would take GDPM as given, modeling and fore-
casting it directly, ignoring the fact that it is based on a first-stage extraction subject to
error. Fortunately, however, in our framework we need not do that. Instead we can es-
timate and forecast directly from the dynamic factor model, accounting for all sources of
uncertainty, which should translate into superior interval and density forecasts. Related, it
would be interesting to calculate directly the point, interval and density forecast functions
corresponding to the measurement-error model.
    Second, consider real-time analysis. Although GDPI data are not as timely as GDPE
data, our filtering framework still uses all available data efficiently, appropriately handling
any missing data. A key insight is that when using simple convex combinations as in the
forecast-error approach of Aruoba et al. (2012), missing GDPI data for the most-recent
quarter(s) forces all weight to be put on GDPE . Our measurement-error framework is very
different, however, because the Kalman filter averages not just over space, but also over time,
and earlier quarters for which we do have GDPI data are informative for the most-recent
quarters with ‚Äúmissing‚Äù GDPI data.




                                              23
Appendices
Here we report various details of theory, establishing identification results for the two- and
three-variable models in appendices A and B, respectively. The identification analysis is
based on Komunjer and Ng (2011).


A       Identification in the Two-Variable Model
The constants in the state-space model can be identified from the means of GDPEt and
GDPIt . To simplify the subsequent exposition we now set the constant terms to zero:

                                 GDPt = œÅGDPt‚àí1 + Gt                                    (A.1)
                           "         #   " #          "     #
                               GDPEt      1             Et
                                       =     GDPt +                                      (A.2)
                               GDPIt      1             It

and the joint distribution of the errors is
                  Ô£Æ      Ô£π                                Ô£Æ           Ô£π
                     Gt                                  Œ£GG  ¬∑   ¬∑
                                      
              t = Ô£∞ Et Ô£ª ‚àº iidN 0, Œ£ ,      where Œ£ = Ô£∞ Œ£EG Œ£EE  ¬∑ Ô£ª.
                   Ô£Ø     Ô£∫                              Ô£Ø             Ô£∫

                     It                                  Œ£IG Œ£IE Œ£II

Using the notation in Komunjer and Ng (2011), we write the system as

                                 st+1 = A(Œ∏)st + B(Œ∏)t+1                                (A.3)
                                 yt+1 = C(Œ∏)st + D(Œ∏)t+1 ,                              (A.4)

where
                                                    " #
                                               GDPEt
                             st = GDPt , yt =                                            (A.5)
                                               GDPIt
                                            h       i
                           A(Œ∏) = œÅ, B(Œ∏) = 1 0 0
                                  " #           "       #
                                    œÅ             1 1 0
                           C(Œ∏) =      , D(Œ∏) =
                                    œÅ             1 0 1

and Œ∏ = [œÅ, vech(Œ£)0 ]0 . Note that only A(Œ∏) and C(Œ∏) are non-trivial functions of Œ∏.


                                              24
Assumption 1 The parameter vector Œ∏ satisfies the following conditions: (i) Œ£ is positive
definite; (ii) 0 ‚â§ œÅ < 1.

   Because the rows of D are linearly independent, Assumption 1(i) implies that DŒ£D0 is
non-singular. In turn, we deduce that Assumptions 1, 2, and 4-NS of Komunjer and Ng
(2011) are satisfied.
   We now express the state-space system in terms of its innovation representation

                                     st+1|t+1 = A(Œ∏)st|t + K(Œ∏)at+1                             (A.6)
                                         yt+1 = C(Œ∏)sÃÇt|t + at+1 ,

where at+1 is the one-step-ahead forecast error of the system whose variance we denote by
Œ£a (Œ∏). The innovation representation is obtained from the Kalman filter as follows. Suppose
that conditional on time t information Y1:t the distribution of st |Y1:t ‚àº N (st|t , Pt|t ). Then
                                   0
the joint distribution of [st+1 , yt+1 ]0 is
        "          #             "           # "                                       #!
            st+1                     Ast|t         APt|t A0 + BŒ£B 0 APt|t C 0 + BŒ£D0
                       Y1:T ‚àº                 ,                                             .
            yt+1                     Cst|t         CPt|t A0 + DŒ£B 0 CPt|t C 0 + DŒ£D0

In turn, the conditional distribution of st+1 |Y1:t+1 is
                                                                     
                                 st+1 |Y1:t+1 ‚àº N st+1|t+1 , Pt+1|t+1 ,

where

 st+1|t+1 = Ast|t + (APt|t C + BŒ£D0 )(CPt|t C 0 + DŒ£D0 )‚àí1 (yt ‚àí Cst|t )
 Pt+1|t+1 = APt|t A0 + BŒ£B 0 ‚àí (APt|t C 0 + BŒ£D0 )(CPt|t C 0 + DŒ£D0 )‚àí1 (CPt|t A0 + DŒ£B 0 ).

Now let P be the matrix that solves the Riccati equation,

      P = AP A0 + BŒ£B 0 ‚àí (AP C 0 + BŒ£D0 )(CP C 0 + DŒ£D0 )‚àí1 (CP A0 + DŒ£B 0 ),                  (A.7)

and let K be the Kalman gain matrix

                                K = (AP C 0 + BŒ£D0 )(CP C 0 + DŒ£D0 )‚àí1 .                        (A.8)




                                                       25
Then the one-step-ahead forecast error matrix is given by

                                      Œ£a = CP C 0 + DŒ£D0 .                                     (A.9)

Equations (A.7) to (A.9) determine the matrices that appear in the innovation-representation
of the state-space system (A.6).
    In order to be able to apply Proposition 1-NS of Komunjer and Ng (2011) we need to
express P , K, and Œ£a in terms of Œ∏. While solving Riccati equations analytically is in general
not feasible, our system is scalar, which simplifies the calculation considerably. Replacing A
by œÅ and P by p such that scalars appear in lower case, and defining

                    Œ£BB = BŒ£B 0 ,      Œ£BD = BŒ£D0 ,      and Œ£DD = DŒ£D0 ,

we can write (A.7) as

                p = pœÅ2 + Œ£BB ‚àí (pœÅC 0 + Œ£BD )(pCC 0 + Œ£DD )‚àí1 (pœÅC + Œ£DB ).                 (A.10)

Likewise,
               K = (pœÅC 0 + Œ£BD )(pCC 0 + Œ£DD )‚àí1        and Œ£a = pCC 0 + Œ£DD .              (A.11)

Because Œ£BB ‚àí Œ£BD Œ£0DD Œ£DB > 0 we can deduce that p > 0. Moreover, because A = œÅ ‚â• 0
and C ‚â• 0, we deduce that K 6= 0 and therefore Assumption 5-NS of Komunjer and Ng
(2011) is satisfied. According to Proposition 1-NS in Komunjer and Ng (2011), two vectors
Œ∏ and Œ∏1 are observationally equivalent if and only if there exists a scalar Œ≥ 6= 0 such that

                                       A(Œ∏1 ) = Œ≥A(Œ∏)Œ≥ ‚àí1                                    (A.12)
                                       K(Œ∏1 ) = Œ≥K(Œ∏)                                        (A.13)
                                       C(Œ∏1 ) = C(Œ∏)Œ≥ ‚àí1                                     (A.14)
                                      Œ£a (Œ∏1 ) = Œ£a (Œ∏).                                     (A.15)

    Define Œ∏ = [œÅ, vech(Œ£)0 ]0 and Œ∏1 = [œÅ1 , vech(Œ£1 )0 ]0 . Using the definition of the scalar A(Œ∏)
in (A.5) we deduce from (A.12) that œÅ1 = œÅ. Since C(Œ∏) depends on Œ∏ only through œÅ we can
deduce from (A.14) that Œ≥ = 1. Thus, given Œ∏ and œÅ, the elements of the vector vech(Œ£1 )




                                                 26
have to satisfy conditions (A.13) and (A.15), which, using (A.11), can be rewritten as

                             Œ£a = Œ£a1 = p1 CC 0 + Œ£DD1                               (A.16)
                             K = K1 = (p1 œÅC 0 + Œ£BD1 )Œ£‚àí1
                                                        a .                          (A.17)

Moreover, p1 has to solve the Riccati equation (A.10):

                           p1 = p1 œÅ2 + Œ£BB1 ‚àí K0 (p1 œÅC + Œ£BD ).                    (A.18)

Equations (A.16) to (A.18) are satisfied if and only if

                             pCC 0 + Œ£DD = p1 CC 0 + Œ£DD1                            (A.19)
                                 pœÅC 0 + Œ£BD = p1 œÅC 0 + Œ£BD1                        (A.20)
                          p(1 ‚àí œÅ2 ) ‚àí Œ£BB = p1 (1 ‚àí œÅ2 ) ‚àí Œ£BB1 .                   (A.21)

   We proceed by deriving expressions for the Œ£xx matrices that appear in (A.19) to (A.21):

                Œ£BB = Œ£GG
                      h                      i
                Œ£BD =   Œ£GG + Œ£GE Œ£GG + Œ£GI
                      "                                        #
                          Œ£GG + Œ£EE + 2Œ£EG           ¬∑
                Œ£DD =
                        Œ£GG + Œ£GE + Œ£GI + Œ£EI Œ£GG + Œ£II + 2Œ£GI

Without loss of generality let

                                    Œ£GG1 = Œ£GG + (1 ‚àí œÅ2 )Œ¥,                         (A.22)

which implies that
                                    Œ£BB1 = Œ£BB + (1 ‚àí œÅ2 )Œ¥.

We now distinguish the cases Œ¥ = 0 and Œ¥ 6= 0.
Case 1: Œ¥ = 0. (A.21) implies p1 = p. It follows from (A.20) that Œ£BD1 = Œ£BD . In
turn, Œ£GE1 = Œ£GE and Œ£GI1 = Œ£GI . Finally, to satisfy (A.19) it has to be the case that
Œ£DD1 = Œ£DD , which implies that the remaining elements of Œ£ and Œ£1 are identical. We
conclude that Œ∏1 = Œ∏.




                                              27
Case 2: Œ¥ 6= 0. (A.21) implies p1 = p + Œ¥. Now consider (A.20):
                                       h         i       h                       i
                   0               2
               pœÅC + Œ£BD = pœÅ              1 1       +
                                             Œ£GG + Œ£GE Œ£GG + Œ£GI
                                       h      h  i  i
                             !
                             = pœÅ2 1 1 + Œ¥œÅ2 1 1
                                 h                      i
                               + Œ£GG + Œ£GE1 Œ£GG + Œ£GI1
                                         h    i
                                       2
                               +Œ¥(1 ‚àí œÅ ) 1 1

We deduce that
                            Œ£GE1 = Œ£GE ‚àí Œ¥,              Œ£GI1 = Œ£GI ‚àí Œ¥.             (A.23)

Finally, consider (A.19), which can be rewritten as

                                 0 = Œ£DD1 ‚àí Œ£DD + Œ¥CC 0 .

Using the previously derived expressions for Œ£DD and Œ£DD1 we obtain the following three
conditions

              0 = (1 ‚àí œÅ2 )Œ¥ + (Œ£EE1 ‚àí Œ£EE ) ‚àí 2Œ¥ + œÅ2 Œ¥ = Œ£EE1 ‚àí Œ£EE ‚àí Œ¥
              0 = (1 ‚àí œÅ2 )Œ¥ ‚àí 2Œ¥ + (Œ£EI1 ‚àí Œ£EI ) + œÅ2 Œ¥ = Œ£EI1 ‚àí Œ£EI ‚àí Œ¥
              0 = (1 ‚àí œÅ2 )Œ¥ + (Œ£II1 ‚àí Œ£II ) ‚àí 2Œ¥ + œÅ2 Œ¥ = Œ£II1 ‚àí Œ£II ‚àí Œ¥.

Thus, we deduce that

                 Œ£EE1 = Œ£EE + Œ¥,   Œ£EI1 = Œ£EI + Œ¥,             and Œ£II1 = Œ£II + Œ¥.   (A.24)

Combining (A.22), (A.23), and (A.24) we find that
                            Ô£Æ                                  Ô£π
                              Œ£GG + Œ¥(1 ‚àí œÅ2 ) Œ£GE ‚àí Œ¥ Œ£GI ‚àí Œ¥
                       Œ£1 = Ô£∞    Œ£GE ‚àí Œ¥       Œ£EE + Œ¥ Œ£EI + Œ¥ Ô£ª .                   (A.25)
                            Ô£Ø                                  Ô£∫

                                 Œ£GI ‚àí Œ¥       Œ£EI + Œ¥ Œ£II + Œ¥

Thus, we have proved the following theorem:

Theorem A.1 Suppose Assumption 1 is satisfied. Then the two-variable model is
   (i) identified if Œ£ is diagonal as in section 2.1;
   (ii) identified if Œ£ is block-diagonal as in section 2.2;

                                                 28
     (iii) not identified if Œ£ is unrestricted as in section 2.3;
     (iv) identified if Œ£ is restricted as in section 2.4.


B      Identification in the Three-Variable Model
The identification analysis of the three-variable is similar to the analysis of the two-variable
model in the previous section. The system is given by

                                    GDPt = œÅGDPt‚àí1 + Gt                                 (A.26)
                                Ô£Æ       Ô£π   Ô£Æ Ô£π          Ô£Æ      Ô£π
                                  GDPEt       1            Et
                                Ô£∞ GDPIt Ô£ª = Ô£∞ 1 Ô£ª GDPt + Ô£∞ It Ô£ª ,                       (A.27)
                                Ô£Ø       Ô£∫   Ô£Ø Ô£∫          Ô£Ø      Ô£∫

                                   Ut         Œª            U t

and the joint distribution of the errors is
                Ô£Æ          Ô£π                             Ô£Æ                         Ô£π
                    Gt                                      Œ£GG   ¬∑    ¬∑    ¬∑
               Ô£Ø           Ô£∫                             Ô£Ø                         Ô£∫
               Ô£Ø    Et    Ô£∫            
                           Ô£∫ ‚àº iidN 0, Œ£ , ,
                                                         Ô£Ø   Œ£EG Œ£EE    ¬∑    ¬∑     Ô£∫
          t = Ô£Ø                               where Œ£ = Ô£Ø                         Ô£∫.
               Ô£Ø
               Ô£∞    It    Ô£∫
                           Ô£ª
                                                         Ô£Ø
                                                         Ô£∞   Œ£IG Œ£IE Œ£II     ¬∑     Ô£∫
                                                                                   Ô£ª
                    U t                                     Œ£U G Œ£U E Œ£U I Œ£U U

The matrices A(Œ∏), B(Œ∏), C(Œ∏), and D(Œ∏) are now given by
                                                    h          i
                               A(Œ∏) = œÅ,   B(Œ∏) =  1 0 0 0
                                      Ô£Æ     Ô£π           Ô£Æ         Ô£π
                                        œÅ                 1 1 0 0
                               C(Œ∏) = Ô£∞ œÅ Ô£ª ,    D(Œ∏) = Ô£∞ 1 0 1 0 Ô£ª ,
                                      Ô£Ø    Ô£∫            Ô£Ø         Ô£∫

                                        ŒªœÅ                Œª 0 0 1

where Œ∏ = [œÅ, Œª, vech(Œ£)0 ]0 .

Assumption 2 The parameter vector Œ∏ satisfies the following conditions: (i) Œ£ is positive
definite; (ii) 0 < œÅ < 1; (iii) Œª 6= 0; (iv) Œ£U E = Œ£U I = 0.

   Condition (A.12) implies that œÅ1 = œÅ. Moreover, (A.14) implies that Œ≥ = 1 and that
Œª1 = Œª provided that œÅ 6= 0. As for the two-variable model, we have to verify that (A.19)




                                                  29
to (A.21) are satisfied. The matrices Œ£xx that appear in these equations are given by

 Œ£BB = Œ£GG
       h                                 i
 Œ£BD =   Œ£GG + Œ£GE Œ£GG + Œ£GI ŒªŒ£GG + Œ£GU
       Ô£Æ                                                               Ô£π
            Œ£GG + Œ£EE + 2Œ£GE           ¬∑                    ¬∑
 Œ£DD = Ô£∞ Œ£GG + Œ£GE + Œ£GI + Œ£EI Œ£GG + Œ£II + 2Œ£GI             ¬∑          Ô£ª.
       Ô£Ø                                                               Ô£∫

           ŒªŒ£GG + ŒªŒ£GE + Œ£GU   ŒªŒ£GG + ŒªŒ£GI + Œ£GU Œª2 Œ£GG + 2ŒªŒ£GU + Œ£U U

Without loss of generality, let

                                     Œ£GG,1 = Œ£GG + (1 ‚àí œÅ2 )Œ¥,

which implies that
                                     Œ£BB,1 = Œ£BB + (1 ‚àí œÅ2 )Œ¥.

Case 1: Œ¥ = 0. (A.21) implies p1 = p. It follows from (A.20) that Œ£BD,1 = Œ£BD . In turn,
Œ£GE,1 = Œ£GE , Œ£GI,1 = Œ£GI , and Œ£GU,1 = Œ£GU . Finally, to satisfy (A.17) it has to be the case
that Œ£DD,1 = Œ£DD , which implies that the remaining elements of Œ£ and Œ£1 are identical for
the two parameterizations. We conclude that it has to be the case that Œ∏1 = Œ∏.
Case 2: Œ¥ 6= 0. (A.21) implies p1 = p + Œ¥. Now consider (A.20):
                               h           i       h                                  i
          0                2
      pœÅC + Œ£BD = pœÅ               1 1 Œª       +
                                        Œ£GG + Œ£GE Œ£GG + Œ£GI ŒªŒ£GG + Œ£GU
                               h         h i     i
                     !
                     = pœÅ2 1 1 Œª + Œ¥œÅ2 1 1 Œª
                         h                                    i
                       + Œ£GG + Œ£GE,1 Œ£GG + Œ£GI,1 ŒªŒ£GG + Œ£GU,1
                                  h      i
                       +(1 ‚àí œÅ2 )Œ¥ 1 1 Œª .

We deduce that

                  Œ£GE,1 = Œ£GE ‚àí Œ¥,         Œ£GI,1 = Œ£GI ‚àí Œ¥,   Œ£GU,1 = Œ£GU ‚àí Œ¥.

Finally, consider (A.19), which can be rewritten as

                                     0 = Œ£DD,1 ‚àí Œ£DD + Œ¥CC 0 .




                                                       30
Using the previously derived expressions for Œ£DD and Œ£DD1 we obtain the following five
conditions

      0 = (1 ‚àí œÅ2 )Œ¥ + (Œ£EE1 ‚àí Œ£EE ) ‚àí 2Œ¥ + œÅ2 Œ¥ = Œ£EE1 ‚àí Œ£EE ‚àí Œ¥
      0 = (1 ‚àí œÅ2 )Œ¥ ‚àí 2Œ¥ + (Œ£EI1 ‚àí Œ£EI ) + œÅ2 Œ¥ = Œ£EI1 ‚àí Œ£EI ‚àí Œ¥
      0 = (1 ‚àí œÅ2 )Œ¥ + (Œ£II1 ‚àí Œ£II ) ‚àí 2Œ¥ + œÅ2 Œ¥ = Œ£II1 ‚àí Œ£II ‚àí Œ¥
      0 = Œª(1 ‚àí œÅ2 )Œ¥ ‚àí ŒªŒ¥ ‚àí Œ¥ + ŒªœÅ2 Œ¥ = Œ¥
      0 = Œª2 (1 ‚àí œÅ2 )Œ¥ ‚àí 2ŒªŒ¥ + (Œ£U U 1 ‚àí Œ£U U ) + Œª2 œÅ2 Œ¥ = Œ£U U 1 ‚àí Œ£U U ‚àí Œª(2 ‚àí Œª)Œ¥.

Thus, we deduce that

        Œ¥ = 0,   , Œ£EE1 = Œ£EE ,   Œ£EI1 = Œ£EI ,    Œ£II1 = Œ£II ,   and Œ£U U 1 = Œ£U U .

This proves the following theorem:

Theorem B.1 Suppose Assumption 2 is satisfied. Then the three-variable model is identi-
fied.




                                             31
References
Aruoba, B. (2008), ‚ÄúData Revisions are not Well-Behaved,‚Äù Journal of Money, Credit and
  Banking, 40, 319‚Äì340.

Aruoba, S.B., F.X. Diebold, J. Nalewaik, F Schorfheide, and D. Song (2012), ‚ÄúImproving
  GDP Measurement: A Forecast Combination Perspective,‚Äù In X. Chen and N. Swanson
  (eds.), Recent Advances and Future Directions in Causality, Prediction, and Specification
  Analysis: Essays in Honour of Halbert L. White Jr., Springer, 1-26.

Carter, C.K. and R. Kohn (1994), ‚ÄúOn Gibbs Sampling for State Space Models,‚Äù Biometrika,
  81, 541‚Äì553.

Diebold, F.X. and L. Kilian (2001), ‚ÄúMeasuring Predictability: Theory and Macroeconomic
  Applications,‚Äù Journal of Applied Econometrics, 16, 657‚Äì669.

Durbin, J. and S.J. Koopman (2001), Time Series Analysis by State Space Methods, Oxford:
 Oxford University Press.

Edwards, C.L. and E.P. Howrey (1991), ‚ÄúA ‚ÄôTrue‚Äô Time Series and Its Indicators: An Alter-
  native Approach,‚Äù Journal of the American Statistical Association, 86, 878‚Äì882.

Faust, J., J.H. Rogers, and J.H. Wright (2005), ‚ÄúNews and Noise in G-7 GDP Announce-
  ments,‚Äù Journal of Money, Credit and Banking, 37, 403‚Äì417.

Fixler, D.J. and J.J. Nalewaik (2009), ‚ÄúNews, Noise, and Estimates of the ‚ÄúTrue‚Äù Unobserved
  State of the Economy,‚Äù Manuscript, Bureau of Labor Statistics and Federal Reserve Board.

Fleischman, C.A. and J.M. Roberts (2011), ‚ÄúA Multivariate Estimate of Trends and Cycles,‚Äù
  Manuscript, Federal Reserve Board.

Gartaganis, A.J. and A.S. Goldberger (1955), ‚ÄúA Note on the Statistical Discrepancy in the
 National Accounts,‚Äù Econometrica, 23, 166‚Äì173.

Geweke, J.F. (1977), ‚ÄúThe Dynamic Factor Analysis of Economic Time Series Models,‚Äù In
 D. Aigner and A. Goldberger (eds.), Latent Variables in Socioeconomic Models, North
 Holland, 365-383.

Harding, D. and R. Scutella (1996), ‚ÄúEfficient Estimates of GDP,‚Äù Unpublished Seminar
  Notes, La Trobe University, Australia.

                                            32
Jacobs, J.P.A.M. and S. van Norden (2011), ‚ÄúModeling Data Revisions: Measurement Error
  and Dynamics of ‚ÄúTrue‚Äù Values,‚Äù Journal of Econometrics, 161, 101‚Äì109.

Kishor, N.K. and E.F. Koenig (2011), ‚ÄúVAR Estimation and Forecasting When Data Are
  Subject to Revision,‚Äù Journal of Business and Economic Statistics, in press.

Komunjer, I. and S. Ng (2011), ‚ÄúDynamic Identification of Dynamic Stochastic General
 Equilibrium Models,‚Äù Econometrica, 79, 1995‚Äì2032.

Mankiw, N.G., D.E. Runkle, and M.D. Shapiro (1984), ‚ÄúAre Preliminary Announcements of
 the Money Stock Rational Forecasts?‚Äù Journal of Monetary Economics, 14, 15‚Äì27.

Mankiw, N.G. and M.D. Shapiro (1986), ‚ÄúNews or Noise: An Analysis of GNP Revisions,‚Äù
 Survey of Current Business, May, 20‚Äì25.

Nalewaik, J. (2012), ‚ÄúEstimating Probabilities of Recession in Real Time with GDP and
  GDI,‚Äù Journal of Money, Credit and Banking, 44, 235‚Äì253.

Nalewaik, J. and E. Pinto (2012), ‚ÄúThe Response of Capital Goods Shipments to Demand
  over the Business Cycle,‚Äù Manuscript, Federal Reserve Board.

Nalewaik, J.J. (2010), ‚ÄúThe Income- and Expenditure-Side Estimates of U.S. Output
  Growth,‚Äù Brookings Papers on Economic Activity, 1, 71‚Äì127 (with discussion).

Rapach, D.E., J.K. Strauss, and G. Zhou (2010), ‚ÄúOut-of-Sample Equity Premium Pre-
  diction: Combination Forecasts and Links to the Real Economy,‚Äù Review of Financial
  Studies, 23, 821‚Äì862.

Sargent, T.J. and C.A. Sims (1977), ‚ÄúBusiness Cycle Modeling Without Pretending to Have
  too Much a Priori Theory,‚Äù In C.A. Sims (ed.), New Methods in Business Cycle Research:
  Proceedings from a Conference, Federal Reserve Bank of Minneapolis, 45-109.

Smith, R.J., M.R. Weale, and S.E. Satchell (1998), ‚ÄúMeasurement Error with Accounting
  Constraints: Point and Interval Estimation for Latent Data with an Application to U.K.
  Gross Domestic Product,‚Äù The Review of Economic Studies, 65, 109‚Äì134.

Stone, R., D.G. Champernowne, and J.E. Meade (1942), ‚ÄúThe Precision of National Income
  Estimates,‚Äù Review of Economic Studies, 9, 111‚Äì125.




                                          33
Watson, M.W. and R.F. Engle (1983), ‚ÄúAlternative Algorithms for the Estimation of Dy-
 namic Factor, MIMIC and Varying Coefficient Regression Models,‚Äù Journal of Economet-
 rics, 23, 385‚Äì400.




                                         34
