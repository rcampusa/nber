                                NBER WORKING PAPER SERIES




    DETERMINACY, LEARNABILITY, PLAUSIBILITY, AND THE ROLE OF MONEY
                      IN NEW KEYNESIAN MODELS

                                        Bennett T. McCallum

                                        Working Paper 18215
                                http://www.nber.org/papers/w18215


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                      July 2012




I am indebted to Marvin Goodfriend, Patrick Minford, Max Gillman, and Michael Magill for helpful
suggestions. The views expressed herein are those of the author and do not necessarily reflect the views
of the National Bureau of Economic Research. At the time at which this paper was first drafted, I
had a consulting relationship with the Federal Reserve Bank of Richmond. Also, an early version
of the paper was presented at a conference held by the Swiss National Bank.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2012 by Bennett T. McCallum. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to
the source.
Determinacy, Learnability, Plausibility, and the Role of Money in New Keynesian Models
Bennett T. McCallum
NBER Working Paper No. 18215
July 2012
JEL No. C61,C62,E37,E47

                                              ABSTRACT

Recent mainstream monetary policy analysis focuses on rational expectation solutions that are uniquely
stable. A number of recent studies have examined the question of whether typical New Keynesian
(NK) models, with policy rules that satisfy the Taylor principle, also exhibit solutions with explosive
inflation that cannot be ruled out by any transversality condition or any other generally accepted economic
principle. This paper contributes to that debate by supporting and developing previous arguments
suggesting that such explosive solutions are informationally infeasible. It also critiques prevailing
notions of "determinancy" and outlines two alternative approaches to solution selection.


Bennett T. McCallum
Tepper School of Business, Posner 256
Carnegie Mellon University
Pittsburgh, PA 15213
and NBER
bm05@andrew.cmu.edu
1. Introduction

         It is well known that linear rational expectations models typically possess more than one

solution.1 Instead, there is typically a multiplicity of relationships from which time paths for

endogenous variables are predicted as the response of the model economy to specified processes

that generate exogenous variables. If unmodified, this would be a highly unsatisfactory state of

affairs since it would imply that the model at hand does not provide a unique prediction about

how the model economy—and thus the actual economy being modeled—behaves under

specified conditions. Consequently, a substantial number of additional requirements have been

proposed by various researchers in order to obtain a unique prediction of the analysis to the

question of how the economy would behave under alternative policies—a prediction that is the

raison d’etre of a monetary (or non-monetary!) policy model.

         In monetary economics in particular one criterion has been rather widely accepted. It is

the criterion of a single stable solution (SSS), i.e., that among the multiple solutions that satisfy

all of the model’s relationships plus the orthogonality implications of rational expectations (RE),

there is one and only one that is dynamically stable (non-explosive). This criterion is in practice

often referred to as “determinacy,” as if the SSS requirement was equivalent to the desired

condition—namely, that the model at hand provides a unique prediction as to the behavior of the

(model) economy. A unique prediction is what “determinacy” is supposed to mean, however, so

it is unsatisfactory for this word to be used as if it were synonymous with the SSS condition.

This point has been made implicitly but effectively by Cochrane (2007), who argues that in a

wide class of “New Keynesian” (NK) models (which have been the centerpiece of monetary

analysis over the past two decades) policy behavior satisfying the “Taylor Principle” leads to


1
 Evidently the situation is even more unfavorable in non-linear models. In monetary policy analysis the usual
procedure is to work with linear models that are intended to be satisfactory approximations to actual structures.

                                                          1
satisfaction of the SSS requirement but nevertheless implies the existence of an explosive

inflation path that is not ruled out by any transversality condition or any other generally accepted

economic principle. Thus the SSS solution does not provide a unique prediction as to the

behavior of the model economy, leading Cochrane to argue that NK analysis is fundamentally

flawed.2 Indeed, the prevailing situation might well be judged as one in which the logical

foundations for mainstream monetary policy analysis are entirely unsatisfactory.

           In a subsequent paper, McCallum (2009b) agrees with Cochrane’s analytical point

regarding the explosive path but shows that the SSS solution does, and the explosive solution

does not, satisfy the criterion of “least squares learnability.” Furthermore, he argues that this type

of learnability should be considered as a necessary condition for a solution to be viewed as a

plausible contender for the unique prediction of behavior provided by the model at hand.

Cochrane (2009) contends, however, that the analysis in McCallum (2009b) is flawed in three

ways. Accordingly, in the present paper I will review this argument and then show that each of

Cochrane’s objections is analytically incorrect or inapplicable.3 In this context, the paper

develops new motivation concerning these fundamental issues in monetary policy analysis. In

addition, Sections 5 and 6 of the paper will consider the possible usefulness of two recently

developed candidates—one by Cho and Moreno (2011) and one by myself (2011b)—to be the

“selection criterion,” distinct from learnability, for the designation of a particular solution as the

one that is relevant for policy analysis with a linear RE model.

2. Cochrane’s Challenge

           A standard three-equation NK model might be written as




2
    Somewhat related arguments have been expressed by Minford and Srinivasan (2009)(2011).
3
    This position is stated, but with inadequate explanation, in McCallum (2009c).

                                                        2
(1)     yt = b0 + b1(Rt − Etπt+1) + Etyt+1 + vt                    b1 < 0

(2)     πt = βEtπt+1 + κ(yt − y t ) + ut                             κ>0

(3)     Rt = µ0 + πt + µ1(πt − π*) + µ2(yt − y t ) + et

where the variables are yt = output, y t = flexible-price “natural” output (taken to be exogenous),

πt = inflation rate, π* = target inflation rate, and Rt = one-period interest rate, all expressed in

terms of fractional deviations from steady-state values (so π* = 0). Here (1) is an “expectational

IS equation” that combines the intertemporal Euler equation (for a typical infinite-lived

household with standard time-separable preferences) with a linearized overall resource constraint

plus the assumption that the economy-wide capital stock is fixed. Equation (2) is the standard

Calvo model of imperfectly flexible price setting, and (3) is the central bank’s policy rule that

specifies settings of the interest instrument Rt in response to current values of inflation and the

output gap. With µ1 > 0 the Taylor Principle will be satisfied even if µ2 = 0. The exogenous

shocks in this system vt , ut, and et are generated by stable mean-zero stochastic processes

pertaining respectively to (i) time-preference plus natural-rate of output plus government

consumption fluctuations, (ii) price-setting behaviour, and (iii) monetary policy behavior. This

is a simplified setup but is highly representative of current mainstream analysis. Furthermore

there will be no loss in substance relating to the particular issues at hand if we simplify even

more by supposing that prices are fully flexible, in which case (2) becomes yt = y t , and also

setting setting y t = 0. Then we can write the system as

(1′)    0 = b 0 + b1 (R t − E t πt +1 ) + v t

(3′)    R t = µ0 + (1 + µ1 )π t + e t

and can combine these two relations to yield


                                                    3
(4)     0 = b0 + b1[µ0 + (1+µ1)πt + et − Etπt+1] + vt .

The latter is the form of the model that is discussed by Cochrane (2007, pp. 5-10), McCallum

(2009b), and Cochrane (2009). Cochrane (2007) shows that the essential aspects of the analysis

also obtain for a system like that of (1)-(3). Note that, with π* = 0, µ 0 will be set by any

sensible central bank to equal the steady-state real rate of interest, i.e., that µ 0 = −b 0 / b1 .

        Quantitatively, most analysts would expect the variability of vt to exceed that of et, but I

will follow Cochrane (2007) in neglecting the former, a step that is substantively unjustified but

innocuous in terms of the issues at hand. For the policy shock, it is assumed that an AR(1)

process obtains, i.e., that et = ρet-1 + εt with εt being white noise and with ρ < 1 . With this setup,

it is natural to conjecture that there will be a solution of the form

(5)     πt = φ0 + φ1et

with expectations therefore obeying Etπt+1 = φ0 + φ1ρet. Substitution in (4) then implies that this

solution is

                       1
(6)     πt = 0 −             et .
                   1+ µ1 − ρ

The latter is often referred to as the “fundamentals” or minimum-state-variable (MSV) solution,

its identifying characteristic being that it does not include state variables other than those

required by the structural model. With µ1 > 0 and ρ < 1 , (6) implies that πt is negatively related

to et and that larger values of µ1 serve to reduce the variability of πt around its target.

        Now suppose, however, that instead of (5) one looks for a solution of the form

(7)     πt = φ0 + φ1et + φ2πt-1.

Then Etπt+1 = φ0 + φ1ρet + φ2(φ1et + φ2πt-1) and a second solution, in addition to (6), is



                                                     4
(8)      πt = (1/ρ)et + (1+µ1)πt-1.

Clearly, with µ1 > 0, as specified by the Taylor Principle, this expression (8) implies an explosive

process for the inflation rate.4 That is the type of solution stressed by Cochrane and referred to

above. It seems clear that in the model at hand there is no transversality condition that would

rule out this explosive solution for the inflation rate, and that this is the case is verified explicitly

on pp. 1106-1107 of McCallum (2009b). Accordingly, one must agree that Cochrane is right to

argue that, although there is a single stable solution in the case at hand, there is not—as matters

stand—“determinacy” in the sense of a unique solution consistent with the model.

         My position, however, is that we should not be satisfied with “as matters stand,” for the

solution permitted by (8), rather than (6), is not least-squares learnable in the sense of Evans and

Honkapohja (2001)—this is demonstrated in McCallum (2009b). As a consequence, I suggest

that the alternative solution (8) is not plausible—and thus that (6) is in fact the only plausible

outcome predicted by the model at hand.

3. Learnability and Feasibility

         What is the nature of the postulated implausibility in the case of the alternative solution

(8)? It should arguably be termed an infeasibility, albeit one that pertains to information rather

than (for example) a budget constraint or production function. To see in what sense this crucial

claim is viable one must consider the nature of least-squares learnability (henceforth LSL) [as

defined by, e.g., E&H (2001, pp. 200, 232-233)]. LSL or its absence is a property, in the context

of a specified model, of each particular RE solution.

         Here I will proceed by arguing in effect that LS learnability should be regarded as a part



4
 It appears from (8) that this solution will not be defined in the measure-zero case with ρ = 0. But in that case one
can add et-1 as an additional state variable in (7) and obtain an infinity of explosive solutions that could be indexed
by the start-up value of πt-1.

                                                           5
of the requirement for a RE solution to serve as the relevant model’s prediction.5 The motivation

for this additional requirement is simple. First, for expectations to meet the orthogonality

requirements for RE, the agents must have considerable quantitative information concerning the

economy’s behavior. Second, in any RE model intended to represent behavior in an actual

market economy, the individual agents should be able to learn these quantitative details

concerning the behavior of variables—which they need to forecast for decision-making

purposes—from data generated in the past by the economy itself.6 Certainly they cannot obtain

such data by introspection, magic, or divine revelation.

         The first task at hand is to describe, in a reasonably precise way, the learning process that

is being discussed. Rather than beginning with the highly special model summarized by

equation (4), I will here proceed in terms of a rather general linear framework that will give a

better idea of the nature and scope of the learning process without requiring any significant

complication in the presentation.7 In this discussion, I assume that we are concerned with an

economy in which the agents are alike, but behave entirely independently. Suppose that the

behavior of per-capita values of prices and quantities is given by

(9)      x t = AE t x t +1 + Cx t −1 + Dz t

where xt is a m×1 vector of endogenous variables, while exogenous variables zt (n×1) are

(10)     zt = Rzt-1 + εt



5
  The present section draws heavily on McCallum (2009b).
6
  For RE to obtain, the implied forecasting relationships must be quantitatively accurate. The statement in this
sentence is part of a rationale for my position concerning learnability; it is not intended to serve as a definition of
learnability. In addition it should be noted that the present paper is concerned throughout with RE solutions that are
conventional except with respect to the informational aspect just mentioned. In particular, the paper does not
address game-theoretic issues such as those implied by monetary policy actions that depart from a specified policy
rule.
7
  This will permit us to report necessary and sufficient conditions for LSL in a very wide class of models. A short
presentation in terms of the special model (4) is included as Appendix A.


                                                           6
with εt a white noise vector and R a stable matrix. Considering fundamental solutions of form

(11)     x t = Ωx t −1 + Γz t ,

standard undetermined-coefficient reasoning establishes that, with RE temporarily specified, the

matrices Ω and Γ must satisfy

(12a) AΩ2 − Ω + C = 0

(12b)     Γ = AΩΓ + AΓR + D.

For any given Ω, (12b) implies that the matrix Γ will be determined uniquely—but typically

there are many real matrices Ω that satisfy (12a). Furthermore, if more than one of them has all

its eigenvalues smaller than 1.0 in modulus there are multiple stable solutions.

        Now, for RE to prevail, agents need to base their expectations/forecasts on accurate

quantitative knowledge of Ω and Γ; so what the agents need to learn about is the system’s law of

motion. Such knowledge must, in reality and therefore in a satisfactory model, be determined

from data generated in the past by the economy itself. The LS learning process for acquiring

such knowledge is as follows. In period t, agents develop estimates Ωt and Γt (of Ω and Γ) by

ordinary least squares using past data: they estimate the relationship x τ = Ω t x τ−1 + Γ t z τ using

data from periods dated τ = t−1 and earlier. Using these estimates, the agents forecast xt+1 as

x et+1 = Ω t x t + Γ t Rz t .8 Then from substitution in (9), but using x et+1 in place of E t x t +1 , the

outcome xt is generated—as a consequence of the supply and demand behavior summarized in

(9)—as

(13)     x t = A[Ω t x t + Γ t Rz t ] + Cx t −1 + Dz t .


8
 The discussion proceeds for simplicity as if R were known. E&H (2001, p. 181) mention, however, that this
assumption is not needed for the relevant results (since exogenous variables can be treated as endogenous). It might
be mentioned incidentally that in the discussion of E&H (2001) the least squares estimation calculations are often
described as being conducted by recursive least squares.

                                                           7
Next, in period t+1 agents add the newly generated observation to their data, estimate Ωt+1 and

Γt+1, form expectations x et+ 2 , make supply-demand choices via (9), and observe xt+1. In periods

t+2, t+3, ... the process continues.9

         We visualize this process as going on indefinitely.10 Then, for a particular value of Ω

(with associated Γ) we can ask if the process is “locally stable” in the sense that the estimates Ωt

and Γt approach the (hypothetically) true values Ω and Γ as t → ∞ , provided that they begin in

the “startup period” with estimates that are not too far from these true values. If the answer is

“yes,” then that particular RE solution is “stable under LS learning,” in the Evans and

Honkapohja terminology, and the model economy can be viewed as tending to behave as implied

by that RE solution if it (the economy) has been operating for a large number of periods. If, on

the other hand, a particular RE solution, relating to a particular solution to (12a) for Ω, is not

stable under LS learning, the implication/prediction of the analysis is that the model economy—

and thus the actual economy represented by the model—will not be found in an equilibrium

corresponding to this particular RE solution.11

         Under what conditions will a particular RE solution, itself dynamically stable, be stable

under LS learning? For the model (9)-(10), the basic analytical result of Evans and Honkapohja

is, in my notation, that the LS learning process will be locally stable if all of the eigenvalues of

the following matrices have real parts smaller than 1.0:



9
  Evans and Honkapohja (2001) also consider a second information assumption, namely, that in each period t an
observation on xt is not available in the learning process. In this case the term xt on the right-hand side of (13)
would be replaced with x et . In the monetary model under discussion in Section 2, this would result in no change in
the learnability findings—although it will in cases in which C ≠ O in (9). See E&H (2001, pp. 244-245).
10
   Note that while the learning process is going on, forecasts are not equal to those implied by RE.
11
   It is the case that in some of their work E&H use a “constant gain” version of the LS learning process as a model
of expectation formulation, rather than as a justification of a particular RE solution. See e.g., E&H (2001, pp. 333-
359). Analysts following this alternative approach include Orphanides and Williams (2005), among others.

                                                          8
(14a)   F = (I − AΩ) −1 A

(14b) Ω '⊗ F

(14c) R '⊗ F .

The proof of this result is presented by E&H (1998) on pp. 26-32, the last two pages being an

application to the linear framework of equations (9)-(11) of a more general analysis [by

Benveniste, Métivier, and Priouret (1990)] that is summarized on E&H’s pp. 26-30.

Alternatively, the result is presented in the treatise of E&H (2001), with the summary statement

of pp. 236-238 utilizing analysis developed on pp. 229-235 and 121-134. If, on the other hand,

conditions (14) are not satisfied, E&H indicate that, with a few regularity assumptions, “… one

can show convergence [obtains] with probability zero” (1998, p. 32).

        At this point a critic might object on the grounds that there are many possible learning

processes, and one cannot know that the one described above is realistic. My response to that

observation emphasizes that LS learnability is being used, in the present discussion concerning

monetary policy, as a necessary condition for plausibility of a RE equilibrium. In that context I

have argued before that: “... Of course any particular learning scheme might be incorrect in its

depiction of actual learning behavior. But in this regard it is important to note that the LS

learning process in question assumes that (i) agents are collecting an ever-increasing number of

observations on all relevant variables while (ii) the structure is remaining unchanged.

Furthermore, (iii) the agents are estimating the relevant unknown parameters (iv) with an

appropriate estimator in (v) a properly specified model. Thus if a proposed RE solution is not

learnable by the process in question—the one to which the E&H results pertain—then it would

seem highly implausible that it could prevail in practice” (McCallum, 2007, p. 1378). In other


                                                 9
words, the process is distinctly “slanted” or “biased” toward a finding of learnability, a bias that

is appropriate for a necessary condition.

         It might also be objected that the notion being advanced—that individual agents should

have some way of obtaining the information necessary to form expectations—represents an

additional requirement not included in standard definitions of economic equilibria. At a first

glance, that might seem to be so, but in fact it is misleading. Actually, but even in standard (i.e.,

RE) analysis, one specifies information sets that include quantitative features of the system plus,

at a maximum, current and past values of relevant variables.12 In standard stochastic models,

therefore, knowledge of future variables is excluded as infeasible. In that manner, standard

analysis actually does typically include a form of information feasibility as a requirement for

equilibrium. What LS learnability does, in a sense, is to extend the requirement of information

feasibility so as to pertain to some limited quantitative knowledge of the economy’s structure.

More specifically, for agents to be able to form expectations rationally—i.e., without systematic

expectational errors—they must be able to develop quantitative knowledge of the economy’s law

of motion on the basis of observations from its past. Then LS learnability posits a particular

process of information acquisition that is highly optimistic with respect to the possibility of the

requisite information being acquired. It is in this sense, that the absence of LS learnability

should be regarded as representing a type of informational infeasibility.

         With respect to monetary policy, the point of the present discussion is, of course, that

application of the LS learnability criterion does, in the monetary policy model of Section 2,

support the standard NK solution (6) while eliminating the explosive solution of equation (8).



12
  For some purposes perfect-foresight analysis is useful, of course, but one would not use that assumption in an
analysis that is concerned with (e.g.) the variability of asset prices or macroeconomic variables in a setting that
includes stochastic shocks.

                                                          10
That conclusion is logically implied by the general analyses of Bullard and Mitra (2002) and

Honkapohja and Mitra (2004), and was mentioned by McCallum (2003, p. 1161), but let us

verify it here by reference to the setup of equations (1)-(6) and conditions (14).

         To begin, it will be noted that, if there are no lagged endogenous variables in the system,

then C = 0 implying that Ω = 0 and F = A. Then the first two of conditions (14) amount to the

requirement that the eigenvalues of A all have real parts less than 1. In the basic system

summarized in (5) above, the fundamentals solution has Ω = 0 and F = A = 1/(1 + µ1). Thus it is

clear that for solution (6) the LS learnability requirements (14a-c) are satisfied. By contrast, the

non-fundamentals solution (8) yields πt = (1/ρ)et + (1+µ1)πt-1, implying that Ω = 1 + µ1 and thus

that F = (I − AΩ) −1 A = [1 − ((1 + µ1 ) /(1 + µ1 ))]−1 (1/(1 + µ1 )) = [1-1]-1 (1/(1 + µ1 )) = (1/(1 + µ1 )) /0.

Thus in this case F > 1 + µ1 and at least two of the three conditions (14) are violated.

Accordingly, the explosive solution is not learnable—convergence to (8) occurs with probability

zero. Although (8) satisfies the orthogonality conditions for a RE solution, it is implausible

(according to the present argument) that an economic system matching the model’s specification

would generate outcomes of the type that (8) describes.

4. Cochrane’s Objections

         As already mentioned, Cochrane does not accept the conclusion presented in the previous

section. He does not explicitly disagree with the idea that learnability is important, but presents

three objections to my application in the monetary policy context that is at issue. These

objections are presented in his JME comment (Cochrane 2009); they will be reviewed and

refuted in the present section.

         First, and most prominently, Cochrane argues that the monetary policy shock—et in

equations (3), (6), and (8) above—is not observable by private agents but is implicitly assumed


                                                         11
to be so in my analysis. His unobservability concern is in principle reasonable, I would agree,

and it is true that no explicit account of that point was taken in the discussion in McCallum

(2009b). It transpires, however, that this does not matter for the issue at hand—i.e., learnability

vs. non-learnability of the NK and explosive RE solutions featured by Cochrane. A preliminary

observation is that in the monetary policy case of concern, he and I should probably both be

including the private-sector technology shock as the relevant one in the stripped-down, one-

shock model in which the current discussion is being conducted.13 But, putting aside that matter,

the main point is that the absence of observability of et does not invalidate my argument

regarding learnability vs. non-learnability in the analysis at hand. Let us again consider the

model in (4) above, namely, π t = aE t πt +1 + u t with ut = −aet and et = ρet-1 + εt (εt is white noise

and a=1/(1+µ1) < 1).14 Thus the model can be written as π t = ρπ t −1 + aE t π t +1 − aρE t −1π t − aε t

where the only unobservable component is white noise. Then we can define ξ t = E t πt +1 and

formulate this relationship as

                  πt  a 0   E t π t +1  ρ −aρ   π t −1   −aε t 
(15)              =                     +              +       
                  ξ t  1 0   E t ξ t +1   0 0   ξ t −1   0 

If we use A and C to denote the two 2×2 matrices, does this system have the same learnability

conditions as given for the system (4) and e t = ρe t −1 + ε t above? I have not been able to find any




13
  It is a more appropriate shock to include because we are concerned with economies in which technology shocks
certainly occur, whereas exogenous policy shocks should not appear at all in a well-designed monetary policy rule.
Then the shock in the system being analyzed would be the technology shock for the typical agent (vt in my paper’s
equation (1)) and would be observable.
14
  It is assumed that µ0 in (4) is set equal to π*−b0/b1, i.e., that the monetary authority take correct account of the
long-run average real rate of interest and its own target for the average inflation rate, and also that π* = 0 since
variables are defined as measured relative to steady states.

                                                           12
results in Evans and Honkapohja (E&H) (2001) that apply to this particular formulation,15 but in

E&H (1998, pp. 30-32) there is an applicable analysis, and it indicates that the presence of an

unobserved white noise shock is irrelevant to learnability of the various RE solutions.16

Specifically, the relevant mapping (from perceived to actual law of motion) does not involve

parameters relating to the unobservable shock. This result evidently pertains to all models in the

very broad class implied by the formulation in equations (9) and (10) above.17 One way to

understand this perhaps surprising result is as follows: Exogenous white noise shocks do not

overturn learnability because they represent purely random influences that are overwhelmed

asymptotically as the number of observations (on an unchanging system) increases.

Furthermore, with shocks that are not white noise, the systematic component can be taken care of

by way of its effects on observable variables, as in equation (1). This is not strictly possible for

moving-average shocks, rather than autoregressive shocks, but one can approximate moving-

average shocks with autoregressive shocks of a larger-than-usual but finite order.18

         The second topic in Cochrane’s criticism concerns his interpretation of the monetary

policy rule, which he describes as involving central-bank “hyperinflationary threats” or threats to

“blow up the world” (Cochrane 2007, p. 4). In this regard his position seems inapplicable. In

the model that we are discussing, policy is specified by the rule Rt = µ0 + (1 + µ1)πt + et in all



15
   There are numerous examples in E&H (2001) in which unobservable white noise shocks are included and do not
overturn results that obtain in their absence, but unobservable shocks that are autocorrelated are not considered. In
the analysis of systems such as (9)(10) of my (2009b) paper, there are no white-noise or other unobservables.
16
   In addition, George Evans has provided me with an explicit proof that, in the case at hand, the fundamentals
solution is learnable and the alternative explosive solution is not learnable. His note is available on the web at:
http://public.tepper.cmu.edu/facultydirectory/FacultyDirectoryProfile.aspx?id=96
17
   In effect, a reformulation such as that in (15)-(16) does not alter the system, but moves serial correlation of
exogenous variables into the behavior of endogenous variables—thereby making condition (14b) relevant (instead of
14c), while enlarging the F matrix in (14a) such that F has more zero eigenvalues—i.e., adding a number of
“infinite” eigenvalues to the list of the system’s (generalized) eigenvalues.
18
   This need arises also with observable shocks.

                                                         13
circumstances. If “threats” were relevant there would be threatened departures from this rule, to

be invoked in certain specified situations. There may be good reasons to be interested in game-

theoretic analyses involving alternative modes of central-bank behavior. But in the basic

rational-expectations analysis of the model that is under discussion there is nothing of that type.

What the central bank’s rule promises is to make nominal interest rates higher than otherwise

when inflation is above its target value. In the presence of some price-level stickiness—not

included in our stripped-down models but included in the three-equation NK framework that

both he and I would use if there was any essential difference in outcome—the higher nominal

interest rate would then bring about a reduced level of real aggregate demand. Thus the policy

behavior promised by the Taylor rule is to make demand relatively low when inflation (and/or

inflationary pressure) is relatively high.

       As a final matter, there are numerous references in Cochrane’s discussion to the lack of

identification of the policy parameter a (equivalent to 1/(1+µ1) above). Here Cochrane’s

analysis fails to recognize the crucial difference between structural and reduced-form

relationships in the context of learnability analysis. The point is that that learnability of the type

under discussion does not require identification, by the model economy’s agents, of this

parameter. The way that the relevant type of learnability analysis proceeds is by substituting

forecasts from a vector-autoregression model (estimated on all past observations) in place of

expectational variables in the model, and then determining whether the implied behavior

converges to a particular RE solution as time passes and data used in estimation of the

forecasting regression increases. The relations estimated for learning purposes by agents in the

model are therefore reduced-form, not structural, equations (from these agents’ perspective). So

the non-identification of the structural parameter in question is not relevant to the issue of



                                                  14
learnability.

        At this point I turn to more recent developments concerning these arguments. First, in a

revised version of his NBER working paper 13409, issued (with the same W.P. number) in 2010,

Cochrane argues explicitly that identifiability of the parameter in question (e.g., a or µ1) would

be important in a researcher’s empirical study designed to determine whether the policy rule

followed by an actual central bank (over some span of time) did, or did not, satisfy the Taylor-

Principle requirement (which is that µ1 > 0 in the simple system being discussed above). That

point is, I believe, correct. Accordingly, I must express basic agreement with Cochrane’s belief

that studies such as Clarida, Gali, and Gertler (2000) have not correctly located the nature of the

actual weakness in U.S. monetary policy during the 1970s. I am not entirely convinced,

however, that the necessary identification would be absent in more fully developed models, in

which there might be relevant predetermined variables in the system that are plausibly excluded

from the monetary policy rule. More generally, there are various points developed in this revised

version of WP 13409, but it does not consider the role of learnability.

        More recently, a slightly revised version of the current WP13409, entitled “Determinacy

and Identification with Taylor Rules,” has appeared in the Journal of Political Economy

(Cochrane, 2011). My first impression is one of substantial agreement with most of the

arguments—to the extent that I understand them—in this published paper. It includes,

surprisingly, no consideration at all of learnability or of the debate reviewed above. But an

appendix to that paper, Appendix B, is available on the JPE web site and on Cochrane’s home

page. That appendix does discuss learnability and other aspects of related to the matters of

concern here. Unfortunately, it repeats the flaws mentioned above: (i) a mistaken belief that the

non-observability by agents of the monetary policy shock [et in equations (1)-(8) above]


                                                 15
overturns the learnability finding when the Taylor principle is satisfied and (ii) a mistaken belief

that identification of the policy-rule parameter ‘a’ by agents in the model is needed for

learnability.19

5. Alternative Selection Criteria: Cho and Moreno

         The preceding sections have suggested that LS learnability should be considered as a

necessary condition for a specific RE solution to be considered economically plausible. In this

section and the next the object is to relate that suggestion to two recent proposals for a “selection

criterion” to be used in designating which of a model’s multiple RE solutions should be regarded

as providing its predictions concerning economic behavior. In an imaginative and promising

recent publication, Cho and Moreno (2011) have developed an algorithm for generating a

“forward solution” of the fundamentals type (i.e., excluding “bubble” components) that,

provided that it exists, is unique for all cases of the general linear model specification given

above in equations (9) (10). A brief outline is as follows. Given (9) and (10), one can define the

following matrices: M1 = A, Ω1 = C, Γ1 = D and then recursively for k = 2, 3, … also define

(16a)    M k = (I − AΩ k −1 ) −1 M k −1

(16b)     Ω k = (I − AΩ k −1 ) −1 C

(16c)    Γ k = (I − AΩ k −1 ) −1 (D + AΓ k −1R) .

These expressions clearly define a unique iterative process. Provided that for all k = 1, 2, … the

regularity condition det (I − AΩ k ) ≠ 0 is satisfied, then also

(17)     x t = M k E t x t + k + Ω k x t −1 + Γ k z t

for all k = 1, 2, …. Then the issue is whether the matrices Mk, Ωk, and Γk converge as k → ∞. If


19
  In addition, incidentally, Cochrane incorrectly characterizes my (2003) distinction between “nominal
indeterminacy” and the real solution multiplicity with which both he and I are concerned in the matters at hand.

                                                         16
so, a “forward convergence condition” (FCC) is satisfied. If in addition Mk → O the limiting

case of the relationship is

(18)     x t = Ω∞ x t −1 + Γ ∞ z t ,

which defines a single RE solution, one that excludes extraneous “bubble” components. This

forward method (FM) solution then provides a unique solution in terms of fundamentals, which

Cho and Moreno recommend as the most attractive solution among those that do not involve

“bubbles.” The clarity of the uniqueness result is quite attractive.20 One limitation of this

approach is that the discussion is restricted to solutions based only on “fundamentals”; no

consideration of “sunspot” solutions is provided.

6. Alternative Selection Criteria: McCallum

        In a very recent working paper (McCallum, 2011b), I have described a plausibility

condition that is conceptually distinct from the LS learnability condition promoted in Sections

1-4 above. It is that the solution coefficients included in the matrices Ω and Γ of equation (11)

must not feature infinite discontinuities in the limit as the parameter matrix A→O.21 The idea in

this case is that very small changes, in those structural parameters that reflect the influence of

expectational variables on agents’ supply-demand choices, should not result in enormous

changes in the resulting choices. In my working paper it is shown that in the general linear

model (9) (10) this condition is satisfied by a single solution.22 It transpires, moreover, that this

single solution is the same as the “minimum state variable” solution originally recommended in

McCallum (1983). A proof is provided below in Appendix B and the criterion is given a



20
   The iterative solution is similar to ones discussed by Flood and Garber (1980) and Sargent (1979, pp. 192-5) but
the Cho and Moreno analysis provides generality and uniqueness results that seem to be essential and quite original.
21
   By A → O for matrices A and O, I mean αA → O as α → 0 where α is a scalar.
22
   This result pertains to the case in which sunspot solutions are permitted, as well as to the case in which only
fundamental solutions are considered.

                                                        17
“causality” interpretation in McCallum (2011a).

           Cho and Moreno (2011, p. 269) have noted explicitly that their forward-method solution

does not always coincide with this MSV solution, that is, the MSV/continuity criterion does not

always agree with the forward-solution criterion. In this regard Cho and Moreno provide an

example (2011, p. 269) in which there is a MSV solution but the forward solution does not exist.

However, in this example the MSV solution does not have the property of LS learnability. Thus,

since my analysis views both continuity/MSV and learnability as necessary conditions for a

solution to be plausible, there is apparently no actual disagreement provided by this particular

example.

7. The Role of Money

           The model (1) – (3) is often interpreted as pertaining to a “cashless economy” in which

there is no medium of exchange, i.e., no money. That is not a necessary interpretation, however;

instead I would take this to be a model in which there is a medium of exchange (MOE) that

provides transaction-facilitating services and a resulting money demand function of the form23

(19)        m t − p t = γ 0 + γ1 y t + γ 2 R t + ζ t

where γ1 > 0, γ 2 < 0, and the disturbance ζ t is presumably related to the other shock processes in

the model (1)-(3). Then if the central bank conducts policy by choosing Rt as specified by (3),

this relation (19) will serve only to specify how much money the central bank has to supply each

period in order to implement its policy as specified in (3); relation (19) will have no effect on the

behavior of either yt or pt and may not need to be considered at all.

           It is true, of course, that a money demand function of the form in (19) is a special case

that will come about only if the way in which money affects transaction costs, in the (implicit)


23
     Here mt denotes the relevant money stock, expressed in fractional deviation units.

                                                           18
model that underlies (1)-(2), involves a transaction-cost function that is separable. And that is a

special and quite unlikely form for the transaction cost function to assume. But my own attempt

to estimate the magnitude of the effect on the model’s properties of specifying a more realistic

transaction cost function led to the conclusion that the quantitative effects of this correction are

negligible.24

         Accordingly, the standard analytical approach of the New Keynesian25 mainstream of

recent years does not seem to be fundamentally flawed, in the sense that it is applicable to an

economy in which there is in fact a tangible medium of exchange. Also, it is in my opinion

appropriate that this analysis includes a price adjustment relationship (aka “Phillips curve”) that

involves some sluggishness in prices, thereby imparting a non-trivial effect of monetary policy

on the cyclical behavior of real output and employment.26 Whether the details of the usual

Calvo-type adjustment relationship are well enough understood to enable central banks to

successfully conduct activist countercyclical policy in a desirable manner is less clear. It may

well be that the best thing that central banks can do to stimulate output and employment is to

keep inflation low and steady. No analysis of these issues has been attempted here.

8. Conclusion

         A brief summary of this paper’s argument is as follows. In recent monetary policy

analysis, it has been common practice to view models as possessing determinacy if they feature a

single RE solution that is dynamically stable. Cochrane (2007) has emphasized that the single-



24
   See McCallum (2001). A similar exercise was independently conducted by Woodford (2003, pp. 111-123) with
results that were extremely close to mine. Ireland (2004) took a different approach but obtained similar conclusions.
25
   The term “New Keynesian,” when applied to the mainstream analytical approach of the past 20 years, is perhaps a
misnomer. This approach seems closer to the “monetarist” position of Friedman, Schwartz, Brunner, Meltzer,
Laidler, and Parkin during the Keynesian vs. Monetarist debates of the 1970s than to the “Keynesian” position of
Tobin, Modigliani, Samuelson, Solow, Gordon, Okun, and Klein.
26
   To exclude any such relationship would be to imply that an extreme tight money episode engineered by the central
bank would not induce a recession—thereby suggesting that the Volcker Disinflation was just an accident.

                                                         19
stable-solution (SSS) condition is not sufficient as a criterion of genuine determinacy, however,

because in typical New Keynesian models there exists a dynamically explosive solution for

inflation that is not ruled out by any transversality condition and accordingly can be eliminated

only by an arbitrary dictum. McCallum (2009b) agrees with this specific proposition, but shows

that in these models it is typically the case that the explosive solutions in question are not least-

squares learnable. Further, he argues that such learnability should be considered a necessary

condition for a solution to be regarded as a model’s prediction of the depicted economy’s

behavior since it amounts to a feasibility condition that pertains to quantitative information

available to individual agents. Consequently, he argues that, despite Cochrane’s point, the

solution typically utilized in recent policy analysis is in many (perhaps not all) cases the

appropriate one. Cochrane’s (2009) response contends that there are three weaknesses in

McCallum’s argument. Here we elaborate on McCallum’s (2009c) claim that in all three cases

Cochrane’s argument is analytically incorrect or inapplicable. First, the presence of unobserved

exogenous shocks does not overturn learnability conclusions. Second, Cochrane’s argument

about “hyperinflationary threats” is not consistent with the analytical setting in which the

argument is normally conducted, namely, one in which the central bank is following a specified

policy rule. Third, the point that a particular structural parameter, concerning the central bank’s

policy behavior, is not identifiable by an econometrician studying the economy-plus-policy

process is not relevant to the learning process for the private-sector agents in the model. The

learning of these agents concerns forecasting of inflation and output in the model economy from

a reduced form perspective; the identification of a structural parameter by the agents is not

necessary for this step.

       In addition, the paper reviews two recent proposals for selection of a single RE solution



                                                  20
as relevant for policy analysis. First, Cho and Moreno (2011) have promoted a recursive

“forward solution” yielding a fundamentals solution that includes no “bubble” components; they

show that such a solution is unique in all cases in which it exists. Second, McCallum (2011b)

has shown that in all linear models of a standard broad class there is a single RE solution that is

plausible in the sense of not implying infinite discontinuities in solution parameters (and impulse

response functions) for extremely small changes in structural parameters pertaining to the

magnitude of response of supply-demand actions to expectational variables.

       Finally, the paper considers the question of whether a policy rule, of a type that involves

period-by-period control of a nominal interest rate, is necessarily unsatisfactory in some

fundamental manner, presuming that the economy is one in which a tangible, transaction-

facilitating, medium of exchange exists. The paper’s conclusion is that the answer is “no,”

which is not the same as arguing that an interest rate instrument is inherently superior to a

monetary-aggregate instrument such as the monetary base.




                                                 21
                                                       Appendix A

           It may be useful, for expository purposes, to describe the LS learning process again, but

now for the special model of equation (4), which we here write as πt = aE t π t +1 + u t , where

a = 1/(1 + µ1 ) and ut = −aet. The RE solution corresponding to (6) is then πt = ψ1u t with

            1
ψ1 =            . For the LS learning process we assume that agents do not know the values of a or
         1 − aρ

ψ1 and accordingly use in place of E t πt +1 the value πet+1 to be defined momentarily. Thus in each

period the agents estimate the relationship πt = ψ1t u t , where the estimate ψ1t is obtained by least

                                                                                t −1          t −1
squares regression with data from all previous periods: ψ1t = [∑ u ]                   2 −1
                                                                                       τ      ∑ u π . 27
                                                                                                     τ   τ    Then
                                                                                τ=1           τ=1



expectations are given by πet+1 = ψ1t ρu t and πt is generated as

(A-1)                π t = a(ψ1t ρu t ) + u t .

                                                                                                                1
In this simple setting, it is easy to see that if the process is such that ψ1t → ψ1 =                               , then in
                                                                                                             1 − aρ

the limit we have

                              1                      aρ              1 
(A-2)                π t = a          ρu t  + u t =       + 1 u t =         ut ,
                              1 − aρ                1 − aρ          1 − aρ 

that is, the RE solution (6). Does the process converge? Clearly the learnability conditions

analogous to (14a)-(14c) are that the 1×1 matrices a, 0, and aρ all have eigenvalues with real

parts less than 1, that is, that a < 1 and aρ < 1. But a < 1 is implied by the Taylor Principle

condition µ1 > 0 whereas ρ < 1 by assumption. Consequently, we see that learnability prevails




27
     In principle, a constant term should also be included. It is omitted here for expositional simplicity.

                                                             22
for the MSV solution (6). In addition, the non-learnability result for the alternative solution (8)

can be obtained in an analogous fashion.

                                                      Appendix B

           The object here is to show that in the model (9)(10) the solution (11) for which Ω → C

as A → O is the same solution as the one for which Ω → O as C → O . Let us begin with the

case in which A is nonsingular. Then we can express the crucial matrix quadratic (12a) as

                               Ω 2   A −1      − A −1C   Ω 
(B-1)                           =                        .
                              Ω   I               O  I 

Let M denote the square matrix of order 2m × 2m.28 Clearly its eigenvalues are the numbers

denoted λ that satisfy

                                 A −1 − λ I         − A −1C 
(B-2)          det(M −λI) = det                              = 0.
                                 I                   O − λI 

Next, an identity for partitioned matrices reported by Johnston (1972, eqn. 4-37, p. 95) implies

that

(B-3)           det(M −λI) = det(A −1 − λI) det[−λI + (A −1 − λI) −1 A −1C] = 0.

Thus we see, from inspection of the latter, that half of the eigenvalues of M are the eigenvalues

of A−1, while the other half depend upon both A and C. Then by further inspection of (B-3) we

see that when C = O, the second half of the λs are all equal to 0. Thus the single solution given

by the particular eigenvalue arrangement for which the eigenvalues of Ω all approach zeros as

C → O , simultaneously has the other half of the eigenvalues of M approaching the eigenvalues

of A−1.

.          Now consider the same arrangement but with C held fixed and consider the implication


28
     Note that here the matrix M is not related to the matrices denoted Mk in section 5.

                                                            23
of A → O . Then the eigenvalues that approached zeros in the previous case now approach the

eigenvalues of C while the eigenvalues that approached those of A−1 before now approach ± ∞.

This establishes the result at issue for the case in which A is nonsingular.

           When instead A is singular, similar results obtain but with the matrix A being replaced in

the argument by the matrix F = (I − AΩ)−1A.29 The system’s generalized eigenvalues (geigs)

then include those of F−1 and Ω, instead of those of A−1 and Ω. As C → O , we have the m

eigenvalues of Ω approaching zeros and the other m geigs approaching those of F−1 . So with the

same arrangement, we find that as A → O , the geigs of F−1 each approach ± ∞.




29
     See McCallum (2007, pp. 1381-1383) for development of this result.

                                                         24
                                          References

Benveniste, A., M. Metivier, and P. Priouret (1990) Adaptive Algorithms and Stochastic

       Approximations. Springer-Verlag.

Bullard, James, and Kaushik Mitra (2002) “Learning About Monetary Policy Rules,” Journal of

       Monetary Economics 49, 1105-1129.

Cho, Seonghoon, and Antonio Moreno (2011) “The Forward Method as a Solution Refinement

       in Rational Expectations Models,” Journal of Economic Dynamics and Control 35(3),

       257-272.

Clarida, R., Gali, J., and M. Gertler (2000) “Monetary Policy Rules and Macroeconomic

       Stability: Evidence and Some Theory,” Quarterly Journal of Economics 115, 147-180.

Cochrane, John H. (2007) “Inflation Determination with Taylor Rules: A Critical Review.

       NBER Working Paper 13409. [Note that current on-line version of WP 13409 is a revised

       2010 version in which much of the relevant material has been removed.]

_____________. (2009) “Can Learnability Save new-Keynesian Models?” Journal of Monetary

       Economics 56, 1109-1113.

_____________. (2011) “Determinacy and Identification with Taylor Rules,” Journal of Political

       Economy 119, 565-615.

Evans, George, and Seppo Honkapohja (1998) “Economic Dynamics with Learning: New

       Stability Results,” Review of Economic Studies 65, 23-44.

______________________________. (2001) Learning and Expectations in Macroeconomics.

       Princeton University Press.

Flood, Robert P., and Peter M. Garber (1980) “An Economic Theory of Monetary Reform,”

       Journal of Political Economy 88, 24-58.



                                              25
Honkapohja, Seppo, and Kaushik Mitra (2004) “Are Non-Fundamental Equilibria Learnable in

       Models of Monetary Policy? Journal of Monetary Economics 51, 1743-1770.

Ireland, Peter N. (2004) “Money’s Role in the Business Cycle,” Journal of Money, Credit, and

       Banking 36, 969-983.

Johnston, J. (1972) Econometric Methods, 2nd ed. McGraw-Hill.

McCallum, Bennett T. (2001) “Monetary Policy Analysis in Models without Money,” Federal

       Reserve Bank of St. Louis Review 83(4), 145-160.

_________________. (2003) “Multiple-Solution Indeterminacies in Monetary Policy Analysis.”

       Journal of Monetary Economics 50, 1153-1175.

________________. (2007) “E-Stability Vis-à-vis Determinacy Results for a Broad Class of

       Linear Rational Expectations Models.” Journal of Economic Dynamics and Control 31,

       1376-1391.

__________________. (2009a) “Indeterminacy from Inflation Forecast Targeting: Problem or Pseudo-

       Problem?” Federal Reserve Bank of Richmond Economic Quarterly 95(1), 25-51.

________________. (2009b) “Inflation Determination with Taylor Rules: Is New-Keynesian

       Analysis Critically Flawed?” Journal of Monetary Economics 56, 1101-1108.

______________. (2009c) “Rejoinder to Cochrane,” Journal of Monetary Economics 56, 1114-5.

______________ (2011a) “Causality, Structure, and the Uniqueness of Rational Expectations

       Equilibria,” Manchester School 79, 551-566. Also available as NBER Working Paper

       15234, August 2009.

______________. (2011b) “A Continuity Refinement for Rational Expectations Solutions,”

       Working Paper, Carnegie Mellon University.

Minford, Patrick, and Naveen Srinivasan. (2009) “Determinacy in New Keynesian Models: A

       Role for Money After All? Cardiff University Working Paper.

                                                26
_________________________________. (2011) “Ruling Out Unstable Equilibria in New

       Keynesian Models,” Economic Letters 112, 247-249.

Orphanides, Athanasios, and John C. Williams (2005) “Imperfect Knowledge, Inflation

       Expectations, and Monetary Policy,” in Ben S. Bernanke and Michael Woodford, eds.,

       Inflation Targeting. University of Chicago Press for NBER.

Sargent, Thomas J. (1979) Macroeconomic Theory. Academic Press.

Woodford, Michael. (2003) Interest and Prices: Foundations for a Theory of Monetary Policy.

       Princeton University Press.




                                             27
