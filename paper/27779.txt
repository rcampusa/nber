                             NBER WORKING PAPER SERIES




            AFFIRMATIVE ACTION AND PRE-COLLEGE HUMAN CAPITAL

                                        Mitra Akhtari
                                         Natalie Bau
                                   Jean-William P. Laliberté

                                     Working Paper 27779
                             http://www.nber.org/papers/w27779


                    NATIONAL BUREAU OF ECONOMIC RESEARCH
                             1050 Massachusetts Avenue
                               Cambridge, MA 02138
                                  September 2020




We gratefully acknowledge funding from the Lab for Economic Applications and Policy and the
Connaught Fund. The Texas Education Agency and a large urban school district provided
invaluable administrative data for this project. We are grateful to Josh Angrist, Peter Blair,
Roland Fryer, Brent Hickman, Caroline Hoxby, Asim Khwaja, Louis-Philippe Morin, Phil
Oreopoulos, Sarah Reber, Alex Whalley, Wesley Yin, and seminar and conference participants at
the NBER Summer Institute, IZA, Harvard, Brown, UCL, UBC, Purdue, Clemson, Collegio
Carlo Alberto, the Ohlstadt workshop, CEA, University of Calgary, and UCLA for their helpful
comments. We also thank Graham Beattie for his help with the newslibrary.com database. The
views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2020 by Mitra Akhtari, Natalie Bau, and Jean-William P. Laliberté. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.
Affirmative Action and Pre-College Human Capital
Mitra Akhtari, Natalie Bau, and Jean-William P. Laliberté
NBER Working Paper No. 27779
September 2020
JEL No. I21,I24,J15,J24,J48

                                          ABSTRACT

Racial affirmative action policies are widespread in college admissions. Yet, evidence on their
effects before college is limited. Using four data sets, we study a U.S. Supreme Court ruling that
reinstated affirmative action in three states. Using nationwide SAT data for difference-in-
differences and synthetic control analyses, we separately identify the aggregate effects of
affirmative action for whites and for underrepresented minorities. Using state-wide Texas
administrative data, we measure the effect of affirmative action on racial gaps across the pre-
treatment test score distribution. When affirmative action is re-instated, racial gaps in SAT
scores, grades, attendance, and college applications fall. Average SAT scores for both whites and
minorities increase, suggesting that reductions in racial gaps are driven by improvements in
minorities' outcomes. Increases in pre-college human capital and college applications are
concentrated in the top half of the test score distribution.

Mitra Akhtari                                   Jean-William P. Laliberté
Harvard University                              Department of Economics
110 Oxford Street, Apt 3A                       University of Calgary
Cambridge, MA 02138                             2500 University Drive NW
mitra.akhtari@airbnb.com                        Calgary, Alberta, T2N 1N4
                                                CANADA
Natalie Bau                                     jeanwilliam.lalibert@ucalgary.ca
Department of Economics
University of California at Los Angeles
Bunche Hall 8283
315 Portola Plaza
Los Angeles, CA 90095
and NBER
nbau@ucla.edu
1       Introduction
Economic opportunity is dramatically unequal across racial groups in the United States
(Chetty et al., 2020; Derenoncourt, 2019; Darity Jr et al., 2018; Bayer and Charles, 2018).
Access to higher education may be an important equalizing force (Chetty et al., forthcoming),
but many minority groups are still underrepresented in American colleges, particularly at
selective institutions. African Americans account for 15% of the college-aged population
but only make up 6% of freshmen, and the underrepresentation of African Americans and
Hispanics has grown over the last 35 years (Ashkenas et al., 2017).
    Affirmative action (AA) policies that weigh race or ethnicity as one factor in the college
admission process can address past inequities and create opportunities for these students.
Indeed, motivating the creation of these policies in the 1960s, at a 1965 speech at Howard
University, Lyndon B. Johnson explained, "You do not take a person who, for years, has
been hobbled by chains and liberate him, bring him up to the starting line in a race, and
then say, `you are free to compete with all others,' and still justly believe that you have been
completely fair."1 However, these policies are also highly controversial and have repeatedly
been challenged by court cases at the sub-national and national level.2 Eight states have
banned racial affirmative action at all public universities. Altogether, despite both the po-
tential of affirmative action policies to address inequities and the controversy surrounding
them, relatively little is known about whether these policies affect students prior to reaching
college. This gap in the literature is important: closing racial achievement gaps in secondary
school could be an effective tool for reducing inequities in long-term outcomes.
    Affirmative action policies may affect pre-college human capital investment by incentiviz-
ing students, their parents, and their teachers to change their behavior in response to changes
in the returns to pre-college human capital. Theoretically, affirmative action policies favoring
students from underrepresented minority (URM) groups in college admissions have ambigu-
ous average effects on human capital attainment prior to college entry. One the one hand,
affirmative action policies may incentivize higher pre-college human capital attainment for
URM students ­ particularly those who are on the margin of being accepted by a selective
university ­ by increasing the probability that increased human capital will translate into
    1
      Stulberg and Chen (2014) discuss the origins of AA initiatives in the United States. AA policies in
higher education and in hiring practices are widespread in numerous countries, including Canada, Brazil,
and India.
    2
      Such cases include: Regents of the University of California v. Bakke in 1979, Hopwood v. Texas in
1996, Grutter v. Bollinger and Gratz v. Bollinger in 2003, Fisher v. University of Texas in 2013, Schuette
v. Coalition to Defend Affirmative Action in 2014, Fisher v. University of Texas in 2016, and Students for
Fair Admissions v. Harvard in 2019.


                                                    1
college admission (Fryer and Loury, 2005). Even if affirmative action does not directly affect
students' perceptions of the likelihood of being admitted, by increasing the observed num-
ber of URM students admitted, it may increase aspirations or the perception that selective
schools are welcoming to URMs, ultimately increasing pre-college human capital investment.
On the other hand, for high-achieving URM students, affirmative action policies may reduce
the returns to pre-college human capital investment by lowering the threshold for college
admissions (Coate and Loury, 1993). Then, affirmative action could disincentivize human
capital investments by these students (or their teachers and parents). Since the theoretical
effects of affirmative action are ambiguous and may also depend on how far students are from
the threshold for admission, we estimate the effects of affirmative action on both the average
student and on students in different parts of the test score distribution.
    To investigate the effects of racial affirmative action on the human capital investments of
high school students, we exploit a natural experiment that induced a policy reversal in Texas,
Louisiana, and Mississippi. In 2003, the Supreme Court decision in Grutter v. Bollinger
ruled that race-conscious admissions processes that do not amount to quota systems are
constitutional. This effectively reversed a 1996 lower court ruling in Hopwood v. Texas that
prohibited the use of race in admissions in public universities in these three states. We exploit
this exogenous policy change to estimate the effects of affirmative action on secondary school
students' outcomes using two identification strategies in three administrative data sets and
one survey data set. In cases where we have administrative data for all of Texas (secondary
school attendance and college applications, admissions, and graduation) or part of the state
(grades), we use a difference-in-differences strategy that compares the change in URM (Black
and Hispanic) and white students' outcomes following the policy. This strategy can be
interpreted as estimating the effect of affirmative action on the racial achievement gap. We
further inspect trends in outcomes by race to ensure that positive effects on URMs are not
driven by negative effects on whites. In cases where we have data across multiple states (SAT
data), we separately compare the change in URMs' and whites' outcomes in states that were
and were not affected by the policy using difference-in-differences and synthetic control group
approaches. This second strategy allows us to identify potential spillover effects on whites
and determine whether estimated effects on racial achievement gaps constitute lower or upper
bounds on the aggregate effects of affirmative action on URMs' pre-college human capital.
Finally, in the SAT data, we use an additional triple-differences strategy that interacts cohort,
geographic, and racial variation. This strategy estimates the differential change in the racial
achievement gap due to the policy and controls for any changes in treated states over time
that affected both whites and URMs.

                                               2
    There are four main findings. First, across data sets and identification strategies, we
find that URMs respond positively to affirmative action policies, including by increasing
their pre-college human capital investment. URMs increase their number of applications to
selective schools, as well as their SAT scores, grades, and attendance. Our estimates suggest
that the re-instatement of affirmative action helped close the racial gap in applications to
selective schools by 13%, the gap in math SAT scores by 5%, the gap in secondary school
grades by 18%, and the gap in secondary school attendance by 8%. These positive effects
are concentrated among high school students in the upper-half of the 6th grade test score
distribution, who are more likely to be on the margin of admission to selective Texas public
universities.
    Second, we find no evidence that pre-college human capital investment fell for URMs
anywhere in the test score distribution. The reintroduction of affirmative action policies
in Texas had no detectable disincentivizing effect on effort by URMs. Third, we find that
white students also experience small increases in their SAT scores in response to the policy,
consistent with either positive spillovers from URMs or whites also responding to increased
returns to effort due to greater competition for admissions. Thus, the reductions in the
racial achievement gap we observe may be smaller than the aggregate effect of the policy on
URMs' pre-college human capital investment. Fourth, we explore the effect of the affirmative
action policy on the racial gap in college graduation with the caveat that the net effect
conflates effects on pre-college human capital investment, college match, and college quality.3
Following the policy, the gap in college graduation falls by 15% for students in the top quintile
of the 6th grade test score distribution and remains unchanged for students in the bottom
four quintiles.
    Turning to mechanisms, several pieces of evidence suggest that students increase their
effort in response to affirmative action policies. First, attendance ­ an outcome likely to be
indicative of effort ­ increases. Second, in survey data, we find no evidence that parents or
guidance counselors respond to the policy, but we do find that URMs spend 10% more time
on homework. Third, the students whose outcomes improve the most are the same ones who
experience increases in the returns to pre-college human capital.
    Broadly, our results contribute to a large literature on the effects of affirmative action
policies. This literature has focused primarily on affirmative action policies in higher educa-
tion and their impact on college applications behavior (Card and Krueger, 2005), admissions
and campus diversity (Bowen and Bok, 1998; Arcidiacono, 2005; Rothstein and Yoon, 2008;
   3
       Mountjoy and Hickman (2020) find little evidence of differential match effects by race in Texas.



                                                       3
Hinrichs, 2012, 2016), major choice (Arcidiacono et al., 2016), and college graduation (Bowen
and Bok, 1998; Hinrichs, 2012). Arcidiacono et al. (2015) reviews this literature.
    This paper is most closely related to a smaller literature about the effects of affirma-
tive action on students prior to college. In the United States, the evidence on educational
outcomes from this literature is mixed.4 Antonovics and Backes (2014) conclude that SAT
scores and high school GPA changed little after California banned affirmative action by public
universities. Caldwell (2010) finds that URM students' time spent studying and test scores
worsened following affirmative action bans in California and Texas in the mid-1990s. Cotton
et al. (2015) simulate affirmative action for younger students in a math competition between
younger and older students and find that their intervention increases younger students' time
spent studying and improves their math performance. Bodoh-Creed and Hickman (2018)
structurally estimate the U.S. college admissions market. Their structural estimates indicate
that moving to a race-blind counterfactual increases pre-college human capital for URMs
with a low cost of effort and decreases it for those with a higher cost of effort.
    We contribute to this literature in two ways. First, we exploit a policy experiment to
directly estimate the effects of the reinstatement of a real affirmative action policy on stu-
dents' outcomes in the U.S. Thus, we complement Cotton et al. (2015) and Bodoh-Creed and
Hickman (2018) by providing less model-dependent, reduced-form estimates of affirmative ac-
tion's effects as it is implemented in practice. Doing so does not require making assumptions
about students' information or how they respond to incentives. Second, we exploit large
and detailed administrative data sets, allowing us to go beyond average effects and trace out
affirmative action's effects on a variety of dimensions across the distribution of pre-treatment
test scores.
    This study also relates to broader literatures on the incentive effects of college admissions
(Cortes and Zhang, 2011; Leeds et al., 2017; Golightly, 2019) and the anticipatory effects of
changes in the returns to human capital investment on children and their parents' investment
decisions (Jayachandran and Lleras-Muney, 2009; Jensen, 2010, 2012; Oster and Steinberg,
2013; Leeds et al., 2017; Moeeni and Tanaka, 2020). While much of the evidence in the
   4
     The evidence from abroad is also mixed. Outside of the U.S., Ferman and Assun¸     c~
                                                                                         ao (2015) and Estevan
et al. (2018) study the effects of race-based and SES-based university admissions quotas in Brazil on high
school students, while Khanna (2016) and Cassan (2019) study the effects of affirmative action on pre-college
education in India. Tincani et al. (2020) study the effect of a program that guaranteed admissions to students
in the top 15% of their high school class in Chile. Ferman and Assun¸    c~
                                                                          ao (2015) find that affirmative action
reduced student effort; Estevan et al. (2018) finds little effect on test preparation; and Khanna (2016) and
Cassan (2019) finding positive effects on education. Tincani et al. (2020) find that the race-blind preferential
admissions program they studied decreased human capital investment because students were overconfident
of their ranking.


                                                       4
latter literature is from low-income countries, our results suggest that students also respond
to changes in the returns to human capital investment in the United States.5
    The remainder of this paper is organized as follows. Section 2 introduces the context in
more detail. Section 3 presents our four data sets. Section 4 uses a simple conceptual frame-
work to generate testable predictions. Section 5 reports our estimates of the average and
distributional effects of affirmative action on student outcomes using both the nation-wide
SAT data and Texas administrative data sets. Section 6 uses survey data to test which mech-
anisms drive the estimated effects, and Section 7 discusses whether alternative educational
policies, such as No Child Left Behind, can explain our results. Section 8 concludes.


2       Context & Policy Change
In this section, we sketch out a brief time line of events during the study period (1997-2010)
and describe the policy change that this paper studies. We then examine whether universities'
stated commitment to affirmative action translated into changes in admissions.

Timeline of Events. In response to profound racial discrimination, affirmative action
policies were first introduced in the United States in the 1960s to encourage firms competing
for federal contracts to hire minorities (and subsequently women). Over time, the use of
affirmative action policies as a tool to address racial discrimination expanded to universities,
which sought to diversify their student bodies. However, these policies have been met with
considerable opposition and have been repeatedly challenged in the courts (see Andrews and
Swinton (2014) for a more detailed discussion).
    In 1996, the U.S. Court of Appeals for the Fifth Circuit, which has jurisdiction over
Texas, Louisiana, and Mississippi, ruled in Texas v. Hopwood that universities may not
use race as a factor in deciding which applicants to admit. In the wake of this ruling, the
Texas legislature passed the "Top 10% Rule" in 1997, which guaranteed admissions to any
state-funded university in Texas to students graduating in the top 10% of their class. This
law was passed as a means to promote diversity in universities by ensuring college access to
high-achieving students from across Texas' somewhat segregated high schools. In June 2003,
the Supreme Court ruled in Grutter v. Bollinger that a race-conscious admissions process
that does not amount to a quota system is constitutional, effectively overturning Texas
    5
     Several papers document educational investment responses to natural resources booms in the U.S. (Ko-
valenko, 2020; Cascio and Narayan, 2015) and Canada (Morissette et al., 2015).



                                                   5
v. Hopwood.6 Thus, public universities in Texas, Louisiana, and Mississippi were unable
to legally use race in the admissions process prior to 2003 and were able to do so again
after 2003. We use this policy reversal to assess the effect of the introduction of race-based
affirmative action on high school students' performance.7
    The Top 10% Rule remained in place from 1997 onward. The only change occurred at the
end of the study period in 2009, when the Texas legislature passed a law allowing UT Austin
to cap the percent of its class admitted through the "Top 10% Rule" at 75%. Following the
new law's implementation in 2011, only the top 7% of students were admitted to UT Austin.

Grutter v. Bollinger. The Grutter v. Bollinger ruling was a close 5-to-4 ruling, with
the deciding vote cast by moderate justice Sandra Day O'Connor. Prior to the ruling, the
outcome of the case was viewed as impossible to predict, with USA Today writing in 2002,
"Both sides think it's their best chance of winning the AA battle...O'Connor is the 5th
vote but her moderate history does not indicate her direction." Indeed, the Supreme Court
majority opinion expressed ambivalence over affirmative action policies, striking down the
ban on considering race holistically but banning assigning points for admissions based on
race.8 The decision was heavily covered by the media. Appendix Figure A1, which plots the
number of articles in US newspapers mentioning affirmative action by day, shows the spike
in coverage around the ruling. The policy was also heatedly discussed in Texas. On June 29,
2003 (5 days after the ruling), every letter to the editor published in the Austin-American
Statesman was about the case.

Policy Response to Grutter v. Bollinger. On the day that the Grutter v. Bollinger
decision was issued, UT Austin's president, Larry Faulkner, stated that the Texas flagship
campus intended to return to considering race in the admissions process. This response was
well-publicized, with Faulkner shown making comments to this effect on the NBC nightly
   6
      As the ruling in Grutter v. Bollinger only established the constitutionality of affirmative action, states
like California, Washington, and Florida, which had banned affirmative action due to ballot measures or
executive orders, were unaffected.
    7
      We don't focus on the earlier policy change in 1996 for two reasons. First, it combines a ban on race-
based affirmative action and the introduction of the Top 10% Rule a year later. Therefore, the 1996 policy
change does not provide a clean experiment for estimating the effects of an affirmative action ban on students'
outcomes. Second, the scarcity of data from the pre-1996 period make credibly estimating the effect of the
ban difficult.
    8
      The majority ruling read, "The court takes the Law School at its word that it would like nothing
better than to find a race-neutral admissions formula and will terminate its use of racial preferences as soon
as practicable. The court expects that 25 years from now, the use of racial preferences will no longer be
necessary to further the interest approved today."



                                                       6
news. Only the University of Texas Board of Regents could authorize the implementation
of such a change, and in August 2003, the Board of Regents voted to allow all its campuses
to return to considering race.9 The Texas Tech University Board of Regents also outlined a
plan to include race as an element in admissions in October 2003. Thus, following the 2003
Supreme Court ruling, it was clear that the state flagship university, UT Austin, and other
public universities in Texas would return to using affirmative action.
    Racial affirmative action co-exists with the Top 10% rule. Texas public universities first
admit students who qualify for automatic admission through the 10% rule. Students who
are not eligible for automatic admission are admitted based on a "holistic" review process.
Following the policy change, race or ethnicity could again play a role in this process. Despite
the Top 10% Rule, holistic admissions remain important. UT Austin, which has the highest
percentage of freshmen admitted under the Top 10% Rule, admitted one-third of its freshman
class through this process in 2003 (Office of the President, 2008).

Did Affirmative Action Policies Affect Admissions? To evaluate whether universi-
ties' stated commitment to affirmative action had real effects, we now consider how it affected
both university composition and admissions. Appendix Figure A2 uses the IPEDS data to
calculate the racial composition of UT Austin's Fall entering class by year. Following Fall
2003, there is a trend-break in the share of Blacks and Hispanics, with both rising pre-
cipitously. These descriptive statistics are consistent with the findings of Hinrichs (2012),
who shows that affirmative action bans decrease the enrollment of URMs at selective uni-
versities. In contrast, the upward trend in the share of Asians, who are not considered an
underrepresented minority, flattened from 2003 onward.
    Similarly, the reversal of the ban appears to have affected UT Austin and other selective
Texas universities' admissions behavior. Using administrative data from the Texas Education
Agency, Appendix Figure A3 plots event study graphs of URM students' relative likelihood of
being admitted to UT Austin, University of Houston, Texas Tech, and Texas A & M relative
to whites by the year in which students attended 9th grade. Here, we focus on students in
the top quintile of the test score distribution since these are the students most likely at the
margin of admission to these institutions.10 The estimation procedure for these event study
graphs is identical to the one used to produce graphs for our outcome variables from the
   9
      University of Texas campuses consist of Austin, Arlington, Dallas, El Paso, Rio Grande Valley, San
Antonio, Tyler, and Permian Basin.
   10
      Throughout our study period, 75% of students admitted to UT Austin were in the top quintile of their
cohort's distribution of 6th grade test scores.



                                                    7
Texas Education Agency data later in this paper and is described in detail in Section 5.2.
Students who ended 9th grade in 2001 were the first group whose admissions were affected by
the reinstatement of affirmative action, although these students would have had little time
to change their pre-college human capital. URMs' likelihood of admission following 2003
grew at UT Austin, the University of Houston, and Texas Tech. For Texas A & M, which
publicly stated that they would not use race-based affirmative action at the time of the ruling
(Parker, 2018), there is no clear positive trend in URM admissions. Altogether, lifting the
affirmative action ban appears to affect URM students' admissions probabilities at selective
Texas universities.


3        Data
In this section, we describe our four data sets: (1) the panel of race-state-year SAT scores,
(2) the administrative data for all Texas students from the Texas Education Agency (TEA),
(3) the administrative data from a large urban school district (LUSD), and (4) the survey
data from the Texas Higher Education Opportunity Project (THEOP).

SAT Data. To analyze the effects of the reinstatement of affirmative action on SAT scores,
we collected data on mean math and verbal SAT scores and the number of test-takers at the
state-race-year level from 1998 to 2010 from the College Board's publicly available reports.
One important benefit of these data is the inclusion of states that were not affected by the
policy change. This allows us to separately estimate the effect of Grutter v. Bollinger on
URMs (Black and Hispanic students) and whites and to estimate the differential change in
URMs' outcomes relative to whites in the treated states. The top panel of Appendix Table A1
reports summary statistics for the SAT data. There is a substantial racial achievement gap
during the pre-treatment period, with whites scoring 91 points higher in math and 87 points
higher in verbal on average, equivalent to about 0.8 standard deviations in both subjects.

Texas Education Agency (TEA) Administrative Data. Our first set of student-level
administrative data come from individual records for all Texas elementary, middle, and high
school students from the Texas Education Agency. The files are linked to (in-state) college
administrative data.11 Altogether, the records include yearly school attendance, test scores
    11
      In 2004, only 8% of Texan residents enrolled in an institution of higher education were enrolled in an
institution outside of Texas (Center for Education Statistics, 2004).




                                                     8
on standardized tests, and demographic characteristics, as well as college applications, admis-
sions, and graduation for Texas universities. Since the data cover the entire state, they allow
us to estimate the population average treatment effects of affirmative action and estimate
affirmative action's effects in different parts of the test score distribution with precision.12
    Using the TEA data, we estimate the effects of affirmative action on attendance, college
applications, admissions, and graduation. While the TEA data also includes standardized
test scores in high school, we do not use these as an outcome measure because these tests
underwent a substantial version change at roughly the same time as affirmative action was
re-instated.13 As a result, we cannot disentangle the effects of affirmative action from the
effects of the version change on URMs' high school test scores.
    Since use of the individual-level TEA data is restricted outside of a secure data room in
Texas, we constructed a data set of aggregate observations for outside analysis from a sample
of roughly 3 million students. To examine the heterogeneous effects of affirmative action by
prior academic achievement, we collapsed these data at the school district-cohort-race-6th
grade test score decile level.14 By weighting cells by their size, we can then replicate the
regression results we would attain with the individual-level data. In our main analyses, we
classify students into quintiles according to their rank in their year-specific 6th grade state-
wide standardized test score distribution. To ensure 6th grade test scores are unaffected by
the policy change, our main analysis focuses on cohorts in 6th grade before the policy (those
in 9th grade from 1997 to 2006). In event study graphs, we do, however, include later cohorts
to show trends over a longer horizon.15
    The middle panel of Appendix Table A1 reports summary statistics by race and pre-
/post-treatment cohort in the TEA data. The fraction of Texas students identified as URMs
increases sharply over time, entirely driven by an increase in the Hispanic population.

Large Urban School District (LUSD) Administrative Data. Our second source of
student-level administrative data is drawn from a large, urban school district in Texas. These
  12
      In contrast, data sets like the SAT are restricted to students who take the exam. Data sets like the
Integrated Post-Secondary Education Survey only have information on students who actually enroll in college.
   13
      In 2003, the standardized exam changed from the TAAS to the TAKS. These tests differ meaningfully.
First, TAAS was administered to grades 3-8 and grade 10. In contrast, TAKS is administered to grades
3-11, with the higher-stakes exit exam taking place in grade 11 instead of 10. Second, the TAKS high school
version includes social studies while TAAS does not (Tutson, 2002).
   14
      For confidentiality reasons, all cells with less than 5 students are dropped (7% of all students). The
fraction of students with valid 6th grade test scores varies slightly across cohorts and is generally in the
70-75% range.
   15
      A cohort is assigned the year it was in the Spring semester.



                                                     9
data consist of repeated cross-sections of all 11th graders in the school district between 2001
and 2008.16 The data contain information on students' demographics, course grades, and
test scores on the norm-referenced Stanford Achievement Test (hereafter, Stanford), a low-
stakes achievement test that the school district has administered since 2000. Data on prior
academic records for the three preceding years (e.g. course grades in 2003, 2004, and 2005
for students enrolled in 11th grade in 2006) also allow us to observe students' grades in 8th
grade, as long as they were enrolled in the same district. We focus on grades as our main
outcome in these data since the Stanford test underwent a minor version change from the
Stanford 9 to the Stanford 10 in 2004, our first post-treatment year. While this change was
less dramatic than the version change between the TAAKs and TAAS exams, we still view
evidence from the Stanford test ­ which we report in Section 5.4 ­ as suggestive. The bottom
panel of Appendix Table A1 reports summary statistics for the sample of 11th graders from
this school district. The majority of students in the district are Black or Hispanic.

Texas Higher Education Opportunity Project Data. Our final data set, the Texas
Higher Education Opportunity Project (THEOP) data, allows us shed light on what mech-
anisms may drive affirmative action's effects. THEOP surveyed high school seniors from a
random sample of 105 public high schools in Texas in 2002 and 2004 regarding their demo-
graphics, college perceptions, parental involvement, and other activities in high school. The
timing of the survey allows us to observe students' responses right before and after affirmative
action was re-introduced, with the limitation that only observing two cross-sections of the
data makes it impossible to evaluate pre-trends. THEOP records time spent on homework
outside of school, a student-reported measure of effort. The survey also records whether
the student applied to their first choice college, providing additional information on whether
college applications behavior changed. Additionally, we combine a series of questions about
parental behavior into a "parental involvement index," with values ranging from 5 to 20.17
This index captures whether parents changed their behavior or educational investments in
response to affirmative action. Finally, a question about whether the student discussed the
   16
       We focused on 11th graders to reduce the substantial administrative burden of constructing the data
set for the school district. We believed this group to be most likely to be affected by affirmative action, as
they had not yet applied to college but were close enough to the college applications stage to make decisions
based on college admissions policies.
    17
       These questions ask "How often do your parents ... (i) give you special privileges because of good grades,
(ii) try to make you work harder if you get bad grades, (iii) know when you are having difficulty in school, (iv)
help with your school work, and (v) talk with you about problems in school." Students' responses range from
"very rarely" (1) to "almost all the time" (4). We sum across the answers to these questions to construct the
"parental involvement index" so that a higher index corresponds to more involvement along these dimensions.



                                                       10
college applications process with her/his guidance counselor captures changes in guidance
counselor involvement. Appendix Table A2 reports summary statistics for these data.


4     Conceptual Framework
Before proceeding to the main results, we introduce a simple model that formalizes different
mechanisms through which affirmative action affects different students' pre-college human
capital. Based on this model, we predict that students for whom the returns to pre-college
human capital increase the most should also increase their pre-college human capital the
most. The second half of this section identifies where these students are in the pre-treatment
test score distribution, generating testable predictions about where we should observe effects
in Section 5.


4.1    Model
Let a student's perceived expected utility from college enrolment be

                                      A
                                u i = r q (hi ; r, A) - ci (hi ; h),

where i denotes a student, q is the expected payoff from pre-college human capital hi in
college admissions (e.g. the economic value of attending a college of a given quality), h is
a vector of all other students' pre-college human capital, r  {U RM, W } is the student's
race, A  {0, 1} denotes the policy environment, and is 1 if there is affirmative action and 0
otherwise, ci is a student-specific cost of human capital investment, which can be affected by
peer effects through h, as well as academic ability and socioeconomic status.
         A
    Let r   be a race-specific scalar that represents the taste for/consumption value of attend-
ing college and may also capture systematically biased beliefs about the likelihood of being
                             0         0     A
admitted to college (e.g. U    RM < W ). r can capture both the fact that students of a given
race may have systematically negatively biased incorrect beliefs about admissions and that
students of a given group may not value attending college as much if colleges are perceived
                                                                                           A
as un-welcoming or having non-diverse student bodies. That is, a student with low r          may
view college as unattainable and not apply even if in fact she is likely to be admitted. To
                                                ¯ ), where i is the portion of the cost of human
simplify exposition, let ci (hi ; h) = hi (i -  h
capital that is unaffected by peers (academic ability and socioeconomic status) drawn from a
                      ¯ is the average human capital of the other students. Fr may vary across
distribution Fr , and h


                                                11
races, capturing differences in socioeconomic status and access to resources. To ensure an
                                                                        2 h ;r,A)
interior solution, assume q(h i ;r,A)
                              h
                                      > 0 and for hi sufficiently high,  q(h
                                                                           i
                                                                             2    < 0. Assume that
there are enough students that they don't internalize their own effects on average pre-college
human capital. Then, a utility maximizing student's pre-college human capital investment
is characterized by the first order condition

                                    A   q (hA
                                            i ; r, A)        ¯
                                    r                 = i -  h,                                     (1)
                                            h

where hA                                                                        A
        i is the optimal choice of hi under affirmative action policy A. Since hi is our object
of interest, we can use equation (1) to understand the different mechanisms through which
the policy affects pre-college human capital.

  1. Effect of AA on Direct Returns to Pre-College Human Capital. Denote
     the change in the payoff to an additional unit of pre-college human capital at h0           i from
                                                   q (h0
                                                       i ;h,r,1)   q (h0
                                                                       i ;h,r,0)
     introducing affirmative action as R(i, r) =       h
                                                                 -     h
                                                                                 . Since q has positive,
     diminishing marginal returns, if R(i, r) > 0, h1               0
                                                            i > hi , and if R < 0, hi < hi .
                                                                                               1      0

     R(i, r) can be positive or negative depending on an individual's race and cost of pre-
     college human capital. To get intuition for this, consider a URM student who has a
     very low value of i , and was already selecting a h0       i that would result in admission
     to the most selective Texas public university with high probability. For this student,
     the human capital needed to be admitted to that school with a high probability falls
     due to affirmative action, so her returns to pre-college human capital at h0             i decline
     and R < 0. In contrast, for a student with a higher value of i , the student may
     have optimally chosen a low h0  i because increasing h enough to be admitted to a high
     quality college would be costly. If the returns to h become more steep for this student
     (e.g. colleges will take URM students with lower values of h with higher probability),
     R > 0. Similar logic applies to whites. Thus, the average effect of this mechanism
     by race and overall is ambiguous. In the next subsection, we will directly estimate
     R(i, r) for URMs in different parts of the pre-policy test score distribution (a proxy
     for h0
          i ) to obtain testable predictions about the direction and location of these effects
     on pre-college human capital.
                               1      0
  2. Aspirations Effect: r        > r   . If students view colleges as more welcoming and
     diverse (raising their value of attending college) or if affirmative action increases their
     aspirations, leading them to believe they can be admitted to a high quality institution,
      1         0
     U  RM > U RM . This would unambiguously lead to an increase in hi due to diminishing


                                                  12
      marginal returns. The existence of an aspirations mechanism is consistent with work
      by Hoxby and Avery (2012), which shows that qualified, economically disadvantaged
      students often do not apply to elite schools.

   3. Spillover Effect: h  ¯1 > h ¯ 0 or h
                                         ¯1 < h¯ 0 . The spillover effect leads to a change in the
      cost of a unit of pre-college human capital (i -  h     ¯ ) due to an increase or decrease in
      ¯ due to affirmative action. Increases in average human capital increase own human
      h
      capital by reducing the cost of human capital, and reductions in average human capital
      increase own cost of human capital, reducing human capital. If both of the previous
      effects have average positive effects on pre-college human capital, we expect this effect
      to amplify the positive effects. If, on net, they have negative effects, we expect it to
      amplify negative effects. If URMs experience increases in the direct returns to human
      capital and whites experience losses, negative direct effects on whites can be mitigated
      or reversed by spillover effects due to the direct effects and aspirations effects on URMs.

    Altogether, the model points to multiple mechanisms through which affirmative action
could have positive or negative effects on pre-college human capital for both URMs and
whites. We next use the data to develop predictions, based on the direct returns to human
capital effect in the model, about where in the test score distribution we should observe
effects on pre-college human capital.


4.2    Changes in Returns to Pre-College Human Capital
In this subsection, we estimate the change in the returns to pre-college human capital for
URMs relative to whites in different parts of the pre-treatment test score distribution fol-
lowing the introduction of affirmative action. To do so, we use TEA data on university
admissions. Taking advantage of the fact that we observe test scores in 6th grade, we esti-
mate changes in the marginal effect of moving up one decile in the test score distribution on
admissions at selective public Texan universities. The estimating equation is



   ydcea =       1,j (U RMe × P artT reatc × Ia aj ) +       2,j (U RMe × F ullT reatc × Ia aj )
             j                                           j

             + Xdcea +    dcea                                                                     (2)

where a denotes a test score decile, c a cohort of 9th graders, d a school district, and e a racial
group. The outcome, ydcea , is the number of selective universities that admit the student,

                                                13
and Ia aj is an indicator variable if a student's 6th grade test score decile a is greater than or
equal to j . Xdcea is a vector of control variables that include average student characteristics
for the observation cell,18 cohort, district and race fixed effects, as well as their interactions
with test score decile indicator variables. We allow changes over time to differ between
partially treated cohorts (P artT reatc ) who were already in high school at the time of the
policy change and fully treated cohorts (F ullT reatc ) who started high school after the policy
change. Thus, 1,j and 2,j capture the change in the marginal effect of moving from decile
j - 1 to j due to the policy for URMs who are partially and fully treated.19 Since increased
human capital investment can allow a student to move up in the distribution of test scores
relative to her peers, we interpret these coefficients as a proxy for the change in the relative
returns to pre-college human capital investment in university admissions.

Figure 1: Relative Change in Returns to Moving Up a 6th Grade Test Score Decile in
Admissions to Selective Texan Public Universities
                                                                     .04
                            Admissions to Selective Texan Universities
                                      0          -.02.02




                                                                           2   3   4       5        6        7       8   9   10
                                                                                       6th grade test score decile




Notes: The outcome is the number of selective Texan public universities to which a student is admitted. Bars
are the coefficients from equation (2), which capture the change in the marginal effect of moving up a 6th
grade test score decile on college admissions. Dashed lines show 95% confidence intervals for standard errors
clustered at the district level.

    Figure 1 reports estimates of 2,j . It shows that the returns mainly rise in the top half
of the test score distribution. For instance, the returns to moving from the 9th to the
10th decile increased by 0.026 for URMs relative to whites among fully treated cohorts.20
  18
     These consist of age, sex, immigrant status, low-income status, gifted, ESL, special education status,
and limited English proficiency.
  19
     Appendix Figure A4 shows the baseline, pre-AA, average number of selective schools a student is ad-
mitted to (unconditional on applications) by test score decile, separately for URMs and whites.
  20
     The fact that there are strong increases in the returns for the top decile isn't inconsistent with the


                                                                                              14
Appendix Figure A5 further reports estimates of 2,j for admissions to each of four selective
Texan universities separately. For UT Austin, University of Houston, and Texas Tech, which
were free to practice affirmative action, there are increases in the returns to human capital
in the top 30-50% of the test score distribution. Reassuringly, for Texas A&M, which does
not practice affirmative action, there is no systematic effect on the returns to human capital.
    Overall, these figures suggest that if students (or teachers and parents) respond to these
changes in the returns to pre-college human capital, we would expect affirmative action to
have (1) positive average effects on pre-college human capital that are (2) concentrated among
students with 6th grade test scores in the top half of the distribution. We empirically examine
both predictions in Section 5, focusing on SAT data to estimate averages effects by race and
using Texas administrative data to uncover heterogeneous effects across the distribution of
test scores.


5     Effects of Affirmative Action on Students' Outcomes
In this section, we estimate the effects of the reinstatement of affirmative action on several
measures of students' behavior using our three non-survey data sets. We first report the
effect of affirmative action on URMs' and whites' average SAT scores using difference-in-
differences and synthetic control group approaches that compare changes in scores in states
that re-instated affirmative action (Texas, Louisiana, Mississippi) to changes in unaffected
states. Next, we turn to the Texas administrative data to examine the effects of affirmative
action across the 6th grade test score distribution. We then complement these results with
an analysis of a single large, urban Texas school district where we observe grades and stan-
dardized test scores in 11th grade. Finally, we estimate the effects of affirmative action on
college completion, though we caution that this outcome is a function of both pre-college
human capital and the college to which a student is matched.


5.1     Effect of Affirmative Action on SAT scores
To measure the effects of affirmative action on SAT scores, we exploit both time variation
in whether students took the SAT after Grutter v. Bollinger and geographic variation in
whether students lived in a state where Grutter v. Bollinger eliminated a previous ban on
existence of the Top 10% Rule. This is because the deciles do not accord with the cut-offs used by the rule:
they are based on performance in 6th grade rather than at the end of high school and are across-school deciles
rather than within-school deciles.



                                                     15
affirmative action. This difference-in-differences strategy allows us to estimate the effect of
affirmative action separately for URMs and whites.

Event Study Graphs. We first use event study graphs to visually inspect the evolution
of SAT scores in treated states relative unaffected states. We estimate the following equation
separately for whites and URMs using a panel of average math and verbal SAT scores at the
state-race-year level

                         2002                                    2010
               yket =            l (T reated Statek × Itl ) +            l (T reated Statek × Itl )
                        l=1998                                  l=2004

                        + Xkt + k + t + ket ,                                                         (3)

where k indexes a state, e indexes a racial group, and t indexes a year. Then, yket is the mean
math or verbal test score for group e in state k and year t, T reated Statek is an indicator
variable equal to 1 if the observation belongs to a state that was treated, Itl is an indicator
variable equal to 1 if t = l, k is a state fixed effect and t is a year fixed effect. The omitted
year is 2003, the year before the policy change. We weight race-state-year cells by the number
of test-takers and cluster our standard errors at the state-level.
    This event study specification estimates the differential effect of being in a treated state
for each year, l . If pre-trends between treated and non-treated states are parallel, we expect
that l should be small and insignificant prior to 2003. One potential concern is that our
estimates might be contaminated by other affirmative action policy changes that occurred
between 1998 and 2010 in the states that were not affected by Grutter v. Bollinger. To
address this issue, we include a vector of controls Xkt for relevant policy changes in control
states during our study period.21
    Panel A of Figure 2 reports l for math separately for URM and white students. The
plot shows a negative pre-trend in math SAT scores for students in treated states relative to
those in non-treated states. That is, prior to Grutter v. Bollinger, students in treated states
were falling behind the rest of the country on the math SAT.22 Following the reinstatement
of affirmative action, there is a reversal of fortunes, and the negative trend turns positive
right after 2004. Importantly, the post-treatment positive trend for math scores appears to
be considerably steeper for URM students than for whites. On the other hand, there is no
clear change in verbal scores over time for either URMs or whites (see Appendix Figure A7).
  21
       These policy changes are listed in Appendix A.
  22
       Appendix Figure A6 shows that a similar pattern holds for Asians.


                                                       16
                                                              Figure 2: Effect of AA on Math SAT Scores


                                                (a) Math SAT score                                                                           (b) Math SAT score, detrended




                                                                                                               40
             20
   Average math SAT score




                                                                                                     Average math SAT score
                                                                                                                        30
                   15




                                                                                                               20
            10




                                                                                                       10
    5




                                                                                                               0
             0




                            98   99   00   01   02    03    04    05   06   07   08   09   10                                 98   99   00    01   02    03    04    05   06   07   08   09   10
                                                           Year                                                                                               Year

                                                     Whites            URMs                                                                             Whites            URMs




Notes: The outcome is average math SAT scores at the state-year level. Dots indicate coefficients of re-
gressions of the outcome on year dummies interacted with an indicator variable for the three treated states,
estimated separately for white and URM students. Cells are weighted by the number of SAT test takers.
Dashed lines show 95% confidence intervals for standard errors clustered at the state level.


As shown by Panel B, which plots the de-trented event study graph, the standard difference-
in-differences estimates that do not account for the observed negative pre-trends understate
the positive effect of AA on math SAT scores.23 Accounting for a linear trend eliminates all
the negative pre-trends, and the positive effects on math SAT scores are now larger.

Difference-in-Differences and Triple-Differences Empirical Strategies. The difference-
in-differences analogue to the event study graphs is given by

                                  yket = DD (T reated Statek × P ost2003t ) + Xkt + k + t + e + ket .                                                                                              (4)

where P ost2003t is an indicator variable equal to 1 if the year is greater than 2003. Since
we expect URMs to be more affected by affirmative action, we also implement a triple-
differences strategy that uses race as a third difference. This identifies the change in the
racial achievement gap due to the policy, in line with our within-Texas results in the next
section. This approach controls for any time-varying shocks in states affected by the policy
but may under or over-estimate the policy's effects on URMs' outcomes if the policy also
affected whites. To estimate the differential effect of affirmative action on URMs relative to
  23
     To construct this figure, we first estimate linear pre-treatment (1998-2003) trends separately for each
ethnicity and treatment group, and subtract these time trend terms from the full panel.




                                                                                                17
non-URMs, we estimate

  yket = DDD (T reated Statek × P ost2003t × U RMe ) + Xket + ke + et + kt + ket , (5)

where U RMe is an indicator for underrepresented minority groups, ke is a state-race fixed
effect, et is a race-year fixed effect, and kt is a state-year fixed effect. While the triple-
differences strategy requires us to include controls for all three sources of variation and their
double interactions, these are subsumed by the fixed effects in this specification.
    This strategy controls for all the same potential sources of bias as the difference-in-
differences strategy. Both strategies use fixed effects to account for level differences in SAT
scores between states and over time. In addition, the triple-differences strategy includes
the fixed effect kt , which controls for any state-specific differences over time. Thus, this
triple-differences strategy is valid even if Texas, Louisiana, and Mississippi have different
time trends from other states, as long as those time trends also don't vary by race.

Difference-in-Differences and Triple-Differences Results. Table 1 reports the coef-
ficients from equation (4) (panels A, B and C) and equation (5) (panel D) for SAT scores.
Column (1) shows that math scores for both URMs and whites improved in treated states
following 2003, though URMs' test scores improved by twice as much (8 points or 0.07 sd
relative to 4 points or 0.035 sd). There is no effect on math scores for Asians and no effect
on verbal scores for any group.
    Whites' human capital appears to be positively affected by the abrogation of the ban. As
described in the conceptual framework, this could occur if whites increased their pre-college
human capital in response to intensifying competition or if positive spillovers from URM
students cancelled out any negative effects on the returns to pre-college human capital. If
the distribution of the cost of pre-college human capital investment is different for whites than
URMs, the introduction of affirmative action could increase the returns to pre-college human
capital investment for both the average white and URM student.24 Altogether, the findings in
Table 1 indicate that, since the policy increased both whites' and URMs' pre-college human
capital investment, estimates of the effect of the policy on the racial achievement gap are
likely to under-estimate its aggregate effects on pre-college human capital.
    In the last panel of Table 1, we report the results of the triple-differences specification.
We find that URMs' math SAT scores improved relative to whites' in treated states by
  24
     This mechanism is consistent with both the theoretical model and empirical findings of Cotton et al.
(2015), who show that students who do not benefit from a simulated affirmative action policy may also be
incentivized to increase their effort.

                                                   18
                   Table 1: Effect of AA on SAT Scores for URMs and Whites


                                               Math          Verbal     # Test       % Test
                                                                        takers       takers
                                                (1)             (2)       (3)          (4)
                                                                  Panel A: URMs
               DD coefficient                8.009***         -0.634    545.9         0.002
                                              (1.544)        (1.784) (1195.1)        (0.005)

               Observations (cells)            1904           1901      1904          1114
               R2                              0.844          0.796     0.802         0.872
               State, year and race FE           X              X         X             X
                                                                 Panel B: Whites
               DD coefficient                4.048***        0.0342    1588.7         0.005
                                              (0.984)        (0.888) (1262.0)        (0.005)

               Observations (cells)             663             663       663          561
               R2                              0.969           0.971     0.987        0.978
               State, year and race FE           X               X         X            X
                                                                  Panel C: Asians
               DD coefficient                  0.658          -0.176    -2086.3       -0.010
                                              (1.827)        (2.753) (2038.4)        (0.007)

               Observations (cells)             663      663        663                 556
               R2                              0.944    0.929      0.975               0.783
               State, year and race FE           X        X          X                   X
                                             Panel D: Triple-Difference (URMs        vs Whites)
               DDD coefficient               4.155*** 1.260        -437.5             -0.002
                                              (0.828) (0.753) (1058.6)               (0.003)

               Observations (cells)            2555          2552       2555          1675
               R2                              0.998         0.998      0.999         0.993
               State-year FE                     X             X          X             X
               State-race FE                     X             X          X             X
               Race-year FE                      X             X          X             X

Notes: This table reports differences-in-difference and triple-differences estimates of the effect of affirmative
action on SAT scores. Each observation is a state-race-year group. In columns (1) and (2), cells are weighted
by the number of test-takers in a group. In column (3), cells are weighted by the average number of test-
takers in the pre-treatment years 1998-2000. In column (4), cells are weighted by the number of 17-19 year
olds in the population group (from ACS), and the dependent variable is (# of test-takers)/(# of 17-19 years
old). In Panels A, B and C, the DD coefficient reports the interaction of an indicator variable for belonging
to a treated state (Texas, Louisiana, Mississippi) and being tested after Grutter v. Bollinger (post 2003),
and the regressions include controls for policy changes in control states. In Panel D, the coefficient is on
the interaction between being a URM, being tested post 2003, and belonging to a treated state, and the
regressions include controls for policy changes in control states interacted with being a URM. Standard
errors are clustered at the state-level.
                                                        19
a statistically significant 4 points, equivalent to 0.035sd or a 5% reduction in the racial
achievement gap. The triple-differences results further confirm that the positive difference-
in-differences estimates are not merely due to differential time trends in states that were not
affected by Grutter v. Bollinger.
    In the last two columns, we evaluate whether the policy change affected test-taking. In
column (3), the outcome is the raw number of SAT test-takers, and cells are weighted by
the average number of test-takers in the first three years of the panel, 1998-2000. In column
(4), we generate a measure of the probability of taking the SAT by dividing the number of
test-takers by the number of 17-19 year-olds in each cell using yearly ACS population counts
to account for fluctuations in the number of test takers due to changes in population size.
Both metrics suggest there was no significant change in the probability of taking the SAT in
treated states relative to untreated states.
    In Appendix A, we report the results of a variety of additional robustness tests for the
SAT results. Motivated by Hinrichs (2012), who argues that Louisiana and Mississippi were
less affected by the original Hopwood v. Texas ruling than Texas, we show that the results
are unchanged if we drop Lousiana and Mississippi from the analysis, or if we drop states
that implemented affirmative action bans.

Synthetic Control Group Strategy. While event study graphs help us to assess the
appropriateness of the parallel trends assumption, synthetic control group methods provide
us with an alternative way of verifying that our results are robust to accounting for differential
time trends. Based on these methods, developed by Abadie and Gardeazabal (2003) and
Abadie et al. (2010), we construct a synthetic control group of states by matching those
states' pre-trends in test scores to the pre-trends of the treated unit (the weighted average
of Texas, Mississippi, and Louisiana).25 We match the pre-treatment values of the number
of URM and white test takers, the math SAT scores of URM and white students, and the
verbal SAT scores of URM and white students. Our estimated effect of the reinstatement
of affirmative action is then the difference between the change in test scores in the weighted
average of the treated states and the synthetic control. Given the null results for verbal
scores found previously, we focus on math SAT scores.
  25
     When generating the synthetic control groups, we exclude South Dakota, North Dakota, Wyoming, and
Washington DC from the pool of potential controls because SAT scores are missing for some ethnic groups
in some years in these states due to small samples. We follow the standard practice of minimizing the mean
squared prediction error of our outcome variable over the entire pre-treatment period. In Appendix B, we
show that our results are robust to using fewer pre-treatment years to construct the synthetic control group
and to using an alternative nearest-neighbor matching approach.



                                                    20
    To assess the significance of our estimates, we use permutation tests. For all possible
combinations of three untreated states, we apply the synthetic control method and calculate
the post/pre-treatment ratio of root mean squared prediction errors (RMSPE).26 We then
calculate the rank of the real treatment unit in the distribution of RMSPE ratios.

                         Figure 3: Synthetic Control Estimates of the Effect of AA on SAT Math Scores


                                                            (a) Whites                                                                                                  (b) URMs
            545




                                                                                                                       460    455
                   540
    Average SAT score




                                                                                                              Average SAT score
                                                                                                                      450
           535




                                                                                                              445
   530




                                                                                                                       440
            525




                         98     99        00    01    02    03    04    05   06    07    08    09   10                              98     99     00    01    02    03     04    05   06    07    08    09   10
                                                                 Year                                                                                                     Year

                                               Treated States            Synthetic Control Group                                                       Treated States             Synthetic Control Group
                         DD coef: 6.273                                                                                             DD coef: 10.778




Notes: This figure reports synthetic control analyses separately for whites and URMs. The left figure
shows SAT math scores for the treated states (Texas, Mississippi and Louisiana) for whites, while the right
panel shows them for URMs. For whites, weights on control units are 42.5% (California), 40.8% (Florida),
8.3% (Pennsylvania), 6.2% (New York), and 2.2% (Indiana). All other states have a weight of zero. For
URMs, weights on control units are 33.2% (Oregon), 28.4% (New Jersey), 20.6% (California), and 17.8%
(Pennsylvania).




Synthetic Control Results. Panel A of Figure 3 shows the evolution of SAT math scores
over time for our treatment unit and the associated synthetic control group separately for
white and URM students. Interestingly, for both URMs and whites, California, which banned
affirmative action in public universities prior to our study period, contributes to the control
group. In both cases, the synthetic control group closely tracks the treatment unit prior to
the reinstatement of affirmative action, and the two trends diverge considerably from 2004
onward. This is true for both groups, but the divergence is greater in magnitude for URMs.
The implied treatment effects are larger than our baseline difference-in-differences estimates,
consistent with the evidence of negative time trends. Whites' math scores increase by 6.3
points, and URMs' increase by 10.8 points. The placebo tests suggest that these results are
not due to chance. The treatment unit's post-pre ratio of RMSPE is at the 99.2th percentile
  26
     Since the donor pool contains 44 control units, the number of possible combinations of three states is
13,244.


                                                                                                         21
of the distribution for whites and at the 96.6th percentile for URMs. Appendix B provides
further robustness tests of the synthetic control estimates, including dropping states that
enacted AA bans during the study period from the donor pool.
    Appendix Figure A8 is a synthetic control plot of the differences between treated and
untreated units separately for white and URM students. For both racial groups, the differ-
ences are close to zero prior to treatment and then exhibit large increases following Grutter v.
Bollinger, with larger effects for URMs. The implied difference in the gains between URMs
and whites is 4.5 points, which is similar to our conventional triple-differences estimate.
    Having found evidence that students respond to affirmative action by improving their SAT
scores, we next investigate whether students also increase other dimensions of their human
capital. Since SAT scores may just reflect better SAT-specific test-taking skills, examining
other outcomes allows us to evaluate if affirmative action affects human capital more broadly.


5.2    Impact of Affirmative Action on College Applications
Motivated by the conceptual framework, to assess the effects of affirmative action throughout
the test score distribution, we now use Texas-wide administrative data. As a first step, we
examine students' college applications behavior and compare the change in URMs' college
applications behavior following Grutter v. Bollinger to the change in whites'.

Event Study Graphs. The key identifying assumption is that the college applications
behavior of URM and comparable non-URM students would have evolved the same way in
the absence of the ruling. We first examine the plausibility of this assumption using an event
study approach in which we plot the relative effect of being a URM on college applications
separately for each cohort. Doing so allows us to establish if trends in college applications for
URMs and whites were parallel prior to the re-introduction of affirmative action. Recalling
that an observation in these data is a race-(pre-treatment) test score quintile-district-cohort
cell, we estimate the following model:


                          1999                          2010
               ydcea =            t (U RMe × Ict ) +            t (U RMe × Ict ) + Xdcea
                         t=1997                        t=2001

                         + da + ca + ea +        dcea ,                                      (6)




                                                   22
where d indexes a school district, c indexes a 9th grade cohort (the year the student entered
9th grade), e indexes an ethnicity, and a indexes quintiles in the 6th grade state standardized
test distribution. The variable U RMe is an indicator variable for belonging to a URM group,
Ict is an indicator variable equal to 1 if t = c, and Xdcea is a vector of average student
characteristics. We estimate the model both separately by test score quintile as well as
pooling all test score quintiles together. In all cases, we include district, cohort, and race
fixed effects, as well as all two-way interactions with test score quintile fixed effects (da , ca ,
and ea ) when test score quintiles are pooled. The dependent variable, ydcea , is either the
average number of applications sent to selective Texan institutions or fraction of students
who applied to any of the campuses of the University of Texas. We focus on the University
of Texas because the University of Texas Board of Regents promptly allowed its campuses
to consider race in admissions. Standard errors are clustered at the district-level.
    If the parallel trends assumption is valid, for t < 2000, we expect that t will be indis-
tinguishable from zero. If the effects we estimate in the difference-in-differences strategy are
due to affirmative action, we expect to see an increase in the values of t soon after the 2000
9th grade cohort. Additionally, if the effects of affirmative action accumulate over time as
students have more time to adjust their behavior, we expect that after 2000, t will generally
be greater for greater values of t. To provide richer evidence on dynamic effects, we include
all cohorts from 1997 to 2010.
    Before progressing to the event study results, we note that one important limitation of this
strategy is that whites' outcomes may also be affected by affirmative action. If, for example,
whites decrease their college applications in response to the reinstatement of affirmative
action, we would estimate positive effects of affirmative action, even if URMs' behavior was
unchanged. To assess whether this could be driving our results, we also separately graph
trends in unconditional applications behavior by race in Appendix Figure A9. This figure
plots raw trends in applications (normalized to the cohort in 9th grade in 2000) separately
for the full sample and for top quintile students. The figure shows that there is a positive
trend break in URMs' behavior around the reintroduction of affirmative action, with no clear
evidence of differential trends across groups prior to the event. Whites do not appear to
reduce their applications.
    Figure 4 plots the year-specific coefficients t for the number of applications to selective
universities (Panel A) and for the probability of applying to any University of Texas (UT)
institution (Panel B). Since the increase in the returns to human capital is concentrated at
the top of the test score distribution, we examine trends separately for students in the top and



                                                23
                         Figure 4: College Application Behavior of URMs Relative to Whites

              (a) Number of Applications to Selective Texan Universities                                             (b) Applying to Any UT
        .2




                                                                                           .2
                                                                                           .15
        .15




                                                                                           .1
        .1




                                                                                           .05
        .05




                                                                                           0
        0




               97   98   99   00   01   02 03 04 05         06   07    08   09   10              97   98   99   00   01   02 03 04 05         06   07    08   09   10
                                         9th grade cohort                                                                  9th grade cohort

                                   Bottom quintile          Top quintile                                             Bottom quintile          Top quintile




Notes: The University of Texas system consists of UT Arlington, UT Austin, UT Dallas, UT El Paso, UT
Permian Basin, UT Rio Grande, UT San Antonio, and UT Tyler. Dots indicate coefficients from a regression
of the outcome on year dummies interacted with URM status separately for students in the bottom and top
quintiles of the 6th grade cohort-specific test score distribution. All regressions condition on cohort, race and
district fixed effects, as well as means of individual characteristics at the district-cohort-ethnicity-test score
quintile level. Dashed lines show 95% confidence intervals for standard errors clustered at the district-level.


bottom quintiles.27 Cohorts between the solid and dashed vertical lines were in high school
at the time of the reinstatement of AA, while cohorts to the right of the dashed vertical line
started high school in the new policy environment.
    For applications to selective universities, the point estimates for bottom quintile students
are very small and statistically insignificant both before and after the policy change. For
top-quintile students, there appears to be a weak negative pre-trend, but these year-specific
coefficients are small and not systematically statistically significant, and a strong positive
effect emerges directly after the policy change. In panel B, coefficients prior to the policy
change are all close to zero and statistically insignificant. For top quintile students, there is
an increase in applications for the 2000 cohort, and then applications grow slowly over time.
For bottom quintile students, a small positive effect appears in later years.28
   27
     Appendix Figure A10 shows average effects pooling all test score quintiles.
   28
     For completeness, Appendix Figure A11 reproduces the event study graph for the probability of applying
to any 4-year public Texan university. There is a small upward trend in URM college applications relative
to whites prior to the policy change, but most year-specific coefficients are close to zero and statistically
indistinguishable from the base year. The results indicate that the probability of applying to a university for
URM students increases at the time of the policy change, and the jump is considerably more pronounced for
top quintile students.




                                                                                      24
Difference-in-Differences Empirical Strategy. The difference-in-differences estimates
for the number of applications are given by

                 ydcea =1 (U RMe × P artT reatc ) + 2 (U RMe × F ullT reatc )
                         + Xdcea + dca + dea +        dcea ,                                   (7)

where we distinguish between partially treated cohorts who were already in high school at the
time of the policy change and fully treated cohorts who started high school after the policy
change. Thus, P artT reatc is equal to 1 if a student was in 9th grade between 2000 and 2003,
while F ullT reatc is equal to 1 if a student was in 9th grade after 2003. To ensure that our test
score quintiles are exogenous to the policy, we restrict the sample to cohorts who completed
6th grade prior to Grutter v. Bollinger. In this specification, the effect of affirmative action
is identified by comparing URM students to non-URM students with similar test scores in
6th grade, in the same cohort and the same school district. The fixed effect dca accounts
for any time trends that may vary across districts or test score levels, as long as they are not
differential by race. The fixed effect dea accounts for any differences across races, districts,
or test score levels (or any combination thereof), as long as these differences do not vary over
time. We cluster the standard errors at the district-level.
    Our main coefficients of interest, 1 and 2 capture the short and medium-run effects
of affirmative action on college applications behavior. Later cohorts may have had greater
opportunities to adjust their human capital investment in high school in response to the
re-instatement of affirmative action. This in turn may have affected their likelihood of being
accepted to college and therefore their propensity to apply in the first place, relative to earlier
treated cohorts, suggesting that 2 > 1 .

Difference-in-Differences Results. We report coefficients from equation (7) in column
(1) of Table 2. In panel A, the outcome is is the average number of applications to selective
institutions, and in panel B, the outcome is the probability of applying to any University
of Texas institution. In panel A, on average, fully treated URM students apply to 0.02
more selective Texas colleges, indicating that affirmative action closed the racial gap by
13%. Turning to Panel B, on average, lifting the ban on affirmative action increased URMs'
probability of applying to at least one UT campus relative to whites' by 0.7 percentage points
for cohorts who entered high school after the ban was lifted. In both panels, the estimates
are precisely estimated and statistically significant at the 5% level.
    For both panels, these average effects mask substantial heterogeneity. The remaining

                                                25
   Table 2: Effect of AA on College Applications Behavior for URMs Relative to Whites


                                                      Percentile of 6th grade test score distribution
                                         All    Bottom        2nd          3rd          4th         Top
                                      students  quintile quintile       quintile     quintile     quintile
                                         (1)       (2)        (3)          (4)          (5)         (6)
                                               Panel A: Applications to selective universities
  Partial treatment                  0.0097***   0.0018     0.0022       0.0024     0.0145** 0.0297***
                                      (0.0027)  (0.0019) (0.0025) (0.0035)           (0.0067)    (0.0085)
  Full treatment                     0.0187***   0.0019     0.0046 0.0151*** 0.0304*** 0.0449***
                                      (0.0038)  (0.0016) (0.0030) (0.0049)           (0.0073)    (0.0105)

  Observations (cells)                 68509       12933       14515       14809        14145        12107
  R2                                    0.913       0.469       0.630      0.738        0.800        0.837
  Mean dependent variable              0.1484      0.0079      0.0331      0.0877       0.1994       0.4158
  Test: quintile q = top quintile
    Partial treatment p-value                      0.0013    0.0022      0.0028      0.1265
    Full treatment p-value                         0.0000    0.0003      0.0046     0.1356
                                                  Panel B: Application to any UT institution
  Partial treatment                    0.0030     0.0031** -0.0025       0.0021     -0.0002        0.0148***
                                      (0.0019)    (0.0014) (0.0023) (0.0030)       (0.0043)         (0.0057)
  Full treatment                      0.0074**     0.0004    0.0022    0.0089**     0.0066         0.0198***
                                      (0.0029)    (0.0017) (0.0022) (0.0041)       (0.0054)         (0.0074)

  Observations (cells)                 68509       12933       14515       14809        14145        12107
  R2                                    0.905       0.825       0.872      0.878        0.864        0.846
  Mean dependent variable              0.1072      0.0212      0.0514      0.0879       0.1390       0.2363
  Test: quintile q = top quintile
    Partial treatment p-value                      0.0578      0.0023      0.0384       0.0171
    Full treatment p-value                         0.0087      0.0219      0.1067       0.0539
  Demographic controls                   X           X           X           X            X            X
  District-cohort-test score FE          X           X           X           X            X            X
  District-ethnicity-test score FE       X           X           X           X            X            X

Notes: This table reports difference-in-differences estimates of the effect of affirmative action on URMs'
college applications behavior. The regressions use the TEA data, an observation is at the district-cohort-
race-test score quintile level, where test score quintile is assigned based on 6th grade (pre-AA) test scores on
the state standardized test. The sample is restricted to students who were in 9th grade between 1997 and
2006. Cells are weighted by the number of student-years in a cell. Partial treatment is the coefficient on the
interaction between an indicator for being a URM and an indicator variable for entering high school after
2001 and before 2003. Full treatment is the coefficient on the interaction between entering high school after
2003 and being a URM. The outcome variable in panel A is the average number of selective universities to
which students applied. The outcome variable in Panel B is the fraction of students in a cell that applied
to any institution of the University of Texas system (UT Arlington, UT Austin, UT Dallas, UT El Paso,
UT Permian Basin, UT Rio Grande, UT San Antonio, UT Tyler). Standard errors are clustered at the
district-level.



                                                      26
columns of the table estimate the effects for students in different quintiles of the 6th grade
test score distribution. In Panel A, while bottom quintile students are no more likely to
apply to selective institutions, top quintile students apply to 0.04 more selective institutions,
and the second highest quintile applies to 0.03 more selective institutions. We can reject
at the 1% level that the coefficients for top quintile students are equal to those of any of
the first three quintiles. Turning to Panel B, we do find a very small positive effect on
applying to any UT campus (0.0031) for partly treated students in the bottom quintile of
the test score distribution, which rapidly fades out. The partial treatment effect is five times
larger among students with top test scores (0.0148). This positive effect on top quintile
students persists, with a coefficient of 0.0198 for fully treated students. In both cases, this
heterogeneity accords with where we would expect affirmative action to have the strongest
effects on college applications, given the estimates in Section 4. Among fully treated students,
there are no significant effects in the bottom 40% of the distribution.
    For all outcomes, the treatment effects appear to be larger for later cohorts. Thus,
allowing students to have more years to adjust in response to the affirmative action policy
appears to strengthen the policy's effect. This could be because students respond to these
policies by increasing their pre-college human capital. We investigate this hypothesis in the
next subsection.


5.3     Impact of Affirmative Action on Grades
Empirical Strategy. In this subsection, we turn to our data from the large, urban Texas
school district (LUSD) to examine the effect of affirmative action on students' grades in 11th
grade. Our econometric specification is similar to equation (7), with some alterations to ac-
commodate the different structure of the school district's administrative data. In particular,
unlike our Texas-wide regressions, which use aggregate district-year-race-test score quintile
data, for the LUSD, an observation is an individual. The specification is

                      yisec =  (U RMi × P ost2003i ) + Xi + sc + e +                isec                   (8)

where i denotes an individual, s denotes a school, e denotes a racial group, and c denotes a
cohort.29 The treatment variable P ost2003i is an indicator variable equal to 1 if the outcome
is realized after the policy change, so a student is observed in 11th grade after 2003. sc
  29
     Since the LUSD data consists of repeated cross-sections of 11th graders, in this data set, a cohort refers
to the year students attended 11th grade.



                                                      27
denotes a school-cohort fixed effect, and e is a race-specific fixed effect. We include sc
to account for the fact that grades may not be comparable across schools or across years.30
Thus, the effect of affirmative action in this regression is identified by comparing URM and
white students in the same school in the same year. The basic controls Xi consists of age,
sex, and home zip code fixed effects. Additionally, in a more conservative, "value-added"
specification, we control for a lagged measure of school grades (8th grade course grades).31
This control accounts for any changes in the achievement distributions of URMs and whites
over time that might otherwise be attributed to affirmative action (such as changes due
to cohort composition or migration). As before, the coefficient of interest,  , represents the
effect of affirmative action on URM students relative to non-URM students. We also estimate
cohort-specific coefficients and plot them in an event study graph. To do so, we simply alter
equation (8) to estimate a different coefficient on the variable U RMi for every cohort.

Figure 5: Raw and Value-Added Estimates of AA's Effect on Mean Grades for URMs Relative
to Whites
                                3
                                2
                                1
                                0
                                -1




                                     01   02    03        04        05         06         07   08
                                                        11th grade cohort

                                                     Baseline               Value-added




Notes: The outcome is mean grades across subjects in 11th grade. Dots indicate the coefficients from
regressions of the outcome on year dummies interacted with an indicator variable for URM status. The
regression also includes school-cohort, race, and ZIP code fixed effects, as well as controls for age and gender.
The value-added specification additionally controls for 8th grade grades. Dashed lines show 95% confidence
intervals for standard errors clustered at the school-cohort level.



Results. Figure 5 reports year-specific coefficients on the U RMi indicator variable when the
outcome is mean grades. There are no significant pre-trends, with the racial gap in school
grades remaining constant over the 2001-2003 period. Grades for URM students improve
   30
    For example, this would be the case if course offerings or grading standards are changing over time.
   31
    The fact that we use 6th grade test scores in the TEA data and 8th grade test scores in the LUSD
simply reflects differences in the availability of lagged scores across the two data sets.


                                                            28
relative to their non-URM peers upon the reinstatement of affirmative action and remain at
this higher level through 2008. Results under the value-added specification, which controls
for 8th grade test scores, are extremely similar.
    The associated difference-in-differences estimates are reported in Table 3. The point
estimates confirm that affirmative action had a positive effect on school grades in 11th grade.
Our baseline estimates of equation (8) in column (1) indicate that grades increased by 0.9
points (on a 0-100 scale), equivalent to 0.1 sd, following the reinstatement of affirmative
action, closing the pre-AA racial gap by 18%. In column (2), we report the results of the value-
added specification. The coefficient is almost identical and remains statistically significant.
    In column (3), we re-arrange the data set into a panel that includes two entries per student
(one for 11th grade and one for 8th grade) and estimate a specification with student fixed
effects. In this model, our main explanatory variable becomes a triple-difference interaction
                            11th Grade           11th Grade
term (U RMe × T reatc × Ig             ), where Ig          is an indicator variable equal to 1 when
a student is enrolled in 11th grade. Here, the effect of affirmative action is identified from
within-student changes in outcomes between 8th and 11th grade for students who were in
11th grade after the policy change and in 8th grade before the change. This alternative
specification further accounts for any unobserved changes in URM students' characteristics
across cohorts that might otherwise bias our estimate of the effect of affirmative action. The
results of this alternative specification are nearly identical to our previous results.
    In columns (4) to (6), we examine whether the effects are heterogeneous by prior school
performance. To do so, we calculate school-by-cohort specific terciles of the distribution of
grades in 8th grade. We focus on terciles instead of quintiles, as we did in the TEA data,
because of the much smaller sample size. We then re-estimate equation (8) separately for
students in the bottom, middle, and top terciles. While the point estimates for the effect
of affirmative action are positive for all terciles, they are particularly large for top-achieving
students (an effect of 1.4 percentage points or 0.2 sd). This is consistent with our estimated
distribution of the increases in the returns to pre-college human capital.


5.4    Impact of Affirmative Action on the Stanford Exam
The data from the large, urban school district also allows us to estimate the effects of affirma-
tive action on the standardized Stanford test, a low-stakes exam that the school district itself
administered. To estimate the effects on the Stanford exam, we use the same difference-in-
differences strategy as we did for grades in Section 5.3. The outcome variable is a student's
mean percentile on the Stanford exam, where percentiles are based on the national distribu-


                                                29
             Table 3: Effect of AA on School Grades for URMs Relative to Whites


                                                                                  Grades in 8th grade
                                               All students                Bottom Middle            Top
                                                                            tercile    tercile     tercile
                                       (1)          (2)           (3)         (4)        (5)         (6)
  Treated                          0.8770***    1.0024***     0.9552***    0.8816*     0.3996 1.3859***
                                    (0.3086)     (0.2979)      (0.3114)    (0.5102) (0.3906) (0.4207)
  Lagged dep. var. (grade 8)                    0.5552***
                                                 (0.0092)

  Observations                       61089        46346         92847       15874       15621        14776
  R2                                 0.226        0.345         0.784       0.189       0.224        0.208
  Mean dependent variable            78.67        79.48         81.11       75.79       79.49        83.46
  S.D. dependent variable             8.67         7.80          7.37        7.43        6.99         6.97
  Test: tercile q = top tercile
    p-value                                                                 0.4412      0.0784
  School-year FE                       X             X            X           X           X            X
  Ethnicity FE                         X             X                        X           X            X
  Demographic controls                 X             X                        X           X            X
  Student FE                                                      X
  Grade-year FE                                                   X
  Grade-ethnicity FE                                              X

Notes: This table reports difference-in-differences estimates of the effect of affirmative action on grades in a
large urban school district. An observation is a student, and the sample consists of repeated cross-sections
of 11th graders. "Treated" is the coefficient on the interaction between being a URM and being observed
post 2003. Achievement terciles are assigned based on 8th grade average school grades. Standard errors are
clustered at the school level.




                                                      30
tion. Appendix Figure A12 plots the event study graph. We see little evidence of pre-trends,
and there is an immediate positive effect of affirmative action on URMs' test scores at the
time of the policy change. Appendix Table A4 reports the point estimates. On average,
Stanford test scores increase by 4.78 percentiles for URMs relative to whites (equivalent to
0.2 sd). The effect is largest for the top tercile, which has gains of 7.47 percentiles (0.3 sd).


5.5             Impact of Affirmative Action on Attendance
Having shown that grades and test scores increase as a result of affirmative action, we now
consider a more direct measure of student effort. Returning to the TEA data, we test whether
affirmative action affects URM students' attendance. Our empirical strategy is identical for
the strategy estimating affirmative action's effects on college applications (see equation (7)).

                      Figure 6: Effect of AA on Attendance for URMs Relative to Whites


                                    (a) 10th grade                                                                     (b) 11th grade
   .008




                                                                                      .006
   .006




                                                                                      .004
   .004




                                                                                      .002
   .002
   0




                                                                                      0
   -.002




                                                                                      -.002




           97   98   99   00   01   02 03 04 05         06   07   08   09   10                97   98   99   00   01   02    03   04    05   06   07   08   09   10
                                     9th grade cohort                                                                  9th grade cohort




Notes: The outcomes are attendance rates in grades 10 and 11. Dots indicate coefficients from a regression
of the outcome on year dummies interacted with URM status. All regressions condition on cohort-test score
quintile, race-test score quintile and district-test score quintile fixed effects, where test score quintiles are
from the cohort-specific distribution of 6th grade standard test scores. Dashed lines show 95% confidence
intervals for standard errors clustered at the district-level.

    Figure 6 reports the event study plots for attendance in 10th and 11th grade. For these
outcomes, because our data is organized in cohort-time, the first treated cohort for 10th
grade attendance is the 2003 cohort, and the first treated cohort for 11th grade attendance
is the 2002 cohort. Reassuringly, the timing of increases in attendance rates is consistent
with a positive treatment effect at the time affirmative action was re-instituted rather than
simple differences in attendance rates across cohorts. Attendance rates for the 2002 cohort
of 9th graders are greater than for the 2001 cohort in 11th grade but not in 10th grade.

                                                                                 31
Overall, the plots show no discernible pre-trend and suggest that there was a positive effect
on attendance.

            Table 4: Effect of AA on School Attendance for URMs Relative to Whites


                                                          Percentile of 6th grade test score distribution
                                          All       Bottom         2nd         3rd          4th         Top
                                       students     quintile    quintile     quintile    quintile      quintile
                                          (1)          (2)         (3)         (4)          (5)          (6)
                                                          Panel A: Attendance in grade 10
  Treated                             0.0022***    0.0036*** 0.0002 0.0023*** 0.0026*** 0.0025***
                                       (0.0005)     (0.0013) (0.0009) (0.0008)           (0.0005)     (0.0007)

  Observations (cells)                  68480       12910       14515       14805        14143        12107
  R2                                     0.761       0.628       0.617      0.595        0.604        0.635
  Mean dependent variable               0.9460      0.9222      0.9377      0.9477       0.9562       0.9655
  Test: quintile q = top quintile
    p-value                                         0.4473     0.0182    0.8013      0.9239
                                                        Panel B: Attendance in grade 11
  Treated                              0.0015**     0.0018    -0.0000    0.0014     0.0014**        0.0034***
                                       (0.0006)    (0.0015) (0.0010) (0.0010)       (0.0007)         (0.0006)

  Observations (cells)                  68431       12865       14509       14807        14143        12107
  R2                                     0.715       0.574       0.580      0.592        0.611        0.648
  Mean dependent variable               0.9402      0.9190      0.9316      0.9406       0.9492       0.9598
  Test: quintile q = top quintile
    p-value                                         0.2731      0.0020      0.0392       0.0089
  Demographic controls                    X           X           X           X            X            X
  District-cohort-test score FE           X           X           X           X            X            X
  District-ethnicity-test score FE        X           X           X           X            X            X

Notes: This table reports difference-in-differences estimates of the effect of affirmative action on URMs'
school attendance. The regressions use the TEA data, an observation is at the district-cohort-race-test score
quintile level, where test score quintile is assigned based on 6th grade (pre-AA) test scores on the state
standardized test. Cells are weighted by the number of student-years in a cell. The reported coefficient is
the coefficient on the interaction between an indicator for being a URM and an indicator variable for being
observed after 2003. The outcome variables in Panels A and B are the average percent of days students in a
cell attended school in 10th and 11th grade respectively. Standard errors are clustered at the district-level.


    Table 4 reports the associated regression results for 10th and 11th grade attendance.
Difference-in-differences estimates indicate a positive average effect on the fraction of days
present of 0.22 percentage points in 10th grade (panel A) and of 0.15 percentage points
in 11th grade (panel B). The latter effect is equivalent to 8% of the pre-AA racial gap in
attendance rates.32 While the effects on attendance occur throughout the distribution in
  32
       Results are quantitatively similar, but considerably less precise, in the LUSD.


                                                       32
10th grade, for 11th grade they are again concentrated in the top part of the distribution.


5.6    Affirmative Action and College Completion
Thusfar, our analyses have documented the positive effects of affirmative action on URMs'
college applications and human capital prior to reaching college. In this subsection, we
estimate the effect of affirmative action on the probability of completing a college degree
using administrative data from the TEA.
    In Section 5.2, we showed that more URM students applied to college as a result of
the reinstatement of affirmative action. However, this need not result in an increase in the
fraction of URM students who obtain a post-secondary degree. On the one hand, if marginal
students are now matched to colleges for which they are not prepared, they may be less likely
to complete their degrees than they would have been absent affirmative action. This is the
mismatch argument of Sander (2004). Then, affirmative action might reduce the fraction of
degree holders among URMs. On the other hand, if increased effort in high school contributes
to the accumulation of human capital, the probability of completing a 4-year college degree
may increase. Additionally, if students are matched to better schools that have higher returns
to education, incentivizing students to graduate, or that are more able to ensure students
graduate, graduation rates may increase. To measure the direction of the effect of affirmative
action on college graduation, we employ the same empirical strategy that we used in the TEA
data to measure college application behavior (see equation (7)).
    Figure 7 is an event study plot of the effect of the reinstatement of affirmative action on
the relative probability of top-quintile URMs completing a 4-year college degree. For these
high test score students, the relative probability of graduating college appears to increase
post-policy change. Graduation rates vary noisily around zero for cohorts that were never
treated (i.e. who would have started college prior to the court ruling), appear to start
increasing with cohorts that were partially treated (i.e. who were in 9th grade between 2001
and 2003), and stabilize at higher values for cohorts who started high school post 2003. This
pattern is consistent with increased pre-college human capital: cohorts who had more time
to adjust their human capital investment experience larger increases in college graduation.
    Table 5 reports the associated difference-in-differences estimates. Pooling all students
together (column (1)), we find no effect of affirmative action on students who had little
opportunity to adjust their level of effort in high school (the partially treated cohorts). For
fully treated cohorts, the probability of graduating increases by 0.46 percentage points (3%).
We find no significant evidence of gains for partially treated cohorts for any of the quintiles,


                                              33
Figure 7: Effect of AA On College Graduation for Top Quintile URMs Relative to Whites




                               .04
                               .02
                               0
                               -.02




                                      97   98   99   00      01      02      03   04   05   06
                                                          9th grade cohort




Notes: The outcome is college graduation. Dots indicate coefficients from a regression of the outcome on
year dummies interacted with URM status. The sample consists of students in the top quintile of the 6th
grade test score distribution. All regressions condition on cohort, race and district fixed effects, as well as
means of individual characteristics. Dashed lines show 95% confidence intervals for standard errors clustered
at the district-level.


though the estimate is positive for top quintile students. For fully treated cohorts, the
point estimates are positive throughout the test score distribution, but positive effects are
concentrated in the top quintile. Fully treated top-quintile URMs are 1.4 percentage points
(4%) more likely to complete college.
    Taking all the results in this section together, high-achieving URM students increased
their effort in high school as measured by attendance, increased their pre-college human cap-
ital as measured by school grades, increased the number of applications they sent to selective
institutions, and became more likely to graduate from college. For college graduation, any
decrease in match-quality that may have resulted from the reinstatement of affirmative ac-
tion was more than made up for by positive effects on effort, application rates, and college
quality.


6     Suggestive Evidence on Mechanisms
So far, we have provided evidence that affirmative action narrowed the achievement gap
between URMs and whites for an array of outcomes. A natural next question is what channels
led to these effects. One possibility that is consistent with both the evidence presented in
the previous section and the effects on attendance is that high school students changed their
behavior in direct response to perceived changes in their likelihood of college admission. Still,


                                                             34
         Table 5: Effect of AA on College Completion for URMs Relative to Whites


                                                       Percentile of 6th   grade test   score distribution
                                          All      Bottom        2nd           3rd          4th        Top
                                       students    quintile quintile        quintile     quintile quintile
                                          (1)         (2)         (3)          (4)          (5)        (6)
  Partial treatment                     -0.0009     -0.0011    -0.0011       -0.0055      -0.0022    0.0098
                                       (0.0022)    (0.0018) (0.0030)        (0.0036)     (0.0037) (0.0063)
  Full treatment                       0.0046*      0.0006      0.0023       0.0033       0.0054 0.0141**
                                       (0.0025)    (0.0023) (0.0031)        (0.0041)     (0.0049) (0.0071)

  Observations (cells)                  68509       12933       14515        14809       14145     12107
  R2                                    0.890        0.556       0.640       0.690        0.708     0.707
  Mean dependent variable               0.1688      0.0202      0.0695       0.1415      0.2398    0.3714
  Test: quintile q = top quintile
    Partial treatment p-value                       0.0955      0.0902       0.0214      0.0568
    Full treatment p-value                          0.0592      0.1295       0.1443      0.2122
  Demographic controls                    X           X           X            X           X          X
  District-cohort-test score FE           X           X           X            X           X          X
  District-ethnicity-test score FE        X           X           X            X           X          X

Notes: This table reports difference-in-differences estimates of the effect of affirmative action on URMs'
college graduation. The regressions use the TEA data, and an observation is at the district-cohort-race-test
score quintile level. The test score quintile is assigned based on 6th grade (pre-AA) test scores on the state
standardized test. Cells are weighted by the number of student-years in a cell. Partial treatment is the
coefficient on the interaction between an indicator for being a URM and an indicator variable for entering
high school after 2001 and before 2003. Full treatment is the coefficient on the interaction between entering
high school after 2003 and being a URM. The outcome variable is the fraction of students in a cell who
completed college. Standard errors are clustered at the district-level.




                                                     35
teachers, guidance counselors, and parents may have also changed their behavior if affirmative
action change their perceived returns to investing in/providing attention to URM students.
To provide suggestive evidence on the drivers of URM students' improved outcomes, we
analyze students' responses from the THEOP survey.

                 Table 6: Student and Parent Behavior and Affirmative Action


                                     (1)               (2)                (3)                (4)
                                   Time on       Applied to First       Parental       Guidance From
                                  Homework       Choice College       Involvement        Counselor
      U RM × P ost2003             5.452**          0.048**              0.176             -0.025
                                   (2.496)           (0.023)            (0.166)           (0.018)

      Mean Whites Pre-2003           51.585            0.732              10.635             0.614
      N                              13,452            9,993              13,558            13,699
      Adjusted R2                     0.061            0.024               0.038             0.026
      Race Fixed Effects                X                X                   X                 X
      Year control                      X                X                   X                 X

Notes: This table reports differences-in-differences analyses using survey data from two cohorts, both in their
senior year, of the Texas Higher Education Opportunity Project (THEOP). The earlier cohort was surveyed
in 2002, and the later cohort was surveyed in 2004. For the measure of how many minutes per day students
spend on homework, students were asked how many hours per day they spent on their homework and were
given the options zero hours, less than 1 hour, 1 to 2 hours, 3 to 4 hours, and 5+ hours. We convert these to
minutes so that 0 hours is 0 minutes, less than 1 hour is 30 minutes, 1 to 2 hours is 90 minutes, and so on.
The parental involvement index is constructed using questions that ask "How often do your parents ... (i)
give you special privileges because of good grades, (ii) try to make you work harder if you get bad grades,
(iii) know when you are having difficulty in school, (iv) help with your school work, and (v) talk with you
about problems in school." Students' responses range from "very rarely" (1) to "almost all the time" (4).
We sum across the answers to these questions to construct the "parental involvement index" in a way that a
higher index corresponds to more involvement along these dimensions. Standard errors are heteroskedasticity
robust.

    As mentioned previously, the THEOP survey asked two cross-sections of high school
seniors across Texas about their demographics, college applications behavior, and high school
activities in 2002 (pre-affirmative action) and then again in 2004 (post-affirmative action).
While the two waves of the survey are not identical, the questions that are consistent across
waves allow us to measure student effort in terms of time spent on homework, as well as
parental involvement, and guidance counselor involvement. For each outcome, we run the
following regression, which closely mirrors our difference-in-differences strategies in the TEA




                                                      36
and LUSD data:33

                     yiet = 1 P ost2003i + 2 (U RMi × P ost2003t ) + e + iet ,                             (9)

where i denotes an individual, e denotes an ethnicity, and t denotes a survey round. P ost2003i
is an indicator variable equal to 1 for seniors surveyed in 2004, while e is an ethnicity fixed
effect. This regression compares the change in outcomes between URM and white seniors
from 2002 to 2004.
    Table 6 reports the results. After the implementation of affirmative action, URM high
school seniors spend 5 (10%) minutes more on homework a day relative to white students.
They are also 5 percentage points more likely to apply to their first choice college compared
to whites, consistent with our findings in the TEA data. However, we do not see any changes
in parental involvement or the likelihood of discussing college applications with guidance
counselors. Overall, students appear to directly respond to affirmative action by changing
their behavior.


7        Alternative Policies
This section discusses whether two alternative educational policies that were enacted in the
early 2000s (No Child Left Behind and charter schooling) can explain our findings.

No Child Left Behind. One threat to the validity of our findings is that a major national
educational policy, No Child Left Behind (NCLB), was signed into law in 2002. NCLB may
have also differentially affected URM students' outcomes, confounding our estimates. We
believe that this is unlikely to be the case for several reasons. First, as documented by Dee
and Jacob (2011) and Deming et al. (2016), Texas has had high-stakes school accountability
policies since 1993. These policies, which were adopted under Governor George Bush, served
as the later basis for the NCLB policies enacted when Bush was president (Deming et al.,
2016). Second, our SAT results exploit geographic variation in the reinstatement of affirma-
tive action policies. Since NCLB was a national law, we do not expect it to differentially
positively affect URMs specifically in Texas, Louisiana, and Mississippi.34 Third, we find
    33
      In this analysis, we cannot include campus fixed effects because we do not observe the campus to which
the student belongs.
   34
      If anything, given that Texas should be less affected by NCLB due to its pre-existing policies, we should
expect our estimates of the change in SAT scores for URMs in Texas, Louisiana and Mississippi will be
under-estimates due to NCLB.


                                                      37
that affirmative action had the largest effects on high-achieving students who would have
been on the margin of college admissions. In contrast, NCLB incentivized schools to ensure
students passed relatively low proficiency cut-offs. Neal and Schanzenbach (2010) show that
NCLB and similar policies increased test scores in the middle of the test score distribution.
Thus, the distribution of effects we estimate is inconsistent with NCLB's incentive system
and with past estimates of the effects of the NCLB program.

Charter School Expansion. In the early 2000s, charter schools expanded rapidly in
Texas. Since these charter schools typically serve disadvantaged populations, they may have
also differentially affected URMs' outcomes. We believe this expansion is unlikely to drive our
results since, at the time of the policy change (2003-2004), charter school enrollment made
up only 1% of total enrollment in Texas (Texas Education Agency, 2004).35 Nonetheless,
in Appendix Table A5, we show that the college applications results are robust to omitting
Houston and Dallas, the two areas with the largest number of students enrolled in charter
schools today.


8        Conclusion
We study the effects of a 2003 U.S. Supreme Court ruling that effectively reinstated race-based
affirmative action policies in public universities in Texas, Louisiana, and Mississippi. We find
that the policy increased applications to selective universities, high school attendance, and
college graduation by URMs in Texas. The policy also reduced the racial achievement gap
in math SAT scores by 5% and grades (in a large, Texan school district) by 18%.
    These effects are concentrated among students in the top half of the test score distribution,
who also experienced the greatest change in the gains of moving up a decile in the test
score distribution in terms of admissions to selective universities. Consistent with students
responding to increased returns to pre-college human capital, the students whose returns to
human capital investment increased the most are also those whose pre-college human capital
investment was most affected by the policy.
    Altogether, given the positive effects on attendance, the distribution of the treatment
effects, and the evidence from the survey data, our findings suggest that URM students
respond to the affirmative action policy by changing their college aspirations and adjust
their effort accordingly. We speculate that these results are consistent with work by Hoxby
    35
    In 2003-2004, there were 60,833 students in charter schools in Texas and 4,328,028 enrolled overall (Texas
Education Agency, 2004).


                                                     38
and Avery (2012) and Hoxby and Turner (2013), which shows that qualified, disadvantaged
students are less likely to apply to highly selective four-year institutions. If affirmative action
leads URM students to perceive admission to a selective school as more attainable or colleges
as more welcoming, they may change their behavior.
    Finally, our estimates suggest that policy debates that ignore the pre-college incentive
effects of affirmative action policies ignore a significant benefit of these policies. Affirmative
action policies do not merely affect admissions among a given pool of applicants; they affect
the composition of the pool of university applicants itself. Given the importance of the racial
achievement gap for determining gaps in long-term outcomes, reductions in the achievement
gap may translate into substantial changes in welfare and inequality later in life.



References
Abadie, Alberto, Alexis Diamond, and Jens Hainmueller, "Synthetic control methods for comparative case studies:
  Estimating the effect of California's tobacco control program," Journal of the American statistical Association, 2010, 105
  (490), 493­505.
   and Javier Gardeazabal, "The economic costs of conflict: A case study of the Basque Country," American Economic
  Review, 2003, 93 (1), 113­132.
Andrews, Rodney J and Omari H Swinton, "The persistent myths of "Acting white" and race neutral alternatives to
  affirmative action in admissions," The Review of Black Political Economy, 2014, 41 (3), 357­371.
Antonovics, Kate and Ben Backes, "The effect of banning affirmative action on human capital accumulation prior to college
  entry," IZA Journal of Labor Economics, 2014, 3 (1), 5.
Arcidiacono, Peter, "Affirmative action in higher education: How do admission and financial aid rules affect future earnings?,"
  Econometrica, 2005, 73 (5), 1477­1524.
  , Esteban M Aucejo, and V Joseph Hotz, "University differences in the graduation of minorities in STEM fields:
  Evidence from California," American Economic Review, 2016, 106 (3), 525­62.
  , Michael Lovenheim, and Maria Zhu, "Affirmative Action in Undergraduate Education," Annual Review of Economics,
  2015, 7 (1), 487­518.
Ashkenas, Jeremy, Haeyoun Park, and Adam Pearce, "Even with affirmative action, Blacks and Hispanics are more
  underrepresented at top colleges than 35 years ago," The New York Times, 2017.
Bayer, Patrick and Kerwin Kofi Charles, "Divergent paths: A new perspective on earnings differences between black and
  white men since 1940," The Quarterly Journal of Economics, 2018, 133 (3), 1459­1501.
Bodoh-Creed, Aaron and Brent R Hickman, "Pre-college human capital investment and affirmative action: a structural
  policy analysis of US college admissions," Working Paper, 2018.
Bowen, William G and Derek Bok, The Shape of the River. Long-Term Consequences of Considering Race in College and
  University Admissions., ERIC, 1998.
Caldwell, Ronald, "The Effects of University Affirmative Action Policies on the Human Capital Development of Minority
  Children: Do Expectations Matter?," Technical Report, University of Kansas, Department of Economics 2010.
Card, David and Alan B Krueger, "Would the elimination of affirmative action affect highly qualified minority applicants?
  Evidence from California and Texas," Industrial & Labor Relations Review, 2005, 58 (3), 416­434.
Cascio, Elizabeth U and Ayushi Narayan, "Who needs a fracking education? The educational response to low-skill biased
  technological change," Technical Report, National Bureau of Economic Research 2015.
Cassan, Guilhem, "Affirmative action, education and gender: Evidence from India," Journal of Development Economics,
  2019, 136, 51­70.
Center for Education Statistics, "Enrollment in Postsecondary Institutions, Fall 2004; Graduation Rates, 1998 2001
  Cohorts; and Financial Statistics, Fiscal Year 2004," U.S. Department of Education, 2004.
Chetty, Raj, John N Friedman, Emmanuel Saez, Nicholas Turner, and Danny Yagan, "Income segregation and
  intergenerational mobility across colleges in the united states," The Quarterly Journal of Economics, forthcoming.
  , Nathaniel Hendren, Maggie R Jones, and Sonya R Porter, "Race and economic opportunity in the United States:
  An intergenerational perspective," The Quarterly Journal of Economics, 2020, 135 (2), 711­783.
Coate, Stephen and Glenn C Loury, "Will affirmative-action policies eliminate negative stereotypes?," The American
  Economic Review, 1993, pp. 1220­1240.
Cortes, Kalena E and Lei Zhang, "The incentive effects of the top 10% plan," Working Paper, 2011.




                                                             39
Cotton, Christopher, Brent R Hickman, and Joseph P Price, "Affirmative action and human capital investment:
    Theory and evidence from a randomized field experiment," Working Paper, 2015.
Darity Jr, William, Darrick Hamilton, Mark Paul, Alan Aja, Anne Price, Antonio Moore, and Caterina Chio-
    pris, "What we get wrong about closing the racial wealth gap," 2018.
Dee, Thomas S and Brian Jacob, "The impact of No Child Left Behind on student achievement," Journal of Policy Analysis
    and management, 2011, 30 (3), 418­446.
Deming, David J, Sarah Cohodes, Jennifer Jennings, and Christopher Jencks, "School accountability, postsecondary
    attainment, and earnings," Review of Economics and Statistics, 2016, 98 (5), 848­862.
Derenoncourt, Ellora, "Can you move to opportunity? Evidence from the Great Migration," 2019.
Estevan, Fernanda, Thomas Gall, and Louis-Philippe Morin, "Redistribution without Distortion: Evidence from An
    Affirmative Action Programme At a Large Brazilian University," The Economic Journal, 2018.
Ferman, Bruno and Juliano Assun¸          c~
                                           ao, "Does Affirmative Action Enhance or Undercut Investment Incentives? Evidence
    from Quotas in Brazilian Public Universities," Working Paper, 2015.
Fryer, Roland G and Glenn C Loury, "Affirmative Action and Its Mythology," Journal of Economic Perspectives, 2005,
    19 (3), 147­162.
Golightly, Eleanor, "Does College Access Increase High School Effort? Evaluating the impact of the Texas Top 10% Rule,"
    2019.
Hinrichs, Peter, "The effects of affirmative action bans on college enrollment, educational attainment, and the demographic
    composition of universities," Review of Economics and Statistics, 2012, 94 (3), 712­722.
    , "Affirmative Action and Racial Segregation," 2016.
Hoxby, Caroline and Sarah Turner, "Expanding college opportunities for high-achieving, low income students," Stanford
    Institute for Economic Policy Research Discussion Paper, 2013, (12-014).
Hoxby, Caroline M and Christopher Avery, "The missing "one-offs": The hidden supply of high-achieving, low income
    students," NBER Working Paper, 2012.
Jayachandran, Seema and Adriana Lleras-Muney, "Life expectancy and human capital investments: Evidence from
    maternal mortality declines," The Quarterly Journal of Economics, 2009, 124 (1), 349­397.
Jensen, Robert, "The (perceived) returns to education and the demand for schooling," The Quarterly Journal of Economics,
    2010, 125 (2), 515­548.
    , "Do labor market opportunities affect young women's work and family decisions? Experimental evidence from India," The
    Quarterly Journal of Economics, 2012, 127 (2), 753­792.
Khanna, Gaurav, "Does Affirmative Action Incentivize Schooling? Evidence From India," Working Paper, 2016.
Kovalenko, Alina, "Natural Resource Booms, Human Capital, and Earnings: Evidence from Linked Education and Employ-
    ment Records," 2020.
Leeds, Daniel M, Isaac McFarlin, and Lindsay Daugherty, "Does student effort respond to incentives? Evidence from
    a guaranteed college admissions program," Research in Higher Education, 2017, 58 (3), 231­243.
Moeeni, Safoura and Atsuko Tanaka, "The Effects of Labor Market Opportunities on Education: The Case of a Female
    Hiring Ceiling in Iran," 2020.
Morissette, Ren´    e, Ping Ching Winnie Chan, and Yuqian Lu, "Wages, youth employment, and school enrollment recent
    evidence from increases in world oil prices," Journal of Human Resources, 2015, 50 (1), 222­253.
Mountjoy, Jack and Brent R. Hickman, "The Returns to College(s): Estimating Value-Added and Match Effects in Higher
    Education," 2020.
Neal, Derek and Diane Whitmore Schanzenbach, "Left behind by design: Proficiency counts and test-based accountabil-
    ity," The Review of Economics and Statistics, 2010, 92 (2), 263­283.
Office of the President, "A Report on the Top Ten Percent Law," Technical Report, The University of Texas at Austin 2008.
Oster, Emily and Bryce Millett Steinberg, "Do IT service centers promote school enrollment? Evidence from India,"
    Journal of Development Economics, 2013, 104, 123­135.
Parker, Claire, "UT-Austin has no plans to drop affirmative action policy, despite new Trump administration guidelines,"
    Texas Tribune, 2018.
Rothstein, Jesse and Albert H Yoon, "Affirmative Action in Law School Admissions: What Do Racial Preferences Do?,"
    Technical Report, NBER 2008.
Sander, Richard H, "A systemic analysis of affirmative action in American law schools," Stanford Law Review, 2004, pp. 367­
    483.
Stulberg, Lisa M and Anthony S Chen, "The origins of race-conscious affirmative action in undergraduate admissions: A
    comparative analysis of institutional change in higher education," Sociology of Education, 2014, 87 (1), 36­52.
Texas Education Agency, "Enrollment in Texas Public Schools 2003-2004," 2004.
Tincani, Michela, Fabian Kosse, and Enrico Miglio, "Student Beliefs and the (Perverse) Incentives of Preferential College
    Admissions," Working Paper, 2020.
Tutson, Teddy, "Students now taking TAKS instead of TAAS tests," Houston Chronicle, 2002.




                                                           40
                       Appendix for Online Publication

                                      Appendix Figures


      Figure A1: Number of Articles Mentioning Affirmative Action by Day, 2002-2004


                                                         Grutter v. Bollinger Decision
                                                         (June 23, 2003)
           600




                             President Bush says
                             AA unconstitutional
           400




                             (January 15, 2003)

                             President Bush pays
                             tribute to MLK on
                             backdrop of AA
                             (January 21, 2003)
           200




                    Announcement
                    SCOTUS will revisit AA
                    (December 3, 2002)
           0




           01jan2002                   01jan2003                   01jan2004              01jan2005



Notes: This figure reports the number of US newspaper articles by day that contained the phrase "affirmative
action" on newslibrary.com.




                                                    41
                         Figure A2: Racial Composition of UT Austin by Year



                                 White                                                                   Asian
           .65




                                                                .14 .15 .16 .17 .18 .19
           .6
           .55
           .5




                  98 99 00 01 02 03 04 05 06 07 08 09 10                                  98 99 00 01 02 03 04 05 06 07 08 09 10


                                 Black                                                                  Hispanic
           .05




                                                                .2
                                                                .18
           .045




                                                                .16
           .04




                                                                .14
           .035




                                                                .12




                  98 99 00 01 02 03 04 05 06 07 08 09 10                                  98 99 00 01 02 03 04 05 06 07 08 09 10




Notes: This figure reports the racial composition of UT Austin's fall enrollment by year using data from the
Integrated Postsecondary Education Data System (IPEDS).




                                                           42
Figure A3: Effect of AA on Admissions to Selective Institutions for URMs Relative to Whites


                                   UT Austin                                                                          U Houston
   .06




                                                                                      .03
   .04




                                                                                      .02
   .02




                                                                                      .01
   0




                                                                                      0
   -.02




                                                                                      -.01
          97   98   99   00   01    02 03 04 05         06   07   08   09   10               97   98   99   00   01    02 03 04 05         06   07   08   09   10
                                     9th grade cohort                                                                   9th grade cohort




                               Texas Tech                                                                        Texas A & M
   .04




                                                                                      .04
                                                                                      .03
   .03




                                                                                      .02
   .02




                                                                                      .01
   .01




                                                                                      0
   0




                                                                                      -.01
   -.01




          97   98   99   00   01    02 03 04 05         06   07   08   09   10               97   98   99   00   01    02 03 04 05         06   07   08   09   10
                                     9th grade cohort                                                                   9th grade cohort




Notes: This figure reports event study graphs for the probability of a URM student receiving admission to
each institution relative to a white student within 4 years of starting 9th grade. The regressions use the TEA
data. The sample is restricted to students in the top quintile of the test score distribution where quintiles
are measured using the of cohort-specific distribution of 6th grade standard test scores. Dotted lines report
95% confidence intervals with standard errors clustered at the district level.

 Texas A & M publicly announced that it would not use race (Parker, 2018).




                                                                                 43
Figure A4: Pre-AA Admissions to Selective Institutions for URMs and Whites, by Test Score
Decile

                                                                     Admissions to Selective Texas Universities


                       Average number of admissions by student
                       0       .1      .2        .3       .4




                                                                 1    2    3     4      5        6      7        8   9   10
                                                                                6th grade test score decile

                                                                                    URMs                Whites




Notes: This figure reports the average number of admissions to selective Texan public universities for the
pre-AA, 1997-2000 cohorts by decile of the 6th grade test score distribution. The statistics are calculated
separately for URM and white students.




                                                                                        44
Figure A5: Change in Relative Returns to Moving Up a Test Score Decile on Admissions to
Specific Texas Universities


                                  Admitted to UT Austin                                                                       Admitted to University of Houston
              .025




                                                                                                          .01
              .02




                                                                                          Admitted to University of Houston
   Admitted to UT Austin




                                                                                                                .005
       .01       .015




                                                                                                 0
              .005
              0




                                                                                                          -.005
                              2   3   4       5        6        7       8   9   10                                             2   3   4       5        6        7       8   9   10
                                          6th grade test score decile                                                                      6th grade test score decile


                                  Admitted to Texas Tech                                                       Admitted to University of Texas A&M
              .015




                                                                                                          .015  .01
                        .01
   Admitted to Texas Tech




                                                                                          Admitted to Texas A&M
                                                                                                        .005
            .005




                                                                                                0
              0




                                                                                                          -.005
              -.005




                                                                                                          -.01




                              2   3   4       5        6        7       8   9   10
                                          6th grade test score decile                                                          2   3   4       5        6        7       8   9   10
                                                                                                                                           6th grade test score decile




Notes: The outcomes are admission to each of 4 selective Texas universities. Bars indicate the coefficients
from equation (2), which capture the change in the marginal effect of moving up a test score decile on college
admissions for URMs relative to whites. Dashed lines show 95% confidence intervals for standard errors
clustered at the district-level.




                                                                                     45
                Figure A6: Effect of AA on SAT Scores for Asians and Whites

                                                                (a) Math SAT score


                            15
                 Average math SAT score
                  0        5-5      10




                                            98   99   00   01   02    03    04    05   06   07   08   09   10
                                                                           Year

                                                                     Whites            Asians



                                                                (b) Verbal SAT score
                            15         10
                 Average verbal SAT score
                 -5     0   -10  5




                                            98   99   00   01   02    03    04    05   06   07   08   09   10
                                                                           Year

                                                                     Whites            Asians



Notes: The outcomes are state-year average SAT math and verbal scores. Dots indicate coefficients from
a regression of the outcome on year indicator variables interacted with an indicator variable for the three
treated states, estimated separately for Asian and white students. Cells are weighted by the number of SAT
test takers. Dashed lines show 95% confidence intervals for standard errors clustered at the state-level.




                                                                        46
                                              Figure A7: Effect of AA on Verbal SAT Scores

                                                                   (a) Verbal SAT score


                             10
                  Average verbal SAT score
                        0    -5     5




                                             98   99   00     01   02    03    04    05   06   07   08   09   10
                                                                              Year

                                                                        Whites            URMs



                                                            (b) Verbal SAT score, detrended
                             20         15
                  Average verbal SAT score
                  0      5   -5  10




                                             98   99   00     01   02    03    04    05   06   07   08   09   10
                                                                              Year

                                                                        Whites            URMs



Notes: To construct this figure, we first estimate linear trends separately for each treatment group (race-by-
treatment status) using pre-AA years only (1998 to 2003). We then partial out these linear pre-trends from
the full panel. We use these de-trended series as the outcome. Dots indicate coefficients of regressions of
the outcome on year dummies interacted with an indicator variable for the three treated states, estimated
separately for white and URM students. Cells are weighted by the number of SAT test takers. Dashed lines
show 95% confidence intervals for standard errors clustered at the state-level.




                                                                           47
Figure A8: Difference Between Treated and Control States in the Synthetic Control Estimates
             15
  Average math SAT scores
       5     0   10




                             98     99        00   01   02    03     04    05   06   07   08   09    10
                                                                    Year

                                                             Whites             URMs
                            DDD coef: 4.505



Notes: This figure reports differences in SAT math scores between treated states and synthetic control groups,
separately for URMs and white students.




                                                                   48
                                   Figure A9: Raw Trends in College Applications by Race
                                    Panel A: Number of Applications to Selective Universities

                               Full sample                                                                            Top quintile
   .08




                                                                                          .3
   .06




                                                                                          .2
   .04




                                                                                          .1
   .02
   0




                                                                                          0
   -.02




                                                                                          -.1
          97   98   99   00   01    02 03 04 05          06      07   08   09   10               97   98   99   00   01   02 03 04 05          06      07   08   09   10
                                     9th grade cohort                                                                      9th grade cohort

                                     URMs               Whites                                                             URMs               Whites




                                     Panel B: Probability of Applying to Any UT Institution

                               Full sample                                                                            Top quintile
   .1




                                                                                          .15
                                                                                          .1
   .05




                                                                                          .05
   0




                                                                                          0
                                                                                          -.05
   -.05




          97   98   99   00   01    02 03 04 05          06      07   08   09   10               97   98   99   00   01   02 03 04 05          06      07   08   09   10
                                     9th grade cohort                                                                      9th grade cohort

                                     URMs               Whites                                                             URMs               Whites




Notes: This figure reports raw average trends in college applications behavior in our analytical sample. Time
series are normalized relative to the cohort that entered 9th grade in 2000.




                                                                                     49
 Figure A10: Average Effect of AA on College Applications for URMs Relative to Whites
                          Panel A: Number of Applications to Selective Universities



                    .08
                    .06
                    .04
                    .02
                    0




                           97   98   99   00   01   02 03 04 05         06   07   08   09   10
                                                     9th grade cohort


                          Panel B: Probability of Applying to Any UT Institution
                    .1
                    .08
                    .06
                    .04
                    .02
                    0




                           97   98   99   00   01   02 03 04 05         06   07   08   09   10
                                                     9th grade cohort



Notes: The outcome is the average number of applications sent to selective universities by students in Panel
A and the probability of applying to any institution in the University of Texas System in Panel B. Dots are
coefficients from a regression of the outcome on year dummies interacted with URM status. All regressions
condition on cohort-test score, race-test score and district-test score fixed effects, as well as means of individual
characteristics, where test score quintiles are from the cohort-specific distribution of 6th grade standard test
scores. Dashed lines show 95% confidence intervals for standard errors clustered at the district-level.




                                                         50
Figure A11: Effect of AA on Probability of Applying to Any Texan Public University for
URMs Relative to Whites



                    .15
                    .1
                    .05
                    0
                    -.05




                           97   98   99   00   01   02 03 04 05         06   07    08   09   10
                                                     9th grade cohort

                                               Bottom quintile          Top quintile




Notes: The outcome is the probability of applying to any Texan 4-year public university within 4 years of
starting 9th grade. Dots are coefficients from a regression of the outcome on year dummies interacted with
URM status. All regressions condition on cohort-test score, race-test score and district-test score fixed effects,
where where test score quintiles are from the cohort-specific distribution of 6th grade standard test scores.
Dashed lines show 95% confidence intervals for standard errors clustered at the district-level.




                                                          51
      Figure A12: Effect of AA on Mean Stanford Scores for URMs Relative to Whites




                              10         5
                    National Percentiles
                             0-5
                              -10




                                             00   01   02   03   04     05     06    07   08   09   10
                                                                 11th grade cohort



Notes: The outcome is the mean percentile rank on the Stanford test in 11th grade, where the mean is taken
across 5 subjects (reading, math, language, science, social science). Dots indicate coefficients from regressions
of the outcome on year dummies interacted with an indicator variable for URM status. The regressions also
include school-cohort, race, and ZIP code fixed effects, as well as controls for age and gender. Dashed lines
show 95% confidence intervals for standard errors clustered at the school-cohort level.




                                                                    52
                                      Appendix Tables

                                    Table A1: Summary Statistics

                                                                   URMs                      Whites
  SAT Data
  Years                                                   1998-2003 2004-2010       1998-2003 2004-2010
  Verbal scores                                              440.9       441.7         527.7        528.4
  Math scores                                               438.7        443.4         530.1        534.7
  Number of cells                                             878        1,026          306           357
  Number of SAT takers                                    1,194,067 2,159,747       4,136,869 5,634,200
  TEA Administrative Data
  Cohorts (grade 9)                                       1997-2000 2001-2010       1997-2000 2001-2010
  Age (grade 9)                                            14.2684     14.1983       14.1648       14.1412
  Limited English Proficiency (LEP)                         0.0671      0.0477        0.0004        0.0004
  Special Ed status                                         0.0772      0.0521        0.0784       0.0590
  English as a Second Language (ESL)                         0.042      0.0379        0.0001        0.0002
  Gifted                                                    0.0771      0.0852        0.1583       0.1599
  Immigrant                                                 0.0051      0.0014        0.0010       0.0004
  Poor                                                      0.6022      0.6628        0.1246        0.1570
  Female                                                     0.508      0.5079        0.4988        0.4963
  Test score decile (grade 6)                               4.3648      4.5541        6.6283       6.6263
  Attendance rate (grade 10)                                0.9343      0.9405        0.9541        0.9554
  Attendance rate (grade 11)                                0.9305      0.9335        0.9493        0.9494
  Applications to selective universities (within 4 years)   0.0603      0.1012        0.2098       0.2384
  UT system application rate (within 4 years)               0.0752      0.1325        0.0969       0.1242
  University application rate (within 4 years)              0.1734      0.2583        0.2900       0.3350
  College graduation rate                                   0.1126      0.0969        0.2488       0.2265
  District-cohort-test score cells                          12,492      36,462        17,414        41,614
  Number of students                                       357,973    1,176,595      405,005       971,850
  Number of districts                                         522         680           803           844
  LUSD Administrative Data
  Cohorts (grade 11)                                      2001-2003 2004-2008       2001-2003 2004-2008
  Age (grade 11)                                           16.3936     16.4087       16.2100       16.2234
  Female                                                    0.5377      0.5346        0.5057       0.5202
  Mean school grades (grade 11)                            77.3440     78.1689       82.2364       83.4534
  Mean school grades (grade 8)                             82.4995     81.9075       86.6246       86.8627
  Attendance rate (grade 11)                                0.9286      0.9274        0.9431        0.9482
  Stanford test percentile rank (grade 11)                 36.1245     49.7647       69.2039       77.8087
  Number of students                                        17,620      34,107         3,623         5,779
  Number of schools                                            42          49            36            42
Notes: This table reports summary statistics (means) from the SAT data, the Texas Education Agency
(TEA) administrative data and the administrative data from a large, urban school district (LUSD). An
observation in the SAT data is a race-year-state cell. An observation in the TEA data is a district-test score
decile-cohort cell. The LUSD data consists of repeated cross-sections of 11th graders, and an observation is
a student.




                                                     53
                    Table A2: Summary Statistics for THEOP Survey Data


       Panel A: Summary Statistics
                                                  Full Sample           Whites          URMs
                                                  Mean    SD        Mean     SD      Mean   SD
       Time (Minutes) Spent on Homework           64.54 56.69       56.06 53.60      70.56 56.26
       Applied to First Choice College            0.65    0.48       0.70   0.46     0.60   0.49
       Parental Involvement Index (0-15)          5.98    3.87       5.94   3.78     6.18   3.96
       Discussed College App. w. Counselor         0.67   0.47       0.65   0.48     0.70   0.46

       Panel B: Total Numbers
                                                     N
       Total Students                             13,938
       Whites                                      6,406
       URMs                                        7,532
       Students in 2002                           11,098
       Students in 2004                           2,840

Notes: This table reports summary statistics for the Texas Higher Education Opportunity Project (THEOP)
survey data for two cohorts of seniors, one in 2002 and one in 2004. For the measure of how many minutes
per day students spend on homework, students were asked how many hours per day they spent on their
homework and were given the options zero hours, less than 1 hour, 1 to 2 hours, 3 to 4 hours, and 5+ hours.
We convert these to minutes so that 0 hours is 0 minutes, less than 1 hour is 30 minutes, 1 to 2 hours is
90 minutes, and so on. The parental involvement index is also constructed using several questions that ask
"How often do your parents ... (i) give you special privileges because of good grades, (ii) try to make you
work harder if you get bad grades, (iii) know when you are having difficulty in school, (iv) help with your
school work, and (v) talk with you about problems in school." Students' responses range from "very rarely"
(1) to "almost all the time" (4). We sum across the answers to these questions to construct the "parental
involvement index" in a way that a higher index corresponds to more involvement along these dimensions
and renormalize the measure by subtracting 5 so that the minimum score is 0 rather than 5.




                                                    54
Table A3: Effect of AA on Application to Any Texan Public University for URMs Relative
to Whites


                                                       Percentile of 6th grade test score distribution
                                         All      Bottom        2nd         3rd          4th         Top
                                      students    quintile    quintile quintile       quintile     quintile
                                         (1)         (2)         (3)        (4)          (5)          (6)
                                               Dependent variable: Application to any university
  Partial treatment                  0.0082*** 0.0085*** 0.0047           0.0016      0.0090*     0.0238***
                                      (0.0026)    (0.0027) (0.0036) (0.0044)          (0.0052)     (0.0073)
  Full treatment                     0.0169***     0.0031     0.0048 0.0125** 0.0254*** 0.0438***
                                      (0.0035)    (0.0030) (0.0040) (0.0058)          (0.0059)     (0.0085)

  Observations (cells)                 68509        12933        14515      14809        14145        12107
  R2                                    0.915        0.788        0.815     0.810        0.802        0.781
  Mean dependent variable              0.2603       0.0659       0.1414     0.2312       0.3499       0.5107
  Test: quintile q = top quintile
    Partial treatment p-value                       0.0552       0.0141     0.0051       0.0610
    Full treatment p-value                          0.0000       0.0000     0.0001       0.0166
  Demographic controls                    X           X            X          X            X            X
  District-cohort-test score FE           X           X            X          X            X            X
  District-ethnicity-test score FE        X           X            X          X            X            X

Notes: This table reports difference-in-differences estimates of the effect of affirmative action on URMs'
college applications behavior. The regressions use the TEA data, an observation is at the district-cohort-
race-test score quintile level, where quintiles are assigned based on 6th grade (pre-AA) test scores on the state
standardized test. The sample is restricted to students who were in 9th grade between 1997 and 2006. Cells
are weighted by the number of student-years in a cell. Partial treatment is the coefficient on the interaction
between an indicator for being a URM and an indicator variable for entering high school after 2001 and
before 2003. Full treatment is the coefficient on the interaction between entering high school after 2003 and
being a URM. The outcome variable is the fraction of students in a cell that applied to any Texan public
university. Standard errors are clustered at the district-level.




                                                       55
        Table A4: Effect of AA on Stanford Test Scores for URMs Relative to Whites


                                                                Grades in 8th grade
                                       All students Bottom tercile Middle tercile Top tercile
                                            (1)           (2)              (3)            (4)
                                          Dependent variable: Stanford Test Scores (grade 11)
     Treated                            4.7801***     4.2109***        4.6267***      7.3731***
                                         (1.1352)      (1.2879)         (1.5649)       (1.4315)

     Observations                          58096             15486              15347           14620
     R2                                    0.444             0.455              0.487           0.464
     Mean dependent variable               49.40             42.24              50.49           59.99
     S.D. dependent variable               25.74             23.38              24.00           23.76
     Test: tercile q = top tercile
       p-value                                              0.0981             0.1184
     School-year FE                          X                X                  X                 X
     Ethnicity FE                            X                X                  X                 X
     Demographic controls                    X                X                  X                 X

Notes: This table reports the difference-in-differences estimates of the effect of affirmative action on mean
Stanford test scores (in national percentile ranks) in a large, urban school district. Mean Stanford test scores
are the average across 5 subjects (reading, math, language, science, social science). An observation is a
student, and the sample consists of repeated cross-sections of 11th graders. "Treated" is the coefficient on
the interaction between being a URM and being observed post 2003. Achievement terciles are assigned based
on 8th grade average school grades, and the sample is restricted to years 2001 to 2008. Standard errors are
clustered at the school-level.




                                                      56
 Table A5: Effect of AA on College Applications Behavior ­ Excluding Houston & Dallas


                                                        Percentile of 6th grade test score distribution
                                         All      Bottom        2nd          3rd          4th         Top
                                      students    quintile quintile       quintile     quintile     quintile
                                         (1)         (2)        (3)          (4)          (5)         (6)
                                                 Panel A: Applications to Selective Universities
  Partial treatment                  0.0096***     0.0026     0.0010       0.0022     0.0146** 0.0312***
                                      (0.0028)    (0.0018) (0.0024) (0.0037)           (0.0071)    (0.0087)
  Full treatment                     0.0213***    0.0028*     0.0042 0.0156*** 0.0355*** 0.0519***
                                      (0.0032)    (0.0015) (0.0030) (0.0050)           (0.0064)    (0.0099)

  Observations (cells)                 67909        12813      14395        14689        14025        11987
  R2                                    0.911        0.466      0.625       0.731        0.797        0.836
  Mean dependent variable              0.1511       0.0079     0.0321       0.0861       0.1980       0.4169
  Test: quintile q = top quintile
    Partial treatment p-value                       0.0016    0.0007      0.0020     0.1074
    Full treatment p-value                          0.0000    0.0000      0.0003     0.1133
                                                   Panel B: Application to any UT Institution
  Partial treatment                    0.0029      0.0035** -0.0032       0.0016     0.0021          0.0133**
                                      (0.0020)     (0.0014) (0.0024) (0.0032)       (0.0042)         (0.0061)
  Full treatment                     0.0088***      0.0007    0.0019     0.0095**   0.0098*         0.0239***
                                      (0.0027)     (0.0017) (0.0021) (0.0040)       (0.0051)         (0.0074)

  Observations (cells)                 67909        12813      14395        14689        14025        11987
  R2                                    0.903        0.827      0.871       0.879        0.864        0.846
  Mean dependent variable              0.1108       0.0229     0.0537       0.0903       0.1407       0.2372
  Test: quintile q = top quintile
    Partial treatment p-value                       0.1337     0.0068       0.0753       0.0700
    Full treatment p-value                          0.0016     0.0041       0.0376       0.0549
  Demographic controls                    X           X          X            X            X            X
  District-cohort-test score FE           X           X          X            X            X            X
  District-ethnicity-test score FE        X           X          X            X            X            X

Notes: This table reports difference-in-differences estimates of the effect of affirmative action on URMs'
college applications behavior. The regressions use the TEA data, an observation is at the district-cohort-
race-test score quintile level, where quintiles are assigned based on 6th grade (pre-AA) test scores on the state
standardized test. The sample is restricted to students who were in 9th grade between 1997 and 2006. The
sample excludes the Houston Independent School District and the Dallas Independent School District. Cells
are weighted by the number of student-years in a cell. Partial treatment is the coefficient on the interaction
between an indicator for being a URM and an indicator variable for entering high school after 2001 and before
2003. Full treatment is the coefficient on the interaction between entering high school after 2003 and being
a URM. The outcome variable in panel A is the average number of selective universities to which students
applied. The outcome variable in Panel B is the fraction of students in a cell that applied to any institution
of the University of Texas system. Standard errors are clustered at the district-level.




                                                       57
  Appendix A: Robustness of Difference-in-Differences
                                           SAT Results
Accounting for AA Bans. Several states implemented affirmative action bans in uni-
versity admissions during our study period. Washington, Michigan, and Nebraska passed
affirmative action bans through ballot initiatives in November 1998, 2006 and 2008, respec-
tively. Governor Jeb Bush issued an executive order banning affirmative action in Florida
in November 1999.36 We do not use these bans to estimate the effects of affirmative action
because, as Hinrichs (2012) points out, the effect of affirmative action bans cannot be dis-
entangled from the effect of percent plans; these two policies were almost always enacted
concurrently. This would certainly be an issue for estimating the effect of bans in our SAT
sample. In this sample, Florida would drive most of the variation in the AA ban indicator
because of its large population size and the fact that Michigan and Nebraska are both ACT
states and have fewer SAT test-takers. Florida implemented a very aggressive "percent plan"
under which students in the top 20% of their high school graduating class were guaranteed
admission to a state public university shortly after the ban.
    In our main empirical specification, we control for affirmative action bans in control
states.37 In this subsection, we verify that our difference-in-differences estimates of the effect
of Grutter v. Bollinger on students in Texas, Louisiana and Mississippi are robust to alter-
native ways of accounting for these affirmative action bans. Robustness tests for math SAT
scores are reported in Appendix Table A6 and, for completeness, corresponding results for
verbal scores are reported in Appendix Table A7. Column (1) reports results for our baseline
specification. The coefficient on the AA ban indicator is statistically insignificant in all three
difference-in-differences specifications (panels A to C). In the triple-differences model (panel
D), the coefficient on the AA ban indicator interacted with a URM dummy is positive and
significant (5.7 points), which suggests that URM students' SAT scores increased relative
to white students' in the states that implemented bans on affirmative action. However, as
discussed above, we strongly caution against interpreting this coefficient as the causal effect
of AA bans. In column (2), we omit the controls for the effect of affirmative action bans.
Our estimates of the effect of Grutter v. Bollinger on whites (4 points) and on URMs (8
points) are unaffected by the exclusion of an indicator for AA bans as a control variable.
   36
       Following our study period, Arizona (2010), New Hampshire (2011) and Oklahoma (2012) also banned
affirmative action in college admissions.
    37
       The indicator turns on after 1999 in Washington, after 2000 in Florida, after 2007 in Michigan, and after
2009 in Nebraska. It is zero in all years for all others states.


                                                      58
Failing to control for AA bans yields a slightly smaller triple-differences estimate of 4 points.
In column (3), we drop the four states that banned affirmative action between 1998 and
2010 from the estimating sample. Again, our estimates of the effect of the reinstatement of
affirmative action are virtually unchanged.

Accounting for Potential Non-Compliance. There is some evidence that Louisiana
and Mississippi may have continued to use race in university admissions to some extent in
1998-2003 despite the Hopwood v. Texas ruling due to pre-existing rulings that required
them to de-segregate their institutions of higher education (Hinrichs, 2012). Thus, we also
drop these two states from the sample and estimate the effects of the policy change on Texas
alone relative to the control states in column (4) of Appendix Table. Dropping these two
states has little effect on the estimates.

Accounting for Group-Specific Pre-Trends. It is apparent in Figure 2 that Texas,
Louisiana and Mississippi were falling behind the rest of the country prior to the reinstatement
of AA. To account for these differential pre-trends, we estimate a linear trend term separately
for each racial group and treatment group using only the pre-treatment year, and partial out
this linear trend from the full panel. We use the resulting de-trended data as our outcome
variable in column (5). The point estimates are generally twice as large as they are in our
baseline specifications. This suggests that, if anything, our main estimates put a lower bound
on the effect of affirmative action on SAT scores.




                                               59
  Table A6: Robustness of Effect of AA on Math SAT Scores to Controlling for AA Bans


                                    Baseline    No control for    Drop AA Drop Mississippi De-trended
                                                  AA bans        ban states    and Louisiana     data
                                       (1)           (2)             (3)             (4)          (5)
                                                                 Panel A: URMs
 DD coefficient                     8.009***       7.998***       8.122***       8.092***     20.02***
                                     (1.544)        (1.498)        (1.694)        (1.538)      (1.522)
 AA Ban Indicator                     0.312                                         0.290       -0.114
                                     (2.696)                                      (2.704)      (2.490)
 Observations (cells)                 1904           1904           1748            1830         1904
 R2                                   0.844          0.844          0.839           0.844       0.693
 State, year and ethnicity FE           X              X              X               X            X
                                                                Panel B: Whites
 DD coefficient                     4.048***       4.145***       3.835***       4.455***     7.208***
                                     (0.984)        (0.995)        (1.021)        (0.849)      (0.984)
 AA Ban Indicator                     -3.282                                       -3.279       -3.382
                                     (2.668)                                      (2.670)      (2.669)
 Observations (cells)                   663           663            611             637         663
 R2                                    0.969         0.968          0.967           0.969       0.968
 State, year and ethnicity FE            X             X              X               X            X
                                                                 Panel C: Asians
 DD coefficient                       0.658          0.658          0.447          0.362      6.659***
                                     (1.827)        (1.813)        (1.962)        (1.788)      (1.828)
 AA Ban Indicator                    -0.0191                                      -0.0268       -0.177
                                     (6.710)                                      (6.725)      (6.716)
 Observations (cells)                  663            663            611             637         663
 R2                                   0.944          0.944          0.939           0.944       0.939
 State, year and ethnicity FE           X              X              X               X            X
                                                  Panel D: Triple-Difference (URMs vs Whites)
 DDD coefficient                    4.155***       3.975***       4.253***       4.059***     10.17***
                                     (0.828)        (0.872)        (0.816)        (0.817)      (1.263)
 AA Ban Indicator                   5.714***                                     5.689***     4.979***
   × URM dummy                       (1.153)                                      (1.158)      (1.137)
 Observations (cells)                 2555           2555           2347            2455         2555
 R2                                   0.998          0.998          0.998           0.998       0.989
 State-year FE                          X              X              X               X            X
 State-ethnicity FE                     X              X              X               X            X
 Ethnicity-year FE                      X              X              X               X            X

Notes: This table reports difference-in-differences and triple-differences effects of affirmative action on SAT
scores. Each observation is a state-race-year group. In all specifications, cells are weighted by the number
of test-takers in a group. In Panels A, B and C, the DD coefficient reports the interaction of an indicator
variable for belonging to a treated state (Texas, Louisiana, Mississippi) and being tested after Grutter v.
Bollinger (post 2003). In Panel D, the coefficient is on the interaction between being a URM, being tested
post 2003, and belonging to a treated state. Standard errors are clustered at the state-level.

                                                      60
 Table A7: Robustness of Effect of AA on Verbal SAT Scores to Controlling for AA Bans


                                    Baseline    No control for    Drop AA Drop Mississippi De-trended
                                                  AA bans        ban states    and Louisiana     data
                                       (1)           (2)              (3)            (4)          (5)
                                                                 Panel A: URMs
 DD coefficient                       -0.634         -0.779         -0.170         -0.649     8.000***
                                     (1.784)        (1.756)        (1.929)        (1.795)      (1.935)
 AA Ban Indicator                    4.131*                            0           4.112*        3.150
                                     (2.264)                          (.)         (2.269)      (2.412)
 Observations (cells)                  1901           1901           1745           1828         1901
 R2                                    0.796         0.795          0.788           0.793       0.717
 State, year and ethnicity FE            X              X              X              X            X
                                                                Panel B: Whites
 DD coefficient                      0.0342         0.0247        0.000796        -0.0255       -0.179
                                     (0.888)        (0.878)        (0.955)        (0.888)      (0.888)
 AA Ban Indicator                     0.321                            0            0.332        0.328
                                     (3.182)                          (.)         (3.183)      (3.182)
 Observations (cells)                  663             663           611             637          663
 R2                                   0.971          0.971          0.970           0.970       0.971
 State, year and ethnicity FE           X               X              X              X            X
                                                                 Panel C: Asians
 DD coefficient                       -0.176         -0.145         -0.456         -0.426      5.088*
                                     (2.753)        (2.709)        (2.880)        (2.743)      (2.751)
 AA Ban Indicator                     -1.408                           0           -1.411       -1.546
                                     (3.531)                          (.)         (3.540)      (3.508)
 Observations (cells)                   663            663           611             637          663
 R2                                    0.929         0.929          0.925           0.928       0.920
 State, year and ethnicity FE            X              X              X              X            X
                                                  Panel D: Triple-Difference (URMs vs Whites)
 DDD coefficient                      1.260           1.083        1.440**        1.331*      7.137***
                                     (0.753)        (0.825)        (0.634)        (0.763)      (1.081)
 AA Ban Indicator                   5.604***                           0         5.575***     4.810***
   × URM dummy                       (1.478)                          (.)         (1.476)      (1.382)
 Observations (cells)                 2552            2552           2344           2453         2552
 R2                                   0.998          0.998          0.998           0.998       0.990
 State-year FE                          X               X              X              X            X
 State-ethnicity FE                     X               X              X              X            X
 Ethnicity-year FE                      X               X              X              X            X

Notes: This table reports difference-in-differences and triple-differences effects of affirmative action on SAT
scores. Each observation is a state-race-year group. In all specifications, cells are weighted by the number
of test-takers in a group. In Panels A, B and C, the DD coefficient reports the interaction of an indicator
variable for belonging to a treated state (Texas, Louisiana, Mississippi) and being tested after Grutter v.
Bollinger (post 2003). In Panel D, the coefficient is on the interaction between being a URM, being tested
post 2003, and belonging to a treated state. Standard errors are clustered at the state-level.

                                                      61
Appendix B: Robustness of SAT Results to Alternative
                    Synthetic Control Specifications

    In our baseline synthetic control results, we choose the control group by minimizing the
mean squared prediction errors in 1998-2003 using the following set of variables as predictors:
number of white SAT test takers, number of URM SAT test takers, white math SAT scores,
URM math SAT scores, white verbal SAT scores, and URM verbal SAT scores. Each of
these variables is averaged over 1998-2000 and over 2001-2003 in the matching process. Here,
we verify that our results are robust to using alternative sets of pre-treatment variables and
alternative donor pools.

Matching on SAT Taking Rates. Using the actual number of SAT test takers may put
too much weight on state size, as opposed to student SAT-taking behavior. Appendix Figure
A13 shows results when we substitute SAT taking rates for number of SAT test takers. To
calculate SAT taking rates, we divide the number of test takers by the number of 17-19 years
olds in each state-by-race-by-year cell, which we obtain from ACS/Census data. Note that
these population counts are not available in 1998 and 1999. Hence, we here match on fewer
values. Also, population counts at such a disaggregated level are quite volatile, which may
introduce measurement error in the process. Nevertheless, the observed patterns under this
alternative approach are quite similar to our baseline results.

Matching on Fewer Pre-treatment Cohorts. Here, we verify that our results are ro-
bust to using fewer pre-treatment years in the construction of the synthetic control group.
Appendix Figure A14 shows time series of math SAT scores for synthetic control groups
based on 4, 5 and 6 years of pre-treatment data.38
    For whites, the results are insensitive to the model's specification, with the 3 synthetic
groups tracking each other very closely. Reassuringly, when fewer years of pre-treatment data
are used to construct the synthetic control group, the gap between treated and untreated
states during pre-treatment years remains very small, even in years that were not used in the
construction of the synthetic control group. The states included in the 5-year match synthetic
control group are California (46.4%), Florida (39.5%), Indiana (6.1%) and Pennsylvania
 38
    When minimizing the RMSPE over 4 years, we average the predictors over 1998-1999 and 2000-2001.
When minimizing the RMSPE over 5 years, we average the predictors over 1998-2000 and 2001-2002.




                                                62
(7.9%). The states included in the 4-year match synthetic control group are California
(44.9%), Florida (41.9%), Indiana (10.7%), North Carolina (1.8%) and Pennsylvania (0.6%).
    There are fewer URMs than whites taking the SAT in a state in a given year. As a result,
yearly mean SAT scores for URMs are more volatile, and the composition of the synthetic
control group is more sensitive to the number of pre-treatment years over which the RMSPE
is minimized. While the SAT scores of the 6-year match synthetic control group track our
treated group very closely for all pre-treatment years, the 4-year and 5-year match groups
do not replicate the treated states' negative pre-trend as closely. In both cases, an upward
movement in SAT scores of the synthetic group appears around 2002, whereas the treated
states are still on a downward trend at that time. By 2007, however, the outcomes of the
three synthetic control groups are similar, and in all cases, the control groups' SAT scores
are significantly below those of the treated states. The states included in the 5-year match
synthetic control group are California (84.3%), Pennsylvania (11.6%) and New Hampshire
(4%). The states included in the 4-year match synthetic control group are California (82.4%),
West Virginia (14.8%), and Pennsylvania (2.7%).

Excluding States That Banned AA During the Study Period. Next, we drop the
four states that banned affirmative action between 1998 and 2010 (Florida, Nebraska, Michi-
gan and Washington) from the donor pool. The results are shown in Appendix Figure A16. In
the pre-treatment years, the synthetic control group tracks the treated states fairly closely,
albeit with more volatility than under our baseline approach. Overall, our results on the
effect of Grutter v. Bollinger are not significantly affected by this sample restriction. The
states included in the synthetic control group for whites are California (35.1%), Pennsylvania
(38.7%), New York (15.2%), Utah (4.5%), New Hampshire (2.8%), Minnesota (2.5%), and
Montana (1.1%). The states included in the synthetic control group for URMs are California
(70.8%), Pennsylvania (20.1%), and New Hampshire (9.1%).

Static Matching. As a final robustness check, we consider an alternative matching algo-
rithm. Here, we use a nearest-neighbor matching approach and match treatment and control
states using cross-sectional variation in observable characteristics. First, we extract several
average characteristics of 17-54 years olds in each state from the 2000 census, separately by
ethnicity (White, Black, Hispanic). We then match treated and control states on the fol-
lowing observable characteristics, all measured for year 2000 and entered separately for the
three ethnicities: fraction immigrant, fraction employed, fraction who has moved in the past
5 years, average occupational income score, average age, fraction of the state's population,

                                              63
the SAT taking rate of 17-19 year olds, their average SAT math score, and their average SAT
verbal score. We run the matching algorithm twice: once weighting states by their number
of white residents, and once weighting states by their number of URM residents. We thereby
retrieve matching weights separately for whites and URMs. 11 states have positive weights in
the matched control group for whites, with the most weight being put on California (26.3%),
Pennsylvania (21.3%), Ohio (20.2%), Missouri (9.4%) and Arizona (5.2%). 8 states have
positive weights in the matched control group for URMs, with the most weight being put on
California (48.7%), New York (21.2%), Florida (18.2%), Ohio (4.8%) and Arizona (4.2%).
The matched control groups do not track the treatment group's pre-trend as closely as the
synthetic control groups do, but the results still indicate positive effects of AA on both whites
and URMs, with a significantly larger effect on URMs.

Figure A13: Synthetic Control Estimates of the Effect of AA on Math SAT Scores, Matching
on SAT Taking Rates


                                                             Whites                                                                                                       URMs
             545




                                                                                                                          460     455
                     540
     Average SAT score




                                                                                                                  Average SAT score
                                                                                                                         450
            535




                                                                                                                445
   530




                                                                                                                          440
             525




                           98     99        00    01    02    03    04    05   06    07    08    09   10                                98     99        00    01    02    03    04    05   06    07    08    09   10
                                                                   Year                                                                                                         Year

                                                 Treated States            Synthetic Control Group                                                            Treated States            Synthetic Control Group
                           DD coef: 6.096                                                                                               DD coef: 6.129




Notes: This figure reports synthetic cohort analyses separately for whites and URMs. It shows SAT math
scores for the treated states (Texas, Mississippi and Louisiana) and for the synthetic control group. In
constructing the control group, we use pre-treatment estimated SAT taking rates rather than number of test
takers as match variables. SAT-taking rates are not available in 1998 and 1999.




                                                                                                           64
Figure A14: Synthetic Control Estimates of the Effect of AA on Math SAT Scores, by
Number of Pre-treatment Years Used in Match


                                                            Whites                                                                                                          URMs
             545




                                                                                                                            460    455
                     540
     Average SAT score




                                                                                                                  Average SAT score
                                                                                                                          450
            535




                                                                                                                  445
   530




                                                                                                                            440
             525




                            98     99      00     01   02    03    04    05   06   07    08    09    10                                    98     99       00     01   02    03    04    05   06   07    08    09    10
                                                                  Year                                                                                                            Year

                                           Synthetic, 6-year match            Synthetic, 5-year match                                                      Synthetic, 6-year match            Synthetic, 5-year match
                                           Synthetic, 4-year match            Treated States                                                               Synthetic, 4-year match            Treated States




Notes: This figure reports synthetic cohort analyses separately for whites and URMs. It shows SAT math
scores for the treated states (Texas, Mississippi and Louisiana) and for the synthetic control group under
alternative matching specifications. The control group "Synthetic, 6-year match" is obtained by minimizing
the root mean squared prediction error (RMSPE) over the 1998-2003 period. For "Synthetic, 5-year match,"
the RMSPE is minimized over the 1998-2002 period, and for "Synthetic, 4-year match," it is minimized over
the 1998-2001 period.



Figure A15: Synthetic Control Estimates of the Effect of AA on Math SAT Scores, Dropping
AA Ban States


                                                            Whites                                                                                                          URMs
             545




                                                                                                                            460     455
                     540
     Average SAT score




                                                                                                                    Average SAT score
                                                                                                                           450
            535




                                                                                                                  445
   530




                                                                                                                            440
             525




                           98     99       00    01    02    03    04    05   06    07    08    09      10                                98     99        00    01    02    03    04    05   06    07    08    09      10
                                                                  Year                                                                                                            Year

                                                Treated States            Synthetic Control Group                                                               Treated States            Synthetic Control Group
                           DD coef: 4.74                                                                                                  DD coef: 7.988




Notes: This figure reports synthetic cohort analyses separately for whites and URMs. It shows SAT math
scores for the treated states (Texas, Mississippi and Louisiana) and for the synthetic control group. In
constructing the control group, Florida, Nebraska, Michigan and Washington were omitted from the donor
pool.



                                                                                                             65
                             Figure A16: Matching Estimates of the Effect of AA on Math SAT Scores


                                                         Whites                                                                                                    URMs




                                                                                                                   465
           550




                                                                                                                           460
   Average SAT score




                                                                                                          Average SAT score
              545




                                                                                                          450      455
   540




                                                                                                                   445
           535




                       98     99        00    01    02    03    04    05   06   07    08   09   10                               98     99        00    01    02    03    04    05   06   07    08   09   10
                                                               Year                                                                                                      Year

                                             Treated States            Matched Control Group                                                           Treated States            Matched Control Group
                       DD coef: 2.082                                                                                            DD coef: 7.654




Notes: This figure reports matching analyses separately for whites and URMs. It shows weighted average SAT
math scores for the treated states (Texas, Mississippi and Louisiana) and for the matched control group. The
control group is constructed by matching on the following observables characteristics measured separately
for Whites, Blacks and Hispanics in each state: fraction immigrant (2000 census), fraction employed (2000
census), fraction who moved in pasted 5 years (2000 census), mean occupational income score (2000 census),
mean age (2000 census), fraction of the population (2000 census), SAT taking rate in 2000, average SAT
math score in 2000 and average SAT verbal score in 2000.




                                                                                                     66
