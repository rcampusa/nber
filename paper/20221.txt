                                 NBER WORKING PAPER SERIES




      FLAKING OUT: STUDENT ABSENCES AND SNOW DAYS AS DISRUPTIONS
                         OF INSTRUCTIONAL TIME

                                           Joshua Goodman

                                         Working Paper 20221
                                 http://www.nber.org/papers/w20221


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                      June 2014




For inspiring this project and providing the data, I am indebted to Carrie Conaway, Associate Commissioner
of Planning, Research, and Delivery Systems at the Massachusetts Department of Elementary and
Secondary Education. I am grateful to Colin Sullivan, Heather Sarsons, Shelby Lin, Napat Jatusripitak
and Carlos Paez for excellent research assistance. I also thank for helpful comments David Deming,
Paul Peterson and Martin West, as well as seminar participants at AEFP, APPAM and Harvard. Institutional
support from the Taubman Center at Harvard is gratefully acknowledged. The views expressed herein
are those of the author and do not necessarily reflect the views of the National Bureau of Economic
Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2014 by Joshua Goodman. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given to
the source.
Flaking Out: Student Absences and Snow Days as Disruptions of Instructional Time
Joshua Goodman
NBER Working Paper No. 20221
June 2014
JEL No. I20,I21,I24

                                            ABSTRACT

Despite the fact that the average American student is absent more than two weeks out of every school
year, most research on the effect of instructional time has focused not on attendance but on the length
of the school day or year. Student and school fixed effects models using Massachusetts data show
a strong relationship between student absences and achievement but no impact of lost instructional
time due to school closures. I confirm those findings in instrumental variables models exploiting the
fact that moderate snowfall induces student absences while extreme snowfall induces school closures.
Prior work ignoring this non-linearity may have mis-attributed the effect of absences to such snow
days. Each absence induced by bad weather reduces math achievement by 0.05 standard deviations,
suggesting that attendance can account for up to one-fourth of the achievement gap by income. That
absences matter but closures do not is consistent with a model of instruction in which coordination
of students is the central challenge, as in Lazear (2001). Teachers appear to deal well with coordinated
disruptions of instructional time like snow days but deal poorly with disruptions like absences that
affect different students at different times.


Joshua Goodman
Harvard Kennedy School
79 JFK Street
Cambridge, MA 02138
and NBER
joshua_goodman@hks.harvard.edu
1       Introduction

Concerns about the academic performance of American students perennially prompt calls to in-

crease the amount of instructional time by lengthening the school day or year. Early in his first

term, for example, President Obama argued in a widely publicized speech that

         We can no longer afford an academic calendar... [that] puts us at a competitive dis-

         advantage. Our children... spend over a month less in school than children in South

         Korea - every year. That’s no way to prepare them for a 21st century economy. That’s

         why I’m calling for us... to rethink the school day to incorporate more time - whether

         during the summer or through expanded-day programs for children who need it.1

Proponents of increased instructional time point not only to international comparisons but also to

suggestive domestic evidence. Highly successful charter schools tend to have long school days

and years, and within the charter sector, larger amounts of instructional time are correlated with

higher school effectiveness (Hoxby and Murarka, 2009; Dobbie and Fryer, 2011; Angrist et al.,

2013). In some settings, low-income children’s achievement declines over the summer at a faster

rate than the achievement of high-income children, a phenomenon known as summer learning

loss (Alexander et al., 2001), though such loss is not observed in all settings Fryer and Levitt

(2004).

        Perhaps because of the frequent focus on achievement losses from long summers or short

school days, the discussion of instructional time has rarely touched on another major determi-

nant of instructional time, namely attendance rates. This omission from the literature is surpris-

ing, given that the average American student is absent more than two weeks out of every school

year.2 What makes this omission particularly odd is that attendance is one of the variables most

commonly contained in the local and state administrative data sets underlying much of modern

education research.
    1
     See President Obama’s March 10, 2009 speech to the Hispanic Chamber of Commerce, accessed at http://www.
whitehouse.gov/briefing-room/speeches-and-remarks on June 2, 2014.
   2
     See Table 203.90 in Snyder and Dillow (2014), which lists the average daily attendance rate as 93.9% and the average
school year length as 179 days. This implies that the average student misses nearly 11 school days, or more than two
weeks, each year. Secondary school students miss three weeks a year on average.



                                                           1
    This paper provides some of the first well-identified evidence on the impact of instructional

time lost due to absences, as well as to school closures. Using statewide, longitudinal, student-

level data from Massachusetts, I run both student and school fixed effects regression models that

show a strong relationship between student absences and achievement but no relationship be-

tween school closures and achievement. I confirm those findings in instrumental variables mod-

els exploiting the fact that moderate snowfall induces student absences while extreme snowfall

induces school closures. Each absence induced by bad weather reduces math achievement by 0.05

standard deviations, suggesting that attendance can account for up to one-fourth of the achieve-

ment gap by income.

    This paper makes three contributions to the literature. First, it provides well-identified ev-

idence that that attendance is an important determinant of student achievement. Nearly all of

the well-identified literature on instructional time focuses on the amount of time built into the

school schedule, generally finding that such time has a substantial impact on student learning.3

Examples include Lavy (2010) and Rivkin and Schiman (2013), which exploit within-student and

within-school variation in instructional time by subject; Pischke (2007) and Lavy (2012), which

exploit policy interventions that respectively shorten the West German school year and increase

Israeli schools’ instructional time budget; and Fitzpatrick et al. (2011) and Carlsson et al. (2012),

which exploit random variation in the timing of standardized tests. What little prior research

addresses unexpected losses of instructional time due to absences generally depends on iden-

tification strategies that leave open the possibility of substantial omitted variable bias, such as

simply controlling for observable characteristics of students or instrumenting absences with stu-

dents’ distance from school (Gottfried, 2009, 2010). This paper provides the first credible strategy

for identifying the impact of one type of student absences, namely those induced by bad weather.

    The paper’s second contribution is to show that prior work estimating the impact of unex-

pected school closures due on student achievement may have mis-identified those effects. Mar-

cotte (2007), Marcotte and Hemelt (2008) and Hansen (2013) provide the first clear evidence that
   3
     One recent exception to this is the finding in Abt Associates Inc. (2012) that Massachusetts’ Expanded Learning
Time Initiative, which added 300 hours of instructional time a year to a subset of schools, had no impact on student
achievement.




                                                         2
bad weather disrupts student learning. My results are consistent with such reduced form esti-

mates. Those papers argue that bad weather can serve as an instrument for the number of snow

days experienced by a given school or student, allowing identification of the impact of snow days.

I show that bad weather violates the exclusion restriction in this context because weather affects

not only school closures but also student absences. When I use multiple weather instruments to

credibly identify the impact of those two endogenous regressors, I find that all of the impact of

weather runs through student absences and none through school closures. This result highlights

the importance of non-linearities in instrumental variables estimation, an issue discussed in Loken

et al. (2012).

    The paper’s third contribution is to provide further empirical support for the congestion model

of classroom learning presented in Lazear (2001). That absences matter but closures do not is con-

sistent with that model of instruction in which coordination of students is the central challenge. In

Massachusetts, teachers and schools deal well with coordinated disruptions of instructional time

like snow days but deal poorly with disruptions like absences that affect different students at dif-

ferent times. Student absences can impede the public aspects of the learning process as teachers

must split their time between students who have and have not missed the previous day’s lessons.

Though Lazear (2001) emphasizes behavioral disruptions as the main source of congestion, they

are not the only such source. All of the predictions of that model regarding optimal class size and

the effects of changing class size hold true if “student behavior” is replaced by “student atten-

dance.”

    The structure of the paper is as follows. Section 2 describes the data, documents broad patterns

in student attendance and achievement, and discusses the relation between weather and school

closures. Section 3 estimates the impact of student absences and school closures on achievement,

first with fixed effects estimates comparing students and schools to themselves over time and

then with instrumental variables estimates that use snowfall as an exogenous source of variation

for both types of lost instructional time. In section 4, I argue that these estimates are consistent

with a model in which the central challenge of teaching is coordination of students. Section 5

concludes with thoughts for future research.



                                                 3
2     The Data and Sample

2.1     Student Attendance and Achievement

Student-level data on attendance and achievement in the 2003-2010 school years come from the

Massachusetts Department of Elementary and Secondary Education (DESE). Students and schools

are assigned unique identifiers allowing them to be linked across years and across data sets within

years. DESE’s Student Information Management System (SIMS) contains basic demographic in-

formation on each student, including gender, race/ethnicity, free or reduced price lunch receipt,

special education status and current grade. The end-of-year SIMS files include information on

each school a student was enrolled in at any point in the year, the number of days the student was

enrolled in each school, and the number of days the student actually attended each school. For

students enrolled in multiple schools in a given year, I generate the total across all such schools of

days enrolled and days in attendance. The modal value of days enrolled is 180, given that most

students attend only one school during a given year and that most school years are 180 days long.

      I generate for each student the total number of absences in the past academic year, defined

as the difference between total days enrolled and total days attended. That these variables are

measured annually at the school year’s end creates two small disadvantages. First, I have no

information on specific dates of student absences, so that I can not link daily weather patterns

to daily attendance. As a result, all analysis here is done at the annual level. Second, because

standardized tests are given before the end of the school year, this measure of absences includes

post-test absences and thus somewhat overstates the number of absences that could affect test

performance. I exclude the 1% of student-year observations with more than 60 absences both

to diminish the influence of outliers and because such students are functionally barely enrolled,

missing at least one of every three school days. This choice has little effect on the estimated impacts

of absences and school closures discussed below. Limiting the sample to students with 30 or fewer

absences leaves those estimates nearly unchanged, as does removing this threshold entirely.

      Data from DESE’s Massachusetts Comprehensive Assessment System (MCAS) contain test

scores in mathematics and English language arts (ELA). These exams are given annually to Mas-



                                                  4
sachusetts students in grades 3-8 and 10.4 For ease of comparison, I standardize raw test scores

by subject, school year and grade. I include in the main analysis only students with valid math

or ELA scores in a given year. Most of the tests are administered during a two-week window

in late March to early April, in the case of ELA, or in mid to late May, in the case of math. The

state does grant waivers to schools or districts allowing them to postpone testing due to extreme

circumstances, such as flooding or other potential hazards, but such exceptions are extremely rare.

       Schools may choose testing dates within this window, so that endogenous re-scheduling of test

dates in reaction to winter weather could confound interpretation of my estimates.5 Such endoge-

nous re-scheduling is, however, unlikely to be important, for three reasons. First, for planning

purposes, most schools announce their testing schedules at the beginning of the year, before any

winter weather has occurred. Second, changing such schedules is quite costly for schools given

other scheduling constraints, and extensive web searches reveal no evidence of schools changing

previously announced testing dates. Third, a subset of tests are scheduled by the state on fixed

days and not in windows. These include 10th grade math and ELA tests, as well as ELA composi-

tion tests given in grades 4, 7 and 10. I show below that estimates based on those tests look quite

similar to estimates based on the broader set of tests.


2.2      Closures and Weather

School closures, almost always due to bad weather, are decided by each school district’s super-

intendent.6 Superintendents generally consult the weather forecast, neighboring superintendents

and other local government officials to determine when impending weather sufficiently threatens

the ability of students and teachers to safely travel to school. Superintendents are generally reluc-

tant to call snow days for two reasons. First, parents often become frustrated by the need to find

backup childcare arrangements that may interfere with their own work lives. Second, and more

important for this study, Massachusetts law requires school years to contain 180 days of instruc-
   4
      In 2003-05, not all tests were taken by all students in grades 3-8. ELA tests were taken only by students in grades
3, 4 and 7, while math tests were taken only by students in grades 4, 6 and 8. From 2006 onward, both subjects were
taken by all students in grades 3-8.
    5
      DESE does not track test administration dates by school, preventing a more rigorous estimate of the extent of
endogenous re-scheduling.
    6
      Other rare causes of school closures include broken heating systems, bomb threats or shootings, and flooding.


                                                           5
tion. As a result, any closures must be made up later in the year. In practice, the overwhelming

majority of such days are tacked onto the end of the school year in June, as districts generally set

aside an additional week in June for just such a scenario.7 This means that, in practice, school

closures result in less instructional time prior to the MCAS tests.

       DESE does not collect data on school closures. I therefore e-mailed representatives of all of

the roughly 350 school districts in Massachusetts, requesting that they send historical data on the

number of closures each year dating back to 2003. I then followed up the non-responsive districts

with phone calls, focusing efforts on the largest districts in the state. Ultimately, the districts that

reported their number of closures in each year from 2003-2010 represented slightly more than half

of the students in the state. Students from districts that reported part or none of this history are

excluded from the subsequent analysis. I show below that the resulting sample looks very similar

to the state as a whole.

       Weather data come from the National Oceanic and Atmospheric Administration’s (NOAA)

Climate Data Online.8 NOAA reports historical weather data measured daily by sensors scattered

across the state of Massachusetts. Data collected include daily snowfall, rainfall, and minimum

and maximum temperatures. To ensure accurate snowfall estimates, I keep data from the 33 sen-

sors missing fewer than 5% of the daily observations between November and April of 2003-2010.

Figure A.1 shows a map of these sensors, which are concentrated in areas of higher population

density. I use the National Center for Education Statistics’ Common Core of Data to assign each

Massachusetts school a latitude and longitude. I then assign each school to its closest sensor and

construct annual measures of snowfall for each school and its students. For example, I can gener-

ate for each school the number of school days in a given year with four or more inches of snow. To

more accurately measure weather relevant to the school closure decision, I generate such measures

excluding clear non-school days, such as weekends and common holidays. I do not, however, ex-

clude non-school days that vary by school district, such as the February vacation week.9
   7
    Districts can be excused from the 180 day requirement only when the number of school closures exceeds five, at
which point they apply to the state for a waiver. Such waivers are quite rare.
  8
    The data can be accessed at http://www.ncdc.noaa.gov/cdo-web/.
  9
    Finding a complete history of district calendars from this time period proved impossible.




                                                        6
2.3      Descriptive Statistics

To summarize, the main analysis sample is defined as students in Massachusetts public schools

from 2003-2010, in grades 3-8 and 10, with valid math or ELA test scores, with 60 or fewer mea-

sured absences and from districts who reported their complete annual history of school closures.

Table 1 reports descriptive statistics. Column 1 includes all Massachusetts students, column 2

includes all students with valid MCAS scores, and column 3 includes only students in districts

that reported the full history of school closures, the analysis sample. As column 1 shows, the av-

erage Massachusetts student misses 8.7 days of school a year. Column 2 shows that the average

MCAS-taker misses a 8.0 days of school a year, somewhat less than column 1 because 9th, 11th

and 12th graders have high absence rates but do not take the MCAS. Comparing columns 2 and 3

shows that the analysis sample appears largely representative of the MCAS-taking population. It

is, however, slightly poorer, likely because of the over-representation of larger, urban districts that

I was more likely to follow up with phone calls.

       Although school closures garner more attention, they constitute less than one-fourth of missed

instructional time, as seen in column 3. Students absences are nearly four times as prevalent but

are less dramatic events than closures. I also construct for each student the average number of

peers’ absences in the same grade and school.10 The average student’s peers are absent 8.1 days

a year. The average student experiences 2.3 school days a year on which four or more inches

of snow falls, with only 0.3 days of 10 or more inches of snow. A little over one-third of the

students are poor, as measured by receipt of free or reduced price lunch. Over two-thirds of the

students are white, while 11% are black, 14% are Hispanic and 6% are Asian. The average test

score in the analysis sample is slightly below the statewide mean, again because of the slight over-

representation of low-scoring urban school districts.

       Columns 4 and 5 of Table 1 separate the sample by poverty status. Poor students miss an

average of 12.6 days of school a year, nearly four days more than the 9.0 missed by non-poor

students. Most of this difference is driven by absences, with poor students absent 10.1 days and

non-poor students absent 6.9 days a year. Figure 1 shows that this gap is relatively constant from
  10
       I used grade and school to define peers because classroom identifiers are not available in this data.



                                                              7
first grade through fifth grade but widens in sixth grade and throughout middle and high school,

particularly in ninth grade. Figure 2 emphasizes that the right tail of the absence distribution is

substantially fatter for poor students, more than 6% of whom are absent between 30 and 60 days

a year. Fewer than 2% of non-poor students are so frequently absent. These differences would

be even more pronounced if I had not excluded students with more than 60 absences from the

analysis. Poor students are also exposed to peers who, on average, are absent for 1.6 days more a

year than the peers of non-poor students. There is little difference in the weather to which poor

and non-poor students are exposed.

         Columns 5-8 reveal striking differences in absence rates by race/ethnicity. White students miss

9.8 days of school a year, 7.7 of which are due to absences. Asian students, conversely, miss only

7.3 days because they are absent only 5.0 days a year, less than two-thirds the absence rate of white

students. Black and Hispanic students respectively miss 11.3 and 13.0 days of school a year, 9.1

and 10.3 of which are due to absences. Figure 3 shows that these racial gaps are relatively constant

in early grades but widen in middle school and then very dramatically at the start of high school.

Even more striking is the distribution of absences by race shown in Figure 4, which reveals that

17 percent of Asian students have perfect attendance, compared to six percent of other students.

Perhaps surprisingly, there are no substantial differences by gender in absence rates.11



3        Estimating the Effects of Disruptions to Instructional Time

3.1        Fixed Effects Estimates

The major challenge of estimating the effect of disruptions to instructional time on student achieve-

ment is that students and schools with high absence and closure rates differ in both observable and

unobservable ways from those with low absence and closure rates. Some dimensions along which

absence rates vary, such as socioeconomic status, are at least crudely observable in the data. Other

dimensions are not. The data do not contain, for example, any measure of students’ physical or

mental health problems, which likely increase absence rates and decrease student achievement.
    11
   See Figure A.2 for mean absence rates by gender and grade and Figure A.3 for the full distribution of absences by
gender.


                                                         8
Ordinary least squares regressions measuring the association between missed instructional time

and student achievement are thus likely to yield overestimates because of such unobserved fac-

tors.

   As a first attempt at eliminating some of these sources of omitted variable bias, I run two types

of fixed effects regression models. In the first, I collapse the data into school-grade-year cells, then

run the following specifications using school-by-grade fixed effects:


        Scoresgt = β0 +β1 DaysM issedsgt                       +γXsgt + µsg + λt + sgt              (1)

        Scoresgt = β0 +β1 Absencessgt + β2 Closuressgt         +γXsgt + µsg + λt + sgt              (2)


The outcome of interest, Score, represents the mean standardized math or ELA score for a school s

and grade g in year t. I measure lost instructional time as the total number of days missed due to

absences and school closures (DaysMissed) averaged by school-grade-year, so that the coefficient

of interest (β1 ) measures the impact of an entire school-grade missing an additional day. I also

explore the separate impact of each of those types of missed days.

   These regressions include school-grade fixed effects so that identification is driven by within

school-grade changes over time in the average amount of days missed. In other words, a given

school and grade is compared to itself across years when it has higher and lower rates of missed

school days. These fixed effects therefore eliminate sources of omitted variable bias generated by

across school-grade differences that are constant over time and may be associated with different

attendance rates, such as socioeconomic or racial composition, and different school closure rates,

such as geography. Because the composition of the student body is not entirely constant over time

in a given school-grade, I also include a vector of controls (Xsgt ) for school-grade-year averaged

measures of gender, race, poverty, special education and grade size. Finally, year fixed effects

control for annual shocks that affect students statewide.

   The longitudinal nature of the data also allows me to run such regression of the following form




                                                   9
using student fixed effects:


  Scoreigt = β0 +β1 DaysM issedigt                                               +γXigt + µi + λgt + igt   (3)

  Scoreigt = β0 +β1 Absencesigt + β2 Closuresigt + β3 P eerAbsigt                +γXigt + µi + λgt + igt   (4)


Here the outcome of interest, Score, represents the standardized test score for an individual student

i in grade g and year t, while lost instructional time is the total number of days missed by an

individual student in a given year.

       The inclusion of student fixed effects means that identification is driven by within-student

changes over time in the number of days missed. A given student is therefore compared to him-

self across years when he has higher and lower numbers of missed school days. These fixed effects

therefore eliminate sources of omitted variable bias generated by across student differences that

are constant over time and may be associated with different attendance rates, such as socioeco-

nomic status, race or engagement with school. Because some of these factors may actually vary

over time for a given student, I also include a vector of controls (Xigt ) for students’ poverty status,

special education status, and grade size. Finally, grade-by-year fixed effects control for annual

grade-specific shocks that affect students statewide. I also include a measure (P eerAbs) of the

average number of absences recorded that year for each student’s peers, defined as those in his

same school and grade.12 These student fixed effects regressions thus parallel the school-grade

fixed effects regressions, with the absences of an individual student and his peers adding up to

the total number of absences in his school and grade.

       Table 2 shows the results of these fixed effects regressions. Panel A estimates the impact of total

days missed due to school closures and absences, while panel B estimates separately the impacts

of closures, own absences and peer absences. The school-grade fixed effects results in column

1 of panel A imply that one additional day missed by a given school-grade is associated with a

0.010 standard deviation decrease in math scores. The student fixed effects results in column 2

are similar, implying that one additional day missed by a given student is associated with a 0.008

standard deviation decrease in math scores. In columns 3 and 4, the relationship between lost in-
  12
       The data lack more detailed information on which classrooms students are assigned to.


                                                           10
structional time and ELA achievement is quite similar, though slightly smaller in the school-grade

fixed effects model, with each additional day missed associated with a 0.008 standard deviation

decrease.

       These estimates mask, however, substantial variation between the impact of school closures

and the impact of student absences. In column 1 of panel B, which separates those types of missed

days, the estimates imply that a one-day increase in a given school-grade’s overall absence rate

is associated with a 0.020 standard deviation decrease in math scores, whereas school closures

show no relationship with achievement. The student fixed effects regression in column 2 shows

similarly little relation between closures and achievement. That regression also suggests that the

impact of school-grade level absence rates observed in column 1 is actually the combination of

two separate channels. A student’s own additional absence has a 0.008 standard deviation impact

on his math score and an overall increase of one additional absence among his peers has a separate

0.008 standard deviation impact. Results for ELA scores are again similar, though slightly smaller

in the school-grade fixed effects model.

       In Table 3, I explore heterogeneous impacts in the school-grade fixed effects estimates.13 In

columns 1 and 2, I test heterogeneity by income by dividing schools into those with poverty rates

below and above 50%, as measured by the fraction of students over this entire time period who

receive free or reduced price lunch. The estimates for both math and ELA suggest that the relation-

ship between absence rates and achievement is large and statistically significant for both types of

schools, but is somewhat stronger for poor schools than for non-poor schools. There is also statis-

tically significant evidence of a small relationship between school closures and math achievement

for poor schools, though none for non-poor schools and none in ELA for either school type. There

is no evidence of heterogeneity in the estimated impact of absences by student age, as seen in

columns 3-5, which divide school-grades into grades 3-5, 6-8 and 10. There is small but statisti-

cally significant evidence that closures affect math achievement in younger grades. Both columns

5 and 6, which use as outcomes tests given on fixed dates and not in testing windows, show little

relationship between closures and achievement. This suggests that the lack of such relationship in
  13
   I focus here on heterogeneity by school-grade rather than student characteristics because my subsequent instru-
mental variables estimates exploit variation at the level of the school and not the individual.


                                                       11
the other regressions is not due to endogenous re-scheduling within the testing window.

      Overall, these results highlight three important patterns. First, variation in school closures

across time are unrelated to variations in overall student achievement, suggesting that instruc-

tional time lost to such school-level disruptions does not impact student learning. The exceptions

to this are low income and primary schools, where there is evidence of a small impact of clo-

sures on math achievement. Second, changes in school absence rates are strongly associated with

changes in student achievement, suggesting that instructional time lost to such student-level dis-

ruptions does impact student learning. Third, an individual student’s achievement appears to

be separately related to both his own absences and those of his peers, suggesting that student

learning is affected both by one’s own lost instructional time and the time lost by one’s peers.

      All of these patterns are suggestive but not conclusive, given that these fixed effects regressions

do not eliminate all potential sources of omitted variable bias. Increases in school-grade level

absence rates may, for example, be driven by changes in the composition of the student body,

so that absences are serving as a proxy for families less invested in their children’s education.

Increases in individual students’ absence rates may be driven by underlying health or family

problems that are the true cause of observed achievement drops. Increases in school closures

may be driven partly by newly hired school district superintendents who change other practices

as well. I now turn to an instrumental variables approach that, I argue, can purge these estimates

of any such remaining bias.


3.2     Instrumental Variables Estimates

Prior research has convincingly argued that temporal and geographic variation in snowfall may

provide a plausibly exogenous source of variation in instructional time because school closures

are driven almost entirely by concerns about weather (Marcotte, 2007; Marcotte and Hemelt, 2008;

Hansen, 2013). Use of snowfall as an instrument for school closures is, however, complicated by

facts this paper is the first to document. To identify the impact of weather on instructional time, I




                                                    12
first run school-grade fixed effects regressions of the form


                         Ysgt = α0 + α1 SnowyDayssgt + γXsgt + µsg + λt + sgt                                   (5)


where SnowyDays is the number of school days with four or more inches of snow for a given

school in a given year, and Y represents various measures of lost instructional time. I choose the

four inch threshold purely for expositional purposes, as will become clearer below. Because of the

school-grade fixed effects, the impact of snowy days on lost instructional time and achievement

is identified off of within-school-grade variation in snowfall over time. The marginal snowy day

here is an excess snowy day, in that it is unusual both relative to the school’s own mean over time

and relative to the statewide mean that year.

       Massachusetts winters provide ample identifying variation for this empirical strategy. Figure

5 shows variation over time in the mean number of school days with four or more inches of snow

experience by students in the analysis sample. This varies from a low of less than one day in 2007

to a high of nearly five days in 2005, and is strongly correlated with the number of school closures

in a given year. I include absences in the figure simply to emphasize how much more prevalent

they are than closures. Figure 6 shows that snowfall varies in Massachusetts not only over time

but also by geography, with the Berkshire Mountains in the west receiving much more snow than

areas such as Cape Cod in the east.

       Estimates from equation 5 are shown in Table 4.14 Panel A shows how strongly snowfall is

related to school closures, with column 1 suggesting that each excess day with four or more inches

of snow leads to a highly statistically significant 0.09 additional school closures. The remaining

columns show that these estimates vary very little by student characteristics, an unsurprising

result given that superintendents often feel obligated to close schools for safety reasons regardless

of the composition of their student body.

       Closures are, however, not the only source of instructional time lost due to weather. Panel B

shows that student attendance is also affected by snowfall, with each excess snowy day inducing a
  14
     Here the sample is defined as students with valid math scores. Using students with valid ELA scores makes little
difference to these first stage estimates.



                                                         13
highly statistically significant 0.08 additional absences. Unlike the closure estimates in panel A, the

absence estimates do vary substantially by student characteristics. The impact of snowfall on poor

students’ absences is more than twice the size of the impact on non-poor students’ absences. A

similar pattern holds when comparing white and Asian students to black and Hispanic students.

There is little difference by gender. The fact that disadvantaged students’ attendance rates are

more strongly affected by weather may be due to their dependence on forms of transportation

more likely to fail during snowstorms, such as public transit or low quality cars. Poor parents

and children may also place less value on school attendance so that a given amount of snow

discourages a higher fraction from attending school, relative to their higher income peers.

   Snowy days thus affect instructional time through two channels. Some snowy days result in

school closures, in which case all students miss school. On other, presumably less, snowy days,

schools remain open but some subset of students remain home perhaps because of transportation

or health problems. The fact that snowfall affects both closures and absences violates the exclusion

restriction required to estimate the impact of closures alone on achievement. To see how this may

have confounded the estimates in previous papers, Table 5 runs the specification in equation 5 us-

ing different measures of snowfall, as well as test scores as outcomes. In the top row of panel A, the

first two columns replicate the prior results that snowy days induce both closures and absences.

As shown in column 3, each excess snowy day thus leads to 0.17 days missed of school, roughly

half of which are due to closures and half of which are due to absences. Column 4 shows that each

excess snowy day reduces math scores by a marginally significant 0.004 standard deviations. If

this measure of snowfall is used an instrument for total days missed, as in column 5, the resulting

estimate suggests that each day missed due to bad weather reduces math scores by a marginally

significant 0.023 standard deviations. Because the instrument fails the exclusion restriction, that

simple measure of snowfall can not identify whether the negative impacts on math achievement

are driven by school closures, by student absences, or by both forms of lost instructional time.

   The bottom half of panel A further highlights the challenge of using snowfall as an instrument

in this setting. Defining the instrument with a more extreme measure of snowfall, namely the

number of days with 10 or more inches of snow, substantially changes the instrumental variables



                                                  14
estimates of the impact of lost instructional time. Each additional extremely snowy day leads to

a huge rise in the number of school closures but no additional absences, likely because nearly all

schools shut down in such weather conditions and no students can therefore be absent.15 Columns

4 and 5 reveal, however, that, unlike moderately snowy days, extremely snowy days have no

relationship with student achievement. In panel B, first stage results using ELA scores look quite

similar to those in panel A, though neither form of the instrument suggests a relationship between

weather and ELA scores.

       Prior research using weather as an instrument for lost instructional time has thus failed to note

two important facts. First, bad weather affects both school closures and student absences, so that

no single instrument can successfully distinguish the effects of those two types of lost instructional

time. The results documented here suggest that prior work may have mistakenly attributed the

impact of absences to the impact of closures. Second, and relatedly, estimates of the impact of

weather on student achievement can be quite sensitive to the chosen definition of the instrument.

I observe non-linearities in the impact of weather, with moderately snowy days appearing to have

much more of an impact on student achievement than extremely snowy days. This non-linearity

turns out to be quite helpful for dealing with the exclusion restriction violation documented here.

       To exploit this non-linearity, I re-estimate the school-grade fixed effects model from equation

2, this time recognizing that both school-grade absences rates and closures are potentially endoge-

nous.16 I therefore instrument both of those endogenous variables with the same vector of snow-

fall measures. Because two endogenous regressors require at least two instruments, the simplest

form of the first stages I use have the following specifications:


       Absencessgt = α0 + α1 M oderateSnowsgt + α2 ExtremeSnowsgt + γXsgt + µsg + λt + sgt                       (6)

        Closuressgt = δ0 + δ1 M oderateSnowsgt + δ2 ExtremeSnowsgt + γXsgt + µsg + λt + sgt                      (7)
  15
      That each extremely snowy day does not yield a 100% closure rate is likely due to measurement error. I do not,
for example, have each district’s February vacation schedule and therefore may be including snowstorms in this total
that did not actually fall on school days. Also, because most schools would also shut down on days with nine inches of
snow, the counterfactual here is not zero closures.
   16
      I use the school-grade fixed effects model because the exogenous weather shocks occur at the school level. The
student fixed effects model would be unable to separately identify the impact of own absences and peer absences
because both would be similarly affected by the weather.



                                                         15
Here, again purely for expositional purposes, I define M oderateSnow as the number of school

days with 4-10 inches of snow and ExtremeSnow as the number of school days with 10 or more

inches of snow.

       The first two columns of table 6 show the estimates from those first stages. In column 1 of

panel A, extremely snowy days are strongly related to school closures whereas moderately snowy

days are not, conditional on the number of extremely snowy days. In column 2, conversely, mod-

erately snowy days are strongly related to student absences whereas extremely snowy days are

not.17 This nonlinear impact of snowfall therefore allows me to separately identify the impact of

school closures and student absences. The reduced form estimates in column 3 imply that each

additional moderately snowy day lowers math scores by a statistically significant 0.004 standard

deviations, while extremely snowy days have no detectable impact on achievement. Given that

moderate snowfall affects absences but not closures, this suggests that absences and not closures

are responsible for the achievement impacts of bad weather.

       The instrumental variables estimates in column 4, in which absences and closures are instru-

mented using the first stages shown in columns 1 and 2, confirm this. Each additional absence

induced by snowfall decreases math achievement by a large and statistically significant 0.05 stan-

dard deviations. The point estimate on the effect of school closures is almost identical to zero and

the standard error allows me to rule out negative effects greater than 0.01 standard deviations per

closure day. To show that these estimates are not sensitive to this particular choice of two instru-

ments, column 5 replicates column 4 but uses a vector of ten instruments measuring the number

of school days with 1-2 inches of snow, 2-3 inches of snow, and so on through 10+ inches of snow.

This specification has little effect on the estimates, with absences now estimated to decrease math

scores by a more precisely estimated 0.05 standard deviations and closures still showing no de-

tectable impact. The parallel estimates in panel B also rule out impacts of closures on ELA scores

larger than 0.01 standard deviations. Absences decrease ELA scores by an imprecisely estimated

0.01 standard deviations.

       Table 7, like Table 3, explores heterogeneity in the impacts of lost instructional time, this time
  17
   The magnitude of this coefficient on moderately snowy days (0.08) implies that, for a classroom of 25 students, each
additional moderately snowy day would result in about two students being absent.


                                                          16
generating estimates through the instrumental variables specification that uses the vector of ten

snowfall instruments. Dividing the sample reduces the precision of the resulting estimates but a

few patterns can nonetheless be discerned. First, estimated impacts of absences on math achieve-

ment are large and negative for both poor and non-poor schools and for younger and older grades.

Second, the estimated impacts of absences on ELA achievement, though mostly negative, are gen-

erally indistinguishable from zero. Third, closures generally have little effect on achievement

except in poor schools, where each closure is associated with a 0.01-0.02 decrease in math and

ELA scores. Finally, both columns 5 and 6, which use as outcomes tests given on fixed dates and

not in testing windows, show no relationship between closures and achievement. Consistent with

the non-instrumented estimates, this again suggests endogenous re-scheduling within the testing

window can not explain the non-impact of closures.



4   Discussion

The evidence presented here shows that the impact of lost instructional time depends on the par-

ticular form of the time lost. Student absences are strongly related to achievement, particularly in

math, in both fixed effects and instrumental variables specifications. School closures show little

relationship to achievement. The contrast between the effects of absences and of closures is con-

sistent with a model of instruction in which coordination of students is the central challenge for

teachers.

    Such a model can be thought of as a re-interpretation of the optimal class size model in Lazear

(2001). In that model, student achievement occurs only at times when the classroom is not being

disrupted by a single student. Achievement is thus proportional to pn , where p is the probability

of any given student behaving well and n is the class size. Though the discussion in that paper

focuses on behavioral disruptions, it notes that p more generally refers to the proportion of time

that a given student is not interfering with the public aspects of knowledge production in the

classroom.

    Absences are one such form of disruption. An absent student presents a teacher with one of

two choices upon his return to the classroom. The teacher may take time out of the classroom

                                                17
schedule to catch the absent student up on missed material, in which case his classmates lose

instructional time from the teacher. Or the teacher may not set aside such time, in which case the

student himself has lost instructional time and may disrupt his classmates’ future lessons because

he has fallen behind. The fixed effects estimates are consistent with this model of disruption,

suggesting both a direct effect of absences on a student’s own achievement and a spillover effect

of peer absences.

       School closures present no such challenge of coordinating students to be on the same page.

When students return to school after a snow day, they have all missed exactly the same lesson.

Teachers can thus compensate by pushing all of the their lesson plans back a day for the rest of the

school year.18 This will have no effect on student achievement as measured by standardized tests

so long as the teacher’s planned schedule had included at least some instructional time devoted

to subjects not on the tests. Such lessons on non-tested material can be compressed, eliminated

or postponed until after the test, so that school closures do not effectively reduce the amount of

instructional time relevant to the available measures of student achievement.

       Two further pieces of evidence presented here are consistent with this coordination challenge

explaining why absences are so much more detrimental than closures to student achievement.

First, in both the fixed effects models and particularly in the instrumental variables models, ab-

sences have a substantially larger impact on math achievement than on ELA achievement. More

so than ELA, math is a subject where understanding the current topic depends on having under-

stood prior topics. As a result, absences in math thus have longer-run effects in which students

lose mastery of both the material for which they were absent and the subsequent material that de-

pends on such knowledge. Teachers may therefore feel more obligated during math instructional

time to catch up absent students, thus depriving the rest of the class of instructional time. Missing

an ELA lesson, conversely, may not have as deep an impact on a student’s ability to learn from

subsequent lessons.

       Second, the magnitude of the instrumental variables estimate of the impact of absences on

math achievement is two and half times larger than that of the fixed effects estimate. One potential
  18
   In informal conversations with me, numerous current and former teachers have concurred that snow days are
much simpler to deal with than student absences, for precisely the reasons highlighted here.


                                                    18
explanation for this is that snowfall-induced changes in absence rates involve unusually high

numbers of students. If on a typical day two students are absent in a given classroom, that number

may jump to four on a moderately snowy day. The congestion effects model in Lazear (2001)

would imply that the disruptive effect of absences increases more than linearly in the number of

absent students. This would explain why absences induced by snowfall hurt student achievement

more than the more typical absences driving variation in the fixed effects models.

   There are other reasons instrumental variables estimates of absences may exceed fixed effects

estimates in this context. Fixed effects estimates may be biased slightly downward by the fact

that the absence measure covers the entire year and thus includes post-exam absences. It may

thus overstate annual fluctuations in pre-exam absences by about 10% in math and 30% in ELA,

if absences are uniformly distributed throughout the school year. The instrumental variables esti-

mates do not suffer from this problem because all snowfall and thus all snowfall-induced absences

contributing to identification occur pre-exam. The fact the ELA-relevant absences are more mis-

measured than math-relevant absences may partly explain why the non-instrumented estimates

of absences are larger in math than in ELA.

   Alternatively, because snowfall increases absence rates more for disadvantaged students, the

marginal students whose absences are estimated by the instrumental variables specification are

disproportionately disadvantaged. Instrumental variables estimates should therefore exceed fixed

effects estimates if such students’ learning is more disrupted by absences than the average absent

student’s learning, perhaps because such families are less able to compensate for their children’s

lost instructional time.

   Finally, instrumental variables estimates would overstate the impact of student absences if

moderate snowfall affects other channels such as student tardiness or teacher absences, neither of

which are observable in my data. That tardiness is unobservable implies that my absence measure

may be understating the true amount of instructional time lost. Unobservable teacher absences

may cause me to mistakenly attribute the impact of teacher absences to student absences. Though

teacher absences clearly harm student achievement (Clotfelter et al., 2009), I argue that this is not

a major concern both because weather often does not strongly affect teacher absences (Herrmann



                                                 19
and Rockoff, 2012) and because when it does the resulting impact on student achievement is too

small to explain my estimated effects (Miller et al., 2008).19



5        Conclusion

This paper provides some of the clearest evidence to date on the substantial role that school at-

tendance plays in student achievement, a role that has been understudied in the literature. Fixed

effects and instrumental variables estimates are consistent with a Lazear-type congestion model

of learning, where congestion comes not from behavioral disruptions but from student absences.

The results highlight the fact that increasing instructional time does not necessarily require length-

ening the school day or year as some gains may be made by increasing the fraction of already

scheduled time that students are in school.

         The magnitude of the estimated impact of absences on math achievement is a substantial 0.05

standard deviations. Relative to non-poor students, poor students are absent three more days

per year and have peers who are absent one and a half more days per year. Assuming, as the

fixed effects estimates suggest, that own and peer absences have similar effects, then exposure to

four additional absences every year would reduce math scores by 0.20 standard deviations. This

represent roughly one-fourth the math achievement gap between poor and non-poor students.

The ELA estimates, though imprecise, suggest that absences explain roughly one-twentieth of the

reading achievement gap by income.

         That school closures have little impact on student achievement might imply that lost instruc-

tional time does not matter, though the bulk of the empirical evidence suggests otherwise. A more

likely explanation is that schools and teachers are well-prepared to deal with the coordinated dis-

ruptions of such snow days, perhaps by postponing or canceling lesson plans on untested topics.

That absences have such a substantial effect suggests, however, that schools and teachers are not

well-prepared with the less dramatic but much more frequent disruptions caused by poor student

attendance. Schools and teacher may be under-investing in strategies to cope with such disrup-
    19
    The central estimate presented in Miller et al. (2008) is that 10 days of weather-induced teacher absences reduces
student achievement by 0.033 standard deviations. My central estimate of a 0.055 standard deviation impact of a single
student absence would thus be equivalent to nearly 17 teacher absences.


                                                         20
tions. It is conceivable that the increasing use of self-paced learning technologies may reduce the

impact of absences by shifting the classroom model to one in which not all students must learn

the same lesson at the same time.

       One limitation of this research is that the marginal absence providing identification is one in-

duced by bad weather. Weather is likely not the main driver of student absences, as illness and, for

older students, engagement with school are probably much more common determinants of atten-

dance. Future research should focus on identifying the impacts of more typical absences, though

finding exogenous sources of variation in such circumstances may be hard. Currie et al. (2009)

provide evidence, for example, that ambient pollution that aggravates asthma can increase absen-

teeism, though they do not connect such absences to student achievement results. A number of

school districts are beginning to experiment with interventions to directly address chronic absen-

teeism, known as truancy.20 It remains to be seen whether such interventions reduce absenteeism

and, if so, whether such improved attendance translates into better student outcomes, either for

the truants themselves or their peers.




  20
   For a description of New York City’s recent efforts, see http://www.nyc.gov/html/truancy/html/home/
home.shtml.


                                                    21
References
Abt Associates Inc. (2012). Evaluation of the Massachusetts Expanded Learning Time initiative
 (ELT): Year five final report 2010-11. Report, Abt Associates Inc.

Alexander, K. L., D. R. Entwisle, and L. S. Olson (2001). Schools, achievement, and inequality: A
  seasonal perspective. Educational Evaluation and Policy Analysis 23(2), 171–191.

Angrist, J. D., P. A. Pathak, and C. R. Walters (2013). Explaining charter school effectiveness.
 American Economic Journal: Applied Economics 5(4), 1–27.

Carlsson, M., G. B. Dahl, and D.-O. Rooth (2012). The effect of schooling on cognitive skills.
  Working Paper 18484, National Bureau of Economic Research.

Clotfelter, C. T., H. F. Ladd, and J. L. Vigdor (2009). Are teacher absences worth worrying about in
  the United States? Education Finance and Policy 4(2), 115–149.

Currie, J., E. A. Hanushek, E. M. Kahn, M. Neidell, and S. G. Rivkin (2009). Does pollution increase
 school absences? The Review of Economics and Statistics 91(4), 682–694.

Dobbie, W. and R. G. Fryer (2011). Getting beneath the veil of effective schools: Evidence from
 New York City. Working Paper 17632, National Bureau of Economic Research.

Fitzpatrick, M. D., D. Grissmer, and S. Hastedt (2011). What a difference a day makes: Estimating
  daily learning gains during kindergarten and first grade using a natural experiment. Economics
  of Education Review 30(2), 269–279.

Fryer, R. G. and S. D. Levitt (2004). Understanding the black-white test score gap in the first two
  years of school. Review of Economics and Statistics 86(2), 447–464.

Gottfried, M. A. (2009). Excused versus unexcused: How student absences in elementary school
 affect academic achievement. Educational Evaluation and Policy Analysis 31(4), 392–415.

Gottfried, M. A. (2010). Evaluating the relationship between student attendance and achievement
 in urban elementary and middle schools: An instrumental variables approach. American Educa-
 tional Research Journal 47(2), 434–465.

Hansen, B. (2013). School year length and student performance: Quasi-experimental evidence.
 Available at SSRN.

Herrmann, M. A. and J. E. Rockoff (2012). Worker absence and productivity: Evidence from teach-
 ing. Journal of Labor Economics 30(4), 749–782.

Hoxby, C. M. and S. Murarka (2009). Charter schools in New York City: Who enrolls and how
 they affect their students’ achievement. Working Paper 14852, National Bureau of Economic
 Research.

Lavy, V. (2010). Do differences in schools instruction time explain international achievement gaps?
  Evidence from developed and developing countries. Working Paper 16227, National Bureau of
  Economic Research.


                                                22
Lavy, V. (2012). Expanding school resources and increasing time on task: Effects of a policy exper-
  iment in Israel on student academic achievement and behavior. Working Paper 18369, National
  Bureau of Economic Research.

Lazear, E. P. (2001). Educational production. The Quarterly Journal of Economics 116(3), 777–803.

Loken, K. V., M. Mogstad, and M. Wiswall (2012). What linear estimators miss: The effects of
  family income on child outcomes. American Economic Journal: Applied Economics 4(2), 1–35.

Marcotte, D. E. (2007). Schooling and test scores: A mother-natural experiment. Economics of
 Education Review 26(5), 629–640.

Marcotte, D. E. and S. W. Hemelt (2008). Unscheduled school closings and student performance.
 Education Finance and Policy 3(3), 316–338.

Miller, R. T., R. J. Murnane, and J. B. Willett (2008). Do teacher absences impact student achieve-
 ment? Longitudinal evidence from one urban school district. Educational Evaluation and Policy
 Analysis 30(2), 181–200.

Pischke, J.-S. (2007). The impact of length of the school year on student performance and earnings:
  Evidence from the German short school years. The Economic Journal 117(523), 1216–1242.

Rivkin, S. G. and J. C. Schiman (2013). Instruction time, classroom quality, and academic achieve-
  ment. Working Paper 19464, National Bureau of Economic Research.

Snyder, T. D. and S. A. Dillow (2014). Digest of education statistics 2013. National Center for Educa-
  tion Statistics.




                                                 23
                    Figure 1: Mean Absences by Grade and Poverty Status




                   Poor
   14




                   Non-poor
   12
   10
   8
   6
   4
   2
   0




        1      2      3       4      5      6     7        8      9       10    11     12
                                             Grade

Notes: Mean numbers of days absent are shown by grade and poverty status, as determined
by federally subsidized lunch receipt. The sample consists of all Massachusetts public school
students from the 2003-2010 school years with no more than 60 absences. Data come from the
Massachusetts Department of Elementary and Secondary Education’s Student Information Man-
agement System.




                                             24
                              Figure 2: Absence Distribution by Poverty Status




                                                (A) Non-poor
                 .08.06
           Fraction
           .04   .02
                 0




                          0                   10                  20             30+
                                                   Days absent


                                                   (B) Poor
                 .08.06
           Fraction
           .04   .02
                 0




                          0                   10                  20             30+
                                                   Days absent


Notes: The distributions of number of days absent are shown by poverty status, as determined
by federally subsidized lunch receipt. The sample consists of all Massachusetts public school
students from the 2003-2010 school years with no more than 60 absences. Data come from the
Massachusetts Department of Elementary and Secondary Education’s Student Information Man-
agement System.


                                                    25
                          Figure 3: Mean Absences by Grade and Race




                   Hispanic
                   Black
   14




                   White
                   Asian
   12
   10
   8
   6
   4
   2
   0




        1      2      3       4      5      6     7        8       9     10      11     12
                                             Grade

Notes: Mean numbers of days absent are shown by grade and race, as determined by federally
subsidized lunch receipt. The sample consists of all Massachusetts public school students from
the 2003-2010 school years with no more than 60 absences. Data come from the Massachusetts
Department of Elementary and Secondary Education’s Student Information Management System.




                                             26
                             Figure 4: Absence Distribution by Race



                      (A) White                                          (B) Asian
        .15




                                                           .15
      Fraction




                                                         Fraction
            .1




                                                               .1
   .05




                                                      .05
        0




                                                           0
                 0   10          20        30+                      0   10          20   30+
                      Days absent                                        Days absent


                      (C) Black                                         (D) Hispanic
        .15




                                                           .15
      Fraction




                                                         Fraction
            .1




                                                               .1
   .05




                                                      .05
        0




                                                           0




                 0   10          20        30+                      0   10          20   30+
                      Days absent                                        Days absent


Notes: The distributions of number of days absent are shown by race, as determined by federally
subsidized lunch receipt. The sample consists of all Massachusetts public school students from
the 2003-2010 school years with no more than 60 absences. Data come from the Massachusetts
Department of Elementary and Secondary Education’s Student Information Management System.




                                                 27
                      Figure 5: Absences, Closures and Snowfall Over Time
         10




                      Absences                 Closures               4+ inch snow days
         8
         6
  Days
         4
         2
         0




              2003   2004      2005        2006          2007     2008       2009        2010
                                                  Year

Notes: The mean number of days absent, school closures and days with four or more inches
of snow experienced by Massachusetts students are shown by school year. The sample consists
of Massachusetts public school students from the 2003-2010 school years with no more than 60
absences, whose schools reported annual school closure numbers for this entire time period. Data
on absences come from the Massachusetts Department of Elementary and Secondary Education’s
Student Information Management System. Data on school closures come from school districts
directly. Data on snowfall come from the National Oceanic and Atmospheric Administration’s
Climate Data Online.




                                              28
                     Figure 6: Mean Annual Snowfall by School District




   46 − 52 inches
   40 − 46 inches
   34 − 40 inches
   28 − 34 inches
   22 − 28 inches
   16 − 22 inches
Notes: The mean annual snowfall on school days is shown by school district for the 2003-2010
school years. Non-school days such as weekends and common holidays are excluded from the
calculations. Data on snowfall come from the National Oceanic and Atmospheric Administra-
tion’s Climate Data Online.




                                            29
                                                               Table 1: Summary Statistics

                                     (1)          (2)            (3)            (4)           (5)          (6)           (7)         (8)           (9)
                                    Full        MCAS          Closures
                                  sample        sample        sample        Nonpoor         Poor         White         Asian        Black      Hispanic
     (A) Days in school
     Days missed                          .             .         10.27           8.95       12.63           9.79        7.28        11.28         13.02
     Days closed                          .             .          2.20           2.03        2.50           2.10        2.27         2.14          2.75
     Days absent                      8.71          8.01           8.06           6.92       10.13           7.69        5.01         9.14         10.27
     Days attended                  170.98        171.97         171.80         173.09      169.49         172.29      174.88       170.48        169.21
     Days in membership             179.69        179.98         179.87         180.01      179.61         179.98      179.88       179.62        179.48
     Peer days absent                 8.71          8.00           8.06           7.49        9.09           7.62        7.84         9.57          9.20
     (B) Weather
     4-10 inch snow days              2.32           2.29           2.30          2.25         2.40           2.24        2.32         2.48          2.46
     10+ inch snow days               0.34           0.34           0.34          0.35         0.33           0.35        0.34         0.33          0.33




30
     (C) Controls
     Poor                             0.30          0.31           0.36               .           .          0.18        0.52         0.76          0.84
     Black                            0.08          0.08           0.11           0.04        0.23               .           .           .             .
     Hispanic                         0.12          0.12           0.14           0.03        0.32               .          .            .             .
     Asian                            0.05          0.05           0.06           0.04        0.08               .           .           .             .
     Special education                0.17          0.17           0.17           0.14        0.22           0.16        0.08         0.22          0.21
     Grade size                     178.50        178.50         180.34         190.36      162.28         188.60      180.43       163.07        155.40
     (D) Outcomes
     Math Z                           -0.00         -0.00          -0.06          0.23        -0.57           0.14        0.32        -0.65         -0.70
     ELA Z                            -0.00         -0.00          -0.07          0.24        -0.62           0.15        0.03        -0.62         -0.75

     Student-years              6,761,496      3,737,241      1,965,306     1,263,748      701,558      1,339,526     109,172      212,890       267,197
     Students                   1,513,103         49,844         25,912        23,932       25,374          4,318       7,963       11,120
      Notes: Mean values of each variable are shown by sample. Column 1 includes all Massachusetts students from 2003-2010. Column 2 includes all students
      with valid MCAS scores. Column 3 includes all students with valid MCAS scores and whose school districts reported school closures for all years from
      2003-2010. Columns 4-9 divide the sample in column 3 by poverty status (as indicated by subsidized lunch receipt) and race/ethnicity.
           Table 2: Fixed Effects Estimates of the Impact of Days Missed on Achievement

                                              (1)                   (2)                   (3)                   (4)
                                                       Math                                         ELA
(A) Days missed overall
Days missed                               -0.010∗∗∗             -0.008∗∗∗             -0.008∗∗∗             -0.008∗∗∗
                                           (0.001)               (0.000)               (0.001)               (0.000)

N                                           19,194              1,723,606               19,845              1,717,509

(B) Days missed by type
Days absent                               -0.020∗∗∗             -0.008∗∗∗             -0.016∗∗∗             -0.008∗∗∗
                                           (0.002)               (0.000)               (0.001)               (0.000)
Days closed                                 -0.001                0.002                 -0.000               0.002∗
                                           (0.001)               (0.001)               (0.001)               (0.001)
Peer days absent                                                -0.008∗∗∗                                   -0.008∗∗∗
                                                                 (0.001)                                     (0.001)

N                                           19,194              1,723,606               19,845              1,717,509

School-grade fixed effects                    X                                           X
Student fixed effects                                               X                                            X
 Notes: Heteroskedasticity robust standard errors are in parentheses (* p<.10 ** p<.05 *** p<.01).Panel A regresses
 standardized test scores on total days missed annually, while panel B separates days missed into absences and
 closures. Columns 1 and 3 collapse the data to school-grade-year cells, weight each cell by the number of test-takers,
 and include school-grade and year fixed effects. Columns 2 and 4 use student-level data and include individual
 student and grade-year fixed effects. Columns 2 and 4 also include the average number of days absent for the other
 students in a given student’s school-grade-year. Columns 1 and 3 control for school-grade-year averaged measures
 of gender, race/ethnicity, poverty, special education and grade size. Columns 2 and 4 control for such measures
 both at the individual student level and averaged across each student’s school-grade-year peers.




                                                          31
                     Table 3: Heterogeneity by School Type, Fixed Effects Estimates

                      (1)               (2)              (3)             (4)             (5)                (6)
                    Nonpoor            Poor            Grades          Grades           Grade              ELA
                    schools           schools           3-5             6-8              10             composition
(A) Math
Days absent         -0.018∗∗∗        -0.022∗∗∗        -0.021∗∗∗       -0.021∗∗∗        -0.018∗∗∗
                     (0.002)           (0.002)          (0.003)        (0.002)          (0.003)
Days closed           0.000           -0.006∗∗         -0.005∗∗         0.002            -0.003
                     (0.002)           (0.003)          (0.002)        (0.002)          (0.003)

N                     11,486           7,709           10,435            7,068           1,692

(B) ELA
Days absent         -0.014∗∗∗        -0.019∗∗∗        -0.015∗∗∗       -0.018∗∗∗        -0.014∗∗∗          -0.012∗∗∗
                     (0.002)          (0.002)          (0.002)         (0.002)          (0.003)            (0.002)
Days closed           -0.001           -0.003           -0.001          -0.000           0.001              0.000
                     (0.001)          (0.003)          (0.002)         (0.002)          (0.004)            (0.002)

N                     11,888           7,958           12,284            5,876           1,686              8,967
 Notes: Heteroskedasticity robust standard errors clustered by school are in parentheses (* p<.10 ** p<.05 *** p<.01).
 Each column regresses standardized test scores on annual absences and closures, collapsing the data to school-
 grade-year cells, weighting each cell by the number of test-takers, and including school-grade and year fixed effects.
 All regressions include school-grade-year averaged measures of gender, race/ethnicity, poverty, special education
 and grade size. Panels A and B limit the sample to school-grade-year cells with valid math and ELA scores respec-
 tively. Columns 1 and 2 limit the collapsed sample to schools above and below a 50% poverty rate over this time
 period. Columns 3-5 limit the collapsed sample to grades 3-5, 6-8 and 10, respectively. Column 6 uses as an outcome
 the ELA composition sub-test, given in grades 4, 7 and 10 on fixed dates each year.




                                                          32
                           Table 4: Impacts of Snow on Absences and Closures

                             (1)           (2)            (3)        (4)            (5)           (6)           (7)
                                                                    White/        Black/
                            All        Non-poor         Poor        Asian        Hispanic        Male        Female
(A) Closures
4+ inch snow days         0.094∗∗∗      0.077∗∗∗      0.094∗∗∗      0.077∗∗∗      0.070∗       0.095∗∗∗     0.092∗∗∗
                           (0.022)       (0.022)       (0.032)       (0.021)      (0.040)       (0.022)      (0.022)

N                          19,195        17,063        18,137        17,780       16,656        17,930       17,693

(B) Absences
4+ inch snow days         0.076∗∗∗       0.050∗∗      0.114∗∗∗      0.059∗∗∗     0.115∗∗∗      0.071∗∗∗     0.082∗∗∗
                           (0.019)       (0.020)       (0.030)       (0.019)      (0.041)       (0.021)      (0.020)

N                          19,195        17,063        18,137        17,780       16,656        17,930       17,693
 Notes: Heteroskedasticity robust standard errors clustered by school are in parentheses (* p<.10 ** p<.05 *** p<.01).
 Each coefficient comes from a regression of annual closures or absences on the number of school days with four or
 more inches of snow, collapsing the data to school-grade-year cells, weighting each cell by the number of math
 test-takers, and including school-grade and year fixed effects. All regressions include school-grade-year averaged
 measures of gender, race/ethnicity, poverty, special education and grade size. Column 1 includes all students.
 Columns 2-7 limit the sample to the listed subgroup of students prior to collapsing the data to the school-grade-
 year level.




                                                          33
                     Table 5: Weather as an Instrument for Lost Instructional Time

                                 (1)             (2)                 (3)                   (4)                (5)
                              Closures         Absences          Days missed           RF impact          IV impact
(A) Math
4+ inch snow days             0.094∗∗∗          0.076∗∗∗            0.169∗∗∗             -0.004∗
                               (0.022)           (0.019)             (0.032)             (0.002)
Days missed                                                                                                 -0.023∗
                                                                                                            (0.012)

N                              19,195            19,195              19,195              19,195             19,195

10+ inch snow days            0.482∗∗∗            -0.042            0.440∗∗∗              0.002
                               (0.049)           (0.028)             (0.054)             (0.003)
Days missed                                                                                                  0.005
                                                                                                            (0.007)

N                              19,195            19,195              19,195              19,195             19,195

(B) ELA
4+ inch snow days             0.095∗∗∗          0.070∗∗∗            0.166∗∗∗              -0.001
                               (0.021)           (0.018)             (0.030)             (0.002)
Days missed                                                                                                  -0.004
                                                                                                            (0.010)

N                              19,846            19,846              19,846              19,846             19,846

10+ inch snow days            0.483∗∗∗          -0.050∗             0.432∗∗∗              0.002
                               (0.046)          (0.028)              (0.051)             (0.003)
Days missed                                                                                                  0.006
                                                                                                            (0.007)

N                              19,846            19,846              19,846              19,846             19,846
 Notes: Heteroskedasticity robust standard errors clustered by school are in parentheses (* p<.10 ** p<.05 *** p<.01).
 Columns 1-3 regress various measures of days missed on the number days that school year with four-plus or ten-
 plus inches of snow. Column 4 estimates the reduced form impact of the given weather measure on standardized
 test scores. Column 5 estimates the impact of total days missed on standardized test scores, instrumenting days
 missed with the given weather measure. Each regression collapses the data to school-grade-year cells, weights each
 cell by the number of test-takers, and includes school-grade and year fixed effects. All regressions include school-
 grade-year averaged measures of gender, race/ethnicity, poverty, special education and grade size. Panels A and B
 limit the sample to school-grade-year cells with valid math and ELA scores respectively.




                                                           34
            Table 6: The Differential Effects of Different Types of Lost Instructional Time

                                    (1)                 (2)              (3)                  (4)              (5)
                                      First stage:                     Reduced                IV               IV
                                Closures       Absences                 form                (2 Zs)           (10 Zs)
(A) Math
4-10 inch snow days               0.040∗             0.084∗∗∗           -0.004∗∗
                                  (0.023)             (0.020)            (0.002)
10+ inch snow days               0.508∗∗∗              0.011             -0.001
                                  (0.048)             (0.030)            (0.003)
Days absent                                                                                -0.052∗∗          -0.053∗∗
                                                                                            (0.025)           (0.021)
Days closed                                                                                  -0.000            -0.005
                                                                                            (0.006)           (0.004)

N                                 19,195              19,195             19,195             19,195           19,195

(B) ELA
4-10 inch snow days               0.042∗             0.080∗∗∗            -0.001
                                  (0.022)             (0.019)            (0.002)
10+ inch snow days               0.509∗∗∗              0.000              0.002
                                  (0.045)             (0.029)            (0.003)
Days absent                                                                                 -0.014            -0.012
                                                                                           (0.021)           (0.016)
Days closed                                                                                 0.003             -0.003
                                                                                           (0.006)           (0.004)

N                                 19,846              19,846             19,846             19,846           19,846
 Notes: Heteroskedasticity robust standard errors clustered by school are in parentheses (* p<.10 ** p<.05 *** p<.01).
 Columns 1 and 2 regress measures of days missed on the number days that school year with 4-10 inches of snow and
 10+ inches of snow. Column 3 estimates the reduced form impact of those two weather measure on standardized
 test scores. Column 4 estimates the impact of absences and closures on standardized test scores, instrumenting
 those measures of days missed with the two measures of snowy days. Column 5 replicates column 4 but uses a
 vector of ten instruments measuring the number of school days with 1-2 inches of snow, 2-3 inches of snow, and so
 on through 10+ inches of snow. Each regression collapses the data to school-grade-year cells, weights each cell by
 the number of test-takers, and includes school-grade and year fixed effects. All regressions include school-grade-
 year averaged measures of gender, race/ethnicity, poverty, special education and grade size. Panels A and B limit
 the sample to school-grade-year cells with valid math and ELA scores respectively.




                                                          35
    Table 7: Heterogeneous Impacts of Lost Instructional Time, Instrumental Variables Estimates

                      (1)                (2)              (3)            (4)             (5)               (6)
                    Nonpoor             Poor            Grades         Grades           Grade             ELA
                    schools            schools           3-5            6-8              10            composition
(A) Math
Days absent          -0.081∗∗            -0.046        -0.056∗∗         -0.036         -0.038∗∗
                      (0.032)           (0.031)         (0.023)         (0.036)         (0.017)
Days closed           -0.006           -0.014∗∗         -0.010          -0.007           0.007
                      (0.006)           (0.006)         (0.007)         (0.006)         (0.009)

N                     11,486            7,709           10,435           7,068          1,692

(B) ELA
Days absent           -0.027            -0.027          -0.021           0.008          0.008              -0.026
                      (0.020)          (0.025)          (0.019)         (0.030)        (0.016)            (0.020)
Days closed           -0.000          -0.016∗∗∗         -0.007          -0.005          0.002              0.003
                      (0.004)          (0.006)          (0.005)         (0.007)        (0.008)            (0.006)

N                     11,888            7,958           12,284           5,876          1,686              8,967
 Notes: Heteroskedasticity robust standard errors clustered by school are in parentheses (* p<.10 ** p<.05 *** p<.01).
 Each column estimates the impact of absences and closures on standardized test scores, instrumenting those mea-
 sures of days missed with a vector of ten instruments measuring the number of school days with 1-2 inches of
 snow, 2-3 inches of snow, and so on through 10+ inches of snow. Each regression collapses the data to school-grade-
 year cells, weights each cell by the number of test-takers, and includes school-grade and year fixed effects. All
 regressions include school-grade-year averaged measures of gender, race/ethnicity, poverty, special education and
 grade size. Panels A and B limit the sample to school-grade-year cells with valid math and ELA scores respectively.
 Columns 1 and 2 limit the collapsed sample to schools above and below a 50% poverty rate over this time period.
 Columns 3-5 limit the collapsed sample to grades 3-5, 6-8 and 10, respectively. Column 6 uses as an outcome the
 ELA composition sub-test, given in grades 4, 7 and 10 on fixed dates each year.




                                                          36
                      Figure A.1: Map of Massachusetts Weather Sensors




Notes: The map shows the location of the 33 Massachusetts weather sensors used to compute
snowfall by school district and year. Locations of the sensors comes from the National Oceanic
and Atmospheric Administration’s Climate Data Online.




                                             37
                      Figure A.2: Mean Absences by Grade and Gender
   14


                   Male
                   Female
   12
   10
   8
   6
   4
   2
   0




        1      2      3      4       5      6     7        8      9      10     11     12
                                             Grade

Notes: Mean numbers of days absent are shown by grade and gender. The sample consists of all
Massachusetts public school students from the 2003-2010 school years with no more than 60 ab-
sences. Data come from the Massachusetts Department of Elementary and Secondary Education’s
Student Information Management System.




                                             38
                          Figure A.3: Absence Distribution by Gender




                                              (A) Male
               .08
               .06
           Fraction
             .04
               .02
               0




                      0                 10                   20                  30+
                                             Days absent


                                             (B) Female
               .08
               .06
           Fraction
             .04
               .02
               0




                      0                 10                   20                  30+
                                             Days absent


Notes: The distributions of number of days absent are shown by gender. The sample consists of
all Massachusetts public school students from the 2003-2010 school years with no more than 60 ab-
sences. Data come from the Massachusetts Department of Elementary and Secondary Education’s
Student Information Management System.



                                               39
