                              NBER WORKING PAPER SERIES




                        PUBLISHING ECONOMICS:
          HOW SLOW? WHY SLOW? IS SLOW PRODUCTIVE? FIXING SLOW?

                                      Aboozar Hadavand
                                     Daniel S. Hamermesh
                                      Wesley W. Wilson

                                      Working Paper 29147
                              http://www.nber.org/papers/w29147


                    NATIONAL BUREAU OF ECONOMIC RESEARCH
                             1050 Massachusetts Avenue
                               Cambridge, MA 02138
                                   August 2021




Wesley Wilson has not received any funding for this study. It is disclosed that at the time this
paper was written, Wesley Wilson was the Editor of Economic Inquiry and did receive a salary
for that position. The views expressed herein are those of the authors and do not necessarily
reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2021 by Aboozar Hadavand, Daniel S. Hamermesh, and Wesley W. Wilson. All rights
reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit
permission provided that full credit, including © notice, is given to the source.
Publishing Economics: How Slow? Why Slow? Is Slow Productive? Fixing Slow?
Aboozar Hadavand, Daniel S. Hamermesh, and Wesley W. Wilson
NBER Working Paper No. 29147
August 2021
JEL No. A11,B31

                                          ABSTRACT

Publishing in economics proceeds much more slowly on average than in the natural sciences, and
more slowly than in other social sciences and finance. It is even relatively slower at the extremes.
We demonstrate that much of the lag, especially at the extremes, arises from authors' dilatory
behavior in revising their work. The marginal product of an additional round of re-submission at
the top economics journals is productive of additional subsequent citations; but conditional on re-
submission, journals taking more time is not productive, and authors spending more time is
associated with reduced scholarly impact. We offer several proposals to speed up the publication
process. These include no-revisions policies; limits on authors' time revising articles, and limits
on editors waiting for dilatory referees.

Aboozar Hadavand                                 Wesley W. Wilson
Minerva University                               Department of Economics
1145 Market Street                               1285 University of Oregon
Ninth Floor                                      Eugene, OR 97403-1285
San Francisco, CA 94103                          wwilson@uoregon.edu
hadavand.a@gmail.com

Daniel S. Hamermesh
Department of Economics
Barnard College
3009 Broadway
New York, NY 10027
and IZA
and also NBER
hamermes@eco.utexas.edu
I. Introduction
        The slowness of publishing in economics was pointed out by Ellison (2002), although scholars who

had been active in the profession for at least a quarter century were by that date very aware of the changes

that had occurred in the publishing process. Today the difficulties are well known and have been discussed

by many editors (discussions in Szenberg and Ramrattan, 2014). In this study we first provide evidence on

how the publishing process--in terms of the lags involved--compares to that in the "hard sciences" (very

much slower) and in other social sciences (substantially slower).

        There are many components that might explain the slowness of economics journals. Culprits might

be dilatory editors/referees, authors' delaying responding to initial encouraging editorial responses, or lags

between a study's acceptance and its publication. We cannot elucidate the underlying causes of each of

these possible contributing factors. There is no way to infer why editors or referees might "sit on" a paper,

why authors might hesitate to revise their work quickly, or why economics differs from other disciplines.

All we can do is document the magnitude of each factor's contribution to slow publication by providing the

first evidence on this issue, one novel contribution of this study.

        The central part of the empirical work here examines the productivity of slowness. We measure

productivity by the professional attention that a study receives from other scholars--its post-publication

(both online and in-print) citations. If a longer publication process increases the scholarly productivity of

economic research, perhaps we should view these benefits as justifying the cost--although evidence

suggests (Conley et al., 2013) that a slow process reduces the quantity of publications, as measured by

pages written. We cannot discover whether slowness in economics publishing makes it more productive

than research in other disciplines, nor can we even analyze whether increasing slowness in economics has

made economic research more productive. We can, however, analyze whether at a point in time published

research with a longer gestation period has a greater impact, providing the first objective evidence on this

crucial outcome of the publication process (although Laband, 1990, provided very useful subjective

evidence on one aspect, the role of referees).



                                                       1
         Answers to these questions require positive analysis. Making normative suggestions about how the

publication process in economics might be speeded up with no loss of quality constitutes the second major

section of this study. Although basically suggestive, it too has some positive bases, as we examine data

describing publications in journals that have experimented with alternatives to standard practices in

economics publishing.

         II.      Characteristics of Slowness in Economics Publishing

         Much of the analysis in this section is based on a set of data collected from leading economics

journals. We asked the editors of each of the "Top Five" journals in the field for details on each article,

excluding Nobel/presidential addresses, comments, replies, etc., that was published in 2012 and 2013. The

details for each paper include: Its initial submission date; date of the initial editorial response; the date of

first re-submission, etc., until date of acceptance. 1 We use articles published in those two years to allow

time for each article to influence subsequent research. Three of the five editors provided the data, showing

these outcomes for each of 241 published articles and thus allowing charting how each article flowed

through the editorial process.

    A. Slowness in Economics--and Other Fields

         Along with other, publicly available data, we use these data to examine the speed of publishing in

economics, political science and psychology, and the natural sciences, both in 2012-13 and recently ( 2020).

The Review of Economics and Statistics (arguably the most-cited general journal outside the "Top Five"),

along with one of the two "Top Five" journals that did not provide complete information, do publish

submission, acceptance (and obviously) publication dates with each article. Adding this information to that

of the three journals in our main data set, we compare the process among them to that in three other social

science journals: The American Political Science Review (APSR), leading in its discipline; and the Journal


1
 We view the "Top Five" as the American Economic Review, Econometrica, the Journal of Political Economy, the
Quarterly Journal of Economics, and the Review of Economic Studies. We are very aware of differences in these
journals' average impacts, of the tremendous heterogeneity of impacts of articles within each journal (Hamermesh,
2018), and of the possibly deleterious effects of over-reliance on publication in these outlets (Heckman and Moktan,
2020). Nonetheless, we follow convention in bibliometric analyses and restrict this part of the study to these journals.


                                                           2
of Applied Psychology and the Journal of Personality and Social Psychology, two of a probable "Top Five"

in psychology, which also publish this information with each article. The same information is included with

each article in Nature, one of the two most widely cited scholarly journals, and in the Proceedings of the

National Academy of Sciences (PNAS), which has a five-year impact factor higher than all but one of the

economics "Top Five." 2

         The upper panel in Table 1 presents statistics describing the distribution of times from initial

submission to acceptance and then to publication among articles published in 2012-13. 3 Time to acceptance

is crucial for young scholars seeking tenured positions and for more senior ones seeking new positions,

since with an acceptance they can include the publication on their CVs. It may also be important for

economists in obtaining public recognition of their work, as journalists often ask whether a study has been

peer-reviewed. It is also crucial to establishing bona fides in expert testimony or in providing policy advice

generally. Time to publication used to be an important indicator of how long it took from the time when

authors viewed their research as complete to when others could see and use the finished product. Today,

however, this measure seems less important, since many journals include widely available online final

versions of articles shortly after acceptance.

         By any measure, the record in economics is, at best, poor, perhaps epitomized by Figure 1. The

mean time from submission to acceptance of articles published in these journals (the REStat and four of the

"Top Five") in 2012-13 was slightly more than two years. This outcome compares to slightly more than




2
 Care is required comparing impact factors across disciplines, since scholars in different fields differ in their propensity
to cite other studies. The average article in the "Top Five" referenced 56 items in 2019, almost the same as in the
APSR. Articles in the two natural science journals averaged 42 references to other studies. At the other extreme,
articles in the two psychology journals averaged 106 references per article; and the two leading sociology journals,
the American Journal of Sociology (AJS) and the American Sociological Review (ASR), with impact factors of 5.9 and
8.2, averaged 110 references in each article (Clarivate Analytics, 2020).
3
 The means are simple averages of the average times in each journal in each group. Regrettably, several attempts to
elicit this information from the leading sociology journals AJS and ASR, in a discipline arguably most comparable to
economics, failed.


                                                             3
one year in the three other social science journals, and only six months in the two science journals. 4 If the

average time suggests problems, the extreme times can only be characterized as disgraceful.5 Even at the

75th percentile the time from submission to acceptance is twice as long in economics as in the other social

sciences, and four times as long as in the science journals. Moreover, the uncertainty faced by economic

researchers is greater: The 90-50 (90/10) ratios of time to acceptance are 2.0 (4.2) in economics, 1.8 (3.7)

in the social science journals and 1.8 (3.0) in the natural science journals.

         While we do not inquire why economics differs so greatly from other disciplines, it is worth noting

that the acceptance rate in the "Top Five" journals currently averages six percent, compared to ten percent

in the three social science journals, and to fifteen percent in the two natural science journals. At least in the

natural science journals, the papers are shorter, and the supply of journal space is greater (with the PNAS

publishing nearly weekly). This is an important difference; but why the very low acceptance rates in the

"Top Five" could generate much longer publishing lags is unclear. 6

         One might argue that these figures reflect ancient history, and that the situation has improved

greatly over the past decade. 7 That argument would be wrong, as shown in the bottom panel of Table 1.

Despite now-universal online submission procedures at these journals, the change over the decade was very

small, with the mean time to acceptance rising slightly and, worse still, with an increase in the mass in the




4
 Upon seeing this Table, one distinguished economist remarked, "If Watson and Crick had to deal with economics
publishing, their article would have been 70 pages long and taken three years to get into print." Watson and Crick
(1953) was published eight weeks after the discovery was announced; it was one page long.
5
 The 90th percentile statistics are bad enough. The maximum durations in the sample were 7 years 5 months from
submission to acceptance, and 9 years 5 months from submission to publication.

6
 One is reminded of George Stigler's perhaps apocryphal response to the then-Editor of the AER, who complained of
having so many good papers to choose among, "Why not publish one occasionally?"
7
 One of the editors who kindly supplied the data underlying most of the work in this Section questioned our request
for 2012-13 data, stating that the journal's process may have been slow in the past but was no longer slow. We
explained that we needed data from those years to examine articles' impacts. We have not had the heart to note that,
while the mean submit-to-accept time at that journal has speeded up slightly, the mass in the right tail has increased.


                                                          4
upper tail of the distribution. 8 Of the five economics journals, the median time from submission to

acceptance increased in two, fell in two and was unchanged in one. The duration at the 90th percentile

increased in four and fell in one. Similar increases in the mass in the upper tails of the distributions of

acceptance times in the other social science journals and in the natural science journals also occurred; but

their average speed and the speed of the slowest publications remained far more rapid than in economics.

To summarize today's situation succinctly, an economics article that is at the 50th percentile of time to

acceptance would be at the 85th percentile of times to acceptance in the other social science journals and at

the 97th percentile in the two natural science journals. 9

         The possible harm from slow publishing is not greatly mitigated by the ever-growing, at both the

extensive and intensive margins, series of discussion/working papers. These are not peer-reviewed, and

thus lack the bona fides of journal articles, in the eyes of other scholars, including university administrators,

and the media. Moreover, the plethora of such papers creates congestion externalities, even in the most

visible such series (Lusher et al., 2021), making it difficult to keep up with what trusted experts view as

important.

B. Contributors to Slow Publishing

         There are many plausible explanations for the slowness in getting an economics paper accepted.

These include the number of times a paper is resubmitted, the amount of time that it spends with editors

and referees (denoted here by time in journal's hands), and the length of time that it spends in author(s)'

revisions (time in author(s)' hands). Here we examine the relative contributions of each of these to the lags

in publication and consider the characteristics of the papers and their authors in relation to these outcomes.



8
 The failure of submit-to-accept times to fall in the economic journals could not have been due to Covid-19 induced
delays. Only 13 percent of the papers tabulated were accepted after April 1, 2020. Given the rapid turn-around in the
natural science journals, however, Covid might explain their (small) increase in submit-to-acceptance times.
9
 Without one of the "Top Five" journals, the statistics in Table 1 are incomplete. We cannot solve this problem for
2012-13 for this journal, but we can piece together a good estimate for articles in 2020 using some in-publication
information and an email survey of authors. The data suggest that its mean submit-to-publication time was 30 months,
with a mean submit-to-accept time of 23 months. If these estimates were included in the statistics shown in the Table,
they would reduce the mean times by one month each.


                                                          5
            Using the descriptions of each stage of the submission/review process for each of the 241 articles

published in the three "Top Five" journals in 2012-13, we calculated the number of rounds of submission/re-

submission/re-re-submission/re-re-re-submission that each went through. We denote this number by 2 if

the second editorial response--the response after the first re-submission--was an acceptance, 3 or 4 if the

third or fourth was an acceptance. 10 We can decompose the total time from submission to publication into

three parts: Time spent in the journal's hands, time in the author(s)' hands, and time between acceptance

and in-print publication.

            In addition to these descriptors of the editorial process itself, we gathered other information on each

article about: Its Web of Science citations in each year from the year of publication up through 2020 (thus

nine years of citations to articles published in 2012, eight years to those published in 2013); the cumulative

number of Google Scholar citations the article had received as of March 2021; its length in pages; 11 the

number of references included; the number of authors; and the sub-field in which the article might be

classified (theory; empirical with administrative data; other empirical, including calibration; experimental;

econometric theory). Characterizing the articles' authors, we obtained the Web of Science citations of each

author in the year the article was submitted, used to construct the citations of the most-cited author; the

post-Ph.D. experience of the most-cited author, and the number of female authors.

            Table 2 presents descriptive statistics of all these variables except times in the journal's and

author(s)' hands, which we examine in detail below. The average or median published paper goes through

three rounds: It is submitted, re-submitted, and then re-submitted again, when it is then accepted; but nearly

one-fourth of all articles went through a fourth round. (For the empirical articles, we consider acceptance

as the date when an acceptance email was sent, i.e., thus earlier than the final submission that includes a

documented dataset.)




10
     Two of the articles went through a fifth round, although in one case the elapsed time was less than one month.
11
  These are calculated based on the average number of characters per page in each journal, with the number normalized
to the journal with the most characters per page.

                                                             6
        Fifty-three percent of articles are empirical (11 percent using administrative data, 42 percent using

other data), with pure theory accounting for 35 percent of the publications, and experiments and

econometric theory accounting for the remaining 12 percent. The average article has slightly above two

authors, but nearly ten percent have four or more authors, reflecting the stretching of the right tail of the

distribution of authors/article noted by Hudson (1996), Ellison (2002), Card and DellaVigna (2013),

Hamermesh (2013), and Jones (2021). The average article contains nearly 29 printed pages, not including

the ubiquitous and often voluminous on-line appendices. There is substantial variation in the number of

references included, and its correlation with article length is only +0.30. Of the articles' authors, 22 percent

were women, with the incidence of female authors rising as the total number of authors increases.

        The average article received 70 Web of Science citations in its first eight or nine years in print with,

as is always the case in citations, substantial skewness in this measure (Hamermesh, 2018). The skewness

is equally pronounced in the distribution of cumulative Google Scholar citations. Even more skewness

exists in the distribution of citations at the time of submission to each article's most cited author. The

average most-cited (on each article) author received over 270 citations in the year of submission, about

average among tenured faculty members in economics departments that might be viewed as Top 30; but

the median most-cited author of an article was cited only one-third as often. The post-Ph.D. experience of

the most-cited authors averaged around 15 years--typical of a relatively young full professor and consistent

with evidence on the age distribution of authors in leading economics journals (Hamermesh, 2013).

        With our focus on the process by which articles are handled, we examine the contributions of the

three components of time from submission to publication. Their distributions are presented in Figure 2,

containing decompositions of the average time from submission to publication, measured in months on the

vertical axis and shown within each of five deciles. (Each journal is weighted as one-third of the total.)

Several aspects of the Figure are striking: 1) The main proximate determinant of inter-decile differences in

speed of publication is the huge rise in the amount of time spent in author(s)' hands (the sum of times

between receiving a response from a journal to re-submission) as the total time to acceptance and

publication rises. Among papers in the middle decile, this is 10 months; among those in the slowest decile,

                                                       7
26 months are spent in author(s)' hands; 2) While the amount of time spent at journals increases with

slowness of publication, moving from the middle to the slowest decile increases that duration much less,

from 10 to 18 months; 3) Lengthier submit to-publication-times are essentially unrelated to changes in the

time between acceptance and publication.

        Figure 2 aggregates across the three journals and does not reflect the role of the heterogeneity of

journals in the total publication lag. To examine how these contributing factors differ across the three

journals, Table 3 shows the means and variances of the submit-to-acceptance lags among the 241 articles

in total and for each journal separately, and it decomposes the variance into its two sources and their

covariance. Most interesting in this Table are: 1) The substantial heterogeneity in the length of time articles

are in process--the variance is quite large even within a journal. 2) The heterogeneity across the journals:

Journal 1 handles the papers somewhat more quickly than the other two, but, most important, there is almost

no variation in the amount of time a paper spends at the journal; and 3) Consistent with the evidence in

Figure 2, over half the variation in lags in acceptance arises from authors spending more time on revisions.

        The covariance between the time in a journal's and author(s)' hands is positive in Table 3, but in

no case does it account for even a third of the total variance in the submit-to-acceptance time. Even this

low correlation is due mainly to the fact that articles that go through more rounds necessarily take more

time of both authors and editors/referees. The correlations between editor/refereeing time and author(s)'

response times are shown for each round separately in Table 4, both for all papers handled in the round,

and for those completed in that round. The correlations at each article's final round average +0.30. Thus,

those articles that take more editor/referee time to handle are associated with authors spending more time,

but the relationship is weak.

        Various characteristics of the articles might cause them to go through more rounds of re-

submissions at a journal; and they might lead editors and referees to spend more time handling the paper.

The same characteristics might lead authors to take longer re-submitting an article that has received an

encouraging initial editorial response. To examine the first issue, in Column (1) of Table 5 we present least-

squares regressions of the number of rounds through which a paper travels at a journal as a function of all

                                                      8
the article/author characteristics on which we have information (except the number of references included,

which may be partly affected by the number of rounds and time spent refereeing/revising). Column (2)

presents the same regressions with journal indicators added to account for the heterogeneity demonstrated

in Table 3. The estimates treat each article equally--the observations are unweighted. 12

         Authors' characteristics are unrelated to the number of rounds an article goes through: Neither how

well-cited an author is, nor his/her post-Ph.D. experience, nor the gender of authors is related to this

outcome. Characteristics of the article do, however, affect the number of rounds: Theory papers are handled

in significantly fewer rounds, with differences across the other sub-fields being small and statistically

insignificant. Papers with fewer authors are handled more rapidly. Articles that are longer when published

are handled in no more rounds than shorter articles.

         Columns (3) and (4) present estimates of the correlates of the length of time that the journals take

to handle a submission. The clearest result is that theory papers are dealt with significantly and substantially

more quickly (2-1/2 months on a mean of 10 months) at each journal (again with only small differences

across the other sub-fields). Weaker evidence shows that having multiple authors is associated with more

rapid treatment by the journals, perhaps because co-authors help iron out problems that might otherwise

lead editors and referees to spend more time handling the article. There is weak evidence that better-cited

authors receive somewhat faster treatment and that, conditional on an author's prior scholarly recognition,

more senior authors' submissions are handled more slowly, other things equal. These last two results are

consistent with the observation that one's prior impact on the profession matters much more than one's

longevity in determining how one is treated. Other than these effects, none of an article's characteristics

affects the time that it spends at a journal.




12
 Using weights that are inversely proportional to the number of articles in each journal in the sample produces only
minute changes in the estimates. Similarly, while ordered-probit estimation is more appropriate than least-squares, its
implications differ little from those of the results in the Table. Similarly, replacing the variable "any female author"
with indicators of the number of female authors and replacing "two or more authors" with indicators of their number
do not change the qualitative conclusions about the effects of these measures.


                                                           9
         The final two columns of Table 5 describe the determinants of the time that authors spend revising

their papers in response to a requested re-submission. The only correlates whose relation to this outcome

are even marginally significant are the presence of a female author (2-1/2 months extra on an average of 12

months) and the negative effect of an article classified as theoretical. 13 There is no evidence that authors

whose prior work has had a greater scholarly impact, or those who are more senior, are differentially slow

in handling requests for revision. Here and throughout this table, variations in the length of articles have

essentially no effect on the outcomes. The results demonstrate that most of the variation in authors' behavior

is idiosyncratic. 14

     C. The Productivity of Slowness

         The most important question in judging whether the uniquely lengthy publication process in

economics is worthwhile is its effect on the scholarly impact of the research that survives this very lengthy

treatment at these major outlets. We recognize that research published in these top journals often has

important influences beyond those on other scholars, for example, on debates about policy or on inchoate

popular feelings about economic issues. Nonetheless, economic research, indeed, any scholarly research is

judged at least in part by the extent to which it influences subsequent work. We therefore answer this

question by measuring the impact of the outcomes examined in Tables 3 and 5 on the annual patterns of

(Web of Science) citations up through 2020 to the articles published in 2012 and 2013. 15

         Table 6 lists the results. Each observation is an article/year, necessitating clustering standard errors

on the individual articles. In addition to the regressors included in Table 5, we add the number of references



13
  Less time is spent revising theory articles at each round of the publication process. There are no significant
differences across the other sub-fields. Thus, articles using administrative data take no longer than other non-theory
articles to revise, and similarly for articles based on experiments.
14
  Here and in the next sub-section we also experiment with a measure of heterogeneity--the standard deviation of
citations across co-authors. This measure is uncorrelated with the time co-authors spend revising, and its inclusion has
minute effects on the estimated impacts of the other regressors.

15
 Checchi et al. (2021) show that there is a remarkably high correlation between this objective bibliometric measure
and subjective peer-based evaluations of individual research products, suggesting that a subjective approach to
measuring impact would yield results that would arguably be similar.


                                                          10
included in each article, since additional references might, for scholarly or invidious reasons, generate more

subsequent citations to the article. Column (1) shows the least-squares estimates of the relationship of

citations to the number of rounds the article has gone through and to various control variables. With average

annual citations of about eight, the productivity of additional authors is low (within this set of studies in

these leading journals), although not much different from that found in other studies (Hollis, 2001; Medoff,

2003; Bosquet and Combes, 2013; Hamermesh, 2018). Having a female author on a study has a substantial

but not quite statistically significant positive effect on the scholarly impact of the article, larger than found

in other studies (Laband, 1987; Ferber and Brün, 2011; Hamermesh, 2018) perhaps because of within-

subfield differences by gender in the topics on which economists work, or perhaps because these are better

articles. 16 Lengthier articles have no greater impacts than shorter ones, perhaps due to the relatively narrow

range of page lengths in the sample. A one standard-deviation increase in the number of references increases

citations to the article by a statistically significant 0.06 standard deviations.

         Theory papers on average receive roughly half as many citations per post-publication year as do

otherwise identical other articles, a result consistent with evidence comparing across leading specialized

journals in different sub-fields. 17 Articles by authors whose prior work has been more heavily cited receive

more attention; but conditional on that measure, more senior authors' work is cited less. As with the impact

of these measures on the time that journals spend handling the paper, this juxtaposition suggests an

autocorrelation of scholarly impacts of one's work, and that those who have not "made it" earlier in their

careers will not "make it" even with work published in a leading outlet.

         The central variables of interest indicate the number of rounds at the journals. The results suggest,

other things equal, that the 51 percent of articles that require a third round (two re-submissions) have greater



16
 The articles cited on this issue, which is quite secondary to the crucial points of this study, are part of a burgeoning
and now voluminous literature.
17
   The average five-year impact factor among the Journal of Development Economics, Journal of Econometrics,
Journal of International Economics, Journal of Labor Economics, Journal of Monetary Economics, and Journal of
Public Economics was 3.67 in 2019. The average five-year impact factor of Games and Economic Behavior and
Journal of Economic Theory was 1.49 (computed from Clarivate Analytics, 2020).


                                                           11
subsequent scholarly impacts than the 27 percent of papers that go through only two rounds (that are

accepted after the first re-submission), the excluded category in Table 6. On the other hand, the marginal

gain in scholarly impact from the fourth round (the 22 percent of articles that are re-submitted, re-submitted

again, and then accepted after yet another re-submission) is smaller although positive.

         One might think that greater editorial attention or more time that authors spend revising before re-

submission(s) would improve the quality of the article in terms of its subsequent impact. The specification

in Column (2) thus adds measures of time spent at the journal and with author(s). Given the number of

rounds an article goes through, greater lags in the process reduce citations to the article. 18 These effects are

statistically significant, are not huge, but not small either: A one standard-deviation increase in the time at

a journal reduces subsequent citations by 0.11 standard deviations. A one standard-deviation increase in the

time that authors spend revising reduces them by 0.13 standard deviations.

         These estimates ignore the tremendous heterogeneity across journals in the kinds of articles and

how they are treated. This difficulty is accounted for in the estimates shown in Columns (3) and (4) of the

Table by the inclusion of journal indicators. The major comparisons to the results presented in the first two

columns are: 1) Not surprisingly, given the heterogeneity shown in Table 3, the negative impact on

subsequent citations of the time that an article spends with the journal disappears; 2) The estimated marginal

productivity of a fourth round at a journal is reduced but becomes about equal to that of a third round; and

3) Most important, the negative effect on citations of additional time spent in author(s)' hands remains

essentially unchanged. 4) None of the estimated impacts of the controls is altered in any important way.

         As the statistics in Table 2 demonstrate, citations to the articles in this sample are highly skewed,

as are prior citations received by their authors. The regressions in Columns (1)-(4) describe the average

experience of these published articles; but given the skewness in these variables, they do not describe what



18
   To account for citations to articles pre-publication, we re-estimate the equations here and in Table 7 using cumulative
Google Scholar citations (through 2020) instead of annual Web of Science citations. This re-specification does not
qualitatively alter any of the inferences. With cumulative Google Scholar citations equaling roughly 35 times annual
Web of Science citations in this sample, the coefficient estimates are almost proportionately smaller. The measures
that are significantly related in Table 6 remain significant.

                                                           12
the median author faces. To infer that, Columns (5) and (6) present least absolute deviation (LAD)

estimates, with the same specifications as in Columns (3) and (4) and including journal indicators. While

the parameter estimates of the control variables are smaller than in the OLS estimates, they are qualitatively

quite similar. The estimated impacts of the number of rounds through which an article goes and the amount

of time spent in editor/referees' or author(s)' hands are also smaller; but the basic inference remains the

same. The marginal impact of another round at a journal is positive, but, conditional on the number of

rounds, authors' slowness in revising their work has a significant negative relation to its citations.

        Table 6 shows that there are differences in the scholarly impacts of theory and other articles, while

Table 5 showed that journals spend sharply different amounts of time dealing with them and that authors

of theory articles spend less time revising them in response to re-submission requests. Perhaps this is

because upon submission a theory paper is clearly correct or incorrect, with fewer inherent possibilities for

revision and the main issue being whether the result is sufficiently important. Regardless, to examine the

theory-other sub-field distinction further, Table 7 presents estimates of equations specified like those in

Columns (4) and (6) of Table 6, but with the articles separated into sub-samples of theory and other papers.

For each type of article, the first column shows OLS estimates, the second LAD estimates.

        Depending upon the type of article, the crucial variables--the marginal impact of an extra round

of re-submission and the time spent at the journal and with author(s)--have different relations to scholarly

impact. The conclusions from Table 6 apply mainly to non-theory articles: For them, the marginal product

of a third re-submission (a fourth round) is positive; most important, additional time that authors spend

revising is associated with a lesser scholarly impact. Among theory articles, the time spent either at the

journal or by authors is unrelated to the paper's impact, although there is evidence that the marginal product

of a second re-submission (a third round) is positive, while the marginal product of a fourth round is not.

        The analysis of this sample leads to the conclusion that multiple rounds of editing/handling at these

journals may be productive (in terms of articles' scholarly impacts). Publishing longer papers (within the

range of full-length articles included in the sample) is, however, unproductive of scholarly impact. The



                                                      13
strongest conclusion is that authors' spending more time responding to requested re-submissions is

unproductive--indeed, those papers over which authors kvetch longer have lesser impacts.

        III.     Solutions to Slowness

        The results in Sections II.B. and II.C. do not reflect ex ante random assignment of papers to quicker

or longer processes; nor were there random assignments of articles to differing amounts of time spent by

editors/referees or by authors. (We do not see how such randomness could be ethical, although randomly

nudging some submitting authors to choose faster decision routes might work.) Without a true experiment,

we cannot be sure that articles that went through more rounds were not inferior to others ab initio and

required extra attention to bring them up to par. Similarly, articles on which authors spent more time,

conditional on the number of rounds, might have needed that time to rise to the quality level of the journal,

even though the author(s)' efforts were insufficient to put their eventual impacts above average. The former

caveat may be important, although we saw that additional rounds of handling were productive; the latter

does not seem credible, especially given the low correlation of the time a journal takes to generate a first

revise-resubmit request and the author(s)' time responding to it.

        The findings in the previous section suggest three margins along which the publishing process

might be improved with no loss of quality. Additional back-and-forth between authors and editors--more

rounds with a journal--has some scholarly value. Even with a positive marginal product of third revisions,

however, that gain must be traded off against the cost to (younger) scholars' careers, in that additional back-

and-forth with journals postpones their ability to demonstrate their scholarly prowess. A second margin is

in the time authors "sit on" their papers after hearing back from journals, time that our results suggest is

unproductive. The final margin is the time that editors and referees spend handling papers, time that is not

productive at the margin.




                                                      14
    A. Fast-track Publication: The Economic Inquiry Experiment

        In Hadavand et al. (2020) we analyzed the impact of an experiment introduced in 2007 at Economic

Inquiry (EI) that created a two-track submission process. Authors could choose between a fast track, in

which the article receives a simple yes or no; or a regular track, which might lead to acceptance with minor

revisions, to one or more revise/re-submit responses with subsequent additional refereeing, or to rejection

(McAfee, 2010) (https://weai.org/view/EI-No-Revisions). The evidence indicated that providing an up-or-

down editorial process did not reduce the quality of publications, at least in a journal outside an elite group.

    B. Limiting Revision Time

        In the data set describing "Top Five" articles published in 2012-13, the time between receipt of the

first decision and the first re-submission exceeded six months on 56 percent of the 241 articles; and it

exceeded one year among 25 percent. Of the 176 articles that went through three or four rounds, 15 percent

spent more than six months in the author(s)' hands between the second response and the second re-

submission. Most surprising is that nine of the 52 papers that went through four rounds were worked on for

more than three months between the third editorial response and the final re-submission. While the times

to re-submission decrease with the number of re-submissions, they remain long.

        With the demonstration that additional time spent re-submitting is at best unproductive, the

question arises as to why. One reason for this apparent negative marginal product may be that

procrastinating authors produce lower-quality research, other things equal. Yet another may be that they

are too busy to devote the real time necessary for producing high-quality revisions (although the estimates

in Table 4 showed that these lags are unrelated to authors' characteristics that might indicate that they are

busier). An alternative explanation is that some authors may use the submission process to obtain comments

on a paper that was not well-polished and was submitted prematurely, with revision time needed to bring

the paper up to a minimally acceptable level. Yet a fourth possibility consistent with slowness on the second

and subsequent re-submissions is that the feedback received in response to the first re-submission is of

reduced quality because the authors and, especially, the editors and referees failed to remember all the

nuances of a subject that they handled many months, or even years before. Regardless, the evidence

                                                      15
suggested that allowing authors free rein to delay re-submission does not add to their articles' scholarly

value.

           Requiring rapid re-submission is standard in the natural sciences but very rare in economics. One

journal, the American Journal of Agricultural Economics (AJAE), the oldest and most distinguished in its

sub-field, does not impose a deadline but does include in its revise-resubmit letter, "please submit the

revised manuscript and separate responses to the reviewers ... within six months of receiving this letter." 19

It had a median submit-to-acceptance time of 10 months in 2020, with the 90th percentile being 22 months. 20

Both statistics are unsurprisingly far below the comparable statistics shown in Table 1 and well below those

of the six leading specialized applied journals. Of those six, none had a median submit-to-accept time as

low as the AJAE, and in only one was the 90th percentile of the distribution at least as fast.

           We cannot tell whether turnaround times in this journal are relatively rapid because of the moral

suasion in its revise/re-submit letters, because for some reason the ethos that generates publishing lags in

the "Top Five" has not infected it as much as other specialized journals, or something else unique to its sub-

specialty. Regardless, this admonition might be included in all revise/re-submit letters. By providing at least

a soft deadline, journals might take advantage of incentives that induce collaborators to move together more

quickly (Bonatti and Hörner, 2011). Going further, the evidence in this study of the negative relation

between subsequent citations and lags in authors' revisions suggests that imposing and enforcing a six-

month limit on time spent revising would not be harmful to their eventual scholarly impact. If nothing else,

it would help pull the right tail in the distribution of submit-to-acceptance times to the left.

           An objection to this proposal is that authors are busy. Of course, they are. But for most authors

publishing an article in these journals is a jackpot prize, one that merits putting an invited re-submission on

the "front burner" of activities. Very few, if any, requested revisions take more than six months of actual



19
     Email communication, Amy Ando, Co-editor, AJAE, March 19, 2021.
20
  The AJAE has an impact factor of 3.44, almost identical to the average of the six journals specialized non-theory
journals listed in Footnote 17.


                                                        16
work; more likely is that the delays simply result from author(s)' procrastination. Given the rewards,

procrastination is difficult to explain; and it can be costly. 21

        While some journals specify length limits on submissions, published versions of accepted articles

suggest that those limits are often violated. Aside from the flouting of these limits incentivizing journals

and authors to drag out the decision process, it also sacrifices journal space that might be devoted to other

authors' work. Raising the remarkably low acceptance rates (compared to other fields) at top economics

journals would be a beneficial result of limiting page counts. The well-documented "page-creep" in

economics journal publishing may accompany the increasing lags in editorial decisions, lags that might be

reduced if page limits were enforced both ab initio and throughout the refereeing process.

     C. Limiting Refereeing/Editing Time

        The evidence in Section II made it clear that editor/refereeing lags are not the more important

contributor to the excessive times from submission to acceptance and publication at the "Top Five"

economics journals. It also demonstrated, however, that conditional on the number of rounds of back-and-

forth, additional time spent by referees and editors has little positive effect on an article's eventual scholarly

impact. This suggests that there is room for marginal improvements along this dimension too.

        While the data used here cannot distinguish between the contributions to publication lags of dilatory

editors and the referees whom they assign, we do know (Hamermesh, 1994) that most referees who

complete their assigned task do so quickly. The difficulty is that a small fraction take a very long time or

more commonly refuse (5 percent) or decline (15 percent) a refereeing request. The theory of

procrastination (see, e.g., Akerlof, 1991) suggests that people backload completion of tasks until just before

a deadline. While there are deadlines in requests to referees, they are not enforced: Referees can backload

indefinitely. Monetary incentives merely shift a few delayed reports across the margin to qualify for the

payment (Hamermesh, 1994); non-monetary incentives, for examples, the American Economic Review's or

Journal of Political Economy's lists of referees, or free journal subscriptions to reward rapid refereeing, are


21
  In at least one case, an author delayed 18 months in responding to a revise-resubmit request from a "Top Five"
journal; the eventual re-submission was quickly rejected by the new editor who was uninterested in the topic.

                                                        17
unlikely to provide much motivation to overcome procrastination. Public shaming of delinquent referees is

a possibility, but journals may be unwilling to engage in it; and, in any case, it is unclear whether such

shaming would reduce delinquents' misbehavior.

        Many referees are simply unreliable; since refereeing deadlines are not enforceable, journal editors

may feel stuck with delinquents. There is a solution: "Fire" the delinquent after some short period of non-

response. If an article is so narrowly focused that only two or three scholars can provide useful

comments/recommendations to the editor, it probably does not belong in a top general-interest journal. A

reasonable argument is thus that no referee should be allowed more than two months to handle an article (a

policy that is currently implicit and tightly enforced by the Quarterly Journal of Economics). If a referee

fails to respond within that time limit, the editor should immediately request a report from another referee.

        We showed in Section II that 22 percent of articles at "Top Five" journals went through four

submissions/re-submissions, back-and-forth with the journal. While these additional rounds did generate

positive marginal products in terms of additional subsequent citations, is that worth the delay in making

research more visible and in authors' improving their CVs? Perhaps journal editors should not plan on

soliciting more than two re-submissions, with the second requesting only "cleaning-up" and "polishing." If

implemented, this would also reduce the incidence of multiple rounds of re-submissions that end in

rejection. This recommendation requires that editors exercise judgment when soliciting the first re-

submission, being clear that, as one former "Top 5" editor suggested, an initial re-submission will only be

sought if the additional work is "doable" and can be handled by the author(s) in a reasonable length of time,

as recommended in the previous sub-section.

        The editors of most "Top Five" journals are paid for their work, with substantial time released from

teaching and/or monetarily and often quite lucratively. (One "Top Five" journal pays its editors $51,500

per annum; another pays $32,000--with $64,000 to the Editor-in-Chief.) They should be well-paid--their

work is important and time-consuming. Asking that they abide by the dictum that they only solicit re-

submissions on papers on which there is a clear path to publication is not unreasonable. Moreover, given



                                                     18
their remuneration, "sitting on" a paper longer than two weeks upon submission/re-submission or upon

receipt of a sufficient number of referee reports is inexcusable.

        IV.      Escaping the Low-level Equilibrium

        The economics profession is in a low-level equilibrium trap, with much longer decision times than

any other discipline that communicates ideas through scholarly journals. Today the lags between an article's

acceptance and publication are unimportant. Online publication often occurs within a few weeks of an

article's acceptance; and most articles published in "Top Five" and other journals have long circulated in

working-paper form. Even ignoring the now technologically irrelevant lag between acceptance and

publication, however, economics publishing remains woefully slower than that in other disciplines.

        The long lags hurt the profession and, as we have shown, are at least partly unproductive. They

have especially severe negative impacts on younger scholars facing tenure/job-security decisions, with

cases where Ph.D. essays are hanging in the balance at a journal even when a person's tenure case is being

considered. In many institutions junior economists are compared to peers in other disciplines, even in other

social sciences, whose research oeuvres do not suffer the same lags in acceptance/publication. Economists

making decisions about their colleagues' future understand this problem, but "higher-level" administrators

often do not, creating needless stumbling blocks to tenure for active junior economists.

        We have outlined several steps that might reduce the time between an article's submission and its

acceptance. While the evidence supporting these recommendations comes from data describing "Top Five"

journals, they are equally valid at lower-level journals (whose decision process, as shown in Section III.B,

is also distinctly slow). The initiatives of a few journals, such as the AER: Insights and Economic Inquiry,

are laudable, but their examples are unlikely to become widespread until the leading journals improve their

turnaround times.

        In all these journals, the burden of improving the situation--of putting the economics profession

on the same footing as other disciplines--rests on their editors. They need to change their behavior, to insist

that referees behave as gatekeepers rather than co-authors, and to be sure that authors respond reasonably



                                                      19
rapidly to editors' requests for re-submissions. The low-level equilibrium trap developed because editors

let it develop. We will not escape it until editors change how they deal with referees and authors.




                                                     20
REFERENCES
George Akerlof, "Procrastination and Obedience," American Economic Review, 81 (May 1991): 1-19.

Clarivate Analytics, Journal Citation Reports, 2020.

Alessandro Bonatti and Johannes Hörner, "Collaborating," American Economic Review, 101 (April 2011):
       632-63.

Clément Bosquet and Pierre-Philippe Combes, "Are Academics Who Publish More Also More Cited?
       Individual Determinants of Publication and Citation Records," Scientometrics 97 (Dec. 2013):
       831­57.

David Card and Stefano DellaVigna, "Nine Facts about Top Journals in Economics," Journal of Economic
       Literature, 51 (March 2013): 144-61.

Daniele Checchi, Alberto Ciolfi, Gianni De Fraja, Irene Mazzotta, and Stefano Verzillo, "Have You Read
        This? An Empirical Comparison of the British REF Peer Review and the Italian VQR Bibliometric
        Algorithm," Economica (2021): forthcoming.

John Conley, Mario Crucini, Robert Driskill, and Alisina Önder, "The Effects of Publication Lags on Life-
       cycle Research Productivity in Economics," Economic Inquiry, 51 (April 2013): 1251­76.

Glenn Ellison, "The Slowdown of the Economics Publishing Process," Journal of Political Economy, 110
       (Oct. 2002): 947-93.

Marianne Ferber and Michael Brün, "The Gender Gap in Citations: Does It Persist?" Feminist Economics,
       17 (Jan. 2011): 151-8.

Aboozar Hadavand, Daniel Hamermesh, and Wesley Wilson, "Is Scholarly Refereeing Productive (At the
      Margin)?" NBER Working Paper No. 26614, Jan. 2020.

Daniel Hamermesh, "Facts and Myths About Refereeing," Journal of Economic Perspectives, 8 (Winter
       1994): 153-63.

-----------------------, "Six Decades of Economics Publishing; Who and How?" Journal of Economic
          Literature, 51 (March 2013): 162-72.

-----------------------, "Citations in Economics: Measurement, Uses, and Impacts," Journal of Economic
          Literature, 56 (March 2018): 115-56.

James Heckman and Sidharth Moktan, "Publishing and Promotion in Economics: The Tyranny of the `Top
       Five," Journal of Economic Literature, 58 (June 2020): 419-70.

Aidan Hollis, "Co-authorship and the Output of Academic Economists." Labour Economics, 8 (Sept. 2001):
       503­30.

John Hudson, "Trends in Multi-Authored Papers in Economics," Journal of Economic Perspectives, 10
       (Summer 1996): 153-58.



                                                   21
Benjamin Jones, "The Rise of Research Teams: Benefits and Costs in Economics," Journal of Economic
       Perspectives, 35 (Spring 2021): 191-216.

David Laband, "A Qualitative Test of Journal Discrimination against Women," Eastern Economic Journal
       13 (April-June 1987): 149­53.

-----------------, "Is There Value-added from the Review Process in Economics? Preliminary Evidence from
          Authors," Quarterly Journal of Economics, 105 (May 1990): 341-52.

Lester Lusher, Winnie Yang, and Scott Carrell, "Does Economics Have a Working Paper Problem?"
        Unpublished paper, University of California--Davis, July 2021.

R. Preston McAfee, "Edifying Editing," American Economist, 55 (Spring 2010): 1-8.

Marshall Medoff, "Collaboration and the Quality of Economics Research." Labour Economics 10 (Oct.
       2003): 597­608.

Michael Szenberg and Lall Ramrattan, eds., Secrets of Economics Editors. Cambridge, MA: MIT Press,
       2014.
James Watson and Francis Crick, "A Structure for Deoxyribose Nucleic Acid," Nature (April 25, 1953):
       737-8.




                                                  22
Table 1. Acceptance and Publication Lags (in Months), Economics, Other Social Sciences, and
"Hard" Sciences, 2012-13 and 2020*
                                             Weighted                     Percentile
                                        Mean Std. Error
                                                                             10       25       50        75      90


                                                                                  2012 -13
 Four "Top 5" + REStat (535)**
 Submission to acceptance                           24.72       (0.63)       10       14         21      32      42
 Submission to publication                          33.15       (0.66)       17       25         35      43      52

 APSR, JApplPsy, JPersSocPsy (371)
 Submission to acceptance                          12.84        (0.36)        6         8        12      16      22
 Submission to publication                         18.05         (0.37)      11        13        17      22      38


 Nature, PNAS (195)
 Submission to acceptance                           5.77        (0.22)        3        4         5       7        9
 Submission to publication                          7.80        (0.24)        5        5         7       9       11


                                                                                   2020

 Four "Top 5" + REStat (308)**
 Submission to acceptance                          26.38        (1.00)       10        15        22      35      50
 Submission to publication                         34.31        (0.93)       18        25        32      44      59

 APSR, JApplPsy, JPersSocPsy (212)

  Submission to acceptance                        14.37         (0.52)        6         8        13      17      24
  Submission to publication                       22.99         (0.56)       14        17        21      26      32


 Nature, PNAS (183)
 Submission to acceptance                           7.16       (0.41)         3         4         6       8      13
 Submission to publication                          9.35        (0.41)        5         6         8      11      15

*Number of articles in parentheses. Means weighted by the inverses of the numbers of articles from the journal in the
samples. Several articles (fewer than five in each case) accepted within a month of submission were deleted from the
samples of psychology journals.

**In addition to the REStat and the three "Top 5" journals that provided us with confidential information, we also
included published information from one of the two "Top 5" journals that did not provide such data.




                                                           1
 Table 2. Descriptive Statistics from the Three-Journal Sample, Articles 2012-13 (N=241)

 Variable means:

 Number of rounds:                 Field:                          Number of authors (fraction with any female):
  2         0.27                   Theory             0.35           1        0.21          (0.12)
  3         0.51                   Admin. data        0.11            2       0.43          (0.18)
  4         0.22                   Other data         0.42            3       0.27          (0.28)
                                   Experiment         0.09           4+       0.09          (0.39)
                                   Econometric theory 0.03


                                                                                 Percentile

 Variable:                                       Mean          Std. Error   10 25       50    75    90

 Page equivalents*                                29.18          0.41       21 25       29    33    37

 References included                               46.08         1.18       26 33       44    55     67

 Cumulative Web of Science citations               69.52         5.15       10 20       44    86    168

 Cumulative Google Scholar citations              299.24        21.67       42 78      168    402   739

 Web of Science citations of most-                271.81        36.53        7    28    97    284   701
 cited author during year of submission

 Post-PhD experience of most-cited                  16.41        0.66        4    8     14    24    32
 author

*Pages standardized to the journal with the densest format.




                                                           2
Table 3. Decomposition of Variance of the Submit-to-Acceptance Lag (in months)

                            Variance      Due to       Due to       2*
                 Mean                    Author(s)    Journal    Covariance
 All journals    22.20        16.68        9.24         4.32         3.12
  Journal 1      15.36        12.12        10.44        0.24         1.44
  Journal 2      24.60        14.16        3.72         6.36         4.08
  Journal 3      26.28        17.52        10.32        2.88         4.32




                                               3
Table 4. Correlations of Time in Journals and Author(s)' Hands
                  All Papers             Completed in Round
Round      Correlation         N=         Correlation    N=
2            0.023             241          0.255         65
3            0.260             176          0.256        124
4            0.364             52           0.364         52




                                               4
Table 5. Determinants of the Editorial Production Process, OLS Estimates, N=241
                               No. of rounds                   Months at journal        Months with author(s)
 Ind. Var.

 Citations to most- cited
 author/100                     0.009        0.005              -0.256      -0.129             -0.161        -0.121
                               (0.008)      (0.008)             (0.086)     (0.070)            (0.127)       (0.126)

 Experience of                 -0.006       -0.006              0.072       0.071               0.074        0.079
  most-cited author            (0.005)      (0.005)             (0.049)     (0.039)            (0.073)       (0.071)

 Any female author              0.044        0.028              -0.902      -0.413              2.467        2.570
                               (0.112)      (0.109)             (1.145)     (0.920)            (1.696)       (1.659)

 Two or more authors           -0.171       -0.162              -1.577      -1.700             -0.013        0.078
                               (0.115)      (0.118)             (1.190)     (0.955)            (1.762)       (1.722)

 Equivalent pages              -0.004       -0.005              0.121       0.039               0.043        -0.074
                               (0.007)      (0.007)             (0.075)     (0.064)            (0.112)       (0.115)

 Theory                        -0.238       -0.205              -1.070      -2.235             -1.808        -2.142
                               (0.098)      (0.096)             (1.000)     (0.810)            (1.481)       (1.461)

 Adj. R2                        0.018        0.081              0.041       0.383               0.006        0.052


*Standard errors in parentheses. Columns (2), (4), and (6) contain journal indicators. The correlation of the residuals
in Columns (3) and (5) is 0.24, between the residuals in Columns (4) and (6) is 0.31.




                                                           5
Table 6. Determinants of Annual Post-publication Citations (N=241 articles, 2,049 citation-years)*

                                                      OLS                                     LAD
Ind. Var:

  3 rounds                      2.541       3.261               1.314     1.827          0.815        1.020
                                (0.956)     (1.038)         (0.924)       (1.033)        (0.323)      (0.357)

 4 rounds                       3.066       5.909               2.349     3.987          0.977        1.295
                                (1.671)     (2.145)         (1.645)       (2.209)        (0.382)      (0.552)

 Journal hands                  -------     -0.145              -------   0.010          -------      0.259
                                            (0.071)                       (0.086)                     (0.306)

 Author(s) hands                -------     -0.147              -------   -0.140         -------      -0.662
                                            (0.057)                       (0.062)                     (0.170)

 Citations to most-             0.508       0.447               0.463     0.446          0.407        0.409
 cited author/100               (0.091)     (0.085)         (0.088)       (0.086)        (0.057)      (0.079)

 Experience of                  -0.114      -0.091          -0.118        -0.106         -0.103       -0.095
  most-cited author             (0.041)     (0.042)         (0.040)       (0.041)        (0.013)      (0.016)

 Any female author              2.953       3.064               2.696     3.011          0.755        0.918
                                (1.695)     (1.638)         (1.610)       (1.600)        (0.372)      (0.376)

 Two or more authors            1.206       1.301               1.139     1.360          0.494        0.429
                                (1.108)     (1.111)         (1.097)       (1.104)        (0.322)      (0.344)

 Equivalent pages               -0.099      -0.068          -0.027        -0.037         0.005        0.011
                                (0.078)     (0.076)         (0.082)       (0.083)        (0.022)      (0.023)

 Number of references           0.072       0.065               0.058     0.061          0.029        0.029
                                (0.026)     (0.025)         (0.025)       (0.025)        (0.007)      (0.007)

  Theory                        -4.087      -4.224          -3.734        3.859          -1.969       -2.036
                                 (0.898)    (0.913)             (0.937)   (0.967)         (0.257       0.266

*Standard errors in parentheses, clustered on the articles. Columns (3)-(6) contain journal indicators. Each equation
also includes a vector of indicators of year post-publication.




                                                            6
Table 7. Determinants of Post-Publication Citations, Theory Articles vs. Others*
Ind. Var.:                         Non-theory                    Theory
                                 OLS        LAD            OLS            LAD


 3 rounds                       0.916       -0.206            1.578       0.727
                                (1.670)     (1.048)        (1.283)       (0.637)

 4 rounds                       3.628        0.559            1.082       0.314
                                (3.255)     (1.368)        (1.406)       (0.922)

 Journal hands                  0.099        0.069            0.025       0.033
                                (0.124)     (0.063)        (0.075)       (0.042)

 Author(s) hands                -0.193      -0.083         -0.004        -0.004
                                (0.076)     (0.038)        (0.068)       (0.030)


 R2                             0.288        0.273            0.315       0.270

N (articles, observations)            (158, 1,345)                    (83, 704)



*Standard errors in parentheses, clustered on the articles. Each equation also includes a vector of indicators of year
post-publication. Also included in each equation are journal indicators and all the other independent variables shown
in the estimates of Table 6.




                                                          7
Figure 1. Depiction of Publishing Lags in Economics*

*Rafael Pereira @UrbanDemog




                                               8
                       Figure 2. Contributions to Slowness, by Decile of Speed

                  60


                  48
Speed in months




                  36


                  24


                  12


                  0
                          Fastest decile      3rd decile         Middle 10 percent      8th decile   Slowest decile



                                           Journal         Author(s)         Accept to Publication




                                                             9
                          Figure 3. Average Citations/year by Rounds of Submissions

                 16


                 14


                 12


                 10
Citations/year




                 8


                 6


                 4


                 2


                 0
                      0      1       2           3           4         5   6   7
                                             Year post-publication

                                      2 Rounds   3 Rounds   4 Rounds




                                                     10
