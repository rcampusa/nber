                                NBER WORKING PAPER SERIES




                    CHOICE PROBABILITY GENERATING FUNCTIONS

                                         Mogens Fosgerau
                                        Daniel L. McFadden
                                         Michel Bierlaire

                                        Working Paper 17970
                                http://www.nber.org/papers/w17970


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                      April 2012




We are grateful for comments from Rosa Matzkin, Richard Blundell and the participants at the Conference
on Demand Analysis and Welfare Measurement held in London, 2011. The views expressed herein
are those of the authors and do not necessarily reflect the views of the National Bureau of Economic
Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2012 by Mogens Fosgerau, Daniel L. McFadden, and Michel Bierlaire. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including © notice, is given to the source.
Choice Probability Generating Functions
Mogens Fosgerau, Daniel L. McFadden, and Michel Bierlaire
NBER Working Paper No. 17970
April 2012
JEL No. C25,D11

                                             ABSTRACT

This paper considers discrete choice, with choice probabilities coming from maximization of preferences
from a random utility field perturbed by additive location shifters (ARUM). Any ARUM can be characterized
by a choice-probability generating function (CPGF) whose gradient gives the choice probabilities,
and every CPGF is consistent with an ARUM. We relate CPGF to multivariate extreme value distributions,
and review and extend methods for constructing CPGF for applications.


Mogens Fosgerau                                     Michel Bierlaire
Technical University of Denmark                     EPFL ENAC INTER TRANSP-OR
Bygningstorvet 116B                                 GC B3 454 (Bâtiment GC) Station 18
Building , room 115C                                CH-1015 Lausanne Switzerland
2800 Kgs. Lyngby                                    michel.bierlaire@epfl.ch
Denmark
mf@transport.dtu.dk

Daniel L. McFadden
University of California, Berkeley
Department of Economics
549 Evans Hall #3880
Berkeley, CA 94720-3880
and NBER
mcfadden@econ.berkeley.edu
        Choice Probability Generating Functions∗
    Mogens Fosgerau†               Daniel McFadden‡                Michel Bierlaire§
                                   March 16, 2012


                     Draft. Do not distribute without permission

                                         Abstract

This paper considers discrete choice, with choice probabilities coming from max-
imization of preferences from a random utility field perturbed by additive location
shifters (ARUM). Any ARUM can be characterized by a choice-probability gen-
erating function (CPGF) whose gradient gives the choice probabilities, and ev-
ery CPGF is consistent with an ARUM. We relate CPGF to multivariate extreme
value distributions, and review and extend methods for constructing CPGF for
applications. The choice probabilities of any ARUM may be approximated by a
cross-nested logit model. The results for ARUM are extended to competing risk
survival models.
Keywords: additive random utility; discrete choice; choice probability generating
functions
JEL codes: D11, C25


1       Introduction
This paper considers decision-makers who make discrete choices that are draws
from a multinomial choice probability vector indexed by the alternatives in a finite
    ∗
      We are grateful for comments from Rosa Matzkin, Richard Blundell and the participants at
the Conference on Demand Analysis and Welfare Measurement held in London, 2011.
    †
      Technical University of Denmark, Centre for Transport Studies, Sweden and Ecole Normale
Supèrieure. mf@transport.dtu.dk
    ‡
      Econometrics Laboratory, University of California, Berkeley
    §
      Transport and Mobility Laboratory, School of Architecture, Civil and Environmental Engi-
neering, Ecole Polytechnique Fédérale de Lausanne , michel.bierlaire@epfl.ch


                                              1
choice set. A random utility model (RUM) associates a vector of random (from the
analyst’s viewpoint) utilities with the choice set alternatives, and postulates that
the choices of decision-makers maximize utility. If the distribution of the util-
ity vectors is absolutely continuous, then it induces a unique multinomial choice
probability vector. This paper is concerned with determining necessary and suffi-
cient conditions for a vector of choice probabilities to be consistent with a RUM.
This question is answered in conventional revealed preference theory (Samuelson,
1947; Houthakker, 1950; Richter, 1966) for choice sets that are economic budget
sets, and in the theory of stochastic revealed preference for finite choice sets (Mc-
Fadden and Richter, 1990; McFadden, 2005). This paper adds to this literature by
showing that a multinomial choice probability vector is consistent with a RUM if
and only if it is the gradient of a choice probability generating function (CPGF)
with specified properties that can be checked in applications. This is the analogue
for discrete choice and the random utility model of the Antonelli et al. (1886) con-
ditions in conventional economic demand analysis; see, for example, Mas-Colell
et al. (1995, 3H).
    In Section 2, we consider multinomial choice probability vectors derived by
maximization of a random utility model (RUM), show that they can be obtained
as gradients (with respect to perturbation parameters) of choice probability gener-
ating functions (CPGF), and establish a necessary and sufficient characterization
of CPGF that can be checked in applications. The key step is to embed the base
RUM in an additive random utility model (ARUM), a random preference field in
which a vector of perturbations shifts the location of the random utility vector.
Mathematically, the CPGF is a transform of a multivariate probability distribu-
tion that is related to a multivariate Laplace transform, and retains exactly those
aspects of the distribution of utilities that are relevant for choice probabilities.
    Section 3 considers the special case of RUM based on multivariate extreme
value (MEV) distributions. We define the exponent (EXP) of a multivariate CDF,
and show that the EXP has the properties of a CPGF if and only if the distribution
of utilities is multivariate extreme value (MEV). Rules are given that allow expo-
nents to be combined into new exponents. This allows the combination of MEV
distributions into new MEV distributions. The associated copulas may be viewed
as generalizations of the Archimedian copula.

                                         2
    The mapping from MEV distributions to EXP is many-to-one, and MEV dis-
tributions that generate observationally distinct ARUM, and hence distinct CPGF,
can have the same EXP. Therefore, even though the EXP of a specific MEV distri-
bution has the properties of a CPGF, it may not be the CPGF associated with this
particular MEV distribution. However, if a MEV that generates a particular EXP
satisfies an additional condition termed cross-alternative max-stability (CAMS),
then this MEV has marginal distributions that are extreme value type 1 distributed,
and a CPGF that coincides with the EXP. Put another way, if EXP is the exponent
of a MEV distribution, then there is another MEV distribution, not necessarily
observationally equivalent, that has extreme value type 1 marginals and the same
exponent EXP, and EXP is its CPGF. The family of CAMS MEV induce ARUM
that include the multinomial logit model, as well as generalizations such as the
nested logit model and the cross-nested logit model. This paper shows that the
choice probabilities of every ARUM may be approximated by a cross-nested logit
model. This shows that even though the set of ARUM from CAMS MEV is a
strict subset of all ARUM, it is in a sense dense in the set of all ARUM.
    Section 4 extends some results relating CPGF and MEV to multiple risk sur-
vival models. Multiple risk survival models are similar to RUM, with duration
and cause of exit playing roles analogous to utility and choice. A difference is
that durations are positive and the smallest duration is observed, while utility has
no sign restriction and is not observed. The paper extends to the case of multiple
risk survival models the main results relating CPGF and MEV to RUM. Section 5
concludes the paper. Table 1 summarizes the acronyms used. All proofs are given
in the Appendix.


2    Random Utility Models for Finite Choice Sets
Suppose decision-makers face a finite set of alternatives indexed by a choice set
C = {1, . . . , J}. Decision-makers and alternatives may be described by explana-
tory variables, and the dependence of utilities on these variables may have struc-
ture derived from assumptions of economic rationality. We suppress these for the
current discussion, and reintroduce them later. We also initially suppress notation
for mixing of RUM. We consider utility to be random from our perspective.

                                         3
        Acronym Definition
        ARUM    Additive Random Utility Model (additive location shifts)
        ASM     Additive Survival Model
        ASP     Alternating Signs Property
        CAMS    Cross-Alternative Max-Stabilty
        CPGF    Choice Probability Generating Function
        EXP     Exponent of a multivariate distribution
        MEV     Multivariate Extreme Value distribution
        RUM     Random Utility Model
        SM      Survival Model
        TARUM Transformed Additive Random Utility Model
                                Table 1: Acronyms

Notation Let σ = (σ(1), . . . , σ(J)) denote a permutation of (1, ..., J), and let
σ : k = (σ(1), . . . , σ(k)) denote the first k elements of σ. Let

                                         ∂ k F (u1 , . . . , uJ )
                         ∇σ:k F (u) ≡
                                         ∂uσ(1) · · · ∂uσ(k)

denote the mixed partial derivatives of a real-valued function F on RJ with respect
to the variables in σ : k. Similarly, denote

                                         ∂ J F (u1 , . . . , uJ )
                        ∇1...J F (u) ≡                            .
                                             ∂u1 · · · ∂uJ



Definition 1 A random utility model (RUM) is a vector U = (U1 , . . . , UJ ) of
latent random variables in RJ , with a Cumulative Distribution Function (CDF)
R(u1 , . . . , uJ ) that is absolutely continuous with respect to Lebesgue measure,
and has a density given by ∇1...J R(u1 , . . . , uJ ). A RUM induces an observable
choice probability
                                                      Z   +∞
(1)      PC (j) = Pr(Uj > Uk for j 6= k ∈ C) =                 ∇j R(u, . . . , u) du,
                                                        −∞


where
                                               ∂R
                        ∇j R(u, . . . , u) ≡       (u, . . . , u).
                                               ∂uj

                                          4
Remark The definition of a RUM ensures that for any σ and k = 1, ..., J, the
derivative ∇σ:k R(u1 , . . . , uJ ) exists almost everywhere and is non-negative. It en-
sures for each j that the marginal CDF R(j) (uj ) = R(+∞, . . . , +∞, uj , +∞, . . . , +∞)
is absolutely continuous on R. It also ensures that the probability of ties is zero;
     PJ
i.e.    j=1 PC (j) = 1. The RUM definition does not exclude zero probability
alternatives.


2.1    Embedding and Observational Equivalence
For any continuously differentiable increasing transformation r : R → R, which
may be stochastic, the image r(U ) ≡ (r(U1 ), . . . , r(UJ )) of a RUM U = (U1 , . . . , UJ )
is again a RUM with the same associated choice probability. Then the family of
such increasing transformations of a RUM defines an observationally equivalent
class. A representative can always be chosen from this equivalence class that has
E|Uj | finite for all j. For example,

(2)                            Uj∗ = 1/(1 + exp(−Uj ))

has this property. Then, we will consider without loss of generality only RUM
representations that have finite means.

Definition 2 If U 0 = (U10 , . . . , UJ0 ) is a finite-mean RUM with CDF R(u1 , . . . , uJ ),
and choice probability PC0 (j), and m = (m1 , . . . , mJ ) ∈ RJ is a location vector,
then

(3)                          U = (U1 , . . . , UJ ) = m + U 0

is again a finite-mean RUM with CDF R(u1 − m1 , . . . , uJ − mJ ), and choice
probability

(4) PC (j|m) = Pr(Uj ≥ Uk for k ∈ C) = Pr(Uj0 + mj ≥ Uk0 + mk for k ∈ C).

A family of RUM with finite means indexed by location vectors m is termed an
additive random utility model (ARUM).


                                             5
Remark Obviously every RUM can be embedded in a ARUM, and recovered by
setting m = 0. Then, without loss of generality, we can represent a RUM as
an ARUM. Note that ARUM have been defined in previous literature as forms
Uj = mj + Uj0 that are the sum of a systematic component of utility mj and a
disturbance Uj0 . Our definition has the same mathematical structure, so that we
retain the name for this family, but we interpret the mj as location shifts from a
base RUM U 0 .
    If a random vector W = (W1 , . . . , WJ ) has an absolutely continuous CDF
R(w1 , . . . , wJ ) with marginal CDF’s R(j) (wj ), and zj = sj (wj ) is a continuously
differentiable increasing transformation with an (also continuously differentiable)
inverse wj = Sj (zj ), then Z = (Z1 , . . . , ZJ ) = (s1 (W1 ), . . . , sJ (WJ )) has a
CDF F (z1 , . . . , zJ ) = R(S1 (z1 ), . . . , SJ (zJ )), and conversely R(w1 , . . . , wJ ) =
F (s1 (w1 ), . . . , sJ (wJ )). The associated densities are related by

                                                                              J
                                                                              Y
(5)      ∇1...J R(w1 , . . . , wJ ) = ∇1...J F (s1 (w1 ), . . . , sJ (wJ ))         s0j (wj ),
                                                                              j=1


where the product in this expression is the Jacobian of the nonlinear transforma-
tion. In particular, the transformation Zj = rj (Wj ) ≡ ψ −1 (R(j) (Wj )), where
ψ is a continuously differentiable increasing univariate CDF whose support is a
bounded or unbounded interval Ψ ∈ R, defines a random vector Z ∈ ΨJ with a
CDF F (z1 , . . . , zJ ) whose univariate marginals are ψ(zj ) for each j. The transfor-
mation zj = sj (wj ) can in general depend on observed and stochastic variables,
and unknown parameters, and when this is the case, the probability statements
above are interpreted as conditioned on these factors.

Definition 3 A finite-mean family of RUM defined implicitly by εj = rj (Uj −
mj ), where rj is a continuously differentiable increasing transformation with a
continuously differentiable inverse, ε = (ε1 , . . . , εJ ) has an absolutely continuous
CDF F (ε), and m = (m1 , . . . , mJ ) is a location vector, is termed a finite-mean
transformed additive random utility model (TARUM).
    Define ζj ≡ rj−1 (εj ) and ζ = (ζ1 , . . . , ζJ ). Then Uj = mj + ζj is a finite-mean
ARUM with a CDF R(U −m) ≡ F (r(U −m)) that is absolutely continuous, with
r(U −m) = (r1 (U1 − m1 ), . . . , rJ (UJ − mJ )), and this ARUM is observationally

                                                6
equivalent to the TARUM.

Lemma 1 The choice probability associated with a TARUM satisfies

        PC (j) = Pr(Uj > Uk for j 6= k ∈ C)

                = Pr(rk (Uj − mk ) > rk (Uk − mk ) for j 6= k ∈ C)

(6)                 Z   +∞
                =            ∇j F (r1 (u − m1 ), . . . , rJ (u − mj ))rj0 (u − mj ) du
                      −∞

                    Z   +∞
                ≡            ∇j R(u − m1 , . . . , u − mJ ) du.
                      −∞


Remark Requiring that a representation of a RUM have finite mean implies that
the random vector ζ has a finite mean; this does not require that ε has a finite
mean. The primary interest in TARUM is that the nonlinear transformations rj can
absorb dependence of stochastic terms on explanatory variables and the effects of
heteroskedasticity, so that ε is clear of these application-specific effects. Suppose
an ARUM with an absolutely continuous CDF R(u1 − m1 , . . . , uJ − mJ ) and
marginal CDF’s R(j) , and define εj = rj (Uj − mj ) ≡ ψ −1 (R(j) (Uj − mj )),
where ψ is a continuous increasing univariate CDF. Then ε = (ε1 , . . . , εJ ) has
a CDF F (ε) with specified univariate marginals ψ. TARUM include Box-Cox
transformations such as

                        r(Ui − mi ) = 1 − e−λ(Ui −mi ) /λ,
                                                      


polynomials such as

                                          K
                                          X
                        r(Ui − mi ) =           ak (Ui − mi )2k−1
                                          k=1


with ak ≥ 0, and other transformations of location and scale, and r can also
be a function of observed explanatory variables and latent stochastic vectors that
capture taste heterogeneities.


                                            7
Remark In a TARUM εj = rj (Uj − mj ) where ε = (ε1 , . . . , εJ ) has a CDF F (ε),
choice probabilities PD (j|m) from a non-empty subset D of C are obtained by first
forming the marginal distribution of the components of ε associated with alterna-
tives in D, and then applying (6) using this distribution. Equivalently, PD (j|m) is
obtained from PC (j|m) by setting mk = −∞ for k 6∈ D.
    Together, the definitions and remarks above establish that every RUM has a
representation that can be embedded in an ARUM with finite mean, or an observa-
tionally equivalent TARUM whose univariate marginals are a specified continuous
increasing univariate CDF ψ.


2.2    Choice Probability Generating Functions
This section defines a class of choice-probability generating functions (CPGF)
with specific properties. The main result shows that every TARUM has an asso-
ciated CPGF whose first derivatives are the choice probabilities of the TARUM,
and conversely that every function with the specific properties is the CPGF as-
sociated with an ARUM. Thus, an observationally equivalent family of RUM are
fully characterized by an associated CPGF.

Definition 4 A function g on [0, +∞)J has the Alternating Signs Property (ASP)
if for any permutation σ of (1, . . . , J) and k = 1, . . . , J, the signed mixed deriva-
tives
                            (−1)k−1 ∇σ:k g(y1 , . . . , yJ )

exist, are independent of the order of differentiation, and are non-negative.

Definition 5 A choice-probability generating function (CPGF) is an extended
non-negative function G : [0, +∞]J → [0, +∞] with the properties:

[G1] (Weak ASP) ln G(y) satisfies the ASP, so that for any permutation σ of
     (1, . . . , J) and k = 1, . . . , J, its mixed partial derivatives are independent
     of the order of differentiation and

      (7)                 χσ:k (ln y) ≡ (−1)k−1 ∇σ:k ln G(y) ≥ 0.


                                           8
[G2] (Homogeneity) For each λ > 0 and y ∈ [0, +∞]J , G(λy) = λG(y).

[G3] (Boundary) G(0) = 0, and for j = 1, . . . , J, if 1(j) denotes a unit vector
     with the jth component equal to one, then

                                    lim G(λ1(j) ) → ∞.
                                   λ→∞


[G4] (Integrability) Let m = (m1 , . . . , mJ ), em = (em1 , . . . , emJ ), L = {m ∈
     RJ | Jj=1 mj = 0}. Then the following holds:
          P

                    Z
                         χ1,...,J (m)dm = J −1 ,
                     L

                    Z
                         |mj |χ1,...,J (m)dm < +∞, for j = 1, . . . , J,
                     L


                    max mk − mj → ∞ implies χj (m) → 0.
                     k6=j



Remark The gradient PC (j|m) = ∂ ln G(em )/∂mj ≡ χj (m) is the choice proba-
bility generated by the CPGF G, with [G1] and [G2] ensuring that the probability
is non-negative and sums to one. An implication of [G2] is that

                              χσ:k (m − c) ≡ χσ:k (m)

for any scalar c.
     If D is a non-empty subset of C, then its CPGF is obtained from G by setting
its arguments to zero for alternatives that are not in D.
     If G is a CPGF, then from [G1],

(8)                     ∂ 2 ln G(em )/∂mj ∂mk ≤ 0 for j 6= k.
                                           PJ
From [G2] and Euler’s theorem, one has        j=1   ∂ ln G(em )/∂mj ≡ 1, implying
                                                    X
(9) ∂PC (j|m)/∂mj = ∂ 2 ln G(em )/∂m2j = −                 ∂ 2 ln G(em )/∂mj ∂mk ≥ 0.
                                                    k6=j




                                          9
Then, the hessian of ln G(em ) has a weakly dominant positive diagonal, implying
that ln G(em ) is a convex function of m.
Examples of CPGF The linear function

                                                 J
                                                 X
                                           m
(10)                                G(e ) =            emj ,
                                                 j=1


satisfies [G1]–[G4] and generates the logit model. The function

                                 J X
                                 X
(11)                  m
                  G(e ) =                  αjk (eµjk mj + eµjk mk )1/µjk ,
                                 j=1 k>j


with αjk ≥ 0 and µjk ≥ 1 satisfies [G1]–[G4] and generates cross-nested logit
models. However, if µjk < 1 for some j, k in the last function, then G fails to
satisfy [G1].

Theorem 1 If εj = rj (Uj −mj ) is a finite-mean TARUM in which ε = (ε1 , . . . , εJ )
has CDF F (ε) and U = (U1 , . . . , UJ ) has finite mean, and an observation-
ally equivalent ARUM is Uj = mj + ζj with ζ = (ζ1 , . . . , ζJ ) having CDF
R(ζ) ≡ F (r(U − m)), where r(U − m) = (r1 (U1 − m1 ), . . . , rJ (UJ − mJ )),
then an associated CPGF G(em ) defined by

               ln G(em ) ≡ E[maxj∈C Uj ]
(12)                 Z     +∞                             Z    0
                 ≡              [1 − R(u − m)]du −                 R(u − m)du
                       0                                   −∞


exists and satisfies [G1]-[G4]. The choice probability implied by the TARUM
satisfies

(13)         PC (j|m) = Pr(Uj > Uk for k 6= j) = ∂ ln G(em )/∂mj .

Conversely, if G is a function satisfying properties [G1]-[G4], then there exists an
ARUM such that G is an associated CPGF and (13) holds.



                                               10
    Since ARUM-consistent choice probabilities are obtained from a gradient of a
CPGF, the properties of choice probabilities with this property are easily derived
from the properties [G1]-[G4] of a CPGF. Further, it is straightforward to show
that these specific properties of choice probabilities are sufficient for ARUM-
consistency by integrating back to obtain the associated CPGF. The following
corollary gives this result.

Corollary 1 A choice probability PC (j|m) on C = {1, . . . , J} is consistent with
a finite-mean TARUM if and only if it is non-negative, sums to one, and satisfies

[CP1] For j 6= k, ∂PC (j|m)/∂mk = ∂PC (k|m)/∂mj , and for every k = 1, . . . , J−
     1 and permutation σ with σ(J) = j, so that σ : k excludes j,

                                              ∂ k PC (j|m)
      (14)                     (−1)k                               ≥ 0.
                                        ∂mσ(1) ∂mσ(2) . . . ∂mσ(k)

[CP2] PC (j|m − c) = PC (j|m) for every scalar c.

[CP3] If maxk6=j mk − mj → +∞, then PC (j|m) → 0.
                                   PJ
[CP4] Let L = {m ∈ RJ |             j=1    mj = 0}. Then

                                             ∂ J−1 PC (j|m)
                   Z
      (15)              (−1)J−1                                    dm = J −1
                    L              ∂m1 . . . ∂mj−1 ∂mj+1 . . . ∂mJ

      and for j = 1, . . . , J,

                                                     ∂ J−1 PC (j|m)
                               Z
                         J−1
      (16)       (−1)              |mj |                                   dm < +∞.
                               L           ∂m1 . . . ∂mj−1 ∂mj+1 . . . ∂mJ


Prior literature: McFadden (1981) proves a theorem, attributed to Williams
(1977) and Daly and Zachary (1978), that utilizes an economic argument to estab-
lish necessary and sufficient conditions under which RUM models with additive
income terms in their utilities can be characterized equivalently in terms of a so-
cial surplus function whose gradient gives the choice probabilities. Theorem 1 and
Corollary 1 use related arguments with location parameters m in place of income,


                                                 11
and obtain similar but more complete results, without restrictive economic condi-
tions on utility. Papers that deal with the relationship between characterization of
choice models and integrability conditions in economic demand theory are Bates
(2003), Ibáñez (2007), Ibáñez and Batley (2008), Koning and Ridder (2003), and
McFadden (2005). Papers that deal with choice-probability generating functions
for nested logit and what econometricians term generalized extreme value models
are McFadden (1978), Daly and Bierlaire (2006) and Bierlaire et al. (2008). A
paper that considers mixing of choice models is McFadden and Train (2000).


2.3    Mixing of CPGF
Suppose a TARUM εj = rj (Uj − mj , α) in which ε = (ε1 , . . . , εJ ) has CDF
F (ε) and α is a latent mixing vector, independent of ε, with density K(α). The
usual interpretation of α is that it indexes the tastes of heterogeneous consumers.
Let G(em , α) denote the CPGF, which is measurable as a function of α, and
PC (j|m, α) = ∂G(em , α)/∂mj the choice probability associated with the TARUM
given α. Then there is an observationally equivalent mixed ARUM Uj = mj +
ζj with ζ having a CDF R(ζ|α) given α, or an unconditional CDF R(ζ) =
R
  R(ζ|α)K( dα). The associated choice probabilities are the corresponding mix-
                   R
tures PC (j|m) = PC (j|m, α)K( dα); these are obviously RUM-consistent. A
simple sum log formula gives the CPGF for this mixed model:
                                    Z
                              m
(17)                   ln G(e ) =       ln G(em , α)K( dα).

It has a gradient that gives the mixed choice probabilities. It is easy to verify
that a mixture of logs of functions G(em , α) that satisfy [G1]-[G4] is the log of a
function that again satisfies these conditions, and hence is a CPGF for the mixed
model. This result can be used together with the results of McFadden and Train
(2000) that every regular RUM can be approximated as closely as one pleases by
some mixture of logit models (or other base models such as independent probit);
the corresponding sumlog mixture of the CPGF for the base model will give the
RUM-consistent CPGF corresponding to the approximating probabilities.




                                         12
2.4    Economic Variables and Economic Rationality
Suppose consumers are rational economic decision-makers that seek maximum
utility through discrete and continuous consumption choices. Let j ∈ C de-
note the set of discrete alternatives, and tj denote the cost of alternative j. Let
x ∈ X denote a continuous consumption vector, and let p denote a correspond-
ing price vector. Let y denote income. Then, the consumer with a utility func-
tion u(x, j) will solve maxj∈C maxx∈X u(x, j) subject to the budget constraint
p0 x ≤ y − tj , where the right-hand-side is the consumer s discretionary income
after paying for discrete alternative j. The solution to the inner maximization,
Uj (p, y − tj ) = maxx∈X {u(x, j)|p0 x ≤ y − tj }, is termed indirect utility con-
ditioned on j. The indirect utility function is homogeneous of degree zero and
quasiconvex in (p, y − tj ), increasing in y − tj , and non-increasing in p, and any
function with these properties induces a utility function u(x, j) = inf p Uj (p, p0 x)
for which Uj is the associated indirect utility function; cf. Diewert (1974), Mc-
Fadden (1974),Varian (1993, Sect. 7.2). The indirect utility Uj may vary over
a population due to heterogeneity in tastes, and in addition to its dependence on
(p, y − tj ), it may depend on other variables Xj that include attributes of the dis-
crete alternative and factors that influence tastes, such as age and family size. The
economic rationality requirement of consumer sovereignty, under which tastes are
determined and invariant with respect to the economic budget the consumer faces,
requires that any latent taste factors in Uj have distributions that are independent
of the budget (p, y − tj ). In a well-specified economically rational TARUM, this
corresponds to a specification εj = rj (Uj − mj , p, y − tj , Xj ) in which the vector
of random taste factors ε = (ε1 , . . . , εJ ) has CDF F (ε) that is independent of
(p, y − tj ). For this TARUM to define an indirect utility function satisfying the
homogeneity, quasiconvexity, and monotonicity requirements of economic ratio-
nality, rj (Uj − mj , p, y − tj , Xj ) must be increasing in Uj − mj , homogeneous of
degree zero and quasiconcave in (p, y − tj ), non-decreasing in p, and decreasing
in y.
    Our specification of economically rational TARUM in which the location pa-
rameters mj are independent of economic variables appears incompatible with
the common practice of introducing dependence on income and prices through a


                                         13
“systematic” utility component mj . However, the TARUM transformation rj may
include an additional quasiconcave function of discretionary income and prices
that is additive to mj and plays the conventional role. For example, the transfor-
mation

(18) rj (Uj − mj , p, y − tj , Xj , α) =
                 ν(Uj − mj − [(y − tj )/a(p)]1−η /(1 − η) + bj (p, Xj , α)/a(p))

with ν an increasing transformation, a(p) and bj (p, Xj , α) concave linear homo-
geneous nondecreasing functions of p, η 6= 1 a positive parameter, and α a latent
stochastic taste factor, defines a useful class of indirect utility functions, called
the generalized Gorman preference field (Gorman, 1953), that allow discrete re-
sponses to depend on income level and on the prices of continuous goods.


3     RUM with Multivariate Extreme Value Distributed
      Utility

3.1    Multivariate Extreme Value Distributions
The logit, nested logit, and cross-nested logit choice probabilities that have been
important for applications are consistent with finite-mean RUM that have multi-
variate extreme value (MEV) distributions; see McFadden (1974) and McFadden
(1978). In this section, we summarize selected results from the statistical theory
of MEV distributions that allow us to relate MEV-RUM families to the general
characterization of finite-mean RUM-consistent CPGF and choice probabilities
given in Theorem 1 and its corollary.

Definition 6 If F (ε) is an absolutely continuous CDF on RJ with univariate
marginals F(j) (εj ), and copula

                                             −1                  −1
                   C(u1 , . . . , uJ ) = F (F(1) (u1 ), . . . , F(J) (uJ ))




                                             14
on [0, 1]J , define the function A : [0, +∞]J → [0, +∞] by

(19)                A(y1 , . . . , yJ ) ≡ − ln C(e−y1 , . . . , e−yJ ),

and term A the exponent of C or equivalently of F ; then

(20)                  C(u1 , . . . , uJ ) = e−A(− ln u1 ,...,− ln uJ )

and

(21)                  F (ε) = e−A(− ln F(1) (ε1 ),...,− ln F(J) (εJ )) .

Remark The exponent of a multivariate CDF is not in general an associated
CPGF, but we will later establish an equivalence that when F is a multivariate
extreme value distribution then A is in fact a CPGF, satisfying the conditions
[G1]-[G4] and generating the choice probabilities for a TARUM based on F . The
exponent of a multivariate distribution is determined solely by its copula, inde-
pendent of its univariate marginals. Hence, the mapping from multivariate distri-
butions to exponents is many-to-one, with the inverse image of a given exponent
being the family of all multivariate distributions with the same copula and various
univariate marginals.
   The following mathematical results will be used to obtain the features of the
exponent of a CDF, and its relation to CPGF.

Definition 7 A real-valued function ψ of a scalar t is completely monotonic if, for
k = 1, 2, . . . ,

(22)                         (−1)k−1 ∂ k ψ(t)/∂tk ≥ 0.

Examples of completely monotonic functions (see Miller and Samko, 2001) are:

   • ln(α + βt), with α + βt > 0 and β > 0;

   • tα , with t ≥ 0 and 0 ≤ α ≤ 1;

   • −e−αt , with α ≥ 0;

                                             15
   • −1/t, with t < 0.

Lemma 2 If a real-valued function g on [0, +∞)J satisfies ASP from Definition 4,
and if ψ is completely monotonic on a domain that includes the range of g, then
ψ(g) satisfies ASP.

Corollary 2 If A : [0, +∞]J → [0, +∞] satisfies ASP, then

   • ln A satisfies ASP;

   • αA satisfies ASP if α > 0;

   • Aα satisfies ASP if 0 < α ≤ 1;

Corollary 3 If A1 : [0, +∞]J → [0, +∞] and A2 : [0, +∞]J → [0, +∞] satisfies
ASP, then

   • αA1 + βA2 satisfies ASP if α, β ≥ 0;

   • A1 A2 satisfies ASP;

Lemma 3 If A : [0, +∞]J → [0, +∞] is the exponent of an absolutely continuous
CDF F (ε), then A satisfies [G3], and satisfies ASP and therefore [G1].

                                    √        √
Remark The function G(y1 , y2 ) = y1 + 2y2 2y1 + y2 satisfies [G1] (i.e., ASP
for ln G), but not ASP for G. Then, ASP for G is strictly stronger than [G1].

Definition 8 Let ε ∈ RJ be a random vector with CDF F (ε) and let mn ≡
W            W                  W
  k≤n εk = ( k≤n εk1 , . . . , k≤n εkJ ) be the component-wise maximum of inde-
pendent draws ε1 , . . . , εn from F . Then ε is location/scale max-stable if there are
location and scale parameter vectors, µ(n) and σ(n) respectively, such that the
CDF of mn is F ((mn1 − µ1 (n))/σ1 (n), . . . , (mnJ − µJ (n))/σJ (n)).

Definition 9 The generalized extreme value (GEV) distribution has CDF
                                                 − 1 !
                                               ε−µ ξ
                   H(ε; ξ, µ, σ) = exp − 1 + ξ           ,
                                                σ  +


                                          16
where σ > 0, [x]+ = max(x, 0) and H(ε; 0, µ, σ) = limξ→0 H(ε; ξ, µ, σ) =
exp − exp − ε−µ      . H is max-stable since, for λ > 0, µ(λ) = (1 − λξ ) ξµ−σ
                  
                σ                                                           ξ
               ξ
and σ(λ) = λ , with limits µ(λ) = σ ln λ and σ(λ) = 1 as ξ → 0, satisfy
H(ε; ξ, µ, σ) = H ε−µ(λ)
             λ
                       σ(λ)
                            ; ξ, µ, σ .

Remark By the Fisher - Tippet - Gnedenko theorem, any max-stable univariate
distribution belongs to the GEV family (Joe, 1997). The distribution H(ε; 0, µ, σ)
is known as the type 1 extreme value (EV1) or Gumbel distribution, which has
mean µ + σγ, where γ is Euler’s constant. When ξ > 0, H(ε; ξ, µ, σ) is called
type 2 extreme value or Fréchet. When ξ < 0, H(ε; ξ, µ, σ) is called type 3
extreme value or reverse Weibull.


Definition 10 Let ε ∈ RJ be a random vector with CDF F (ε). Then ε is termed
multivariate extreme value (MEV) if it is location/scale max-stable. The univariate
marginals of a MEV distribution must be in the GEV family just defined.1

    A max-stable CDF F (ε1 , . . . , εJ ) must then satisfy

                F (ε1 , . . . , εJ )λ ≡
                                                                       λ
(23)               1 ; ξ1 , µ1 , σ1 ), . . . , H(εJ ; ξJ , µJ , σJ )) ≡
                C(H(ε                                                                         
                       ε1 −µ1 (λ)
                C H      σ1 (λ)
                                   ; ξ1 , µ1 , σ1 ), . . . , H( εJσ−µ  J (λ)
                                                                    J (λ)
                                                                             ; ξJ , µJ , σJ        ≡
                C(H(ε1 ; ξ1 , µ1 , σ1 )λ , . . . , H(εJ ; ξJ , µJ , σJ )λ ).

    This demonstrates the following result:

Lemma 4 (Joe, 1997) F (ε1 , . . . , εJ ) is a MEV distribution if and only if its copula
C satisfies the homogeneity condition

(24)                          C(u1 , . . . , uJ )λ = C(uλ1 , . . . , uλJ )
    1
      We follow the statistics literature in naming the univariate family H(ε; ξ, µ, σ) the general-
ized extreme value (GEV) distribution; the econometrics literature often uses the term GEV for
MEV distributions. Characterization of univariate max-stable distributions dates to Fisher and
Tippett (1928), Gnedenko (1943), and Gumbel (1958); see also Johnson et al. (1995). Joe (1997)
and Coles (2001) give detailed treatments of multivariate max-stable distributions. When trans-
formations other than location and scale are allowed, the family of max-stable distributions has
additional members; see Sreehari (2009).


                                                   17
for u ∈ [0, 1]J and λ > 0.

Remark If C(u1 , . . . , uJ ) is the copula of any multivariate CDF F (ε1 , . . . , εJ ),
then other multivariate distributions with the same copula can be obtained by sub-
stituting different univariate marginal distributions into the copula. In particular,
if C is the copula of a MEV distribution F (ε1 , . . . , εJ ), so that C has the homo-
geneity property in Lemma 4, then
                                                −ε                −ε
                                                                      
                     F ∗ (ε1 , . . . , εJ ) = C e−e 1 , . . . , e−e J

is a MEV distribution with the same copula and EV1 univariate marginals with
location parameters zero and scale parameters 1. We will term these MEV1 distri-
butions.
    Combined with the definition (19) of the exponent of a distribution, Lemma 4
gives the following result:

Lemma 5 If A : [0, +∞]J → [0, +∞] is the exponent of an absolutely continuous
CDF F (ε), then A satisfies [G2] if and only if F is max-stable.

   Not all multivariate max-stable distributions have the property that vectors of
cross-alternative maxima are max-stable. For example, F (ε1 , ε2 ) = H(ε1 ; 0, 0, 1)H(ε2 ; 0, 0, 2)
implies that M = max(ε1 , ε2 ) has the CDF Pr(M ≤ m) = exp(−e−m − e−m/2 ),
which is not a max-stable distribution.

Definition 11 A multivariate max-stable distribution F (ε1 , . . . , εJ ) is cross-alternative
max-stable (CAMS) if for every j, k, max(εj + mj , εk + mk ) is max-stable for all
location-shift parameters mj , mk .

    The following result gives the condition under which max-stability is pre-
served under cross-alternative maximization.

Lemma 6 Suppose F (ε1 , . . . , εJ ) is max-stable. F is CAMS if and only if the
univariate marginals of F are EV1 with a common scale parameter σ.




                                            18
Remark Thus any MEV1 distribution is CAMS. As noted in a previous remark,
a MEV1 distribution can be created from the copula of any MEV distribution
together with EV1 univariate marginals with a common scale parameter.
   The following functions are examples of MEV exponents.
               P             1δ
                         δ
   • A (y) =        j∈C yj          for δ ≥ 1.

   •                                                    "                #− 1δ
                                    X                       X
                  A (y) =                  (−1)|T |+1             yi−δ           , 0 ≤ δ ≤ ∞.
                                    T ⊆C                    i∈T


More examples are known, some are indicated in Joe (1997).


3.2    CPGF and CAMS MEV
We will show that a random utility model characterized by an ARUM Uj = mj +ζj
with a CDF R(ζ1 , . . . , ζJ ), or an observationally equivalent TARUM, has a CPGF
given by the exponent of R if and only if R is a CAMS MEV. If R is MEV but
not CAMS, then its exponent is a CPGF for another ARUM, not observationally
equivalent, that is CAMS with the same copula. We state the conditions on a
CPGF, or on a choice probability, that are necessary and sufficient for them to be
associated with a cross-alternative max-stable ARUM. We tie these results to the
analysis by McFadden (1978) and Smith (1984) of choice probabilities derivable
from “generalized extreme value” models.
    The following two assumptions are stronger than the parallel assumptions [G1]
and [CP1], and are used to establish that a candidate CPGF G : [0, +∞]J →
[0, +∞], or a choice probability PC (j|m), is consistent with a CAMS ARUM:

[G1*] (Strong ASP) G(y) satisfies ASP.

[CP1*] For j 6= k, ∂PC (j|m)/∂mk = ∂PC (k|m)/∂mj . For k = 1, . . . , J − 1
     and permutation σ satisfying σ(J) = j, the test functions Tσ:k (m), defined
     recursively by

         • Tσ(1) (m) = PC (j|m) and,


                                                   19
          • for k > 1, Tσ:k+1 (m) = Tσ:k (m)Tσ(k+1) (m) + ∂Tσ:k (m)/∂mk+1 ,

       satisfy
                                    (−1)k−1 Tσ:k (m) ≥ 0.

Theorem 2 Suppose A : [0, +∞]J → [0, +∞] is the exponent of a multivariate
CDF R(ζ1 , . . . , ζJ ). Then, A satisfies [G3], and [G1*] and hence [G1]. Second,
A satisfies [G2] if and only if R(ζ1 , . . . , ζJ ) is MEV. Third, A is a CPGF for the
ARUM Uj = mj +ζj with a MEV CDF R(ζ1 , . . . , ζJ ) if and only if R(ζ1 , . . . , ζJ ) is
CAMS, but any A satisfying [G1*], [G2], and [G3] is a CPGF for an ARUM Uj =
mj +νj with the CAMS MEV R̃(ν1 , . . . , νJ ) = exp(−A(exp(−ν1 ), . . . , exp(−νJ ))).
In these results, [G4] is implied by [G1*], [G2], and [G3]. In general, the ARUM
Uj = mj + ζj and Uj = mj + νj are not observationally equivalent.

Remark Suppose R is a CDF corresponding to a RUM and that R is MEV. By
the remarks in Section 2.1, this has a representation that is embedded in an ob-
servationally equivalent TARUM with EV1 marginals. This TARUM is MEV and
hence it is also CAMS MEV.
    If one requires cross-alternative max-stability in the presence of scale shifts
rather than location shifts, one finds that Weibull univariate marginals with a com-
mon shape parameter ξ < 0 and location parameter µ = 0 are CAMS for the
family of scale shifts. This does not create a new family of ARUM and CPGF, as
one is obtained from the other by a log transformation of utility. This is utilized
in section 4 on survival models.


Lemma 7 [CP1*] for the choice probability PC (j|m) implies [G1*] for the func-
tion
                         J Z
                         X       mj
                   m
(25)        ln G(e ) =                  PC (j|m1 , . . . , mj−1 , zj , 0, ..., 0) dzj ,
                          j=1   zj =0


and implies [CP1].

Lemma 8 (Smith, 1984) If a choice probability PC (j|m) satisfies [CP1*], [CP2],



                                               20
and [CP3], then it is consistent with an ARUM Uj = mj +νj with the CAMS MEV

                  R(ν1 , . . . , νJ ) = exp −G e−ν1 , . . . , e−νJ
                                                                     
                                                                          ,

with G given by (25).

Prior literature Building on Strauss (1979) and Robertson and Strauss (1981),
Lindberg et al. (1995) discuss ARUM that have the property of invariance of
achieved utility (IAU). This property states that the distribution of utility con-
ditional on choosing alternative j is independent of j. They show that this class
of models coincides with the class of models where the CDF of utility has the
form F (x) = φ(G(exp(−x))), where G satisfies [G2] (homogeneity). See also
de Palma and Kilani (2007)
Remark It is straightforward to establish that the CPGF corresponding to such
a distribution is in fact G, that G satisfies strong ASP, and that any ARUM with
the IAU property is observationally equivalent to a CAMS ARUM. Admissible
functions φ may be constructed as Laplace transforms of random variables, see
Joe (1997, pp. 204). In this case, F may be viewed as a power mixture of a
MEV distribution or equivalently as the distribution obtained from adding the
same random variable to all utilities in a MEV distribution. This has no effect on
choice probabilities. In the converse direction, one may use that a function ψ on
[0, ∞[ is the Laplace transform of a random variable if and only if ψ is completely
monotonic and ψ(0) = 0 (Nelsen, 2006, Lemma 4.6.5). The copula corresponding
to F (x) = φ(G(exp(−x))) is φ(G(φ−1 (u))). The case G (y) = y1 + ... + yJ
corresponds to the Archimedean copula (Nelsen, 2006). In the case of a general
CPGF G, the corresponding copula may thus be called a generalized Archimedean
copula.


3.3   An Approximation Result
This section establishes a constructive way to approximate any ARUM by a cer-
tain type of MEV ARUM. It is known that any RUM may be approximated arbi-
trarily well by a MEV model. This section will show that the choice probabilities


                                          21
of any ARUM, Ui = mi + εi , may be approximated arbitrarily well by the choice
probabilities of a MEV model from the nested logit family, for m in a compact set.
In fact, the approximating type of model is a cross-nested logit model (Vovsha,
1997; Bierlaire, 2006). The proof of this combines a theorem by Dagsvik (1995)
and its proof with the following Lemma.
Lemma 9 Let µ be a finite measure on RJ . Let {gk } by a finite set of continuous
and µ−integrable functions from RJ to R. Let K ⊂ RJ be a compact set. Then
                              N       N
for all δ > 0 there exist wnN n=1 , xNn n=1 such that for every k and for every
m∈K
                Z                      N
                                       X
                                          wnN gk xN
                                                           
                   gk (x − m) µ (dx) −             n −m       < δ.
                                        n=1
    We shall now review Theorem 1 in Dagsvik (1995). Dagsvik’s theorem ap-
plies to general random utility. Here we specialize the result to the additive case
Ui = mi + εi , where ε follows some general multivariate distribution with CDF
F. This means that the mapping from m to the CDF of U is continuous. The cor-
responding choice probabilities are P F (j|m). Dagsvik assumes that there exists
a small ā > 0 such that 0 < Eeaεj < ∞ for any j and any 0 < a < ā.
    Dagsvik defines MEV (and calls it GEV) from functions A that satisfy lim-
its and strong signs but a−homogeneity and not just 1-homogeneity. The de-
gree of homogeneity is not important for us, as a MEV ARUM based on an
a−homogeneous A is observationally equivalent to a MEV ARUM based on A1/a ,
which is 1-homogeneous. Then Dagsvik proves the following theorem.
Theorem 3 (Dagsvik, 1995) For any compact K and for any δ > 0 there exists a
MEV model with corresponding CDF F̃ (u − m) such that

                        sup P F̃ (j|m) − P F (j|m) < δ.
                       m∈K


    The proof works by constructing a MEV model that tends to the true model
at any m ∈ K. Since K is compact, convergence is uniform over K. The MEV
CDF is constructed as follows.
                                                        !a2
                                                            
                                         
                                  X        mk + εk − zk
             F̃ (z) = exp −E        exp                     
                                   k
                                                a

                                        22
and the corresponding choice probabilities are
                              
                                      mj +εj     P               mk +εk
                                                                            a2 −1 
                            E exp       a               k   exp     a
(26)         P F̃ (j|m) =                                            a2               .
                                            P               mk +εk
                                      E         k exp         a


This expression tends to P F (j|m) as a tends to 0. Combining this with Lemma
9 is sufficient to prove the following theorem.

Theorem 4 For any compact K and for any δ > 0 there exists a MEV model with
corresponding CDF F̂ (u − m) such that

                        sup P F̂ (j|m) − P F (j|m) < δ.
                        m∈K


The approximating model is a cross-nested logit.


Remark The model has the following associated MEV CPGF:
                  
                    N
                                                              !!a2  a1
             m
                   X              X          mk +       xN
                                                         nj
         A (e ) =    wnN             exp                               , 0 < a < 1.
                     n=1          k
                                                a




4      Multiple Risk Survival Models
There is a close connection between random utility models and multiple risk sur-
vival models. This section explores this link.

Definition 12 A survival model (SM) is a vector exp (−ε) = exp (−ε1 , ..., −εJ )
of positive latent durations in RJ where ε has an absolutely continuous CDF
R and E |ε| < ∞. The minimum duration exp (−ε0 ) = minj exp (−εj ) is ob-
served and induces an observable survival function S (t) = P (exp (−ε0 ) > t) =
R (− ln t, ..., − ln t) .

   When ε0 = εj , say that exit occurs for the j 0 th cause. The cause is considered
observable in some applications.

                                            23
    As in the RUM, the CDF R of latent durations may depend on observed and
unobserved covariates. This notation is suppressed in the following. The CDF R
is not identified in general without further assumptions (Kalbfleisch and Prentice,
2002). This motivates the following definition.

Definition 13 If exp (−ε) = exp (−ε1 , ..., −εJ ) is a SM and m ∈ RJ is a location
vector, then t = exp (− (m + ε)) , where the minimum duration T0 = minj Tj
is observed, is again a SM with survival function S (t|m) = R (− (m + ln t)) .
A family of SM indexed by the location vector m is termed an additive survival
model (ASM). Note that R is now identified from S(t|m) since R(−m) = S(1|m).

Remark These models may also be termed multivariate accelerated failure time
models (Kalbfleisch and Prentice, 2002).

Theorem 5 If t = exp (− (m + ε)) is an ASM, then an associated CPGF defined
by

(27)                       ln G (em ) = −E (ln T0 |m)

exists and satisfies properties [G1]-[G4]. The probability of exit for cause j is
given by

                                         ∂ ln G (em )
(28)                         P (j|m) =                .
                                             ∂mj

Conversely, if G is a function satisfying properties [G1]-[G4], then there exists a
ASM such that (27) and (28) hold.

Definition 14 An ASM has an exponential survival function if the hazard does not
depend on t. The ASM is termed exponential in this case. The ASM has propor-
tional hazard if the hazard factors as λ(t|m) = A (em ) λ0 (t).

Theorem 6 Consider an ASM t = exp(−(m+ε)) with CPGF G (em ) = exp (−E (ln T0 |m)) .
Then ε is CAMS MEV if and only if the ASM is exponential. In this case, the haz-
ard A (em ) is equal to the CPGF A (em ) = G (em ) .

Theorem 7 Any proportional hazard ASM is exponential.

                                         24
5    Conclusion
This paper has contributed by completely characterizing the relationship between
RUM and CPGF without imposing structure on utility. Furthermore, the paper has
contributed by completely characterizing the subset of MEV ARUM in terms of
CPGF and also the further subset of CAMS MEV ARUM in terms of CPGF. The
subset of CAMS MEV ARUM consisting of cross-nested logit models is dense
in the set of all RUM. The main results are extended to the case of multiple risk
survival models. The present results generalize and subsume a range of previous
contributions.


References
Antonelli, G., Chipman, H. and Hurwicz, L. (1886) Sulla Teoria Matematica
  della Economia Politica Preferences, Utility, and Demand Harcourt-Brace-
  Jovanovich New York.

Bates, J. (2003) Economic evaluation and transport modelling: theory and prac-
  tice in K. W. Axhausen (ed.), Moving through nets: the physical and social
  dimensions of travel Elsevier.

Bierlaire, M. (2006) A theoretical analysis of the cross-nested Logit model Annals
  of Operations Research 144(1), 287–300.

Bierlaire, M., Bolduc, D. and McFadden, D. (2008) The estimation of generalized
  extreme value models from choice-based samples Transportation Research Part
  B: Methodological 42(4), 381–394.

Coles, S. (2001) An introduction to statistical modeling of extreme values Springer
  Series in Statistics.

Dagsvik, J. (1995) How large is the class of generalized extreme value random
  utility models? Journal of Mathematical Psychology 39(1), 90–98.

Daly, A. and Bierlaire, M. (2006) A general and operational representation of


                                        25
  Generalised Extreme Value models Transportation Research Part B: Method-
  ological 40(4), 285–305.

Daly, A. and Zachary, S. (1978) Improved multiple choice models in D. Hen-
  sher and Q. Dalvi (eds), Identifying and Measuring the Determinants of Mode
  Choice Teakfields London.

de Palma, A. and Kilani, K. (2007) Invariance of conditional maximum utility
  Journal of Economic Theory 132(1), 137–146.

Diewert, E. (1974) Applications of Duality Theory in M. Intriligator and
  D. Kendrick (eds), Frontiers of Quantitative Economics North Holland Ams-
  terdam.

Fisher, R. A. and Tippett, L. H. C. (1928) Limiting forms of the frequency distri-
  bution of the largest or smallest member of a sample Mathematical Proceedings
  of the Cambridge Philosophical Society 24, 180–190.

Gnedenko, B. (1943) Sur La Distribution Limite Du Terme Maximum D’Une
  Série Aléatoire The Annals of Mathematics 44(3), 423–453.

Gorman, W. M. (1953) Community Preference Fields Econometrica 21(1), 63–80.

Gumbel, E. (1958) Statistics of Extremes Columbia University Press New York.

Houthakker, H. (1950) Revealed Preference and the Utility Function Economica
  17, 159–174.

Ibáñez, N. (2007) On the compatibility of probabilistic choice systems with ran-
   dom utility maximization ITS, University of Leeds Working paper 592.

Ibáñez, N. and Batley, R. P. (2008) On the integrability conditions for discrete
   travel choice.

Joe, H. (1997) Multivariate Models and Dependence Concepts Chapman & Hall
  London.

Johnson, N., Kotz, S. and Balakrishnan, N. (1995) Continuous univariate distri-
  butions Vol. 2 2nd. edn John Wiley New York.

                                       26
Kalbfleisch, J. D. and Prentice, R. L. (2002) The Statistical analysis of failure time
  data Wiley Series in probability and statistics 2nd. edn Wiley Hoboken, New
  Jersey.

Koning, R. and Ridder, G. (2003) Discrete Choice and Stochastic Utility Maxi-
  mization Econometrics Journal 6, 1–27.

Lindberg, P. O., Eriksson, E. A. and Mattsson, L.-G. (1995) Invariance of acheived
  utility in random utility models Environment & Planning A 27(1), 121–142.

Mas-Colell, A., Whinston, M. and Green, J. (1995) Microeconomic Theory Ox-
 ford Press Oxford.

McFadden, D. (1974) The measurement of urban travel demand Journal of Public
 Economics 3(4), 303–328.

McFadden, D. (1978) Modelling the choice of residential location in A. Karlquist
 (ed.), Spatial Interaction Theory and Planning Models North Holland Amster-
 dam chapter 25, pp. 75–96.

McFadden, D. (1981) Econometric Models of Probabilistic Choice in C. Manski
 and D. McFadden (eds), Structural Analysis of Discrete Data with Econometric
 Applications MIT Press Cambridge, MA, USA chapter 5, pp. 198–272.

McFadden, D. L. (2005) Revealed stochastic preference: a synthesis Economic
 Theory 26(2), 245–264.

McFadden, D. L. and Richter, M. (1990) Stochastic Rationality and Revealed
 Stochastic Preference in J. Chipman, D. L. McFadden and M. Richter (eds),
 Preferences, Uncertainty, and Optimality: Essays in honor of Leonid Hurwicz
 Westview Press Boulder and Oxford pp. 161–186.

McFadden, D. and Train, K. (2000) Mixed MNL Models for discrete response
 Journal of Applied Econometrics 15, 447–470.

Miller, K. S. and Samko, S. G. (2001) Completely monotonic functions In-
 tegr.Transf.and Spec.Funct. 12(4), 389–402.


                                         27
Nelsen, R. B. (2006) An introduction to copulas Springer Series in Statistics 2
  edn.

Richter, M. (1966) Revealed Preference Theory Econometrica 34, 635–645.

Robertson, C. A. and Strauss, D. (1981) A characterization theorem for random
  utility variables Journal of Mathematical Psychology 23(2), 184–189.

Samuelson, P. (1947) Foundations of Economic Analysis Harvard Press Cam-
  bridge.

Smith, T. E. (1984) A choice probability characterization of generalized extreme
  value models Applied Mathematics and Computation 14(1), 35–62.

Sreehari, M. (2009) General max-stable laws Extremes 12(2), 187–200.

Strauss, D. (1979) Some results on random utility models Journal of Mathemati-
  cal Psychology 20(1), 35–52.

Varian, H. (1993) Microeconomic Analysis Norton New York.

Vovsha, P. (1997) Application of a Cross-Nested Logit model to mode choice in
  Tel Aviv, Israel, Metropolitan Area Transportation Research Record 1607, 6–
  15.

Williams, H. C. W. L. (1977) On the Formulation of Travel Demand Models and
 Economic Evaluation Measures of User Benefit Environment & Planning A
 9(3), 285–344.



A     Proofs

A.1    Random Utility Models for Finite Choice Sets
Proof of Lemma 1. Given the absolutely continuous CDF F (ε) of ε = (ε1 , . . . , εJ )
with density ∇1...J F (ε), the density of U is ∇1...J F (r(u − m)) Jj=1 rj0 (uj − mj ).
                                                                  Q

Then


                                         28
   PC (j) = Pr(Uj > Uk for j 6= k ∈ C)

                Z   +∞     Z   uj          Z   uj         Z    uj                 Z   uj
            =                        ···                                    ···
                  uj =−∞    u1 =−∞         uj−1 =−∞           uj+1 =−∞            uJ =−∞


                                                                    J
                                                                    Y
                                    ∇1...J F (r(u − m))                   rj0 (uj − mj ) du1 . . . duJ
                                                                    j=1

                Z   +∞
            =              ∇j F (r1 (uj − m1 ), . . . , rJ (uj − mJ ))rj0 (uj − mj ) duj .
                  uj =−∞


By definition, R(ζ) ≡ F (r(ζ)), so that ∇j R(ζ) ≡ ∇j F (r(ζ))rj0 (ζj ). Then,

  Z   +∞
            ∇j F (r1 (uj − m1 ), . . . , rJ (uj − mJ ))rj0 (uj − mj ) duj =
   uj =−∞
                                                     Z   +∞
                                                               ∇j R(u − m1 , . . . , u − mJ ) du.
                                                         −∞




Proof of Theorem 1. Consider first sufficiency. Assume that εj = rj (Uj − mj )
is a TARUM and ε = (ε1 , . . . , εJ ) has CDF F (ε). Let Uj = mj + ζj with ζ =
(ζ1 , . . . , ζJ ) having CDF R(ζ) be an observationally equivalent ARUM.
     Consider [G1]: The requirement that the TARUM have finite mean utility
implies that UC = maxj∈C Uj has E|UC | ≤ Jj=1 E|Uj | < ∞. Then ln G(em ) ≡
                                               P

E[UC ] exists. Then, integrating by parts,
(29)                               Z      +∞
           m
   ln G(e ) ≡ E[UC |m] =                       u[dR(u − m)/du]du
                                      −∞

                                     Z    +∞                                      Z   0
                                =              [1 − R(u − m)]du −                          R(u − m)du,
                                      0                                               −∞




                                                    29
and (12) holds. Differentiating (29) with respect to mj yields
                                            Z   +∞
                   m
(30)      ∂ ln G(e )/∂mj =                           ∇j R(u − m1 , . . . , u − mJ )du,
                                             −∞


and from (6), the result (13) holds.
     Mixed differentiation of ln G for any permutation σ of (1, . . . , J) and k =
1, . . . , J gives

           χσ:k (m) = (−1)k−1 ∂ k ln G(em )/∂mσ(1) . . . ∂mσ(k)
(31)                             Z    +∞
                         =                 ∇σ:k R(u − m1 , . . . , u − mJ )du ≥ 0.
                                     −∞


Hence, [G1] holds.
   Consider [G2]: If λ > 0, then
(32)               Z     +∞                                           Z    0
          m
  ln G(λe ) =                 [1 − R(u − ln λ − m)]du −                        R(u − ln λ − m)du
                     0                                                    −∞

                   Z     +∞                                 Z    − ln λ
               =              [1 − R(u − m)]du −                          R(u − m)du
                     − ln λ                                   −∞

                                 Z    +∞                              Z    0
               = ln λ +                    [1 − R(u − m)]du −                  R(u − m)du
                                  0                                       −∞


               = ln λ + ln G(em ),

implying that G(y) is homogeneous of degree one on y ≡ em ≥ 0 and [G2] holds.
Letting λ = exp(−c) for any scalar c, (32) implies

                                       χj (m) ≡ χj (m − c).

   Consider [G3]. From (29),
                          Z      +∞                          Z   0
          ln G(1(j) ) =               [1 − R(j) (u)]du −             R(j) (u)du = E[ζj ]
                             0                                  −∞



                                                     30
is finite, so that G(1(j) ) > 0, implying with [G2] that

                                   lim G(λ1(j) ) → ∞.
                                   λ→∞


[G2] also implies G(0) = 0. Hence, [G3] holds.
   Consider [G4]. First, suppose

                                w = max mk − m1 → ∞.
                                      k>1


Then,
(33)               √
               Z       w
 χ1 (m) =                  ∇1 R(u, u − m2 + m1 , . . . , u − mJ + m1 ) du
                u=−∞

                                                Z   +∞
                                            +     √
                                                         ∇1 R(u, u − m2 + m1 , . . . , u − mJ + m1 ) du
                                                u= w

                   √
               Z       w          √                     √
          ≤                ∇1 R(u, w − m2 + m1 , . . . , w − mJ + m1 ) du
                u=−∞

                                                                        Z   +∞
                                                                    +     √
                                                                                 ∇1 R(u, +∞, . . . , ∞) du
                                                                        u= w

              √ √                      √                       √
          ≤ R( w, w − m2 + m1 , . . . , w − mJ + m1 ) + [1 − R( w, +∞, . . . , +∞)]

                             √                                √
          ≤ R(+∞, . . . , +∞, w − w, +∞, . . . , +∞) + [1 − R( w, +∞, . . . , +∞)]
          → 0 as w → +∞.

Since this argument holds for any permutation of (1, . . . , J), the last property in
[G4] holds.
   From (31),
(34)                                  Z +∞
                        J        m
                  J−1 ∂ ln G(e )
  χσ:J (m) ≡ (−1)                   =       ∇1...J R(u − m1 , . . . , u − mj )du.
                      ∂m1 . . . ∂mJ    −∞




                                            31
Then
          Z                       Z Z          +∞
(35)              χσ:J (m)dm =                      ∇1...J R(u − m1 , . . . , u − mJ )dudm.
              L                       L     −∞


Make the linear transformation

(36)                     (ζ1 , ζ2 , . . . , ζJ ) = (u, m2 , . . . , mJ )A,

with
                                                                    !
                                                      1     10J−1
(37)                              A=                                    ,
                                                1J−1       −IJ−1

and note that
                                                                             !
                            −1        −1                       0     00J−1
(38)                    A        =J        1J 10J   +                            ,
                                                           0J−1     −IJ−1

and det A = (−1)J−1 J. Substitute this transformation in (35), noting that the
Jacobian is J, and obtain
          Z                                Z   +∞
                                  −1
(39)           χσ:J (m)dm = J                        ∇1...J R(ζ1 , . . . , ζJ )dζ1 . . . dζJ = J −1 .
           L                                −∞


For j = 1, . . . , J, the finite mean property for R(ζ) implies
(40)
 Z                              Z Z        +∞
      |mj |χσ:J (m)dm =                         |mj |∇1...J R(u − m1 , . . . , u − mJ )dudm
  L                               L       −∞

                                       Z       +∞
                                  −1
                            = J                     |ζj − 10 ζ/J| ∇1...J R(ζ1 , . . . , ζJ )dζ1 . . . dζJ < +∞.
                                           −∞


This completes the demonstration of [G4].
    Next, the converse proposition in the theorem will be proved. Assume that
G(em ) is a function satisfying properties [G1]-[G4]. Let χσ:J (m) be the mixed
derivative of ln G(em ) from (7), and let η be any continuous density on R with
a finite mean. Consider an ARUM Uj = mj + ζj in which ζ = (ζ1 , . . . , ζJ ) is

                                                      32
assigned the candidate density

(41)                      ρ(ζ) = η(10 ζ/J)χσ:J (10 ζ/J − ζ) ≥ 0.

    Transform from (ζ1 , . . . , ζJ ) to (u, v2 , . . . , vJ ), where u = 10 ζ/J and vj =
10 ζ/J − ζj = u − ζj for j = 1, . . . , J. Note that this is just the inverse of the linear
transformation (36), and that its Jacobian is 1/J. Then,

                                                      J
                                                      X
(42)                                      v1 = −            vj
                                                      j=2


and
        Z   +∞                                        Z   +∞                Z
(43)             ρ(ζ1 , . . . , ζJ )dζ1 . . . dζJ =              η(u)du               Jχσ:J (v)dv = 1
          −∞                                              u=−∞              v∈L


by [G4], establishing that ρ is a density. Further, by the finite mean property of η
and [G4],
                                                Z     +∞                    Z
            Eζ |ζj | = Eu,v |u − vj | ≤                     |u|η(u)du                 Jχσ:J (v)dv
                                                  u=−∞                          v∈L

                                                      Z   +∞            Z
(44)
                                                +              η(u)du            |vj |Jχσ:J (v)dv
                                                      −∞                  v∈L


                                           < +∞,

so that this density has a finite mean. Let R(ζ) denote the CDF for the density ρ.
The ARUM Uj = mj + ζj then has the choice probability




                                                 33
(45) PC (1|m) = Pr(U1 ≥ Uk for k = 2, . . . , J)
                    Z +∞
                  =        ∇1 R(u − m1 , . . . , u − mJ )du
                      −∞
          Z +∞ Z u−m2      Z u−mJ
       =               ···        ρ(u − m1 , ζ2 , . . . , ζJ )dudζ2 . . . dζJ
                 u=−∞ ζ2 =−∞                  ζJ =−∞
            Z   +∞ Z m2                 Z   mJ
 [a] =                            ···             ρ(u − m1 , u − z2 , . . . , u − zJ )dudz2 . . . dzJ
            u=−∞         z2 =+∞         zJ =+∞
                                                                              J
                                                                                        !
                     Z   +∞   Z    m2            Z mJ                        X
                 =                           ···        η u − (m1 +              zj )/J
                      u=−∞        z2 =+∞          zJ =+∞                    j=2

                       χσ:J (m1 − u, z2 − u, . . . , zJ − u)dudz2 . . . dzJ
        Z   +∞    Z      +∞     Z +∞
[b] =                       ···         η(w)(−1)J−1 χσ:J (m1 , z2 , . . . , zJ )dwdz2 . . . dzJ
         w=−∞        z2 =m2      z =m
                                Z J+∞ J
                         [c] =          η(w)dw χ1 (m1 , m2 , . . . , mJ )
                                    w=−∞

                                                                             = ∂ ln G(em )/∂m1 ,

where in [a] we use the transformation zj = u − ζj for j = 2, . . . , J; in [b] we use
the transformation w = u − (m1 + Jj=2 zj )/J; and in [c] we use the condition
                                     P

from [G4] that χ1 (z) is zero when any component of (z2 , . . . , zJ ) equals +∞.
Note that the density η introduces a factor that is common to all utilities and has
no effect on the choice probabilities. The result above holds for any permutation
of the indices. Thus, G(em ) is a choice-probability generating function for the
ARUM Uj = mj + ζj , completing the proof of the theorem.

Proof of Corollary 1. Given a finite-mean TARUM, let G be an associated
CPGF. Properties [G1]-[G4] of G, translated to statements about PC (j|m) =
∂G(em )/∂mj , become properties [CP1]-[CP4]. Then, by the theorem, [CP1]-
[CP4] are necessary for RUM-consistent choice probabilities.
   Conversely, given a choice probability PC (j|m) satisfying [CP1]-[CP4], de-




                                                       34
fine a candidate CPGF by

                           J Z
                           X         mj
                   m
(46)          ln G(e ) =                    PC (j|m1 , . . . , mj−1 , zj , 0, . . . , 0)dzj .
                           j=1    zj =0


Then, using the symmetry condition in [CP1]
(47)
 ∂ ln G(em )/∂mk = PC (k|m1 , . . . , mk , 0, . . . , 0)

                                 J Z            mj
                                 X                   ∂PC (j|m1 , . . . , mj−1 , zj , 0, . . . , 0)
                           +                                                                       dzj
                               j=k+1        zj =0                      ∂mk


                       = PC (k|m1 , . . . , mk , 0, . . . , 0)

                                 J Z            mj
                                 X                   ∂PC (k|m1 , . . . , mj−1 , zj , 0, . . . , 0)
                           +                                                                       dzj
                               j=k+1        zj =0                      ∂mj


                       = PC (k|m1 , . . . , mk , 0, . . . , 0)

                                 J
                                 X
                           +               [PC (k|m1 , . . . , mj−1 , mj , 0, . . . , 0)−PC (k|m1 , . . . , mj−1 , 0, 0, . . . , 0)]
                               j=k+1



                       = PC (k|m1 , . . . , mk , . . . , mJ ).

Then G generates the given choice probability. The proof is completed by showing
that G defined by (46) satisfies [G1]-[G4]. The argument above establishes that
χj (m) ≡ PC (j|m) ≥ 0. Then [CP1] implies [G1]. From (47),

        J                      K                                           J
        X ∂ ln G(em )          X
                                           mk            m         m
                                                                           X
                           =           e        ∇k G(e )/G(e ) =                 PC (k|m) = 1,
        k=1
                 ∂mk           k=1                                         k=1


implying that
                               J
                               X                ∂G(em )
                                       emk              = G(em ),
                                 k=1
                                                 ∂mk


                                                      35
and hence by Euler’s theorem that G satisfies [G2]. Conditions [G3] and [G4] fol-
low from [CP3] and [CP4] by noting that χj (m) ≡ PC (j|m). Then, the candidate
CPGF G satisfies [G1]-[G4] and generates the given choice probability.


A.2     RUM with MEV Distributed Utility
Proof of Lemma 2. A mixed derivative of ψ(g) can be written in terms of mixed
derivatives of g as

                            k
                            X                          X
(48)     ∇σ:k ψ(g(y)) =           ψ (i) (g(y))                           ∇a1 g(y) . . . ∇ai g(y),
                            i=1                  (a1 ,...,ai )∈Aiσ
                                                                     k



where ψ (i) (t) = ∂ i ψ(t)/∂ti and Aiσ:k is the set of all partitions of (σ(1), . . . , σ(k))
into i non-empty subvectors. This formula can be verified by induction. The ASP
follows by induction, since differentiation of a term in (48) leads to new terms, all
having the opposite sign of the original term.

Proof of Lemma 2. From Lemma 2 and the fact that ψ(t) = ln(t), ψ(t) = αt
and ψ(t) = tα are completely monotonic for t > 0.

Proof of Lemma 3. The results comes from Lemma 2 and the properties of
completely monotonic (c.m.) functions that a linear combination of c.m. func-
tions with non-negative multipliers is also c.m., and that the product of two c.m.
functions is also c.m.

Proof of Lemma 3. Consider the construction A(y) = − ln C(e−y ). Computa-
tion shows that −C(e−y ) satisfies ASP, that ψ1 (t) = −1/t is completely mono-
tonic for t < 0, and that ψ2 (t) = ln t is completely monotonic for t > 0. Then by
Lemma 2, the composition A(y) = ψ2 (ψ1 (−C(e−y )) satisfies ASP. Then, Corol-
lary 2 implies that ln A(y) satisfies ASP, and hence [G1]. The boundary condi-
tions C(1) = 1 and C(u1 , . . . , uj−1 , 0, uj+1 , . . . , uJ ) = 0 for each j imply that A
satisfies [G3].

Proof of Lemma 5. A(y) = − ln C(e−y ) implies A(λy) = − ln C (e−y )λ =
                                                                    

− ln C(e−y )λ = λA(y).

                                                 36
Proof of Lemma 6. If the univariate marginals of F are all EV1 with common
scale parameter σ, Lemma 5 gives
                           
(49)    Pr max(εj + mj ) ≤ m =
              j≤J
                                 −(m−µ1 −m1 )/σ ,...,e−(m−µJ −mJ )/σ
                          e−A(e                                        )=
                                                            −m/σ A
                                                        e−e            (e(µ1 +m1 )/σ ,...,e(µJ +mJ )/σ ) ,


and the cross-alternative maxima are EV1 distributed with mean

                       σ ln A e(µ1 +m1 )/σ , . . . , e(µJ +mJ )/σ + σγ.
                                                                 


Conversely, if max(εj + mj , εk + mk ) is max-stable, then for some max-stable
univariate distribution H(ε; ξ, µ, σ),

(50)    Pr (max(εj + mj , εk + mk ) ≤ m) =
       e−A(+∞,...,∞,− ln H(m−mj ;ξj ,µj ,σj ),+∞,...,+∞,− ln H(m−mk ;ξk ,µk ,σk ),+∞,...,+∞)
                                                                                ≡ H(m; ξ; µ; σ).

The homogeneity of A implies that

            0 ≡ A (+∞, . . . , ∞, Lj , +∞, . . . , +∞, Lk , +∞, . . . , +∞) ,

with
                                    H(m; ξ; µ; σ)
                        Li = ln                             , i = j, k.
                                  H(m − mi ; ξi , µi , σi )
   The first finite argument of A is independent of m for more than one value of
mj if and only if ξ = ξj = 0 and σ = σj . Since A is increasing in each of its finite
arguments for some range of location shifts, both arguments must be independent
of m, requiring that ξ = ξj = ξk = 0 and σk = σj .

Proof of Theorem 2. Lemma 3 establishes that the exponent of R satisfies [G3],
[G1*], and hence [G1]. Lemma 5 establishes that A satisfies [G2] if and only if
R is MEV. Lemma 6 establishes that A is a CPGF for the ARUM Uj = mj + ζj


                                                37
with a MEV CDF R(ζ1 , . . . , ζJ ) if and only if R(ζ1 , . . . , ζJ ) is CAMS. McFad-
den (1978) proves that if A satisfies [G1*], [G2], and [G3], then it is a CPGF for
the ARUM Uj = mj + νj with the CAMS MEV distribution R(ν1 , . . . , νJ ) =
exp(−A(exp(−ν1 ), . . . , exp(−νJ ))). Since the CAMS MEV distribution has fi-
nite means, [G4] is implied by the first part of Theorem 1.

Proof of Lemma 7. Using the symmetry condition in [CP1*], (25) implies


 ∂ ln G(em )
             = PC (k|m1 , . . . , mk , 0, . . . , 0)
     ∂mk
                                                               J Z     mj
                                                               X              ∂PC (j|m1 , . . . , mj−1 , zj , 0, . . . , 0)
                                                          +                                                                 dzj
                                                              j=k+1   zj =0                     ∂mk
                = PC (k|m1 , . . . , mk , 0, . . . , 0)
                                                              J Z      mj
                                                              X               ∂PC (k|m1 , . . . , mj−1 , zj , 0, . . . , 0)
                                                          +                                                                 dzj
                                                              j=k+1   zj =0                     ∂mj
                = PC (k|m1 , . . . , mk , 0, . . . , 0)
                      XJ
                  +      [PC (k|m1 , . . . , mj−1 , mj , 0, . . . , 0) − PC (k|m1 , . . . , mj−1 , 0, 0, . . . , 0)]
                       j=k+1
                = PC (k|m1 , . . . , mJ ).

Apply the derivative formula (48) to g(y) = ln G(y) and ψ(t) = et to obtain

                              k
            ∇σ:k G(y) X                 X
(51)                 =                                  ∇a1 ln G(y) · · · ∇ai ln G(y).
             G(y)      i=1        (a1 ,...,ai )∈Aiσ:k


Differentiate this expression with respect to yσ(k+1) to obtain the recursion

           ∇σ:k+1 G(y)   ∇σ:k G(y) ∇σ(k+1) G(y) ∂∇σ:k G(y)/∂yσ(k+1)
(52)                   =                       +                    .
              G(y)        G(y)        G(y)             G(y)

Substitute y = em in (52) for each k, multiply this expression by exp(mσ(1) +
· · · + mσ(k) ), and name it Tσ:k (m).Then (52) becomes the recursion Tσ:k+1 (m) =
Tσ:k (m)Tσ(k+1) (m) + ∂Tσ:k (m)/∂mk+1 in [CP1*]. The construction of G gives
Tσ(1) (m) = PC (σ(1)|m). Then, the condition (−1)k−1 Tσ:k (m) ≥ 0 in [CP1*]


                                                  38
and the equality

            exp(mσ(1) + · · · + mσ(k) )∇σ:k G(em )/G(em ) = Tσ:k (m)

implies [G1*]. By Lemma (2), [G1*] implies [G1], and [G1] and the condition
∂ ln G(em )/∂mj = PC (j|m) establish [CP1].

Proof of Lemma 9. Consider m ∈ N and divide RJ into cubes Cnm with sides
of length 2−m . Choose a point xm                            m          m
                                   n in each cube and let wn = µ (Cn ). This
construction does not depend on gk and m.
    Define gkm (x) = gk (xm               m
                           n ) when x ∈ Cn and note that gk is the pointwise limit
of gkm since gk is continuous. Let g = sup{gk (x)|k, x ∈ K} < ∞ and note that
R
  gµ(dx) < ∞. Then by the Lebesgue dominated convergence theorem
                                Z
                       ∞ >      gk (x − m) µ (dx)
                                   Z
                            = lim     gkm (x − m) µ (dx)
                              m→∞
                                   X
                            = lim      wnm gk (xm
                                                n)
                                m→∞
                                        n
                                                 N
                                                 X
                            =    lim lim                 wnm gk (xm
                                                                  n)
                                m→∞ N →∞
                                                 n


   This shows that N
                  P       N      N
                                                R
                     n=1 wn gk xn − m tends to      gk (x − m) µ (dx) for every
                               R
k and for every m. Moreover, gk (x − m) µ (dx) is continuous in m. Then
convergence is uniform over the compact set {1, .., k} × K, which proves the
Lemma.

Proof of Theorem 4. For each j, the numerator and the denominator of (26) can
be approximated arbitrarily well by finite sums using Lemma 9. The approxima-
tions all use the same weights and mass points xN n . The approximation then has
the form
                                       m       N
                                                      P                             a2 −1
                       PN    N              j +xnj                           mk +xN
                        n=1 wn   exp                               exp            nk
                                             a                 k                a
        P F̂ (j|m) =                         P                             a2                .
                                PN       N                         mk +xN
                                    n=1 wn               exp            nk
                                                     k                a


                                            39
                      P        mk +εk −zk
                                          a2
    The function E       k exp     a
                                               is positive and bounded away from
zero on K. Hence P F̂ (j|m) may be made arbitrarily close to P F̃ (j|m) by choos-
ing N sufficiently large.


A.3    Multiple Risk Survival Models
Proof of Theorem 5. Let t = exp (− (m + ε)) be an ASM. Then

                   −E (ln T0 |m) = −E min (− (mj + εj ))
                                               j
                                     = E max (mj + εj ) .

By Theorem 1, this exists and is a CPGF satisfying [G1]-[G4] with exit probabil-
ities satisfying (28).
    Conversely, let G satisfy [G1]-[G4]. Then by Theorem 1 there exists an
ARUM m + ε such that G is an associated CPGF. From this define an ASM
by t = exp (− (m + ε)) . This ASM satisfies (27) and (28).

Proof of Theorem 6. In case ε is CAMS MEV then the survival function is
S (t|m) = exp (−G (exp (m + log t))) = exp (−tG (em )) which is an exponen-
tial survival function. The hazard rate is given by − ∂ ln S(t|m)
                                                           ∂t
                                                                  = G (em ) , which
does not depend on t.
     Conversely, assume that the ASM is exponential with constant hazard given
                                                                     
by A (em ) . Note that S (t|m) = S (1|m + ln t) = exp −A em+ln t , such that
S (t|m) = exp (−A (tem )) = exp (−tA (em )) . Now,

                    R (m) = S (1| − m) = exp −A e−m
                                                              
                                                                   ,

with univariate marginals R(j) (mj ) = exp (−e−mj A (0, ..., 0, 1, 0, ..., 0)) and in-
verses
                 −1
                R(j) (yj ) = ln A (0, ..., 0, 1, 0, ..., 0) − ln (− ln yj )




                                         40
such that R has copula
                               −1                   −1
                                                         
           C (y) = exp −A e−R(1) (y1 ) , ..., e−R(J) (yJ )
                                                                     
                               − ln y1                   − ln yJ
                 = exp −A                      , ...,                     .
                            A (1, 0, ..., 0)          A (0, ..., 0, 1)

  Finally, note that C is max-stable such that Lemma 4 implies that R is CAMS
MEV and has the form R(m) = exp (−G (e−m )) . Hence A (e−m ) = G (e−m ).


Proof of Theorem 7.         Let t = exp(−(m + ε)) be the ASM and let R be
the CDF of ε. Write the survivor function P (T0 ≥ et ) = R(−(t + m)) =
exp (−A (em ) Λ0 (et )) . Then the integrated hazard A (em ) Λ0 (et ) satisfies

                    A (em ) Λ0 (es ) Λ0 et = A (em ) Λ0 es+t .
                                                           


This implies that Λ0 (es ) Λ0 (et ) = Λ0 (es+t ), which in turn implies that Λ0 (et ) =
et , such that the hazard is constant.




                                          41
