                              NBER WORKING PAPER SERIES




      CAN INNOVATORS BE CREATED? EXPERIMENTAL EVIDENCE FROM AN
                         INNOVATION CONTEST

                                     Joshua S. Graff Zivin
                                       Elizabeth Lyons

                                      Working Paper 24339
                              http://www.nber.org/papers/w24339


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                    February 2018




We thank participants at the May, 2016 Innovation Growth Lab Research Meeting and those at
the 5th AIEA-NBER conference. We gratefully acknowledge funding support from the Kauffman
Foundation and the National Science Foundation through its SciSIP Program (Award
SBE-1460344). This study is included in the AEA RCT Registry (AEARCTR-0001857). The
views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2018 by Joshua S. Graff Zivin and Elizabeth Lyons. All rights reserved. Short sections of text,
not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.
Can Innovators be Created? Experimental Evidence from an Innovation Contest
Joshua S. Graff Zivin and Elizabeth Lyons
NBER Working Paper No. 24339
February 2018
JEL No. J24,M54,O32

                                          ABSTRACT

Existing theories and empirical research on how innovation occurs largely assume that
innovativeness is an inherent characteristic of the individual and that people with this innate
ability select into jobs that require it. In this paper, we investigate whether people who do not
self-select into being innovators can be induced to innovate, and whether they innovate
differently than those who do self-select into innovating. To test these questions, we designed and
implemented an innovation contest for engineering and computer science students which allowed
us to differentiate between those who self-select into innovative activities and those who are
willing to undertake them only after receiving an additional incentive for doing so. We also
randomly offer encouragement to subsets of both the induced and self-selected contest
participants in order to examine the importance of confidence-building interventions on each
sample. We find that while induced participants have different observable characteristics than
those that were ‘innately’ drawn to the competition, on average, the success of induced
participants was statistically indistinguishable from their self-selected counterparts and
encouragement does not change this result. Heterogeneity in treatment effects suggests an
important role for the use of targeted interventions.


Joshua S. Graff Zivin
University of California, San Diego
9500 Gilman Drive, MC 0519
La Jolla, CA 92093-0519
and NBER
jgraffzivin@ucsd.edu

Elizabeth Lyons
School of Global Policy and Strategy
University of California, San Diego
9500 Gilman Drive, MC 0519
La Jolla, CA 92093-0519
lizlyons@ucsd.edu
1     Introduction

Innovation has long been viewed as important for productivity and income growth (Grossman and Helpman,

1994; Solow, 1957). Therefore, understanding the conditions under which productivity enhancing innovation

occurs is critical for understanding economic development more generally. Recent research has examined

incentive design for encouraging appropriate levels of experimentation (Azoulay et al., 2011; Ederer and

Manso, 2011; Holmstrom, 1989), how governments may be able to increase innovative activity through trade
and immigration policy (Grossman and Helpman, 1990; Oettl and Agrawal, 2008), and how intellectual

property policy can provide incentives to innovate and learn from others (Scotchmer, 1991). While these

studies provide important evidence on tools to increase innovative output, they all implicitly assume that

the population of innovators is fixed and, thus, that eﬀorts to increase innovation should be directed at these

existing innovators.1

     In this paper, we use a randomized control trial (RCT) to explore the validity of this assumption. More

specifically, we examine whether successfully innovating requires an innate predisposition by testing whether

people who do not self-select into being innovators can be induced to innovate, and whether they innovate

diﬀerently than those who do self-select into innovating. In particular, our study allows us to address three

inter-related questions:


    1. Is the desire to innovate innate or is it suﬃciently pliable that it can be induced?
    2. Are induced innovators less able to innovate than those who naturally gravitate to innovative activities?

    3. What is the impact of encouragement on the performance of innovators, and does this diﬀer between
       innate and induced innovators?


     Understanding whether innovators can be created, and how they fare relative to those who self-select

into innovative activities, has important implications for public and private policy. Should innovation policy

and strategy limit its attention to optimizing conditions for the workforce already engaged in that space or

might they be better served by designing institutions and incentives to lure more individuals into the fray?
If incumbents and induced entrants diﬀer in the quantity and quality of their innovative output, what is the
   1 Research on entrepreneurs as innovators has begun to examine key characteristics of entrepreneurs and what leads them

to enter into self-employment. Both pre-founding work experience (e.g. Elfenbein et al., 2010), training (e.g. Lyons and Zhang,
2017), and genetics (Nicolaou et al., 2008) appear to impact the decision to become an entrepreneur. While the latter is
consistent with the notion that innovative ability is innate, the impacts of work experience are potentially consistent with our
contention that innovators can also be created. Given that would-be entrepreneurs chose their early work experience, more
evidence is needed to substantiate this claim. Moreover, entrepreneurs are only a subset of innovators and their characteristics
may not generalize to non-entrepreneur innovators. For example, in addition to innovation, entrepreneurs’ responsibilities
include labor management, securing financing, and marketing. Someone with a preference and the ability to innovate may not
have the desire to take on these additional responsibilities as well as the risks that innovation within an existing organization
does not involve.


                                                               2
optimal mix of eﬀorts to expand the knowledge frontier? Moreover, understanding whether innovative talent

is innate provides novel insights about the distribution of rents that arise from new inventions. If innovative

talent is entirely a quiddity, organizations will have to provide large amounts of compensation to attract

scarce innovators to the firm (e.g. Acemoglu, 1998). If, however, innovators can be created, compensation

to innovators will be disciplined by potential new entrants and the cost of creating them (e.g. Acemoglu

and Pischke, 1998). Moreover, if induced innovators are portable, firms may under-invest in creating them

(Becker, 1962).

     More generally, examining the potential for growing the pool of innovators has important implications

for our understanding of the innovation process and possible avenues for increasing inventive output. In

particular, our study allows us to determine whether individuals who do not choose to innovate in the

absence of an intervention are being held back by accurate beliefs about their ability to perform, or by

psychological barriers that, if overcome, could meaningfully contribute to the innovation process.2
     The RCT we implemented to interrogate these research questions was undertaken within an innovation

contest for undergraduate engineering and computer science students at UC San Diego (UCSD). Our design,

described in detail in Section 3, allows us to compare self-selected innovators to a population of potential

innovators with identical training, and to test whether the non-self-selected individuals can successfully

innovate. Moreover, it allows us to assess the diﬀerential eﬀects of confidence boosting messages across these

populations to determine whether this type of managerial intervention impacts innovative outcomes, and

whether the induced innovators’ performance benefits more from these eﬀorts. In addition, by observing

actual innovative output through the innovation contest, we are able to determine whether innate and

induced innovators have diﬀerent innovative skills.

     As expected, those participants that were induced to participate were diﬀerent than those that volun-

teered based on observable characteristics. By design, the induced sample was more female, but induced

participants were also less likely to be drawn from majors that provide the most relevant skills for the com-

petition and had lower cumulative GPAs. Yet, despite appearing to be less well equipped to compete, the

success of induced participants was statistically indistinguishable from those that were ‘innately’ drawn to

the competition. Thus, at least on average, it looks like innovators can be created.

     The impacts of encouragement on competition outcomes were a bit more surprising. Encouragement
  2 We  designed our sampling frame to allow us to test whether females are more likely to be impacted by interventions to
encourage entry into innovation. Given that females are under-represented in STEM jobs (Beede et al., 2011), they may be a
particular important target for firm and public policies that are aimed at expanding the pool of innovators. However, we did
not find robust diﬀerential treatment eﬀects for females and males (see Appendix Tables A1 and A2), and, therefore, do not
focus on this dimension of our study in this paper.




                                                             3
appears to have no eﬀect on any of our outcomes of interest.3 Moreover, it does not appear to have a

diﬀerential eﬀect for those induced, suggesting that confidence boosting is not essential for the reluctant

participants once they are induced to participate.

      While induced participants do as well as those that initially volunteer and neither group appears to

benefit from encouragement on average, as predicted by the framework that motivates our experimental

design (see Section 2), these average eﬀects mask important heterogeneity in the impacts of each treatment

arm. In particular, the impacts of inducement are significantly less promising for lower ability students, as

proxied by cumulative GPA. At the same time, they are helped by encouragement. The impacts on high

ability students are much more surprising. Not only do they not benefit from this encouragement, but they

appear to be harmed by it.

      Combined, our results demonstrate that innovators can be created through inducement subsidies, but

that targeting inducement is likely to be more cost eﬀective especially since targeting can be based on
information like GPA that is relatively easy to collect. Moreover, we demonstrate that encouragement may

also need to be targeted to focus on those who benefit from it while avoiding those it may harm.

      The paper proceeds as follows; Section 2 motivates our experiment design, Section 3 describes our

research setting and experiment, and Section 4 describes our data and analysis, Section 5 presents our

findings, and Section 6 summarizes and concludes.



2     Motivating Framework

We begin with a simple and stylized framework to motivate our experimental treatment groups and exper-

imental analysis. In particular, the framework allows for diﬀerent preferences and abilities for innovative

activities. The utility function used in the framework is consistent with our setting, but intended to be

general enough to be useful in other settings as well.


2.1     Framework set-up

There are n workers who each have an innovative type α. This α may aﬀect a worker’s cost of innovative ac-

tivities, their expected likelihood of a successful innovative activity outcome, or both. For simplicity, assume
   3 While encouragement does not aﬀect outcomes, survey evidence suggests that it does increase the perception that contestants

do not have enough time to complete their project amongst those that do not ultimately submit a final proposal. Since our
encouragement design included reminders about the competition deadline it may have made time scarcity more salient for those
that were falling behind on their project.




                                                               4
there are two possible α’s.4 Workers are presented with an opportunity to spend time on an innovative activ-

ity, referred to as an “innovation contest” that will pay them R if they succeed. Each worker succeeds with

some probability p(success|αi ). Each worker i has a cost c(αi ) of spending time on the contest. Therefore,

worker i’s expected utility from participating in the innovation contest is E(Ui |αi ) = p(success|αi )R − c(αi ).

Alternatively, workers can spend time on some outside option O. For simplicity, we assume the value of this

outside option is the same across workers.

      Suppose that E(Ui |α1 ) ≥ E(Ui |α2 ) either because p(success|α1 ) ≥ p(success|α2 ), or c(α1 ) ≥ c(α2 ), or

both. In addition, suppose that E(Ui |α1 ) ≥ O ≥ E(Ui |α2 ) so that only workers with α1 participate in the

innovation contest. Going forward, we refer to these workers as “innate innovators”. This is consistent with

the idea that, all else equal, some people are more likely to select into innovative activities than others.


2.2     Subsidy Introduction

Suppose now that those who have not selected into the innovation contest are oﬀered some subsidy S to

participate in it. As a result, their expected utility from participating is now: E(Ui |α2 ) = p(success|α2 )R −

c(α2 )+S. Importantly, S does not aﬀect p(success|αi ). To avoid generating an income eﬀect from the subsidy

in which S is diﬀerentially aﬀecting p(success|α2 ), the subsidy is subsequently oﬀered to α1 type workers

as well, albeit after they have elected to participate in the study to avoid influencing their participation

decision.5 Suppose further than S is high enough that E(Ui |α2 ) ≥ O so that the non-innate workers now

also join the contest. Going forward, we refer to these workers as “induced innovators”.

      If E(Ui |α1 ) ≥ E(Ui |α2 ) because p(success|α1 ) ≥ p(success|α2 ), and c(α1 ) is not less than c(α2 ), then

innate innovators are more likely to succeed in the innovation contest than induced innovators are. This

implies that innate innovators select into innovation because they have high innovative abilities.

      Alternatively, if E(Ui |α1 ) ≥ E(Ui |α2 ) because c(α2 ) ≥ c(α1 ), and p(success|α1 ) is not greater than
p(success|α2 ), then innate innovators are no more likely to succeed in the innovation contest than induced

innovators are.6 This implies that innate innovators select into innovation because they have lower costs of

doing so, for instance, because they enjoy it more.78
    4 In reality, there are a continuum of α types. This framework focuses on those at the margin of selecting into innovation.

Our experiment is not targeted at inducing workers who require a very large subsidy to participate in innovative activities and
we therefore do not consider how our treatments are likely to aﬀect them.
    5 Note that if α type workers are better able to use S in their innovative activity because they have better abilities, than S
                     1
may diﬀerentially aﬀect worker types’ likelihood of success. Given the small size of S in the actual experiment, we do not think
it is likely to have a meaningful aﬀect on success likelihoods.
    6 In this case, induced innovators may also have higher costs of innovation.
    7 If we let the value of outside options vary across worker types, this result could come up because workers with α have
                                                                                                                            2
higher value outside options.
    8 Although we are only allowing for one possible low α type in our model, in reality, it is possible that there are both low α




                                                                5
      Therefore,

Proposition 1 If innate and induced innovators diﬀer in their probability of successfully innovating, then,

conditional on the cost of innovating being incurred, induced innovators should perform worse than innate

innovators.

Proposition 2 If innate and induced innovators diﬀer in their cost of innovation, then, conditional on the
cost of innovating being incurred, they should perform no diﬀerently on innovative activities.


2.3     Encouragement Intervention

Suppose now that managers can intervene in workers’ innovative activities in an eﬀort to increase p(success|αi ).

Specifically, they can undertake a confidence boosting intervention where confidence is defined as a worker’s

belief in their likelihood of success in innovation. Imagine this intervention increases p(success|αi ) if a

worker’s i is below some threshold. This may be the case if, for instance, lack of confidence causes poor per-

formance due to anxiety-induced choking (Compte and Postlewaite, 2004) but that the intervention cannot

raise confidence above a certain level due to practical constraints.9 Managers cannot observe ex-ante which

worker’s are under-confident. If what diﬀerentiates α1 and α2 types is how confident in their abilities they

are, then this managerial intervention will raise p(α2 ) by more than p(α1 ). Therefore,

Proposition 3 If high and low type innovators diﬀer in self-confidence, then managerial interventions aimed

at increasing worker confidence in their abilities will increase innovative activity performance among low type

innovators (α2 s) more than it will among high type ones (α1 s).



3     Experimental Design

3.1     Research Setting & Population

To address our research questions, we implemented an RCT within an innovation contest for a subset of

students who are arguably most at risk of entering innovative careers. In particular, we introduced an

innovation contest open to all undergraduate engineering and computer science students at UCSD for which

participants were required to design and/or develop an application that helps people fall asleep faster based
types that have higher costs of innovating but similar abilities to those of innate innovators, and low α types that have lower
likelihoods of success than innate innovators. We test for this possibility empirically in section 5.
    9 We do not believe that our confidence-boosting intervention has the potential to lead to over-confidence in workers which

could negatively impact performance (Barber and Odean, 2001). Our intervention will provide encouragement rather than
suggest to workers that they have exception skills.


                                                              6
on their personal preferences. This problem was defined through discussions with several executives and

entrepreneurs in technology industries, some of whom served as contest judges. It is both an important

problem that does not yet have an ideal solution, and one that we believed the undergraduate students

could make reasonable progress on within a three month window. Prior to the contest sign-up deadline,

students were told that the innovation contest would require them to submit an application that solves a

specified problem related to personalization, but were not told about the specific problem until after the

sign-up deadline.10

      Students were invited to enroll in the contest through a series of newsletters and emails that were

supplemented with two information sessions between December, 2016 and January, 2017. The contest began

on February 8, 2017 and had a deadline of May 27, 2017. Contest winners were announced approximately two

weeks later during an awards ceremony and pitch event. The Engineering Department in which our target

participants are enrolled has been ranked in the top 10 globally (US News & World Report, 2016) and oﬀers
“...a broad and rigorous curriculum designed to provide students with the strong academic education and

technical training necessary for placement in the competitive high-tech job market as well as for advanced

studies in graduate school.” We selected this population because these students will have the technical

capabilities to produce impactful inventions in their lifetime, and because engineers are frequently the targets

of interventions to increase innovative activity (e.g. Bureau of Labor Statistics, 2013). In total, 190 students

signed up for the contest.

      Submissions made by the contest deadline were evaluated by five technology industry participants who

helped us identify the contest problem and acted as judges for the contest output. They evaluated each

submission across four categories; functionality, user-friendliness, novelty, and potential commercial value

and provided a score of 1-5 on each category for a total score maximum of 20. The developers of the top

three applications were awarded prize money. First place received $5,000, second place received $2,000, and

third place received $1,000. Participants were instructed to submit any output they had at the time of the

deadline, including written plans, design mock-ups, minimum viable products, and beta apps. To maximize

design flexibility, submissions could be intended for any platform.


3.2     Treatments

In order to diﬀerentiate between innate and induced innovators, a random subset of eligible students who

did not sign up by the contest deadline were oﬀered a monetary incentive to participate in the contest,
  10 This was to ensure that students who signed up early would not have a mechanical advantage over those who signed up

later.


                                                           7
specifically a $100 visa gift card. Taking up this oﬀer did not require students to do anything more than put

their name on the list of contest participants, and agree to receive emails about the contest. This incentive is

our inducement treatment, which is designed to ‘create’ innovators from a sample that did not self-identify

as such. In order to provide this incentive, the contest sign-up deadline was extended by one week. Students

who had already signed up to participate were informed about the sign-up deadline extension and monetary

incentive being oﬀered to some students to increase the participant pool. Moreover, they were also told they

would receive the same amount of money being oﬀered to the students who had not yet signed up.11 The

emails sent to both the students in our inducement treatment, and to the students who had self-selected into

the contest without inducement are provided in Appendix B. The innovation contest began the day after

the extended contest sign-up deadline, when the contest problem was revealed to students.12

     To determine the diﬀerential eﬀect of a managerial intervention aimed at raising confidence on the self-

selected and induced populations, a random subset of each group received a schedule of confidence boosting
emails throughout the contest period. In total, four emails were sent every two weeks with the exception

of the first three weeks during which all participants were receiving regular emails about the details of the

contest, and the final two weeks of the contest when all participants received a series of reminder emails.

The text included in the emails diﬀers from one email to the next, but they are all written to provide

versions of messages that have been shown to correlate with employee satisfaction and productivity in

organizational behavior research (e.g. Amabile and Pratt, 2016). For example, the emails sent to participants

in the encouragement treatment were designed to convey to participants that they are making a meaningful

contribution to their future careers and to the development of sleep technologies through their participation.

We also provided them links to resources for students working on their innovative capabilities at UCSD. The

complete texts of each email are included in Appendix B.

     With this set up, we have four treatment groups (see Figure I). In total, 103 eligible students signed

up to participate before the initial sign-up deadline13 , and 87 eligible students who received the inducement

treatment signed up before the extended sign-up deadline. This is out of a total of 3,445 Engineering and

Computer Science Department undergraduate students of which 1,000 received the inducement treatment

email.14 Our sample sizes per treatment arm are as follows: 52 participants in the self-selected, no man-
  11 Oﬀering the money to all participants reduces concerns about income eﬀects increasing the ability of participants to

successfully innovate. Those who sign up before the initial deadline were not expecting this payment so it will not bias our
measure of intent.
  12 Given our intention to test heterogeneous treatment eﬀects across females and males, we oversampled females in our

inducement treatment email because only 24% of eligible students are female. As a result of this oversampling, 50% of the
students who received the inducement treatment were female.
  13 This represents about 2% of the eligible population.
  14 A take up of about 9% suggests that students who did sign up after the inducement treatment email did not do so just to




                                                             8
agerial intervention group; 51 in the self-selected with managerial intervention group; 44 in the induced, no

managerial intervention group; and 43 in the induced with managerial intervention group.


                                     Figure I: Treatment Groups

                                      No Managerial Intervention         Managerial Intervention
        Self-Selected Innovators                   n=52                             n=51

        Induced Innovators                         n=44                             n=43




4     Data & Analysis

All participants were asked to complete a basic survey when they signed up for the contest. The survey

asked participants for their degree majors, gender, year of study, GPA, and whether they have previously

participated in an innovation contest.

     We collected outcome data based on whether or not participants submitted a project for consideration

by the judges, and the judges’ scoring of projects that were submitted. Each project was scored by three

judges. Our preferred measure of the quality of submissions is the average ranking judges gave each project.

Each judge scored 7 projects, so this measure ranges from 1-7 with 7 as the highest and 1 as the lowest.

We prefer this measure for two reasons. First, we are analyzing a competition in which the highest ranked

project wins. Second, our ranking measure captures the idiosyncratic scoring rubric for each judge without

the need for normalizations that can be hard to interpret. Including judge fixed eﬀects in our context is

impractical because projects were judged by three people and no three judges evaluated the same 7 projects

which leaves very few observations within each judge-triad. Our findings are robust to alternative measures,

including normalized average scores, as shown in Appendix Table A3.
     We also ran a survey following the conclusion of the contest to ask participants about their experience

in the contest, including whether they spent any time on the contest problem and, if they did not submit

something for consideration, why they chose not to. There were four versions of the survey, one for each

treatment group combination, where each shared a common group of questions as well as some that were

specific to their treatment status. As detailed below, these survey results will be used to probe possible

mechanisms for our findings.
receive the $100 gift card.



                                                     9
4.1     Summary Statistics and Measurement

Mean participant characteristics based on pre-contest participant survey responses are provided in Panel A

of Table I. These statistics demonstrate that about one-third of participants are female, the majority are
enrolled in a computer science (CS) or electrical engineering (EE) major, participants are in their third

year of study on average, and a small minority have prior innovation contest experience. In addition, the

average cumulative GPAs of participants are quite high. CGPA is measured using response data from a

survey question in which we asked participants to indicate which category their cumulative GPA falls into

on a scale from 1-6 with 1 being less than 2.0, 2 being 2.0-2.49, 3 being 2.50-2.99, 4 being 3.0-3.49, 5 being

3.50-3.99, and 6 being 4.0. The sample mean suggests an average participant CGPA of about 3.5.

      Contest performance summary statistics are presented in Panel B of Table I. About one-tenth of partici-

pants submitted a project for consideration by the judges. Conversations with organizations and individuals

who regularly run innovation contests and hackathons provide anecdotal evidence that this is a typical sub-

mission rate. In order to treat both the act of submitting and the quality of that submission as an endpoint

of interest, we generate an outcome variable using a combination of whether or not someone submitted, and

the project rank conditional on submitting. In particular, Average Ranking is equal to zero if a participant

did not submit a project and equal to their average ranking if they did. Consistent with the fact that many

participants did not submit a project for consideration by the judges, the mean of our outcome variable is

0.33. We verify that our findings are consistent with alternative measures that account for the large number

of zeros in this measure.15
      Panel C of Table I presents summary statistics for three survey-based measures of contest engagement.

The first thing to note is that 78 of the contest participants completed the survey, representing about 41% of

the population of students who signed up to participate in the contest. As we discuss in section 5, those who

filled in the survey appear similar to those who did not on observable characteristics, but, not surprisingly,

were on average more engaged in the contest than those who did not complete the post-contest survey.

Among this selected population, close to 70% did spend some time on the contest problem but only 22%

of these participants ended up submitting a project for consideration by the judges. Among those who did

not spend any time on the contest or spent time but did not submit a project for consideration, about half

indicated that time constraints were their primary reason for not submitting a project, and another 40%

indicated that the diﬃculty associated with the contest problem was their primary reason for not submitting
  15 In particular, we use the inverse hyperbolic sine transformation (Ramirez et al., 1994) to generate an alternative outcome

variable of interest. Analyses using this and other alternative outcome measures are presented in Appendix Table A3.




                                                              10
a project.16 We use this data to explore possible mechanisms for our main findings in section 5.5.

                                            Table I: Summary Statistics

                                                                                Mean       Std. Dev.         N
                Panel A: Participant Characteristics
                Female                                                           0.332        (0.472)       190
                Weighted Female                                                  0.261        (0.386)       190
                CS or ElecEng Major                                              0.702        (0.459)       190
                Weighted CS or ElecEng Major                                     0.649        (0.429)       190
                Year of Study                                                    3.005        (1.261)       183
                CGPA (1-6)                                                       4.392        (0.901)       176
                Prior Contest Experience                                         0.131        (0.338)       190

                Panel B: Outcomes
                Average Ranking (0 if not submission)                            0.332        (1.164)       190
                Submitted Project                                                0.090        (0.285)       190
                Average Ranking Score Conditional on Submitting                  3.715        (1.630)        17

                Panel C: Survey Responses
                Any Eﬀort Invested in Contest                                    0.679         (0.47)        78
                Did not Submit due to Time Constraints                           0.470        (0.503)        66
                Did not Submit due to Challenge                                  0.409        (0.495)        66
Notes:Female and CS/Elec Eng Major weighted to account for over sampling in induced treatment.




4.2     Treatment Eﬀects Estimation

Since our study provides random assignment of treatments, our analysis will focus both on mean comparisons

across treatment groups and regression analyses. We begin by presenting the eﬀects of the inducement

treatment on selection into the contest, and then turn our attention to performance among those who
participate in the contest. Importantly, because we expect that the primary mechanism through which

inducement will aﬀect outcomes is through selection into participation, our preferred empirical specification

does not include controls for participant characteristics. Nonetheless, we also present results that include

controls for participant characteristic covariates to illustrate the role they are playing in our core findings.

      We follow this by separately analyzing the impacts of the encouragement treatment on participant

performance. The encouragement treatment was randomly assigned to participants who had already selected

into the contest, so we do not expect that participant characteristics will vary by encouragement treatment

(comparisons are presented in section 5). As with inducement, we nonetheless run our regression analysis of
  16 A small percentage of participants indicated their primary reason for not submitting a project for consideration was because

the contest problem was not suﬃciently interesting for them to spend time on.




                                                               11
the eﬀects of encouragement on outcomes with and without controls for these characteristics.

         Since encouragement may diﬀerentially influence the induced and innate samples, we also analyze the

following equation:


            Yi = α + β1 Inducementi + β2 Encouragementi + β3 (Inducementi ∗ Encouragementi ) + ϵi                              (1)


where Yi is a measure of performance, T reatmenti is equal to one if participant i received the inducement

treatment, and Encouragementi is equal to one if participant i received the encouragement treatment.17

         As our framework presented in section 2 demonstrates, we expect our treatments will have diﬀerent

impacts depending on student ability. Using cumulative GPA as our most comprehensive measure of ability,
we assess this directly by estimating the following equation:



    Yi     =    αi + β1 (T reatmenti ) + β2 (HighCGP Ai ) + β3 (T reatmenti ∗ HighCGP Ai ) + ϵi                                (2)


where Yi is a measure of performance or participation, T reatmenti is equal to one if participant i received

one of the two treatments, and HighCGP Ai is equal to one if participant i has above the sample median

cumulative GPA. We estimate these equations separately for the encouragement and inducement treatments.



5        Results

The presentation of our results follow the progression described in the previous section. We begin with

estimates of the overall impacts of the inducement and encouragement treatments as well as the interaction

between the two. This is followed by an analysis of heterogeneity in our treatment eﬀects by ability and an

exploration of the potential mechanisms that might underlie these findings.


5.1        Average Eﬀects of Receiving an Inducement to Innovate

5.1.1       Selection into Participation

Table II presents comparisons of mean participant characteristics by inducement treatment. As expected,

these comparisons demonstrate important diﬀerences between the population of participants who signed

up without receiving a subsidy for participating and those who only did so with a subsidy. By design,
  17 We also verify that all of our estimates of treatment eﬀects on whether or not participants submit a project for consideration

are robust to using probit regressions.



                                                                12
the induced sample was more female. More importantly, induced participants were also less likely to be

drawn from majors that provide the most relevant skills for the competition, even when we account for the

over sampling of these majors in our inducement treatment assignment, and had lower cumulative GPAs.

Consistent with the predictions of our conceptual framework, inducement appears to lead lower ability

students to participate by increasing the pay-oﬀs to participation.18

         Table II: Mean Participant Characteristic Comparisons by Inducement Treatment

                                                          Not Induced        Induced        p-value
                           Female                              0.252            0.425      0.009***
                                                              (0.043)          (0.054)
                           Weighted Female                     0.252            0.272        0.726
                                                              (0.043)          (0.034)
                           CS or ElecEng Major                 0.789            0.605      0.006***
                                                              (0.040)          (0.053)
                           Weighted CS or ElecEng              0.786            0.487      0.000***
                                                               0.040            0.042
                           Year of Study                       2.941            3.111        0.365
                                                              (0.120)          (0.146)
                           CGPA (1-6)                          4.500            4.274       0.096*
                                                              (0.091)          (0.101)
                           Above Median CGPA                   -.663            0.521       0.065*
                                                              (0.049)          (0.060)
                           Prior Contest Experience            0.163            0.093        0.154
                                                              (0.036)          (0.032)
                                        N                       104               86
Notes: Standard deviations are in parentheses. Female and CS/Elec Eng Major weighted to account for over sampling in induced
treatment. * significant at 10%; ** significant at 5%; *** significant at 1%




5.1.2     Impact on Outcomes

Despite the mean comparisons presented in Table II suggesting that the induced participants may be less

well equipped to compete, the success of these participants appears statistically indistinguishable from those

that were ‘innately’ drawn to the competition. In particular, mean outcomes across induced and innate

innovators presented in Table III demonstrate that induced participants have slightly lower mean submission

rates and scores than innate innovators, but that these diﬀerences are statistically insignificant and quite

small.
   18 One possible concern with the inducement treatment is that those who signed up after the receiving it did so because

they did not see any of the contest announcements that were sent out prior to the inducement treatment. We think this is
unlikely for several reasons. First, the Engineering and Computer Science department, and the entrepreneurship center located
within the department sent out numerous emails to students about the contest over a two month period. Therefore, even if
the induced population did not read the emails announcing the contest, they would have chosen not to based on the subject
line that made clear there was a contest being announced which suggests they self-selected out of the contest based on their
preferences. Second, we asked participants in the inducement treatment why they had not signed up prior to receiving the
subsidy oﬀer in the post-contest survey, and while some stated they were not aware of the contest, many others stated that
they thought they didn’t have the time or ability to participate in it.


                                                              13
                           Table III: Mean Outcomes by Inducement Treatment

                                                                         Not Induced         Induced       p-value
                  Average Ranking                                              0.390           0.264        0.460
                                                                              (0.126)         (0.108)
                  Submitted Project                                            0.096           0.081        0.725
                                                                              (0.029)         (0.030)
                  Average Ranking Conditional on Submitting                    4.016           3.285        0.379
                                                                              (0.497)         (0.653)
                                          N                                     104              86
Notes: Standard deviations are in parentheses. Female and CS/Elec Eng Major weighted to account for over sampling in induced
treatment. * significant at 10%; ** significant at 5%; *** significant at 1%



     We verify that the average eﬀect of the inducement treatment on outcomes is zero using regression

analysis and present these results in Table IV. Columns 1 and 2 present the estimated eﬀect of inducement

on whether or not a participant submits a project for consideration, columns 3 and 4 present the estimated

eﬀect of inducement on average project rankings, and columns 5 and 6 present the inducement treatment

eﬀect estimates on average project rankings conditional on making a submission to the contest. Columns 1,

3, and 5 do not include controls for participant characteristics, with those added in columns 2, 4, and 6. In

all specifications, the eﬀect of inducement on outcomes is insignificant.

                          Table IV: Eﬀect of Inducement Treatment on Outcomes

                                            (1)       (2)           (3)      (4)           (5)            (6)
                                             Submission            Average Ranking            Average Ranking
                                                                                          Conditional on Submitting

            Inducement Treatment          -0.017       -0.024       -0.126      -0.190     -0.732           -0.527
                                         (0.0418)     (0.0475)     (0.170)     (0.191)    (0.806)          (0.846)

            Controls                        No           Yes           No        Yes        No               Yes
            Observations                    190          172           190       172        17               17
            R-squared                      0.001        0.025         0.003     0.046      0.052            0.404
            Mean dep var                   0.090        0.090         0.510     0.510      2.824            2.824
Notes: Standard errors are in parentheses. Columns 2, 4, and 6 include controls for participant gender, cgpa, year of study, whether
or not they major in computer science or electrical engineering, and whether or not they have prior innovation contest experience. *
significant at 10%; ** significant at 5%; *** significant at 1%



     Thus, at least on average, it looks like eﬀective innovators can be ‘created’ through a simple inducement.

It is, however, noteworthy that the addition of controls for participant characteristics has a sizable eﬀect

on the point estimates for the average proposal scores conditional on submitting, suggesting a potentially

important role for heterogeneity that we will return to below.




                                                                 14
5.2       Average Eﬀects of Receiving an Encouragement During the Contest

We are now ready to turn to the estimated eﬀects of the encouragement treatment on participant outcomes.

Table V presents mean comparisons between participants who did and did not receive the encouragement
treatment. As described earlier, the encouragement treatment was randomly assigned to all participants so

participants who received the encouragement treatment should look the same as those who did not. Panel A

on Table V largely confirms this with one minor exception. There is a small statistically significant diﬀerence

at the 10% level in whether or not a participant is in a computer science or electrical engineering major. To

ensure this diﬀerence is not impacting our findings, we confirm that all our results are robust to controlling

for it.

      Panel B of Table V presents mean outcomes by encouragement treatment status. As in the case of

the inducement treatment, encouragement does not appear to have any significant impact on participant

outcomes in the contest.
                        Table V: Mean Comparisons by Encouragement Treatment

                                                                     Not Encouraged           Encouraged           p-value
             Panel A: Participant Characteristics
             Female                                                         0.375                  0.287           0.201
                                                                           (0.050)                (0.047)
             CS or ElecEng Major                                            0.760                  0.648           0.093*
                                                                           (0.044)                (0.049)
             Year of Study                                                  2.901                  3.130           0.218
                                                                           (0.137)                (0.125)
             CGPA (1-6)                                                     4.427                  4.356           0.604
                                                                           (0.100)                (0.092)
             Above Median GPA                                               0.577                  0.570           0.918
                                                                           (0.050)                (0.052)
             Prior Contest Experience                                       0.135                  0.128           0.875
                                                                           (0.035)                (0.035)

             Panel B: Outcomes
             Average Ranking                                                0.369                  0.294           0.656
                                                                           (0.118)                (0.121)
             Submitted Project                                              0.104                  0.074           0.476
                                                                           (0.031)                (0.027)
             Average Ranking Conditional on Submitting                      3.583                  3.904           0.702
                                                                           (0.415)                (0.792)
                                      N                                      104                    86
Notes: Standard deviations are in parentheses. * significant at 10%; ** significant at 5%; *** significant at 1%



      Table VI presents these results in a regression framework. The coeﬃcient estimates suggest that encour-

agement had no meaningful eﬀect on whether or not participants submitted a project or on our combined

average normalized score variable. The coeﬃcient estimate on submission scores conditional on submitting


                                                                  15
(columns 5 and 6) are positive and quite large but as in the other columns, are statistically insignificant.

Together, these findings suggest that encouragement had no eﬀect on outcomes, the small sample size for

those that submitted a project make it diﬃcult to draw any definitive conclusions regarding that outcome.

                                 Table VI: Eﬀect of Encouragement Treatment

                                               (1)      (2)             (3)      (4)        (5)            (6)
                                                Submission             Average Ranking         Average Ranking
                                                                                           Conditional on Submitting

           Encouragement Treatment            -0.028     -0.020         -0.075    -0.014    0.322            0.425
                                             (0.042)    (0.047)        (0.169)   (0.190)   (0.824)          (0.948)

           Controls                            No          Yes          No        Yes        No               Yes
           Observations                        190         172          190       172        17               17
           R-squared                         0.002        0.025        0.001     0.040      0.010            0.393
           Mean dep var                      0.0895      0.0895        0.510     0.510      2.824            2.824
Notes: Standard errors are in parentheses. Columns 2, 4, and 6 include controls for participant gender, cgpa, year of study, whether
or not they major in computer science or electrical engineering, and whether or not they have prior innovation contest experience. *
significant at 10%; ** significant at 5%; *** significant at 1%




5.3     Interaction Eﬀects between Inducement and Encouragement

We next explore whether our encouragement treatment changes the eﬀect of inducement, for instance, by

boosting the confidence of participants who do not feel as capable of innovating as innate innovators. We

present the estimates from equation 1 described in section 4 in Table VII. As in Tables VI and IV, we run

the analysis with and without controls for participant characteristics.
      The estimates demonstrate that across all specifications, the interaction between the inducement and

encouragement treatments is negative and, in some cases, quite large. However, it is important to note that

we cannot rule out that the coeﬃcients are zero or even positive. In the end, the treatment eﬀects and

interaction are explaining very little of the variation in participant performance, suggesting little role for the

interaction of our two treatments on participant outcomes.


5.4     Heterogeneous Treatment Eﬀects

We theorized in section 2 that the inducement treatment could vary by participant ability if inducement

leads both lower ability innovators and innovators with a higher cost of innovation but similar ability as

the self-selected population to participate. In particular, inducement should reduce performance among the

lower ability population, but not impact it among those that simply have a higher cost of participation.



                                                                  16
                 Table VII: Joint Eﬀect of Inducement & Encouragement Treatment

                                                (1)      (2)            (3)      (4)         (5)            (6)
                                                 Submission            Average Ranking          Average Ranking
                                                                                            Conditional on Submitting

          Inducement Treatment                  0.019     0.016          0.031    -0.019     -0.367           -0.253
                                              (0.059)    (0.066)       (0.238)   (0.267)    (1.099)          (1.180)
          Encouragement Treatment              0.006       0.018         0.071     0.151      0.501            0.683
                                              (0.057)    (0.064)       (0.230)   (0.259)    (1.099)          (1.308)
          Encouragement Treatment*             -0.073     -0.079        -0.318    -0.344     -0.902           -0.729
          Inducement Treatment                (0.084)    (0.093)       (0.340)   (0.374)    (1.823)          (2.053)

          Controls                              No        Yes           No        Yes         No               Yes
          Observations                          190       172           190       172          17              17
          R-squared                            0.007     0.030         0.009     0.051       0.072            0.424
          Mean dep var                        0.0895     0.0895        0.510     0.510       2.824            2.824
Notes: Standard errors are in parentheses. Columns 2, 4, and 6 include controls for participant gender, cgpa, year of study, whether
or not they major in computer science or electrical engineering, and whether or not they have prior innovation contest experience. *
significant at 10%; ** significant at 5%; *** significant at 1%



Moreover, encouragement may diﬀerentially impact high and low ability participants if, for instance, lower

ability participants are less confident than high ability participants are.

     To simplify the presentation of our analysis of heterogeneous treatment eﬀects, we present mean com-

parison figures and regression estimates from equation 2 below. We begin by presenting heterogeneous eﬀects

of inducement, followed by those of encouragement.19


5.4.1    Eﬀects of Inducement by Participant GPA

Figure II presents the diﬀerence in mean contest performance between induced and non-induced contest par-
ticipants for below and above median CGPA participants respectively. These means support our predictions

that when inducement leads lower ability individuals to participate in innovation, it leads to lower innovative

performance. In particular, inducement leads to a large and significant reduction in participant performance

among low GPA students, but an increase in performance among high GPA students. Interestingly, the

highest performers are innate low GPA students suggesting that they may have private information about

their innovative capabilities that are not reflected in their academic performance.

     Table VIII presents estimates of the interaction between GPA and inducement, and provides support for

the mean comparisons. In particular, low GPA students suﬀer from inducement whereas high GPA students

benefit from it. These eﬀects seem to work both by aﬀecting submission rates and rankings conditional on
  19 We did not design our study to have suﬃcient sample size to estimate heterogeneous eﬀects by all four treatment groups

and so we don’t report these eﬀects here. However, controlling for whether those in the inducement treatment are also in the
encouragement treatment and vice versa does not change our results.



                                                                  17
Figure II: Change in Average Ranking due to Inducement by GPA




                             18
submissions.20 Appendix Table A4 demonstrates that the estimates presented in Table VIII are minimally

aﬀected by the inclusion of controls for participant characteristics, though we lose some significance.

                         Table VIII: Joint Eﬀect of Inducement Treatment by GPA

                                                (1)                  (2)                           (3)
                                             Submission        Average Ranking              Average Ranking
                                                                                        Conditional on Submitting

             Inducement Treatment                -0.067                -0.480*                       -2.068*
                                                (0.064)                (0.259)                       (1.085)
             Above Median CGPA                   -0.059                -0.460*                      -2.101**
                                                (0.059)                (0.238)                       (0.939)
             Above Median CGPA*                   0.084                0.581*                         2.601
             Inducement Treatment               (0.085)                (0.344)                       (1.473)

             Observations                         190                   190                            17
             R-squared                           0.007                 0.024                          0.323
             Mean dep var                        0.09                  0.332                          3.715
Notes: Standard errors are in parentheses. * significant at 10%; ** significant at 5%; *** significant at 1%




5.4.2      Eﬀects of Encouragement by Participant GPA

Figure III presents the diﬀerence in mean contest performance between encouraged and not encouraged

contest participants below and above median CGPA participants, respectively. As with inducement, these

comparisons demonstrate that the impacts of encouragement diﬀer by ability. Unsurprisingly, low GPA

students benefit from the additional support provided by encouragement. The impacts on high GPA students

are much less intuitive. Not only do they not benefit from this encouragement, but they appear to be harmed

by it.21

     Table IX presents the estimated impact of the interaction between participant GPA and the encourage-

ment treatment on our three primary outcomes of interest. This Table demonstrates that encouragement

negatively impacted both the likelihood of submitting a project and project quality conditional on submit-

ting among high GPA students. The positive eﬀect of encouragement on low GPA student performance

appears to work largely by improving the quality of submitted projects. Appendix Table A5 demonstrates

that the estimates presented in Table VIII are minimally aﬀected by the inclusion of controls for participant
characteristics.
   20 Given the relatively large standard errors on our estimates, we do not think interpreting the specific sizes of our estimates

is particularly valuable, and instead focus on interpreting their signs.
   21 Interestingly, virtually all encouraged participants who completed the post-contest survey indicated positive experiences

with the encouragement emails suggesting those who were negatively impacted by the treatment did feel as though they had
been.


                                                                  19
               Figure III: Change in Average Ranking due to Encouragement by GPA




                          Table IX: Joint Eﬀect of Inducement Treatment by GPA

                                                   (1)                 (2)                            (3)
                                                Submission       Average Ranking               Average Ranking
                                                                                           Conditional on Submitting

          Encouragement Treatment                  0.052                 0.397                          1.890*
                                                  (0.064)               (0.256)                        (0.905)
          Above Median CGPA                        0.052                 0.246                          0.675
                                                  (0.059)               (0.237)                        (0.855)
          Above Median CGPA*                      -0.139*              -0.827**                       -4.510***
          Encouragement Treatment                 (0.084)               (0.338)                        (1.344)
          Constant                                 0.073                 0.228                        3.110***
                                                  (0.045)               (0.180)                        (0.715)

          Observations                              190                   190                             17
          R-squared                                0.018                 0.037                          0.529
          Mean dep var                              0.09                 0.332                          3.715
Notes: Standard errors are in parentheses. * significant at 10%; ** significant at 5%; *** significant at 1%




                                                                  20
5.5     Exploring Mechanisms

To better understand the mechanisms driving our estimated average eﬀects of the encouragement and in-

ducement treatments, we ask all participants to complete a short survey following the announcement of
contest winners for the chance to win a $100 Visa gift card. The survey questions are reported in Appendix

B. Importantly, the sample of participants who completed the survey represents 41% of the total contest

participant population, and, as Table X shows, those who completed the survey were, on average, much

more likely to have submitted a project for consideration than those who did not complete it. Given this

selected sample, we view this part of our analysis as suggestive rather than conclusive evidence on some of

the underlying factors that may be driving our results.

                         Table X: Summary Statistics by Final Survey Completion

                                                                       No Response          Response         p-value
                Panel A: Participant Characteristics
                Female                                                       0.313              0.359         0.506
                                                                            (0.043)            (0.055)
                CS or ElecEng Major                                          0.714              0.692         0.745
                                                                            (0.042)            (0.053)
                Year of Study                                                3.073              2.932         0.458
                                                                            (0.122)            (0.144)
                CGPA (1-6)                                                   4.417              4.356         0.657
                                                                            (0.083)            (0.115)
                Prior Contest Experience                                     0.152              0.103         0.326
                                                                            (0.034)            (0.035)
                Inducement Treatment                                         0.446              0.474         0.706
                                                                            (0.0470            (0.058)
                Encouragement Treatment                                      0.456              0.538         0.262
                                                                            (0.047)            (0.058)

                Panel B: Outcomes
                Submission                                                    0.117             0.639       0.002***
                                                                            (0.070)            (0.173)
                Average Ranking                                               0.418             0.642        0.015**
                                                                            ( 0.041)           (0.094)
                Average Ranking Conditional on Submitting                     3.249             3.858         0.530
                                                                            (1.236)            (0.383)
                                         N                                     114                76
Notes: Standard deviations are in parentheses. * significant at 10%; ** significant at 5%; *** significant at 1%



      In particular, we focus on three survey-based measures of contest engagement that we think are most
relevant for understanding how our treatments aﬀected participants’ perception and experience with the

contest. Specifically, we analyze whether encouragement or inducement correlates with whether or not

participants spent any time on the contest problem, and if they did not submit a project for consideration,



                                                                  21
whether the treatments related to what prevented them from doing so. We break the latter measure of

engagement into two categories that were the most frequently cited explanations for not submitting a project;

not having enough time, and finding the contest problem too challenging to allow for satisfying solution

strategies.

     Table XI presents the results of this analysis. Consistent with the finding that neither encouragement

nor inducement impacted participant outcomes on average, and with the mean comparisons presented in Ta-

bles III and V, the treatments do not appear to correlate significantly with whether or not participants invest

any eﬀort in the contest. Similarly, our treatments do not relate to the likelihood that participants failed

to submit a project to the contest because they felt the problem was too challenging for them. However, as

demonstrated by Column 3, we find that the encouragement treatment is associated with an approximately

thirty percentage point increase in the likelihood that participants report not submitting due to time con-

straints. In column 4, we add controls for participant characteristics to better capture selection, at least
on observables, and the estimate increases slightly. We view this finding as one consistent with the notion

that the encouragement emails increased the salience of the time required for developing a solution to the

contest problem and thus one that decreased submissions.22 In light of our results in Table IX, which showed

that the negative eﬀects of encouragement are concentrated on high GPA students, it seems plausible that

this time salience feature from encouragement is felt most acutely by high-achieving students whose scarce

time is more likely to be allocated to school work. Whether it also relates to the crowding out of intrinsic

motivation remains an open question.

               Table XI: Eﬀects of Inducement and Encouragement on Survey Outcomes

                                      (1)         (2)              (3)           (4)                  (5)              (6)
                                     Any Eﬀort on Contest        No Submission due to Time           No Submission due to Challenge

 Inducement Treatment                 -0.027        -0.040        -0.091            -0.058            0.055                0.023
                                     (0.107)       (0.122)       (0.121)           (0.152)           (0.125)              (0.154)
 Encouragement Treatment              -0.091        -0.081       0.273**           0.304**            -0.002               0.004
                                     (0.107)       (0.119)       (0.122)           (0.143)           (0.125)              (0.145)

 Controls                              No            Yes           No                Yes               No                   Yes
 Observations                          79            72            66                59                66                    59
 R-squared                            0.010         0.063         0.088             0.124             0.003                0.066
 Mean dep var                         0.684         0.684         0.470             0.470             0.409                0.409
Notes: Standard errors are in parentheses. Columns 3-6 are restricted to the sample of participants who did not submit a project for
consideration in the contest. Columns 2, 4, and 6 include controls for participant gender, cgpa, year of study, whether or not they
major in computer science or electrical engineering, and whether or not they have prior innovation contest experience. * significant at
10%; ** significant at 5%; *** significant at 1%


  22 All   estimates report in Table XI are robust to using probit regressions rather than linear probability models.



                                                                  22
6    Discussion

This study provides novel and causal evidence on the scope for creating new innovators, with and without

encouragement. It also sheds light on the obstacles to inducing participation and the key characteristics

that distinguish those that self-identify as an innovator from those that need to be induced. Our findings

demonstrate that self-selected, or innate, innovators appear to have better academic performance and are

more likely to be enrolled in a major typically associated with the skills required to perform well in an
app contest relative to induced innovators. Despite these quality diﬀerences, we do not observe diﬀerences

in performance across the innate and induced samples, nor do we observe any eﬀect of encouragement on

participant performance. However, additional analysis of our data demonstrates that these average eﬀects

mask important heterogeneity in our sample. In fact, the impact of inducement is significantly less promising

for lower ability students, as proxied by cumulative GPA, but these students are precisely the ones that benefit

from the additional support provided by encouragement. The impacts on high ability students are much

more surprising. Not only do they not benefit from encouragement, but they appear to be harmed by it.

While our survey evidence suggests that this may due to the increased salience of the time commitment

required to complete the project, it is also consistent with the idea that encouragement is crowding out

intrinsic motivation in this more capable population (Benabou and Tirole, 2003).

    Combined with the framework that motivated our study design, our results suggest that some people

select out of innovative activities based on their expected performance, while others select out based on the

costs of participating. They demonstrate that innovators can be created by subsidizing their initial entry

into innovative tasks, but that targeting inducement towards those who select out due to their expected cost

of participation rather than their expected performance is a more eﬀective strategy to promote innovation.
That targeted can be based on relatively easy information to obtain suggests that such a strategy may be

both practical and cost eﬀective. In particular, we find evidence that targeting can be based on information

that is relatively easy to collect. In addition, we demonstrate that encouragement may also need to be

targeted in order improve performance of workers who benefit from it, and importantly, to avoid harming

those who do not.

    Several important caveats of our study are worth highlighting. First, our study sample is comprised

of undergraduate engineering students. While these students have the relevant technical capabilities to

innovate and will form the backbone of the innovation economy after graduation, their relative youth may

limit the generalizability of our findings to more experienced cohorts in the workplace. Second, the sample of

workers who submitted a project for consideration is quite low. Although we have anecdotal evidence that a


                                                      23
10% submission rate is standard for this type of competition and, therefore, that our findings have relevant

external validity, some of our null results may be in part due to lack of power. Third, while our encouragement

emails were motivated by evidence on motivating employees (e.g. Amabile and Pratt, 2016), there are many

ways to provide workers with encouragement aimed at enhancing performance. Therefore, while we think

our finding that managerial interventions designed to encourage workers can have negative impacts on

performance highlights a potentially important concern for managers of innovative firms, it remains possible

that alternative interventions could avoid this shortcoming. Lastly, our measures of contest success are

based on quantifiable performance metrics provided by expert evaluators. We do not have market-driven

measures of innovative success, which may better reflect the ambitions of firms. How well expert evaluations

of directed innovation translate into market success is an important area for future research.



7     References

Acemoglu, Daron, “Why do new technologies complement skills? Directed technical change and wage
 inequality,” Quarterly Journal of economics, 1998, pp. 1055–1089.
     and Jorn-Steﬀen Pischke, “The structure of wages and investment in general training,” Technical
    Report, National Bureau of Economic Research 1998.
Amabile, Teresa M and Michael G Pratt, “The dynamic componential model of creativity and inno-
 vation in organizations: Making progress, making meaning,” Research in Organizational Behavior, 2016,
 36, 157–183.
Azoulay, Pierre, Joshua Graﬀ Zivin, and Gustavo Manso, “Incentives and Creativity: Evidence from
 the Howard Hughes Medical Investigator Program,” The RAND Journal of Economics, 2011, 42, 527–554.
Barber, Brad M and Terrance Odean, “Boys will be boys: Gender, overconfidence, and common stock
 investment,” Quarterly Journal of Economics, 2001, pp. 261–292.
Becker, Gary S, “Investment in human capital: A theoretical analysis,” The Journal of Political Economy,
 1962, pp. 9–49.
Beede, David N, Tiﬀany A Julian, David Langdon, George McKittrick, Beethika Khan, and
 Mark E Doms, “Women in STEM: A gender gap to innovation,” Economics and Statistics Administration
 Issue Brief, 2011, (04-11).
Benabou, Roland and Jean Tirole, “Intrinsic and extrinsic motivation,” The review of economic studies,
 2003, 70 (3), 489–520.
Bureau of Labor Statistics, “Monthly Labor Review, 2013,” Technical Report 2013.
Compte, Olivier and Andrew Postlewaite, “Confidence-enhanced performance,” American Economic
 Review, 2004, 94 (5), 1536–1557.
Ederer, Florian and Gustavo Manso, “Incentives for innovation: Bankruptcy, corporate governance,
 and compensation systems,” Handbook of Law, Innovation, and Growth, 2011, pp. 90–111.


                                                      24
Elfenbein, Daniel W, Barton H Hamilton, and Todd R Zenger, “The small firm eﬀect and the
  entrepreneurial spawning of scientists and engineers,” Management Science, 2010, 56 (4), 659–681.
Grossman, Gene and Elhanan Helpman, “Endogenous Innovation in the Theory of Growth,” Journal
 of Economic Perspectives, 1994, 8 (1), 23–44.
Grossman, Gene M and Elhanan Helpman, “Trade, knowledge spillovers, and growth,” Technical
 Report, National Bureau of Economic Research 1990.
Holmstrom, Bengt, “Agency costs and innovation,” Journal of Economic Behavior & Organization, 1989,
 12 (3), 305–327.
Lyons, Elizabeth and Laurina Zhang, “Who Does (Not) Benefit from Entrepreneurship Programs?,”
  Strategic Management Review, 2017, Forthcoming.
Nicolaou, Nicos, Scott Shane, Lynn Cherkas, Janice Hunkin, and Tim D Spector, “Is the
 tendency to engage in entrepreneurship genetic?,” Management Science, 2008, 54 (1), 167–179.

Oettl, Alexander and Ajay Agrawal, “International labor mobility and knowledge flow externalities,”
 Journal of International Business Studies, 2008, 39 (8), 1242–1260.

Ramirez, Octavio A, Charles B Moss, and William G Boggess, “Estimation and use of the inverse
 hyperbolic sine transformation to model non-normal correlated random variables,” Journal of Applied
 Statistics, 1994, 21 (4), 289–304.
Scotchmer, Suzanne, “Standing on the shoulders of giants: cumulative research and the patent law,” The
  Journal of Economic Perspectives, 1991, 5 (1), 29–41.
Solow, Robert M, “Technical change and the aggregate production function,” The Review of Economics
  and Statistics, 1957, pp. 312–320.
US News & World Report, “Best Global Universities for Computer Science,” Technical Report 2016.




                                                 25
Appendix A                   Additional Tables

                                      Table A1: Eﬀects of Inducement Gender

                                                 (1)                  (2)                           (3)
                                              Submission        Average Ranking              Average Ranking
                                                                                         Conditional on Submitting

            Inducement Treatment                  -0.011                -0.087                        -0.607
                                                 (0.052)               (0.212)                       (1.002)
            Female                                 0.024                 0.276                        1.643
                                                 (0.065)               (0.265)                       (1.103)
            Inducement Treatment*                 -0.023                -0.203                        -0.783
            Female                               (0.090)               (0.366)                       (1.645)

            Observations                          190                   190                             17
            R-squared                            0.002                 0.009                           0.216
            Mean dep var                         0.0895                0.332                           3.715
Notes: Standard errors are in parentheses. * significant at 10%; ** significant at 5%; *** significant at 1%



                                 Table A2: Eﬀects of Encouragement by Gender

                                                   (1)                  (2)                           (3)
                                                Submission        Average Ranking              Average Ranking
                                                                                           Conditional on Submitting

          Encouragement Treatment                    0.009               0.046                           0.189
                                                   (0.051)              (0.207)                         (0.909)
          Female                                     0.057               0.289                           0.767
                                                   (0.060)              (0.246)                         (0.949)
          Encouragement Treatment*                  -0.111               -0.337                          2.845
          Female                                   (0.089)              (0.363)                         (1.878)

          Observations                               190                   190                             17
          R-squared                                 0.011                 0.009                          0.309
          Mean dep var                             0.0895                 0.332                          3.715
Notes: Standard errors are in parentheses. * significant at 10%; ** significant at 5%; *** significant at 1%




                                                                  26
 Table A3: Eﬀects of Encouragement & Inducement on Alternate Measures of Performance

                                 (1)                  (2)                           (3)                            (4)
                             Average              Average               Average Normalized Score          Average Normalized
                           Ranking (IHS)       Normalized Score         Conditional on Submitting            Score (IHS)
     Inducement                -0.098               -0.084                        -0.327                         -0.059
     Treatment                (0.128)              (0.134)                       (0.773)                        (0.091)
     Encouragement             -0.028               -0.031                        0.473                          -0.013
     Treatment                (0.128)              (0.133)                       (0.773)                        (0.091)

     Observations                190                    190                           17                           190
     R-squared                  0.003                  0.002                        0.047                         0.002
     Mean dep var               0.582                  0.253                        2.824                         0.510
Notes: Standard errors are in parentheses. * significant at 10%; ** significant at 5%; *** significant at 1%




                  Table A4: Joint Eﬀect of Inducement Treatment by GPA, Controls

                                                (1)                  (2)                           (3)
                                             Submission        Average Ranking              Average Ranking
                                                                                        Conditional on Submitting

             Inducement Treatment                -0.064                -0.487*                        -1.978
                                                (0.069)                (0.277)                       (1.102)
             Above Median CGPA                   0.081                  0.088                        -3.014*
                                                (0.094)                (0.378)                       (1.581)
             Above Median CGPA*                   0.074                 0.551                         2.314
             Inducement Treatment               (0.093)                (0.373)                       (1.470)

             Observations                         172                   172                             17
             R-squared                           0.040                 0.065                          0.627
             Mean dep var                        0.09                  0.332                          3.715
Notes: Standard errors are in parentheses. All columns include controls for participant gender, cgpa, year of study, whether or not
they major in computer science or electrical engineering, and whether or not they have prior innovation contest experience. *
significant at 10%; ** significant at 5%; *** significant at 1%




                                                                  27
               Table A5: Joint Eﬀect of Encouragement Treatment by GPA, Controls

                                                                      (1)                 (2)                           (3)
                                                                   Submission       Average Ranking              Average Ranking
                                                                                                             Conditional on Submitting

 Encouragement Treatment                                               0.067               0.477*                          2.490
                                                                      (0.068)              (0.273)                        (1.414)
 Above Median CGPA                                                    0.202**              0.831**                         1.619
                                                                      (0.096)              (0.387)                        (2.239)
 Above Median CGPA*Encouragement Treatment                            -0.163*             -0.920**                       -4.488**
                                                                      (0.092)              (0.371)                        (1.667)

 Observations                                                           172                  172                             17
 R-squared                                                             0.054                0.081                          0.726
 Mean dep var                                                          0.09                 0.332                          3.715
Notes: Standard errors are in parentheses. All columns include controls for participant gender, cgpa, year of study, whether or not
they major in computer science or electrical engineering, and whether or not they have prior innovation contest experience. *
significant at 10%; ** significant at 5%; *** significant at 1%



Appendix B                   Data Appendix

Inducement Treatment Emails

The email oﬀering a monetary incentive for contest participation sent to students in the inducement treatment

is copied below.


Hello,

The 2017 UC San Diego Student Innovation Contest is oﬀering students the opportunity to solve a real world

problem and win up to $5,000! Thanks to an award from the Kauﬀman Foundation, the contest organizers

are oﬀering a $100 pre-paid visa card for participating in the contest. A random sample of students have

been selected for this invitation-only opportunity and you are one of them.

The organizers have postponed the sign up deadline from February 1 until February 7 to allow students who
receive this invitation to take advantage of this opportunity. If you would like to participate in the contest,

please sign up by 6 pm on February 7 and you will automatically be awarded a $100 visa card. For more

information and to sign up for the contest, please visit: contest website.

This contest is open to all Jacobs School of Engineering undergraduate students.

Sincerely,

Contest organizer



                                                                 28
The email explaining the monetary incentive and sign-up deadline extension to students in the self-selected
group is copied below.


Hello,

Thank you for signing up to participate in the 2017 UC San Diego Student Innovation Contest. Thanks to a

generous award from the Kauﬀman Foundation, the contest organizers are oﬀering students a $100 pre-paid
visa card just for participating in the contest! In addition, they have invited a randomly selected set of

students to sign up and also take advantage of this opportunity. To allow these students time to sign up,

the organizers have postponed the start of the contest until February 8.

As a result of these changes, you will be receiving a $100 visa card, and a description of the problem you are

to solve for the contest will be announced on February 8. The organizers apologize for any inconveniences

this delay may cause you. Details on how to collect your visa card will be sent to you within the next three

weeks.

Sincerely,

Contest organizer




                                                     29
    Encouragement Treatment Emails



    Encouragement Email #1



Dear UCSD Student Innovation Contest Participant,



We hope that youre enjoying the Quarter! We wanted to reach out to tell you how happy we are that you

are participating in the first ever UCSD Student Application Innovation Contest. We are confident that you

will enjoy the time you spend developing your submission, and that you will gain valuable experience and

knowledge through the process. By developing and refining your creativity, technical abilities, and project

management skills we strongly believe that this contest will prepare you for a rewarding and innovative
career. In addition, the solution you are developing for how an app can be used to help people fall asleep

has the potential to have meaningful social and commercial value.



We also want to remind you that UCSD has a number of resources available for students interested in

furthering their innovation capabilities, including the Institute for the Global Entrepreneur at the Jacobs

School of Engineering (http://jacobsschool.ucsd.edu/globalentrepreneur/).



We look forward to seeing your innovation!



Sincerely,

Contest Organizers



    Encouragement Email #2



Dear UCSD Student Innovation Contest Participant,



You are now almost one third of the way through the first UCSD Student Innovation Contest! This also

means that you still have over ten weeks to work on your submission. We hope that you have begun to make

progress on your solution for helping people fall asleep faster, but if you havent had the chance to work on



                                                    30
it yet, there is plenty of time remaining to develop a solution in time for the deadline.



We look forward to seeing your innovation!



Sincerely,

Contest Organizers



    Encouragement Email #3



Dear UCSD Student Innovation Contest Participant,



We hope youre enjoying Spring Break and getting some time to do things you enjoy! The contest judges

and organizers are very excited about the amount of creativity, eﬀort, and knowledge being put into

finding a solution to help people fall asleep faster and are looking forward to seeing your proposals and

applications. Just as a reminder, UCSD has some excellent resources for students considering careers

in entrepreneurship and innovation, including the Institute for the Global Entrepreneur at the Jacobs

School of Engineering (http://jacobsschool.ucsd.edu/globalentrepreneur/) and the Oﬃce of Research Af-
fairs (http://innovation.ucsd.edu/entrepreneur/).



We look forward to seeing your innovation!



Sincerely,

Contest Organizers



    Encouragement Email #4



Dear UCSD Student Innovation Contest Participant,



We hope your Spring Quarter has gotten oﬀ to a good start! We have just over 5 weeks left until the

contest deadline plenty of time for you to come up with and improve your solution to helping people


                                                      31
fall asleep faster with an application.   As a student in one of the 20 most innovative Computer Sci-

ence and Engineering departments in the US, we are thrilled to have you working on an application

that has the potential to have an impact on peoples well-being, and generate commercial success as well.

In addition to the sources available to students interested in careers in innovation and entrepreneurship

(http://jacobsschool.ucsd.edu/globalentrepreneur/, (http://innovation.ucsd.edu/entrepreneur/), the Kauﬀ-

man Foundation, one of the contest sponsors, also has some great resources you can take advantage of

(http://www.kauﬀman.org).



We look forward to seeing your innovation!



Sincerely,

Contest Organizers




                                                   32
Copy of Post-Contest Survey




                              33
34
Notes: Question 1 was only included in the survey given to the induced population. Question 7 was only included in the survey given
to the encouraged population.




                                                                35
