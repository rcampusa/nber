                                NBER WORKING PAPER SERIES




        PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS

                                           Andrew Foerster
                                         Juan Rubio-Ramírez
                                         Daniel F. Waggoner
                                               Tao Zha

                                        Working Paper 20390
                                http://www.nber.org/papers/w20390


                      NATIONAL BUREAU OF ECONOMIC RESEARCH
                               1050 Massachusetts Avenue
                                 Cambridge, MA 02138
                                     August 2014




For helpful comments we thank Rhys Bidder, Han Chen, Seonghoon Cho, Lars Hansen, Giovanni
Lombardo, Leonardo Melosi, Harald Uhlig, as well as seminar participants at Duke University, the
Federal Reserve Bank of St. Louis, the 2010 Society of Economic Dynamics meetings, the 2011 Federal
Reserve System Committee on Business and Financial Analysis Conference, the 2012 Annual Meeting
of the American Economic Association, the 8th Dynare Conference, and the 2012 NBER Workshop
on Methods and Applications for DSGE Models. Zhao Li and Tong Xu provided excellent research
assistance. This research is supported in part by the National Science Foundation Grants SES-1127665
and SES-1227397. The views expressed herein are solely those of the authors and do not necessarily
reflect the views of the Federal Reserve Banks of Atlanta and Kansas City, the Federal Reserve System,
or the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.

© 2014 by Andrew Foerster, Juan Rubio-Ramírez, Daniel F. Waggoner, and Tao Zha. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including © notice, is given to the source.
Perturbation Methods for Markov-Switching DSGE Models
Andrew Foerster, Juan Rubio-Ramírez, Daniel F. Waggoner, and Tao Zha
NBER Working Paper No. 20390
August 2014
JEL No. C6,E3,G1

                                            ABSTRACT

Markov-switching DSGE (MSDSGE) modeling has become a growing body of literature on economic
and policy issues related to structural shifts. This paper develops a general perturbation methodology
for constructing high-order approximations to the solutions of MSDSGE models. Our new method,
called "the partition perturbation method,'' partitions the Markov-switching parameter space to keep
a maximum number of time-varying parameters from perturbation. For this method to work in practice,
we show how to reduce the potentially intractable problem of solving MSDSGE models to the manageable
problem of solving a system of quadratic polynomial equations. We propose to use the theory of Gröbner
bases for solving such a quadratic system. This approach allows us to first obtain all the solutions and
then determine how many of them are stable. We illustrate the tractability of our methodology through
two examples.


Andrew Foerster                                    Daniel F. Waggoner
Research Department                                Federal Reserve Bank of Atlanta
Federal Reserve Bank of Kansas City                1000 Peachtree Street N.E.
Kansas City, MO 64198                              Atlanta, Georgia 30309-4470
andrew.foerster@kc.frb.org                         dwaggoner@frbatlanta.org

Juan Rubio-Ramírez                                 Tao Zha
Duke University                                    Emory University
P.O. Box 90097                                     1602 Fishburne Drive
Durham, NC 27708                                   Atlanta, GA 30322-2240
juan.rubio-ramirez@duke.edu                        and Federal Reserve Bank of Atlanta
                                                   and also NBER
                                                   tzha@emory.edu
             PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                          1

                                     I. Introduction

  In this paper we extend the conventional perturbation method, as described in Judd
(1998) and Schmitt-Grohe and Uribe (2004) and advocated recently by Lombardo (2010)
and Borovic̆ka and Hansen (2013), to approximating the solutions of Markov-switching dy-
namic stochastic general equilibrium (MSDSGE) models. The extension poses a very chal-
lenging task because the presence of time-varying parameters in MSDSGE models makes
high-order approximations potentially intractable. We advance the literature in three signif-
icant respects. First, we develop a general methodology for approximating the solution to
a wide class of Markov-switching models with any order of accuracy. Second, our method-
ology preserves the time-varying coefficients to the maximum extent in high-order Taylor
series expansions. Third, we show the feasibility and practicality of constructing high-order
approximations by reducing the potentially intractable problem to the manageable problem
of solving a system of quadratic polynomial equations.
  The literature on Markov-switching linear rational expectations (MSLRE) models has been
an active field in empirical macroeconomics (Leeper and Zha (2003), Blake and Zampolli
(2006), Svensson and Williams (2007), Davig and Leeper (2007), and Farmer, Waggoner,
and Zha (2009)). Building on standard linear rational expectations models, the MSLRE
approach allows parameters to change over time according to discrete Markov processes.
This nonlinearity has proven to be important in explaining shifts in monetary policy and
macroeconomic time series (Schorfheide (2005), Davig and Doh (2008), Liu, Waggoner, and
Zha (2011), and Bianchi (2010)) and in modeling the expected effects of future fiscal policy
changes (Davig, Leeper, and Walker (2010), Davig, Leeper, and Walker (2011), Bi and
Traum (2012), Bianchi and Melosi (2013)). In particular, Markov-switching models provide
a tractable way to study how agents form expectations over possible discrete changes in the
economy, such as those in technology and policy.
  There are, however, two major shortcomings with the MSLRE approach advocated by
Farmer, Waggoner, and Zha (2011). First, the approach begins with a system of standard
linear rational expectations equations that have been obtained by linearizing equilibrium
conditions as though the parameters were constant over time. Discrete Markov processes
are then annexed to certain parameters. As a consequence, the resultant MSLRE model
may be incompatible with the optimizing behavior of agents in an original economic model
with Markov-switching parameters. Second, because it builds on linear rational expecta-
tions models, the MSLRE approach does not take into account higher-order coefficients in
the approximation. Not only do higher-order approximations improve the approximation
               PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                             2

accuracy but they are essential to addressing important questions such as whether time-
varying volatility is the driving force of fluctuations in the financial markets and business
cycles (Bloom, 2009).
  This paper develops a general perturbation methodology for constructing first-order and
second-order approximations to the solutions of MSDSGE models in which certain parame-
ters vary over time according to discrete Markov processes.1 The key is to derive high-order
approximations to the equilibrium conditions implied by the original nonlinear economic
model when Markov-switching parameters are present. Our methodology, therefore, over-
comes the serious shortcomings associated with the MSLRE shortcut. By working with the
original MSDSGE model directly rather than taking a system of linear rational expectations
equations with fixed parameters as a shortcut, we maintain the congruity between the orig-
inal economic model with Markov-switching parameters and the resultant approximations
to the model solution. Such congruity is necessary for researchers to derive both first-order
and higher-order approximations consistent with the original nonlinear model. Our general
methodology leads to several developments as follows.
      • We show that the steady state must be independent of the realization of any regime
        in the discrete Markov process governing parameter changes. We follow the literature
        and define the steady state with the ergodic mean values of Markov-switching pa-
        rameters. One natural extension of the conventional perturbation method commonly
        used for DSGE models with no time-varying parameters is to perturb all Markov-
        switching parameters around their ergodic mean values. We call this “the naive
        perturbation method.”
      • Since certain Markov-switching parameters such as time-varying volatilities do not
        influence the steady state, we develop a rigorous framework called “the Partition Prin-
        ciple” for partitioning the Markov-switching parameter space such that those Markov-
        switching parameters are not perturbed. By not perturbing the Markov-switching
        parameters that have no bearing on the steady state, we preserve the original Markov-
        switching nonlinearity in first-order as well as higher-order approximations. This
        preservation improves approximation accuracy, especially at low orders, in compar-
        ison to the naive perturbation method. We call this newly-developed method “the
        partition perturbation method.” We provide a revealing Markov-switching model to
        illustrate the importance of our methodology. In addition, we use a Markov-switching
        real business cycle (RBC) model as a more realistic example to demonstrate that the
        partition perturbation method delivers more accurate first-order and second-order
        approximations than the naive perturbation method.
  1
   We show in the paper that one can extend our methodology to higher-order approximations through
standard linear algebra.
                PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                  3

      • We show that any finite-order approximation to the model solution can be reduced to
         the manageable problem of solving a system of quadratic polynomial equations. The
         rest of the approximation involves solving a system of linear equations recursively—a
         key insight of our methodology. This result is powerful because it provides a viable
         way of approximating the solution of an MSDSGE model at a high order without in-
         curring much of the computational time. Obtaining such a result is difficult because
         Markov switching compounds the complexity of implicit differentiation when deriv-
         ing the Taylor series expansion. The most difficult part is the potentially rampant
         notation that inhibits the reader from following and implementing our methodology.
         We introduce a new notation that makes transparent to the reader (as well as us) that
         simple linear algebra is all researchers need to accomplish high-order approximations,
         even in the presence of time-varying coefficients in the Taylor series expansion.
      • Solving a system of quadratic polynomial equations is the only bottleneck for ob-
         taining an approximate solution of any order. There are numerical algorithms in the
         literature (Svensson and Williams (2007), Farmer, Waggoner, and Zha (2011), and
         Cho (2011)), but those algorithms may not converge or may find only a subset of
         solutions. We propose to apply the theory of Gröbner bases to obtaining all solu-
         tions to a system of quadratic polynomial equations.2 The Gröbner-bases approach
         has not been discovered or utilized in the DSGE literature. We document that it is
         computationally efficient relative to the existing numerical algorithms.
      • Once we obtain all solutions, we can determine how many of these solutions are
         stable according to the mean-square-stability criterion (Costa, Fragoso, and Marques
         (2005) and Farmer, Waggoner, and Zha (2009)). This procedure enables researchers
         to ascertain both the existence and the uniqueness of a stable solution.
  The rest of the paper is organized as follows. Section II presents the framework for solving
a general class of MSDSGE models. We outline our methodology, review the conventional
perturbation method, extend this commonly-used method to the naive perturbation method,
and develop the partition perturbation method according to the Partition Principle. Sec-
tion III derives both first-order and second-order approximations that have convenient forms
for researchers to use. We show how to reduce the complex Markov-switching problem to
solving a system of quadratic polynomial equations. We prove that the rest of the approx-
imation of any order involves simple linear algebra. Section IV proposes the application of
Gröbner bases for solving a system of quadratic polynomial equations, reviews the concept
of mean square stability, and discusses how efficient the Gröbner-bases approach is relative
  2For   the theory of Gröbner bases and its application to economics, see Kubler and Schmedders (2010a)
and Kubler and Schmedders (2010b) for finding multiple equilibria in general equilibrium models and Datta
(2010) for finding all Nash equilibria.
                 PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                    4

to the existing numerical algorithms. Section V uses a simple Markov-switching model to
illustrate why the partition perturbation method is more accurate than the naive perturba-
tion method. Section VI applies our methodology to a Markov-switching RBC model and
compares approximation errors between the two perturbation methods. Concluding remarks
are offered in Section VII.

                                           II. The Framework

  This section establishes the theoretical foundation of our proposed partition perturbation
method for a general class of MSDSGE models. We present the class of MSDSGE models
and introduce the key idea of partitioning the Markov-switching parameter space. Based
on this idea we propose the partition perturbation method and highlight the importance
of our method in contrast to the naive perturbation method that derives directly from the
conventional perturbation method, which has been used for DSGE models. Throughout the
paper, we use a stylized real business cycle (RBC) model as an illustrative example to guide
the reader through our new methodology.

II.1. A general class of MSDSGE models. We study a general class of MSDSGE models
in which some of the parameters follow a discrete Markov process indexed by st ∈ {1, . . . , ns }
                                       
with the transition matrix P = pst ,st+1 . The element pst ,st+1 represents the probability of
st+1 at time t + 1 conditional on observing st at time t. We denote the time t vector of
all Markov-switching parameters by θ(st ) ∈ Rnθ .3 We assume that the Markov process is
ergodic and denote the ns -vector of ergodic probabilities by p̄. The ergodic mean of θ(st ) is
θ̄ = [θ(1) · · · θ(ns )] p̄.
  Given the vector of state variables (xt−1 , εt , st ), the equilibrium conditions for MSDSGE
models have the general form
                                                                                    
                      Et f y t+1 , y t , xt , xt−1 , εt+1 , εt , θ (st+1 ) , θ (st ) = 0ny +nx ,        (1)

where Et denotes the mathematical expectation operator conditional on information available
at time t, y t ∈ Rny is a vector of non-predetermined (control) variables, xt ∈ Rnx is a vector
of (endogenous and exogenous) predetermined variables, 0ny +nx is an (ny + nx )-vector of
zeros, and εt ∈ Rnε is a vector of i.i.d. innovations to the exogenous predetermined variables
with Et εt+1 = 0nε and Et εt+1 ε|t+1 = I nε . The superscript | indicates the transpose of a
matrix or a vector and I nε denotes the nε × nε identity matrix. The function f is defined on
an open subset of Rnf , where nf = 2(ny + nx + nε + nθ ), and its range is a subset of Rny +nx .

  3The     parameters that are constant over time, which we call “constant parameters” for the rest of the
paper, are not included in the vector θ (st ). Unless otherwise stated, all vectors in this paper are column
vectors.
                   PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                          5

We make the following assumptions about f throughout the paper. These assumptions are
satisfied by almost all economic models.

Assumption 1. The function f is infinitely differentiable with respect to all arguments.

Assumption 2. Integration and differentiation of f are exchangeable.

Assumption 3. There exist the steady state values y ss and xss such that
                                                                  
                    f y ss , y ss , xss , xss , 0nε , 0nε , θ̄, θ̄ = 0ny +nx .                                  (2)

  We use a simple RBC model to illustrate how the equilibrium conditions can be arranged
in the form of (1). Consider an economy with the representative household whose preferences
over a stochastic sequence of consumption goods, ct , are represented by the expected utility
function                                                 ∞
                                                         X          cυt
                                                max E0         βt       ,
                                                         t=0
                                                                    υ
where β is the discount factor and υ relates to risk aversion. The resource constraint is

                                       ct + kt = zt1−α kt−1
                                                        α
                                                            + (1 − δ) kt−1 ,

where δ is the rate of depreciation, kt is a stock of physical capital, and zt represents a
technological process that evolves according to
                        zt                                      zt−1
                   log      = (1 − ρ(st )) µ (st ) + ρ(st ) log      + σ (st ) εt ,
                       zt−1                                     zt−2
where εt ∼ N (0, 1) is a standard normal random variable. The drift, persistence, and
volatility parameters are time varying with st ∈ {1, 2}. The three equations characterizing
the equilibrium are the equation describing the technological process and the following two
first-order equations

                                     cυ−1 = βEt cυ−1
                                                      1−α α−1          
                                      t          t+1 αzt+1 kt  + (1 − δ) ,
                                       ct + kt = zt1−α kt−1
                                                        α
                                                            + (1 − δ) kt−1 .
                                                                                                               zt
  The economy is non-stationary. To obtain a stationary equilibrium we define z̃t =                           zt−1
                                                                                                                   ,
        kt                  ct
k̃t =   zt
           ,   and c̃t =   zt−1
                                .   The stationary equilibrium conditions summarized by (1) can be
specifically expressed as
                                                                     
  03 = Et f y t+1 , y t , xt , xt−1 , εt+1 , εt , θ (st+1 ) , θ (st ) =
                              n                                                                            o
       c̃υ−1 − β z̃ υ−1 υ−1
                       c̃       αe [(1−ρ(st+1 ))µ(st+1 )+ρ(st+1 ) log(z̃t )+σ(st+1 )εt+1 ](1−α) α−1
                                                                                               k̃   + 1 − δ
       t          t      t+1                                                                     t
                                                                                                             
   Et                              c̃   + z̃ k̃ −  z̃ 1−α α
                                                          k̃     −  (1  −   δ) k̃                             , (3)
                                      t     t t      t      t−1                 t−1                         
                         log z̃t − (1 − ρ(st )) µ (st ) − ρ(st ) log z̃t−1 − σ (st ) εt
where y t = c̃t , xt = [k̃t z̃t ]| , εt = εt , and θ (st ) = [µ(st ) ρ(st ) σ(st )]| . The dimensions of
this RBC model are ny = 1, nx = 2, nε = 1, nθ = 3, and ns = 2.
               PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                   6

II.2. The conventional perturbation method. Before we propose our partition pertur-
bation method for solving MSDSGE models, we review the conventional perturbation method
used for solving constant-parameter DSGE models (Judd, 1998; Schmitt-Grohe and Uribe,
2004; Lombardo, 2010; Holmes, 2012; Borovic̆ka and Hansen, 2013; Gomme and Klein, Forth-
coming). The constant-parameter model can be considered as a special Markov-switching
model with either ns = 1 or θ(st ) = θ̄ for all st .
  The conventional perturbation method begins with positing that the solutions y t and xt
are of the form

                                           y t = g (xt−1 , εt , χ) ,                                 (4)
                                          xt = h (xt−1 , εt , χ) ,                                   (5)

where g : Rnx +nε +1 → Rny and h : Rnx +nε +1 → Rnx are functions with the Taylor series
representation about the point (xss , 0nε , 0) satisfying

                                          y ss = g (xss , 0nε , 0) ,                                 (6)
                                          xss = h (xss , 0nε , 0) ,                                  (7)

and χ ∈ R is the perturbation parameter. The conventional perturbation is a method that
recursively finds the Taylor series expansion of g and h by positing that equations (4) and
(5) are a solution of

             0ny +nx = F (y t , xt , xt−1 , εt , χ)
                       Z
                                                                                      
                     ≡      f g(xt , χεt+1 , χ), y t , xt , xt−1 , χεt+1 , εt , θ̄, θ̄ dµ(εt+1 ),    (8)
                            Rnε

for all xt−1 , εt , and χ, where µ(εt+1 ) is a σ-finite measure on the space of εt+1 . When χ = 1,
equation (8) reduces to equation (1). By construction, g and h satisfy equation (8) when
xt−1 = xss , εt = 0nε and χ = 0.
  To form the Taylor series expansion of g and h, one must be able to compute the deriva-
tives of g and h and evaluate these derivatives at the point (xss , 0nε , 0). By repeated implicit
differentiation of equation (8), one can recursively solve for the derivatives of g and h eval-
uated at (xss , 0nε , 0).

II.3. The naive perturbation method. It is straightforward to extend the conventional
perturbation method discussed in Section II.2 to MSDSGE models as in Amisano and Tris-
tani (2011). Suppose that y t and xt are of the form

                                          y t = g st (xt−1 , εt , χ) ,                               (9)
                                         xt = hst (xt−1 , εt , χ) ,                                 (10)
                 PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                              7

for all st , where g st : Rnx +nε +1 → Rny and hst : Rnx +nε +1 → Rnx are continuously differ-
entiable functions. In the constant-parameter case, the choice of the steady state as the
approximation point is natural and one needs to perturb εt+1 only. The choice of approxi-
mation point in the Markov-switching case is more involved. We show that θ(st+1 ) and θ(st )
must be perturbed. To this end we first show that the steady state in the Markov-switching
case must be independent of regime st .
  Suppose that the steady-state variables xss (st ) depend on regime st . As in the constant-
parameter case, we must choose the values of g st (xss (st ) , 0nε , 0) and hst (xss (st ) , 0nε , 0)
such that

  f g st+1 (hst (xss (st ), 0nε , 0) , 0nε , 0) , g st (xss (st ), 0nε , 0) ,
                                hst (xss (st ), 0nε , 0) , xss (st ), 0nε , 0nε , θ (st+1 ) , θ (st )) = 0ny +nx (11)

for all st and st+1 . Because the value of g st+1 is evaluated at the point (xss (st+1 ), 0nε , 0), it
follows that xss (st+1 ) = hst (xss (st ) , 0nε , 0) for all st and st+1 . For the latter relationship
to hold, it must be that xss (st ) = xss and xss (st+1 ) = xss for all st and st+1 . That is, the
steady state must be regime independent.
  We now show that the Markov-switching parameters θ(st+1 ) and θ(st ) must in general be
perturbed. Since xss (st ) = xss for all st , the system of equations (11) becomes
                                                                                                  
     f g st+1 (xss , 0nε , 0) , g st (xss , 0nε , 0) , xss , xss , 0nε , 0nε , θ (st+1 ) , θ (st ) = 0ny +nx .   (12)

This is a system of n2s (ny + nx ) equations in ns ny + nx unknowns (ny unknowns in each
g k (xss , 0nε , 0) for 1 ≤ k ≤ ns and another nx unknowns in xss ), which cannot be solved in
general. We must, therefore, perturb the Markov-switching parameters to reduce the number
of equations.
  One natural approach is to define a perturbation function for Markov-switching parameters
by
                                          θ(k, χ) = χθ(k) + (1 − χ)θ̄                                            (13)

for 1 ≤ k ≤ ns . When χ = 0, we have θ(k, 0) = θ̄; when χ = 1 we have θ(k, 1) = θ(k).
Given xss (k) = xss for 1 ≤ k ≤ ns , we have the following assumption

Assumption 4. The function g k (xss , 0nε , 0) has the same value for all 1 ≤ k ≤ ns . We
denote this value by y ss .

  With this perturbation and Assumption 4, system (12) becomes
                                                                             
                               f y ss , y ss , xss , xss , 0nε , 0nε , θ̄, θ̄ = 0ny +nx .

By Assumption 3 there is a solution to this system of equations.
                  PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                                        8

   For illustration we return to the RBC model in which the system of equations f is given
by (3). Let the steady state and ergodic mean values of parameters be denoted by y ss = c̃ss ,
xss = [k̃ss z̃ss ]| , and θ̄ = [µ̄ ρ̄ σ̄]| . The steady state must satisfy

                                                       
  03 = f y ss , y ss , xss , xss , 0nε , 0nε , θ̄, θ̄ =
                                                                    n                                                  o
                                    c̃υ−1  −   β  z̃ υ−1 υ−1
                                                            c̃          αe  [(1−ρ̄)µ̄+ρ̄ log(z̃ss )](1−α) α−1
                                                                                                         k̃     + 1 − δ
                                    ss             ss         ss                                           ss
                                                                                                                         
                                                     c̃     +    z̃   k̃   −  z̃ 1−α α
                                                                                      k̃    −   (1   − δ)  k̃             . (14)
                                                        ss         ss   ss      ss      ss                  ss          
                                                             log z̃ss − (1 − ρ̄) µ̄ − ρ̄ log z̃ss

Solving for the steady state is the same as in the constant-parameter case. With the pertur-
bation function (13), it is straightforward to write down an equation analog of the constant-
parameter case (8) and obtain the Taylor series expansions for g st and hst around the point
(xss , 0nε , 0). We call this approach the “naive perturbation method.” In Section V we show,
through a revealing example, why this method is naive in comparison to the new perturbation
method developed below.


II.4. The partition perturbation method. As in many DSGE models, the steady state
expressed in (14) can be obtained in closed form as

                                                          z̃ss = eµ̄ ,
                                                                                              1
                                 k̃ss = α−1 e(α−1)µ̄ β −1 e(1−υ)µ̄ − 1 + δ
                                                                                           α−1
                                                                                                   ,
                          and c̃ss = k̃ss 1 − δ − eµ̄ + α−1 β −1 e(1−υ)µ̄ − 1 + δ
                                                                                                       
                                                                                                            .

Clearly, the steady state solution does not depend on either ρ̄ or σ̄. As argued in Section II.3,
the purpose of perturbing the Markov-switching parameters around their ergodic mean values
is to solve the steady state when the perturbation parameter χ and the innovations εt are set
to zero. Since ρ (st ) and σ (st ) do not influence the steady state, perturbing these parameters
generates unnecessary approximations. If we do not perturb these parameters, we maintain
the Markov-switching nonlinearity along the direction of these parameters in the original
model. We formalize this idea by proposing the following perturbation function
                                   "        #                "           #       "                              #
                                    θ̄ 1 (k)                     θ̄ 1                θ̄ 1 + χ θ 1 (k) − θ̄ 1
                  θ(k, χ) = χ                   + (1 − χ)                    =                                             (15)
                                     θ 2 (k)                   θ 2 (k)                       θ 2 (k)

for 1 ≤ k ≤ ns with the Partition Principle stated below.

Partition Principle. Let the Markov-switching parameters be ordered and partitioned as
θ | (st ) = [θ |1 (st )    θ |2 (st )]. The second block θ 2 (st ) is chosen to contain the maximum
                  PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                                      9

number of Markov-switching parameters such that

  f (y ss , y ss , xss , xss , 0nε , 0nε , θ (st+1 , 0) , θ (st , 0)) =
                                                                                                              
                                                                f y ss , y ss , xss , xss , 0nε , 0nε , θ̄, θ̄ = 0ny +nx (16)

for all st and st+1 .

  According to the Partition Principle, the second block of Markov-switching parameters
is not perturbed. Since perturbation is necessary only for approximations to the original
nonlinear model, the fewer number of Markov-switching parameters we perturb, the more
accurate are finite-order approximations. We illuminate this point through examples dis-
cussed in Sections V and VI.
  It is practicable to implement the Partition Principle. Whenever we write down DSGE
models, we should be able to write down the steady state equilibrium conditions and identify
which Markov-switching parameters have no influence on these conditions. For most DSGE
models like our RBC model, the steady state can be solved in closed form. We group all
such Markov-switching parameters into θ 2 (st ) as long as the critical system (16) is satisfied.
Verifying whether (16) holds is straightforward.
  To obtain the analog of system (8), we define the continuously differentiable function
F st : Rny +2nx +nε +1 → Rny +nx as
                                       ns
                                       X                    Z       
  F st (y t , xt , xt−1 , εt , χ) =             pst ,st+1         f g st+1 (xt , χεt+1 , χ), y t , xt , xt−1 ,
                                      st+1 =1               Rnε
                                                                                                                
                                                                             χεt+1 , εt , θ(st+1 , χ), θ(st , χ) dµ(εt+1 )

such that (9) and (10) are a solution to

                                          F st (y t , xt , xt−1 , εt , χ) = 0ny +nx                                    (17)

for all st , xt−1 , εt , and χ. The perturbation functions θ(st+1 , χ) and θ(st , χ) are given
by (15). When χ = 1, the perturbed system (17) reduces to the original system (1). By
construction, system (17) is satisfied for all st when y t = y ss , xt = xt−1 = xss , εt = 0nε ,
and χ = 0. We call this approach “the partition perturbation method.”
  Like the conventional perturbation method or the naive perturbation method, the par-
tition perturbation method allows one to solve recursively for the partial derivatives of g st
and hst by repeated implicit differentiation of system (17) and evaluate these derivative
at (xss , 0nε , 0). Unlike those perturbation methods, the partial derivatives of g st and hst
depend on the partial derivatives of f evaluated at

                               (y ss , y ss , xss , xss , 0nε , 0nε , θ(st+1 , 0), θ(st , 0)) .
               PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                     10

Because the second block of Markov-switching parameters is not perturbed, the Taylor series
coefficients for g st and hst are in general time-varying when the set containing θ 2 (st ) is
not empty. The presence of such time-varying Taylor series coefficients makes high-order
approximations a potentially intractable problem. One principal contribution of this paper
is to prove that the partition perturbation method can be implemented by reducing this
potentially intractable problem to a recursive problem involving only simple linear algebra
once we remove the bottleneck of solving a system of quadratic polynomial equations. This
theoretical result is provided in Section III. In Section V we provide a revealing Markov-
switching dynamic equilibrium example that has closed-form solutions. Using this example
we illustrate that the Partition Principle delivers a more accurate solution than the naive
perturbation method for an approximated solution of any order.

                 III. First-Order and Second-Order Approximations

  This section gives a detailed description of how to derive first-order and second-order
approximations to the model solution by using the partition perturbation method. We
present the results up to only second order to conserve the space, but it is straightforward
to derive higher-order approximations with a similar approach. To make our theoretical
results transparent to a general reader, we develop a new notation, which proves crucial
to the clarity of our derivations. The new notation, moreover, enables us to show that
Markov-switching volatility (uncertainty) has first-order effects on dynamics while the naive
perturbation method nullifies such effects by construction.

III.1. New notation. We stack the regime dependent solutions (9) and (10) as
                                                                                                   
                             g 1 (xt−1 , εt , χ)                                   h1 (xt−1 , εt , χ)
                                    ..                                                 ..          
 Y t = G (xt−1 , εt , χ) = 
                                     .           and X t = H (xt−1 , εt , χ) = 
                                                                                         .          .
                                                                                                      
                            g ns (xt−1 , εt , χ)                                  hns (xt−1 , εt , χ)
Define Y ss = 1ns ⊗y ss and X ss = 1ns ⊗xss , where 1ns is the ns -vector of ones. It follows that
                                                                                      
y t = g st (xt−1 , εt , χ) = e|st ⊗ I ny Y t and xt = hst (xt−1 , εt , χ) = e|st ⊗ I nx X t for all st ,
where ek , for 1 ≤ k ≤ ns , is the k th column of the ns × ns identity matrix. Approximating
a solution to y t and xt is equivalent to approximating a solution to Y t and X t .
  Define Fi : Rns ny +ns nx +nx +nε +1 → Rny +nx by

                                                   e|i ⊗ I ny Y t , (e|i ⊗ I nx ) X t , xt−1 , εt , χ
                                                                                                    
            Fi (Y t , X t , xt−1 , εt , χ) = F i

and F : Rns ny +ns nx +nx +nε +1 → Rns (ny +nx ) by
                                                                                       
                                                         F1 (Y t , X t , xt−1 , εt , χ)
                                                                      ..               
                       F (Y t , X t , xt−1 , εt , χ) = 
                                                                       .               .
                                                                                        
                                                        Fns (Y t , X t , xt−1 , εt , χ)
              PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                           11

With these definitions, system (17) is equivalent to

                             F (Y t , X t , xt−1 , εt , χ) = 0ns (ny +nx ) .               (18)

  We now introduce a derivative notation that is used throughout the paper. Let w(u) be
a continuously differentiable function from Rnu into Rnw . Let u` be the `th component of u
for 1 ≤ ` ≤ nu and wk (u) be the k th component of w(u) for 1 ≤ k ≤ nw . D` wk (u), a real
number, denotes the partial derivative of wk with respect to u` evaluated at the point u.
Dw(u), the nw × nu matrix [D` wk (u)] for 1 ≤ k ≤ nw and 1 ≤ ` ≤ nu , denotes the total
derivative of w evaluated at the point u.
  As for second-order partial derivatives, let D`2 D`1 wk (u), a real number, denote the second
partial derivative of wk with respect to u`1 and u`2 evaluated at u. D`2 D`1 w(u) denotes
the nw -vector [D`2 D`1 wk (u)] for 1 ≤ k ≤ nw . D`2 Dw(u) denotes the nw × nu matrix
[D`2 D` wk (u)] for 1 ≤ k ≤ nw and 1 ≤ ` ≤ nu . It is straightforward to extend this notation
to higher-order partial derivatives.
  If w(u, v) is a continuously differentiable function from Rnu +nv into Rnw , we use Du w(u, v)
to denote the nw × nu matrix consisting of the first nu columns of the nw × (nu + nv )
matrix Dw(u, v). Similarly, Dv w(u, v) denotes the last nv columns of Dw(u, v) and
Dw(u, v) = [Du w(u, v) Dv w(u, v)].
                                                  h           i           h           i
III.2. First-order approximation. Denote z |t = x|t−1 ε|t χ and z |ss = x|ss 0|nε 0 .
The dimension of both z t and z ss is nz = nx + nε + 1. The first-order approximation of
G(z t ) and H(z t ) is

                             G(z t ) ≈ Y ss + DG(z ss )(z t − z ss ),
                             H(z t ) ≈ X ss + DH(z ss )(z t − z ss ).

The following proposition shows that both DG(z ss ) = [Dxt−1 G(z ss ) Dεt G(z ss ) Dχ G(z ss )]
and DH(z ss ) = [Dxt−1 H(z ss ) Dεt H(z ss ) Dχ H(z ss )] can be obtained by solving a system
of quadratic polynomial equations and two systems of linear equations.

Proposition 1. Under Assumptions 1-4, the matrices Dxt−1 G(z ss ) and Dxt−1 H(z ss ) can be
obtained by solving a system of ns (ny +nx )nx quadratic polynomial equations in ns (ny +nx )nx
unknowns. Given a solution to this quadratic polynomial system, the matrices Dεt G(z ss )
and Dεt H(z ss ) can be obtained by solving a system of ns (ny + nx )nε linear equations in
ns (ny + nx )nε unknowns; the vectors Dχ G(z ss ) and Dχ H(z ss ) can be obtained by solving a
system of ns (ny + nx ) linear equations in ns (ny + nx ) unknowns.

Proof. See Appendix A.

  The proof of Proposition 1 shows how to represent the first-order solution in a form that
can be implemented in practice. More important is the elegant result that reduces the
               PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                                    12

potentially intractable problem of solving MSDSGE models to the manageable problem of
solving a system of quadratic polynomial equations. Section IV provides an effective way of
solving this problem.

III.3. Characterizing the first-order approximation. As shown in the proof of Proposi-
tion 1, the slope coefficient matrices, represented by Dxt−1 G(z ss ) and Dxt−1 H(z ss ), and the
impact coefficient matrices represented by Dεt G(z ss ) and Dεt H(z ss ), are functions of the
partial derivatives Dyt+1 f (uss ), Dyt f (uss ), Dxt f (uss ), Dxt−1 f (uss ), and Dεt f (uss ), where

                      u|ss = [y |ss , y |ss , x|ss , x|ss , 0|nε , 0|nε , θ(st+1 , 0)| , θ(st , 0)| ].

Thus, the slope and impact coefficients depend, in general, on both θ 2 (st+1 ) and θ 2 (st ).
When the naive perturbation method is used, by contrast, the slope and impact coefficients
depend only on θ̄, not on θ(st+1 ) or θ(st ), as stated in the following corollary.

Corollary 1. Let Assumptions 1-4 hold. Under the naive perturbation method, the first-
order coefficients Dxt−1 G(z ss ), Dxt−1 H(z ss ), Dεt G(z ss ), and Dεt H(z ss ) do not depend on
θ (st ), but are functions of θ̄ only.

  For our RBC model summarized in (3), one can see that Dyt+1 f (uss ) and Dxt f (uss )
depend on ρ(st+1 ), Dxt−1 f (uss ) depends on ρ(st ), and Dεt f (uss ) depends on σ(st ). Thus,
both the Markov-switching persistence and volatility parameters have first-order effects. By
contrast, these effects are muted by the naive perturbation method because the partial
derivatives of f depend only on ρ̄ and σ̄.4 Consequently the finite-order approximation
becomes less accurate. In Section VI we provide a numerical assessment of this accuracy by
computing approximation errors of the Euler equations.

III.4. Second-order approximation. The second-order approximation is represented by
                                                       nz X nz
                                                    1X
  G(z t ) ≈ Y ss + DG(z ss )(z t − z ss ) +                    D` D` G(z ss )(zt,`1 − zss,`1 )(zt,`2 − zss,`2 ),
                                                    2 ` =1 ` =1 2 1
                                                       1      2
                                                       nz X
                                                          nz
                                                    1  X
 H(z t ) ≈ X ss + DH(z ss )(z t − z ss ) +                            D`2 D`1 H(z ss )(zt,`1 − zss,`1 )(zt,`2 − zss,`2 ),
                                                    2`
                                                         1 =1 `2 =1


where zt,` and zss,` are the `th component of z t and z ss . The following proposition delivers
a powerful result that the vector D`2 D`1 G(z ss ) and D`2 D`1 H(z ss ) can be obtained through
simple linear algebra.

  4The   naive perturbation method resembles the existing methods for solving DSGE models with drift-
ing parameters, where slope and impact coefficients in the first-order approximation are not time-varying
(Fernandez-Villaverde, Guerron-Quintana, and Rubio-Ramirez, 2014).
                PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                     13

Proposition 2. Under Assumptions 1-4 and given a first-order approximation, the vectors
D`2 D`1 G(z ss ) and D`2 D`1 H(z ss ), for 1 ≤ `1 , `2 ≤ nz , can be obtained by solving a system
of ns (ny + nx )n2z linear equations in ns (ny + nx )n2z unknowns.

Proof. See Appendix A.

  Because the coefficients represented by D`2 D`1 G(z ss ) and D`2 D`1 H(z ss ) can be time-
varying, it is not at all obvious that Proposition 2 would hold.                   One of the principal
developments in this paper is to reduce the potentially unmanageable complexity of the
Markov-switching problem to a straightforward linear algebra problem for higher-order ap-
proximations. In the proof of Proposition 2 we show that, with a delicate application of
implicit differentiation, the second-order approximation simply requires solving a system
of linear equations even in the presence of Markov-switching coefficients.5 As second-order
coefficients are functions of first-order coefficients, Markov-switching volatility has a first-
order effect on the impact coefficients and a second-order effect on both slope and impact
coefficients.

                                 IV. Removing the Bottleneck

  Propositions 1 and 2 show how to translate the complex Markov-switching DSGE problem
into a simple linear algebra problem, as long as one is able to solve for Dxt−1 G(z ss ) and
Dxt−1 H(z ss ). As indicated by Proposition 1, the bottleneck involves solving a system of
quadratic polynomial equations. In this section we discuss the Gröbner-bases approach
for solving this system and the mean-square-stability (MSS) criterion for selecting a stable
solution. The theory of Gröbner bases implies that in most cases we can find all the solutions
of the system and thus form the first-order Taylor series expansion of G and H. Stable first-
order solutions are then selected by the MSS criterion. Higher-order expansions can be
derived recursively from a first-order stable solution.

IV.1. Solving polynomial equations with Gröbner bases. When there are no Markov-
switching parameters, the system of quadratic polynomial equations (see system (A4) in
Appendix A) collapses to a special form that can be solved by using the generalized Schur
decomposition (Uhlig, 1999; Klein, 2000). When Markov-switching parameters are present,
however, the system of ns (ny + nx )nx quadratic polynomial equations in ns (ny + nx )nx
unknowns are no longer of this special form and the general Schur technique is no longer
applicable. Gröbner bases provide a practical means to obtain all the solutions to a system
of quadratic polynomial equations. A more detailed description of Gröbner bases is provided
  5Armed   with our notation and applying the same technique, one can prove that the approximation of any
higher-order higher involves solving a system of linear equations recursively. We leave the derivation to the
reader.
               PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                         14

in Appendix B. In this section we provide an intuitive explanation of how to apply Gröbner
bases to solving a system of multivariate polynomials.
  Suppose one wishes to find all the solutions to a system of n polynomial equations in n
unknowns. There exist a number of routines that transform the original system of n polyno-
mial equations to another system of n polynomial equations with the same set of solutions.
This transformed system is known as a Gröbner basis. The following theorem, known as
the Shape Lemma, shows that in most cases there is a Gröbner basis with a particularly
powerful form. The Shape Lemma is known in the mathematics and computational science
literature, but is still an unfamiliar object in the economics literature. We therefore restate
this theorem in a form that is suitable to our problem.

The Shape Lemma There exists an open dense subset S of all systems of n polynomial
equations in n unknowns such that for every system

                            f1 (x1 , . . . , xn ) = 0, · · · , fn (x1 , . . . , xn ) = 0

in S, there exists a system of n polynomial equations in n unknowns with the same set of
roots of the form

                    x1 − q1 (xn ) = 0, · · · , xn−1 − qn−1 (xn ) = 0, qn (xn ) = 0,

where each qi (xn ) is a univariate polynomial.

  See Becker, Marianari, Mora, and Treverso (1993) for the proof of this result. There are
several important aspects of the Shape Lemma. First, most polynomial systems have a
Gröbner basis of this form. Second, most algorithms for obtaining a Gröbner basis returns
the above form. For instance, Mathematica’s GroebnerBasis[] command implements the
Shape Lemma. Third, it is straightforward to find all the roots of the univariate polynomial
qn (xn ). With these values of xn in hand, it is trivial to find x1 , · · · , xn−1 .
  A large strand of literature has dealt with the computation of Gröbner bases in the Shape
Lemma. Buchberger (1998)’s algorithm is the original technique. A number of more efficient
variants have been subsequently proposed. We refer the interested reader to Cox, Little, and
O’Shea (1997). In this paper we use Mathematica to find a Gröbner basis.
  To illustrate how powerful the Shape Lemma is, consider the following example featuring
a system of quadratic polynomial equations in four unknown variables x1 , . . . , x4 :

                            x1 x2 + x3 x4 + 2 = 0, x1 x2 + x2 x3 + 3 = 0,
                     x1 x3 + x4 x1 + x4 x2 + 6 = 0, and x1 x3 + 2x1 x2 + 3 = 0.
              PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                            15

A Gröbner basis of the form given in the Shape Lemma is
                  1                                  1
            x1 − (9x54 + 6x34 − 15x4 ) = 0, x2 − (−9x54 − 6x34 + 99x4 ) = 0,
                  28                                28
                    1
             x3 − (−3x54 − 9x34 − 2x4 ) = 0, and 3x64 + 9x44 − 19x24 − 49 = 0.
                   14
The last polynomial is univariate of degree six in x4 . There are 6 roots for this polynomial.
Each of these roots can be substituted into the first three equations to obtain all 6 solutions.
The theory of Gröbner bases ensures that these solutions are the same as those of the original
system (see Appendix B for details).
  This example illustrates the multiple-solution nature of a system of quadratic polynomial
equations. For the two models studied in this paper, it turns out that there is a unique
stable solution. We are able to establish this result precisely because we use the theory of
Gröbner bases to find all the solutions to the system of quadratic polynomial equations,
coupled with the MSS criterion (discussed below), to ascertain the uniqueness of a stable
first-order solution.

IV.2. Mean square stability. In the case of constant-parameter DSGE models, whether
the first-order approximation is stable or not can be determined by verifying whether its
largest absolute generalized eigenvalue is greater than or equal to one, a condition that
holds for most concepts of stability. In the MSDSGE case, the problem is both subtle and
complicated because alternative concepts of stability would imply different kinds of solutions.
Given the first-order approximation, we use the concept of mean square stability (MSS) as
defined in Costa, Fragoso, and Marques (2005) and advocated by Farmer, Waggoner, and
Zha (2009) who discuss several advantages of using the MSS criterion over alternative ones
such as the bounded stability. The MSS criterion states that a solution is stable if and only
if all the eigenvalues of the ns n2x × ns n2x matrix
                                 h                                             i
                   |
                          
                 P ⊗ In2x diag Dxt−1 h1 ⊗ Dxt−1 h1 . . . Dxt−1 hns ⊗ Dxt−1 hns

are inside the unit circle, where diag denotes the block diagonal matrix with the Dxt−1 hk ⊗
Dxt−1 hk , for k = 1, . . . , ns , along the diagonal. The nx × nx matrices Dxt−1 hk are obtained
by reading off the appropriate rows of the matrix Dxt−1 H. In particular we have
                                                       
                                              Dxt−1 h1
                                                 ..    
                                  Dxt−1 H = 
                                                  .    .
                                                        
                                              Dxt−1 hns
IV.3. Why is the Gröbner-bases approach computationally efficient? While the
mathematics literature provides no specific formula to determine the nature of solutions for
the system of quadratic polynomial equations in regard to no solution, a finite number of
solutions, or infinitely many solutions, an open dense subset in the Shape Lemma implies
              PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                          16

that, for all practical purposes, a system of quadratic polynomial equations has a finite
number of solutions.
  Although the theory of Gröbner bases is well known in the mathematics literature, the
existing DSGE literature has not discovered or utilized this powerful application. Instead the
literature has relied on numerical methods such as Newton’s algorithm (Farmer, Waggoner,
and Zha, 2011). We have experimented with a number of widely-used DSGE models with a
wide range of parameter configurations (including a Markov-switching dynamic equilibrium
model larger than Smets and Wouters (2007)’s model), the Gröbner-bases approach finds
all the solutions in a fraction of a second while Newton’s algorithm typically takes several
seconds to find only a subset of the solutions, depending on how good the starting points
are and how thorough the search for these points is. There may be situations in which the
Gröbner-bases application does not return solutions within a reasonable frame of time. In
such a case, one can simply code up additional lines terminating the application and returning
the warning message “no finite number of solutions.” As for the Newton algorithm, we often
encounter the situation in which the algorithm fails to converge while the Gröbner-bases
approach proves successful. For both theoretical and practical points of view, the Gröbner-
bases approach is superior to the Newton method.


             V. Understanding the Partition Perturbation Method

  In the preceding sections we develop the partition perturbation method and show how to
use it for obtaining first-order and second-order approximations to the solutions of MSDSGE
models. In this section we use a simple dynamic equilibrium model to reveal the power of the
partition perturbation method in comparison to the naive perturbation method. The model
is particularly instructive because we can obtain a closed-form solution, which allows us to
show that the naive partition method incurs needless approximation errors in the Taylor
series expansion, especially in low-order expansions.
  Consider a simple inflation model in which the nominal interest rate is linked to the real
interest rate and the expected inflation rate by the Fisher equation

                                       Rt = r + Et π t+1 ,

where Rt is the nominal interest rate at time t, π t+1 is the inflation rate at time t + 1, and
the steady state real interest rate r = R − π. Monetary policy follows the rule

                             Rt = R + φ (st ) (π t − π) + σ (st ) εt ,

where the monetary policy shock εt is an i.i.d. normal random variable. A positive monetary
policy shock raises the nominal interest rate and lowers inflation. Denoting π̂ t = π t − r and
                PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                            17

combining the previous two equations lead to

                                       φ (st ) π̂ t + σ (st ) εt = Et π̂ t+1 .                                (19)

Suppose that st ∈ {1, 2} follows a two-state Markov process. Because of the presence of
Markov-switching parameters φ (st ) and σ (st ), equation (19) is in essence a nonlinear model.
  To write this model in the same form as (1), we define a new variable such that π ∗t = π t
and let y t = π ∗t and xt = π t . We thus have y ss = π and xss = π. To use the partition
perturbation method, we follow the Partition Principle and partition the Markov-switching
parameters
h          iso| that no Markov-switching parameter is perturbed. Specifically, θ (k, χ) =
  φ(k) σ(k) . The equilibrium conditions can be expressed as
                                                                       
  Et f y t+1 , y t , xt , xt−1 , χεt+1 , εt , θ (st+1 , χ) , θ (st , χ) =
                                                        "                                                     #
                                                          (1 − φ (st )) π + φ (st ) π t − π ∗t+1 − σ (st ) εt
                                                    Et                                                          (20)
                                                                             π ∗t − π t
such that
                   f (y ss , y ss , xss , xss , 0, 0, θ(j, 0), θ(i, 0)) = 0, for 1 ≤ i, j ≤ 2.

Proposition 3. With the partition perturbation method, a first-order approximation to the
nonlinear model (20) is an exact solution and there are no higher-order Taylor series expan-
sions (i.e., higher-order coefficients are all zero).

Proof. See Appendix A.

  The proof of Proposition 3 in Appendix A shows that the implication of Proposition 3
is more general than the result specific to model (19) or (20). For a large class of Markov-
switching dynamic equilibrium models, a first-order solution generated by the partition per-
turbation method delivers an exact solution. Indeed, applying the partition perturbation
method to our example yields the exact solution as
                                                           σ (st )
                                                π̂ t = −           εt .
                                                           φ (st )
  By contrast, the naive perturbation method perturbs the Markov-switching parameters as
                                     " #           "              #
                                      φ̄             φ (st ) − φ̄
                           θ(k, χ) =     + (1 − χ)                  ,
                                      σ̄             σ (st ) − σ̄

where φ̄ and σ̄ are the ergodic means of φ (st ) and σ (st ). The first-order approximation
                                                               
generated by the naive perturbation method is π t = − σ̄/φ̄ εt for all st . Clearly, this
solution is not exact and higher-order Taylor series expansions are needed to improve the
solution accuracy.
                PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                         18

     We demonstrate these results numerically with the following parameterization: p1,1 = 0.95,
p2,2 = 0.85, φ(1) = 1.25, φ(2) = 0.96, σ(1) = 0.1, and σ(2) = 0.6. The Gröbner-bases
analysis gives four solutions for this parameterization, but only one is stable according to the
MSS criterion. The first-order stable approximation generated by the partition perturbation
method is
                       π̂ t = −0.08 εt for st = 1 and π̂ t = −0.625 εt for st = 2.
Because all higher-order coefficients are exactly zero, the first-order approximation is the
exact solution.
     Similarly, the first-order stable approximation produced by the naive perturbation method
is
                  π̂ t = −0.191083 εt for st = 1 and π̂ t = −0.191083 εt for st = 2.
Because all the Markov-switching parameters are perturbed, the first-order solution does not
depend on the realization of a particular regime. The regime-dependent nature relies on the
second-order solution

                 π̂ t = 0.0447610 εt for st = 1 and π̂ t = −0.8986170 εt for st = 2.

     How does this approximation compares to the exact solution? To assess the accuracy of
the two perturbation methods, we compute Euler-equation errors (EEs) as suggested in Judd
(1998). Table 1 reports the base-10 log absolute value of the approximation error for the
original nonlinear equation (19), where the initial condition is set as εt = 1.0. We discuss
the reason for using the base-10 log value in Section VI.3.
     Given the simplicity of this model, we can compute EEs without any simulation. Since
the first-order solution generated by the partition perturbation method is the exact solution
(Proposition 3), the absolute value of the approximation error is zero (the log absolute
value of the error is −∞). On the other hand, the naive perturbation method relies on
higher-order approximations to get a more accurate solution. As indicated in Table 1, the
second-order approximation obtained by the naive perturbation method is closer to the exact
solution with a much smaller approximation error than the error generated by the first-order
approximation, but it is still not close to the exact solution. This example clearly illustrates
the importance of the partition perturbation method in obtaining an accurate low-order
approximation.
                  Table 1. Euler-equation errors (base-10 log absolute value)

        Perturbation Method                 Partition      Naive           Naive
                                  Exact First-order First-order Second-order
                  EE               −∞         −∞          −0.5564        −1.3691
                   PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                   19

                                VI. Application to the RBC Model

      In this section we apply the partition perturbation method to the two-state Markov-
   switching RBC model introduced in Section II.1. We then compare approximation errors
   generated by the partition perturbation method with those incurred by the naive perturba-
   tion method to asses the accuracy of both methods.
      The parameterization we use is presented in Table 2 and it is motivated by business-
   cycle facts related to emerging markets. The value of β corresponds to a real rate of
   3 percent in steady state, the value of of α corresponds to a capital share of one-third,
   and the value of δ corresponds to an annual capital depreciation rate of approximately
   10 percent. The growth-rate parameters µ (1) and µ (2) and the standard deviations pa-
   rameters σ (1) and σ (2) are set to make the output growth and its unconditional variance
   differ across regimes in magnitudes consistent with the emerging markets such as the Ar-
   gentinian economy (Fernández-Villaverde and Rubio-Ramirez, 2007; Fernández-Villaverde,
   Guerrón-Quintana, Rubio-Ramı́rez, and Uribe, 2011). Note that the first regime is associ-
   ated with positive growth while the second with negative growth. Moreover, the first regime
   is less volatile and more persistent than the second regime. Given this parameterization, the
   stationary steady-state values of consumption, capital, and technology are c̃ss = 2.08259,
   k̃ss = 22.1504, and z̃ss = 1.007. Denote ĉt = c̃t − c̃ss , k̂t = k̃t − k̃ss , and ẑt = z̃t − z̃ss .


   VI.1. Solution from the partition perturbation method. For the first-order approxi-
   mation, the Gröbner-bases approach delivers four solutions. According to the MSS criterion,
   only one of these solutions is stable. We report below the second-order approximation asso-
   ciated with the unique stable solution


                                                                                        |
                                                             −0.0009    −0.0003
                                                            
                                                                                    0
                                                             0.0022
                                                                       −0.0957     0   
                                                                                        
                                                             0.0002
                                                                       −0.0069     0   
                                                                                        
                                                            −0.0004    −0.0168     0   
                                                                                       
                                                             0.0022    −0.0957     0
                                                                                       
                                                                                        
                                                            −0.1173     2.3364 −0.0894
                                                                                       
                                                                                                     
                                            k̂t−1        0.0006     0.0153  0.0007     k̂t−1     k̂t−1
 ĉt      0.0405 0.1264   0.0091      0.000049                                        
k̂t  = 0.9692 −2.1406 −0.1552                  ẑt−1 
                                                         1  0.0008     0.0374  0.0018 
                                                                                         ẑt−1  ⊗ ẑt−1 
                                                                                                         
                                      −0.3720 
                                                       + 
                                                     εt  2 0.0002    −0.0069     0     εt   εt 
 ẑt        0.0    0.1    0.0072       0.0184                0.0006
                                                                                        
                                                     1                  0.0153  0.0007 
                                                                                               1         1
                                                             0.0000     0.0011  0.0001 
                                                                                       
                                                             0.0001     0.0027  0.0001 
                                                                                       
                                                            
                                                            −0.0004    −0.0168
                                                                                        
                                                                                   0   
                                                                                        
                                                             0.0008     0.0374  0.0018 
                                                                                       
                                                             0.0001     0.0027  0.0001 
                                                             −0.0495     0.0557  0.0003
                       PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                             20

      if st = 1, and
                                                                                         |
                                                     −0.0009             −0.0003
                                                    
                                                                                     0
                                                    
                                                        0                   0       0   
                                                                                         
                                                     0.0005
                                                                        −0.0208     0   
                                                                                         
                                                    −0.0021              0.0405     0   
                                                                                        
                                                         0                   0       0
                                                                                        
                                                                                        
                                                         0                   0       0
                                                                                        
                                                                                        
                                                                                                    
                                       k̂               0                   0       0       k̂t−1    k̂t−1
            0.0405 0.0 0.0268 −0.0968  t−1 
                                                                                     
   ĉt                                                                                  
                                          ẑt−1   1     0                   0       0    ẑt−1  ẑt−1 
                                                                                           εt  ⊗  εt 
  k̂t  = 0.9692 0.0 −0.4649 0.9227  
                                         εt  + 2  0.0005
                                                                                                     
                                                                         −0.0208     0
   ẑt        0.0  0.0 0.0217 −0.0410                                                   
                                             1      
                                                        0                   0       0   
                                                                                               1        1
                                                     0.0004              0.0100  0.0005 
                                                                                        
                                                    −0.0012             −0.0193 −0.0009
                                                                                        
                                                    
                                                    −0.0021
                                                                                         
                                                                         0.0405     0   
                                                                                         
                                                    
                                                        0                   0       0   
                                                                                         
                                                    −0.0012             −0.0193 −0.0009
                                                     −0.0467              0.0869  0.0017

      if st = 2. For the dynamics of ĉt and k̂t , one can see that the coefficients of ẑt−1 and εt
      are considerably different across regimes. The large difference across regimes also shows up
      in the coefficients of k̂t−1 εt , ẑt−1 εt , and ε2t . These differences are induced by the Markov-
      switching volatility parameter σ (st ), which has both first-order and second-order effects on
      the dynamics of ĉt and k̂t .6

      VI.2. Solution from the naive perturbation method. The naive perturbation method,
      according to Corollary 1, does not have the time-varying effects as discussed in the previous
      section. In particular, it can be seen from the following second-order solution that the
                                                            2
      coefficients of ẑt−1 , εt , k̂t−1 ẑt , k̂t−1 εt , ẑt−1 , ẑt−1 εt , and ε2t are all identical across regimes.
                                                                                           |
                                                      −0.0008               −0.0003
                                                     
                                                                                      0.
                                                      0.0014
                                                                           −0.0643   0.  
                                                      0.0002
                                                                           −0.0116   0.  
                                                      0.0006
                                                                           −0.0186   0.  
                                                      0.0014               −0.0643   0. 
                                                                                          
                                                      0.0038                0.1027   0. 
                                                                                          
                                                                                                        
                                       k̂t−1      0.0007                0.0185   0.       k̂t−1     k̂t−1
 ĉt      0.0374 0.0856   0.0154  0.0335                                                 
                                                  1
k̂t  = 0.9703 −1.5534 −0.2796 −0.4535  t−1 +  0.0449
                                            ẑ                             −0.7477 0.0333 
                                                                                            ẑt−1  ⊗ ẑt−1 
                                                                                                            
                                           εt  2  0.0002                 −0.0116   0.      εt   εt 
 ẑt        0.   0.0667   0.012   0.0191             
                                                      0.0007
                                                                                           
                                               1                            0.0185   0.         1         1
                                                      0.0001                0.0033   0. 
                                                                                          
                                                     −0.0058                0.1171 −0.0048
                                                                                          
                                                     
                                                                            −0.0186
                                                                                           
                                                      0.0006                         0. 
                                                                                          
                                                      0.0449
                                                                           −0.7477 0.0333 
                                                                                           
                                                     −0.0058                0.1171 −0.0048
                                                      −0.1203                0.1585 −0.0014

        6The                                                                    2
               time-varying coefficients of the cross terms k̂t−1 ẑt−1 , and ẑt−1 are related to the Markov-switching
      persistence parameter ρ (st ).
                       PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                  21

      if st = 1, and
                                                                                       |
                                                       −0.0008         −0.0003
                                                      
                                                                                  0.
                                                       0.0014
                                                                      −0.0643    0.  
                                                       0.0002
                                                                      −0.0116    0.  
                                                       −0.001          0.0369    0. 
                                                                                      
                                                       0.0014         −0.0643    0. 
                                                                                      
                                                       0.0038          0.1027    0. 
                                                                                      
                                                                                                    
                                      k̂t−1        0.0007          0.0185    0.       k̂t−1     k̂t−1
 ĉt      0.0374 0.0856   0.0154 −0.0626                                             
k̂t  = 0.9703 −1.5534 −0.2796 0.8996  ẑt−1 + 1 −0.0897          1.4958 −0.0667 ẑt−1  ⊗ ẑt−1 
                                                                                                      
                                           εt  2  0.0002            −0.0116    0.      εt      εt 
 ẑt        0.   0.0667   0.012  −0.038               
                                                       0.0007
                                              1                        0.0185    0.         1         1
                                                       0.0001          0.0033    0. 
                                                                                      
                                                       0.0116         −0.234   0.0096 
                                                                                      
                                                      
                                                       −0.001
                                                                                       
                                                                       0.0369    0.  
                                                      −0.0897          1.4958 −0.0667
                                                                                      
                                                       0.0116         −0.234   0.0096 
                                                       −0.1248          0.2792 −0.0054

      if st = 2.
        The only Markov-switching effect is through the coefficient of the perturbation parameter
      χ. As a result, the naive perturbation method produces less accurate approximations as
      shown in the following section—a result that confirms what we find in Section V.
                   Table 2. The parameterization for the Markov-switching RBC model

         α         β     υ       δ      µ (1)      µ (2)     ρ (1) ρ (2)     σ (1)     σ (2)    p1,1   p2,2
        0.33 0.9976 −1 0.025 0.0274 −0.0337                   0.1    0.0    0.0072 0.0216 0.75 0.5


      VI.3. Assessing approximation errors. Using the parameterization in Table 2, we com-
      pare the accuracy of approximated solutions from the two perturbation methods. Our results
      confirm that the partition perturbation method is more accurate than the naive perturbation
      method, especially for first-order and second-order approximations.
        As a basis for comparison, we solve the nonlinear model using value function iterations
      (Uhlig, 1999). To accomplish this task we formulate the value function problem for the
      Markov-switching stationary RBC model as
                                                   υ                           
                                                 c̃       υ
                                                               
                                                                  0 0 0 0
                          V k̃, z̃, ε, s = max        + β z̃ EV k̃ , z̃ , ε , s
                                            c̃,k̃   υ
      subject to

              c̃ + z̃ k̃ 0 = z̃ 1−α k̃ α + (1 − δ) k̃ and log z̃ 0 = (1 − ρ(s))µ(s) + ρ(s) log z̃ + σ(s)ε.

      Following Aruoba, Fernandez-Villaverde, and Rubio-Ramirez (2006), we solve the problem
      on a grid of 25600 points for k̃, 51 points for z̃, and 51 points for ε. We use Tauchen
      (1986)’s method to discretize the stochastic process and smooth the policy functions using
                        PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                                            22

   the Shape-Preserving Splines described in Judd and Solnick (1994). Since we need to find
   two value functions (one for each regime), the computation is very expensive. To solve the
   above value function problem within a reasonable amount of time, we rely on the CUDA
   (compute unified device architecture) of NVIDIA to build algorithms that utilize graphics
   processing units (GPUs). This approach leads to a remarkable improvement in computing
   time. Aldrich, Fernández-Villaverde, Gallant, and Rubio-Ramı́rez (2011) document that
   utilization of the GPU delivers a speed improvement of about 200 times.
      Let g order
            st    and horder
                       st    denote the solution from the Taylor series expansion of a particular
   order of interest. For our Markov-switching RBC model, the dimension of g order
                                                                             st    is just one
   (i.e., ny = 1) and we consider approximations up to the first three orders. Let hk,
                                                                                    st
                                                                                       order
                                                                                             be the
   k th function of horder
                     st    (there are two functions because nx = 2). The EE evaluated at k̃t−1 ,
   z̃t−1 , εt , and st is
                                                                                                                        υ−1
                                               2               Z  g order h1,order k̃t−1 , z̃t−1 , εt , 1 , z̃t , εt+1 , 1
                                             X                       st+1        st
EEorder       k̃t−1 , z̃t−1 , εt , st = 1−β         pst ,st+1                                                       υ−1
                                            st+1 =1              R                    g order
                                                                                        st       k̃    , z̃
                                                                                                    t−1 t−1 t , ε , 1
                                     n                                                                      o
                                                 2,order     1,order
                               α exp (1 − α)hst            hst          k̃t−1 , z̃t−1 , εt , 1 , z̃t , εt+1 , 1
                                                                                             α−1               
                                                              1,order
                                                           hst          k̃t−1 , z̃t−1 , εt , 1         + 1 − δ µ (εt+1 ) εt+1 ,

   where µ denotes the unconditional probability density. The associated absolute value of the
   unconditional EE is
               2 Z Z Z
               X                                                                                                              
       order                                   order
   EEE       =                            EE               k̃t−1 , z̃t−1 , εt , 1, st       µ k̃t−1 , z̃t−1 , εt dk̃t−1 dz̃t−1 dεt p̄ (st ) ,
                      st =1   R   R   R


   where p̄ (st ) is the ergodic probability of st .
      We use the following procedure to approximate EEEorder for order ∈ {first, second, third}.
   We begin by simulating εt from the standard normal distribution and st from the ergodic
   distribution. Conditioning on each simulated set {εt , st }, we use horder
                                                                        st    to simulate k̃t and z̃t .
   The length of the simulated path is 10,000 periods, with first 1,000 periods discarded as a
   burn-in. The remaining 9,000 simulations are used to form the unconditional distribution of
   the variables k̃t−1 and z̃t−1 . This procedure is justified by Santos and Peralta-Alva (2005).
      For each set of k̃t−1 , z̃t−1 , εt , and st randomly selected from these 9,000 simulations,
   we draw 10,000 values of εt+1 from the standard normal distribution and 10,000 values of
   st+1 from the transition probability pst ,st+1 to compute the expectation     that depends on        the
                                     order                                order
   functions g order    order
               st+1 , g st    , and hst . The result is 9,000 values of EE       k̃t−1 , z̃t−1 , εt , st . We
   average across these 9,000 values to compute EEEorder . We repeat this procedure for each
   order ∈ {first, second, third}, and for both the partition and naive perturbation methods.
                 PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                       23

When simulating a path for second-order and third-order approximations, we use the pruning
technique described in Andreasen, Fernandez-Villaverde, and Rubio-Ramirez (2013). We
repeat the same procedure for the value function iteration approach except there is no need
for pruning.
  Table 3 reports the base-10 log absolute values of EEs for each solution method.7 Although
the value function iteration method is most accurate as expected, the partition perturbation
method fares remarkably well in comparison. This is an important result because, even with
the advanced CUDA technology, value function iterations take about fifteen minutes to find
an approximation to the model solution (with the steady state as an initial starting point),
while either perturbation method takes only a fraction of a second to find a third-order
approximation.

                   Table 3. Euler-equation errors (base-10 log absolute value)

                                    Value function iteration -4.54
                                    Partition perturbation
                                          First-order              -3.01
                                          Second-order             -3.59
                                          Third-order              -3.73
                                    Naive perturbation
                                          First-order              -2.48
                                          Second–order             -3.07
                                          Third-order              -3.16


  For both perturbation methods, Table 3 indicates that higher-order approximations pro-
duce a higher degree of accuracy. In all cases, increasing the approximation from first order
to second order delivers significant gain without taking much more computational time. The
accuracy gain is much smaller when the approximation moves from second order to third
order. More important is the result that the partition perturbation method is more accurate
than the naive perturbation method for any order of approximation. As argued in Section III
and illuminated in Section V, the partition perturbation method does not take approximation
along the direction of θ 2 (st ) and thus preserves the time-varying nature of these parameters
even for the first-order approximation. Indeed, the accuracy of the first-order approximation
from the partition perturbation method is almost as good as the accuracy of the second-order


  7As   a reference, the base-10 log value has this interpretation: the value −4 implies an error of $1 for each
$10,000 of consumption.
              PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                           24

approximation from the naive perturbation method. Because the programming and compu-
tational time is the same for both methods, the partition perturbation method is superior
to the naive perturbation method.

                                      VII. Conclusion

  Markov switching has been introduced as an essential ingredient to a large class of models
usable for analyzing structural breaks in the economy and regime shifts in policy, rang-
ing from backward-looking models (Hamilton (1989) and Sims and Zha (2006)) to forward-
looking rational expectations models (Clarida, Gali, and Gertler (2000), Lubik and Schorfheide
(2004), Davig and Leeper (2007), Farmer, Waggoner, and Zha (2009)). This paper expands
the literature by developing a general methodology for constructing high-order approxima-
tions to the solutions of MSDSGE models. Higher-order approximations enable researchers
to study many economic problems, such as how important is uncertainty in both the private
sector and government policies for shaping the business cycle.
  While the key developments have been extensively discussed in the introduction, we em-
phasize that the contribution of this paper is not only theoretically lucid but also practically
important. We show through a Markov-switching RBC model that the implementation of
the partition perturbation method is not burdensome but rather straightforward, once one
knows how to solve a system of quadratic polynomial equations efficiently. It is our hope that
the advance made in this paper enables applied researchers to estimate MSDSGE models by
focusing on particular economic problems.
               PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                       25

                    Appendix A. Proofs of Propositions 1, 2, and 3

  Before presenting the proofs of Propositions 1, 2, and 3, we briefly review two forms of
the chain rule in our notation and clarify the notation for the arguments of the function
f . If w : Rnu → Rnw , u : Rnv → Rnu and v ∈ Rnv , the chain rule for the nw × nv total
derivative matrix is Dw ◦ u(v) = Dw(u(v))Du(v). This is the form used for the first-order
Taylor series expansion. For second-order and higher-order Taylor series expansions, we use
the following nw × 1 vector form:

                                                  nu
                                                  X
                             D` w ◦ u(v) =               Dm w(u(v))D` um (v),
                                                  m=1



for 1 ≤ ` ≤ nv . We write the function f as f (y t+1 , y t , xt , xt−1 , ε̃t+1 , εt , θ t+1 , θ t ). This
notation prevents confusion when making the substitutions ε̃t+1 = χεt+1 , θ t+1 = θ(st+1 , χ),
and θ t = θ(st , χ).



A.1. Proof of Proposition 1. Define

                                                                   |                       
                                                                   (ej ⊗ I ny )G(v i (z t ))
                                                                   (e|i ⊗ I ny )G(z t ) 
                                                                                           
                                                                                           
                                                                   (e| ⊗ I )H(z ) 
                          |                                          i     nx       t
                          (ei ⊗ I nx )H(z t )
                                                                                           
                                                                                           
                                                                          xt−1             
            v i (z t ) =      χεt+1           and ui,j (z t ) =                          .
                                                                
                                                                          χε   t+1
                                                                                            
                                  χ
                                                                                           
                                                                                           
                                                                  
                                                                            εt             
                                                                                            
                                                                  
                                                                         θ(j,  χ)          
                                                                                            
                                                                          θ(i, χ)


With this notation we have

                                                  ns
                                                  X             Z
                       0(ny +nx ) = Fi (z t ) =          pi,j         f (ui,j (z t ))dµ(εt+1 )
                                                  j=1           Rnε



for 1 ≤ i ≤ ns . Thus,

                                            ns
                                            X            Z
             0(ny +nx )×nz = DFi (z t ) =         pi,j          Df (ui,j (z t ))Dui,j (z t )dµ(εt+1 ),   (A1)
                                            j=1           Rnε
               PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                        26

for 1 ≤ i ≤ ns . The nf × nz matrix Dui,j (z t ) is computed with implicit differentiation as
                                                                              
                                       (e|j ⊗ I ny )DG(v i (z t ))Dv i (z t )
                                               (e|i ⊗ I ny )DG(z t )
                                                                              
                                                                              
                                                                              
                                                  |
                                   
                                              (e i ⊗   I nx )DH(z t )         
                                                                               
                                                                            
                                    I nx        0nx ×nε        0nx ×1         
                    Dui,j (z t ) = 
                                                                              ,        (A2)
                                    0nε ×nx 0nε ×nε            εt+1         
                                                                               
                                                                            
                                   
                                    0n ε ×nx      I nε        0 n ε ×1
                                                                              
                                                                              
                                    nθ ×nx 0nθ ×nε θ(j, 1) − θ(j, 0)
                                   0                                        

                                     0nθ ×nx 0nθ ×nε θ(i, 1) − θ(i, 0)

where the nz × nz matrix Dv i (z t ) is
                                                   |                   
                                                   (ei ⊗ I nx )DH(z t )
                                                  "                   #
                                    Dv i (z t ) =  0nε ×(nx +nε ) εt+1  .                             (A3)
                                                     01×(nx +nε )   1

Substituting (A2) and (A3) into equation (A1), evaluating at z ss , and integrating, one
obtains
                                   ns
                                   X
  0(ny +nx )×nz = DFi (z ss ) =          pi,j Df (ui,j (z ss ))
                                   j=1
              |                                                                                 
              (ej ⊗ I ny ) Dxt−1 G(z ss )(e|i ⊗ I nx )DH(z ss ) + [0ns ny ×(nx +nε ) Dχ G(z ss )]
                                                |                                                
             
                                             (e i ⊗   I ny )DG(z ss )                            
                                                                                                  
                                                 |
             
                                             (e i ⊗   I nx )DH(z    ss  )                        
                                                                                                  
                                                                                               
                                     I n x     0  nx ×n ε         0 nx  ×1                       
            ×                                                                                    .
                                    0           0                  0
                                                                                               
                                   nε ×nx         nε ×nε            nε ×1
                                                                                               
                                                                                                
                                 0n ×n           I n             0 n   ×1
                                                                                                 
                                     ε    x          ε               ε                         
                                   0            0            θ(j, 1) −     θ(j, 0)
                                                                                               
                                   nθ ×nx        nθ ×nε                                        
                                   0nθ ×nx 0nθ ×nε θ(i, 1) − θ(i, 0)
                                                                  R
In the above expression we have used the fact that                Rnε
                                                                        εt+1 dµ(εt+1 ) = Et εt+1 = 0nε . Since
there is an explicit expression for f and ui,j (z ss ), the (ny + nx ) × nf matrix Df (ui,j (z ss ))
also has an explicit representation. The above system can be written as

                    ns
                    X         n
  0(ny +nx )×nx =         pi,j Dxt−1 f (ui,j (z ss ))+
                    j=1

               Dyt+1 f (ui,j (z ss ))(e|j ⊗ I ny )Dxt−1 G(z ss )(e|i ⊗ I nx )Dxt−1 H(z ss )+
                                                                                                    o
   Dyt f (ui,j (z ss ))(e|i ⊗ I ny )Dxt−1 G(z ss ) + Dxt f (ui,j (z ss ))(e|i ⊗ I nx )Dxt−1 H(z ss ) , (A4)
                PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                                 27

                      ns
                      X          n
  0(ny +nx )×nε =            pi,j Dεt f (ui,j (z ss ))+
                      j=1

                   Dyt+1 f (ui,j (z ss ))(e|j ⊗ I ny )Dxt−1 G(z ss )(e|i ⊗ I nx )Dεt H(z ss )+
                                                                                                     o
        Dyt f (ui,j (z ss ))(e|i ⊗ I ny )Dεt G(z ss ) + Dxt f (ui,j (z ss ))(e|i ⊗ I nx )Dεt H(z ss ) , (A5)

and

                   ns
                   X         n
  0(ny +nx )×1 =         pi,j Dθt+1 f (ui,j (z ss ))(θ(j, 1) − θ(j, 0)) + Dθt f (ui,j (z ss ))(θ(i, 1) − θ(i, 0))
                   j=1

       + Dyt+1 f (ui,j (z ss ))(e|j ⊗ I ny ) Dxt−1 G(z ss )(e|i ⊗ I nx )Dχ H(z ss ) + Dχ G(z ss )
                                                                                                   
                                                                                                  o
                               |                                             |
       + Dyt f (ui,j (z ss ))(ei ⊗ I ny )Dχ G(z ss ) + Dxt f (ui,j (z ss ))(ei ⊗ I nx )Dχ H(z ss )   (A6)

for 1 ≤ i ≤ ns . From these representations, one can see that equation (A4) represents a sys-
tem of ns (ny + nx )nx quadratic polynomial equations in the ns (ny + nx )nx unknown matrices
Dxt−1 G(z ss ) and Dxt−1 H(z ss ). For a solution to the quadratic system (A4), equation (A5)
represents a linear system in the unknown matrices Dεt G(z ss ) and Dεt H(z ss ) and equation
(A6) represents a linear system in the unknown matrices Dχ G(z ss ) and Dχ H(z ss ). These
results complete the proof of Proposition 1.


A.2. Proof of Proposition 2. The ns (ny +nx )n2z unknowns D`2 D`1 G(z ss ) and D`2 D`1 H(z ss )
can be found by solving the system of equations

                                                           D`2 D`2 Fi (z ss ) = 0,

for 1 ≤ i ≤ ns and 1 ≤ `1 , `2 ≤ nz . Since
                                        ns           Z       nf
                                        X                    X
                D`1 Fi (z t ) =               pi,j                Dm1 f (ui,j (z t ))D`1 um
                                                                                          i,j (z t )dµ(εt+1 ),
                                                                                             1


                                        j=1           Rnε m =1
                                                           1



we obtain

                        ns              Z     nf
                        X                     X
  D`2 D`1 Fi (z t ) =            pi,j                    Dm1 f (ui,j (z t ))D`2 D`1 um
                                                                                     i,j (z t )dµ(εt+1 )
                                                                                        1


                         i=1            Rnε   m1 =1
                ns           Z          nfnf
                X                       X X
            +         pi,j                           Dm2 Dm1 f (ui,j (z t ))D`2 um              m1
                                                                                 i,j (z t )D`1 ui,j (z t )dµ(εt+1 ). (A7)
                                                                                    2


                i=1            Rnε m =1 m =1
                                    2    1



Each of the terms in the second summation in equation (A7) can either be explicitly com-
puted or are known from the first order expansion. All that remains is to compute the term
                 PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                                                 28

D`2 D`1 um                          th
         i,j (z t ), which is the m1 component of
            1

                                                                                  
                                                (e|j ⊗ I ny )D`2 D`1 G ◦ v i (z t )
                                                (e|i ⊗ I ny )D`2 D`1 G(z t ) 
                                                                                  
                         D`2 D`1 ui,j (z t ) = 
                                               
                                                     |
                                                                                   .                                             (A8)
                                                (ei ⊗ I nx )D`2 D`1 H(z t ) 
                                                                                   
                                                          0nx +2nε +2nθ
The term D`2 D`1 G ◦ v i (z t ) is equal to
                 nz                                             nz X
                                                                   nz
                                                                                                                              !
                 X                                              X
  (e|j ⊗I ny )           Dk1 G(z t )D`2 D`1 v ki 1 (z t )   +                 Dk2 Dk1 G(z t )D`2 v ki 2 (z t )D`1 v ki 1 (z t )    ,
                 k1 =1                                          k2 =1 k1 =1

where
                                                        "                               #
                                                            (e|i ⊗ I nx )D`2 D`1 H(z t )
                                 D`2 D`1 v i (z t ) =                                             .
                                                                         0nε +1
Substituting this into equation (A7) and evaluating at z ss , it is easy to see that this will
be linear in the unknowns D`2 D`1 G(z ss ) and D`2 D`2 H(z ss ). These complete the proof of
Proposition 2.

A.3. Proof of Proposition 3. Proposition 3 follows directly from the more general version
given below. While there is no constant term in equation (A9), this case can easily be
handled by appending a variable x̃t to the vector of predetermined variables xt and adding
an equation of the form x̃t − x̃t−1 = 0. While this introduces an additional unit root into the
system, this will not pose any problems for the solutions techniques discussed in this paper.

Proposition 4. With the partition perturbation method, the first-order solution of

  Et [A1 (θ(st ), θ(st+1 ))yt+1 + A2 (θ(st ), θ(st+1 ))yt + A3 (θ(st ), θ(st+1 ))xt
           + A4 (θ(st ), θ(st+1 ))xt−1 +A5 (θ(st ), θ(st+1 ))εt+1 + A6 (θ(st ), θ(st+1 ))εt ] = 0 (A9)

is exact and all higher-order terms are zero, where A1 and A2 are (ny + nx ) × ny , A3 and
A4 are (ny + nx ) × nx , and A5 and A6 are (ny + nx ) × nε .

Proof. It is easy to see that the steady-state is y ss = 0ny and xss = 0nx , which is independent
of all the parameters. This implies that none of the parameters need to be perturbed and the
perturbation function is θ(k, χ) = θ(k). We first show that the first order Taylor expansion
of G and H exactly solves equation (A9) and then show that all terms of order two or
greater in the full Taylor series expansion of G and H are zero.
  The first order Taylor expansion, evaluated at χ = 1 is

                  yt = (est ⊗ I ny )(Dxt−1 G(z ss )xt−1 + Dεt G(z ss )εt + Dχ G(z ss )),
                 xt = (est ⊗ I nx )(Dxt−1 H(z ss )xt−1 + Dεt H(z ss )εt + Dχ H(z ss )).
                    PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                                      29

Substituting this into the left hand side of equation (A9), taking expectations, and gathering
like terms, we obtain

  ns
  X          n
         pi,j A4 (i, j) + A1 (i, j)(e|j ⊗ I ny )Dxt−1 G(z ss )(e|i ⊗ I nx )Dxt−1 H(z ss )
   j=1
                                                                                                            o
              +   A2 (i, j)(e|i   ⊗ I ny )Dxt−1 G(z ss ) +            A3 (i, j)(e|i   ⊗ I nx )Dxt−1 H(z ss ) xt−1
                  ns
                  X         n
              +         pi,j A6 (i, j) + A1 (i, j)(e|j ⊗ I ny )Dxt−1 G(z ss )(e|i ⊗ I nx )Dεt H(z ss )
                  j=1
                                                                                             o
                    + A2 (i, j)(e|i ⊗ I ny )Dεt G(z ss ) + A3 (i, j)(e|i ⊗ I nx )Dεt H(z ss ) εt
              ns
              X         n
                    pi,j A1 (i, j)(e|j ⊗ I ny ) Dχ G(z ss ) + Dxt−1 G(z ss )(e|i ⊗ I nx )Dχ H(z ss )
                                                                                                    
          +
              j=1
                                                                                                               o
                                        + A2 (i, j)(e|i ⊗ I ny )Dχ G(z ss ) + A3 (i, j)(e|i ⊗ I nx )Dχ H(z ss ) ,

Where Ak (i, j) is short hand notation for Ak (θ(i), θ(j)). Since equations (A4) through (A6)
must hold, the above is equal to zero. Thus the first order expansion is an exact solution of
(A9).
  We now show that all the higher order terms must be zero. Because none of the parameters
are perturbed, one sees that the last 2nθ rows of the expression for Dui,j (z t ) given in equation
(A2) are zero. So, if m > 2(ny +nx +nε ), then D` um
                                                   i,j (z t ) = 0 for 1 ≤ ` ≤ nz . It is also easy to
see that Dm2 Dm1 f (ui,j (z t )) = 0 if both m1 and m2 are less than or equal to 2(ny + nx + nε ).
Thus, an easy induction argument on q shows that

                                  ns           Z     2(ny +nx +nε )
                                  X                      X
    D`q · · · D`1 Fi (z t ) =           pi,j                          Dm1 f (ui,j (z t ))D`q · · · D`1 um
                                                                                                        i,j (z t )dµ(εt+1 ).
                                                                                                           1


                                  j=1          Rnε       m1 =1


Finally, if follows from equation (A8) that
                                                                                               
                                                       (e|j ⊗ I ny )D`q · · · D`1 G ◦ v i (z t )
                                                       (e|i ⊗ I ny )D`q · · · D`1 G(z t ) 
                                                                                               
                          D`q · · · D`1 ui,j (z t ) = 
                                                      
                                                            |
                                                                                                ,
                                                        (e i ⊗  I nx )D `q · · · D `1 H(z t )  
                                                                                                
                                                                    0nx +2nε +2nθ

for q > 1. Since D`q · · · D`1 G◦v i (z t ) is linear in D`q · · · D`1 G(z t ) and D`q · · · D`1 H(z t ) it fol-
lows that D`q · · · D`1 G(z t ) = 0 and D`q · · · D`1 H(z t ) = 0 will be a solution of D`q · · · D`1 Fi (z t ) =
0. Thus all the terms of order two or greater in the Taylor series expansion of G and H are
zero. These results complete the proof of Proposition 4.
               PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                              30

                          Appendix B. Discussion of Gröbner bases

  In this appendix we give an overview of Gröbner bases and describe how they can be
applied to our problem. See Becker, Weispfenning, and Kredel (1998) for a more detailed
description and other applications.
   We wish to find all the solutions of a system of n polynomial equations in n variables.
Let the polynomial system under study be

                               f1 (x1 , . . . , xn ) = 0, · · · , fn (x1 , . . . , xn ) = 0.

Each equation in this system defines a manifold of dimension (n − 1) in Rn and the set of
solutions of the system is the intersection of these manifolds.
  When all the fi ’s are linear, the solution set consists of a linear subspace of Rn . It is well
known that there are three possible outcomes: a unique solution, no solutions, or infinitely
many solutions. More importantly, the set of linear systems with no solution or infinitely
many solutions is of measure zero in the set of all linear systems. When there is a unique
solution, it can be easily found.
  When the fi ’s are higher-order polynomials, the solution set is more complicated, but the
intuition from the linear case still holds. For most polynomial systems of n equations in n
variables, there are only finitely many solutions and these solutions can be easily found.
  To describe how solutions are computed for polynomial systems, we need to develop
the concept of an ideal and its Gröbner basis. Given a set of polynomials in n variables,
{f1 , . . . , fm }, the ideal generated by {f1 , . . . , fm } is the set of all polynomials of the form

                g1 (x1 , . . . , xn )f1 (x1 , . . . , xn ) + · · · + gm (x1 , . . . , xn )fm (x1 , . . . , xn )

where g1 , . . . , gm vary over all polynomials in n variables. We denote this ideal by hf1 , . . . , fm i.
For our purpose we focus on one important feature of an ideal. The point (a1 , . . . , an ) ∈ Rn
is a zero of the polynomials f1 , . . . , fm if and only if it is a zero of every polynomial in the
ideal hf1 , . . . , fm i. This feature implies that if two different sets of polynomials generate the
same ideal, then they have the same zeros. The goal is to find a generating set for which it
is easy to compute zeros.
  Before giving the definition of a Gröbner basis, we must first define what we mean by
the leading term of a polynomial. A polynomial in x1 , . . . , xn is a sum of terms of the form
cxk11 xk22 · · · xknn , where ki is a non-negative integer and c is a non-zero real number. The
product xk11 xk22 · · · xknn is called a monomial in x1 · · · xn . The degree of a term is the sum of
its exponents, k1 +· · ·+kn . For polynomials in a single variable, the leading term is defined to
be the one of highest degree. For polynomials of several variables, there may be many terms
of the same degree. Thus, one defines the leading term relative to a monomial ordering. For
instance, the lexicographical ordering of monomials implies that xk11 · · · xknn < xm        mn
                                                                                    1 · · · xn
                                                                                     1
                 PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                          31
                           Pn               Pn                Pn             Pn
if and only if either          i=1   ki <       i=1   mi or     i=1   ki =    i=1   mi and there is an i such that
ki < mi and kj = mj for j < i. In general, a monomial order must satisfy
    (1) The monomial x01 x02 · · · x0n = 1 is the est monomial.
    (2) If X, Y , and Z are monomials with X < Y , then XZ < Y Z.
    The leading term of a polynomial is the largest term with respect to the monomial
ordering. With these notions in hand, we are ready to define a Gröbner basis. The set
{h1 , . . . , hk } is a Gröbner basis for the ideal hf1 , . . . , fm i if
    (1) hf1 , . . . , fm i=hh1 , . . . , hk i
    (2) The leading term of any polynomial in hf1 , . . . , fm i is divisible by the leading term
         of hi for some i.
   Consider the following example. Consider the ideal generated by

                                            {2x1 x2 − x1 , x2 − x3 , x23 − 1}.

Note that the first term of each polynomial is the leading term with respect to the lexico-
graphical order. Is this generating set a Gröbner basis? The answer is negative because the
leading term in 21 (2x1 x2 − x1 ) − x1 (x2 − x3 ) = x1 x3 − 12 x1 is not divisible by any of the leading
terms in the generating set.
    As an illustration, we show how to use Buchberger’s Algorithm to construct a Gröbner
basis. There are many other algorithms, most of which are based on Buchberger’s Algorithm,
that can also be used to construct Gröbner bases. The algorithm begins with constructing
                                                1
S-polynomials. The polynomial                   2
                                                  (2x1 x2   − x1 ) − x1 (x2 − x3 ) = x1 x3 − 12 x1 is called the
                                                                              1
S-polynomial of 2x1 x2 − x1 and x2 − x3 because factors                       2
                                                                                  and x1 were chosen so that the
leading terms would cancel. After the S-polynomial has been formed, it must be reduced
using the elements of the generating set. The reduction step is illustrated by the following
example.
   Consider the S-polynomial of 2x1 x2 −x1 and x23 −1, which is 21 x23 (2x1 x2 −x1 )−x1 x2 (x23 −1) =
x1 x2 − 12 x1 x23 . This polynomial is reduced by using the leading terms in the generating set
to eliminate terms in the S-polynomial. In this case the reduction proceeds as follows:
                      1                1          1                  1        1
              x1 x2 − x1 x23 ⇒ (x1 x2 − x1 x23 ) − (2x1 x2 − x1 ) = − x1 x23 + x1
                      2                2          2                  2        2
               1        1         1       1        1
             − x1 x23 + x1 ⇒ (− x1 x23 + x1 ) + x1 (x23 − 1) = 0
               2        2         2       2        2
So the reduction of the S-polynomial of 2x1 x2 − x1 and x23 − 1 gives the zero polynomial.
Readers should convince themselves that the S-polynomial of 2x1 x2 − x1 and x2 − x3 given
above cannot be reduced further and that the S-polynomial of x2 − x3 and x23 − 1 can be
reduced to zero. Note that the reduction is in general not unique. It can depend on the order
in which the terms are eliminated and on particular elements of the generating set that are
                PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                             32

used to eliminate the terms. One can always devise an algorithm to reduce any polynomial
in finite steps.
   Buchberger’s Algorithm proceeds as follows. Successively form the S-polynomials from
pairs of polynomials in the generating set and reduce them. If a reduced non-zero S-
polynomial is obtained, add it to the generating set. Continue until all S-polynomials formed
from pairs of the enlarged generating set can be reduced to zero. This algorithm is guaran-
teed to terminate in a Gröbner basis. See Buchberger (1998) or Becker, Weispfenning, and
Kredel (1998) for details.
   Continuing with our example, the reduced S-polynomial of 2x1 x2 − x1 and x2 − x3 is
x1 x3 − 21 x1 . We add it to our generating set to obtain

                                                                      1
                             {2x1 x2 − x1 , x2 − x3 , x23 − 1, x1 x3 − x1 }.
                                                                      2
As discussed above, the S-polynomials of both the pair 2x1 x2 − x1 and x23 − 1 and the pair
x2 − x3 and x23 − 1 are zero. Note also that the S-polynomial of 2x1 x2 − x1 and x1 x3 − 12 x1
reduces to zero, but the S-polynomial of x2 − x3 and x1 x3 − 12 x1 is x1 x3 (x2 − x3 ) − x2 (x1 x3 −
1
  x)
2 1
       = 12 x1 x2 − x1 x23 and reduces to

              1                   1                  1                          1
                x1 x2 − x1 x23 ⇒ ( x1 x2 − x1 x23 ) − (2x1 x2 − x1 ) = −x1 x23 + x1
              2                   2                  4                          4
                         1                 1                         3
              −x1 x23 + x1 ⇒ (−x1 x23 + x1 ) + x1 (x23 − 1) = − x1 .
                         4                 4                         4
We add this non-zero polynomial to our generating set to obtain
                                                                          3
                         {2x1 x2 − x1 , x2 − x3 , x23 − 1, 2x1 x3 − x1 , − x1 }.
                                                                          4
The reader should verify that all S-polynomials of pairs from this generating set will reduce
to zero. Thus we have obtained a Gröbner basis.
   Gröbner bases are not unique, because adding any element from the ideal generated by
a Gröbner basis will result in another Gröbner basis. To obtain uniqueness, with respect to
the monomial ordering, we work with a reduced Gröbner basis. A Gröbner basis is said to
be reduced if
   (1) The coefficient of the leading term of each polynomial in the basis is one.
   (2) Each polynomial in the basis cannot be further reduced with respect to the other
         polynomials in the basis.
   Any Gröbner basis can be easily transformed to a reduced Gröbner basis by first reducing
each polynomial in the basis with respect to the other polynomials in the basis and then
dividing the resultant leading term by the leading coefficient. For instance, the Gröbner
basis obtained above is not reduced because both 2x1 x2 − x1 and 2x1 x3 − x1 can be reduced
                PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                                              33

to zero. Thus these polynomials must be eliminated to obtain the reduced Gröbner basis

                                              {x1 , x2 − x3 , x23 − 1}.


   The reduced basis above is called a Shape basis because it is of the form

                               {x1 − q1 (xn ), . . . , xn−1 − qn−1 (xn ), qn (xn )},

where q1 , . . . , qn are polynomials in a single variable with the degree of qi strictly less than the
degree of qn for 1 ≤ i ≤ n−1. Shape bases are particularly useful because it is straightforward
to find all the zeros from this representation. One first finds the values of xn that are zeros
of qn (xn ) and then substitutes each of these values into q1 through qn−1 to obtain the values
of x1 through xn−1 .
  Not all reduced Gröbner bases are Shape bases. An alternative form of the Shape lemma,
given below, gives the conditions under which the reduced Gröbner basis is a Shape basis.

The Shape Lemma Let f1 , . . . , fn be polynomials in x1 , . . . , xn . The reduced Gröbner basis
with respect to the lexicographical ordering of the ideal hf1 , . . . , fn i is a Shape basis if and
only if the following conditions hold.
    (1) The system f1 , . . . , fn has only finitely many zeros.
    (2) If (a1 , . . . , an ) and (b1 , . . . , bn ) are two distinct zeros, then an 6= bn .
    (3) Each zero is either a simple point or a multiple point of local dimension one.
    (4) If a zero is a multiple point, then the tangent line at the zero does not contain the
         hyperplane xn = 0.

  The meaning of Conditions 1 and 2 is clear, but Conditions 3 and 4 need further explana-
tion. The point (a1 , . . . , an ) ∈ Rn is a zero of the polynomial system f1 , . . . , fn if and only if
hf1 , . . . , fn i ⊆ hx1 − a1 , . . . , xn − an i. If there exists an i such that

         hf1 , . . . , fn i ⊆ hx1 − a1 , . . . , (xi − ai )2 , . . . , xn − an i ⊂ hx1 − a1 , . . . , xn − an i,

then we say the zero is a multiple point; otherwise, the zero is simple. One can verify that the
zero (a1 , . . . , an ) is a multiple point if and only if there exists an i such that Di fj (a1 , . . . , an ) =
0 for all 1 ≤ j ≤ n. The tangent space at the zero (a1 , . . . , an ) is the set of all (x1 , . . . , xn ) ∈
Rn such that                                                                      
                          D1 f1 (a1 , . . . , an ) · · · Dn f1 (a1 , . . . , an )    x1
                        
                                  .
                                   ..              . ..           .
                                                                  ..
                                                                                   . 
                                                                                    ..  = 0.
                                                                                  
                         D1 fn (a1 , . . . , an ) · · · Dn fn (a1 , . . . , an )     xn
Note that this matrix of partial derivatives is the Jacobian. If the zero is simple, then this
definition of the tangent space corresponds to our usual geometric notion of a tangent space,
but the correspondence breaks down if the zero is a multiple point. The local dimension of
              PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                           34

a zero is the dimension of the tangent space. Note that the local dimension is zero if and
only if the Jacobian is of full rank. Thus, if the Jacobian is of full rank, then the zero will
be simple. The converse, however, is not necessarily true. Finally, if the Jacobian at each
zero is of full rank, then each zero is isolated and there can only be finitely many zeros.
  One can easily verify that if the reduced Gröbner basis is a Shape basis, then Conditions
1-4 will hold. The converse is also true, but the verification requires much more work. See
Becker, Marianari, Mora, and Treverso (1993) for details. While the Shape Lemma does not
hold for every set of n polynomials in n unknowns, it is the case that for every such system,
there is a nearby system that will satisfy conditions 1-4.
  In summary, for most polynomial systems, there are only finitely many zeros and Buch-
berger’s Algorithm can be used to find them. While Buchberger’s Algorithm is instructive,
it can be inefficient for certain problems. Active research continues to develop variants of
this algorithm that improve efficiency.
             PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                    35

                                     References

Aldrich, E., J. Fernández-Villaverde, R. Gallant, and J. Rubio-Ramı́rez
  (2011): “Tapping the Supercomputer Under Your Desk: Solving Dynamic Equilibrium
  Models with Graphics Processors,” Journal of Economic Dynamics and Control, 35(3),
  386–393.
Amisano, G., and O. Tristani (2011): “Exact Likelihood Computation for Nonlinear
  DSGE Models with Heteroskedastic Innovations,” Journal of Economic Dynamics and
  Control, 35(12), 2167–2185.
Andreasen, M., J. Fernandez-Villaverde, and J. Rubio-Ramirez (2013): “The
  Pruned State-Space System for Non-Linear DSGE Models: Theory and Empirical Appli-
  cations,” Working Paper 18983, NBER.
Aruoba, S., J. Fernandez-Villaverde, and J. Rubio-Ramirez (2006): “Comparing
  Solution Methods for Dynamic Equilibrium Economies,” Journal of Economic Dynamics
  and Control, 30(12), 2477–2508.
Becker, E., M. Marianari, T. Mora, and C. Treverso (1993): “The Shape of the
  Shape Lemma,” in International Symposium on Symbolic and Algebraic Computation, pp.
  129–133. ACM Press.
Becker, T., V. Weispfenning, and H. Kredel (1998): Gröbner Bases: A Computa-
  tional Approach to Commutative Algebra. Springer-Verlag.
Bi, H., and N. Traum (2012): “Estimating Sovereign Default Risk,” European Economic
  Review, 102(3), 161–66.
Bianchi, F. (2010): “Regime Switches, Agents’ Beliefs, and Post-World War II US Macroe-
  conomic Dynamics,” Working Paper 12-04, Duke University.
Bianchi, F., and L. Melosi (2013): “Modeling the Evolution of Expectations and Un-
  certainty in General Equilibrium,” Manuscript.
Blake, A., and F. Zampolli (2006): “Optimal Monetary Policy in Markov-Switching
  Models with Rational Expectations Agents,” Working Paper 298, Bank of England.
Bloom, N. (2009): “The Impact of Uncertainty Shocks,” Econometrica, 77(3), 623–685.
Borovic̆ka, J., and L. P. Hansen (2013): “Examining Macroeconomic Models through
  the Lens of Asset Pricing,” Manuscript.
Buchberger, B. (1998): “An Algorithmic Criterion for the Solvability of Algebraic Sys-
  tems of Equations,” Gröbner Bases and Applications, 251, 535–545.
Cho, S. (2011): “Characterizing Markov-Switching Rational Expectation Models,” Working
  Paper.
Clarida, R., J. Gali, and M. Gertler (2000): “Monetary Policy Rules and Macroe-
  conomic Stability: Evidence and Some Theory,” Quarterly Journal of Economics, 115(1),
             PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                     36

  147–180.
Costa, O., M. Fragoso, and R. Marques (2005): Discrete-Time Markov Jump Linear
  Systems. Springer.
Cox, D., J. Little, and D. O’Shea (1997): Ideals, Varieties and Algorithms: An Intro-
  duction to Computational Algebraic Geometry and Commutative Algebra. Undergraduate
  Texts in Mathematics, Springer-Verlag, 2 edn.
Datta, R. (2010): “Finding all Nash Equilibria of a Finite Game using Polynomial Alge-
  bra,” Economic Theory, 42(1), 55–96.
Davig, T., and T. Doh (2008): “Monetary Policy Regime Shifts and Inflation Persistence,”
  Research Working Paper 08-16, Federal Reserve Bank of Kansas City.
Davig, T., and E. Leeper (2007): “Generalizing the Taylor Principle,” American Eco-
  nomic Review, 97(3), 607–635.
Davig, T., E. M. Leeper, and T. B. Walker (2010): “Unfunded Liabilities and Un-
  certain Fiscal Financing,” Journal of Monetary Economics, 57(5), 600–619.
        (2011): “Inflation and the Fiscal Limit,” European Economic Review, 55(1), 31–47.
Farmer, R., D. Waggoner, and T. Zha (2009): “Understanding Markov-Switching
  Rational Expectations Models,” Journal of Economic Theory, 144(5), 1849–1867.
         (2011): “Minimal State Variable Solutions to Markov-Switching Rational Expec-
  tations Models,” Journal of Economic Dynamics and Control, 35(12), 2150–2166.
Fernandez-Villaverde, J., P. Guerron-Quintana, and J. Rubio-Ramirez (2014):
  “Estimating Dynamic Equilibrium Models with Stochastic Volatility,” Manuscript.
Fernández-Villaverde, J., P. Guerrón-Quintana, J. F. Rubio-Ramı́rez, and
  M. Uribe (2011): “Risk Matters: The Real Effects of Volatility Shocks,” American
  Economic Review, 101(6), 2530–2561.
Fernández-Villaverde, J., and J. Rubio-Ramirez (2007): “Estimating Macroeco-
  nomic Models: A Likelihood Approach,” Review of Economic Studies, 74(4), 1059–1087.
Gomme, P., and P. Klein (Forthcoming): “Second-Order Approximation of Dynamic
  Models Without the Use of Tensors,” Journal of Economic Dynamics & Contral.
Hamilton, J. (1989): “A New Approach to the Economic Analysis of Nonstationary Time
  Series and the Business Cycle,” Econometrica, 57(2), 357–384.
Holmes, M. H. (2012): Introduction to Perturbation Methods. Springer, second edn.
Judd, K. (1998): Numerical Methods in Economics. MIT Press.
Judd, K., and A. Solnick (1994): “Numerical Dynamic Programming with Shape-
  Preserving Splines,” Mimeo.
Klein, P. (2000): “Using the Generalized Schur Form to Solve a Multivariate Linear Ra-
  tional Expectations Model,” Journal of Economic Dynamics & Contral, 24, 1405–1423.
            PERTURBATION METHODS FOR MARKOV-SWITCHING DSGE MODELS                    37

Kubler, F., and K. Schmedders (2010a): “Competitive Equilibria in Semi-Algebraic
  Economies,” Journal of Economic Theory, 145(1), 301–330.
         (2010b): “Tackling Multiplicity of Equilibria with Gröbner Bases,” Operations
  Research, 58(4), 1037–1050.
Leeper, E., and T. Zha (2003): “Modest Policy Interventions,” Journal of Monetary
  Economics, 50(8), 1673–1700.
Liu, Z., D. F. Waggoner, and T. Zha (2011): “Sources of Macroeconomic Fluctuations:
  A Regime-Switching DSGE Approach,” Quantitative Economics, 2(2), 251–301.
Lombardo, G. (2010): “On Approximating DSGE Models by Series Expansions,” Euro-
  pean Central Bank Working Paper No. 1264.
Lubik, T., and F. Schorfheide (2004): “Testing for Indeterminacy: An Application to
  US Monetary Policy,” American Economic Review, 94(1), 190–217.
Santos, M. S., and A. Peralta-Alva (2005): “Accuracy of Simulations for Stochastic
  Dynamic Models,” Econometrica, 73(6), 1939–1976.
Schmitt-Grohe, S., and M. Uribe (2004): “Solving Dynamic General Equilibrium Mod-
  els Using a Second-Order Approximation to the Policy Function,” Journal of Economic
  Dynamics and Control, 28(4), 755–775.
Schorfheide, F. (2005): “Learning and Monetary Policy Shifts,” Review of Economic
  Dynamics, 8, 392–419.
Sims, C., and T. Zha (2006): “Were There Regime Switches in US Monetary Policy?,”
  American Economic Review, 96(1), 54–81.
Smets, R., and F. Wouters (2007): “Shocks and Frictions in US Business Cycles: a
  Bayesian DSGE Approach,” American Economic Review, 97(3), 586–606.
Svensson, L., and N. Williams (2007): “Monetary Policy with Model Uncertainty:
  Distribution Forecast Targeting,” Discussion Paper 6331, CEPR.
Tauchen, G. (1986): “Finite State Markov-Chain Approximations to Univariate and Vector
  Autoregressions,” Economics Letters, 20(2), 177–181.
Uhlig, H. (1999): “A Toolkit for Analyzing Nonlinear Dynamic Stochastic Models Easily,”
  in Computational Methods for the Study of Dynamic Economies, ed. by R. Marimon, and
  A. Scott, pp. 30–61. Oxford University Press, Oxford, England.

  Federal Reserve Bank of Kansas City, Duke University, Federal Reserve Bank of At-
lanta, CEPR, FEDEA, and BBVA Research, Federal Reserve Bank of Atlanta, Federal
Reserve Bank of Atlanta, Emory University, and NBER.
