                               NBER WORKING PAPER SERIES




                                     WISHFUL THINKING

                                         Andrew Caplin
                                         John V. Leahy

                                       Working Paper 25707
                               http://www.nber.org/papers/w25707


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                    March 2019




We thank Anmol Bhandari, Stefano DellaVigna, Wouter den Haan, Behzad Diba, Jordi Gali,
Nicola Pavoni, Kaitlin Raimi, Matthew Shapiro, Allen Sinai, Alp Simsek, Linda Tesar, Fabrizio
Perri, Jaume Ventura, and Gianluca Violante for helpful discussions. We thank the Alfred P.
Sloan and NOMIS Foundations for support. The views expressed herein are those of the authors
and do not necessarily reflect the views of the National Bureau of Economic Research.

At least one co-author has disclosed a financial relationship of potential relevance for this
research. Further information is available online at http://www.nber.org/papers/w25707.ack

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2019 by Andrew Caplin and John V. Leahy. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including © notice, is given to the source.
Wishful Thinking
Andrew Caplin and John V. Leahy
NBER Working Paper No. 25707
March 2019
JEL No. D84,D91,E03,E71

                                         ABSTRACT

We model agents who get utility from their beliefs and therefore interpret information
optimistically. They may exhibit several biases observed in psychological studies such as
optimism, procrastination, confirmation bias, polarization, and the endowment effect. In some
formulations, they exhibit these biases even though they are subjectively Bayesian. We argue that
wishful thinking can lead to reduced saving, can make possible information-based trade, and can
generate asset bubbles.


Andrew Caplin
Department of Economics
New York University
19 W. 4th Street, 6th Floor
New York, NY 10012
and NBER
andrew.caplin@nyu.edu

John V. Leahy
Gerald R. Ford School of Public Policy
University of Michigan
3308 Weill Hall
735 S. State St. #3308
Ann Arbor, MI 48109
and NBER
jvleahy@umich.edu
                                   Wishful Thinking

                              Andrew Caplinyand John Leahyz

                                            March 2019



                                               Abstract

          We model agents who get utility from their beliefs and therefore interpret informa-
      tion optimistically. They may exhibit several biases observed in psychological studies
      such as optimism, procrastination, con…rmation bias, polarization, and the endowment
      e¤ect. In some formulations, they exhibit these biases even though they are subjec-
      tively Bayesian. We argue that wishful thinking can lead to reduced saving, can make
      possible information-based trade, and can generate asset bubbles.



      “For a man always believes more readily that which he prefers” Francis Bacon (1620)



1     Introduction

Expectation formation is central to many economic questions. Workers must form expec-
tations regarding retirement. Investors must form expectations of risk and return. Price
setters must form expectations of competitor’s prices. While expectations are central, we
do not fully understand how expectations are formed. The typical approach is to assume
that expectations are model consistent. Agents understand the world in which they live and
      We thank Anmol Bhandari, Stefano DellaVigna, Wouter den Haan, Behzad Diba, Jordi Gali, Nicola
Pavoni, Kaitlin Raimi, Matthew Shapiro, Allen Sinai, Alp Simsek, Linda Tesar, Fabrizio Perri, Jaume Ven-
tura, and Gianluca Violante for helpful discussions. We thank the Alfred P. Sloan and NOMIS Foundations
for support.
    y
      Center for Experimental Social Science and Department of Economics, New York University. Email:
andrew.caplin@nyu.edu
    z
      Department of Economics and Gerald R Ford School of Public Policy, University of Michigan and NBER.
Email: jvleahy@umich.edu

                                                   1
form expectations rationally. There is a lot of psychological evidence, however, that agents
are poor information aggregators. They are often over-con…dent. They tend to interpret
information in accordance with their priors. Beliefs seem to be sensitive to rewards. It is
therefore of interest to develop models of belief formation that go beyond the assumption of
rational expectations.

    In this paper, we proceed in the spirit of Becker and model beliefs as a choice. Agents
choose beliefs that raise their subjective utility subject to a cost. This desire to “see the world
through rose colored glasses”naturally leads to several apparent deviations from rationality
such as optimism, procrastination, con…rmation bias, and polarization. We illustrate the
economic implications in a series of simple examples and models. We show how wishful
thinking may reduce saving and create bubbles. We show how wishful thinkers may engage
in information based trade.

   Any model of belief choice must specify the costs and the bene…ts of distorting beliefs. In
the standard economic model, there is no bene…t to believing anything other than the truth.
Agents get utility from outcomes, and probabilities serve only to weight these outcomes.
Getting the probabilities wrong muddles one’s view of the payo¤s to an action and leads to
mistakes. In the standard model, there are strong incentives to have accurate beliefs, since
accurate beliefs lead to accurate decisions.

   To model the bene…ts of belief choice we follow Jevons (1905), Loewenstein (1987) and
Caplin and Leahy (2001) and assume that some portion of current wellbeing depends on the
anticipation of future outcomes. Caplin and Leahy argue that anxiety, fear, hopefulness and
suspense are all ways in which beliefs about the future a¤ect wellbeing today. The American
Psychiatric Association de…nes anxiety as “apprehension, tension, or uneasiness that stems
from the anticipation of danger.” Jevons is even more direct. He argues that agents only
care about the future because beliefs a¤ect wellbeing in the present. In either case, the
dependence of current wellbeing on beliefs about the future creates an incentive to believe
that “good” outcomes are more likely than “bad” outcomes. As in the Bacon quotation
above, wishful thinking involves choosing to believe that the truth is what one would like
the truth to be.

    Without constraints a theory of belief choice would lack content. One could believe
whatever one liked. Our model of the constraints rests on the idea that there are often
lots of possible beliefs that are consistent with experience. Experience is rarely de…nitive.
We limit our agents to “plausible beliefs”, by which we mean beliefs that are not obviously
contradicted by the available evidence. We do not model the technology by which agents


                                                2
choose beliefs. Instead we follow Hansen and Sargent (2008) and impose a cost to beliefs
that are too far away from the truth, where we associate the truth with the beliefs that
an objective observer would hold. This cost is related to the likelihood that the subjective
beliefs would be rejected in favor of the objective ones. The more unlikely the truth, the
more costly the beliefs.

    The outcome is a model of belief choice. Optimal beliefs tend to twist the probabilities
in the direction of events with high utility. The upper bound on probabilities limits wishful
thinking about very likely events. Events can only be so likely. While unlikely events with
high payo¤s receive more weight, wishful thinking is also not magical thinking. Low prob-
ability events remain low probability, and zero probability events remain zero probability.
Wishful thinking is strongest when outcomes are uncertain and payo¤ di¤erences are large.
Such situations might plausibly include choices that are made infrequently so that the agent
lacks experience. Planning for retirement is an example. They might also include situations
in which the options are di¢ cult to value such as the valuation of real estate where every
house is in some sense a unique asset and few houses trade at any given time. They might
include any situation in which there are multiple theories on the table and very little evidence
to distinguish between them as is often the case with asset bubbles.1

    We present two formulations of the cost function which di¤er as to how beliefs are cho-
sen. In the …rst formulation, we allow agents to directly choose their posterior beliefs. This
formulation is simpler, and allows us to directly incorporate many of the tools developed
by Hansen and Sargent (2008) to study robust control. It leads directly to optimism and
over-con…dence as agents overstate the probability of desired states. Wishful thinkers, in
this formulation, tend to value uncertainty as it opens up the possibility of wishful think-
ing. This can lead them to delay actions when the future is uncertain, which can explain
procrastination. It also can lead them to take actions that are themselves uncertain, which
can help explain bubbles.

    In the second formulation, we allow agents to choose how they interpret signals which
then enter into their posterior beliefs. This formulation is mathematically more complex,
but gives rise to a richer set of apparent deviations from rationality. In addition to optimism
and procrastination, agents appear to twist information in the direction of their priors, a
phenomenon known in psychology as con…rmation bias. After observing the same informa-
tion, two agents with divergent priors may also come to hold these divergent beliefs more
strongly, a phenomenon known as polarization. This second formulation has the additional
  1
    Reinhart and Rogo¤ title their study of credit booms "This Time is Di¤erent", emphasizing that there
are multiple interpretations of the evidence and a tendency to gravitate towards the optimistic ones.


                                                   3
distinction that these apparent deviations from rationality all occur in a model in which
agents are subjective Bayesians. In this formulation, agents accurately combine subjective
signals with priors to form subjective posteriors, so that their subjective reality is rational.
Their problem is that is that their subjective interpretation of the signals di¤ers from the
objective counterpart. While subjectively Bayesian, they will appear non-Bayesian to an
objective observer. We label the …rst formulation the cumulative model since the cost is
on the posterior, which is the sum of all accumulated information, and we label the second
formulation the ‡ow model since the cost is on the ‡ow of new information.

    We present three economic implications of wishful thinking. First, we extend the cumu-
lative model to a dynamic setting and present a simple model of consumption and saving
in the presence of idiosyncratic income risk in the style of Huggett (1993). The economy
is populated by both wishful thinkers and objective agents. Wishful thinkers tend to be
optimistic regarding their future labor income. They therefore tend to place relatively high
weight on high utility states which also tend to be the low marginal utility states. This leads
them to consume more and save less, and therefore accumulate less wealth than do the ob-
jective agents. Second, we show that our setting is outside of the class of models considered
by Milgrom and Stokey (1982). We present an example in which a wishful thinker and an
objective agent actively trade based on private information. In the example, agents do not
hold their beliefs dogmatically. They learn from the other agent’s desire to trade. Never-
theless they agree to disagree. The wishful thinker knows the beliefs of the objective agent
but chooses to believe di¤erently. Third, we sketch a model of asset bubbles. We consider
the introduction of a new and uncertain technology and argue that the wishful thinkers will
bid its price above its fundamental value, where fundamental value is determined by the
valuation of the objective agents. We map our description of a bubble to the narrative in
Kindelberger (1978).

    Our premise is that people shade their beliefs in ways that make desired states more likely.
There is evidence that supports this assertion. In a classic study of cognitive dissonance,
Knox and Inkster (1968) interviewed bettors at a race track and found that bettors placed
higher odds on their preferred horse when interviewed after placing their bets than bettors
did when interviewed while in line waiting to place their bets. Knox and Inkster attribute this
phenomenon to a desire to reduce post-decision dissonance, that is a desire to match one’s
world view with ones decisions. Mijovic-Prelec and Prelec (2010) perform a similar analysis
in a controlled experimental setting. They had subjects make incentivized predictions before
and after being given stakes in the outcomes, and found that there was a tendency for subjects
to reverse their predictions when the state that they had predicted to be less likely turned


                                               4
out to be the high payo¤ state. Closer to economics, Ito (1990) surveyed the exchange
rate expectations of Japanese …rms and found evidence of “wishful expectations.” Firms
expected the exchange rate to change in directions that bene…tted them. Exporters tended
to expect greater yen depreciation, whereas importers expected greater yen appreciation.
More recently, Exley and Kessler (2018) …nd that agents interpret uninformative signals of
their ability as positive signals, a phenomenon that they attribute to motivated reasoning.

    While we consider the e¤ect of anticipatory utility on belief choice, there may be other
motivations for choosing beliefs that di¤er from objective reality. Beliefs may aid in goal at-
tainment (Benabou and Tirole, 2002). People may react to the fear disappointment (Loomes
and Sugden, 1982) or a concern for robustness (Hansen and Sargent, 2008). People might
fear that their beliefs will a¤ect outcomes (Pronin et al., 2006). Some of these alternative
theories may predict people choose pessimistic beliefs. It is not our contention that all people
at all times choose beliefs that make them happier. Rather we believe that wishful think-
ing is an important component of belief choice that can help to explain a large variety of
apparently irrational behavior.

   Section 2 discusses related literature. Section 3 presents the cumulative model. Section 4
presents the ‡ow model. Section 5 discusses the economic applications. Section 6 discusses a
number of issues, including alternative modeling choices and the relationship to the literature
on robust control. Section 7 concludes.



2     Related Literature

We contribute to three literatures. The …rst is the literature on belief choice which is surveyed
by Benabou and Tirole (2016). Benabou and Tirole divide the literature into two classes
depending on the motivation for distorting one’s beliefs. In one class, beliefs enter directly
into utility. In the other beliefs are instrumental in motivating desirable actions or achieving
desirable goals. In this latter class, beliefs may aid in overcoming self-control problems,
signaling one’s type, or fostering commitment.

    Our paper …ts into the …rst class. Akerlof and Dickens (1982) is a prominent early
contribution to this literature. They present the example of an agent considering a job
in a hazardous industry. Upon accepting the job the agent may choose to understate the
probability of an accident in their industry. This is desirable because it reduces fear, and
fear reduces utility in their model. The cost of distorting beliefs is that mistaken beliefs
may lead to suboptimal decisions in subsequent periods. For example, the agent may choose

                                               5
to forgo safety equipment if they believe that the risk of an accident is low. Akerlof and
Dickens assume that the agent chooses beliefs balancing the gain in belief utility against
the cost of suboptimal decisions. The agent uses the objective probabilities when making
this choice. Brunnermeier and Parker (2005) is another closely related paper. They assume
that an agent chooses their beliefs at the beginning of their life prior to making any other
decisions. Given this prior, the agent then behaves as a Bayesian in all subsequent periods.
Like Akerlof and Dickens, they model belief choice as balancing the gain to anticipating a
more positive future against the cost of suboptimal decisions. Like Akerlof and Dickens the
agent evaluates belief choice using the objective probability distribution, and then proceeds
with the chosen beliefs. There is a sense in which both of these models are models with
divided selves.2 When choosing beliefs the agent evaluates outcomes using the objective
probabilities. When choosing actions the agent uses the chosen beliefs to evaluate the same
outcomes. This tension makes it di¢ cult to place these models into dynamic settings in
which beliefs are chosen repeatedly over time, since it is di¢ cult to model an agent who
switches from being objective in one setting to optimistic in another. In our model, the
only role of the objective beliefs is to anchor the cost of distorting beliefs. The objective
beliefs are not used to evaluate the costs and beni…ts of choices. We discuss the relationship
between our model and Brunnermeier and Parker’s in detail in Section 6 below.

    A second literature is the literature on anticipatory utility. Jevons (1905), Loewenstein
(1987) and Caplin and Leahy (2001, 2004) all suppose that current happiness depends in
some way on beliefs regarding future outcomes. Jevons believed that agents acted only to
maximize current happiness. Intertemporal optimization, in this view, maximized the sum
of the happiness from actions today and the current happiness arising from the anticipation
of future actions. Loewenstein builds a model to explain why an agent might wish to bring
forward an unpleasant experience to shorten the period of dread, or to postpone a pleasant
experience in order to savor the anticipation. Caplin and Leahy model emotional responses
to future risks such as anxiety, suspense, hope, and fear.

   Our paper also contributes to the recent explosion of work that deviates from rational
expectations. A partial and incomplete selection includes the following. Hansen and Sargent
(2008) consider robust expectations that incorporate a fear of model misspeci…cation. Fuster,
Laibson, and Mendel (2010) propose what they call “natural expectations” which involve a
weighted average of rational expectations and the prediction of a simple linear forecasting
model. Gabaix (2014) considers a “sparsity-based” model in which agents place greater
   2
     One interpretation of the Brunnermeier and Parker model is that parents choose beliefs for their children.
In this interpretation there really are two selves.



                                                      6
weight on variables that are of greater importance. Burnside, Eichenbaum and Rebelo (2016)
develop a model in which the distribution of expectations in the economy are in‡uenced by
social dynamics. Bordalo, Gennaioli, and Schleifer (2018) consider what they call “diagnostic
expectations”. These are based on what psychologists call the representative heuristic and
involve an overweighting of outcomes that are becoming more likely. All of these papers
focus on the consumers of information. Mullainathan and Schleifer (2005) model the supply
side. They show how the public’s preference for biased information a¤ects the supply of
information that is produced by the news media.



3       A Simple Model of Belief Choice

We begin with the cumulative information model in which the agent chooses their posterior
beliefs and discuss the ‡ow model in the next section. The essential elements of both theories
are: (1) a decision whose outcome is unknown; (2) objective probabilities of the outcome;
(3) utility from beliefs regarding the outcome; and (4) a cost to choosing beliefs that di¤er
from the objective probabilities. We discuss these elements in turn.

    There are two periods. In the …rst period, an agent chooses an action a from a …nite
set of potential choices A. In the second period, nature selects a state ! from a …nite set
of potential states of the world . There is an objective probability distribution over the
second-period states 2int ( ), which we associate with the beliefs of an objective observer.

    We follow Jevons (1905) and assume that the agent maximizes their current subjective
expected utility. Current subjective expected utility incorporates both utility from current
experience and utility from the anticipation of future outcomes. For simplicity we abstract
from the former and focus solely on the anticipation of the future. We break down the utility
from the anticipation into two components. The …rst is the payo¤ that the agent anticipates
receiving in state ! should they choose action a, which we denote u(a; !). The second is the
agents’subjective probability that state ! will occur, which we denote (!). We assume the
agent understands their preferences so that they have an accurate assessment of u(a; !).3 We
allow the agent’s subjective beliefs to di¤er from . Subjective beliefs may also depend
    3
    Nothing is lost in assuming that the agent cannot manipulate their beliefs regarding u(a; !). We can
interpret ! broadly as including the quality of the match between the agent and the action a. An increase
in the probability of a good match is equivalent to an increase in u(a; !).




                                                   7
on the action choice a. The agent’s subjective expected utility from the action a is:4;5
                                               X
                                                     (!)u(a; !)                                              (1)
                                               !2



   Maximizing (1) generates an incentive to choose beliefs. We discipline this choice with
a cost of distorting beliefs. Rather than model the speci…c technology by which beliefs
are distorted, for example by selective memory, selective attention, or self-signalling, we
hypothesize that the costs of belief distortion are increasing in the size of the distortion.6
We follow Hansen and Sargent (2008) and relate the cost of choosing (!) to the Kullback-
Leibler divergence from (!) to (!). The cost is:

                                             1X                (!)
                                                      (!) ln                                                 (2)
                                               !2
                                                               (!)

This cost (2) is the expected likelihood ratio under the subjective measure . It measures
the ability of the agent to discriminate between and given that the agent believes .
The idea is that it is easier to choose a subjective belief that is not wildly contradicted by
experience.

    This cost function provides the link between the agent’s subjective reality and the
outside world : We will think of as re‡ecting the objective view of an unbiased expert.
Agents understand what the expert is saying, but are aware that experts are not all knowing
and are frequently wrong. Even in the best of cases, estimates of models come with standard
errors. The cost function states that beliefs become harder and harder to justify, the further
they are from expert opinion.

   An alternative interpretation of the model is there exists a collection of experts with
di¤ering views. Such would be the case with many fundamental macroeconomic questions
such as size of the …scal multiplier, the slope of the Phillips curve, or the level of the natural
rate of unemployment. In these cases there is no consensus on the true structural model and
   4
      The advantage of Jevon’s formulation is that the objective probabilities do not enter this calculation.
The agent does not directly care about their future self and therefore does not consider the potential costs
of mistaken beliefs as they do in the models of Akerlof and Dickens (1982) and Brunnermeier and Parker
(2005). An interesting way forward is incorporate a concern for future mistakes into the model.
    5
      The agent receives utility from the action a both through prior anticipation and eventual experience.
In Jevons’view, only the former in‡uences choice. In dynamic models with multiple periods choice is time
consistent if anticipatory utility mirrors experienced utility and the agent discounts the anticipation of future
utility exponentially. Optimal policy invloves additional complications. See Caplin and Leahy (2006).
    6
      See Benebou and Tirole (2016) for a discussion of theories of selective memory, selective attention and
self-signalling.



                                                       8
experts come to vastly di¤erent conclusions. In this interpretation, represents mainstream
opinion. The agent chooses which expert to believe and sees an increasing cost to choosing
an expert that deviates too far from the consensus. In this interpretation, need not re‡ect
the “truth”or “objective opinion.”Instead might re‡ect the prevailing orthodoxy and the
cost function might re‡ect the cost of deviating from this orthodoxy.7

   The parameter captures the ease with which the agent can manipulate their beliefs.
The larger is the greater the amount of evidence the agent would need before they reject
their chosen beliefs in favor of the objective ones. When is equal to in…nity, any beliefs are
possible. When is equal to zero, any deviation from comes at an in…nite cost.

       Summarizing the above, the agent’s maximization problem becomes:
                                             X                         1X                  (!)
                    V( )=        max                 (!)u(a; !)                   (!) ln       .      (3)
                              2int ( );a2A
                                             !2                          !2
                                                                                           (!)

The …rst term is the subjective expected utility of choice a given the belief . The second term
is the cost of the believing . Implicit in the maximization problem (3) is the assumption
that the agent understands that their beliefs will depend on the choice a. We consider the
implications of assuming that the agent is naïve in Section 6.

     The maximization problem (3) is very similar to the robust control problem in Hansen
and Sargent (2008). There are two di¤erences. First, Hansen and Sargent maximize over a
and conditional on a minimize over . Second, because Hansen and Sargent minimize over
  , they add rather than subtract the cost (2). This is equivalent to replacing with       . It
is therefore not surprising that many of our conclusions will be exactly the opposite of those
of Hansen and Sargent.


3.1       Implications for belief choice

Given that the agent understands the interaction between belief choice and action choice,
it does not matter whether the agent chooses beliefs and then actions or actions and then
beliefs. We will therefore …x the action and focus, for the time being, on belief choice. Given
that the action a is …xed, we write u(!) for u(a; !). The …rst order condition for (!) implies

                                                       (!) exp [ u(!)]
                                   (!) = P                                                            (4)
                                                  !0 2    (! 0 ) exp [ u(! 0 )]
   7
     If we take this view then an interesting way forward is to endogenize the supply of experts along the
lines of Mullainathan and Schleifer (2005) .


                                                        9
                 1.0

                 0.9

                 0.8

                 0.7

                 0.6

                 0.5

                 0.4

                 0.3

                 0.2

                 0.1

                 0.0
                       0.0   0.1       0.2           0.3    0.4    0.5   0.6       0.7       0.8     0.9   1.0


Figure 1: The …gure depicits                 H   as a function of        H   for    L    =    H    = :5 and (uH   uL ) = 2.

According to (4), if u(!) = u for all !, then the agent has no incentive to distort beliefs.8
Otherwise, the agent distorts their beliefs. They tend to increase the probability of states
with high utility and they reduce the probability of states with low utility.

    Figure 1 graphs (!) as a function of (!) for an example with two states: a high utility
state ! H in which utility is uH and a low utility state ! L with utility uL < uH . The objective
probability of the high utility state is on the horizontal axis. The solid line represents the
chosen probability as measured on the vertical axis. The dashed line is the 45 degree line.
The gap between the two lines represents the extent of wishful thinking,

                                                           H L (exp [ uH ]       exp [ uL ])
                                   H             H   =
                                                           H exp [ uH ] +      L exp [ uL ]


Since the ! H is the good state, exp [ uH ] exp [ uL ] > 0 and this gap is everywhere positive.
The constraint that probabilities are less than one, limits the amount of wishful thinking
when the good state is very likely. It is hard to be over-optimistic about a near certain event.
For example, Germans may be optimistic about their team’s chances to win the FIFA world
cup, but this does not necessarily re‡ect wishful thinking. Similarly, it is hard to be too
optimistic about very uncertain events. Wishful thinking is not magical thinking. If H is
zero, then H is zero too. Once the US team has been eliminated from the world cup, it is
di¢ cult to for Americans to fantasize about winning the tournament.
  8
    Exley and Kessler (2018) …nd that when they remove motivation for distorting beliefs, agents appear
unbiased.


                                                                  10
    Wishful thinking is strongest when the state is unknown. The situations in which we
are likely to see wishful thinking are situations in which it is di¢ cult to know the value
of an option, such as the purchase of a house, or the agents have little experience, such as
retirement, or there are multiple theories on the table, such as when there are trends in the
data.9

    It is easy to show that the di¤erence between H and H peaks at H < 12 , so that
wishful thinking is strongest when the good state ! H is slightly less likely than the bad
state. This has two implications. First, the agent interprets uninformative signals positively.
Consistent with this result, Exley and Kessler (2018) …nd that subjects in their experiment
update favorably upon receiving a signal that is known to be uninformative. Second, there
is a range of H for which H < 12 and H > 12 , so that the wishful thinker believes that
the good state is more likely than the bad state, whereas the objective observer believes the
opposite. This can help explain why people gamble. Note that the house can exploit this
behavior to a certain extent but not too much. The odds can favor the house but H must
stay close enough to fair, so that agents can believe H > 12 .


3.2     Action Choice

We can calculate the value of the action a under the optimal beliefs. Substituting (4) into
V ( ) for a given action choice a yields
                                                                              !
                                                1        X
                                                                     u(a;!)
                                 V ( ) = max        ln        (!)e                                       (5)
                                            a
                                                          !


This has the form of Epstein-Zin (1989) preferences, f 1 (Eff (u(!)g) where f (x) = exp(x).
Given that exp(x) is convex, the agent has a preference for late resolution to uncertainty.
This is not surprising as it is uncertainty that allows the agent to engage in wishful thinking.

    While we have modeled an agent who distorts their beliefs, choice in this model turns out
to be observationally equivalent to the choice of an agent with distorted utility. One way to
test for the di¤erence between these two settings would be to combine data on choice and
beliefs.
   9
    One has to be careful in de…ning the state space . For example, the outcome of the ‡ip of a fair coin
is unknown, but there may be little room for wishful thinking if it is known that the coin is fair. In such a
case is very small and it is di¢ cult to believe is too di¤erent from       Alternatively, one might take the
state to be the fairness of the coin, in which case wishful thinking is more likely to be signi…cant.




                                                     11
3.3     Overcon…dence

Debondt and Thaler (1995) write, “Perhaps the most robust …nding in the psychology of
judgement is that people are overcon…dent.”Experimental tests of overcon…dence take several
forms. In one type of experiment, an agent is asked to choose the correct answer from a
set of potential answers and then asked their subjective probability of getting the correct
answer. In this case, overcon…dence takes the form of optimism and arises when the subject’s
subjective probability of being correct exceeds the observed frequency with which they in
fact answer correctly. Another set of experiments asks for a numerical answer to a question
and for a subjective con…dence interval. In this case, overcon…dence takes the form of excess
precision and arises when the correct answer fails to lie in the subjective con…dence interval
as often as believed.

    The spirit of these tests can be captured in a tracking problem in which the agent must
guess the state after receiving a signal. Suppose that there are N states labeled ! 1 through
! N equally spaced around a circle, so that the distance between ! 1 and ! 2 is equal to the
distance between ! 1 and ! N . Nature picks the true state !
                                                           ^ 2 , and the agent picks a state
a 2 . Let (a; !   ^ ) denote the minimum distance (about the circle) between the true state
and the choice, and suppose that u depends only on : u(a; !                  ^ )). This payo¤
                                                                ^ ) = u( (a; !
function captures both types of experiment. In the …rst case, there is a correct answer and
a collection of incorrect answers: u( ) = 1 if = 0 and u( ) = 0 otherwise. In the second
case, the loss is increasing in the . Suppose that the objective expert has a uniform prior
over the states and receives a signal s 2 that has an objective density that is symmetric
about the true state and declining in the distance from the true state. The symmetry
of the prior and the signal imply that the experts beliefs are symmetric about the signal:
 (!j! = s + x) = (!j! = s x) for all x j j=2.

    Given the symmetry of the problem, the optimal choice is obvious: the agent simply
reports the signal: a = s. The question that we focus on is what the agent chooses to
believe. The …rst-order condition (4) becomes:

                                              (!) exp [ u( (s; !))]
                                 (!) = P           0
                                                                      :                            (6)
                                           ! 0 (! ) exp [ u( (s; !))]


Without loss of generality label the signal state ! 0 . Label the states to the right of ! 0 (as
we move about the circle): ! 1 , ! 2 ,..., and label the states to the left ! 1 , ! 2 ,... If there are
an odd number of states keep the number of states with positive and negative indices equal.
If there are an even number of states, label the state furthest from ! 0 , ! N=2 . With this


                                                  12
labeling, the absolute value of the index is equal to (s; !). Now consider the ratio implied
by (6):
                                  (! m )    (! m ) exp [ u(jmj)]
                                         =
                                  (! n )    (! n ) exp [ u(jnj))]

    Several observations follow immediately. First, (! n ) = (! n ) implies (! n ) = (! n ),
                                                                                  (! 0 )   (! 0 )
so that inherits the symmetry of . Second, since u is maximized at = 0, (!          n)
                                                                                         > (! n)
                                                                                                  for
all ! n 6= ! 0 . As the sum to one, it follows that (! 0 ) > (! 0 ). The agent is overcon…dent
that they have selected the correct state. Finally, if we consider any subset of states relatively
                                           (! n )   (! n )
close to ! 0 ,     = f! n s.t. jnj < N g, (! m)
                                                  > (! m)
                                                           for any ! n 2  and ! m 62 . Hence
the agent will be overcon…dent that the true state is in . It follows that the agent will be
overcon…dent in the sense that their subjective con…dence intervals will be too tight.


3.4    Procrastination and Self-Control

An example illustrates how the model generates procrastination. Consider the decision
problem in Figure 2. There are three periods represented by the nodes A, B, and C. In the
…rst period (node A), the agent chooses whether to take an action or delay. The cost of the
action is 1. If the agent delays, then the agent is either free or busy in period 2 (node B).
If the agent is free, they take the action in period 2 at a cost of 1/2. If they are busy, they
delay the action until period 3 (node C) and take the action at a cost of 2. The agent wishes
to minimize costs.


                                         [Insert Figure 2]


    If we assume that it is equally likely that the agent is free or busy in period 2, then
an objective agent would calculate the expected cost of delay in period 1 to be 5/4. The
objective agent would then choose to act in period 1. What would a wishful thinker do?
Conditional on delay in period 1, the wishful thinker would want to increase the probability
of being free in period 2. If we take = 1, then a direct application of (4) implies that the
wishful thinker will anticipate an 82% chance of being free. Their subjective cost of delay
in period 1 would then be .77. The cost of taking the action is still 1. The wishful thinker
would then choose to delay. The agent overestimates their ability to complete the task in
period 2 and puts o¤ taking the action.

    The reason that the agent procrastinates is that delay is the uncertain option and wishful
thinkers value uncertainty. In a model of …rm entry such as Dixit (1989), in which the value

                                                 13
of delay is uncertain, wishful thinking will tend to reduce entry. In a model of …rm entry
such as Hopenhayn (1982), in which the value of entry is uncertain, wishful thinking will
tend to increase entry.

    A slight reformulation of the example …ts the experimental evidence of DellaVigna and
Malmendier (2006). They …nd that agents who purchase monthly gym memberships would
save money if they instead paid for each visit separately. Moreover, they …nd that agents
who purchase monthly memberships, which automatically roll-over in their data set, tend
to cancel less often than agents who purchase annual memberships, which do not roll over.
Their preferred explanation is that agents both overestimate their ability to attend the gym
and overestimate their ability to cancel their membership when desired. In our example,
delay would be analogous to the purchase of a monthly membership, and the second period
action would be analogous to attendance or cancellation. Note that in our explanation,
agents are time consistent. They correctly anticipate what they will do in each state of the
world. Their mistake is that they endogenously overestimate the probabilities of the states
in which they go to the gym and cancel their membership.

    Another reformulation illustrates the planning fallacy of Kahneman and Tversky (1979).
The planning fallacy is the tendency of people to underestimate the time that it will take
to complete a task. To capture the planning fallacy, we relabel “free” as “short comple-
tion time” and “busy” as “long completion time” in the example. Agents will then choose
to underestimate the time of completion because they want to believe that the completion
time is small. There are many explanations of the planning fallacy in the psychology litera-
ture, but Buehler, Gri¢ n and McDonald (1997) attribute it to wishful thinking.10 In their
experiments, they manipulate the incentive for early completion and show that incentives
to complete a task earlier exacerbate the planning fallacy. Participants’beliefs respond to
incentives.

   Agents underestimate the time it will take to complete a task even though they have
past experience with the task (Buehler, Gri¤en and Ross, 1994). This is also consistent with
our theory. In our theory past experience would play a role similar to objective information
 . So long as past experience is not de…nitive, there is room for wishful thinking. Buehler,
Gri¤en and Ross discuss several reasons that agents might convince themselves that past
experience is not de…nitive, including arguments such as past experience is not comparable,
that the situation has changed, and that there might have been extenuating circumstances.
  10
    Brunnermeier, Papakonstantinou, and Parker (2005) use the model of Brunnermeier and Parker (2005)
to explain the planning fallacy.




                                                 14
4      The ‡ow model11

In Section 3, we placed the information cost on the agent’s posterior. The agent could
manipulate their stock of information. An alternative approach is to place the cost on the
‡ow of new information. A feature of this approach is that the agent may be subjectively
Bayesian, yet exhibit non-Bayesian behavior to an outside observer.12 They accurately com-
bine their subjective interpretation of signals with their subjective priors to form subjective
posteriors. Their subjective reality is therefore rational. Their bias is that they view the
world optimistically and twist the interpretation of the signals that they observe. They see
the world through rose colored glasses.

    We alter the model of Section 3 to place the cost of information on the ‡ow of new
information. As before there is a set of actions a 2 A, a set of future states ! 2 , and a
payo¤ to each action in each state u(a; !). We drop the objective posterior (!). Instead
we assume that the agent has a prior over       and observes a signal which is informative
about the realization of ! 2 . We denote agent’s prior (!) 2int        . This prior need not
equal the prior held by an objective observer, as it may be distorted by the interpretation
of information in the past. The signal s is drawn from some …nite space of signals S. s is
generated by an information structure p : ! (S). An objective observer understands this
information structure. The wishful thinker can choose to believe that the signal is generated
by some alternative information structure p : ! (S). The cost of choosing p di¤erent
from p is:
                                 1 XX                p(sj!)
                                           p(sj!) ln                                      (7)
                                   !2 s2S
                                                     p(sj!)

The agent distorts the mapping between states and signals. The idea is that after seeing a
signal, the agent has an incentive to exaggerate the likelihood that it was generated by a
desirable state and downplay the likelihood that it was generated by an undesirable state. We
assume that the cost is independent of the prior . Alternatively, we could have assumed
that each term in (7) is weighted by (!) with the idea that it is more costly to twist
probabilities in more likely states. The cost function (7) is simpler and leads to qualitatively
similar phenomenon.
  11
    We thank Nicola Pavoni and Alp Simsek whose comments greatly improved this section.
  12
    The agents in Section 3 are not subjective Bayesians. New information alters the set of permissible
beliefs leading agents to reinterpret past information as well.




                                                  15
   The value to choosing an action a 2 A given the prior      and the signal s is then:
                            X     p(sj!) (!)                 1 XX                       p(s0 j!)
         V (a; ; s) = max        P         0    0
                                                   u(!; a)                p(s0 j!) ln              (8)
                       p
                            !2    ! 0 p(sj! ) (! )           !2   s0 2S
                                                                                        p(s0 j!)

The …rst term is subjective expected utility. The agent combines their subjective interpreta-
tion of the signal with their prior according to Bayes rule. As the signal s is known, expected
utility depends only on the probability of observing the signal s in each state. Note that
                                P
there is no presumption that !2 p(sj!) = 1, as each p(sj!) represents the probability of
observing s in a di¤erent state. The second term is the cost of information. This depends
not only on the signal s, but the probability of observing other signals s0 6= s.

   The agent chooses a 2 A to maximize (8).


4.1    Implications for belief choice

As before we …x the action a and write u(!) for u(a; !). We also …x s 2 S, and write p(!)
and p(!) for p(sj!) and p(sj!) respectively. Finally let (!) denote the posterior resulting
from the choice of p(!) :
                                            p(sj!) (!)
                                  (!) = P           0    0
                                                            :
                                           ! 0 p(sj! ) (! )


   The …rst order condition for p(!) implies:
                                                   h           i
                                          p(!) exp @E@p(!)u(!)

                            p(!) =          h          i                                           (9)
                                   p(!) exp @E@p(!)
                                                  u(!)
                                                         + (1 p(!))

                                                                                          @E u
where E u(!) is the expectation of u(!) with respect to the subjective posterior , and @p(!)
is the partial derivative of this expectation with respect to p(!). The derivation of (9) is in
the appendix.

   According to (9), the agent distorts their interpretation of the signal whenever @E@p(!)
                                                                                        u(!)
                                                                                             is
not zero. In this case, they tend to increase the probability of that the signal they received
comes from a state if increasing that probability increases expected utility. The derivative
can be written as
                             @E u(!)        (!)
                                       =         [u(!) E u(!)]:
                              @p(!)      Ep (!)
According to the term in brackets, the agent tends to raise the probability of states with


                                               16
above average utility (according to the posterior ). This is the essence of wishful thinking.
The agent believes to be true what they would like to be true. According to the ratio in
front of the term in brackets, the agent tends to distort beliefs more (in absolute value) if
the prior probability of the state is high. Given the cost of distorting beliefs, it does not
make sense to waste e¤ort distorting unlikely events. @E@p(!)
                                                            u(!)
                                                                 in (9) is multiplied by . The
larger is , the easier it is for the agent to manipulate their interpretation of the signal.13

   Note that since p a¤ects , it enters both sides of (9). These …rst-order conditions
therefore de…ne p implicitly. The next proposition shows that (9) is not vacuous. A solution
always exists. All proofs are in the appendix.


Proposition 1 Given 2int ( ) and p 2int[0; 1]j j , there exists a p 2int[0; 1]j                  j
                                                                                                     that sat-
    is…es (9) for all ! 2 .


    It is possible that there are multiple solutions to (9). This can happen when @E@p(!)u(!)
                                                                                              is
increasing in p(!), so that an increase in p(!) raises both the gain in subjective utility and
the cost of belief distortion. In such cases, the agent chooses the solution associated with
the highest V (a; ; s).

   Given that the ‡ow model leads to equations that are less familiar than those of the
cumulative model, it is useful to consider an example with two states to see the how the
model works.


4.2       Example with two states

Suppose that there are two states ! H and ! L with uH u(! H ) > u(! L ) uL so that ! H is
the good state and ! L is the bad state. Let H denote the prior belief that the state is ! H
and L the prior that the state is ! L . Let pH = p(sj! H ) denote the objective probability
that the signal is s given that the state is ! H . De…ne pL , pH , and pL accordingly.

       With these de…nitions (9) can be written as,

                                                          pH
                               pH =                              H L pL (uH uL )
                                                                                                         (10)
                                                                (pH H +pL L )2
                                         pH + (1      pH )e
                                                        pL
                               pL =                            H L pH (uH uL )
                                                                                 :
                                                              (pH H +pL L )2
                                         pL + (1      pL )e
  13
    If the terms in (7) are weighted by (!), then it is more costly to distort beliefs when the probability of
the state is high. This e¤ect o¤sets the desire coming from preferences to distort these beliefs.

                                                     17
In this case, pH and pL still appear on both sides of the equation, but the assumption of
two states eliminates much of the interaction between states and allows us to state several
comparative static results cleanly. We collect these in the next proposition. The proposition
is proved in the appendix.


Proposition 2 With two states:

        1. pH > pH and pL < pL
        2. pH is strictly increasing in uH        uL , whereas pL is strictly decreasing in uH             uL
        3. pH is strictly increasing in , whereas pL is strictly decreasing in
        4. pH is strictly increasing in pH , whereas pL is strictly increasing in pL
        5. pH is strictly increasing in H if pH         H   < pL   L   and decreasing in   H   if pH   H   >
           pL L . The opposite applies for pL .


    Point (1) is the essence of wishful thinking: the subjective probability that the signal
originated from the good state rises, whereas the subjective probability that the signal orig-
inated from the bad state falls. The subjective interpretation of the signal is therefore more
optimistic than the objective interpretation, which implies that the subjective posterior will
also be more optimistic. Point (1) follows immediately upon inspection of the sign of the
exponent in the exponential term in the denominator of (10). Point (2) states that the
extent of wishful thinking is increasing in the relative payo¤ of the desirable state. Point
(3) states that wishful thinking is decreasing in cost parameter 1= . Point (4) re‡ects the
e¤ect of the objective probabilities on the subjective probabilities. Finally, point (5) re‡ects
the sensitivity of the posterior with respect to the signal. The only surprising result is (5).
To understand this result, note that @E@p(!)
                                           u(!)
                                                = 0 both when H = 0 and when H = 1, so
pH = pH in each of the extreme cases. In between, pH rises and then falls relative to pH as
  H rises. It turns out that the in‡ection point is equal to pL L = H .



4.2.1   Action Choice

We can calculate the value of the action a under the optimal beliefs (see the appendix).
Substituting (9) into V (a; ; s) for a given action choice a yields,

                                             1X                        @E u(!)
        V ( ; s) = max E   (a) u(a; !)   +        ln p(!) exp                  + (1    p(!))
                   a2A
                                             !2
                                                                        @p(!)


                                                   18
where (a) is the posterior associated with action a.

    Like the cumulative model, the ‡ow model can produce overcon…dence and procrastina-
tion. The ‡ow model also leads to other apparent deviations from rational behavior such as
con…rmation bias and polarization.


4.3    Con…rmation bias

Con…rmation bias occurs when an agent interprets information in a way that conforms to
their priors. Wishful thinking occurs when an agent interprets information in a way that
enhances their subjective utility. The connection between wishful thinking and con…rmation
bias rests on the observation that the agent’s prior is itself the result of wishful thinking in
the past and hence also likely correlated with payo¤s if payo¤s are persistent.

    To illustrate con…rmation bias, consider the example with two states, ! 1 and ! 2 . Consider
two agents, one of whom receives high utility from state ! 1 and the other receives high
utility in state ! 2 . According to Proposition 2, both will twist signals in the direction of
their preferred state. Now suppose that the agents unexpectedly receive additional signals.
Again applying Proposition 2, each agent will again twist the signals in the direction of their
preferred state, which will also be the direction of their priors.

    Most tests of con…rmation bias take the priors as given and evaluate how an agent
interprets additional information. They do not consider the agent’s subjective utility. It
is therefore di¢ cult to know whether the interpretation of the signal is being in‡uenced
by the prior beliefs or whether both beliefs and the interpretation are being in‡uenced by
payo¤s. A few studies attempt to disentangle the e¤ects of beliefs and payo¤s. Mijovic-
Prelec and Prelec (2010) had subjects make incentivized predictions before and after being
given stakes in the outcomes. There was a tendency for subjects to reverse their predictions
when the state that they had predicted to be less likely turned out to be the high payo¤
state. Bastardi, Uhlmann, and Ross (2011) considered a population of parents with similar
priors: all professed to believe that home care is superior to day care for their children. They
di¤ered, however, in their payo¤s, as some had chosen home care for their children, while
others had chosen day-care. They found that the interpretation of evidence aligned with the
payo¤s of the subjects rather than the prior. The parents who had placed their children in
day care rated a study supporting day care more favorably, whereas the parents who cared
for their children at home did the opposite. In both of these studies, the interpretation of
information appears to have been more responsive to payo¤s than priors. This does not


                                              19
imply that priors do not matter, but only that wishful thinking might be present as well.


4.4    Polarization

Polarization occurs when two agents with opposing beliefs see the same signal and each
becomes more convinced that their view is the correct one (Lord, Ross and Lepper, 1979).
Wishful thinkers can exhibit polarization if they place di¤erent values on the states and the
information that they receive is su¢ ciently ambiguous.

    Consider again a setting with two agents labeled i and j and two states labeled ! 1 and ! 2 .
Suppose that agent i receives utility uH in state ! 1 and uL in state ! 2 and agent j receives
utility uH in state ! 2 and uL in state ! 1 . In keeping with our discussion of con…rmation
bias, suppose that each has received some information in the past that they have interpreted
optimistically, so that agent i has a prior that places weight H > 12 on state ! 1 , and agent
j places the same prior on state ! 2 . Each then sees the same signal s generated by the
information structure p. Let p1 denote the probability of seeing s in state ! 1 and p2 the
probability of seeing s in state ! 2 .

    Each interprets the signal according to (10). Since their payo¤s and priors di¤er, their
interpretation di¤ers. Agent i chooses

                                                       p1
                         p1 (i) =                        H (i) L (i)p1 (i)(uH uL )
                                                        (p1 (i) 1 (i)+p2 (i) 2 (i))2
                                    p1 + (1   p1 )e
                                                      p2
                         p2 (i) =                      H (i) L (i)p2 (i)(uH uL )
                                                      (p1 (i) 1 (i)+p2 (i) 2 (i))2
                                    p2 + (1   p2 )e

whereas agent j chooses

                                                      p1
                        p1 (j) =                       H (j) L (j)p1 (j)(uH uL )
                                                      (p1 (j) 1 (j)+p2 (j) 2 (j))2
                                    p1 + (1   p1 )e
                                                       p2
                        p2 (i) =                         H (j) L (j)p2 (j)(uH uL )
                                                        (p1 (j) 1 (j)+p2 (j) 2 (j))2
                                    p2 + (1   p2 )e

The functional forms are similar. Only the mapping between payo¤s, priors, and states is
switched. In keeping with Proposition 2, agent i twists their interpretation of the signal in
the direction of their more preferred state, which is state ! 1 . They choose p1 (i) > p1 and
p2 (i) < p1 . Agent j twists the signal in the opposite direction. They choose p1 (j) < p1 and
p2 (j) > p1 .


                                               20
   These choices give rise to the posteriors:

                                                                           H
                                                 1 (i)   =                         p2 (i)
                                                                H   + (1       H ) p1 (i)


and
                                                                           L
                                                1 (j)    =                         p2 (j)
                                                                H   + (1       H ) p1 (j)


Polarization occurs if i (! 1 ) > H and j (! 1 ) < L which requires pp21 (i)
                                                                         (i)
                                                                             < 1 < pp12 (j)
                                                                                        (j)
                                                                                            . In this
case both agents have observed the same signal and each has become more con…dent in their
assessment of the state.
         p2 (i)
   Now   p1 (i)
                  < 1 if

                                    H (i) L (i)p1 (i)(uH uL )                                         H (i) L (i)p2 (i)(uH uL )
                                   (p1 (i) 1 (i)+p2 (i) 2 (i))2                                      (p1 (i) 1 (i)+p2 (i) 2 (i))2
      p2 p1 + (1         p1 )e                                       < p1 p2 + (1            p2 )e                                  :

            p2 (j)
Similarly   p1 (j)
                     > 1 if

                                  H (j) L (j)p1 (j)(uH uL )                                           H (j) L (j)p2 (j)(uH uL )
                                 (p1 (j) 1 (j)+p2 (j) 2 (j))2                                        (p1 (j) 1 (j)+p2 (j) 2 (j))2
      p2 p1 + (1         p1 )e                                      > p1 p2 + (1            p2 )e                                   :

Since uH > uL , the signs of the exponents in the exponentials push the inequalities in the
right direction. If p1 = p2 , then both inequalities hold. Hence polarization is possible.
Polarization is more likely (at least in this example) when the objective odds p(!   2)
                                                                                 p(! 1 )
                                                                                         are close
to even and when uH uL is large. In other words, polarization tends to occur when the
signal is relatively uninformative about the state and the desire to believe is large.


4.5     Comparing the two formulations

The cumulative model and the ‡ow model each have their advantages and disadvantages.
Both approaches can explain overcon…dence and procrastination. In addition, the ‡ow model
can explain con…rmation bias and polarization. The cumulative model cannot. The reason
is that subjective posteriors are closely tied to objective posteriors in (4). News that raises
  (!) will tend to raise (!) for all agents. The cumulative model leads to an algebraically
simpler solution which may prove useful in dynamic applications.

   There are other di¤erences in the two approaches. Agents in the ‡ow model are subjective
Bayesians and appear non-Bayesian to an objective observer. On the other hand, agents in


                                                                    21
the cumulative model maximize (3). They therefore appear to be objective Bayesians with
an Epstein-Zin utility function. If one attempts to elicit their subjective beliefs, however,
these subjective beliefs will appear non-Bayesian.

    Beliefs are more stable in the ‡ow model. They evolve with the ‡ow of information.
Beliefs can potentially change dramatically in the cumulative model. If an agent chooses
action a, and the payo¤ to action a changes, then the agent will alter their beliefs even if
they have not received any new information.

    If the payo¤s to states are stable, then beliefs in the ‡ow model may diverge further
and further from objective reality over time as the agent continues to twist new signals in
the direction of the higher payo¤s. This divergence may seem undesirable in some settings.
It is possible that the true model is a combination of the two settings. The ‡ow model is
used on a day to day basis, but ever so often the agent takes stock of their world view and
recalibrates their posteriors using the cumulative model.



5     Three asset pricing models

In this section we illustrate some of the equilibrium implications of the theory through three
asset pricing models. The …rst is a model with a risk free bond and idiosyncratic income risk
along the lines of Huggett (1993) extended to include agents that di¤er in their optimism.
All else equal the more optimistic agents tend to consume more and save less, and therefore
are less wealthy in steady state. The equilibrium interest rate is above that in an economy
without optimism. The second is a model of trade with private information. Again we assume
that agents di¤er in their optimism. We show that informed traders, whether optimistic or
not, can pro…t from their private information by trading with agents with di¤erent beliefs.
The third model is a model of bubbles in the spirit of Kindleberger (1978). Occasionally
optimists get lucky; their wealth increases; and their in‡uence on asset prices grows, raising
asset prices for a time above what is warranted by objective observers.


5.1    A Huggett economy

Time is discrete. There is a single asset, a risk free bond, with a gross return R. There are
a continuum of agents indexed by i 2 [0; 1]. Agents indexed by i 2 [0; ] are objective. They




                                             22
maximize
                                                         X
                                                         1
                                                                t
                                                    E               u(ct )
                                                         t=0

The remainder of agents are wishful thinkers. Wishful thinkers maximize the same utility
function u and have the same discount factor , but choose their expectations. In both cases
we assume that u is increasing, concave, di¤erentiable and displays decreasing absolute risk
aversion, a class which includes constant relative risk aversion.14

    Each period t, each agent i receives an endowment yit . yit takes one of S values fy1 ; : : : yS g
Y . The realizations of yit are independent and identically distributed across individuals. The
probability of yit is p(yit ).

   The state of individual i in period t is (Ai ; yi ) where Ai is their in period t 1 saving
and yi is their current-period endowment income. We restrict Ai > where < 0 and
y1     (R 1) so that the agent can always service their debts if saving is negative.

    We need to extend (3) to a dynamic setting. We construct the dynamic analog of the
cumulative model. We maintain the assumption that wishful thinkers are sophisticated
and that they understand the relationship between action choice and beliefs. Given their
initial state (A0 ; y0 ), we assume that they choose a sequence of state contingent plans A(y t )
subjective beliefs (y t ) where y t is the history of endowment realizations through period t.
Their maximization problem is:

                                                         X
                                                         1           X
                                                                t
       V w (A0 ; y0 ) =              max                                           (y t )u(RA(y t 1 (y t )) + yt   A(y t ))
                          f (y t );A(y )> gt>0;yt 2Y t
                                     t
                                                         t=0        y t 2Y t

                                                         1          X  1            X                 (y t )
                                                                               t                t
                                                                                              (y ) ln
                                                                                                      (y t )
                                                                     t=1           y t 2Y t


where y t 1 (y t ) denotes the history through y t 1 embedded in the history y t . As before the
…rst term is subjective expected utility. The second term is the cost of distorting beliefs. We
allow the agent to manipulate beliefs at all horizons. We discount the distortion of future
beliefs at the same rate as future utility. The 1       in front compensates for the fact that
distorting (y ) also tends to distort (y ) for all s > t, so that (y t ) e¤ectively enters the
                  t                         s

sequence problem with a weight t =(1          ).
  14
    We need asset accumulation to be bounded to use standard theorems. The only cases in the literature
in which it is known that asset accumulation is bounded is the case of i.i.d. income shocks and decreasing
absolute risk aversion (Schechtman and Escudero, 1977) or income that follows a two state Markov chain
and constant relative risk aversion (Huggett, 1983).




                                                               23
    If we assume subjective beliefs are consistent in the sense that the conditional expecta-
tions satisfy the laws of probability, (y t ) = (ys (y t )) (y t jys (y t )) for all 0 < s < t, then we
can write the cost of distorting y t recursively:
                                                   2                                                                                            3
      X                        t
                             (y )           X                                                  X                                       t
                                                                                                                                   (y jy1 ) 5
                (y t ) ln          =               4 (y1 ) ln (y1 ) + (y1 )                                        (y t jy1 ) ln
                             (y t ) y                         (y1 )                                                                (y t jy1 )
     y t 2Y t                               1 2Y                                        y t 2Y t s.t. y1 2y t


The cost of distorting y t is the cost of distorting y1 plus the cost of distorting y t conditional
on y1 . This allows us to write the wishful thinker’s problem recursively (see the appendix
for the details):

                                                                        X                                          X                   (y 0 )
        V w (A; y) =                    max0               u(c) +                (y 0 )V w (A0 ; y 0 )                     (y 0 ) ln                (11)
                               A0 > ;f (y )gy0 2Y
                                                                        y 0 2Y                                    y 0 2Y
                                                                                                                                       (y 0 )
                                                       1
                            = max
                               0
                                  u(c) +                   ln E(A;y) expf V w (A0 ; y 0 )g
                               A>


where it is understood that c = RA + y A0 and the second equality comes from substituting
the optimal beliefs as in (5). Note that choice is dynamically consistent in this setting. Even
though, following Jevons, we think of the agent as choosing the entire future sequence of
beliefs and actions to maximize their current subjective utility, the agent solves a problem
of similar form in the future so that the subjective plans that the agents contemplates in
one period become actual plans when future states are realized. The wishful thinker distorts
the probabilities that future states will occur but not the actions that will be taken in those
states.

    An equilibrium is an interest rate R, two densities ho (A; y) and hw (A; y), and two func-
tions co (A; y) and cw (A; y) such that co (A; y) is the optimal policy of the objective agents
and cw (A; y) is the optimal policy of the wishful thinkers, the goods market clears
                              Z                                     Z   1                                Z   1
                                        o                                    w
                                       c (Ait 1 ; yit )di +                 c (Ait 1 ; yit )di =                 yit di
                                   0                                                                     0


and ho (A; y) and hw (A; y) characterize the steady state distribution across states of the two
types of agent respectively.

   We have the following proposition (the proof is in the appendix).

Propostion The following hold:

   1. An equilibrium exists.

                                                                            24
   2. The consumption function cw (A; y) and the value function V w (A; y) for the wishful
      thinkers are increasing in both their arguments.

   3. Whenever A0 > , the Euler equation for the wishful thinkers is

                                                    expf V w (A0 ; y 0 )g
                   u0 (cw (A; y)) = RE(A;y)                                     u0 (cw (A0 ; y 0 )) :
                                                 E(A;y) [expf V w (A0 ; y 0 )g]

       where E(A;y) is the objective expectation conditional on (A; y).

   4. Given y, ho (A; y) …rst order stochastically dominates hw (A; y).

   5. Whenever the equilibrium is unique, R is decreasing in .

    Given the assumptions of DARA utility and i.i.d. income, Schechtman and Escudero
(1977) show that asset accumulation is bounded above. The …rst three results then follow
from standard dynamic programming arguments. Given that high value states tend to be
high consumption states and high consumption states are low marginal utility states, the
Euler equation implies that wishful thinkers tend to place greater weight on low marginal
                                                                     0 w (A0 ;y 0 ))       u0 (co (A0 ;y 0 ))
utility states than do the objective agents. It follows that E(A;y) uu(c
                                                                      0 (cw (A;y)) < E(A;y) u0 (co (A;y))

whenever A0 > , and that wishful thinkers consume more, save less, and accumulate less
wealth. The lower wealth explains point 4. The precautionary savings motive of the objective
agents tends to push down the real interest rate. Wishful thinkers’optimism tends to push
the interest rate up. R is therefore increasing in the proportion of wishful thinkers which
explains point 5.15

    Note it is important here that wishful thinking a¤ects the only the expectation of labor
income in this Huggett economy. The bond return is …xed. In a model with risky assets,
wishful thinkers can be optimistic about asset returns. Depending on the relative importance
of income and substitution e¤ects, saving could rise. We will revisit this issue below when
we consider asset bubbles.

   Figure 3 depicts the determination of the equilibrium. The gross interest rate R is on
the vertical axis. The two curves depict the average saving of each type of agent: Aw (R) for
wishful thinkers and Ao (R) for objective agents. When R equals 0, Ao (R) equals . As R
approaches 1= , Ao (R) converges to 1 (Chamberlain and Wilson, 2000). Since the objective
agents save more, Ao (R) is always to the right of Aw (R). The equilibrium is at the point
that total saving in the economy is equal to zero, so that Ao (R) + (1      )Aw (R) = 0.
  15
    The quali…er “whenever the equilibrium is unique” is needed only because one cannot guarantee that
the equilibrium in the Huggett model is unique and hence there may be equilibria in which the A(R) curves
in Figure 4 below “bend the wrong way.”

                                                     25
                                            [Insert Figure 3]


5.2     Information-based trade

In our Huggett economy, agents have access to the same objective information yet hold
di¤erent beliefs. The fact that they “agree to disagree” suggests that our model might lie
outside of the class of considered by Milgrom and Stokey (1982). In fact, relative to Milgrom
and Stokey, our model relaxes the assumption that it is common knowledge that all agents
are rational expected utility maximizers.16

   We present an example of information-based trade. There are four states f! 1 ; ! 2 ; ! 3 ; ! 4 g
and two assets a1 and a2 . There are two agents: one is objective and one is a wishful thinker.
The following table presents u(a; !). These are the same for both agents.


                                                    a1    a2
                                               !1   6     4
                                               !2   2     4
                                               !3   2     3
                                               !4   2     1
                                 Table 1: Payo¤s to the two actions


    We assume that initially all states are equally likely. Since both assets have the same
expected payout, the objective agent is indi¤erent. The wishful thinker, however, places
more weight on ! 1 and prefers asset a1 .17 Therefore assigning a1 to the wishful thinker and
a2 to the objective agent is ex ante e¢ cient.

    Suppose now that the agents receive a signal that indicates whether the state is in the
set f! 1 ; ! 2 g or the set f! 3 ; ! 4 g. If the signal indicates f! 1 ; ! 2 g there is no trade. The
objective agent is still indi¤erent and the wishful thinker still prefers a1 . If, however, the
signal indicates f! 3 ; ! 4 g. The objective agent remains indi¤erent, but the wishful thinker
places greater weigh on ! 3 and prefers to trade a1 for a2 . The objective agent obliges.

   Note that the signal could be the private information of the wishful thinker without
a¤ecting this outcome. The wishful thinker’s willingness to trade would reveal that their
  16
     We also implicity shut down any learning mechanism that would get rid of biased beliefs in the long run
as agents gather enough information to reject their biased model in favor or the objective one.
  17
     For example if = 1, the expected value of a1 is 4.67 and the expected value of a2 is 3.50.


                                                    26
information set is f! 3 ; ! 4 g, but the agents would agree to disagree on the relative probabilities
of ! 3 and ! 4 and trade would still take place. Similarly we could raise the payo¤ to a1 in state
! 3 and the payo¤ to a2 in state ! 2 by a small amount " without altering the ex ante e¢ ciency
of the allocation, and then the signal could be the private information of the objective agent
and trade would take place in the case that the signal was f! 3 ; ! 4 g.

   When the signal is private information, agents learn from trade. They understand the
motivation of the other agent and back out the signal from the other agents desire to trade.
This di¤erentiates our framework from other models of trade with heterogeneous beliefs in
which agents hold their beliefs dogmatically and do not learn from trade. Examples include
Blume and Easley (1992), Geanakoplos (2003), Borovicka (2018), or Caballero and Simsek
(2018).

    While special this example illustrates the general point that wishful thinkers and objective
agents process information di¤erently. A change in circumstance may alter the relative
probability of various states in the mind of the objective agent, but it has an additional
e¤ect on the perspective of the wishful thinker as it also alters the wishful thinker’s desire to
distort these probabilities. In this way, news is likely to di¤erentially a¤ect perceived asset
returns, and these di¤erential e¤ects on perceived returns are likely to generate trade.


5.3    Bubbles

We saw in our Huggett economy that the presence of wishful thinkers can drive up the price
of an asset, in this case a risk free bond, relative to that of an economy populated only by
objective agents. Here we use this observation to ‡esh out a story of asset bubbles. In normal
times, assets will be priced mainly by the objective agents as we saw in our Huggett economy
that the wishful thinkers will tend to have less wealth. Every now and then, however, the
wishful thinkers may take over and an asset price may rise above fundamental value, where
fundamental value is taken to be the price in an economy dominated by objective agents.

    Kindelberger (1978) describes the typical bubble as follows. The bubble begins with
the introduction of a new asset, typically re‡ecting a new technology such as railroads,
information technology, or cryptocurrency. A period of good news then increases interest
in the new asset. In the second phase, interest evolves into euphoria, and prices rise above
what would be expected by an objective observer. This is the bubble phase. Typically the
bubble does not crash immediately. There is a period of hesitation at the top of the market.
This is the third phase. The …nal phase is the crash, as reality sets in and prices return to


                                                 27
normal.

    A model with wishful thinkers and objective agents can …t this general pattern. Here we
sketch the broad outlines of such a model. Consider the introduction of a new technology.
Suppose that initially it is not known wheather the technology is viable or not, and that
conditional on being viable there is a chance that the technology is transformative and a
chance that the technology is merely mildly pro…table. Wishful thinkers will be drawn to
the new technology both because it is unproven and hence uncertain and because it promises
high returns. Initially wishful thinkers will make up only a small portion of the demand for
the asset because they tend to be less wealthy than objective agents. The initial success
of the asset may cause their role to grow with time. This happens for two reasons. First,
since the wishful thinkers will hold a greater share of the new asset in their portfolios, initial
reports that the technology is viable will disproportionately bene…t them.18 Second, in the
‡ow model each bit of good news will be interpreted in a positive light, leading to greater and
greater optimism. As the importance of the wishful thinkers grows, they bid the price of the
asset above fundamentals. As the price rises the importance of the wishful thinkers continues
to grow, as objective agents see the market as overvalued. At the top of the market, when
an objective observer would question the potential of the technology to be transformative,
wishful thinkers will tend to downplay bad news. This is the period of hesitation. Wishful
thinking, however, is not magical thinking. Eventually even optimists must admit that the
asset is only mildly successful.



6      Discussion

6.1     Sophistication vs naïveté

We have chosen to model sophisticated agents that are aware of how choices a¤ect their
beliefs. When choosing an action in the decision problems (3) or (11), the agent foresees
that their beliefs will change and takes this into consideration. Another possibility is that
agents are naïve. They may not consider or may not be aware of how their choices a¤ect
their beliefs.

  Most of the phenomenon considered above would still be apparent if the agent were naïve.
Optimism, overcon…dence and polarization only depended on the choice of beliefs, not on
  18
    This e¤ect is also present in Caballero and Simsek (2018). The price of the risky asset rises with the
wealth of their optimistic agents.


                                                   28
the choice of actions. Naïveté, however, gives rise to dynamic inconsistency, as the agent
fails to anticipate how a choice today will a¤ect beliefs that a¤ect choices tomorrow. Time
inconsistency gives rise to additional phenomenon which we consider below.

    One such phenomenon is the endowment e¤ect (Kahneman, Knetsch, and Thaler, 1990).
The endowment e¤ect is the idea that the mere possession of an object increases its value
in the mind of the possessor. Consider a naïve agent in the cumulative model and consider
an object of uncertain value. If the agent possesses the object, then the agent will tend to
overweight the possibility that the object has high value. If the agent does not posses the
object they have no reason to believe that it is of high value and since they are naïve they
would not consider how possession of the object would a¤ect their beliefs. This gives rise
to the endowment e¤ect. This explanation of the endowment e¤ect is similar to those in
cognitive science which emphasize biased search, memory and information processing (See
Morewedge and Giblin (2015) for a review).19

    Another phenomenon is the foot-in-the-door technique in marketing (Freedman and
Fraser, 1966). The foot-in-the-door technique involves getting a person to make a big deci-
sion by …rst having them make a similar decision on a smaller scale. As an example consider
a world with two states ! H and ! L and consider a gamble in which the agent gets x if the
state is ! H and x otherwise. Suppose that utility, u(x), is increasing and concave and that
the agent has a prior belief H that the state is ! H . If the agent is naïve, they base the
decision on their prior and do not consider how taking the gamble will a¤ect their beliefs.
If H is high enough, but not too high, it is possible due to the concavity of utility that
the agent would choose the gamble for small x and avoid the gamble for larger x. Upon
choosing the gamble for small x, wishful thinking would lead the agent to increase the per-
ceived probability of ! H , and it is then possible that they would be willing to take the larger
gamble.


6.2     Robustness or Wishful Thinking

Hansen and Sargent (2008) model agents as pessimistic. Their agents are concerned that
their model of the economy is inaccurate, and seek to make sure that their decisions are
robust to plausible alternatives. This leads to an optimization problem very similar to (3),
but the cost (2) enters with the opposite sign and the agent …rst minimizes with respect
  19
    Since the agent in the ‡ow model manipulates the ‡ow of information and not the stock of information,
the ‡ow model can only explain the endowment e¤ect if the person who receives the object also receives a
signal that they can manipulate.


                                                   29
to beliefs before maximizing with respect to actions. Not surprisingly, this leads to very
di¤erent behavior. The agent distorts beliefs toward the low payo¤ states instead of the high
payo¤ states, and behaves as if they have a preference for early resolution of uncertainty
rather than late resolution of uncertainty.

    Which model is a better is a better model of human behavior is not an easy question
to answer. Each model is supported by its own body of psychological evidence and each
performs well on in certain domains and poorly in others. The psychological justi…cation
for robustness is that it is consistent with ambiguity aversion and generates a preference
for late resolution of uncertainty, which many …nd plausible. The economic justi…cation for
robustness is that a preference for robustness gives rise to risk sensitive preferences which
help to explain the behavior of asset prices, in particular the equity premium.

    As discussed above, there is also psychological evidence that agents distort beliefs in
the direction of payo¤s, and the psychological evidence in favor of optimism is at least as
strong as that in favor of ambiguity. While robustness appears to help explain asset pricing
behavior, there are many economic situations where are better explained by wishful thinking.
Corporate …nance tends to treat entrepreneurs as optimistic. Referring to entrepreneurs,
Daniel Kahneman said, “A lot of progress in the world is driven by the delusional optimism
of some people.”Cooper, Woo, and Dunkelburg (1988) …nd that two thirds of entrepreneurs
believe that their …rm will fare better than similar …rms run by others. Hamilton (2000) …nds
that the median earnings of entrepreneurs is 35% less than would they would be predicted
to earn in alternative jobs. Hall and Woodward (2010) argue that due to the extreme
dispersion in payo¤s, an entrepreneur backed by venture capital with rational expectations
and a coe¢ cient of relative risk aversion equal to two should place a certainty equivalent
value only slightly greater than zero on the distribution of outcomes that they face at the
time that they start their company. Dropping out of Harvard to develop a social networking
site as Mark Zuckerberg did would appear much more consistent with optimism than a
preference for robustness.

    Many self-control problems would appear to be more consistent with optimism than
robustness. We have already cited the evidence on gym memberships (DellaVigna and
Malmendier, 2006). Payday lending is another example. Payday loans typically accrue
about 18% over a period of two weeks or an annualized value of over 7000%. Borrowers
appear to be overoptimistic regarding their ability to repay and end up rolling loans over
multiple times. Borrowers also tend to be optimistic regarding how many times they will
roll over debt.



                                             30
    It is a question for future research to …nd the key determinants of when a domain is more
appropriate for wishful thinking and when a domain is more appropriate for robustness. Our
Huggett economy suggests that in normal times asset pricing may naturally be a domain
for robustness, since wishful thinkers tend to accumulate less wealth. Our discussion of
bubbles suggests that sometimes, however, wishful thinkers may come to play a larger role.
Entrepreneurship, on the other hand, would seem to be a natural domain for wishful thinking.

    It may also be the case that the same agents are wishful thinkers in some situations and
robust in others. Bassanin, Faia, and Valaria (2018) take a step in this direction. Citing
psychological research that suggests people are sometimes ambiguity averse and sometimes
ambiguity seeking and that these attitudes are state dependent, they construct a business
cycle model that incorporates both behaviors. They assume that agents are ambiguity averse
if the value function is below its historical mean, and ambiguity seeking otherwise. Their
model ampli…es business cycles by generating optimism in booms and pessimism in busts.


6.3    Brunnermeier and Parker

The most closely related paper is Brunnermeier and Parker (2005). That paper like our
paper presents a model of belief choice in which the bene…t of belief choice is that beliefs
enter directly into utility. Like our agents in the ‡ow model, their agents are subjective
Bayesians. Their model leads to many of the same phenomenon as our model, in particular
optimism and overcon…dence.

    The main di¤erence between the two approaches is the way in which they handle the
cost of belief choice. We assume a cost of distorting beliefs from some objective benchmark.
Brunnermeier and Parker focus instead on how distorted beliefs might lead to suboptimal
decisions. Because an agent with distorted beliefs may not be aware that their decisions are
suboptimal, they assume that the costs and bene…ts of belief choice are evaluated according
to the objective beliefs. To avoid the contractions arising from an agent using the objective
beliefs for one set of decisions and the distorted beliefs for another set of decisions, they
separate the two decisions in time. In their model there is an initial “period zero” that
occurs before all choices are made. In this period the agent chooses a prior. This choice
balances the utility gain from choosing an optimistic prior against the against the mistakes
that result from a mistaken prior. This choice is made using the objective probabilities
to weight outcomes. In subsequent periods, the agent observes the world, updates their
information as would a Bayesian and makes decisions. There is no subsequent belief choice.



                                             31
    Suboptimal decisions are clearly an important cost of distorted beliefs. Incorporating
this cost, however, presents signi…cant modelling challenges as one has to …gure out how to
model an agent that simultaneously juggles two sets of beliefs. Brunnermeier and Parker
found an ingenious solution to this dilemma by separating the choice of beliefs from the
choice of actions. The cost of their approach is that beliefs are only chosen once at the
beginning of life.

    Other di¤erences between the models evolve out of the placement of belief choice at the
beginning of life. In Brunnermeier and Parker, agents have an incorrect prior, but their
interpretation of evidence accords with objective reality. In our ‡ow model, agents may or
may not have an incorrect prior, it is there interpretation of signals that is overly optimistic.
In Brunnermeier and Parker the initial choice of beliefs tends to a¤ect future choices. In our
model, past choices also mold future beliefs.



7     Conclusion

We model an agent who gets utility from their beliefs and therefore interprets information op-
timistically. The framework can explain behavioral biases such as optimism, procrastination,
con…rmation bias, polarization, the endowment e¤ect, and the foot-in-the-door phenomenon.
In spite of these biases, the agent is subjectively Bayesian in some formulations.

    Our theory is based on two fundamental ideas. First that agents derive utility from their
beliefs along the lines of Jevons (1905), Loewenstein (1987) and Caplin and Leahy (2001).
The second is that at any point in time there are a set of models of the world that are all
plausible (Hansen and Sargent, 2008), so that agents have some freedom in choosing their
beliefs without choosing beliefs that are obviously wrong.

    An interesting direction for future research is to endogenize the set of plausible models.
This could be done either on the supply side or the demand side. If one takes the view
that the set of plausible models is well represented by the views in the mainstream media,
one could endogenize this supply along the lines Mullainathan and Schleifer (2005). On the
demand side, one could imagine enriching the model to add a choice of attention along the
lines of Sims (1998), Matejka and McKay (2015), or Caplin, Csaba, Leahy and Nov (2018).
Since wishful thinkers have a preference for late resolution of uncertainty, one might expect
wishful thinkers to exhibit willful ignorance.




                                               32
References


Akerlof, George, and William Dickens (1982), “The Economic Consequences of Cognitive
Dissonance,”American Economic Review, 72, 307-319.

Bassanin, Marzio, Ester Faia, and Valeria Patella (2018), “Ambiguous Leverage Cycles,”
working paper.

Bastardi, A.; Uhlmann, E. L.; Ross, L. (2011), “Wishful Thinking: Belief, Desire, and the
Motivated Evaluation of Scienti…c Evidence,”Psychological Science, 22, 731–732.

Benabou, Roland, and Jean Tirole (2002), “Self-Con…dence and Personal Motivation,”Quar-
terly Journal of Economics 117, 871-915.

Benabou, Roland, and Jean Tirole (2016), “Mindful Economics: The Production, Consump-
tion, and Value of Beliefs,”Journal of Economic Perspectives 30, 141-164.

Bernardo, Antonio, and Ivo Welch (2001), “On the Evolution of Overcon…dence and Entre-
preneurs,”Journal of Economics and Management Strategy, 10, 301-330.

Blume, Lawrence, and David Easley (1992), “Evolution and Market Behavior.” Journal of
Economic Theory 58, 9–40.

Brunnermeier, Markus and Jonathan Parker (2005), “Optimal Expectations,” American
Economic Review, 1092-1118.

Brunnermeier, Markus, Filippos Papakonstantinou, and Jonathan Parker (2008), “An Eco-
nomic Model of the Planning Fallacy,”NBER Working Paper 14228.

Burnside, Craig, Martin Eichenbaum and Sergio Rebelo (2016), “Understanding Housing
Booms and Busts,”Journal of Political Economy 124, 1088-1147.

Bordalo, Pedro, Nicola Gennaioli, and Andrei Schleifer (2018), “Diagnostic Expectations
and Credit Cycles," Journal of Finance 73, 199-227.

Borovicka, Jaroslav (2018), “Survival and Long-Run Dynamics with Heterogeneous Beliefs
under Recursive Preferences,”Journal of Political Economy, forthcoming.

Buehler, Roger, Dale Gri¢ n, and Michael Ross (1994), “Exploring the Planning Fallacy:
Why People Underestimate their Task Completion Times,” Journal of Personality and
Social Psychology 67, 366-381.

Buehler, Roger, Dale Gri¢ n, and Heather MacDonald (1997), “The Role of Motivated Rea-


                                           33
soning in Optimistic Time Predictions,”Personality and Social Psychology Bulletin 23, 238-
247.

Caballero, Ricardo, and Alp Simsek (2108), “A Risk-centric Model of Demand Recessions
and Macroprudential Policy,”NBER Working Paper No. 23614

Caplin, Andrew, and John Leahy (2001), “Psychological Expected Utility,”Quarterly Jour-
nal of Economics 116, 55–79.

Caplin, Andrew, and John Leahy (2004), “The Supply of Information by a Concerned Ex-
pert,”Economic Journal 114, 487-505.

Caplin, Andrew, and John Leahy (2006), “The Social Discount Rate,” Journal of Political
Economy 112, 1257-1268.

Caplin, Andrew, Daniel Csaba, John Leahy, and Oded Nov (2018), “Rational Inattention
and Psychometrics,”working paper.

Chamberlain, Gary and Charles Wilson (2000), “Optimal Intertemporal Consumption under
Uncertainty.”Review of Economic Dynamics 3, 365-395.

Cooper, Arnold, Carolyn Woo, and William Dunkelburg (1988), “Entrepreneur’s Perceived
Chances of Success,”Journal of Business Venturing 3, 97-108.

Dixit, Avinash (1989), “Entry and Exit Decisions under Uncertainty,” Journal of Political
Economy 97, 620-638.

Debondt, Werner, and Richard Thaler (1996), “Financial Decision Making in Markets and
Firms: A Behavioral Perspective,” Handbook in Operations Research and Management
Science 9, North-Holland.

DellaVigna Stefano, and Ulrike Malmendier (2006), “Paying not to go to the Gym,”Amer-
ican Economic Review 96, 694-719.

Epstein, Larry, and Stanley Zin (1989), “Substitution, Risk Aversion, and the Temporal
Behavior of Consumption and Asset Returns: A Theoretical Framework,”Econometrica, 57,
937-969.

Exley, Christine, and Judd Kessler (2018), “Motivated Errors,”working paper.

Freedman, J. L., and S. C. Fraser (1966), “Compliance without pressure: The foot-in-the-
door technique.”Journal of Personality and Social Psychology 4, 195–202.

Fuster, Andreas, David Laibson, and Brock Mendel (2012), “Natural Expectations and Eco-

                                           34
nomic Fluctuations," Journal of Economic Perspectives 24, 87-84.

Gabaix, Xavier (2014), “A Sparsity-Based Model of Bounded Rationality,”Quarterly Journal
of Economics 129, 1661-1710.

Geanakoplos, John (2003) “Liquidity, Default, and Crashes: Endogenous Contracts in Gen-
eral Equilibrium,” in Advances in Economics and Econometrics: Theory and Applications,
Econometric Society Monographs, Eighth World Conference 2, 170–205. New York: Cam-
bridge University Press.

Hall, Robert, and Susan Woodward (2010), “The Burden of the Nondiversi…able Risk of
Entrepreneurship,”American Economic Review 100, 1163-1194.

Hamilton, Barton (2000), “Does Entrepreneurship Pay? An Empirical Analysis of the Re-
turns to Self-employment,”Journal of Political Economy 103, 604-631.

Hansen, Lars, and Thomas Sargent (2008), Robustness, Princeton: Princeton University
Press.

Hopenhayn, Hugo (1992), “Entry, Exit, and Firm Dynamics in Long Run Equilibrium,”
Econometrica 60, 1127-1150.

Huggett, Mark (1993), “The Risk Free Rate in Heterogeneous-Agent, Incomplete-Insurance
Economies,”Journal of Economic, Dynamics and Control 17, 953-969.

Ito, Takatoshi (1990), “Foreign Exchange Rate Expectations: Micro Survey Data,”American
Economic Review 80, 434-449.

Jevons, William (1905), Essays in Economics, London: Macmillan.

Kahneman, Daniel, Jack Knetsch, and Richard Thaler (1990), “Experimental Tests of the
Endowment E¤ect and the Coase Theorem,”Journal of Political Economy 98, 1325–1348.

Kahneman, Daniel, and Amos Tversky (1979): “Intuitive Prediction: Biases and corrective
procedures,”TIMS Studies in Management Science, 12,313–327.

Kindelberger, Charles (1978), Manias, Crashes and Panics, New York: Basic Books.

   Knox, R. E., Inkster, J. A. (1968), “Postdecision Dissonance at Posttime,” Journal of
Personality and Social Psychology, 18, 319–323.

Loomes, Graham and Robert Sugden (1982), “Regret Theory: An Alternative Theory of
Rational Choice Under Uncertainty,”The Economic Journal 92, 805-824.



                                           35
Lord, Charles, Lee Ross and Mark Lepper (1979), “Biased Assimilation and Attitudinal
Polarization: The E¤ects of Prior Theories on Subsequently Considered Evidence,”Journal
of Personality and Social Psychology, 37, 2098-2109.

Loewenstein, George (1987), “Anticipation and the Valuation of Delayed Consumption,”
The Economic Journal, 97, 666–684.

Schechtman, Jack, and Vera Escudero (1977), “Some Results on ‘An Income Fluctuation
Problem’," Journal of Economic Theory 16, 151-166.

Stokey, Nancy, and Robert Lucas (1989), Recursive Methods in Economic Dynamics, Cam-
bridge: Harvard University Press.

Milgrom, Paul, and Nancy Stokey (1982), “Information, Trade, and Common Knowledge,”
Journal of Economic Theory 26, 17-27.

Mijovic-Prelec, Canica, and Drazen Prelec (2010), “Self-Deception as Self-Signalling: A
model and Experimental Evidence,” Philosophical Transactions of the Royal Society, B,
265, 227-240.

Morewedge, Carey, and Colleen Giblin (2015), “Explanations of the endowment e¤ect: an
integrative review,”Trends in Cognitive Sciences 19, 339–348.

Matejka, Filip, and Alisdair McKay (2015), “Rational Inattention to Discrete Choices: A
New Foundation for the Multinomial Logit Model,” American Economic Review, 105, 272-
298.

Mullainathan, Sendil, and Andrei Schleifer (2005), “The Market for News,” American Eco-
nomic Review 95, 1031-1052.

Pronin, Emily, Kimberly McCarthy, Sylvia Rodriguez, and Daniel Wegner (2006), “Everyday
Magical Powers: The Role of Apparent Mental Causation in the Overestimation of Personal
In‡uence,”Journal of Personality and Social Psychology 91, 218 –231

Sims, Christopher (1998), “Stickiness,”Carnegie-Rochester Conference Series on Public Pol-
icy 49, :317-356.




                                           36
8       Appendix

8.1       Derivation of (9)

Consider the maximization problem (8). The …rst order condition for p(sj!) is

                                            @E u(!)       1        p(sj!)       1
                                      0=                      ln                          !
                                            @p(sj!)                p(sj!)
                                                     P
where is the Lagrange multiplier on the constraint s0 p(s0 j!) = 1. We ignore the con-
straint p(!) 0. We will show that the it is never binding.

     Solving for p(sj!);

                                                               @E u(!)
                                   p(sj!) = p(sj!) exp                           1            !                   (12)
                                                                @p(!)

Now consider s0 2 Sns. The …rst order condition for p(s0 j!) implies

                                           p(s0 j!) = p(s0 j!) exp [ 1               !]


     @E u(!)
as   @p(s0 j!)
                 = 0.

     Summing over all s0 including s,

          X                                    @E u(!)                           X
     1=           p(s0 j!) = p(sj!) exp                       1       !     +             p(s0 j!) exp [ 1   !]   (13)
          s0 2S
                                                @p(!)
                                                                                s0 2SnS


or
                                                                                                         1
                                                                  @E u(!)                         0
                        exp [ 1       !]   = p(sj!) exp                   + (1                p(s j!))
                                                                   @p(!)
Dividing the left-hand side of (12) by the left-hand side of (13) yields,
                                                              h          i
                                                   p(sj!) exp @E@p(!)
                                                                    u(!)

                                  p(sj!) =            h         i
                                                        @E u(!)
                                           p(sj!) exp     @p(!)
                                                                  + (1 p(sj!))

as required. Note that given p(sj!) 2 (0; 1), p(sj!) > 0 so the constraint p(sj!)                            0 is never
binding.




                                                           37
8.2    Derivation of the Value of action a

Substituting (9) into (7)

        1 XX                         p(s0 j!)
                       p(s0 j!) ln
         !2    s0 2S
                                     p(s0 j!)
         2                                       h
                                                   @E u(!)
                                                           i                                                                                                  3
                                      p(sj!) exp    @p(!)                                                                             p(s0 j!) i
                                           h         i                                                                          h
        16
         6X                                                                      X X                                                               +(1 p(sj!)) 7
                                             @E u(!)                                                                                @E u(!)
                                p(sj!) exp    @p(!)
                                                       +(1 p(sj!))
                                                                                                     0
                                                                                                                   p(sj!) exp        @p(!)                     7
 =       6   p(sj!) ln                                                    +                    p(s j!) ln                                                     7
         4!2                                    p(sj!)                                                                              p(s0 j!)                  5
                                                                                s0 2Sns !2

                                           2
        X               @E u(!) 1 4X                                                         @E u(!)                                                   X X
 =            p(sj!)           +      p(sj!) ln p(sj!) exp                                           + (1                   p(sj!)) +                              p(s0 j!)
                         @p(!)                                                                @p(!)
        !2                         !2                                                                                                                 s0 2Sns !2
        X               @E u(!) 1 X                                             @E u(!)
 =            p(sj!)           +     ln p(sj!) exp                                      + (1                      p(sj!))
        !2
                         @p(!)    !2
                                                                                 @p(!)


   Focus on the …rst term
         X               @E u(!) X                                        (!)
               p(sj!)           =    p(sj!)                   P             0    0
                                                                                    [u(!)                    E u(!)]        =0
         !2
                          @p(!)   !2                               ! 0 p(sj! ) (! )




   which completes the derivation.


8.3    Derivation of (11)

We begin with the maximization problem



                                                             X
                                                             1           X
                                                                     t
      V (A; y) =                      max                                         (y t )u(RA(y t 1 (y t )) + yt                     A(y t ))
                        f (y t )gt>0;y2Y ;fA(y t )gt>0;y2Y
                                                             t=0         y2Y

                                                      1        X
                                                               1               X                         (y t )
                                                                          t
                                                                                         (y t ) ln
                                                                                                         (y t )
                                                                   t=1        y t 2Y t




                                                               38
where y t 1 (y t ) denotes the history through y t 1 embedded in y t and A >                                                                       . The key
observation that allows us to write the problem recursively is that
                                                              2                                                                                3
    X                            (y )t                X                  X                                                           t
                                                                                                                       (y1 ) (y jy1 ) 5
                  (y t ) ln             =                     4                             (y1 ) (y t jy1 ) ln
                                 (y t )                                                                                (y1 ) (y t jy1 )
   y t 2Y t                                           y1 2Y     y t 2Y t s.t. y1 2y t
                                                              2                                                                                                 3
                                                      X                                              X                                                t
                                                                                                                                                (y jy1 ) 5
                                             =                4 (y1 ) ln (y1 ) +                                      (y1 ) (y t jy1 ) ln
                                                                         (y1 )                                                                  (y t jy1 )
                                                      y1 2Y                                   y t 2Y t s.t. y1 2y t


so that

    1             X
                  1             X                           (y t )
                           t
                                            (y t ) ln
                                                            (y t )
                  t=0          y t 2Y t
                                                  2                                                                                              3
              1            X
                           1              X                                                 X                                              t
                                                                                                                                         (y jy1 ) 5
        =                            t            4 (y1 ) ln (y1 ) +                                       (y1 ) (y t jy1 ) ln
                                                             (y1 )                                                                       (y t jy1 )
                           t=1            y1 2Y                                    y t 2Y t s.t. y1 2y t
                                                                                                           2                                                        3
                   X                          (y1 )           X                    1         X
                                                                                             1                        X                                     t
                                                                                                                                                          (y jy1 ) 5
        =                      (y1 ) ln             +                      (y1 )                     t 1   4                         (y t jy1 ) ln
                                              (y1 ) y                                                                                                     (y t jy1 )
                   y1 2Y                                      1 2Y                            t=2            y t 2Y t s.t. y1 2y t


Similarly we can rewrite expected utility

   X
   1              X
              t
                           (y t )u(RA(y t )                 A(y t 1 (y t )))
    t=0           y2Y
                                                      X
                                                      1                  X              X
                                                                  t 1
        = u(RA(y1 )                      A0 ) +                                                         (y1 ) (y t jy1 )u(RA(y t )              A(y t 1 (y t )))
                                                      t=1              y1 2Y y t 2Y t s.t. y1 2y t
                                                        X                  X1                  X
                                                                                  t 1
        = u(RA(y1 )                      A0 ) +                      (y1 )                                        (y t jy1 )u(RA(y t )             A(y t 1 (y t )))
                                                        y1 2Y              t=1         y t 2Y t s.t. y1 2y t


Putting the two together




                                                                                       39
                                                          X
                                                          1             X
                                                                    t
   V (A; y) =                    max                                              (y t )u(RA(y t )                A(y t 1 (y t )))
                 f (y t )gt>0;y2Y ;fA(y t )gt>0;y2Y
                                                          t=0           y2Y

                                                    1           X
                                                                1              X                         (y t )
                                                                          t
                                                                                         (y t ) ln
                                                                                                         (y t )
                                                                t=1           y t 2Y t
                                                                                                     X                      (y1 )
             =                   max                      u(RA(y1 )                A0 )                       (y1 ) ln
                 f   (y t )gt>0;y2Y   ;fA(y t )gt>0;y2Y
                                                                                                 y1 2Y
                                                                                                                            (y1 )
                               2
                       X        X1                                       X
                     +   (y1 ) 4                        t 1
                                                                                          (y t jy1 )u(RA(y t )              A(y t 1 (y t )))
                             y1 2Y             t=1            y t 2Y t s.t. y1 2y t
                                                                                                              3
                         1           X
                                     1                    X                                          t
                                                                                                (y jy1 ) 5
                                            t 1
                                                                              (y t jy1 ) ln
                                                                                                (y t jy1 )
                                      t=2         y t 2Y t s.t. y1 2y t

             =                   max                      u(RA(y1 )                A0 )
                 f (y t )gt>0;y2Y ;fA(y t )gt>0;y2Y
                                                        X                           (y1 )            X
                                                                    (y1 ) ln              +                       (y1 )V (A(y0 ); y1 )
                                                        y1 2Y
                                                                                    (y1 )        y1 2Y


which is the desired equation.


8.4    Proof of the Propositions

Proposition 1 Given             and p, there exists a p that satis…es (9) for all ! 2 .

   Proof: Consider the mapping T : [0; 1]j                      j
                                                                    ! [0; 1]j j de…ned by (9). Given any p 2 [0; 1]j                            j

de…ne T (p)(!) 2 [0; 1], by
                                                         h           i
                                                p(!) exp @E@p(!)u(!)

                              T (p)(!) =          h          i            :
                                         p(!) exp @E@p(!)
                                                        u(!)
                                                               + (1 p(!))

Clearly T (p)(!) 2 [0; 1] for each !. Also, T (p) is continuous in p. By Brouwer’s …xed point
theorem, there exists p 2 ( ) such that T (p) = p:

Proposition 2 With two states:

       1. pH > pH and pL < pL
       2. pH is strictly increasing in uH                       uL , whereas pL is strictly decreasing in uH                                   uL

                                                                    40
           3. pH is strictly increasing in , whereas pL is strictly decreasing in
           4. pH is strictly increasing in pH , whereas pL is strictly increasing in pL
           5. pH is strictly increasing in H if pH                H   < pL    L   and decreasing in      H   if pH   H   >
              pL L . The opposite applies for pL .


     Proof: Given two states (9) can be rewritten as.

                                                                pH
                                      pH =                             H L pL (uH uL )
                                                                      (pH H +pL L )2
                                              pH + (1      pH )e

                                                                               H L pL (uH uL )
                                                                              (pH H +pL L )2
(1) follows from the observation that uH > uL implies e                                          < 1. pL < pL because
     H L pL (uH uL )
    (pH H +pL L )2
e                      > 1.

    Consider now T mapping de…ned in Proposition 1 and applied to the example with two
states. Let T (pH ) denote T (p)(! H ). Then

                                                                   pH
                                    T (pH ) =                            H L pL (uH uL )
                                                                        (pH H +pL L )2
                                                 pH + (1    pH )e
Note that when pH = 0, we have

                                                             pH
                                    T (0) =                             H (uH uL )
                                                                                     >0
                                              pH + (1      pH )e         pL L




and when pH = 1
                                                             pH
                                  T (1) =                             H L pL (uH uL )
                                                                                         <1
                                                                      ( H +pL L )2
                                             pH + (1     pH )e
Each …xed point of the T mapping is a solution to the …rst order condition.

     Now consider the value of the policy pH :

    pH    H uH         1                     1
                           pH ln (pH =pH )       (1 pH ) ln ((1       pH ) =(1       pH ))+terms independent of pH
pH    H   + pL   L


The derivative of this value is

                  H uH  pH H uH + pL L uL       1               1
                                         2 H      ln (pH =pH ) + ln ((1                              pH ) =(1    pH ))
        pH H + pL L      (pH H + pL L )
          H L pL (uH uL ) 1                1
      =                2
                             ln (pH =pH ) + ln ((1 pH ) =(1 pH ))
         (pH H + pL L )


                                                           41
Note here that pH and pL are chosen separately and do not necessarily sum to one. This
derivative is positive and in…nite if pH = 0 and negative and in…nite when pH = 1: Hence
the …rst and last critical points are maxima. Generically every local maximum is associated
with a point T (p) = p such that T 0 (p) < 1.

   (2), (3) and (4) follow from the observation that T is increasing in                                   H         L,    , and pH
together with the observation that T 0 (p) < 1 at all maxima.
                                                                                                                                H (1    H)
   As concerns point (5), consider the e¤ect of an increase in                         H    on   (pH
                                                                                                        H L
                                                                                                                2   =                            2
                                                                                                       H +pL L )         (pH   H +pL (1      H ))
the derivative is                                       2
                              1 2 H             ( H     H )(pH                           pL )
                                              2
                          (pH H + pL L )2         (pH H + pL                           L)
                                                                                         3

This has the same sign as

                                                              2
(1     2   H)       (pH     H   + pL   L)       2(   H        H )(pH      pL )
                                                                                                                  2              2
                = pH      H   + pL     L    2   H pH     H      2    H pL L      2   H pH   +2     H pL       2   H pL   +2      H pH

                =    L pL        H pH


          (1 H )
So (pH H+p  L (1
                      2 is increasing in H when H pH < L pL and decreasing otherwise. It
        H        H ))
follows that T (p) is increasing in H when H pH < L pL and decreasing otherwise, which
implies (5).


Proposition 3 The following hold


     1. An equilibrium exists.

     2. The consumption function cw (A; y) and the value function V w (A; y) for the wishful
        thinkers are increasing in both their arguments.

     3. Whenever A0 > , the Euler equation for the wishful thinkers is

                                                                expf V w (A0 ; y 0 )g
                    u0 (cw (A; y)) = RE(A;y)                                                u0 (cw (A0 ; y 0 )) :
                                                             E(A;y) [expf V w (A0 ; y 0 )g]

        where Ey is the objective expectation conditional on y and V w is the value of an optimal
        policy.

     4. Given y, ho (A; y) …rst order stochastically dominates hw (A; y).

     5. R is decreasing in .


                                                                42
    Proof: We begin with the individual’s problem and then prove existence of an equilib-
rium. Suppose that there an upper bound A such that Ait A. We will establish that such
an A exists. Let = [ ; A]. Since is above the natural borrowing constraint by assump-
tion, an individual with assets and the lowest income realization can always consume. This
ensures that the utility function is bounded on .

   Because income is i.i.d. the agent’s current state is simply a = RA + y. The Bellman
equation for the objective individuals is

                           V o (a) = max
                                      0
                                         u(a    A0 ) + Ey V o (RA0 + y 0 )
                                     A>


Consider the mapping T V o (a) = maxA0 > u(a A0 ) + Ey fV o (RA0 + y 0 )g. Given R < 1= ,
u0 > 0, u00 < 0, standard dynamic programming arguments (Stokey and Lucas, 1979) insure
that T has a unique …xed point and that this is the optimal policy of the objective individual.
Given the strict concavity of utility, the Theorem of the Maximum the maximum implies
Ao0 (ajR) is continuous in R. Standard dynamic programming arguments also imply that
V o (a) is increasing and di¤erentiable in a.20

    These results also apply to the wishful thinkers. The Bellman equation for the wishful
thinkers is
                     V w (a) = max
                                0
                                   u(a A0 ) + ln E expfV w (RA0 + y 0 )g
                                A>

Consider the mapping T V w (a) = maxA0 > u(a          A0 ) + ln E expfV w (RA0 + y 0 )g. Note that

max
 0
    u(a A0 )+ ln E expfV w (RA0 +y 0 )+ag = max
                                             0
                                                u(a A0 )+ (E expfV w (RA0 +y 0 )g)+ a
A2                                                    A2


so that Blackwell’s conditions hold (monotonicity is obvious), and T is a contraction mapping.
Again standard dynamic programming arguments insure that a solution exists V w (A; y),
that V w (a) is increasing and di¤erentiable in a and that Aw0 (ajR) is continuous in R. This
establishes point (2).

       The Euler equation for the objective agents is standard

                                       u0 (ct ) = REu0 (ct+1 )
  20
    T o maps the set of bounded weakly increasing functions into the set of bounded weakly increasing
functions. The Benviniste-Schenkman theorem establishes di¤erentiability.




                                                 43
The Euler equation for the wishful thinkers is less standard. The …rst order condition for A0
is
                                                          d
                                      E expfV w (at+1 )g da V w (at+1 )
                         u0 (ct ) = R
                                           E expfV w (at+1 )g
The derivative of the value function with respect to A is

                                          d w
                                            V (at ) = u0 (ct )
                                         da

Together these imply.
                                              E expfV w (at+1 )gu0 (ct+1 )
                               u0 (ct ) = R
                                                 E expfV w (at+1 )g
This establishes point (3).

   We now establish that Aw0 (ajR) Ao0 (ajR). Consider the mappings T o and T w . Suppose
      d              d               d              d
that da V w (at+1 ) da
                       V o (at+1 ). da T V w (at ) da
                                                      T V o (at ). Consider the Euler Equation of
the wishful thinker
                                                                d
                          d                 E expfV w (at+1 )g da V w (at+1 )
                            T V w (at ) = R
                         da                      E expfV w (at+1 )g

We can expand the right-hand side
                       d                                            d                                 d
   E expfV w (at+1 )g da V w (at+1 )         Eyt expfV w (at+1 )gE da V w (at+1 ) + cov V w (at+1 ); da V w (at+1 )
 R                                   =     R
        E expfV w (at+1 )g                                            E expfV w (at+1 )g
                                                                                                  !
                                                                         w          d   w
                                                  d              cov   V   (a    );
                                                                             t+1 da   V   (at+1 )
                                     =     R E V w (at+1 ) +                      w
                                                 da                    E expfV (at+1 )g

Since V w (a) and c are both increasing in y and the exponential is positive, the second
covariance term is non-positive. It follows that

               d                        d w                       d o
                 T V w (at )    REyt      V (at+1 )       REyt      V (at+1 ) = T V o (at )
              da                       da                        da
                                                             d          d
It then follows from Corollary 3.1 in Stokey and Lucas that da V w (a) da V o (a) and it follows
from the Euler equation that Aw0 (ajR) Ao0 (ajR). This establishes point (4).

   We now turn to the question of existence. Given R < 1= and DARA utility there exists
an upper bound on the assets of the objective agents (Schechtman and Escudero, 1977). Let
A denote the least upper bound. Given R, we then have a 2 X = [R + y1 ; RA + yS ]. We
consider the measurable space (X; S) where S is the Borel -algebra on X. Let P o (Aja)
and P w (Aja) denote the probability of transiting to the set A 2 S conditional on the state

                                                    44
a 2 X:
                                              X
                              P o (AjA) =            p(y 0 )IAo0 (a)+y0 2A :
                                            y 0 2Y

Stokey and Lucas (1999) Theorem 9.14 implies that P o has the Feller property. A similar
argument establishes that P w has the Feller property. Since Ao0 (ajR) and Aw0 (ajR) are
increasing in a, it follows that P w and P o are both monotone. Finally note that an agent
with A = who receives a su¢ ciently long string of the highest income realizations will
eventually accumulate enough wealth to place themselves in the neighborhood of A, and that
an agent with A = A who receives a su¢ ciently long strong of the lowest income realizations
will eventually accumulate enough wealth to place themselves in the neighborhood of .
Assumption 12.1 of Stokey and Lucas is therefore satis…ed. Stokey and Lucas’ Theorem
12.12 then establishes the existence of a unique invariant distributions ho (ajR) and hw (ajR).

   Let A!0 (ajR) and Ao0 (ajR) denote the optimal saving policies of the wishful thinkers and
the objective agents respectively. De…ne
                                          Z
                                 w
                               A (R) =        A!0 (ajR)hw (dajR)

and                                       Z
                                  o
                                A (R) =       Ao0 (ajR)ho (dajR)

Consider R ! R, Lucas and Stokey Theorem 12.13 states that hw (ajR) converges weakly to
hw (ajR) and ho (AjR) converges weakly to ho (AjR). As A!0 (ajR) and Ao0 (ajR) are continuous,
Aw (R) ! Aw (R) and Ao (R) ! Ao (R) establishing the continuity of Ao (R) and Aw (R)

   Now if R = 0, then Aw (R) = Ao (R) =          < 0, so that Aw (R) + Ao (R) < 0. And
as R ! 1= , Ao (R) ! 1 (Chamberlain and Wilson, 2000) Since Aw (R)               , we have
Aw (R) + Ao (R) > 0 for R su¢ ciently close to 1= : Since Aw (R) and Ao (R) are continuous,
there exists R such that
                                   Aw (R) + Ao (R) = 0:

This establishes point (1).

   Consider R as a function of , the fraction of objective agents. An increase in , given
R, drives up consumption and down the interest rate. This establishes point (5).




                                                 45
                      1                    1/2

    act              free/act


                                                       2
A    delay       B        busy/delay   C         act


          Figure 2: An Example of Procrastination
               R
                                             𝐴𝐴𝑤𝑤 (𝑅𝑅)
1/β                                                                  𝐴𝐴𝑜𝑜 (𝑅𝑅)


              𝑅𝑅∗              𝜂𝜂𝐴𝐴𝑜𝑜 𝑅𝑅∗ + 1 − 𝜂𝜂 𝐴𝐴𝑤𝑤 𝑅𝑅∗ = 0




      φ        0




          Figure 3: Equilibrium determination in the Huggett model
