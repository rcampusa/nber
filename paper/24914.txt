                             NBER WORKING PAPER SERIES




                                   QUADRATIC GAMES

                                      Nicolas S. Lambert
                                       Giorgio Martini
                                      Michael Ostrovsky

                                     Working Paper 24914
                             http://www.nber.org/papers/w24914


                    NATIONAL BUREAU OF ECONOMIC RESEARCH
                             1050 Massachusetts Avenue
                               Cambridge, MA 02138
                                   August 2018




We thank Kostas Bimpikis, Ben Golub, Tibor Heumann, Johannes Hörner, Matt Jackson, David
Myatt, Alessandro Pavan, Andy Skrzypacz, Xavier Vives, Bob Wilson, Anthony Lee Zhang, and
seminar and conference participants at Stanford, UIUC, the 22nd Coalition Theory Network
Workshop, the 2017 Workshop on Markets with Information Asymmetries at Collegio Carlo
Alberto, the 2018 ASSA Annual Meeting, and the 2018 North American Summer Meeting of the
Econometric Society for helpful comments and suggestions. Lambert is grateful to Microsoft
Research New York and the Cowles Foundation at Yale University for their hospitality and
financial support. The views expressed herein are those of the authors and do not necessarily
reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2018 by Nicolas S. Lambert, Giorgio Martini, and Michael Ostrovsky. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.
Quadratic Games
Nicolas S. Lambert, Giorgio Martini, and Michael Ostrovsky
NBER Working Paper No. 24914
August 2018
JEL No. C62,C72,D43,L13

                                           ABSTRACT

We study general quadratic games with multidimensional actions, stochastic payoff interactions,
and rich information structures. We first consider games with arbitrary finite information
structures. In such games, we show that there generically exists a unique equilibrium. We then
extend the result to games with infinite information structures, under an additional assumption of
linearity of certain conditional expectations. In that case, there generically exists a unique linear
equilibrium. In both cases, the equilibria can be explicitly characterized in compact closed form.
We illustrate our results by studying information aggregation in large asymmetric Cournot
markets and the effects of stochastic payoff interactions in beauty contests. Our results apply to
general games with linear best responses, and also allow us to characterize the effects of small
perturbations in arbitrary Bayesian games with finite information structures and smooth payoffs.


Nicolas S. Lambert                                Michael Ostrovsky
Graduate School of Business                       Graduate School of Business
Stanford University                               Stanford University
655 Knight Way                                    655 Knight Way
Stanford, CA 94305                                Stanford, CA 94305
USA                                               and NBER
nlambert@stanford.edu                             ostrovsky@stanford.edu

Giorgio Martini
Graduate School of Business
Stanford University
655 Knight Way
Stanford, CA 94305
USA
gmartini@stanford.edu
1    Introduction
Games of incomplete information with quadratic payoff structures and linear best responses play
an important role in the analysis of a diverse variety of questions in economics, such as the value
of macroeconomic information (Morris and Shin, 2002; Angeletos and Pavan, 2007), the structure
of markets under Cournot and Bertrand competition (Vives, 1984; Gal-Or, 1986), the properties
of games on networks (De Martı́ and Zenou, 2015; Leister, 2016; Myatt and Wallace, 2017), team
production and coordination in organizations (Radner, 1962; Dessein and Santos, 2006), and the
behavior of leaders in political communication (Dewan and Myatt, 2008, 2012), among many others.
In this paper, we provide a convenient unified framework for the analysis of rich versions of such
games, allowing for a variety of features: multidimensional actions, stochastic payoff interactions,
and general information structures. Among many other possibilities, our framework accommodates
Cournot competition with asymmetric information about both the intercept and the slope of the
demand function, beauty contests in which the incentives to conform are heterogenous and stochastic,
and games on networks in which the knowledge of the network structure is partial and dispersed.
    We consider two types of information structures. In the first, any finite information structure is
allowed. In particular, the signals of different players may be arbitrarily correlated, may overlap,
may contain information about the signals of other players, and so on—we allow for the same level
of generality as the framework of Aumann (1976), subject only to the finiteness of the signal space.
We show that generically there exists a unique Bayesian Nash equilibrium, and give a closed-form
characterization of equilibrium strategies.
    We then consider information structures that combine finite and (potentially) infinite signals.
The joint distribution of the finite components of the signals is arbitrary, as in the previous case.
The infinite components have the restriction that certain conditional expectations must be linear.
This setup includes, as a special case, the Linear-Quadratic-Gaussian setup, where (infinite) signals
are distributed according to a multivariate normal distribution. By also allowing for arbitrary finite
signal components, we can capture various stochastic interactions and heterogeneous information
about the infinite signals (for example, about their correlations and observability across players). We
show that generically there exists a unique linear Bayesian Nash equilibrium, and give a closed-form
characterization of equilibrium strategies.
    To illustrate our framework and results, we present two sets of applications.
    First, we consider Cournot competition with quadratic production costs and linear demand
functions, both of which may be only partially known by firms. This model fits our framework with
finite signals, and as in that framework, we allow for arbitrary information structures about the
costs and about the demand function. In particular, we allow not just the intercept but also the
slope of the demand function to be only partially known to the firms. We use our general results
to show that in this setting, an equilibrium of any Cournot competition game always exists and is
unique, and characterize it in closed form. We then prove two results about decentralized efficiency
in large asymmetric markets. First, as the market grows large, equilibrium becomes ex-ante efficient.
Second, when costs are linear, equilibrium forces act as an “invisible statistician”: the equilibrium


                                                  2
quantity converges to the best linear estimate of the ex-post socially efficient quantity, given the
information available to the firms.
   Second, we analyze beauty contests in which players may target different state variables and are
allowed to have only incomplete information about the payoff structure of others. This generalization
makes it possible to consider rich versions of beauty contests and coordination games: e.g., one can
consider a coordination game on a network in which each player knows who her friends are, but has
only partial information about the rest of the network, the strengths of the connections there, etc.
In this framework, we show that there always exists a unique linear equilibrium, and characterize it
in closed form. We illustrate the framework with an example that shows some of the novel effects
that arise when the strengths of payoff interactions in a beauty contest are stochastic.
   We also present several additional findings. First, we discuss how our closed-form characterizations
(both for the finite and infinite information cases) further simplify if payoff interactions between
players’ actions are deterministic rather than stochastic (but there is still uncertainty about the
random variables that directly affect the players’ payoffs, as in, e.g., the conventional beauty contests
or in Cournot competition games in which the slope of the demand function is known). Second,
we discuss the applicability of our results to general games with linear best responses. Finally, we
show how our framework can be used to characterize the effects of small perturbations in arbitrary
Bayesian games with finite information structures and smooth payoffs. For the last application, it is
essential that the framework allows for stochastic payoff interaction terms; without this feature, such
characterization would not be possible.
   The paper is organized as follows. In Section 1.1, we briefly review the related literature
on incomplete-information games with quadratic payoff structures (the literatures on Cournot
competition and beauty contests are briefly reviewed in the corresponding sections). We present
the model for arbitrary finite information structures in Section 2, and prove the existence and
uniqueness of Bayesian Nash equilibrium. We apply this framework to the questions of equilibrium
characterization and information aggregation in Cournot markets in Section 3. In Section 4, we present
the richer model with both finite and potentially infinite signals. Applications to beauty contests are
presented in Section 5. In Section 6, we present the simplified closed-form characterization for the
case in which payoff interaction coefficients are deterministic. Finally, in Section 7, we discuss the
applications of our framework to general games with linear best responses and to the characterization
of the effects of small perturbations in general Bayesian games.

1.1   Related Literature
A large literature spanning multiple fields has investigated incomplete-information games with
quadratic payoff structures. In this section, we briefly review some key papers on the general
properties of such games, highlighting the relative contributions of our work. We review the
literatures more directly related to our applications to Cournot competition and to beauty contests
in Sections 3 and 5, respectively.
   The seminal paper of Radner (1962) formalizes team problems as multi-agent decision problems


                                                   3
in which agents share a common goal but information is decentralized, and shows that under the
quadratic payoff specification, the person-by-person optimal decision policies are linear in signals. Ui
(2009) uses Bayesian potential games in order to apply Radner’s methods to games in which the
common goal assumption does not hold. A limitation of this approach is that various symmetry
assumptions on the payoffs are required for the games to admit a potential function. In contrast, our
paper allows for general asymmetric payoff structures.
        Basar (1978a) allows for asymmetries in the payoff structure, as well as for multidimensional
actions and signals. He employs a contraction-mapping approach that gives sufficient conditions for
equilibrium uniqueness in general. However, this approach does not give necessary and sufficient
conditions under which the linear equilibrium exists and is unique. Furthermore, in contrast to Basar
(1978a), we provide closed-form solutions for the unique linear equilibrium, and allow for stochastic
payoff interaction terms. Basar (1978b) studies 2-player quadratic games in which payoff interaction
terms are allowed to be stochastic. Like Basar (1978a), Basar (1978b) only gives sufficient conditions
for equilibrium existence, and does not provide closed-form solutions.
        A recent paper that also studies general quadratic games with rich asymmetric information
structures is Bergemann, Heumann, and Morris (2017). The focus of that paper, however, is different
from ours. Bergemann, Heumann, and Morris (2017) focus on games with single-dimensional
actions, fixed payoff interaction terms, and Gaussian information structures, and explore such topics
as identification in games, the range of outcomes across information structures, and connections
to Bayes Correlated Equilibrium (Bergemann and Morris, 2013, 2016). By contrast, we provide
existence, uniqueness, and closed-form characterization results for games with multidimensional
actions, stochastic payoff interaction terms, and general information structures with linear conditional
expectations. This level of generality allows us to explore such applications as Cournot competition
games with uncertain slope of demand, beauty contests in which the weights that players put on
matching others’ actions are stochastic, and the characterization of the effects of small perturbations
in arbitrary Bayesian games with finite information structures and smooth payoffs.


2        Games with Finite Information Structures
In this section, we state and prove our first main result: generic equilibrium existence and uniqueness
for quadratic games with arbitrary finite information structures. We impose no restrictions on the
information structure (beyond finiteness), which enables us to represent arbitrary informational
asymmetries and interdependencies.1 In Section 4, we present parallel results for games with
potentially infinite state and signal spaces, under some additional assumptions.
    1
    Our informational framework is equivalent to the canonical “partitional” information structure of Aumann (1976)
with a finite underlying state space, although its mathematical description is slightly different.




                                                        4
2.1       Model
There are n players, i = 1, . . . , n. Prior to taking an action, each player i privately observes a
signal si whose set Si of possible realizations is finite and contains ki ≥ 1 elements. We denote
by s = (s1 ; s2 ; . . . ; sn ) the random vector summarizing the signals of all n players. Players share a
common prior belief P about the joint probability distribution over signal vectors s. Without loss
of generality, we assume that for every player i and realization sei ∈ Si , the probability of player i
observing signal sei ∈ Si is positive. We do not impose any other restrictions on distribution P.
As in Aumann (1976), this lack of restrictions is the key feature that allows our framework to
accommodate arbitrary information asymmetries and interdependencies, by appropriately choosing
the joint distribution P over signal vectors s.

2.2       Actions and Payoffs
After observing his signal si , each player i chooses action ai ∈ Rmi , where mi ≥ 1 is the dimension of
player i’s action. The payoff πi of player i depends on his own action ai , the actions of other players
(denoted by vector a−i ), and the vector of signals s. Specifically,

                                      1
                   πi (ai , a−i , s) = aTi Γii (s)ai + aTi Γi,−i (s)a−i + aTi gi (s) + hi (a−i , s),       (1)
                                      2
                                                                                       P
where Γii (s) is a matrix of size mi × mi , Γi,−i (s) is a matrix of size mi × ( j6=i mj ), gi (s) is a vector
of size mi , and hi is an arbitrary function of a−i and s. Note that the presence of function hi does
not affect the incentives of player i (and thus the equilibria of the game), but does in general affect
the efficiency and welfare properties of various strategy profiles.
    The only assumption we impose on the parameters of payoff functions πi is that for each i
and each signal realization sei ∈ Si , the conditional expectation E[Γii (s)|si = sei ] is a symmetric
and negative definite matrix. The symmetry assumption is made for notational convenience and
is without loss of generality. The assumption that the matrix is negative definite is substantive: it
ensures that player i’s optimization problem is well-defined and has a finite solution. In the case of
single-dimensional actions, this assumption reduces to the conditional expectation of the quadratic
coefficient in equation (1) being negative.
    We impose no other assumptions on the parameters of payoff functions πi . In particular, the
dimensions of different players’ action spaces can be different; the interaction terms Γi,−i between
different players’ actions can be different and asymmetric, and can vary arbitrarily as functions of the
entire vector of signals s; and functions gi , which determine the direct payoff interactions between
the vector of signals s and the players’ actions, can be arbitrary as well.2,3
   2
     Because of this generality, the quadratic games we consider are in general not potential games. Applying Theorem
4.5 in Monderer and Shapley (1996), a quadratic game with one-dimensional actions is a potential game if and only if
 ∂ 2 πi     ∂2π
∂ai ∂aj
       = ∂ai ∂aj j . We do not impose any such symmetry restrictions between Γi,j and Γj,i .
    3
    Using standard techniques, any game of incomplete information with finite signals and multidimensional actions
can be expressed as a game of complete information with single-dimensional actions. However, in our setting, we find it
more convenient and transparent to work directly with incomplete information and multidimensional actions.



                                                          5
2.3     Bayesian Nash Equilibrium
A profile of pure strategies ai (·) of all players is a Bayesian Nash equilibrium if for every player i,
for every signal realization sei , action ai (e
                                              si ) maximizes player i’s expected payoff, conditional on the
realization of the signal, given the primitives of the game and the strategies of other players.4

2.4     Equilibrium Existence, Uniqueness, and Characterization
We can now state and prove the first main result of the paper.

Theorem 1 Generically, there exists a unique Bayesian Nash equilibrium.

    The remainder of this section presents the proof of Theorem 1 and the closed-form characterization
of the unique Bayesian Nash equilibrium. The proof consists of two parts. Lemma 1 provides
a condition that guarantees equilibrium existence and uniqueness. It also provides closed-form
expressions for the equilibrium strategies when the condition is satisfied. Lemma 2 shows that the
condition for existence and uniqueness required in Lemma 1 holds generically.
    To state Lemma 1, we need to introduce additional notation.
    Let Γij (s) be the matrix of size mi × mj corresponding to the terms multiplying actions aTi and
aj of players i and j in equation (1), for a particular vector of signals s.
    Let Φ be a block matrix defined as follows. Enumerate the ki possible signal realizations of player
i as 1, 2, . . . , ki , and let K = k1 + · · · + kn . Matrix Φ consists of K × K blocks: each block row
corresponds to one player i and one possible signal realization of that player, sei ,5 and analogously,
each block column corresponds to one player j and one possible signal realization of that player, sej .
The block of matrix Φ in block row (i, sei ) and block column (j, sej ) is given by

                           Φ(i,esi ),(j,esj ) = E[Γij (s)|si = sei , sj = sej ] · P[sj = sej |si = sei ].

Note that the size of block Φ(i,esi ),(j,esj ) is the same as the size of matrix Γij (s): mi × mj . Also, when
i = j, then Φ(i,esi ),(i,esi ) = E[Γii (s)|si = sei ], and when sei 6= sbi , then Φ(i,esi ),(i,bsi ) = 0.

Condition 1 Matrix Φ is invertible.

Lemma 1 The game has a unique Bayesian Nash equilibrium if and only if Condition 1 is satisfied.

    The proof of Lemma 1 is in Appendix A.1. In addition to showing the result, the proof also shows
that when Condition 1 is not satisfied, then either the game has no Bayesian Nash equilibrium, or it
has infinitely many. Also, the proof provides a convenient closed-form solution for the equilibrium
   4
     In general, Bayesian games may of course have mixed-strategy equilibria in addition to pure-strategy ones, but as
we will note in the proof of Theorem 1, in our setting best responses are always unique. Thus, there cannot be any
mixed-strategy equilibria, and so to simplify notation we only talk about pure strategy profiles and equilibria.
   5
     I.e., block row 1 corresponds to the first signal realization of player 1, block row 2 corresponds to the second
signal realization of player 1, . . . , block row k1 corresponds to the last signal realization of player 1, block row (k1 + 1)
corresponds to the first signal realization of player 2, and so on.



                                                                 6
when the condition is satisfied. Specifically, slightly abusing notation, let ai ∈ Rmi ki denote a
“stacked” vector of player i’s actions, one for each possible realization of signal si (i.e., the first mi
elements of vector ai are player i’s action after observing si = 1, the next mi elements of ai are the
action after observing si = 2, and so on). Let vector a = (a1 ; a2 ; . . . ; an ) denote the combined profile
of all players’ actions. Similarly, let gi ∈ Rmi ki denote a stacked vector of player i’s conditional
expectations of gi (s), one for each realization of signal si (i.e., the first mi elements of vector gi are
equal to E[gi (s)|si = 1], the next mi elements of gi are equal to E[gi (s)|si = 2], and so on). Let
g = (g1 ; g2 ; . . . ; gn ) denote the vector combining the vectors gi of all individual players i.
    When Condition 1 is satisfied, the unique Bayesian Nash Equilibrium is given by

                                                   a = −Φ−1 g.                                           (2)


    The second step of the proof of Theorem 1 shows that Condition 1 holds generically. Formally,
consider the following one-dimensional collection of quadratic games, parameterized by γ ∈ R. The
information structure is the same for all the games in the collection, and payoffs are given by

                                   1
                πi (ai , a−i , s) = aTi Γii (s)ai + aTi (γΓi,−i (s)) a−i + aTi gi (s) + hi (a−i , s).    (3)
                                   2

Lemma 2 Condition 1 holds for all γ ∈ R, except for at most finitely many values.

    The proof of Lemma 2 is in Appendix A.2. Together with Lemma 1, this concludes the proof of
Theorem 1.


3     Application: Cournot Competition
In this section, we apply the results of Section 2 to Cournot markets with incomplete information.
Our model uses the classical linear demand functions and linear-quadratic costs that are used in
Palfrey (1985) and Vives (1988), also in the context of incomplete information. While these two
papers use symmetric information structures in which firms receive i.i.d. signals (conditionally on
the state of the world), we leverage the framework of the previous section to derive implications for
the case of arbitrary finite information structures.
    Rich information structures in Cournot markets are also considered by Lambert, Ostrovsky, and
Panov (2018a), who study information aggregation properties of large asymmetric markets. They
assume that the firms’ information is jointly normally distributed, and show that as the market grows
large, information gets aggregated. As our results in Section 3.3 demonstrate, this result depends on
the property of jointly normal distributions that one random variable can be “decomposed” as a
linear combination of other jointly normal random variables and idiosyncratic noise. Without this
property, under general information structures, full information aggregation does not occur. Instead,
the decentralized market serves, in effect, as an “invisible statistician”, with equilibrium market
quantities and prices providing optimal linear estimators of social welfare-maximizing quantities and
prices.

                                                         7
       We are not the first to step away from the assumption of joint normality of signals and parameters
in Cournot competition with incomplete information. Li et al. (1987) point out that to obtain tractable
results in a Cournot setting, it is sufficient to consider distributions for which certain conditional
expectations are linear. They also note the advantages of certain non-Gaussian distributions, which
make it possible to circumvent the issues with negative quantities and prices that can arise under
the Gaussian specification (Hurkens, 2014). However, to the best of our knowledge, ours is the first
specification that allows tractable analysis of linear-demand settings in which firms are uncertain
not only about the intercept of the demand function, but also about its slope. Note also that
analogously to the current setting, the framework of Section 2 can also be used to study models
of differentiated Bertrand and differential Cournot competition with multi-product firms and rich
asymmetric information structures about various demand and cost parameters.

3.1       Model of Cournot Competition
There is a market with n firms, i = 1, . . . , n. The firms produce and sell a good to a population of
consumers. Each firm observes a finite signal si ∈ Si , using the notation of Section 2.1. In addition,
there is a state of the world ω that takes values in a finite set Ω. For each firm, the marginal
probability distribution over signals has full support. The joint distribution of signals and state of
the world is otherwise arbitrary.
       After each firm i has observed its signal si , it decides on a quantity qi ∈ R to produce; this is the
player’s action in our general framework. Each firm incurs cost of production ci (ω)qi + di (ω)qi2 , with
di (·) ≥ 0 and ci (·) ≥ 0. Consumer demand is linear, and inverse demand is

                                              P (Q, ω) = α(ω) − β(ω)Q,

where α(·) > 0 and β(·) > 0. For a given profile of quantities q1 , . . . , qn supplied by the firms, and a
given state of the world, the realized profit of firm i is

                                   πi = (α(ω) − β(ω)Q) qi − ci (ω)qi − di (ω)qi2
               P
where Q =        j qj   is the total quantity supplied by the firms. This model of Cournot competition is
therefore a special case of our framework of Section 2.6 We refer to the game just described as a
Cournot game.
       The following proposition shows that there always exists a unique equilibrium of the Cournot
game. Note that this statement is stronger than the statement of Theorem 1, because it does not
rely on genericity.
   6
      Strictly speaking, our Cournot competition model does not fit the framework of Section 2.1, as it involves a state
of the world that is not part of the finite signals of the firms. This issue, however, is purely notational. To make the
model fit the framework of Section 2.1, one can introduce an additional player, Nature, whose signal space is Ω and
whose payoff is given by, for example, πN = −a2N , so that it always plays aN = 0. Alternatively, without introducing an
artificial player, one can replace the payoff functions πi (ai , a−i , s, ω) with their expectations conditional on the vector
of firms’ signals s: πi (ai , a−i , s) = E[πi (ai , a−i , s, ω)|s]. Either approach brings the model into the formal framework
of Section 2.1.


                                                              8
Proposition 1 There exists a unique Bayesian Nash equilibrium of the Cournot game.

   The proof of Proposition 1 is in Appendix A.3. The idea of the proof is as follows. First, we
show that in the special case α(·) = ci (·) = 0 for every i, all firms producing zero (for all signal
realizations) is the unique Bayesian Nash equilibrium. Thus, by Lemma 1, Condition 1 is satisfied.
Second, we observe that in the general case, with no conditions on α(·) and ci (·), matrix Φ (defined
in Section 2.4), which determines existence and uniqueness of equilibrium via Condition 1, does not
depend on α(·) and ci (·). Hence, since Condition 1 is satisfied in the special case α(·) = ci (·) = 0 for
every i, it is also satisfied in the general case. We conclude by Lemma 1 that there exists a unique
Bayesian Nash equilibrium in the general case.

3.2    On the Efficiency of Large Markets
We now show that a property of invisible hand of competitive markets holds under incomplete
information for arbitrary finite information structures, extending the work of Vives (1988) to arbitrary
finite information structures. Our result also relates to Palfrey (1985), who gives conditions on the
information structures for the first-best market outcome to be achieved in large Cournot markets for
firms with constant marginal costs.
   To establish the results of this subsection, we consider a sequence of markets of the type just
described. The markets of the sequence are indexed k = 1, 2, . . . Each market k corresponds to a
market of Section 3.1 in which both the number of firms and consumer demand are scaled by a factor
k. Specifically, market k has N groups of firms, and each group includes k firms. There continues to
be a finite state of the world ω taking values in Ω. Every firm of group i observes the same finite
signal si ∈ Si , and incurs cost ci (ω)qi + di (ω)qi2 when producing qi units. Inverse demand in market
k is
                                                            Q
                                          P = α(ω) − β(ω)     .
                                                            k
By Proposition 1, there exists a unique Bayesian Nash equilibrium in every market k.
   In a Cournot environment with incomplete information, one must distinguish between two relevant
notion of efficiency, which we refer to as ex-ante versus ex-post efficiency. The notion of ex-post
efficiency assumes all uncertainty has resolved. Specifically, fixing a given state of the world ω, a
vector of production quantities is ex-post efficient when the total surplus is maximized among all
possible vectors of production quantities. Thus, ex-post efficiency corresponds to a social planner
who has full knowledge of the state of the world, and recommends to each firm an output level so
as to maximize total surplus. In contrast, ex-ante efficiency captures the idea that the state of the
world is not known by the firms at the time they must decide on production quantities. Furthermore,
information is decentralized: each firm’s decision can only depend on its own signal. Formally, we
say that a strategy profile is ex-ante efficient when the expected total surplus is maximized among
all firm strategy profiles. Hence, ex-ante efficiency corresponds to a social planner who can dictate
the strategies to be followed by each firm, but does not have any particular information on the state
of the world. When firms observe ω directly then both ex-ante and ex-post efficiency reduce to the


                                                    9
classical notion of efficiency under complete information. Our notion of ex-ante efficiency coincides
with the notion of second-best decentralized efficiency of Vives (1988), also for Cournot games, and
with the efficiency notion of Angeletos and Pavan (2007) for a broader class of quadratic games.
       We let TSak be the maximum expected total surplus that can be achieved in market k over all
possible strategy profiles. Either TSak is infinite for all k, or TSak is proportional to the number of
                                                                                                                            a
firms.7 We restrict attention to the interesting case of finite maximum total surplus, and we let TS
be the normalized maximum expected total surplus per firm that can be achieved in any market k.
Analogously, we let TS∗k be the expected total surplus of the unique equilibrium in market k, and
   ∗
TSk the expected total surplus per firm.
       Under incomplete information, it is well-known that it is generally not possible for the market
equilibrium to be ex-post efficient8 (see, for example, Proposition 1 of Vives (1988)). Ex-ante efficiency
is thus the natural benchmark for models of Cournot competition with incomplete information, as
a second-best welfare property. Our next result shows that as markets grow large and many firms
share the same information, the market equilibrium becomes ex-ante efficient.

Proposition 2 In the limit as the market size grows, the market equilibrium becomes ex-ante
                          ∗        a
efficient: limk→∞ TSk = TS .

The decentralized efficiency of large Cournot markets was observed by Vives (1988) in the case of i.i.d.
signals. Our result implies that this efficiency result does not rely on the symmetry of information.
       The proof of Proposition 2 is in Appendix A.4. It relies on the observation that the strategies
which obtain in the Bayesian Nash equilibrium correspond to the strategies that a planner would
want to enforce to maximize a biased expected total surplus, where the bias is additive and inversely
proportional to market size. As the market size grows, the objective of the planner becomes close to
the unbiased expected total surplus, and the equilibrium strategies yield a expected total surplus
that, in turn, becomes close to the surplus obtained under an ex-ante efficient strategy profile.

3.3      The Invisible Statistician
Because information is incomplete, in general as the market grows large the equilibrium market
quantity cannot converge to the ex-post efficient quantity. However, these two quantities are related
in a statistical sense. In this section, we show that the equilibrium market quantity converges to the
best linear estimate of the ex-post efficient quantity.
       Throughout this section, marginal costs are constant and identical across firms: di (·) = 0 and
ci (ω) = c(ω) for every i. Let Q denote the set of all real-valued mappings with vectors of firms’ signals
and states of the world as input. Elements of Q are market quantities determined by the realization
   7
      The possibility of unbounded total surplus is an artifact of the general quadratic framework from which our model
of Cournot competition derives, and which does not restrict firms to nonnegative output levels. Such situation may
occur when the costs are linear and the marginal costs vary across firms.
    8
      Palfrey (1985) shows that if marginal costs are constant and identical across firms, and if firms receive i.i.d. signals
on the state of the world that determines the firms’ costs and the intercept of the demand function, ex-post efficiency
is achieved in large markets under certain general conditions on the distributions of signals and states.



                                                             10
of the firms’ signals and the state of the world; they can be interpreted as random variables. For
the cost structures under consideration, both the ex-ante and ex-post efficient market quantities
exist in every market k. Let us denote them by Qak and Qpk , respectively. Note that Qak , Qpk ∈ Q. We
                                                                                                p
continue to make use of the bar notation to denote per-firm averages, that is, Q = Qpk /(N k) and
  a
Q = Qak /(N k). We omit subscript k because per-firm average efficient quantities do not depend on
the market k.
      To state our result, we introduce the collection C ⊂ Q of additively separable mappings:

                      C = {Q ∈ Q with Q(s1 , . . . , sn , ω) = q1 (s1 ) + · · · + qN (sN )} .

              a                                p
Note that Q ∈ C, but that in general, Q 6∈ C. In the following, elements of C can be interpreted as
                                     p
possible statistical estimates of Q . These estimates are additively separable in the signal values, and
so correspond to classical statistical linear estimates in which each firm signal is a dummy variable.
We refer to the elements of C as linear estimates.
      Consider the statistical question of finding a linear estimate Q that minimizes the β-weighted
quadratic error
                                                                  p
                                              E[β(ω)(Q − Q )2 ].
                                                                                           p
When such a linear estimate exists, we refer to it as best linear estimate of Q with respect to the
β-weighted squared error.
      The following proposition shows how this statistical question relates to Cournot markets. It
consists of two parts. The first part of the proposition shows that the ex-ante efficient production is
the unique best linear estimate of the ex-post efficient production for the β-weighted quadratic error.
The second part of the proposition shows that, in large markets, the equilibrium production per firm
approximates the best linear estimate of the ex-post efficient production level. In the following, Q∗k
                                                                      ∗
denotes the equilibrium quantity in market k, and let Qk denote the output per firm. Both are a
function of the firms’ signals.
                                                                              †   p
Proposition 3 There exists a unique best linear estimate Q of Q with respect to the β-weighted
squared error, and the following obtains:
         a        †
  1. Q = Q .
                                                              ∗           †
  2. For every realization of joint signals, limk→∞ Qk = Q .

As opposed to the previous result of Section 3.2 on the ex-ante efficiency of large markets, Proposition 3
does not apply when the costs are quadratic.
                                                                                      p
      One direct implication of the above result is that, if (and only if) Q ∈ C, then at the limit,
the large Cournot market becomes ex-post efficient. For the case of i.i.d. signals, and assuming
constant and identical marginal costs, Palfrey (1985) shows that under fairly general conditions on
distributions, ex-post efficiency of large market obtains. Our result suggests that, with asymmetric
information, ex-post efficiency requires stronger conditions: ex-post efficiency only obtains under
additive separability of the first-best output.

                                                        11
    The proof of Proposition 3 is in Appendix A.5. Uniqueness of the best linear estimate owes to the
convexity of the squared error, and to the convexity of the set of linear estimates. The key to the first
statement of the proposition is the observation that, when there are no quadratic costs, the problem
of minimizing the β-weighted error is identical to the problem of maximizing the expected surplus,
so that if the problems have a unique maximizer, the maximizers must be identical. The second
statement of the proposition uses an argument related to the proof of Proposition 2. The equilibrium
market quantity is the unique solution of an optimization problem that can be interpreted as the
minimization of the β-weighted squared error with a bias. The magnitude of the bias vanishes as the
market size grows, consequently the problem of finding the equilibrium market quantity becomes
very similar to the problem of finding the quantity that minimizes the β-weighted squared error, and
the two maximizers become arbitrarily close.


4     Games with Infinite Information Structures
In some applications, using infinite signal spaces may be more convenient than restricting attention to
finite signal spaces. For example, it is common to assume that signals of players are jointly normally
distributed. In this section, we consider a setting with potentially infinite signal spaces, with some
additional assumptions on the distribution of signals and the payoff structure. We restrict attention
to linear equilibria (in which the actions of players are linear functions of some of the signals). Our
second main result shows that generically, there exists a unique linear equilibrium. This equilibrium
can be characterized in closed form.

4.1    Model
There are n players, i = 1, . . . , n. Prior to taking an action, each player i privately observes a pair of
signals: si ∈ Si (where, as in Section 2, set Si is finite and contains ki elements) and θi ∈ R`i (where
`i ≥ 1 is the dimension of signal θi ). We denote by s = (s1 ; s2 ; . . . ; sn ) and θ = (θ1 ; θ2 ; . . . ; θn ) the
vectors summarizing the signals of all n players. For convenience, we refer to si ’s as “finite signals”
of the players and θi ’s as “infinite signals” (although the latter are not required to have an infinite
number of possible realizations).
    We make the following assumptions about the joint distribution of signals (s, θ). First, for every
player i and realization sei ∈ Si , the probability of player i observing sei is positive. As in Section 2,
this is without loss of generality. Also as in Section 2, we do not impose any other restrictions on
the joint distribution of finite signals s.
    Second, for every player i and realization sei ∈ Si , the conditional distribution of θi has finite first
and second moments, and matrix Var(θi |si = sei ) has full rank. The latter assumption is also without
loss of generality, as redundant signals can always be replaced with independent noise.
    Third, conditional on the finite signals of a subset of players, their infinite signals do not contain
any additional information about other players’ finite signals. Formally, take any subset T of players,
with |T | ≥ 1 and |T | < n. Take any profile of finite and infinite signal realizations (e
                                                                                         sT , θeT ) of players in


                                                        12
set T . Then the probability of any realization se−T of finite signals of players outside of T , conditional
on the entire profile of signals (e
                                  sT , θeT ), is equal to the probability of realization se−T conditional only
on the profile of finite signal realizations seT . One immediate case of distributions satisfying this
condition is vector θ being independent of vector s. However, more interesting dependencies are also
allowed. For example, n − 1 players may observe independent identically distributed signals θi , and
the n-th player may observe a subset of those signals, with his signal sn determining which subset
of the n − 1 independent signals he observes.9 Another example is two players observing signals θi
drawn from two potentially correlated distributions (with several possible correlation coefficients),
and also observing partially informative signals si about the correlation coefficient.
       Next, for convenience, we assume that for every player i, for every realization sei of his finite
signal, the expected value of his infinite signal is zero: E[θi |si = sei ] = 0. This is without loss of
generality. Note, however, that in conjunction with the previous assumption, this renormalization
implies a stronger property: for every subset T of players, with |T | ≥ 0 and |T | ≤ n, for any profile
of their finite signal realizations seT that has a positive probability, for any player i (who may or may
not be a part of T ), we have E[θi |sT = seT ] = 0.10
   Finally, we assume that for every player i and every player j 6= i, the conditional expectation
E[θj |si = sei , sj = sej , θi = θei ] is a linear function of θei . This is a substantive assumption, which we
discuss in more detail in Section 4.5. Note that while the expectation has to be a linear function
of θei , the coefficients in this linear function are allowed to depend on sei and sej (although of course
the case when they do not depend on one or both of these finite signals is also allowed). In particular,
these assumptions allow for the case of jointly normal signals θ whose covariance matrix may depend
on the profile of finite signals s.

4.2      Actions and Payoffs
After privately observing his signal, each player i chooses action ai ∈ Rmi , where mi ≥ 1 is the
dimension of player i’s action. Note that there is in general no relation between the size ki of player
i’s finite signal space Si , the dimension `i of his infinite signal θi , and the dimension mi of his
action ai . The payoff of player i depends on his own action ai , the actions of other players (denoted
by vector a−i ), and the entire vectors of signals s and θ (which include both the signals of player i
and the signals of other players):

                                    1
              πi (ai , a−i , s, θ) = aTi Γii (s)ai + aTi Γi,−i (s)a−i + aTi gi (s, θ) + hi (a−i , s, θ), (4)
                                    2
                                                                                            P
where Γii (s) is a matrix of size mi × mi , Γi,−i (s) is a matrix of size mi × ( j6=i mj ), gi (s, θ) is a
vector of size mi , and hi is an arbitrary function of a−i , s, and θ.11 As before, the presence of
   9
      Formally, for the first n − 1 players, |Si | = 1, and θi ∈ Rk . For the n-th player, Sn = {0, 1}n−1 and θn ∈ R(n−1)k .
When the j-th element of sn is equal to 1, components (k(j − 1) + 1, . . . , kj) of θn are equal to θj . When the j-th
element of sn is equal to 0, these components are random noise.
   10
      The proof of this statement is given in Appendix A.6.
   11
      The only assumption we need to impose on function hi is that the expected value of hi (a−i , s, θ) is finite for every
profile of linear strategies of players other than i, conditional on every possible realization (e
                                                                                                 si , θei ) of player i’s signals.


                                                               13
function hi does not affect the incentives of player i (and thus the equilibria of the game), but does
in general affect the efficiency and welfare properties of various strategy profiles.
    We assume that for each i and each signal realization sei ∈ Si , the conditional expectation
E[Γii (s)|si = sei ] is a symmetric negative definite matrix. In addition, we assume that for every
player i, the expectation E[gi (s, θ)|si = sei , θi = θei ] is a linear function of θei . Note that while the
expectation has to be a linear function of θei , the coefficients in this linear function are allowed to
depend on sei . We impose no other restrictions on payoff functions πi .

4.3    Linear Equilibrium
We say that a strategy of player i is linear if it can be represented as ai (si , θi ) = κi (si ) + Λi (si )θi ,
                                                                                   si ) is a matrix in Rmi ×`i .
                                                   si ) is a vector in Rmi and Λi (e
where for every realization sei of signal si , κi (e
Note, in particular, that the sensitivity of player i’s action to his infinite signal θi may depend on
the realization of his finite signal si .
    We say that a profile of strategies of all players is a linear equilibrium if (1) every strategy ai (·)
in the profile is linear, and (2) the profile of strategies is a Bayesian Nash equilibrium, i.e., for every
player i, for every realization (e
                                 si , θei ) of signals (si , θi ), action ai (e
                                                                              si , θei ) maximizes player i’s expected
payoff, given the primitives of the game and the strategies of other players.

4.4    Equilibrium Existence and Uniqueness
We can now state and prove the second main result of the paper.

Theorem 2 Generically, there exists a unique linear equilibrium.

    The remainder of this section presents the proof of Theorem 2 and the closed-form characterization
of the unique linear equilibrium. As in the proof of Theorem 1, the argument consists of two parts.
Lemma 3 provides conditions that guarantee the existence and uniqueness of linear equilibrium.
It also provides closed-form expressions for the equilibrium strategies when these conditions are
satisfied. Lemma 4 shows that the conditions for existence and uniqueness required in Lemma 3
hold generically.
    The first condition in Lemma 3 is the same as Condition 1 stated earlier (in Section 2). To
give the second condition, we need to introduce some additional notation. By assumption, the
expectation E[θj |si = sei , sj = sej , θi = θei ] is a linear function of θei . Denote this linear function by
E[θj |si = sei , sj = sej , θi = θei ] = QT (e
                                        ij   si , sej )θei .12
    Let Ψ be a block matrix defined as follows. As in Section 2, enumerate the ki possible signal
realizations sei of player i as 1, 2, . . . , ki , and let K = k1 + · · · + kn . Matrix Ψ consists of K × K
blocks: each block row corresponds to one player i and one possible signal realization of that player,
sei , and analogously, each block column corresponds to one player j and one possible signal realization
  12
     Note that this linear function does not have a constant term. As we show in Appendix A.6, this lack of the constant
term is implied by our normalization of the signal distributions.



                                                          14
of that player, sej . The block of matrix Ψ in block row (i, sei ) and block column (j, sej ) is given by
                                                                                       
                                           si , sej ) ⊗ E [Γij (s)|si = sei , sj = sej ] · P[sj = sej |si = sei ]
                 Ψ(i,esi ),(j,esj ) = Qij (e

where “⊗” denotes the Kronecker product of two matrices.13 When actions a or infinite signals θ of
all players are single-dimensional, the Kronecker product reduces to regular multiplication by a scalar.
When both actions a and infinite signals θ of all players are single-dimensional, the expressions
simplify further and each block Ψ(i,esi ),(j,esj ) is just a real number. In the general case, the size of
block Ψ(i,esi ),(j,esj ) is mi `i × mj `i .

Condition 2 Matrix Ψ is invertible.

Lemma 3 The game has a unique linear equilibrium if and only if Conditions 1 and 2 are satisfied.

       The proof of Lemma 3 is in Appendix A.7. In addition to showing the result, the proof also
shows that when Condition 1 or Condition 2 are not satisfied, then either the game has no linear
equilibrium, or it has infinitely many. Also, the proof provides a closed-form solution for the
equilibrium when both conditions are satisfied. Specifically, recall our representation of linear
strategies as ai (si , θi ) = κi (si ) + Λi (si )θi . Slightly abusing notation, let κi ∈ Rmi ki be the stacked
vector of player i’s constant terms κi (si ), one for each possible realization of signal si (i.e., the first
mi elements of κi are κi (1), the next mi elements are κi (2), and so on). Let vector κ = (κ1 ; . . . ; κn )
denote the combined profile of all players’ constant terms. Next, consider the vectorization vec Λi (e
                                                                                                     si ),
i.e., the column vector of size mi `i in which the columns of matrix Λi (e
                                                                         si ) are stacked on top of
each other.14 Let Λi ∈ Rmi `i ki be the stacked vector of these vectorizations vec Λi (e
                                                                                       si ), one for each
realization sei . Finally, let vector Λ = (Λ1 ; . . . ; Λn ) combine the vectors Λi of individual players.
    Next, by assumption, the expectation E[gi (s, θ)|si = sei , θi = θei ] is a linear function of θei . Denote
this function by E[gi (s, θ)|si = sei , θi = θei ] = Gi (e          si )θei . Let gi ∈ Rmi ki be the stacked vector
                                                         si ) + Fi (e
of individual vectors Gi (e
                          si ), one for each possible realization of si (i.e., gi = (Gi (1); . . . ; Gi (ki )),
and let g = (g1 ; . . . ; gn ) denote the vector combining these terms for all players. Finally, let
fi = (vec Fi (1); . . . ; vec Fi (ki )) ∈ Rmi `i ki , and let f = (f1 ; f2 ; . . . ; fn ).
       When Conditions 1 and 2 are satisfied, the unique linear equilibrium is given by

                                                         κ = −Φ−1 g                                                 (5)
                                                                    −1
                                                         Λ = −Ψ          f.                                         (6)


       The second step of the proof of Theorem 2 shows that Conditions 1 and 2 hold generically.
Formally, consider the following one-dimensional collection of quadratic games, parameterized by
  13
     If matrix A is of size k × m with elements aij and matrix B is another matrix, of any size, then A ⊗ B is defined
as a block matrix with k × m blocks, in which the size of each block is equal to the size of B and each block (i, j) is
equal to aij B. See http://en.wikipedia.org/wiki/Kronecker_product for details.
  14
     See https://en.wikipedia.org/wiki/Vectorization_(mathematics) for details.



                                                               15
γ ∈ R. The information structure is the same for all the games in the collection, and payoffs are
given by

                                   1
             πi (ai , a−i , s, θ) = aTi Γii (s)ai + aTi (γΓi,−i (s)) a−i + aTi gi (s, θ) + hi (a−i , s, θ)     (7)
                                   2

Lemma 4 Conditions 1 and 2 hold for all γ ∈ R, except for at most finitely many values.

    The proof of Lemma 4 is in Appendix A.8. Together with Lemma 3, this concludes the proof of
Theorem 2.

4.5    Linear Conditional Expectations
As mentioned in Section 4.1, the linearity of conditional expectations assumption (i.e., the assumption
                                           6 i, the conditional expectation E[θj |si = sei , sj = sej , θi = θei ]
that for every player i and every player j =
is a linear function of θei ) is substantive. However, there are many interesting and common examples
of joint distributions that satisfy this restriction.
    The most common example is the multivariate normal distribution. For example, if vector θ
is distributed normally, with any variance-covariance matrix, and is independent of vector s, then
 E[θj |si = sei , sj = sej , θi = θei ] is a linear function of θei , for any i and j. More complex examples “built
from” normal distributions are also possible. For example, finite signals s may determine correlations
between the infinite signals of different players.
    For a very different example of joint distributions satisfying the conditional linearity assumption,
suppose random variables α and β are independent (and other than that, come from arbitrary
                                                                                               6 i
distributions), and suppose player i observes both of them (i.e., θi = (α; β)), while player j =
observes only one (e.g., θj = (α)). Then both E[θj |θi ] and E[θi |θj ] are linear functions. More
generally, if there are several independent random variables, and each agent observes a subset of
them, the resulting information structure satisfies the linearity condition. For example, suppose
there are no finite signals s (formally, a fixed vector s is observed with probability 1), and consider a
network of agents in which the infinite signal (type) of each agent is a random variable drawn from
some distribution (possibly a different one for each agent). The types of agents are independent of
each other. Each agent observes their own type, and the types of their neighbors in the network.
Then, for all i and j, E[θj |θi = θei ] is a linear function of θei .
    For yet another example, suppose random variables α and β are independent and identically
distributed, and player i observes each of them separately, while player j only observes their sum.
Again, both E[θj |θi ] and E[θi |θj ] are linear functions. As before, we can use this observation to
explore richer models in which some players observe specific variables while others only observe their
aggregates (and in which who observes what may depend on finite signals s).
    Finally, note that if a player’s signal θi is binary, then for any joint distribution of θi and θj , the
expectation E[θj |θi ] is a linear function of θi . We return to this observation in Section 6.2, where it
serves as a basis for a connection between two seemingly distinct models.



                                                          16
         The list above is by no means exhaustive—there are many other types of joint distributions
of signals for which our assumption of linear conditional expectations is satisfied.15 So while the
assumption is certainly substantive, it nevertheless allows for a wide variety of interesting cases.


5         Application: Beauty Contests
In this section, we illustrate the framework and results of Section 4 with an application: beauty
contests with potentially uncertain relative weights that players put on coordinating with others.
In beauty contests (Morris and Shin, 2002), players receive signals about an uncertain variable,
and their optimal action is a weighted average of their estimate of the value of the variable and
their estimate of the average action of other players. The standard BC framework assumes that
all players are ex ante identical, and in particular, receive identically distributed signals and put
the same weights on matching the actions of all other players. In their analyses of beauty contests,
Bergemann et al. (2017) and Lambert et al. (2018b) allow for rich asymmetric information structures,
but maintain the assumption that each agent cares equally about matching all other agents’ actions
(i.e., each player tries to match a weighted average of the true state of the world and the average
action of other players).
         Golub and Morris (2017), Leister (2016), and Myatt and Wallace (2017) relax this assumption,
and allow players to put more weight on matching some agents’ actions and less (or none) on matching
other agents’ actions, examining the interplay between beauty contests and network settings. In
such environments, Golub and Morris (2017) consider common and heterogeneous priors, and focus
on the characterization of higher-order expectations and their limit as the weight of the coordination
component in payoff functions goes to 1. Leister (2016) and Myatt and Wallace (2017) explore
endogenous information acquisition.16
         The contribution of the current section of our paper is to not only allow players to put different
weights on matching different agents’ actions, but to also allow these weights to be stochastic, with
players potentially having rich information both about these weights and about the “states of the
world” (and about other players’ knowledge of those parameters). We also allow players to target
different state variables, allowing for many other interpretations of the framework (e.g., the framework
can be viewed as a model of a coordination game, in which each player has some (individual) “bliss”
action that he would pick in the absence of interactions with other players, but also puts some weight
on picking an action close to the actions of some other players), and to receive multidimensional
information (so that, for example, one dimension of the signal is informative about a player’s own
optimal bliss action and another dimension is informative about another player’s bliss action; or one
dimension is a player’s own signal, another dimension is a signal shared with some other players,
    15
    See, e.g., Li et al. (1987).
    16
    With the exception of Golub and Morris (2017), all papers on beauty contests mentioned above consider games
with jointly normal information structures. Golub and Morris (2017) consider beauty contests with finite information
structures, which (in the case of common priors) fit the model of Section 6.1 below. As we explain in Section 6.2, all
these models are special cases of a unified model of quadratic games with fixed interaction coefficients and information
structures that satisfy the “linear conditional expectations” property.



                                                          17
and the third, finite dimension, contains information about other players’ payoff functions).
    In Section 5.1, we describe our general model of beauty contests. In Section 5.2, we show that in
this model, there is always a unique linear equilibrium (unlike Theorem 2, this statement is always
true, not just generically). In Section 5.3, we consider a particular example of a beauty contest
with uncertain interactions and show that allowing for uncertain interaction terms in players’ payoff
functions leads to economically novel predictions.

5.1     Model of Beauty Contests
There are n players, i = 1, . . . , n. Each player observes a finite signal si ∈ Si and an infinite
signal θi ∈ R`i . Each player also has a bliss point b∗i ∈ R, which is a random variable. Denote by
b = (b∗1 ; . . . ; b∗n ) the random vector of bliss points. As in Section 4, we do not impose any restrictions
on the distribution of finite signals s, apart from assuming that for each player i and each signal
realization sei ∈ Si , the probability of player i observing sei is positive. For the profile of infinite
signals θ and the vector of bliss points b, we assume that they are jointly normally distributed, with
the mean of θ being equal to zero, the mean of b being equal to b, and the variance-covariance matrix
of (θ; b) being arbitrary, subject only to the constraint that for each i, matrix Var(θi ) has full rank
(as before, this assumption is without loss of generality). Note that different bliss points b∗i can be
assumed to be identical, but are not required to. We assume that s is independent of θ and b.17
    Each player’s action is a real number: ai ∈ R. The payoff of each player is a function of his bliss
point, his action, the actions of other players, and the profile of finite signals s, and is equal to
                                                                              X
                           πi (ai , a−i , b∗i , s) = −γii (s)(ai − b∗i )2 −          γij (s)(ai − aj )2 ,                   (8)
                                                                              j6=i


where for every s, γii (s) > 0 and for each j 6= i, γij (s) ≥ 0.18 In the classical models of beauty
contests, players have an incentive to choose an action that is close to a common random bliss point,
and at the same time that is close to the average action of the other players. The weights that
players put on each component can vary across players, but are fixed and commonly known. Our
model of beauty contests allows for more flexibility along three dimensions. First, different players
may have different bliss points. Second, a player may put different weights on matching the actions
of different other players. Finally, the weights that players put on matching the bliss points and
on matching various other players’ actions may be stochastic, with complex information structures
about these weights. E.g., on a network, a player may know the preferences of her neighbors, but
only have probabilistic information about the preferences of agents who are further away. Similarly,
   17
      The results of this section can be extended to more general cases in which the distribution of θ is not necessarily
normal, and in which s and θ are not independent, while still remaining within the framework of Section 4. We restrict
attention to the current set of assumptions for expositional convenience.
   18
      As in the Cournot competition model of Section 3, our beauty contests model does not formally fit the framework
of Section 4, because the bliss points are not directly parts of either finite signals s or infinite signals θ. Similarly to the
Cournot competition model, to fit formally the framework of Section 4.1, one can introduce a dummy player Nature
whose finite signal space consists of only one element and whose infinite signal is equal to vector b and whose payoff πN
is given by πN = −a2N , so that it always plays aN = 0.



                                                              18
a player may know who her neighbors are, but only have incomplete information about the overall
network structure.

5.2    Equilibrium Existence and Uniqueness
A linear equilibrium in our model is defined as in Section 4.3. The following proposition shows that
there always exists a unique equilibrium. Note that this statement is stronger than the corresponding
statement in Theorem 2, since it does not rely on genericity.

Proposition 4 There exists a unique linear equilibrium of the beauty contest.

The proof of Proposition 4 is in Appendix A.9. The idea of the proof is to first observe that in a
given game, Conditions 1 and 2 of Lemma 3 are satisfied if and only if they are satisfied in a modified
game where all the b∗i are replaced by zeros. The next step of the proof is to show that the modified
game has a unique equilibrium (the one in which all players always play zero). This implies that
Conditions 1 and 2 are satisfied for the modified game—which in turn implies that they are satisfied
for the original game, and thus the original game has a unique linear equilibrium.

5.3    Example of a Beauty Contest with Stochastic Payoff Interactions
To illustrate the framework, we present a simple example in which players are uncertain about the
relative weights other players put on the bliss point vs. matching the actions of other players. We
find that the impact of this uncertainty on the equilibrium of the game is subtle, and is substantively
different from an equilibrium that would arise if these uncertain terms were simply replaced by
their expected values. Our framework also allows us to provide predictions on the signs of various
comparative static effects as this uncertainty increases.

Example 1 There are n ≥ 2 players who receive signals θi = θ + i , where θ ∼ N (0, σ 2 ) is the
                                                                                                               σ2
players’ common “bliss point” and errors i ∼ N (0, σ2 ) are iid. We denote by ρ =                         σ 2 +σ2
                                                                                                                       the
informativeness of signal θi about the state variable θ. Each player i also observes his “payoff type”
si ∈ {H, L}, with prior P(si = H) = P(si = L) = 1/2. Payoff types are correlated across players:
P[sj = x|si = x] = q ≥ 12 , for x ∈ {H, L}, for all j 6= i. At the same time, the profile of players’
payoff types s is independent of state θ and signals θi .
    After observing his signal θi and payoff type si , each player i chooses action ai ∈ R to minimize
a combination of two quadratic loss terms: one from the distance to the bliss point θ and one from
the distance to the average action of other players, a−i . The relative weights player i puts on each of
the two terms are determined by his payoff type: when player i has type si = H, the weight he places
on the coordination component of his payoff is αi = αH , and when his type is si = L, the weight
is αL . We assume that 0 ≤ αL ≤ αH < 1.19
  19
     The case αH = 1 would violate the assumption in the model of Section 5.1 that γii (s) is always positive, and so we
rule it out. Note, however, that the existence and uniqueness result and the explicit formulas below would continue to
hold even in the case αH = 1, as long as q < 1 and αL < 1, allowing for the possibility that some agents care only
about matching the average action of other players and put zero weight on matching the fundamental value θ.


                                                          19
       Formally, player i’s payoff depends on his action ai , the average action of other players a−i , his
payoff type αi , and the state θ:

                           πi (ai , a−i , αi , θ) = −(1 − αi )(ai − θ)2 − αi (ai − a−i )2 .                        (9)

       By Proposition 4, there exists a unique linear equilibrium of this game. In this equilibrium, the
sensitivity of the player’s action to his signal θi depends on his payoff type si . Since the game is
symmetric and the linear equilibrium is unique, the equilibrium is also symmetric. Equilibrium
strategies are described by two numbers: the sensitivity βH when payoff type is H, and the sensitivity
βL when payoff type is L (the constant term is 0 for both payoff types). I.e., when a player of type
H observes signal θi , his action is ai = βH θi , and when a player of type L observes signal θi , his
action is ai = βL θi . Using our closed-form characterization, we find

                                    (1 − αH )(1 − αL qρ) + αH (1 − αL )(1 − q)ρ
                             βH = ρ                                             ,
                                     (1 − αH qρ)(1 − αL qρ) − αH αL (1 − q)2 ρ2
                                    (1 − αL )(1 − αH qρ) + αL (1 − αH )(1 − q)ρ
                             βL = ρ                                             .
                                     (1 − αH qρ)(1 − αL qρ) − αH αL (1 − q)2 ρ2

       For the discussion of the properties of the equilibrium, it is convenient to introduce two new
                       αH +αL              αH −αL
variables. Let α =        2     and ∆ =       2   ,   so that α represents the average weight that each player
puts on the square of the difference between his action and the average action of other players (recall
that types H and L are equally likely) and ∆ represents the absolute amount by which the actual
weights αH and αL differ from that average. Note first that our model naturally nests the standard
beauty contest case without stochastic interactions: if αH = αL = α, the equilibrium reduces to
             1−α
βH = βL = ρ 1−ρα , and if q = 1, the game “decomposes” into either all players being of type H (and
knowing that) or all players being of type L, with the corresponding equilibrium strategies reducing
           1−αH             1−αL 20
to βH = ρ 1−ραH
                and βL = ρ 1−ραL
                                 .
       Another corner case is when the type of player i is not informative about the types of other
players, i.e., q = 12 . In that case, we get βH = ρ 1−α−(1−ρ)∆
                                                       1−ρα    and βL = ρ 1−α+(1−ρ)∆
                                                                             1−ρα    , and the average
                                           βH +βL                    1−α
sensitivity of a player to his signal,        2   ,   is equal to ρ 1−ρα . That is, the average sensitivity of a
player to his signal is the same as in the standard beauty contest with constant interaction term α,
and each individual player behaves as if he is simply best responding to a population of such “average”
players.
       Away from these corner cases, the relationship between the parameters of the game and the
equilibrium strategy profiles becomes more subtle. To illustrate this relationship, we look at
comparative statics of the equilibrium, holding fixed the average weight α and varying the difference
between the weights in the two states (2∆) as well as the informativeness of a player’s state about
  20
    Note that the number of players n has no impact on the equilibrium behavior of a given player in the game, as long
as n ≥ 2. In particular, we could consider a version of the beauty contest with a continuum of players, as is common in
the literature. All of the formulas and results would remain the same. More generally, we could consider a model of
Section 5.1 with continuous masses of players of different types (or even with continuous masses of “small” players of
some types and discrete “large” players of other types). Aside from minor notational adjustments, none of our results
would change.


                                                          20
the states of other players (q). Proposition 5 summarizes our results.

Proposition 5 The following comparative statics hold:
                                   βH +βL
    1. The average sensitivity        2     decreases in ∆ and decreases in q.

    2. The sensitivity βH decreases in ∆ and decreases in q.

    3. The sensitivity βL increases in q, but is not monotone in ∆.

    The proof is in Appendix A.10. Intuition for the non-monotonicity in part 3 is as follows: as
∆ increases, the weight αL (that a player of type L puts on matching the actions of other players)
decreases, which in the absence of other effects would lead such a player to increase the weight he
puts on his own signal. However, the weight that players of type H put on their signals decreases,
which in equilibrium also gives an incentive to players of type L to decrease the sensitivity of their
action to their signals. For some parameter values, the latter effect outweighs the former.


6     Models with Constant Interaction Terms
The models of Sections 2 and 4 allow the interaction terms Γij to vary stochastically as a function of
the profile of players’ finite signals s. While the results of those sections provide tractable closed-form
solutions for those general models, the solutions are further simplified in applications in which
interaction terms Γij are constant. In this section, we present these simplified solutions in two special
cases. First, we consider the case of constant interaction terms and finite signals. Second, we consider
the case of constant interaction terms and potentially infinite signals.

6.1    Constant Interaction Terms and Finite Signals
Consider the setting of Section 2, and suppose that for all i and j, interaction terms Γii (s) and Γij (s)
do not depend on the profile of signals s, and are simply always equal to some matrices Γii and Γij
(where each matrix Γii is negative definite). The payoff term gi (s) is still allowed to depend on signal
s in an arbitrary way.
    Blocks of matrix Φ then simplify to Φ(i,esi ),(j,esj ) = Γij · P[sj = sej |si = sei ]. Furthermore, for every
pair of players i and j, all blocks Φ(i,esi ),(j,esj ) (across all possible realizations of signals sei and sej ) can
be joined together, and expressed more compactly as

                                                Φij = Γij ⊗ Mij ,

where ⊗ denotes the Kronecker product and Mij is a matrix of size ki × kj given by
                                                                                  
                                   P [sj = 1|esi = 1] · · · P [sj = kj |e si = 1]
                                          ..           ..             ..          
                           Mij = 
                                           .               .           .          .
                                                                                   
                                   P [sj = 1|esi = ki ] · · · P [sj = kj |e
                                                                          si = ki ]

                                                         21
   Lemma 1, of course, continues to hold: there is a unique Bayesian Nash equilibrium if and only if
matrix Φ is invertible, and when it is, equilibrium strategies are given by a = −Φ−1 g. Lemma 2 also
applies directly, showing that in the model with fixed interaction terms, generically, there exists a
unique Bayesian Nash equilibrium.

6.2   Constant Interaction Terms and Potentially Infinite Signals
The second case we consider is the setting of Section 4, in which we assume that the players only
receive potentially infinite signals θi , and do not receive any finite signals si (a formal way to
incorporate this into the setting of Section 4 is to simply assume that for each i, set Si contains only
one element, which player i observes with probability 1 and which therefore contains no information).
This assumption leads to several simplifications. First, as in Section 6.1, interaction terms are
constant, given by matrices Γii and Γij . Second, the joint distribution of signals θi has to satisfy
only the following restrictions: (i) for each i, matrix Var(θi ) has full rank; (ii) for each i, E[θi ] = 0;
and (iii) for each i and j 6= i, the conditional expectation E[θj |θi = θei ] is a linear function of θei .
Finally, the payoff terms gi (θ) also have to satisfy a linearity property: E[gi (θ)|θi = θei ] is a linear
function of θei . Note that only the last two assumptions, on the linearity of conditional expectations,
are substantive; assumptions (i) and (ii) are made only for convenience, without loss of generality.
   In this setting, the expression for the blocks of matrix Φ simplify even further, and we can drop
the realizations of finite signals si from the subindices:

                                                Φij = Γij .

Thus, matrix Φ is simply equal to the matrix Γ that summarizes the interaction terms in players’
payoff functions.
   The expression for the blocks of matrix Ψ is also substantially simplified, and also no longer
requires the realizations of finite signals si in the subindices:

                                             Ψij = Qij ⊗ Γij .

   Of course, Lemma 3 continues to hold, and the game has a unique linear equilibrium if and only
if matrices Φ and Ψ are invertible. When the matrices are invertible, the equilibrium strategies
continue to be given by κ = −Φ−1 g and Λ = −Ψ−1 f . And as before, Lemma 4 applies directly,
showing that in this model, generically, there exists a unique linear equilibrium.
   The models of Sections 6.1 and 6.2 are seemingly quite different: the former allows arbitrary
finite signals without imposing any restrictions on their joint distribution or on functions gi (s), while
the latter allows infinite signals but imposes the restrictions of linearity on conditional expectations
E[θj |θi = θei ] and E[gi (θ)|θi = θei ]. The two models, however, are closely related: the model of
Section 6.1 is a special case of the model of Section 6.2. To see that, recall the observation made
in Section 4.5 that if a player’s signal θi is binary, then for any joint distribution of θi and θj , the
expectation E[θj |θi = θei ] is a linear function of θi . Similarly, if player i’s signal takes ki possible


                                                    22
values (as in Section 6.1), we can “project” it onto a ki -dimensional space Rki , as follows: when
the original signal realization is 1, the projection takes the value (1, 0, . . . , 0); when the original
signal realization is 2, the projection takes the value (0, 1, 0, . . . , 0); and so on—when the original
signal realization is ki , the projection takes the value (0, . . . , 0, 1). With this representation, any
function of the projected signal is linear. Thus, if we represent the signals of all players in this
fashion, all conditional expectations E[θj |θi = θei ] and E[gi (θ)|θi = θei ] become linear, and thus the
model of Section 6.1 can be represented as a special case of the model of Section 6.2. (Formally, this
representation violates both assumptions (i) and (ii) of the model of Section 6.2. However, as we
noted, these assumptions are without loss of generality, and it is straightforward to further adjust
the representation so that it fully fits the model.)
    Thus, the model of Section 6.2 can be viewed as a unifying framework for a “linear conditional
expectations” family of quadratic games with fixed interaction coefficients, including those with
finite information structures, Gaussian information structures, and so on.


7     Beyond Quadratic Games
We end with a brief discussion on applying the main framework beyond quadratic payoff functions.
In Section 7.1, we discuss how our results can be applied to other, not necessarily quadratic, games
and economies with linear best responses. In Section 7.2, we provide an informal discussion on how
our framework and results can be used to characterize changes in equilibrium behavior after small
perturbations in general games with smooth payoffs.

7.1    Games with Linear Best Responses
In some applications, it is useful to abstract away from the game itself, and instead write down
directly the best responses of each player as a function of the strategies of other players. These
best responses continue to characterize the behavior of the agents in an economic system, without
the need to specify agents’ payoffs. When the best response functions are a linear function of the
strategies of other players, the “game” is one of linear best responses. Linear best response games
can be interpreted as an alternative formulation to quadratic games. Which formulation to use is a
matter of preference, and our results apply to both formulations.
    To illustrate, consider the game described in Section 2.1. The best response of player i satisfies
                                                                  X
                         − E[Γii (si )|si ]ai = E[gi (s)|si ] +          E[Γij (s)aj (sj )|si ]         (10)
                                                                  j6=i


When Condition 1 holds, the Bayesian Nash equilibrium is characterized by the unique solution
to (10).
    Now let us consider the case in which the game is not specified. Instead, assume that when player
i conjectures that player j takes action b
                                         aj (sj ) upon receiving his signal sj , player i strictly prefers to



                                                       23
play action
                                                               X
                                 ai (si ) = E[gi (s)|si ] +            E[Γij (s)b
                                                                                aj (sj )|si ]
                                                                j6=i

upon receiving signal si . In the above best response equation, gi is arbitrary and Γij (s) is a matrix
of size mi × mj whose elements can depend arbitrarily on the joint vector of signals s. Except for
payoff structure which is left unspecified, we continue to use the notation and information structure
of Section 2.
     An equilibrium in this context is defined as a strategy profile (a1 (·), . . . , an (·)) such that for every
i,
                                                               X
                                ai (si ) = E[gi (s)|si ] +             E[Γij (s)aj (sj )|si ].
                                                               j6=i

The results of Section 2 continue to apply in this alternative model specification, replacing Γii by
the negative of the identity matrix of size mi . Analogous arguments apply to the model of Section 4.

7.2     Approximate Equilibrium in General Games
Quadratic games with stochastic interaction terms can be used to understand changes in player
behavior in general games with smooth payoff functions when small changes are made to those games’
payoff functions or information structures.
     Specifically, consider a general game of incomplete information, whose payoff functions are smooth
but not necessarily quadratic in players’ actions. The signal structure is finite and the actions are
real-valued or multidimensional. Suppose the game has a known pure-strategy equilibrium. How
does the equilibrium strategy profile change after a small change in the information structure or
payoff functions? Quadratic games with stochastic interaction terms provide a convenient approach
to answering these questions. We give an informal illustration of this approach below.
     For concreteness, we focus on changes to payoff functions; small changes to the information
structure can be treated analogously. Consider the following example. There are n players. Each
player i takes a one-dimensional action ai , taking real values (the argument extends directly to
multidimensional actions). Each player i privately observes a random signal si , which takes finitely
many possible values, as in Section 2.
     However, unlike the framework of Section 2, player i now gets utility

                                          ui (a1 , . . . , an , s1 , . . . , sn ; x),

where x is a real-valued parameter, and where ui is not necessarily quadratic, but is sufficiently
smooth in the players’ actions and parameter x.
     Suppose there exists a pure-strategy Bayesian Nash equilibrium of the game just described for
the case x = 0. The equilibrium strategy profile is denoted a∗ (s) = (a∗1 (s1 ); . . . ; a∗n (sn )).
     In general, when x is nonzero, the strategy profile a∗ (s) is no longer an equilibrium. We now
explain how the framework and the results of Section 2 help us find an approximate equilibrium
profile for small values of x.

                                                             24
   First, we perform a second-order expansion of player i’s utility around the initial equilibrium for
x = 0, by computing the utility of player i when every player j plays action a∗j (sj ) + ∆aj , for small
values of ∆aj :

                                                        ∂ui ∗
        ui (a∗ (s) + ∆a, s, x) ≈ ui (a∗ (s), s, 0) + x      (a (s), s, 0)
                                                        ∂x
                                          X     ∂ui ∗               X            ∂ 2 ui
                                        +   ∆aj     (a (s), s, 0) +     ∆aj ∆ak         (a∗ (s), s, 0)
                                                ∂aj                             ∂aj ∂ak
                                            j                                      j,k
                                            X                ∂ 2 ui
                                        +       x∆aj                  (a∗ (s), s, 0).
                                                             ∂aj ∂x
                                            j


Observe that the payoff of player i as a function of the action increments ∆a is linear quadratic,
when approximating the payoffs to the second order.
   Thus, these payoffs define a quadratic game in the action increments. Using the notation of
Section 2, this game is defined by

                            ∂ 2 ui ∗
                  Γii (s) = 2       (a (s), s, 0)
                             ∂a2i
                               ∂ 2 ui
                Γij (s) = 2            (a∗ (s), s, 0)
                            ∂ai ∂aj
                              ∂ 2 ui ∗
                 gi (s) = x           (a (s), s, 0)
                            ∂ai ∂x
                                                   ∂ui ∗
           hi (∆a−i , s) = ui (a∗ (s), s, 0) + x      (a (s), s, 0)
                                                   ∂x
                              X          ∂ui ∗                 X             ∂ 2 ui
                           +        ∆aj      (a (s), s, 0) +        ∆aj ∆ak         (a∗ (s), s, 0)
                                         ∂aj                                ∂aj ∂ak
                                 j6=i                                      j6=i,k6=i
                                 X                  ∂ 2 ui
                             +          x∆aj                 (a∗ (s), s, 0).
                                                ∂aj ∂x
                                 j6=i


   Note that the second-order approximation of utility is necessary. The first-order approximation
is not enough because the first-order terms vanish in expectation, meaning that
                                                                 
                                              ∂ui ∗
                                            E     (a (s), s, 0) si = 0,
                                              ∂ai

which is the first order condition for a∗ (s) to be an equilibrium profile for the case x = 0.
   The last equality implies that E[gi (s)|si ] is of order x, which in turn implies that the equilibrium
actions of this quadratic game are of order x as well. Hence, the second-order approximation of
utility is also sufficient to obtain a first-order approximation of the equilibrium strategy following a
small perturbation of the original game.
   Finally, we remark that in this application, stochastic interactions play a major part. A model of
quadratic games with deterministic payoff interaction terms does not allow to derive the approximate
equilibrium of the perturbed game, because the partial derivatives of the players’ utility functions,

                                                                 25
which define the interaction terms Γij above, generally depend on the vector of signals.


Appendix A: Proofs
A.1     Proof of Lemma 1
Consider the optimization problem of player i who has observed realization sei of signal si . If he
chooses action ai , his expected payoff (ignoring the term hi (a−i , s), which does not affect incentives)
is equal to

                                   1
                 E[πi |ai , sei ] = aTi E[Γii (s)|e
                                                  si ]ai + aTi E[Γi,−i (s)a−i |e
                                                                               si ] + aTi E[gi (s)|e
                                                                                                   si ].
                                   2

Since matrix E [Γii (s)|e
                        si ] is negative definite for all sei , the unique best response of player i is to
set ai (e
        si ) to the value that satisfies the first-order condition
                                                       X
                       E [Γii (s)|e
                                  si ] ai (e
                                           si ) +             E [Γij (s)aj (sj )|e
                                                                                 si ] + E [gi (s)|e
                                                                                                  si ] = 0,     (11)
                                                       j6=i


and a necessary and sufficient condition for a profile of strategies ai (·) to be a Bayesian Nash
equilibrium is that the first-order condition (11) is satisfied for every i and every signal realization sei .
    Bringing the first term under the summation sign, equation (11) becomes
                                      n
                                      X
                                               E [Γij (s)aj (sj )|e
                                                                  si ] + E [gi (s)|e
                                                                                   si ] = 0.
                                      j=1


By the law of iterated expectations, conditioning over all kj possible realizations of signal sej , the
equation can be further rewritten as

                     kj
                   n X
                   X
                                            si , sej ] P [sj = sej |si = sei ] aj (e
                                 E [Γij (s)|e                                      sj ) + E [gi (s)|e
                                                                                                    si ] = 0.   (12)
                    j=1 sej =1


Using the notation introduced in Section 2.4, we can rewrite (12) as
                                       X
                                               Φ(i,esi ),(j,esj ) aj (e
                                                                      sj ) + E [gi (s)|e
                                                                                       si ] = 0.                (13)
                                        j,e
                                          sj


Stacking equations (13) for all i = 1, . . . , n and all sei = 1, . . . , ki we obtain

                                                              Φa + g = 0.                                       (14)

If Φ is invertible, linear equation (14) admits the unique solution

                                                              a = −Φ−1 g.                                       (15)



                                                                   26
Conversely, if Φ is not invertible, then (14) has either zero or infinitely many solutions, and hence
either the equilibrium does not exist or there are infinitely many equilibria.

A.2      Proof of Lemma 2
Slightly abusing notation, let Φ(γ) denote the matrix Φ corresponding to the quadratic game with
parameter γ. Matrix Φ(γ) is invertible if and only if its determinant det Φ(γ) is not equal to zero.
Note that det Φ(γ) is a polynomial in γ, because each element of matrix Φ(γ) is either independent
of γ or is a linear function of it, and the determinant of any matrix is a polynomial function of its
elements.
                                                                                                      1 T
    Consider the quadratic game with γ = 0, so that payoffs are πi (ai , a−i , s) =                   2 ai Γii (s)ai   +
aTi gi (s) + hi (a−i , s).   Since E [Γii (s)|e
                                              si ] is negative definite for all sei , there is a unique optimal action
for each player i, and this optimal action is independent of the actions of other players. Therefore,
this game has a unique Bayesian Nash equilibrium. Thus, by Lemma 1, Condition 1 holds, and so
det Φ(γ) 6= 0 at γ = 0.
    Thus, the polynomial det Φ(γ) is not equal to the zero polynomial. Therefore, it has at most
a finite number of roots, and so matrix Φ(γ) is invertible for all γ ∈ R, except for at most finitely
many values.

A.3      Proof of Proposition 1
To begin, consider the special case α(·) = ci (·) = 0 for every i. We show that in this case there exists
a unique Bayesian Nash equilibrium. The profit of firm i becomes πi = −β(ω)qi Q − di (ω)qi2 . For
such a profit function, it is readily verified that all firms producing zero is an equilibrium: thus, there
exists at least one equilibrium of this game. We also note that no matter what other firms produce,
a firm can always guarantee itself a profit of zero by producing zero. Hence, in every equilibrium
profile qi (si ), i = 1, . . . , n, the expected profit of each firm is nonnegative, and so is the sum of profits
for all the players,
              X                                               h            X                i
                   E −β(ω)qi (si )Q(s) − di (ω)qi (si )2 = − E β(ω)Q(s)2 +   di (ω)qi (si )2 ,
                                                       

               i
                   P
where Q(s) =         j qj (sj )   is the total equilibrium quantity supplied by the firms. Note that the right
hand side is also nonpositive, and hence has to be equal to zero. Therefore, in every equilibrium, the
expected profit of every firm is equal to zero. Fixing the strategies of other firms, the best response of
firm i, that maximizes its expected profit, conditional on its signal and conditional on the strategies
of the other firms, is unique, because β(·) > 0 and di (·) ≥ 0. Hence, the only strategy for which the
best response of firm i yields an expected profit of zero is to produce zero.
    We have shown that there exists a unique Bayesian Nash equilibrium for the special case
where α(·) = ci (·) = 0 for every i. We now consider the general case in which α(·) and ci (·) are
arbitrary. Note that, using the notation of Section 2, the term Γij reduces to −β(ω) if i 6= j and
−2di (ω) − 2β(ω) < 0 if i = j. Hence, the assumptions of Section 2.2 are satisfied, and Lemma 1

                                                            27
applies. Observe that the matrix Φ, defined in Section 2.4, does not depend on the terms α(·) and
ci (·) of the profit function. By Lemma 1, Condition 1 is satisfied for the special case α(·) = ci (·) = 0,
and so by our observation Condition 1 is also satisfied for the general case. Therefore, by Lemma 1,
there exists a unique Bayesian Nash equilibrium in this general case.

A.4     Proof of Proposition 2
To save on notation, we restrict attention to symmetric strategy profiles in which the firms of a given
group use identical strategies. (By symmetry of the game structure, this restriction is without loss
of generality.) A strategy profile then reduces to the specification of the strategies qi (si ) common to
every firm of group i, for every group i.
   Let us write the total surplus of a given strategy profile qi (si ) for every firm of group i in market
k. Given market price P and market quantity Q, the ex-post consumer surplus is:

                                              1                  1
                                                (α(ω) − P ) Q =    β(ω)Q2 ,
                                              2                 2k

and the ex-post producer surplus is
        X                       X                               1          X                  X
P Q−k        ci (ω)qi (si )−k           di (ω)qi (si )2 = α(ω)Q− β(ω)Q2 −k   ci (ω)qi (si )−k   di (ω)qi (si )2 ,
                                                                k
         i                          i                                                 i                        i

so the ex-post total surplus is

              1            X                     X
  α(ω)Q −       β(ω)Q2 − k    ci (ω)qi (si ) − k   di (ω)qi (si )2
             2k
                           i                     i
                                   !                         !2
                        X               k         X                X                    X
                = kα(ω)    qi (si ) − β(ω)           qi (si ) − k    ci (ω)qi (si ) − k   di (ω)qi (si )2 ,
                                        2
                                i                            i                    i                        i

and the ex-ante expected total surplus, denoted TSk , is
                                        !                          !2                                                    
                         X                    k        X                      X                        X
  TSk = E kα(ω)                qi (si )     − β(ω)          qi (si )    −k       ci (ω)qi (si ) − k       di (ω)qi (si )2  .
                                              2
                          i                              i                    i                        i


In the remainder of the proof, it is useful to make explicit the dependence on the strategy profile.
For a strategy profile summarized by q = (q1 (·), . . . , qn (·)) in any market k, we denote by TSk (q)
                                                                                  a
the expected total surplus in that market. By assumption, TS < ∞, so supq TSk (q) < ∞. The
optimization problem that consists in finding the supremum is quadratic, which implies that the
supremum is reached for some instance of strategy profile. Thus, there exists at least one ex-ante
efficient strategy profile, which we denote q a . Since the total surplus is linear in the market size, q a
does not depend on the market index k.
   Next, let us consider the equilibrium in market k. Recall that, by Proposition 1, there exists a
unique Bayesian Nash equilibrium profile (q1 (s1 ), . . . , qN (sN )). The profit of any firm in group i,


                                                             28
who produces q instead of its prescribed equilibrium quantity qi (si ), is

        P q−ci (ω)q − di (ω)q 2
                                
                           β(ω)
             = α(ω) −           Q q − ci (ω)q − di (ω)q 2
                            k
                                                                        
                           β(ω)    β(ω)(k − 1)                 X
             = α(ω) −          q−             qi (si ) − β(ω)   qj (sj ) q − ci (ω)q − di (ω)q 2 .
                             k           k
                                                                           j6=i


The equilibrium profile is the unique solution to the first-order conditions
                                                                                              
                                                    N
                             β(ω)                   X
                E α(ω) −         qi (si ) − β(ω)         qj (sj ) − ci (ω) − 2di (ω)qi (si ) si  = 0       (16)
                              k
                                                    j=1


for every i.
   These first-order conditions are the same first-order conditions of the maximization of the expected
total surplus with the addition of an extra term, a modified total surplus which we write MTSk (q)
and is expressed as MTSk (q) = TSk (q) − Rk (q) with
                                                 "             #
                                               β(ω) X
                                    Rk (q) = E        qi (si )2 ≥ 0.
                                                2
                                                               i

   Denote by qk∗ the unique equilibrium strategy profile in market k, and by q a a strategy profile
that is ex-ante efficient. Since the total surplus is linear in k, ex-ante efficient strategy profiles do
not depend on the market index k.
   As qk∗ maximizes the expected modified total surplus, MTSk (qk∗ ) ≥ MTSk (q a ). Hence, we have

           TSk (qk∗ ) = MTSk (qk∗ ) + Rk (qk∗ ) ≥ MTSk (qk∗ ) ≥ MTSk (q a ) = TSk (q a ) − Rk (q a ).

Besides, q a maximizes the expected total surplus, so TSk (qk∗ ) ≤ TSk (q a ). Hence, letting Rk (q) =
                                                                                  a                      ∗
Rk (q)/(kN ) and TSk (q) = TSk (q)/(kN ), noting that TSk (q a ) = TS and TSk (qk∗ ) = TSk , we have

                                           a                       ∗          a
                                       TS − Rk (q a ) ≤ TSk ≤ TS .

For any fixed strategy profile q, limk→∞ Rk (q) = 0. Thus,

                                                          ∗            a
                                               lim TSk = TS ,
                                               k→∞

which concludes the proof.




                                                          29
A.5      Proof of Proposition 3
First, let us demonstrate that a best linear estimate exists. The problem of minimizing the β-weighted
squared error can be formulated as a quadratic optimization problem, in which we minimize
                            X                                            p
                                        β(ω)(q1,s1 + · · · + qN,sN − Q (ω))2 P[s1 , . . . , sN , ω],
                        s1 ,...,sN ,ω


over the variables q1,1 , . . . , q1,k1 , . . . , qN,1 , . . . , qN,kN . In this optimization problem, the objective is a
quadratic function of k1 + · · · + kN variables. It is nonnegative, thus a minimum exists, and this
minimum is reached in at least one instance of the variables. Hence, there exists at least one best
                        p
linear estimate of Q .
      Next, we prove that the best linear estimate is unique. Suppose, by contradiction, that Q1 and
Q2 are two different best linear estimates: there is at least one vector of signals for which Q1 and
Q2 take different values. Observing that C is convex, we claim that (Q1 + Q2 )/2 is a strictly better
                        p
linear estimate of Q . We have, for all realizations of joint signals,
                              2
               Q1 + Q2   p               1       p           1        p        1        p        p
                       −Q               = (Q1 − Q )2 +         (Q2 − Q )2 +      (Q1 − Q )(Q2 − Q )
                  2                      4                   4                 2
                                         1       p           1        p        1        p     1      p
                                        ≤ (Q1 − Q )2 +         (Q2 − Q )2 +      (Q1 − Q )2 + (Q2 − Q )2
                                         4                   4                 4              4
                                         1       p           1        p
                                        = (Q1 − Q )2 +         (Q2 − Q )2 ,
                                         2                   2

                                                                               6 Q2 . As all vectors of
and where the inequality is strict for the vectors of signals are such that Q1 =
signals have positive probability, we get
                      "                       2 #
                           Q1 + Q2    p                     1 h        p 2
                                                                            i 1 h
                                                                                           p 2
                                                                                                i
                  E                −Q                 <       E Q1 − Q       + E Q2 − Q
                              2                             2                 2
                                                              h          i    h           i
                                                                     p 2
                                                                                    p 2
                                                      =     E Q1 − Q       = E Q2 − Q

and hence (Q1 + Q2 )/2 is a strictly better linear estimate. Thus, we have established that there
exists a unique best linear estimate Q† .
                                                 †      a                           †
      We now proceed to prove that Q = Q . First, note that as Q is the unique minimizer of

                                                                  p 
                                                      E β(ω)(Q − Q )2
                                                       

                                          p
for Q ∈ C, subtracting β(ω)(Q )2 from the objective and then multiplying by −N 2 k/2, we get that
  †
Q is also the unique maximizer of
                                                                  
           1      2 2    2      p     1      2 2
        E − β(ω)kN Q + kN β(ω)QQ = E − β(ω)kN Q + kN Qα(ω) − kN Qc(ω)                                               (17)
           2                          2

for Q ∈ C, where we used the fact that the ex-post efficient market quantity Qpk is equal to



                                                               30
                                                             p
k(α(ω) − c(ω))/β(ω) in market k, and thus Q = (α(ω) − c(ω))/(N β(ω)). Writing Q in the form
       1
Q=     N (q1 (s1 )   + · · · + qN (sN )), the value of (17) is equal to
                                                  !                    !2                 
                                     X                  k     X              X
                       E kα(ω)            qi (si )    − β(ω)   qi (si ) − k   c(ω)qi (si ) ,
                                                        2
                                       i                              i               i


which is the expected total surplus when each firm of group i produces qi (si ), as shown in the
proof of Proposition 2. The variable Q can then be interpreted as the per-firm average production.
                          †
Hence, the value Q is the per-firm average production that makes the market ex-ante efficient, and
  †       a
Q =Q .
      Finally, we prove that the per-firm average equilibrium production converges to the ex-ante
efficient level. Borrowing notation and terminology from the proof of Proposition 2, let us consider
the problem of finding a profile q = (q1 (s1 ), . . . , qN (sN )) that maximizes the value of
                                           "                                          #
                                                         β(ω) X
                                                             p 2
                                       E −β(ω)(Q − Q ) −        qi (si )2                                  (18)
                                                         kN
                                                                          i

                                                                                  p
where we write Q = (q1 (s1 ) + · · · + qN (sN ))/N . Using that Q = (α(ω) − c(ω))/(N β(ω)), the
first-order conditions of this maximization problem are
                                 "                                                 #
                              2         X                          β(ω)
                                E −β(ω)   qi (si ) + α(ω) − c(ω) −      qi (si ) si = 0                    (19)
                              N                                     k
                                               i

for every i. Observe that these first-order conditions are identical to the first-order conditions
associated with the unique equilibrium of market k. Indeed, recall from the proof of Proposition 2
that an equilibrium profile (q1 (s1 ), . . . , qN (sN )) in market k is the unique solution to (16) for every i,
and equations (16) and (19) are identical for the cost structures of the environments being considered.
Thus, there exists a unique profile that maximizes (18), and that profile is the equilibrium strategy
profile of market k, denoted qk∗ .
      For a profile q, and for Q ∈ C, we let
                                                      h                      i
                                                                        p 2
                                           A(Q) = E −β(ω) Q − Qk               ,
                                                      "                  #
                                                        β(ω) X 2
                                           Bk (q) = E            qi (si ) ,
                                                        kN
                                                             i
                                                                     !
                                                         1 X
                                           Fk (q) = A        qi (si ) − Bk (q).
                                                        N
                                                                 i

Thus, qk∗ maximizes Fk (q) over all profiles q. Let q a = (q1a (s1 ), . . . , qN
                                                                               a (s )) be a profile such that
                                                                                   N
  a                                                                           a       †     a
Q = (q1a (s1 ) + · · · + qN
                          a (s ))/N . We have shown above that Q = Q , and that Q maximizes A(Q)
                              N
over all profiles Q ∈ C.



                                                                 31
           a                                   ∗
    As Q maximizes A(Q), and Qk ∈ C, we have

                                                           ∗        a
                                                      A(Qk ) ≤ A(Q ).                                           (20)

Noting that Bk (q) ≥ 0, and that qk∗ maximizes Fk (q), we also have

                      ∗                                                         a                       a
                A(Qk ) = Fk (qk∗ ) + Bk (qk∗ ) ≥ Fk (qk∗ ) ≥ Fk (q a ) = A(Q ) − Bk (q a ) → A(Q )              (21)

where the limit obtains as k → ∞ and is implied by the fact that for any fixed profile q,
limk→∞ Bk (q) = 0.
    Hence, putting together the inequalities (20) and (21), we obtain the limit

                                                               ∗            a
                                                     lim A(Qk ) = A(Q ).                                        (22)
                                                     k→∞

                                                                        ∗                  a
To finish, we observe that the limit (22) implies that Qk converges to Q for every realization of
                                                                                                            a
joint signals, because every realization of joint signals occurs with positive probability and Q is the
                                                               ∗    a
unique maximizer of A(Q) for Q ∈ C. Hence, Qk → Q as k → ∞, where the limit holds for every
realization of joint signals.

A.6      Additional Properties of Conditional Expectations
In this section, we state and prove a lemma that summarizes two additional properties of conditional
expectations of variables θi that follow from our assumptions.

Lemma A.1 For every i, conditional expectations of signal θi satisfy the following properties:

   1. For every subset T of players, for any profile of their finite signal realizations seT that has a
       positive probability, we have E[θi |sT = seT ] = 0.

   2. For every j 6= i, for every pair of finite signal realizations sei and sej , there exists a matrix
           sj , sei ) such that for every infinite signal realization θej , the conditional expectation of θi is
      Qji (e
      given by E[θi |sj = sej , si = sei , θj = θej ] = QT (e
                                                            sj , sei )θej .
                                                               ji


Proof of statement 1:       It is sufficient to prove the statement for the case i ∈ T : if the statement
                                                                                           P
is true for all i and T such that i ∈ T , then for any T and i ∈  / T , E[θi |sT = seT ] = sei E[θi |sT =
seT , si = sei ] P[si = sei |sT = seT ] = 0.
    Now suppose i ∈ T . Consider a new random variable, χ, which is equal to θi when sT = seT and
is equal to zero otherwise. Note that E[χ] = E[θi |sT = seT ]P (e
                                                                sT ), so it is sufficient to show that
                                   sT ) 6= 0). Decompose seT as seT = (e
E[χ] = 0 (because by assumption, P(e                                   si , seT \i ). Then

                      E[χ] = P(e
                               si ) E[χ|si = sei ]
                                    Z
                           = P(e
                               si )   θei P(sT \i = seT \i |si = sei , θi = θei ) dP (θei |si = sei )
                                               θei


                                                               32
                                                Z
                                  = P(e
                                      si )    θei P(sT \i = seT \i |si = sei ) dP (θei |si = sei )
                                                 θei
                                                                        Z
                                      si ) P(sT \i = seT \i |si = sei )
                                  = P(e                                    θei dP (θei |si = sei )
                                                                                 θei
                                      si ) P(sT \i = seT \i |si = sei ) E[θi |si = sei ]
                                  = P(e
                                  = 0.

Note that a key step in the calculation is the substitution P(sT \i = seT \i |si = sei , θi = θei ) = P(sT \i =
seT \i |si = sei ), which is one of our assumptions on the joint distribution of finite and infinite signals.

Proof of statement 2:            By assumption, the conditional expectation of θi is a linear function of θej ,
                                                     sj , sei ) + QTji (e
and so E[θi |sj = sej , si = sei , θj = θej ] = qji (e                  sj , sei )θej for some vector qji (e
                                                                                                           sj , sei ) and matrix
QTji (e                              sj , sei ) = 0, consider the conditional expectation E[θi |sj = sej , si = sei ],
      sj , sei ). To prove that qji (e
and note that on one hand, we have E[θi |sj = sej , si = sei ] = 0, and on the other hand, E[θi |sj =
                        sj , sei ) + QTji (e
sej , si = sei ] = qji (e                  sj , sei ) E[θj |sj = sej , si = sei ] = qji (e
                                                                                         sj , sei ).

A.7       Proof of Lemma 3
Consider the optimization problem of player i who has observed realization (e
                                                                            si , θei ) of signal (si , θi ).
If he chooses action ai , his expected payoff, ignoring the term hi (ai , s, θ) which does not affect
incentives, is equal to
          h                i 1        h              i           h                     i        h              i
       E πi ai , sei , θei = aTi E Γii (s) sei , θei ai + aTi E Γi,−i (s)a−i sei , θei + aTi E gi (s) sei , θei .
                                2
         h                 i
Since E Γii (s) sei , θei = E [Γii (s)|e si ] is negative definite for all sei , the unique best response of player i
is to set ai (e
              si , θei ) to the value that satisfies the first-order condition
                h                 i                 X h                              i   h                   i
               E Γii (s) sei , θei ai (e
                                       si , θei ) +  E Γij (s)aj (sj , θj ) sei , θei + E gi (s, θ) sei , θei = 0,        (23)
                                                       j6=i


and a necessary and sufficient condition for a profile of linear strategies aj (sj , θj ) = κj (sj ) + Λj (sj )θj
for every player j to be a linear equilibrium is that the first-order condition (23) is satisfied for every
i and every signal realization (esi , θei ).
     Bringing the first term under the summation sign in equation (23), we get
                                  n
                                  X      h                              i   h                   i
                                        E Γij (s)aj (sj , θj ) sei , θei + E gi (s, θ) sei , θei = 0.                     (24)
                                  j=1


By the law of iterated expectations, conditioning over all kj possible realizations of signal sej , we can




                                                                      33
rewrite (24) as

                 kj
               n X                                    h                                    i   h                   i
               X
                             P [sj = sej |si = sei ] E Γij (s)aj (sj , θj ) sei , sej , θei + E gi (s, θ) sei , θei = 0.                (25)
               j=1 sej =1


                                                           sj |e
For simplicity, in the remainder of the proof, we write P [e   si ] to denote P [sj = sej |si = sei ].
       By the law of iterated expectations and our assumption that the distribution of s given (e
                                                                                                si , sej , θei , θej )
is equal to the distribution of s given (e
                                         si , sej ), we get
                  h                       i   h h                             i               i
                 E Γij (s) sei , sej , θei = E E Γij (s) sei , sej , θei , θej sei , sej , θei = E [Γij (s)|e
                                                                                                            si , sej ] .
                              h                   i
Then, recalling our notation E gi (s, θ) sei , θei = Gi (e
                                                         si ) + Fi (e
                                                                    si )θei , equation (25) becomes

   X                                                   h                                  i
             sj |e
          P [e   si ] E [Γij (s)|e
                                 si , sej ] κj (e                   sj )θej sei , sej , θei + Gi (e
                                                sj ) + E Γij (s)Λj (e                             si ) + Fi (e
                                                                                                             si )θei = 0.               (26)
   j,e
     sj


    Let us use again the law of iterated expectations and our assumption that the distribution of s
given (e
       si , sej , θei , θej ) is equal to the distribution of s given (e
                                                                       si , sej ) to obtain the following equalities:
                      h                                  i     h h                                                i                i
                     E Γij (s)Λj (e
                                  sj )θej sei , sej , θei = E E Γij (s)Λj (e         sj )θej sei , sej , θei , θej sei , sej , θei
                                                               h h                                i                                 i
                                                           = E E Γij (s) sei , sej , θei , θej Λj (e        sj )θej sei , sej , θei
                                                               h                                                       i
                                                           = E E [Γij (s)|e    si , sej ] Λj (esj )θej sei , sej , θei
                                                                                                  h                    i
                                                           = E [Γij (s)|e
                                                                        si , sej ] Λj (e  sj ) E θej sei , sej , θei .
                        h                  i
Recalling our notation E θj sei , sej , θei = QTij (e
                                                    si , sej )θei , equation (26) can then be written

             X                                                                              
                        sj |e
                     P [e   si ] E [Γij (s)|e
                                            si , sej ] κj (e          sj )QTij (e
                                                           sj ) + Λj (e         si , sej )θei + Gi (e
                                                                                                    si ) + Fi (e
                                                                                                               si )θei = 0.             (27)
              j,e
                sj


This equation is linear in θei . By assumption, the variance of θi has full rank, so for (27) to hold for
all possible realizations θei of θi , both the constant term and the multiplier of θei must be equal to
zero.21
       The equation corresponding to the constant term is
                                         X
                                                   sj |e
                                                P [e   si ] E [Γij (s)|e
                                                                       si , sej ] κj (e
                                                                                      sj ) + Gi (e
                                                                                                 si ) = 0.                              (28)
                                         j,e
                                           sj

  21
     To see this, consider a square matrix M ∈ R`×` , a vector N ∈ R` , and a random vector X ∈ R` with E[X] = 0
and finite second moments, with full rank variance matrix Var(X). Suppose that the equality M Xe + N = 0 holds for
all possible realizations X of X. Then E[M X + N ] = 0. First, note that as E[X] = 0, we must have N = 0. Second,
                          e
we now have M X   e = 0, which implies M X
                                         eXe T = 0, and so E[M XX T ] = 0. Since E[M XX T ] = M Var(X) and Var(X)
has full rank, we must have M = 0.


                                                                          34
and using the notation introduced in Section 2.4, we can rewrite (28) as
                                              X
                                                      Φ(i,esi ),(j,esj ) κj (e
                                                                             sj ) + Gi (e
                                                                                        si ) = 0.                  (29)
                                               j,e
                                                 sj


Stacking equations (29) for all i = 1, . . . , n and all sei = 1, . . . , ki , we get

                                                                Φκ + g = 0.                                        (30)

Note that (30) is the same as (12), where κj (e
                                              sj ) is used instead of aj (e
                                                                          sj ) and Gi (e
                                                                                       si ) is used instead
of E [gi (s)|e
             si ]. If Φ is invertible, (30) admits the unique solution

                                                                κ = −Φ−1 g.

If Φ is not invertible, then (30) has either zero or infinitely many solutions.
    Now we write the equation corresponding to the coefficient of θei :
                            X
                                       sj |e
                                    P [e   si ] E [Γij (s)|e              sj )QTij (e
                                                           si , sej ] Λj (e         si , sej ) + Fi (e
                                                                                                     si ) = 0.     (31)
                             j,e
                               sj


We vectorize this equation and apply the identity vec(XY Z) = (Z T ⊗ X) vec(Y ):22
                   X
                             sj |e
                          P [e              si , sej ) ⊗ E [Γij (s)|e
                                 si ] (Qij (e                       si , sej ]) vec Λj (e
                                                                                        sj ) + vec Fi (e
                                                                                                       si ) = 0.   (32)
                   j,e
                     sj


Stacking equations (32) for all i = 1, . . . , n and all sei = 1, . . . , ki , we get

                                                               ΨΛ + f = 0.                                         (33)

If Ψ is invertible, then (33) admits the unique solution

                                                               Λ = −Ψ−1 f.

If Ψ is not invertible, then (33) has either zero or infinitely many solutions.
       Therefore, if both Φ and Ψ are invertible, then there exists a unique linear equilibrium given by
κ = −Φ−1 g and Λ = −Ψ−1 f . Conversely, if Φ or Ψ are not invertible, then either there exists no
linear equilibrium, or there are infinitely many linear equilibria.

A.8       Proof of Lemma 4
The proof is analogous to the proof of Lemma 2. Similar to that proof, let Φ(γ) and Ψ(γ) denote the
matrices Φ and Ψ corresponding to the quadratic game with parameter γ. As in that proof, det Φ(γ)
  22
    See        https://en.wikipedia.org/wiki/Vectorization_(mathematics)#Compatibility_with_Kronecker_
products for details.



                                                                      35
and det Ψ(γ) are polynomials in γ, and so it is sufficient to prove that neither of these polynomials
is identically equal to zero.
                                                                                                         1 T
     Consider the quadratic gameh with γ = 0,             i so that payoffs are πi (ai , a−i , s, θ) = 2 ai Γii (s)ai +
aTi gi (s, θ) + hi (a−i , s, θ). Since E Γii (s) sei , θei is negative definite for all sei and θei , there is a unique
optimal action for each player i, andh this optimal   i action is independent of the actions of other
players. Also, since by assumption E Γii (s) sei , θei does not depend on θei and E[gi (s, θ)|e  si , θei ] is a
linear function in θei , the optimal strategy of player i is also linear in θei . Thus, the quadratic game
with γ = 0 has a unique linear equilibrium, which in turn implies that Conditions 1 and 2 are both
satisfied, and so det Φ(γ) 6= 0 and det Φ(γ) 6= 0 at γ = 0.

A.9     Proof of Proposition 4
First, observe that terms b∗i do not affect matrices Φ and Ψ in any way: these matrices only depend
on the distribution of the profile of finite signals s; the terms Γij (s), which in the current context
depend only on the parameters γii and γij ; and matrices Qij (si , sj ), which in the current context
depend only on the distribution of the profile of infinite signals θ. By Lemma 3, there exists a
unique equilibrium if and only if Conditions 1 and 2 are satisfied, i.e., if matrices Φ and Ψ are
invertible. Thus, it is sufficient to prove that the game has a unique equilibrium when all bliss points
b∗i are always equal to zero: this fact would imply that Conditions 1 and 2 are satisfied for that
modified game, which would in turn imply that Conditions 1 and 2 are satisfied for the original
game, completing the proof.
    Consider a beauty contest with zero bliss points: the payoffs are given by
                                                                   X
                               πi (ai , a−i , s) = −γii (s)a2i −          γij (s)(ai − aj )2 .                   (34)
                                                                   j6=i


It is immediate that this game has a linear equilibrium in which each player i always plays ai = 0
regardless of his information. Let us prove that there are no other linear equilibria in this game.
    Consider a linear equilibrium in which each player i plays ai (si , θi ) = κi (si ) + Λi (si )θi . We will
first show that for all i and all realizations sei , the constant term κi (e
                                                                           si ) is equal to zero, and will then
prove an analogous statement about the terms Λi (si ), thus completing the proof.
    Suppose for some i and some realization sei , the term κi (e
                                                               si ) is not equal to zero. Without loss of
generality, suppose that for this i and sei , the term κi (e
                                                           si ) has the largest absolute value: for any player
j and signal realization sej , we have |κj (e
                                            sj )| ≤ |κi (e
                                                         si )|. Consider the case when player i observes the
realization of his finite signal equal to sei , and observes the realization of his infinite signal equal
to zero. Conditional on this information, the expected value of the infinite signal θj of any other
player j is also equal to zero, and the expected action of player j depends only on the κj terms of
his strategy, and not on Λi terms. The optimal action of player i, which by assumption is given by




                                                          36
κi (e
    si ), must satisfy the following first-order condition:
                                                         X
                           E[γii (s)|e
                                     si ]κi (e
                                             si ) +                           si ) − κj (sj ))|e
                                                                E[γij (s)(κi (e                si ] = 0.
                                                         j6=i


Since γii (s) is always positive, γij (s) is always non-negative, and κi (e
                                                                          si ) has the largest possible
absolute value among all κj (sj ), the above expression has the same sign as κi (e
                                                                                 si ), and in particular
is not equal to zero, contradicting the assumption of equilibrium. Thus, all terms κi (si ) are equal to
zero, and the linear equilibrium behavior of each player i reduces to ai (si , θi ) = Λi (si )θi .
    We will now show that terms Λi (si ) also have to be equal to zero (and thus the actions of all
players are identically equal to zero). Suppose that is not the case. Take player i and finite signal
realization sei such that the variance Var(ai |e
                                               si ) = Λi (e                si )T is maximal, i.e., for every j
                                                          si ) Var(θi )Λi (e
and every signal realization sej , Var(aj |e
                                           sj ) ≤ Var(ai |e
                                                          si ) (recall that actions are one-dimensional in
this application).
    Suppose in addition to the finite signal realization sei , player i also observes an infinite signal
realization θei . His first-order condition then implies that
                                                    X
                     E[γii (s)|e
                               si ]Λi (e
                                       si )θei +                         si )θei − Λj (sj )θj )|e
                                                           E[γij (s)(Λi (e                      si , θei ] = 0,
                                                    j6=i


which can be rewritten as
                                                  X
                   E[γii (s)|e
                             si ]Λi (e
                                     si )θei +                         si )θei − Λj (sj ) E[θj |θei ])|e
                                                         E[γij (s)(Λi (e                               si ] = 0.
                                                  j6=i


    Multiplying this equation by θeiT Λi (e
                                          si )T on the right, and taking the expectation over θi , we get
                                           X
                     si ] Var(ai |e
           E[γii (s)|e            si ) +          E[γij (s)(Var(ai |e                                si )T |e
                                                                    si ) − Λj (sj ) Cov(θj , θi )Λi (e      si ] = 0.   (35)
                                           j6=i


    The final step of the proof is to observe that for every player j and every realization sej of his
finite signal, the expression Λj (e                        si )T is equal to Cov(aj , ai |e
                                     sj ) Cov(θj , θi )Λi (e                              sj , sei ), for which we have
                         p
Cov(aj , ai |e
             sj , sei ) ≤ Var(aj |e
                                  sj ) · Var(ai |e
                                                 si ) ≤ Var(ai |e si ) (where the second inequality follows from
the choice of player i and signal realization sei ). Thus, the left-hand side of equation (35) is strictly
positive, contradicting the assumption that it is equal to zero. Thus, the modified game has a
unique linear equilibrium, in which every player always plays zero, and therefore, as explained in the
beginning of the proof, the original game also has a unique equilibrium.

A.10      Proof of Proposition 5
1. The derivative of (βL + βH )/2 with respect to ∆ is

                                       2ρ2 ∆(2q − 1)(1 − ρ)(α(2q − 1)ρ − 1)
                                    (ρ2 (2q − 1)(α − ∆)(α + ∆) − 2αqρ + 1)2


                                                                   37
which is negative because 2q − 1 > 0 (as q > 1/2), 1 − ρ > 0, and α(2q − 1)ρ − 1 < αρ − 1 < 0.
   Next, the derivative of (βL + βH )/2 with respect to q is

                                            2∆2 ρ2 (ρ − 1)
                              (ρ2 (2q − 1)(α − ∆)(α + ∆) − 2αqρ + 1)2

which is negative, because ρ − 1 < 0.
2. The derivative of βH with respect to q is:

                                2ρ2 ∆(ρ − 1)(α + ∆)(−αρ + ∆ρ + 1)
                              (ρ2 (2q − 1)(α − ∆)(α + ∆) − 2αqρ + 1)2

which is negative, because ρ − 1 < 0 and because −αρ + ∆ρ + 1 = 1 − ρ(α − ∆) > 0.
   The derivative of βH with respect to ∆ is:

                 (ρ − 1)ρ (2q − 1)ρ2 (α + ∆)2 − 4α∆q − 2ρ(αq − 2∆q + ∆) + 1
                                                                          
                                                                                    .        (36)
                              (ρ2 (2q − 1)(α − ∆)(α + ∆) − 2αqρ + 1)2

To evaluate the sign of (36) we will show that the following inequality holds:

                      (2q − 1)ρ2 (α + ∆)2 − 4α∆q − 2ρ(αq − 2∆q + ∆) + 1 > 0.
                                                
                                                                                             (37)

To see this, recall that α = (αL + αH )/2 and ∆ = (αH − αL )/2. Plugging these in the above
expression, (37) becomes

               2
              αH (−2q 2 + 3q − 1)ρ2 + αH (q − 1)ρ + (αL qρ − 1)(αL (2q − 1)ρ − 1) > 0.

Note that −2q 2 + 3q − 1 = −(q − 1)(2q − 1) > 0 and so, since αH > αL ,

               2
              αH (−2q 2 + 3q − 1)ρ2 + αH (q − 1)ρ + (αL qρ − 1)(αL (2q − 1)ρ − 1)
                     2
                  > αL (−2q 2 + 3q − 1)ρ2 + αH (q − 1)ρ + (αL qρ − 1)(αL (2q − 1)ρ − 1)
                  = qρ(αH + αL (2αL ρ − 3)) − ρ(αH + αL (αL ρ − 1)) + 1

which is linear in q. If q = 1, we have

               qρ(αH + αL (2αL ρ − 3)) − ρ(αH + αL (αL ρ − 1)) + 1 = (αL ρ − 1)2 > 0.

If q = 1/2, we have

                                                                    1
           qρ(αH + αL (2αL ρ − 3)) − ρ(αH + αL (αL ρ − 1)) + 1 = 1 − ρ(αH + αL ) > 0.
                                                                    2

So, for every q ∈ (1/2, 1),

                       qρ(αH + αL (2αL ρ − 3)) − ρ(αH + αL (αL ρ − 1)) + 1 > 0

                                                 38
which proves (37). Using (37) and the fact that ρ − 1 < 0, we obtain that (36) is negative.

3. The derivative of βL with respect to q is

                                           2ρ2 ∆(ρ − 1)(α − ∆)(ρ(α + ∆) − 1)
                                    (ρ2 (2q − 1)(α − ∆)(α + ∆) − 2αqρ + 1)2

which is positive because ρ − 1 < 0, α − ∆ > 0 and ρ(α + ∆) − 1 < ρ − 1 < 0.
   The derivative of βL with respect to ∆ is:

                    (ρ − 1)ρ ρ (2q − 1)ρ 4α∆q + (α − ∆)2 − 2q(α + 2∆) + 2∆ + 1
                                                                             
               −                                                                                .              (38)
                                      ((2q − 1)ρ2 (α − ∆)(α + ∆) − 2αqρ + 1)2

Fix α = 78 , q =   15
                   16 ,   and ρ =   95
                                    96 .   Then at ∆ =    1
                                                         10   expression (38) is negative, while at ∆ =   1
                                                                                                          11   it is
positive. Hence the comparative static is in general ambiguous.


References
Angeletos, G.-M. and A. Pavan (2007). Efficient use of information and social value of information.
  Econometrica 75 (4), 1103–1142.

Aumann, R. J. (1976). Agreeing to disagree. The Annals of Statistics 4 (6), 1236–1239.

Basar, T. (1978a). Decentralized multicriteria optimization of linear stochastic systems. IEEE
  Transactions on Automatic Control 23 (2), 233–243.

Basar, T. (1978b). Equilibrium solutions in static decision problems with random coefficients in the
  quadratic cost. IEEE Transactions on Automatic Control 23 (5), 960–962.

Bergemann, D., T. Heumann, and S. Morris (2017). Information and interaction. Cowles Foundation
  Discussion Paper 2088.

Bergemann, D. and S. Morris (2013). Robust predictions in games with incomplete information.
  Econometrica 81 (4), 1251–1308.

Bergemann, D. and S. Morris (2016). Bayes correlated equilibrium and the comparison of information
  structures in games. Theoretical Economics 11 (2), 487–522.

De Martı́, J. and Y. Zenou (2015). Network games with incomplete information. Journal of
  Mathematical Economics 61, 221–240.

Dessein, W. and T. Santos (2006). Adaptive organizations. Journal of Political Economy 114 (5),
  956–995.

Dewan, T. and D. P. Myatt (2008). The qualities of leadership: Direction, communication, and
  obfuscation. The American Political Science Review 102 (3), 351–368.


                                                          39
Dewan, T. and D. P. Myatt (2012). On the rhetorical strategies of leaders: Speaking clearly, standing
  back, and stepping down. Journal of Theoretical Politics 24 (4), 431–460.

Gal-Or, E. (1986). Information transmission–Cournot and Bertrand equilibria. The Review of
  Economic Studies 53 (1), 85–92.

Golub, B. and S. Morris (2017). Expectations, networks, and conventions. Working paper.

Hurkens, S. (2014). Bayesian Nash equilibrium in “linear” Cournot models with private information
  about costs. International Journal of Economic Theory 10 (2), 203–217.

Lambert, N., M. Ostrovsky, and M. Panov (2018a). Strategic trading in informationally complex
  environments. Econometrica 86 (4), 1119–1157.

Lambert, N., M. Ostrovsky, and M. Panov (2018b). Supplementary online appendix to “Strategic
  trading in informationally complex environments”.

Leister, C. M. (2016). Information acquisition and welfare in network games. Working paper.

Li, L., R. D. McKelvey, and T. Page (1987). Optimal research for Cournot oligopolists. Journal of
  Economic Theory 42 (1), 140–166.

Monderer, D. and L. S. Shapley (1996). Potential games. Games and Economic Behavior 14 (1),
  124–143.

Morris, S. and H. S. Shin (2002). Social value of public information. American Economic Review 92 (5),
  1521–1534.

Myatt, D. P. and C. Wallace (2017). Information acquisition and use by networked players. Working
  paper.

Palfrey, T. R. (1985). Uncertainty resolution, private information aggregation and the Cournot
  competitive limit. Review of Economic Studies 52 (1), 69–83.

Radner, R. (1962). Team decision problems. Annals of Mathematical Statistics 33 (3), 857–881.

Ui, T. (2009). Bayesian potentials and information structures: Team decision problems revisited.
  International Journal of Economic Theory 5 (3), 271–291.

Vives, X. (1984). Duopoly information equilibrium: Cournot and Bertrand. Journal of Economic
 Theory 34 (1), 71–94.

Vives, X. (1988). Aggregation of information in large Cournot markets. Econometrica 56 (4), 851–876.




                                                 40
