                             NBER WORKING PAPER SERIES




            COLLECTIVE CHOICE IN DYNAMIC PUBLIC GOOD PROVISION

                                       T. Renee Bowen
                                      George Georgiadis
                                      Nicolas S. Lambert

                                      Working Paper 22772
                              http://www.nber.org/papers/w22772


                    NATIONAL BUREAU OF ECONOMIC RESEARCH
                             1050 Massachusetts Avenue
                               Cambridge, MA 02138
                                   October 2016




An earlier version of this paper circulated under the title “Collective Choice in Dynamic Public
Good Provision: Real versus Formal Authority.” We thank Eduardo Azevedo, Dan Barron,
Marco Battaglini, Alessandro Bonatti, Steve Coate, Jaksa Cvitanic, Jon Eguia, Bob Gibbons,
Mitchell Hoffman, Matias Iaryczower, Navin Kartik, Roger Lagunoff, Jin Li, Niko Matouschek,
Dilip Mookherjee, Tom Palfrey, Michael Powell, Patrick Rey, Andy Skrzypacz, Galina
Vereshchagina, Leeat Yariv, seminar audiences at Caltech, Cornell, Microsoft Research, MIT,
Northwestern, NYU, Stanford, UCLA, UIUC, USC, Yale, and participants at CRETE 2015, the
Econometric Society World Congress 2015, GAMES 2016, INFORMS 2015, the 2015 Midwest
Economic Theory Conference, SAET 2015, the 2016 SED Annual Meeting, Stony Brook Game
Theory Festival Political Economy Workshop 2015, and SIOE 2016 for helpful comments and
suggestions. Lambert gratefully acknowledges financial support from the National Science
Foundation through grant CCF-1101209 The views expressed herein are those of the authors and
do not necessarily reflect the views of the National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2016 by T. Renee Bowen, George Georgiadis, and Nicolas S. Lambert. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.
Collective Choice in Dynamic Public Good Provision
T. Renee Bowen, George Georgiadis, and Nicolas S. Lambert
NBER Working Paper No. 22772
October 2016
JEL No. C73,D70,D78,H41

                                          ABSTRACT

Two heterogeneous agents contribute over time to a joint project, and collectively decide its
scope. A larger scope requires greater cumulative effort and delivers higher benefits upon
completion. We show that the efficient agent prefers a smaller scope, and preferences are time-
inconsistent: as the project progresses, the efficient (inefficient) agent’s preferred scope shrinks
(expands). We characterize the equilibrium outcomes under dictatorship and unanimity, with and
without commitment. We find that an agent’s degree of efficiency is a key determinant of control
over project scopes. From a welfare perspective, it may be desirable to allocate decision rights to
the inefficient agent.


T. Renee Bowen                                  Nicolas S. Lambert
Graduate School of Business                     Stanford University
Stanford University                             Graduate School of Business
655 Knight Way                                  655 Knight Way
Stanford, CA 94305                              Stanford, CA 94305
and NBER                                        nlambert@stanford.edu
trbowen@stanford.edu

George Georgiadis
Northwestern University
2001 Sheridan Rd
Evanston IL, 60208
gjgeorgiadis@gmail.com
1        Introduction
In many economic settings, agents must collectively decide the goal or scope of a joint project.
A greater scope reflects a more ambitious project, which requires more cumulative e↵ort from
the agents but yields a larger reward upon completion. Such collective decisions are common
among countries who collaborate on a project. For example, the International Space Station
(ISS) was a collaboration among the United States, Russia, the European Union, Japan,
and Canada that cost approximately $150 billon. The Asian Highway Network, running
about eighty-seven thousand miles and costing over $25 billion, is a collaboration among
thirty-two Asian countries, the United Nations, and other entities to facilitate greater trade
throughout the region. In both examples, the projects took several decades to implement,
and an agreement that determined the project scope was signed by all stakeholders.1
        If the agents’ preferences over the project scope are aligned, it is natural for the agents
to agree on the ideal scope, and there will be little debate. Yet, it is common to find
disagreement about when and at what stage to complete a project. For example, the process
of identifying roads to be included in the Asian Highway Network began in the late 1950s,
and it was not until the 1990s that the majority of the work began, owing to the endorsement
of the United Nations (see Yamamoto et al. 2003). The World Trade Organization’s (WTO’s)
Doha Round began in 2001 and has (infamously) yet to be concluded fifteen years later.
The delay is due, in part, to di↵erences between member countries over which industries
the agreement should cover and to what extent (see Bhagwati & Sutherland 2011). Central
to many of these conflicts is the asymmetry between participants—often large contributors
versus small contributors. In this paper, we investigate how the agents’ cost of e↵ort and
their stake in the project a↵ect their incentives to contribute and their preferences over the
project scope, and, ultimately, how these parameters impact their influence on the project
scope under di↵erent decision protocols.
        We focus on projects with three key features. First, progress on the project is gradual,
and hence the problem is dynamic in nature. Second, the project generates a payo↵ only
upon completion, and each agent receives a fixed fraction of that payo↵. Third, the scope of
the project is endogenous, and the project’s payo↵ increases with its scope. Thus, the scope
of the project is a crucial determinant of not only the magnitude of the payo↵s and e↵ort,
but also their timing.
        Several other examples fit our framework. For instance, many new business ventures
require costly e↵ort before payo↵s can be realized. Academics working on a joint research
project exert e↵ort over time, and the reward is largely realized after submission and
publication of the findings. In both cases, agents must agree at some point in time on the
    1
   Other notable multi-country collaborations include the International Thermonuclear Experimental
Reactor (ITER) under construction in France, and the Joint European Torus (JET) in the United Kingdom.


                                                   2
scope of the project. Does the venture seek a blockbuster product or something that may
have a quicker (if smaller) payo↵? Do the coauthors target highly regarded general interest
journals or work towards a more specific field journal? Indeed, there is often dissent on
when a joint project is ready to be monetized through the launch of the product, sale of the
company, or submission of the article.
   A key ingredient of our framework is the agents’ ability to decide on the project scope.
The decision is collective and can be made at any time, with or without the ability to
commit. As an example, it is common for the scope of a public infrastructure project to
change throughout its development, a phenomenon often referred to as “scope creep.” In
such cases, the parties cannot commit to not renegotiate. In other cases, such as with an
entrepreneurial venture, legally binding contracts can be enforced. An agreement can then
be made at any time during the project, and parties can commit to it, preventing subsequent
renegotiation. The ability to commit is considered a part of the economic environment and is
not a choice of the agents. The actual choice of the project scope is determined by a protocol
we refer to as collective choice institution. In the examples of the ISS and the Asian Highway
Network, each country must sign a formal agreement for the project to enter into force (see
Yakovenko 1999, Yamamoto et al. 2003). In these examples, the scope of the project cannot
be decided without the consent of all parties: the collective choice institution is unanimity.
An agreement may also designate a single party with the right to complete the project, such
as when one party has a controlling share of an entrepreneurial joint venture. In this paper,
we focus on these two common instances of collective choice institution: dictatorship and
unanimity.
   Our modeling approach is based on the dynamic public good provision framework of
Marx & Matthews (2000). It is well established in this setting that free-riding occurs when
agents make voluntary contributions to a public good, and basic comparative statics (e.g., the
e↵ect of changes in e↵ort costs, discount rates, scope, etc.) are well understood when agents
are symmetric. However, little is known about this problem when agents are heterogeneous.
We begin by studying a simple two-agent model. The agent with the lower e↵ort cost per
unit of benefit is referred to as the efficient agent, and the agent with the higher e↵ort
cost per unit of benefit is referred to as the inefficient agent. The solution concept we use
is Markov perfect equilibrium (hereafter MPE), as is standard in this literature. When
multiple equilibria exist, we refine the set of equilibria to the Pareto-dominant ones.
   To lay the foundations for the collective choice analysis, in Section 3, we consider the
setting in which the project scope is exogenously fixed. We show that the efficient agent
exerts more e↵ort than the inefficient agent at every stage of the project and, moreover,
obtains a lower discounted payo↵ (normalized by his project stake). It is known in this
setting that the agents’ e↵orts increase as the project nears completion (see Cvitanić &


                                              3
Georgiadis (2016)), and we further show that the efficient agent’s e↵ort level increases at
a faster rate than that of the inefficient agent. We use these results to derive the agents’
preferences over the project scope. A lower normalized payo↵ for the efficient agent means
that at every stage of the project, he prefers a smaller project scope than does the inefficient
agent. Furthermore, we show that the scope of the project that the efficient agent prefers
decreases as the project progresses, while the opposite is true for the inefficient agent. This
is because the efficient agent’s share of the remaining project cost is not only higher than
the inefficient agent’s, but also increases as the project progresses. The agents’ preferences
over the project scope are thus time-inconsistent and divergent.
       In Section 4, we endogenize the project scope and analyze the equilibrium outcomes
under dictatorship and unanimity, with and without commitment.2 With commitment,
we show that the project scope is decided at the start of the project in equilibrium under
any institution. When either agent is dictator, he chooses his ex-ante ideal project scope,
whereas under unanimity, the project scope lies between the agents’ ex-ante ideal scopes.
Without commitment, if the efficient agent is the dictator, then he completes the project at
his ideal scope. However, if the inefficient agent is dictator, then there exists a continuum of
equilibria on the Pareto frontier, which lie between the agents’ ideal scopes. That is because
the project scope that is implemented in equilibrium depends on when inefficient agent
expects the other agent to stop working (at which moment the former optimally completes
the project immediately). Lastly, because the inefficient agent always prefers a larger project
scope than the efficient agent, without commitment, the set of equilibria under unanimity
are the same as when the inefficient agent is dictator.
       While institutions can enforce authority of an agent, the scope that is implemented
remains an equilibrium outcome. That is, even if an agent has dictatorship rights, he has to
account for the other agent’s actions when deciding the project scope. Akin to Aghion &
Tirole (1997), we say that an agent has real authority if his preferences are implemented in
equilibrium. With commitment, whichever agent has formal authority (i.e., the dictator),
also has real authority. However, this is not the case without commitment. In particular, if
the efficient agent is dictator, then he also has real authority. In contrast, if the inefficient
agent is dictator, then he has real authority while the project is in progress, but it eventually
“runs out”, and at the completion state, it is the efficient agent who has real authority.
Therefore, real authority changes hands as the project progresses.
       From a social welfare perspective, with or without commitment, when the efficient agent
is the dictator, the equilibrium project scope is too small relative to the social planner’s.
The reason is that he retains full control of the scope and his ideal project scope does not
   2
    The former refers to the case in which the agents can commit to a decision about the project scope at
any time. The latter refers to the case in which the agents cannot commit to an ex-ante decision. Therefore,
at every moment, they can either decide to complete the project immediately, or continue working.


                                                     4
internalize the inefficient agent’s higher dynamic payo↵. Therefore, it may be desirable to
confer some formal authority to the inefficient agent (via dictatorship or unanimity) as a
means to counter the real authority that the efficient agent obtains in equilibrium.3
     To test the robustness of our results, we consider two extensions of the model in Section
5. If transfers are allowed, then the social planner’s project scope can be implemented in
equilibrium under all institutions. When the agents can choose the stakes (or shares) of
the project ex-ante, simulations show that the efficient agent is always allocated a higher
share than the inefficient agent. With the efficient agent as dictator, the share awarded
to him is naturally the largest. We also consider the case in which the project progresses
stochastically, and using simulations, we illustrate that the main results continue hold.4
Finally, we discuss the case in which the group comprises of more than two agents in Section
6.

Related Literature
Our model draws from the literature on the dynamic provision of public goods, including
classic contributions by Levhari & Mirman (1980) and Fershtman & Nitzan (1991). Similarly
to our approach, Admati & Perry (1991), Marx & Matthews (2000), Compte & Jehiel
(2004), Yildirim (2006), and Georgiadis (2016) consider the case of public good provision
when the benefit is received predominantly upon completion. Bonatti & Rantakari (2015)
consider collective choice in a public good game, where each agent exerts e↵ort on an
independent project, and the collective choice is made to adopt one of the projects at
completion. Battaglini et al. (2014) study a public good provision game without a terminal
date, in which each agent receives a flow benefit that depends on the stock of the public good,
in contrast to our setting. We contribute to this literature by endogenizing the provision
point of the public good, and studying how di↵erent collective choice institutions influence
the project scope that is implemented in equilibrium.
     This paper joins a large political economy literature studying collective decision-making
when the agents’ preferences are heterogeneous, including the seminal work of Romer &
Rosenthal (1979). More recently, this literature has turned its attention to the dynamics of
collective decision making, including papers by Baron (1996), Dixit et al. (2000), Battaglini
& Coate (2008), Strulovici (2010), Diermeier & Fong (2011), Besley & Persson (2011) and
Bowen et al. (2014). Other papers, for example, Lizzeri & Persico (2001), have looked at
alternative collective choice institutions. To the best of our knowledge, this is the first paper
   3
     This resonates with Galbraith (1952), who argues that when one party is strong and the other weak, it is
preferable to give formal authority to the latter.
   4
     The models with uncertainty and endogenous choice of project shares in the voluntary contribution game
with heterogeneous agents that we study is analytically intractable, so we examine them numerically. All
other results are obtained analytically.


                                                     5
to study collective decision-making in the context of a group of agents collaborating to
complete a project.
        The application to public projects without the ability to commit relates to a large
number of articles studying international agreements. Several of these study environmental
agreements (for example, Nordhaus 2015, Battaglini & Harstad forthcoming) and trade
agreements (see Maggi 2014).5 To our knowledge, this literature has not examined the
dynamic selection of project scope (or goals) in these agreements with asymmetric agents
or identified the source of authority. Our theory sheds light on the dominance of large
countries in many trade and environmental agreements in spite of unanimity being the
formal institution.
        Finally, our interest in real and formal authority relates to a literature studying the
source of authority and power, including the influential work of Aghion & Tirole (1997)
and more recent contributions by Callander (2008), Levy (2014), Callander & Harstad
(2015), Hirsch & Shotts (2015), and Akerlof (2015). Unlike this paper, these authors focus
on the role of information in determining real authority. Bester & Krähmer (2008) and
Georgiadis et al. (2014) consider a principal-agent setting in which the principal has formal
authority to choose which project to implement, but that choice is restricted by the agent’s
e↵ort incentives; or she can delegate the project choice decision to the agent. Acemoglu &
Robinson (2008) consider the distinction of de jure and de facto political power, which are
the analogs of formal and real authority, but the source of the latter is attributed to various
forces outside the model. In contrast, we are able to endogenously attribute the source of
real authority under di↵erent collective choice institutions to the agents’ e↵ort costs and
stake in our simpler setting of a public project.


2        Model
We present a stylized model of two heterogeneous agents i 2 {1, 2} deciding the scope of a
public project Q        0.6 Time is continuous and indexed by t 2 [0, 1). A project of scope Q
requires voluntary e↵ort from the agents over time to be completed. Let ait                    0 be agent i’s
instantaneous e↵ort level at time t, which induces flow cost ci (ait ) =              2
                                                                                   i ait /2   for some   i   > 0.
Agents are risk-neutral and discount time at common rate r > 0.
        We denote the cumulative e↵ort (or progress on the project) up to time t by qt , which we
call the project state. The project starts at initial state q0 = 0 and progresses according to

                                           dqt = (a1t + a2t ) dt .
    5
     Bagwell & Staiger (2002) discuss the economics of trade agreements in depth. Others look at various
aspects of specific trade agreements, such as flexibility or forbearance in a non-binding agreement, (see, for
example, Beshkar & Bond 2010, Bowen 2013).
   6
     We discuss the case of n 3 agents in Section 6.


                                                      6
It is completed at the moment that the state reaches the chosen scope Q.7 The project
yields no payo↵ while it is in progress, but upon completion, it yields a payo↵ ↵i Q to agent
i, where ↵i 2 R+ is agent i’s stake in the project.8 Agent i’s project stake therefore captures
all of the expected benefit from the project.9 All information is common knowledge.
        Therefore, given an arbitrary set of e↵ort paths {a1s , a2s }s               t   and project scope Q, agent
i’s discounted payo↵ at time t satisfies
                                                         Z       ⌧
                                         r(⌧ t)                          r(s t) i 2
                               Jit = e            ↵i Q               e           ais ds ,
                                                             t                 2
where ⌧ denotes the equilibrium completion time of the project (and ⌧ = 1 if the project is
never completed).
        By convention, we assume that the agents are ordered such that                          1
                                                                                               ↵1       2
                                                                                                        ↵2 .   Intuitively,
this means that agent 1 is relatively more efficient than agent 2, in that his marginal cost of
e↵ort relative to his stake in the project is smaller than that of agent 2. In sequel, we say
that agent 1 is efficient and agent 2 is inefficient.
        The project scope Q is decided by collective choice at any time t                     0, i.e., at the start of
the project, or after some progress has been made. The set of decisions available to each
agent depends on the collective choice institution, which is either dictatorship or unanimity.
To lay the foundations for the collective choice analysis, we shall assume that the project
scope Q is fixed in the next section. When we consider the collective choice problem in
Section 4, we will enrich the model by introducing additional notation as necessary.


3        Analysis with fixed project scope Q
In this section, we lay the foundations for the collective choice analysis. We begin by
considering the case in which the project scope Q is specified exogenously at the outset of
the game and characterize the (essentially unique) stationary Markov Perfect equilibrium
(MPE) of this game.10 We then derive each agent’s preferences over the project scope Q
given the MPE payo↵s induced by a choice of Q. Finally, we characterize the social planner’s
benchmark. In Section 4, we consider the case in which the agents decide the project scope
via collective choice.
    7
     We make the simplifying assumption that the project state progresses deterministically. See Section 5.2
for an extension in which the state progresses stochastically.
   8
     Without loss of generality, one can assume that upon completion, the project yields a stochastic payo↵
to agent i that has expected value ↵i Q.
   9
     The sum ↵1 + ↵2 reflects the publicness of the project, and if ↵1 + ↵2 = 1, then the project stake can
be interpreted as the project share. We assume that these stakes are exogenously fixed. In Section 5.1, we
extend our model to allow the agents to use transfers to re-allocate shares.
  10
     As is standard in this literature, we focus on MPE. These equilibria require minimal coordination between
the agents, and in this sense they are simple. The simplicity of MPE make them naturally focal in the
collective choice setting.



                                                         7
3.1      Markov perfect equilibrium with exogenous project scope
In a MPE, at every moment, each agent chooses his e↵ort level as a function of the current
project state q to maximize his discounted payo↵ while anticipating the other agents’ e↵ort
choices. Let us denote each agent i’s discounted continuation payo↵ and e↵ort level when the
project state is q by Ji (q) and ai (q), respectively. Using standard arguments (for example,
Kamien & Schwartz 2012) and assuming that {J1 (·), J2 (·)} are continuously di↵erentiable,
it follows that they satisfy the Hamilton-Jacobi-Bellman (hereafter HJB) equation
                                       n                              o
                                           i 2
                        rJi (q) = max       b     ai + aj (q)) Ji0 (q) ,
                                            ai + (b                                                      (1)
                                  b
                                  ai 0    2
subject to the boundary condition

                                           Ji (Q) = ↵i Q ,                                               (2)

where aj (·) is agent i’s conjecture for the e↵ort chosen by agent j 6= i. We refer to such
MPEs as well-behaved.
                                               ai = max {0, Ji0 (q) / i }. Intuitively, at every
       The right side of (1) is maximized when b
moment, each agent either does not put in any e↵ort, or he chooses his e↵ort level such
that the marginal cost of e↵ort is equal to the marginal benefit associated with bringing
the project closer to completion. In any equilibrium we have Ji0 (q)               0 for all i and q, that
is, each agent is better o↵ the closer the project is to         completion.11     By substituting each
agent’s first-order condition into (1), it follows that each agent i’s discounted payo↵ function
satisfies
                                          [Ji0 (q)]2  1
                              rJi (q) =              + Ji0 (q) Jj0 (q) ,                                 (3)
                                             2 i       j

subject to the boundary condition (2), where j denotes the agent other than i. By noting
that each agent’s problem is concave, and thus the first-order condition is necessary and
sufficient for a maximum, it follows that every well-defined MPE is characterized by the
system of ordinary di↵erential equations (ODEs) defined by (3) subject to (2).12 The
following Proposition, which builds upon Cvitanić & Georgiadis (2016) characterizes the
MPE.

Proposition 1. For any project scope Q, there exists a unique well-behaved MPE. Moreover
for any project scope Q, exactly one of two cases can occur.

   1. The MPE is project-completing: both agents exert e↵ort at all states and the project is
         completed. Then, Ji (q) > 0, Ji0 (q) > 0, and a0i (q) > 0 for all i and q           0.
  11
    See the proof of Proposition 1.
  12
    This system of ODEs can be normalized by letting Jei (q) = Ji (q)
                                                                   i
                                                                      . This becomes strategically equivalent
to a game in which 1 = 2 = 1, and agent i receives ↵ii Q upon completion of the project.



                                                     8
   2. The MPE is not project-completing: agents do not ever exert any e↵ort, and the project
         is not completed.

If Q is sufficiently small, then case (1) applies, while otherwise, case (2) applies.

    All proofs are provided in Appendix A.
    Proposition 1 characterizes the unique MPE for any given project scope Q. In any
project-completing MPE, payo↵s and e↵orts are strictly positive, and each agent increases
his e↵ort as the project progresses towards completion, i.e., a0i (q) > 0 for all i and q. Because
the agents discount time and they are rewarded only upon completion, their incentives are
stronger the closer the project is to completion.
                                                                     1        2
    If the agents are symmetric (i.e., if                           ↵1   =   ↵2 ),   then in the unique project-completing
MPE, each agent i’s discounted payo↵ and e↵ort function can be characterized analytically
as follows:
                                            r     i (q       C)2                          r (q       C)
                              Ji (q) =                               and       ai (q) =                   ,                (4)
                                                         6                                       3
                       q
                              6↵i Q
where C = Q                    r i     (see Georgiadis et al. (2014)). A project-completing MPE exists if
C < 0. While the solution to the system of ODEs given by (3) subject to (2) can be found
with relative ease in the case of symmetric agents, no closed-form solution can be obtained
for the case of asymmetric agents. Nonetheless, we are able to derive important properties
of the solution, which will be useful for understanding the intuition behind the results in
Section 3.2. The following proposition compares the equilibrium e↵ort levels and payo↵s of
the two agents.
                                                    1         2
Proposition 2. Suppose that                       ↵1     <   ↵2 .   In any project-completing MPE:

   1. Agent 1 exerts higher e↵ort than agent 2 in every state, and agent 1’s e↵ort increases
         at a greater rate than agent 2’s. That is, a1 (q)                                 a2 (q) and a01 (q)   a02 (q) for all
         q    0.

   2. Agent 1 obtains a lower discounted payo↵ normalized by project stake than agent 2.
                     J1 (q)       J2 (q)
         That is,     ↵1          ↵2      for all q           0.
                                   1        2                                                                         J1 (q)
Suppose instead that              ↵1   =   ↵2 .    In any project-completing MPE, a1 (q) = a2 (q) and                  ↵1      =
J2 (q)
 ↵2      for all q      0.

    It is intuitive that the more efficient agent always exerts higher e↵ort than the less
efficient agent, as well as that the more efficient agent raises his e↵ort at a faster rate than
the less efficient agent. Notice that each agent i’s e↵ort incentives are proportional to his
normalized gross payo↵ e                   r(⌧ t) ↵i Q.           Therefore, as the project progresses (i.e., as ⌧             t
                                                         i




                                                                         9
decreases), the incentives of the efficient agent grow at a faster rate than the incentives of
the inefficient agent.
       What is perhaps surprising is that the more efficient agent obtains a lower discounted
payo↵ (normalized by his stake) than the other agent. This is because the more efficient agent
not only works harder than the other agent, but he also incurs a higher total discounted cost
of e↵ort (normalized by his stake). To examine the robustness of this result, in Appendix
B.1, we consider a larger class of e↵ort cost functions, and we show that this result holds as
long as each agent’s e↵ort cost is weakly log-concave in the e↵ort level; i.e., {c1 (·), c2 (·)} are
not “super-convex”.

3.2      Preferences over project scope
In this section, we characterize each agent’s optimal project scope without institutional
restrictions. That is, we determine the Q that maximizes each agent’s discounted payo↵
given the current state q and assuming that both agents follow the MPE characterized in
Proposition 1 for the project scope Q. Notice that the agents will choose a project scope
such that the project is completed in equilibrium.

Agents working jointly

To make the dependence on the project scope explicit, we let Ji (q; Q) denote agent i’s payo↵
at project state q when the project scope is Q. Let Qi (q) denote agent i’s ideal project scope
when the state of the project is q. That is,

                                     Qi (q) = arg max {Ji (q; Q)} .
                                                     Q q

       For each agent i there exists a unique state q, denoted by Qi such that he is indi↵erent
between terminating the project immediately or an instant later, and Q2                 Q1 .13 Throughout
the remainder of this paper, we shall assume that the parameters of the problem are such that
Q 7! Ji (q; Q) is strictly concave on [q, Q2 ].14 Observe that the strict concavity assumption
implies that Ji (0, Q) > 0 for all i and Q 2 (0, Q2 ), so the corresponding MPE is project-
completing.
       The following proposition establishes properties of each agent’s ideal project scope.

Proposition 3. Consider agent i’s optimal project scope Q when both agents choose their
e↵ort strategies based on Q.
  13
    The value of Qi is provided in Lemma 7 in the proof of Proposition 3.
  14
    This condition is satisfied in the symmetric case ↵11 = ↵22 (see Georgiadis et al. (2014) for details) and,
by a continuity argument, it is also satisfied for neighboring, asymmetric parameter values. While we do not
make a formal claim regarding the set of parameters values for which the condition is satisfied, numerical
simulations suggest that this condition holds generically.



                                                     10
                                                     1           2
     1. If the agents are symmetric (i.e.,         ↵1     =   ↵2 ),     then for all states q, their ideal project
                                                                          3↵i
         scopes are equal and given by Q1 (q) = Q2 (q) =                  2 ir .

                                                     1           2
     2. If the agents are asymmetric (i.e.,         ↵1    <     ↵2 ),   then:

          (a) The efficient agent prefers a strictly smaller project scope than the inefficient
               agent at all states up to Q2 , i.e., Q1 (q) < Q2 (q) for all Q2 .
          (b) The efficient agent’s ideal scope is strictly decreasing in the project state up to Q1 ,
               while the inefficient agent’s scope is strictly increasing for all q, i.e., Q01 (q) < 0
               for all q < Q1 and Q02 (q) > 0 for all q.
          (c) Agent i’s ideal is to complete the project immediately at all states greater than
               Qi , i.e., Qi (q) = q for all q      Qi .

       Part 1 asserts that when the agents are symmetric, they have identical preferences over
project scope, and these preferences are time-consistent.
       Part 2 characterizes each agent’s ideal project scope when the agents are asymmetric,
and is illustrated in Figure 1. Part 2 (a) asserts that the more efficient agent always prefers
a strictly smaller project scope than the less efficient agent for q < Q2 .15 Note that each
agent trades o↵ the bigger gross payo↵ from a project with a larger scope and the cost
associated with having to exert more e↵ort and wait longer until the project is completed.
Moreover, agent 1 not only always works harder than agent 2, but at every moment, his
discounted total cost remaining to complete the project normalized by his stake (along the
equilibrium path) is larger than that of agent 2.16 Therefore, it is intuitive that agent 1
prefers a smaller project scope than agent 2.
       Part 2 (b) shows that both agents are time-inconsistent with respect to their preferred
project scope: as the project progresses, agent 1’s optimal project scope becomes smaller,
whereas agent 2 would like to choose an ever larger project scope. To see the intuition
behind this result, recall that a01 (q)          a02 (q) > 0 for all q; that is, both agents increase their
e↵ort with progress, but the rate of increase is greater for agent 1 than it is for agent 2. This
implies that for a given project scope, the closer the project is to completion, the larger is
the share of the remaining e↵ort carried out by agent 1. Therefore, agent 1’s optimal project
scope decreases. The converse holds for agent 2, and as a result, his preferred project scope
becomes larger as the project progresses.
       Recall that Qi is the project scope such that agent i is indi↵erent between stopping
immediately (when q = Qi ) and continuing one instant longer. This is the value of the state
  15
       The agents’ ideal project scopes are equal for q       Q2 by Proposition 3.2 part (c).
  16
                                                                                                  R⌧           2
                                                                                                           rt a1 (qt ;Q)
      Formally and as implied by Proposition 2.2, for every t 2 [0, ⌧ ), we have              1
                                                                                             ↵1   t
                                                                                                       e          2
                                                                                                                         dt   >
     R ⌧ rt a22 (qt ;Q)
 2
↵2    t
        e        2
                        dt along the equilibrium path of the project.



                                                           11
at which Qi (q) hits the 45 line. Part 2 (c) shows that at every state q          Qi , agent i prefers
to stop immediately.

Agents working independently

This section characterizes each agent’s optimal project scope when he works alone on the
project. We use this to characterize the equilibrium with endogenous project scope in Section
4. Let Jbi (q, Q) denote agent i’s discounted payo↵ function when he works alone on the
project, the project scope is Q, and he receives ↵i Q upon completion.17 We define agent i’s
optimal project scope as
                                                      n          o
                                     b i (q) = arg max Jbi (q; Q) .
                                     Q
                                                   Q q

                                  b i (q).
The following lemma characterizes Q

Lemma 1. Suppose that agent i works alone and he receives ↵i Q upon completion of a
project with scope Q. Then his optimal project scope satisfies
                                     b i (q) = ↵i ,
                                     Q
                                              2r i
for all q      ↵i                     b i (q) = q. Moreover, for all q,
               2r i ,   and otherwise, Q
                                     b 2 (q)  Q
                                     Q         b 1 (q)  Q1 (q)  Q2 (q) .

      Lemma 1 asserts that if an agent works solo, then his preferences over the scope are
time-consistent (as long as he does not want to stop immediately). As such, we will abuse
notation and write Qb i = ↵i .
                                2r   i
      Intuitively, when the agent works alone, he bears the entire cost to complete the project,
in contrast to the case in which the two agents work jointly. The second part of this lemma
rank-orders the agents’ ideal project scopes. If an agent works in isolation, then he cannot
rely on the other to carry out any part of the project, and therefore the less efficient agent
prefers a smaller project scope than the more efficient one. Last, it is intuitive that the more
efficient agent’s ideal project scope is larger when he works with the other agent relative to
when he works alone.

3.3      Social Optimum
To conclude this section, we consider a social planner choosing the project scope that
maximizes the sum of the agents’ discounted payo↵s, conditional on the agents choosing
e↵ort strategically. For this analysis, we assume that the social planner cannot coerce the
 17
      The value of Jbi (q; Q) is given in the proof of Lemma 1 in the Appendix.




                                                      12
agents to exert e↵ort, but she can dictate the state at which the project is completed.18 Let

                                                          Q⇤ (q) = arg max {J1 (q; Q) + J2 (q; Q)}
                                                                               Q q

denote the project scope that maximizes the agents’ total discounted payo↵.

Lemma 2. The project scope that maximizes the agents’ total discounted payo↵ satisfies
Q⇤ (q) 2 (Q1 (q) , Q2 (q)).

         Lemma 2 shows that the social planner’s optimal project scope Q⇤ (q) lies between the
agents’ optimal project scopes for every state of the project. This is intuitive, since she
maximizes the sum of the agents’ payo↵s. Note that in general, Q⇤ (q) is dependent on
q; i.e., the social planner’s optimal project scope is also time-inconsistent. We illustrate
Proposition 3, and Lemmas 1 and 2 in Figure 1 below.
                                                                      α 1 = 0.5, α 2 = 0.5 ,γ1 = 0.5, γ2 = 1, r= 0.1
                                             20
                                                                                                                                  Q1 (q)
                                                                                                                                  Q2 (q)
                                             18                                                                                   Q∗ (q)
                                                                                                                                  45◦
                                                                                                                                  Q̂1
                                             16
                                                                                                                                  Q̂2


                                             14
                     Optimal Project Scope




                                             12


                                             10


                                              8


                                              6


                                              4


                                              2

                                                           Q̂2       Q̂1              Q1                                Q2
                                              0
                                                  0   2          4         6     8         10         12        14     16    18            20
                                                                                            q


                               Figure 1: Agents’ and social planner’s ideal project scope



4         Endogenous Project Scope
We now allow agents to choose the project scope via a collective choice institution. The
project scope in this section is thus endogenous, in contrast to the analysis in Section 3. In
    18
    This implies that the social planner is unable to completely overcome the free-rider problem. We consider
the benchmark in which the social planner chooses both the agents’ e↵ort levels, and the project scope in
Appendix B.2. However, as it is unlikely that a social planner can coerce agents to exert a specific amount of
e↵ort, we use the result in the following lemma as the appropriate benchmark.



                                                                                        13
Section 4.1 and 4.2, we characterize the MPE under dictatorship and unanimity, respectively,
while in Section 4.3 we discuss the implications for real authority and welfare. Whenever
multiple equilibria exist, we shall focus on the Pareto-efficient ones (i.e., equilibrium outcomes
such that in no other equilibrium outcome can a party get a strictly larger ex-ante payo↵
without a reduction of the other party’s payo↵).

4.1      Dictatorship
In this section, one of the two agents, denoted agent i, has dictatorship rights. The other
agent, agent j, can contribute to the project, but has no formal authority to end it. We
consider that the dictator can either commit to the project scope or not.
       We enrich the baseline model of Section 2 by defining a strategy for agent i (the dictator)
to be a pair of maps {ai (q, Q), ✓i (q)}, where q 2 R+ , Q 2 R+ [ { 1}, and Q =               1 denotes
the case in which the project scope has not yet been decided yet.19 The function ai (q, Q)
gives the dictator’s e↵ort level in state q when project scope Q has been decided, where
Q=        1 represents the case in which a decision about the project scope is yet to be made.
The value ✓i (q) gives the dictator’s choice of project scope in state q, which applies under
the assumption that no project scope has been committed to before state q. We set by
convention ✓i (q) =     1 if the dictator does not yet wish to commit to a project scope at state
q, and ✓i (q)     q otherwise. Similarly, a strategy for agent j 6= i is a map aj (q, Q) associated
with his e↵ort level in state q and the project scope decided by the dictator Q (or Q =               1 if
a decision has not yet been made). Notice that each agent’s strategy conditions only on
the payo↵-relevant variables q and Q, and hence they are Markov in the sense of Maskin &
Tirole (2001).

Dictatorship with Commitment

We first consider dictatorship with commitment. In this institution, the dictator can at any
time announce a particular project scope, and, following this announcement, the project
scope is set once and for all. Therefore, at every state q before some project scope Q has
been committed to, the dictator chooses ✓i (q) 2 { 1} [ [q, 1). After a project scope has
been set, it is definitive, so ✓i (·) becomes obsolete.
       After a project scope Q has been committed to, it is completed and each agent obtains
his reward as soon as the cumulative contributions reach Q. If the agents do not make
sufficient contributions, then the project is never completed: both agents incur the cost
of their e↵ort, but neither gets any reward. The project cannot be completed before the
dictator announces a project scope.
  19
    Before the project scope has been decided, in equilibrium, the agents correctly anticipate the project
scope that will be implemented, and choose their e↵ort levels optimally.


                                                   14
       The following proposition characterizes the equilibrium. Under commitment, each agent
finds it optimal to impose his ideal project scope. The time inconsistency of the dictator’s
preferences implies that the scope is always chosen at the beginning of the project.

Proposition 4. Under dictatorship with commitment, there exists a unique MPE in which
agent i commits to his ex-ante ideal project scope Qi (0), and the project is completed.

Dictatorship without Commitment

We now consider dictatorship without commitment. In this case, the dictator does not have
the ability to credibly commit to a particular project scope, so at every instant, he must
decide whether to complete the project immediately or continue one more instant. Formally,
at every state q while the project is in progress, the dictator chooses ✓i (q) 2 { 1, q}.20 Note
that in contrast to the commitment case, the strategies no longer condition on any agreed
upon project scope Q, as no agreement on the project scope is reached before the project
is completed. As soon as the project is completed, both agents collect their payo↵s.The
following Proposition characterizes the MPE.

Proposition 5. Under dictatorship without commitment, if agent 1 (i.e., the efficient agent)
is the dictator, then there exists a unique MPE, and scope Q = Q1 is implemented. If agent
2 is the dictator, then any Q 2 [Q1 (0), Q2 (0)] can be part of an MPE.

    We provide a heuristic proof, which is useful for understanding the intuition for this
result. First, recall from Lemma 1 that Q b2 < Q b 1 < Q1 < Q2 . Assume that agent i is
                        b i , Qi ), and conjecture the following strategies. Agent i stops the
dictator, fix some Q 2 (Q
project immediately when q          Q; i.e., he chooses ✓i (q) = q for all q        Q, and ✓i (q) =     1
otherwise. For all q < Q, both agents exert e↵ort according to the MPE with fixed project
scope Q characterized in Proposition 1, and exert no e↵ort thereafter. We shall argue that
neither agent has an incentive to deviate, and hence these strategies constitute an MPE.
Notice that the agents’ e↵orts constitute an MPE for a fixed project scope Q, so they have
no incentive to exert more or less e↵ort at any q < Q. Because Q  Qi , agent i has no
incentive to stop the project at any q < Q. Moreover, anticipating that he will contribute
alone to the project at any q          Q, and noting that Q           Q̂i , agent i cannot benefit by
completing the project at any state greater than Q.
       Finally, observe that both agents’ (ex-ante) payo↵s increase (decrease) in the project
scope for all Q < Q1 (0) (Q > Q2 (0)). Therefore, if agent 1 is the dictator, then there
  20
    Any announcement of project scope other than the current state cannot be committed to. Thus any
announcement by agent i other than the current state is ignored by agent j in equilibrium. Thus, agent i’s
strategy collapses to an announcement to complete the project immediately, or keep working.




                                                   15
exists a unique Pareto-efficient MPE in which Q = Q1 . If agent 2 is the dictator, then any
Q 2 [Q1 (0), Q2 (0)] can be part of a Pareto-efficient MPE.
       Notice that because the agents have conflicting preferences on [Q1 , Q2 ] (i.e., agent 1
prefers to complete the project, whereas agent 2 prefers to continue), the Pareto-efficient
MPE are also renegotiation-proof.

4.2       Unanimity
In this section, we consider the case in which both agents must agree on the project scope.
One of the agents, whom we denote by i, is (exogenously) chosen to be the agenda setter,
and he has the right to make proposals for the project scope. The other agent (agent j) must
respond to the agenda setter’s proposals by either accepting or rejecting each proposal.21 If
a proposal is rejected, then no decision is made about the project scope at that time. The
project cannot be completed until a project scope has been agreed to.
       A strategy for agent i (the agenda setter) is a pair of maps {ai (q, Q), ✓i (q)} defined for
q 2 R+ and Q 2 R+ [ { 1}. Here, ai (q, Q) denotes the e↵ort level of the agenda setter
when the project state is q and the project scope agreed upon is Q; by convention, ai (q, 1)
denotes his e↵ort level when no agreement has been reached yet. The value of ✓i (q) is the
project scope proposed by the agenda setter in project state q; by convention, ✓i (q) =          1
if the agent does not make a proposal at state q. Similarly, the map aj (q, Q) denotes the
e↵ort level in state q when project scope Q has been agreed upon; by convention, Q =           1 if
no agreement has been reached yet. The map Yj (q, Q) is the acceptance strategy of agent j
if agent i proposes project scope Q at state q, where Yj (q, Q) = 1 if agent j accepts, and
Yj (q, Q) = 0 if he rejects.

Unanimity with Commitment

We first consider the case in which the agents can commit to a decision about the project
scope. At any instant, the agenda setter can propose a project scope. Upon proposal, the
other agent must decide to either accept or reject the o↵er. If he accepts, then the project
scope agreed upon is set once and for all, and cannot be changed. From that instant onwards,
the agenda setter stops making proposals, so {✓i (·), Yj (·)} become obsolete. The agents may
continue to work on the project, and the project is completed and the agents collect their
payo↵s if and only if the state reaches the agreed upon project scope. If agent j rejects the
proposal, then no project scope is decided upon, and the agenda setter may continue to
make further proposals.
  21
       The set of equilibrium project scopes is independent of who is the agenda-setter.




                                                       16
    The following Proposition characterizes the set of MPE for the game in which both
agents must agree to a particular project scope, and they can commit ex-ante.

Proposition 6. Under unanimity with commitment, the project scope is agreed to at the
beginning of the project, and any Q 2 [Q1 (0), Q2 (0)] can be part of an MPE.

    In other words, the project scope is decided at the outset, and it lies between the agents’
ideal project scopes.

Unanimity without Commitment

Now suppose that the agenda setter cannot commit to a future project scope. Given the
current state q, the agenda setter either proposes to complete the project immediately, or
he does not make any proposal; i.e., ✓i (q) 2 { 1, q}. The following Proposition shows that
without commitment, unanimity generates the same set of equilibria as the game when the
inefficient agent is the dictator.

Proposition 7. Without commitment, under unanimity, the set of MPE outcomes are
the same as when agent 2 (i.e., the inefficient agent) is the dictator. That is, any Q 2
[Q1 (0), Q2 (0)] can be part of an MPE.

    Recall from Proposition 3 that agent 2 always prefers a larger project scope than agent
1 (i.e., Q2 (q)   Q1 (q) for all q). Therefore, at any state q such that agent 2 would like to
complete the project immediately, agent 1 wants to do so as well, but the opposite is not
true. Because both agents must agree to complete the project, e↵ectively, it is agent 2 who
has the decision rights over the project scope.
    Note that there is another institution wherein at every moment, the agents must both
agree to continue the project. By a symmetric argument, the set of MPE outcomes are the
same as when agent 1 is the dictator; i.e., there exists a unique MPE in which Q = Q1 is
implemented. However, to remain consistent with the previous cases analyzed, we focus on
the institution in which both agents must agree to stop the project.

4.3    Implications
In this section, we elaborate on two implications of our results. First, we seek to understand
how closely the equilibrium project scope is aligned with each agent’s preferences, or
equivalently, which agent has “real authority” over the scope of the project. Second, we
examine the welfare implications associated with each collective choice institution.




                                              17
Real Authority

Naturally, institutions can enforce an agent’s authority. However, the scope that is eventually
implemented remains an equilibrium outcome, and thus the agent with formal decision power
(e.g., the dictator) also has to account for his anticipation of the other agent’s actions. In
that sense, the scope implemented in equilibrium may be better aligned with the preferences
of the agent who does not exercise formal decision power.
   We model formal authority as the ability to determine the state at which the project
ends and rewards are collected. We consider formal authority to be enforceable by courts:
an agent has formal authority if he has the right to “sign the documents” or “pull the plug.”
It is determined by the collective choice institution. In the dictatorship setting, formal
authority goes to the agent chosen as the dictator. By convention, in the unanimity setting,
we say that the agents share formal authority. In contrast, the agent who has e↵ective
control over the project scope (i.e., he whose preferences are implemented in equilibrium), is
said to have real authority. We define real authority as follows.

Definition 1. Suppose the state is q, and a project scope has not been decided at any q̃ < q.
Agent i has real authority if either:

   1. The project scope Q is decided at q and Q = Qi (q); or,

   2. The project scope Q is not decided at q and Qi (q) > q.

   Note that this definition applies only until a project scope is committed to. After the
project scope has been decided, the game becomes one of dynamic contributions with a
fixed, exogenous scope, and the concept of real authority is no longer relevant.
   Our notions of real and formal authority are much like those described in Aghion & Tirole
(1997). As pointed out in Aghion & Tirole (1997), the agent endowed with formal authority
is not necessarily able to control the project. For example, consider a developed country
assisting a developing country to construct a large infrastructure project. The project,
being carried out on the developing country’s soil, is subject to its laws and jurisdiction.
The developing country thus has formal authority over the project and can specify the
termination state, but it is not clear that the developing country does so at a state that is
its ideal scope, due to the incentives of the donor developed country.
   With commitment, the project scope is decided at the beginning of the project, and
whichever agent has formal authority (i.e., dictatorship rights), also has real authority. Under
unanimity, recall that any Q 2 [Q1 (0), Q2 (0)] can be part of an equilibrium, so depending
on which scope is implemented, either agent can have real authority, or neither.
   Without commitment, because the agents’ preferences over project scope are time-
inconsistent, real authority has a temporal component, and therefore richer implications.

                                              18
The following remark elaborates.

Remark 1. Consider the case without commitment. For all q < Q1 , the agents share real
authority. For q    Q1 :

   1. If agent 1 is dictator, then he has real authority at the completion state q = Q1 .

   2. If agent 2 is dictator (or under unanimity) and Q 2 [Q1 (0), Q2 (0)] is implemented,
                                            ⇥
      then he has real authority for all q 2 Q1 , Q . However, agent 1 has real authority at
      the completion state Q.

   First note that for all q < Q1 , both agents prefer to continue the project. Thus, the
                                                            ⇥      ⇤
domain in which the agents have conflicting preferences is Q1 , Q2 . The main takeaway
from this remark is that if the efficient agent is dictator, then he completes the project at
his ideal project scope, so he has real authority at the completion state Q1 . In contrast,
when the inefficient agent is the dictator (or under unanimity), the inefficient agent has real
authority while the project is ongoing (since he prefers to continue, whereas the efficient
agent would like to complete the project immediately), but his real authority eventually
“runs out”, and upon completion, it is the efficient agent who has real authority.
    This may also help explain why it is often the case that agreements formally governed
by unanimity still appear to be heavily influenced by large contributors. These large donors
are the more efficient agents, who contribute more to the public project and hence have the
incentive to stop the project before the inefficient agent.

Welfare

Finally, we discuss the welfare implications associated with each collective choice institution.
In particular, we are interested in the question — which institutions can maximize total
welfare. The following remark summarizes.

Remark 2. With commitment, the social planner’s ex-ante ideal project scope can be
implemented only with unanimity. Without commitment, the social planner’s project scope
can be implemented if the inefficient agent is dictator or with unanimity.

    First, notice that these are possibility results. Because in some cases, multiple MPE exist,
this is the best one can hope for. The main takeaway is that from a welfare perspective,
it may be desirable to give the weaker party (i.e., the inefficient agent) formal authority,
because the stronger party obtains real authority in equilibrium. If instead the efficient agent
is conferred formal authority, then because he does not internalize the positive externality
associated with a larger project scope, total welfare will be lower.



                                              19
5         Extensions
In this section, we extend our model in two directions. First, we allow the agents to use
monetary transfers in exchange for (a) implementing a particular project scope, or (b) re-
allocating the shares {↵1 , ↵2 }. Second, we consider the case in which the project progresses
stochastically.

5.1         Transfers
So far we have assumed that each agent’s project stake ↵i is exogenous, and transfers
are not permitted. These are reasonable assumptions if agents are liquidity constrained.
However, if transfers are available, then there are various ways to mitigate the inefficiencies
associated with the collective choice problem. Our objective in this section is to shed light
on how transfers can be useful for improving the efficiency properties of the collective choice
institutions. We consider that agents choose e↵ort levels strategically, so free-riding still
occurs. We look at two types of transfers. First, we discuss the possibility that the agents
can make lump-sum transfers at the beginning of the game to directly influence the project
scope that is implemented. Second, we consider the case in which the agents can bargain
over the allocation of shares in the project in exchange for transfers. In both cases, we
assume that the agents commit to the project scope, transfers, and reallocation of shares at
the outset of the game.

Transfers contingent on project scope

Let us consider the case in which one of the agents is dictator, and he can commit to a
particular project scope.22 Assume that agent 1 is dictator and makes a take-it-or-leave-it
o↵er to agent 2, which specifies a transfer in exchange for committing to some project scope
Q. Then agent 1 solves the following problem:

                                    max          J1 (0; Q)     T
                                  Q 0, T 2R
                                        s.t.     J2 (0; Q) + T      J2 (0; Q1 (0)) .

Put in words, agent 1 chooses the project scope and the corresponding transfer to maximize
his ex-ante discounted payo↵, subject to agent 2 obtaining a payo↵ that is at least as great
as his payo↵ if he were to reject agent 1’s o↵er, in which case agent 1 would commit to
the status quo project scope Q1 (0), and no transfer would be made. Because transfers are
unlimited, the constraint binds in the optimal solution, and the problem reduces to

                                max {J1 (0; Q) + J2 (0; Q)          J2 (0; Q1 (0))} .
                                 Q 0

    22
         The analysis for the other cases is similar, and yields the same insights.


                                                          20
Note that the optimal choice of Q maximizes total surplus. This is intuitive: because the
agents have complete and symmetric information, bargaining is efficient. Moreover, it is
straightforward to verify that the same result holds under any one-shot bargaining protocol
irrespective of which agent has dictatorship rights, and for any initial status quo.23

Transfers contingent on reallocation of shares

We now consider ↵1 + ↵2 = 1, so the project stakes can be interpreted as project shares.
We consider an extension of the model in which, at the outset, the agents start with an
exogenous allocation of shares and then engage in a bargaining game in which shares can be
reallocated in exchange for a transfer. After the re-allocation of shares, the collective choice
institution determines the choice of scope as given in Section 4. Note that the allocation
of shares influences the agents’ incentives and consequently the equilibrium project scope.
Because this is a game with complete information, the agents reallocate the shares so as to
maximize the ex-ante total discounted surplus, taking the collective choice institution as
given. For the cases in which the Pareto-efficient MPE is not unique, we further refine the
MPE to the one in which total surplus is maximal.24
       Based on the analysis of Section 4, there are three cases to consider:

   1. Agent i is dictator, for i 2 {1, 2}, and he has the ability to commit. As such, he
         commits to Q = Qi (0) at the outset, by Proposition 4.

   2. Agent 1 is dictator, but he is unable to commit. In this case, the project is completed
         at state Q1 , by Proposition 5.

   3. Agent 2 is dictator, but he is unable to commit, or decisions must be made unanimously,
         with or without commitment. In these cases, the equilibrium project scope is Q⇤ (0)
         by Propositions 5, 6, and 7, and the refinement to the total surplus-maximizing MPE.

We focus the analysis on the case in which agent 1 is dictator and can commit to a particular
project scope at the outset; the other cases lead to similar insights. To begin, let Q1 (0; ↵)
denote the (unique) equilibrium project scope when agent 1 is dictator and has the ability
to commit, conditional on the shares {↵1 , 1          ↵1 }. Assume that agent 1 makes a take-it-or-
leave-it o↵er to agent 2, which specifies a transfer in exchange for reallocating the parties’
shares from the status quo shares {↵1 , 1           ↵1 } to {↵1 , 1    ↵1 }. Let Ji (q; Q, ↵) denote the
  23
     One might also consider the case in which commitment is not possible. Because Q1 (q)  Q2 (q) for all q,
to influence the project scope at some state, agent 1 might o↵er a lump-sum transfer to agent 2 in exchange
for completing the project immediately, whereas agent 2 might o↵er flow transfers to agent 1 to extend the
scope of the project. This model is intractable, so we do not pursue it in the current paper.
  24
     This is the case under dictatorship without commitment, and unanimity with or without commitment.
Simulations indicate that the findings are robust to the equilibrium selection rule.



                                                    21
continuation value for agent i when the state is q, the chosen project scope is Q and the
chosen share to agent 1 is ↵. Then agent 1 solves the following problem:

                                  max                        J1 (0; Q1 (0; ↵1 ) , ↵1 )           T
                         ↵1 2[0,1], T 2R
                                          s.t.               J2 (0; Q1 (0; ↵1 ) , ↵1 ) + T                J2 (0; Q1 (0; ↵1 ) , ↵1 ) .

Because transfers are unlimited and each agent’s discounted payo↵ increases in his share,
the incentive compatibility constraint binds in the optimal solution, and so the problem
reduces to

             max {J1 (0; Q1 (0; ↵1 ) , ↵1 ) + J2 (0; Q1 (0; ↵1 ) , ↵1 )                                           J2 (0; Q1 (0; ↵1 ) , ↵1 )} .
          ↵1 2[0,1]

The optimal choice of ↵1 maximizes total surplus, conditional on the scope subsequently
selected by the collective choice institution. In all other cases, and under any one-shot
bargaining protocol, the agents will agree to re-allocate their shares to maximize total
surplus.
   The problem of optimally reallocating shares is analytically intractable, therefore we
find the solution numerically. Figure 2 below illustrates the share allocated to agent 1, as
a function of his e↵ort cost. Note that without commitment, both the case of unanimity
and the case in which agent 2 is dictator deliver the same result, and hence the result for
unanimity is omitted.
                                           γ2= 1, r= 0.2                                                                     γ2= 1, r= 0.2
          0.95                                                                                   0.95
                                                                             D1                                                                                       D1
                                                                             D2                                                                                       D2
           0.9                                                               U
                                                                                                  0.9


          0.85                                                                                   0.85


           0.8                                                                                    0.8


          0.75                                                                                   0.75
     α1




                                                                                             1
                                                                                             α




           0.7                                                                                    0.7


          0.65                                                                                   0.65


           0.6                                                                                    0.6


          0.55                                                                                   0.55


           0.5                                                                                    0.5
             0.1   0.2      0.3     0.4         0.5        0.6   0.7   0.8        0.9               0.1   0.2    0.3   0.4        0.5        0.6       0.7      0.8        0.9
                                                γ1                                                                                γ1



                           (a) Commitment                                                                       (b) No commitment

                                                      Figure 2: Agent 1’s optimal project share

   In all cases, it is optimal for agent 1, who is more productive (i.e.,                                                                    1     <     2 ),   to possess
the majority of the shares. Moreover, his optimal allocation decreases as his e↵ort costs
increase, i.e., as he becomes less productive. In other words, if one agent is substantially
more productive than the other, then the former should possess the vast majority of the
shares. Indeed, it is efficient to provide the stronger incentives to the more productive agent,
and the smaller the disparity in productivity between the agents, the smaller should be the


                                                                                        22
di↵erence in the shares that they possess.

5.2    Collective Choice under Uncertainty
To examine the robustness of our results, in this section, we consider the case in which the
project progresses stochastically according to

                                             dqt = (a1t + a2t ) dt + dZt ,

where Zt is a standard Brownian motion, and                          > 0 captures the degree of uncertainty
associated with the evolution of the project. We discuss the results for collective choice
under this form of uncertainty.
   As in the deterministic case studied in Section 3, we begin by establishing the existence
of an MPE with an exogenous project scope Q. In an MPE, each agent’s discounted payo↵
function satisfies
                                               [Ji0 (q)]2  1                  2
                                 rJi (q) =                + Ji0 (q) Jj0 (q) + Ji00 (q)
                                                  2 i       j                2
subject to the boundary conditions limq!                    1 Ji (q)      = 0 and Ji (Q) = ↵i Q for each i. It
follows from Georgiadis (2015) that for any project scope Q, an MPE exists and satisfies
Ji (q) > 0, Ji0 (q) > 0, ai (q) > 0 and a0i (q) > 0 for all i and q. This is the analog of
Proposition 1 in the case of uncertainty.
   We next establish the key properties of the MPE with exogenous project scope for
asymmetric agents.
                                                                                                    1        2
Proposition 8. Consider the model with uncertainty, and suppose that                               ↵1   <   ↵2 .

   1. Agent 1 exerts higher e↵ort than agent 2 in every state, and agent 1’s e↵ort increases
      at a greater rate than agent 2’s. That is, a1 (q)                       a2 (q) and a0i (q)    a02 (q) for all q.

   2. Agent 1 obtains a lower discounted payo↵ normalized by project stake than agent 2.
                  J1 (q)         J2 (q)
      That is,     ↵1            ↵2      for all q.
              1        2                                    J1 (q)       J2 (q)
If instead   ↵1   =   ↵2 ,   then a1 (q) = a2 (q) and        ↵1      =    ↵2      for all q.

   Proposition 8 is the analog of Proposition 2 in the case of uncertainty. It asserts that,
under uncertainty, if agents are asymmetric, then the efficient agent exerts higher e↵ort at
every state of the project, and the efficient agent’s e↵ort increases at a higher rate than that
of the inefficient agent. Furthermore, the efficient agent achieves a lower discounted payo↵
(normalized by the stake ↵i ) at every state of the project.
   As for the agents’ preferences over project scopes, while we are unable to prove the
counterpart of the results in Section 3.2, numerical computations suggest that they continue
to hold. This is not surprising given the result in Proposition 8 and because the intuition for

                                                            23
the ordering and divergence of preferences is identical to that for the case without uncertainty.
An example is illustrated in Figure 3.
                                                             σ= 1, α1= 0.5, α2= 0.5 ,γ1= 0.5, γ2= 1, r= 0.1
                                            20
                                                                                                                         Q1(q)
                                                                                                                         Q2(q)
                                            18
                                                                                                                         Q*(q)
                                                                                                                         45°
                                            16


                                            14
                    Optimal Project Scope




                                            12


                                            10


                                             8


                                             6


                                             4


                                             2

                                                                                 Q1                            Q2
                                             0
                                                 0   2   4    6          8        10         12        14     16    18           20
                                                                                  q




               Figure 3: Agent i’s ideal project scope Qi (q) with uncertainty

    As Figure 3 illustrates, the inefficient agent prefers a larger scope than the efficient agent
at every state, and furthermore, his ideal project scope increases over the course of the
project, whereas the efficient agent’s ideal project scope decreases. Moreover, for each agent,
there exists a threshold such that he prefers to complete the project immediately at every
state larger than that threshold.
    Notice that the results of Section 4 rely on the key properties of the preferences illustrated
in Figure 3. Conditional on these preferences, all results of Propositions 4–7 will hold.


6    Discussion
We study a dynamic game in which two heterogeneous agents make costly contributions
towards the completion of a public project. The scope (i.e., the size) of the project is
endogenous, and it can be decided by a predetermined collective choice institution at any
time.
    Three main takeaways arise from our analysis. First, due to free-riding incentives, the
agents’ preferences with respect to their ideal project scope are time-inconsistent, and the
more efficient agent prefers to implement a smaller project relative to the less efficient agent.
Second, absent the ability to commit to a decision about the project scope, if the efficient
agent has dictatorship rights, then he also has real authority of the project scope that is
implemented. In contrast, if the inefficient agent is the dictator or under unanimity, then

                                                                               24
real authority has a temporal component: for a duration of time, the dictator has real
authority, but it eventually runs out, and upon completion of the project, it is the efficient
agent who has real authority. Third, from a welfare perspective, it may be desirable to give
some formal authority to the inefficient agent (via dictatorship rights or unanimity).
   Finally, we suggest several directions for future research. A natural next step is to extend
some of our results to a model with an arbitrary number of players, and understand, first,
how incentives for e↵ort interact, and second, how di↵erent collective choice institutions
influence the project scope that is implemented in equilibrium. Notice that with even three
players, other collective choice institutions can be considered, such as majority voting. As
an example, Figure 4 illustrates each agent’s ideal project scope, as well as the socially
optimal project scope for a group of 4 agents. Similar to the 2-player case, the agents’




         Figure 4: Agents’ and social planner’s ideal project scopes with 4 agents.

preferences over project scope are time-inconsistent, and rank-ordered from most to least
efficient. Second, a richer contracting space may be considered, where each agent’s payo↵ is
conditioned both the project scope, and the completion time. Lastly, our model assumes
complete information. This aids tractability, but likely misses important e↵ects related to
learning about the project’s benefit and the agents’ e↵ort costs over time. For example, if an
agent’s cost of e↵ort is private information, then the efficient agent may have an incentive
to mimic the inefficient agent, thus contributing a smaller amount of e↵ort. This may lead
to a greater ideal project scope for the efficient agent, which will be welfare enhancing if the
efficient agent is the dictator, but the welfare implications are not immediate because the
distribution of work will likely be further away from that of the social planner.

                                              25
A      Proofs
A.1     Proof of Proposition 1
We first establish two Lemmas that will be used throughout the proof of this Proposition,
as well as in the proof of Proposition 3. We consider the benchmark game of Section 3 with
exogenous project scope Q.

Lemma 3. Let (J1 , J2 ) be a pair of well-behaved value functions associated with an MPE.
Then Ji (q) 2 [0, ↵i Q] and Ji0 (q)       0 for all i and q.

Proof of Lemma 3. Because each agent i can guarantee himself a payo↵ of zero by not
exerting any e↵ort, in any equilibrium, it must be the case that Ji (q)               0 for all q. Moreover,
because he receives reward ↵i Q upon completion of the project, he discounts time, and the
cost of e↵ort is nonnegative, his payo↵ satisfies Ji (q)  ↵i Q for all q. Next, suppose that
Ji0 (q ⇤ ) < 0 for some i and q ⇤ . Then agent i exerts zero e↵ort at q ⇤ , and it must be the
case that agent j 6= i also exerts zero e↵ort, because otherwise it implies Ji (q ⇤ ) < 0, which
cannot occur in equilibrium. Since both agents exert zero e↵ort at q ⇤ , the project is never
completed, and so J1 (q ⇤ ) = J2 (q ⇤ ) = 0. Therefore, for sufficiently small ✏ > 0, we have
Ji (q ⇤ + ✏) < 0, which is a contradiction, implying Ji0 (q)             0 for all i and q.

    Observe that dividing both sides of equation (3) by             i   the system of ODEs defined by (3)
subject to (2) can be rewritten as
                                                1 h e0 i2 e0
                                   rJei (q) =      J (q) + Ji (q) Jej0 (q)                                  (5)
                                                2 i
subject to Jei (Q) =    ↵i
                         i
                             Q for all i 2 {1, 2} and j 6= i. The following lemma derives an explicit
system of ODEs that is equivalent to the implicit form given in (5) of Section 3.

Lemma 4. Let (J1 , J2 ) be a pair of well-behaved value functions associated with an MPE,
and let Jei (q) = Ji (q)
                      i
                         . Then if, at state q, the project is completing, the following explicit
ODEs are satisfied on the range (q, Q):25
           r r q                                     r r q
             r                                        r
    Je1 =
       0
                 2 Je12 + Je22 Je1 Je2 + Je1 + Je2 +    2 Je12 + Je22               Je1 Je2   Je1 + Je2 ,
             6                                        2
           r r q                                     r r q
             r                                        r
    Je20 =       2 Je12 + Je22 Je1 Je2 + Je1 + Je2      2 Je12 + Je22               Je1 Je2   Je1 + Je2 .
             6                                        2
Proof of Lemma 4. In an MPE in which the project is completing at state q, Je10 + Je20 > 0 on
[q, Q) as otherwise both agents put zero e↵ort at some intermediary state and the project is
not completed.
  25
     We say that the project is completing at state q to indicate that if the state is q, then the project will
be completed. In contrast, we say that the project is completed at state Q to indicate that state Q is the
termination state.


                                                      26
    Using (5), subtracting Je2 from Je1 and adding Je2 to Je1 yields
                                               1 e0
                            r(Je1    Je2 )      (J + Je20 )(Je10 Je20 ) = 0 , and
                                               2 1
                                                       1 e0
                                         r(Je1 + Je2 )    (J + Je20 )2 = Je10 Je20 ,
                                                       2 1
respectively, where for notational simplicity we drop the argument q. Letting G = Je1 + Je2
and F = Je1 Je2 , these equations can be rewritten as
                                     1 0 0
                              rF       F G =0
                                     2
                                    1 0 2 1 0 2 1 0 2
                              rG      (G ) = (G )        (F ) .
                                    2         4        4
                                                       2rF
    From the first equation we have F 0 =               G0   (and recall that we have assumed G0 > 0),
while the second equation, after plugging in the value of F 0 , becomes
                                             1 0 2 1 0 2                     F2
                                    rG         (G ) = (G )             r2          ,
                                             2       4                      (G0 )2
    This equation is quadratic in (G0 )2 , and noting by Lemma 3 that in any project-completing
MPE we have G0 > 0 on [0, Q], the unique strictly positive root is
                                                    r q
            0 2   2r ⇣p 2         2
                                       ⌘
                                                 0     2r p 2
          (G ) =         G + 3F + G =) G =                    G + 3F 2 + G .
                  3                                     3
Since G0 > 0 on the interval of interest, we have
                                 p                      qp
              0  2rF               6rF            0
                                                    p
            F =        = pp                   =) F = 2r   G2 + 3F 2                       G.
                  G0            2      2
                              G + 3F + G
By using that Je1 =   1
                      2   (G + F ) and Je2 =       1
                                                   2   (G    F ), we obtain the desired expressions.

                                                              Ji (q)
Existence.       Fix some Q > 0, and let Jei (q) =               i
                                                                       . As in Lemma 4, we note that the
system of ODEs of Section 3 defined by (3) subject to (2) can be rewritten as
                                          1 h e0 i2 e0
                               rJei (q) =    J (q) + Ji (q) Jej0 (q)                        (6)
                                          2 i
subject to Jei (Q) = ↵ii Q for all i 2 {1, 2} and j 6= i. If a solution to this system of ODEs
exists and Je0 (q) 0 for all i and q, then it constitutes an MPE, and each agent i’s e↵ort
             i
level satisfies ai (q) = Jei0 (q).
                                ⇣  n     o⌘
Lemma 5. For every ✏ 2 0, mini ↵ii Q , there exists some q✏ < Q such that there exists
                      ⇣        ⌘
a unique solution Je1 , Je2 to the system of ODEs on [q✏ , Q] that satisfies Jei ✏ on that
interval for all i.

Proof of Lemma 5. This proof follows the proof of Lemma 4 in Cvitanić & Georgiadis (2016)



                                                        27
closely. It follows from Lemma 4 above that we can write (3) as
                                            ⇣                 ⌘
                               Jei0 (q) = Hi Je1 (q) , Je2 (q) ,                                                            (7)

with
                      r q                                     r q
                       r   p                                   r  p
          H1 (x, y) =     2 x2 + y 2             xy + x + y +    2 x2 + y 2                                  xy    x + y,
                       6                                       2
                      r q                                     r q
                       r   p                                   r  p
          H2 (x, y) =     2 x2 + y 2             xy + x + y      2 x2 + y 2                                  xy    x + y.
                       6                                       2
    For given ✏ > 0, let
                                      MH = max               max↵          Hi (x1 , x2 ) .
                                                 i       ✏xi        iQ
                                                                      i

Let us choose q✏ < Q sufficiently large such that, for all i,
                                  ↵i
                                     Q (Q q✏ ) MH ✏.
                                             i

Then, define        q=   Q q✏
                          N     and functions JeiN by Euler iterations (see, for example, Atkinson
et al. (2011)). Going backwards from Q,
                                                           ↵i
                                                 JeiN (Q) = Q
                                                                           i
                                                                               ✓                        ◆
                                                     ↵i                            ↵1         ↵2
                             JeiN (Q     q) =                Q         qHi              Q,          Q
                                                         i                          1           2

             JeiN (Q    2 q) = JiN (Q     q)                  qHi J1N (Q                     q) , . . . , JnN (Q    q)
                             ✓            ◆
               ↵i              ↵1    ↵2
          =         Q    qHi      Q,    Q                    qHi J1N (Q                  q) , . . . , JnN (Q       q) ,
                i                 1      2

and so on, until JeiN (Q N q) = Jei (q✏ ). We then complete the definition of function
JeiN by making it piecewise linear between the points Q k q, k = 1, . . . , N . Note
from the assumption on Q q✏ that JeN (Q k q)         ✏, for all k = 1, . . . , N . Since the
                                                     i
Hi ’s are continuously
                 h      di↵erentiable,
                          i h       i they are Lipschitz continuous on the 2 dimensional
                     ↵1         ↵2
bounded domain ✏, 1 Q ⇥ ✏, 2 Q . Therefore, following standard arguments, the sequence
n oN
 Jein      converges to a unique solution Jei of the system of ODEs, and we have Jei (q) > ✏
       n=1
for all q 2 [q✏ , Q].

    Let

                                                 q = inf q✏ .                                                               (8)
                                                             ✏>0

Lemma 5 shows that the system of ODEs has a unique solution on [q✏ , Q] for every ✏ > 0.
                                               ⇤
Thus, there exists a unique solution on q, Q . Then, by standard optimal control arguments,
it follows that Jei (q) is the value function of agent i for every initial project value q > q.


                                                                 28
    To establish convexity, we di↵erentiate (5) with respect to q to obtain
                                 h                   i
                      rJei0 (q) = Je10 (q) + Je20 (q) Jei00 (q) + Jei0 (q) Jej00 (q) ,

or equivalently, in matrix form,
  "      # "                          #"       #    "       #                    2 ⇣ ⌘2 3
    Je10      Je10 + Je20      Je10      Je100        Je100           r              Je10
r         =                                      =)           = ⇣ ⌘2 ⇣ ⌘ 2       4 ⇣      ⌘2 5 . (9)
    Je20           Je20   Je10 + Je20    Je200        Je200      e0   e 0  e0 e0
                                                                 J1 + J2 + J1 J2     Je 0
                                                                                       2

Note that a0i (q) = Jei00 (q) > 0 if and only if Jei0 (q) > 0 for all i, or equivalently, if and only if
q > q.
    So far, we have shown that for any given Q, there exists some q < Q (which depends
on the choice of Q) such that the system of ODEs defined by (3) subject to (2) has a
                                   ⇤
project-completing solution on q, Q . In this solution, Ji (q) > 0, Ji0 (q) > 0, and a0i (q) > 0
for all i and q > q. On the other hand, Lemma 6 implies that Ji (q) = Ji0 (q) = 0 for all
q  q. Therefore, the game starting at q0 = 0 has a project-completing MPE if and only if
q < 0.
    As shown in Lemma 1 regarding the single agent case, for small enough Q, each agent
would be exerting e↵ort and completing the project by himself even if the other agent were
to exert no e↵ort. A fortiori, the project will complete in an equilibrium where both agents
can exert e↵ort. Hence, for Q small enough, the MPE is project-completing.
    As is shown in Section 3.2 regarding the socially optimal e↵ort levels, for large enough
Q, agents are better o↵ not starting the project. A fortiori, for such project scopes, the
project will not complete in an equilibrium where both agents can exert e↵ort. Hence, for Q
large enough, the MPE is not project-completing. Instead, neither agent puts any e↵ort on
the project and the project is never started.

Uniqueness.       We show that if (J1a , J2a ) and (J1b , J2b ) are two well-behaved solutions to (3)
subject to the boundary constraint (2) and subject to the constraint that each of the four
functions is nondecreasing, then (J1a , J2a ) = (J1b , J2b ) on the entire range [0, Q]. If the value
functions associated with some MPE are well-behaved, then they must satisfy (3) subject
to (2), and by Lemma 3 they must be nondecreasing. As the value functions uniquely pin
down the equilibrium actions, it implies that for any project scope Q there exists a unique
MPE with well-behaved solutions to the HJB equations.
    The following Lemma shows that at every state q, J1 (q) > 0 if and only if J2 (q) > 0.

Lemma 6. Let (J1 , J2 ) be a pair of well-behaved value functions associated with an MPE.
Then for every state q, J1 (q) > 0 if and only if J2 (q) > 0. Furthermore, if the project is
completing at state q, then both J10 and J20 are strictly positive on (q, Q).



                                                   29
Proof of Lemma 6. Fix agent i and let j denote the other agent. If Ji (q) > 0, then the
project is completing at state q. By Lemma 4, Je10 is bounded strictly above 0 on (q, Q), thus
J10 is also bounded strictly above zero on that range, and as an agent’s action is proportional
to the slope of the value function, agent 1’s e↵ort is also bounded strictly above 0 on the
range (q, Q). This implies that, if agent 2 chooses to exert no e↵ort on (q, Q), potentially
deviating from his equilibrium strategy, the project is still completed by agent 1—and thus
agent 2 makes a strictly positive discounted payo↵ at state q without exerting any e↵ort
from state q onwards. Agent 2’s equilibrium strategy provides at least as much payo↵ as
in the case of agent 2 exerting no e↵ort past state q, thus agent 2’s equilibrium discounted
payo↵ at state q, J2 (q) should be strictly positive. To summarize, J1 (q) > 0 and J2 (q) > 0.
Thus, if the project is completing at state q, then J1 (q) and J2 (q) are both strictly positive.
By Lemma 3, J10 (q)       0 and J20 (q)     0 and therefore J1 and J2 are strictly positive on (q, Q).
Equation (5) then implies that       J10   and J20 are strictly positive on (q, Q). Hence, if in some
MPE the project is completing at state q, both agents exert strictly positive e↵ort at all
states beyond q (and up to completion of the project).

    First, consider the case J1a (0) > 0. Then J2a (0) > 0 by Lemma 6. As J1a and J2a are
nondecreasing, it follows from Lemma 5 that (J1a , J2a ) = (J1b , J2b ) on the entire range [0, Q].
If instead J1b (0) > 0, the symmetric argument applies.
    Next consider the case J1a (0) = J1b (0) = 0, and let q a = sup{q             0 | J1a (q) = 0}. As
J1a (0) = 0 we have q a      0. The boundary condition (2) and the continuity of J1 implies
that   qa   < Q. Moreover, on the non-empty interval (q a , Q] we have J1a > 0, and thus by
Lemma 6, J1b > 0 on that same interval. Lemma 5 then implies that (J1a , J2a ) = (J1b , J2b ) on
every [q a + ✏, Q] for ✏ > 0, and thus that (J1a , J2a ) = (J1b , J2b ) on (q a , Q]. Now let us consider
the range [0, q a ]. By continuity of J1a we have J1a (q a ) = 0. As J1a is nondecreasing and
nonnegative, then J1a (q a ) = 0 implies that J1a = 0 on the interval [0, q a ]. As J1a (q) = 0 if and
only if J2a (q) = 0, we get that J2a = 0 on the interval [0, q0 ]. Thus, (J1a , J2a ) = 0 on [0, q a ].
    Similarly let q b = sup{q | J1b (q) = 0}. We have q b 2 [0, Q), and by a symmetric argument
(J1b , J2b ) = 0 on [0, q b ]. If q b < q a , then we get by Lemma 5 that (J1a , J2a ) = (J1b , J2b ) > 0
on (q b , Q], which contradicts (J1a , J2a ) = 0 on [0, q a ]. If instead q b > q a , then we get that
(J1a , J2a ) = (J1b , J2b ) > 0 on (q a , Q], which contradicts that (J1b , J2b ) = 0 on [0, q b ]. Hence
qa = qb.
    Altogether this implies that on the interval [0, q a ], (J1a , J2a ) = (J1b , J2b ) = 0, and on the
interval (q a , Q], (J1a , J2a ) = (J1b , J2b ) > 0. Hence the HJB equations define a unique value
function and thus a unique MPE. ⌅




                                                    30
A.2       Proof of Proposition 2
                                                                                      Ji (q)
First, we fix some Q > 0, and we use the normalization Jei (q) =                         i
                                                                                                as in the proof of
Proposition 1.
                                                 e (q) = Je1 (q) Je2 (q), and note that D
    To prove part 1, assume that ↵11 < ↵22 , let D                                       e (·)
                                               ⇣          ⌘
           e (q) = 0 for q  q and D
is smooth, D                        e (Q) = ↵1 ↵2 Q > 0, where q is given by (8), in
                                                 1      2

the proof of Proposition 1. Observe that either D   e 0 (q) > 0 for all q   0, or there exists
some q 2 [0, Q] such that De 0 (q) = 0. Suppose that the latter is the case. Then it follows
from (5) that De (q) = 0, which implies that D e (q) 0 for all q, and D e 0 (q) > (=) 0 if and
        e (q) > (=) 0. Therefore, D
only if D                          e 0 (q) 0, which implies that a1 (q) a2 (q) for all q 0.
Observe from equation (9) in the proof of Proposition 1, that Ji00 (q) = · (Ji0 (q))2 , where
 = r/[(Je0 )2 + (Je0 )2 + Je0 Je0 ], and note that ai (q) = Je0 (q). Moreover, we know from part
            1         2       1 2                                    i
1 of Proposition 2 that a1 (q)      a2 (q), which implies that J100 (q)                J200 (q), or equivalently,
a01 (q)   a02 (q) for all q   0.
     To prove part 2, note first the result for actions follows from the previous paragraph with
                                                                                       J1 (q)      J2 (q)
all weak inequalities replaced with strict inequalities. Let D (q) =                    ↵1          ↵2 ,    and note
that D (·) is smooth, D (q) = 0 for q sufficiently small, and D (Q) = 0. Therefore, either
D (q) = 0 for all q, or D (·) has an interior extreme point. Suppose that the former is true.
Then for all q, we have D (q) = D0 (q) = 0, which using (3) implies that
                                        ✓        ◆
                              [J10 (q)]2 ↵2 ↵1
                     rD (q) =                      = 0 =) J10 (q) = 0 .
                                 2↵12     2    1

However, this is a contradiction, and so the latter must be true. Then there exists some q
such that D0 (q) = 0. Using (3) and the fact that Ji0 (q)                 0 for all q and Ji0 (q) > 0 for some
q, this implies that D (q)  0. Therefore, D (q)  0 for all q, which completes the proof.
                                                                       e 0 (q) = 0 and D (q) = 0,
    Finally, if ↵1 = ↵2 , then it follows from the analysis above that D
                  1       2
                                            J1 (q)       J2 (q)
which implies that a1 (q) = a2 (q) and       ↵1      =    ↵2      for all q    0. ⌅

A.3       Proof of Proposition 3
                                        1        2
To prove part 1, first suppose that    ↵1   =   ↵2 .     In this case, we know from equation (4) that
each agent’s discounted payo↵ function satisfies
                                           "      s       #
                                       r i          6↵i Q
                           Ji (q; Q) =       q Q+           ,
                                        6            r i
                                                                                                        3↵i
and by maximizing Ji (q; Q) with respect to Q, we obtain that Q1 (q) = Q2 (q) =                         2r i   for all
q.

                                                           1        2
     To prove part 2, consider the case in which          ↵1   <   ↵2 .   This part of the proof comprises 3
steps. To begin, in the following lemma, we characterize the values Qi for i = 1, 2 that are

                                                     31
defined to be the project state that makes each agent i indi↵erent between terminating the
project at this state, and continuing the project one more instant.
                                                                       1                2
Lemma 7. Assume the agents are asymmetric, i.e.,                      ↵1       <       ↵2 .     The values of Q1 and Q2 are
unique and given by                              p
                                 q                    p
                                                   2/3 µ↵1 / 1
                                     Q1 = p           p ⇥
                                                          p    p ⇤2
                                            r↵1 / 1 + 12r   µ + 3⌫
and                              q               p    p
                                                   2/3 µ↵2 /                   2
                                  Q2 = p              p ⇥
                                                          p                        p            ⇤2
                                            r↵2 / 2 + 12r   µ                           3⌫
where                       s✓ ◆     ✓ ◆2
                              ↵1 2    ↵2                          ↵1 ↵2                 ↵1           ↵2
                         µ=2       +                                               +             +
                                        1            2             1       2                1         2

and                        s✓ ◆     ✓ ◆2
                             ↵1 2    ↵2                          ↵1 ↵2                  ↵1           ↵2
                        ⌫=2       +                                                             +         .
                                        1            2            1        2                1         2

Furthermore, Q1 < Q2 .
Proof of Lemma 7. Throughout this proof, we consider a project of a given scope Q. Let
ai (Q) denote the equilibrium e↵ort agent i exerts at the very end of the project, when the
terminal state is Q. Recall that, in equilibrium, the action of agent i at state q is given by

                                            ai (q) = Ji0 (q)/ i ,

and thus ai (Q) = Ji0 (Q)/   i   = Jei0 (Q). From Lemma 4 and noting that Jei (Q) = (↵i / i )Q, we
get
                                                 r
                                          rQ ⇣p      p ⌘
                                      a1 (Q) =   µ + 3⌫                                                                        (10)
                                           6
                                       r
                                          rQ ⇣p      p ⌘
                              a2 (Q) =           µ     3⌫ ,                                                                    (11)
                                           6
with µ and ⌫ defined as in the statement of the current lemma.
      For a project of scope Q, agent i gets value ↵i Q at the completion of the project, when
q = Q. If the project is instead of scope Q +                 Q (for small enough                             Q), and if the current
state is q = Q, there is a delay ✏ before the project is completed. To the first order in ✏, the
relationship    Q = (a1 (Q) + a2 (Q))✏ holds. Thus, to the first order in ✏, the net discounted
value of the project to agent i at state q = Q is
                                                                  r✏               i
                         ↵i [Q + (a1 (Q) + a2 (Q))✏] e                                 (ai (Q))2 ✏.
                                                                               2
      At project scope Q = Qi , the agent is indi↵erent between stopping the project now
(corresponding to a project scope Qi ) and waiting an instant later (corresponding to a

                                                         32
project scope Qi +             Q for an infinitesimal           Q). So to the first order,
                                                                                         r✏           i
                         ↵i Qi = ↵i (Qi + (a1 (Qi ) + a2 (Qi ))✏)e                                        (ai (Qi ))2 ✏.
                                                                                                   2
So:
                                                                                     i
                               ↵i (a1 (Qi ) + a2 (Qi ))        r↵i Qi                    (ai (Qi ))2 = 0.
                                                                                    2
Solving this equation for i = 1, 2 yields
     q              p p                       q            p p
                      2/3 µ↵1 / 1                            2/3 µ↵2 /                                                            2
       Q1 = p             p ⇥
                            r p      p ⇤2 and  Q2 = p           p ⇥
                                                                    p                                                                 p           ⇤2 .
               r↵1 / 1 + 12     µ + 3⌫                r↵2 / 2 + 12r   µ                                                                   3⌫
Note that                                   q         ⇣ ⌘            1 ⇥p                 p        ⇤2
                                             Q1   12 + ↵22                      µ             3⌫
                                            q   =     ⇣ ⌘            1 ⇥p                 p        ⇤2 .
                                             Q2   12 + ↵11                      µ+            3⌫

In particular, Q1 < Q2 if and only if the inequality
         ✓ ◆ 1/2 h                ✓ ◆1/2 ✓ ◆                                    1/2 ✓             ◆
          ↵2        p      p i       ↵1        ↵2                                         ↵2              1/2 h
                                                                                                                  p       p     i
                      µ + 3⌫                                                                                          µ       3⌫ > 0                     (12)
               2                                     1              2                         2
holds. Let
                     q         p                                      q                                           p
              f (x) = 1 + x + 2 1 + x2                    x and g(x) = 1                                  x+2      1 + x2             x.

Note that
        ✓          ◆                                  ✓        ◆✓           ◆        !                       ✓         ◆✓         ◆       !
                       1/2 h            p     i                                  1            p                                       1
              ↵2               p                          ↵1        ↵2                                            ↵1        ↵2
                                   µ+       3⌫ = f                                        +        3g
               2                                           1            2                                          1          2

and
          ✓        ◆                                  ✓        ◆✓        ◆          !                       ✓         ◆✓        ◆         !
                       1/2 h            p     i                                 1             p                                       1
              ↵2               p                          ↵1        ↵2                                          ↵1         ↵2
                                   µ        3⌫ = f                                                3g                                          .
               2                                           1         2                                            1         2
                                                                                   p               p
Since, by assumption, ↵1 /              1   < ↵2 / 2 , (12) is satisfied if [f (x)+ 3g(x)] x[f (x)   3g(x)] >
0 for every x 2 (0, 1). Note that, as f, g > 0 on (0, 1), so
                p                    p                     p                                                                    p
        [f (x) + 3g(x)] x[f (x)        3g(x)] x[f (x) + 3g(x)]                                                  x[f (x)             3g(x)]
                                                                 x[f (x) + g(x)]                          x[f (x)         g(x)]
                                                               = 2xg(x) > 0.

This establishes the inequality (12), and thus Q1 < Q2 .

      Equations (10) and (11) show that the agent’s action at time of termination is strictly
increasing with the project scope.

Lemma 8. The value Ji0 (Q; Q) is strictly increasing in Q. Furthermore Qi is the unique
solution to the equation in Q, Ji0 (Qi (Q) ; Qi (Q)) = ↵i .

                                                               33
Proof of Lemma 8. Consider agent i’s optimization problem given state q. We seek to find
                                                                                        @
the unique q such that q = arg maxQ             q   {Ji (q; Q)}. For such q, we have   @Q Ji (q; Q) q=Q      = 0.
Note that Ji (Q; Q) = ↵i Q, and totally di↵erentiating this with respect to Q yields
                                    dJi (Q; Q)                @Ji (q; Q)
                                               = Ji0 (Q; Q) +
                                        dQ                       @Q        q=Q

thus
                                                Ji0 (Q; Q) = ↵i .                                            (13)

By our assumption that Ji (q; Q) is strictly concave in Q for all q  Q  Q2 , it follows that
(13) is necessary and sufficient for a maximum.
     Noting that the explicit form of the HJB equations of Lemma 4 implies that Ji0 (Q; Q) =
          p
Ji0 (1; 1) Q, it follows that Ji0 (Q; Q) is strictly increasing in Q. Therefore, the solution to
(13) is unique.

Step 1:      We show that Q02 (q) 0 for all q Q1 .
       To begin, we di↵erentiate Jei (q; Q) in (5) with respect to Q to obtain

               r@Q Je1 (q; Q) = @Q a1 (q; Q) [a1 (q; Q) + a2 (q; Q)] + a1 (q; Q) @Q a2 (q; Q)
               r@Q Je2 (q; Q) = @Q a2 (q; Q) [a1 (q; Q) + a2 (q; Q)] + a2 (q; Q) @Q a1 (q; Q)
                                                                                                 @2 e
where we note @Q Jei (q; Q) = @Q
                               @ e
                                  Ji (q; Q), and where @Q ai (q; Q) = @Q Jei0 (q; Q) =          @Q @q Ji (q; Q),
and ai (q; Q) = Je0 (q; Q) = @ Jei (q; Q).26 Rearranging terms yields
                        i            @q

              (a1 + a2 )2 a1 a2                      ⇣       ⌘   ⇣       ⌘
                                (@Q a1 ) = (a1 + a2 ) @Q Je1   a1 @Q Je2            (14)
                       r
              (a1 a2 )2 + a1 a2                      ⇣       ⌘   ⇣       ⌘
                                (@Q a2 ) = (a1 + a2 ) @Q Je2   a2 @Q Je1 ,          (15)
                       r
where we drop the arguments q and Q for notational simplicity. Because ai , aj > 0, note
that (a1 + a2 )2            a1 a2 > 0 and (a1   a2 )2 + a1 a2 > 0. Recall Qi (q) is agent i’s ideal project
scope given the current state q. Then for all q < Qi (q) and for the smallest q such that
q = Qi (q), we have @ Jei (q; Qi (q)) = 0. Di↵erentiating this with respect to q yields
                              @Q

          @2                     @2 e                                                @Q ai (q; Qi (q))
              Jei (q; Qi (q)) +     Ji (q; Qi (q)) Q0i (q) = 0 =) Q0i (q) =                              .
        @Q @q                   @Q2                                                  @ 2 Jei (q; Qi (q))
                                                                                       Q

Since     2 Je (q; Q)
         @Q             < 0 (by our strict concavity assumption), it follows that Q0i (q)  0 if and
              i
only if @Q ai (q; Q)           0.
    Next, fix some qb 2 Q1 , Q2 . By the strict concavity of Jei (q; Q) in Q, it follows that
@Q Je1 (b       q )) < 0 and @Q Je2 (b
        q , Q2 (b                    q , Q2 (b
                                             q )) = 0; i.e., agent 1 would prefer to have completed
  26
    Note ai (q; Q) is distinct from agent strategies in the case of commitment ai (q, Q). Here ai (q; Q) denotes
agents’ actions in the MPE with exogenous project scope Q.


                                                         34
the project at a smaller project scope than Q2 (b
                                                q ), whereas agent 2 finds it optimal to
complete the project at Q2 (b
                            q ) (the latter statement being true by definition of Q2 (b
                                                                                      q )).
Using (15) it follows that @Q a2 (b       q )) > 0, which implies that Q02 (b
                                  q , Q2 (b                                 q ) > 0. Therefore,
Q02 (q) > 0 for all q 2 Q1 , Q2 and Q2 Q1 > Q1 , where the last inequality follows from the
facts that by assumption Je2 (q; Q) is strictly concave in Q for q  Q  Q2 and so it admits
a unique maximum, and that Je20 Q1 ; Q1 <         ↵2
                                                    2
                                                        , which implies that he prefers to continue
work on the project rather than complete it at Q1 .

Step 2:     We show that Q01 (q)  0  Q02 (q) for all q  Q1 . Moreover, Q01 (q) < 0 < Q02 (q)
for all q such that Q1 (q) < Q2 (q).
      Because Q2 Q1 > Q1 and Qi (·) is smooth, there exists some q        0 such that Q2 (q) >
                                                                          e
Q1 (q) for all q 2 q, Q1 . Pick some q in this interval, and note that @Q J1 (q, Q2 (q)) < 0 and
@Q Je2 (q, Q2 (q)) = 0, which together with (15) implies that @Q a2 (q, Q2 (q)) > 0. Similarly,
we have @Q Je1 (q, Q1 (q)) = 0 and @Q Je2 (q, Q1 (q)) > 0, which together with (14) implies that
@Q a1 (q, Q1 (q)) < 0. Therefore, Q01 (q) < 0 < Q02 (q) for all q 2 q, Q1 .
      Next, by way of contradiction, assume that there exists some q such that Q1 (q) > Q2 (q)
for some q < q. Because Qi (q) is smooth, by the intermediate value theorem, there exists
some qe such that Q1 (e q ) > Q2 (e
                                  q ) and at least one of the following statements is true:
  0
Q (e
  1
                0 q ) > 0. This implies that for such qe, we must have @Q Je1 (e
    q ) < 0 or Q (e
                  2                                                            q , Q2 (e
                                                                                       q )) > 0,
@Q Je2 (e       q )) = 0, @Q Je1 (e
        q , Q2 (e                         q )) = 0 and @Q Je2 (e
                                  q , Q1 (e                    q , Q1 (e
                                                                       q )) < 0. Then it follows from
(14) and (15) that @Q a1 (e
                          q , Q2 (e
                                  q )) > 0 and @Q a2 (e
                                                      q , Q1 (e
                                                              q )) < 0. This in turn implies
that Q01 (e
          q ) > 0 > Q02 (e
                         q ), which is a contradiction. Therefore, it must be the case that
Q2 (q)      Q1 (q) for all q, and therefore Q01 (q)  0 for all q  Q1 and Q02 (q)          0 for all
q  Q2 .

Step 3:     We show that there does not exist any q such that Q1 (q) = Q2 (q).
      First, we show that if there exists some q such that Q1 (q) = Q2 (q), then it must be
the case that Q1 (q) = Q2 (q) for all q  q. Suppose that the converse is true. Then by
the intermediate value theorem, there exists some qe such that Q1 (e
                                                                   q ) < Q2 (e
                                                                             q ) and at least
one of the following statements is true: either Q01 (eq ) > 0 or Q02 (e  q ) < 0. This implies that
for such qe, we must have @Q Je1 (e       q )) < 0, @Q Je2 (e
                                  q , Q2 (e                         q )) = 0, @Q Je1 (e
                                                            q , Q2 (e                 q , Q1 (e
                                                                                              q )) = 0
and @Q Je2 (e
            q , Q1 (e
                    q )) > 0. Then it follows from (14) and (15) that @Q a1 (e
                                                                             q , Q2 (e
                                                                                     q )) < 0 and
@Q a2 (e       q )) > 0. This in turn implies that Q01 (e
       q , Q1 (e                                        q ) < 0 < Q02 (e
                                                                       q ), which is a contradiction.
Therefore, if there exists some q such that Q1 (q) = Q2 (q), then Q1 (q) = Q2 (q) and
@Q a1 (q; Q) = @Q a2 (q; Q) = 0 for all q  q and Q = Q1 (q).
      Next, note that each agent’s normalized discounted payo↵ function can be written in




                                                 35
integral form as
                                                          Z        ⌧ (Q)                                  2
                                      r[⌧ (Q) t] ↵i                             r(s t) (ai (qs ; Q))
                   Jei (qt ; Q) = e                   Q                     e                                 ds .
                                                  i            t                                  2
Di↵erentiating this with respect to Q yields the first-order condition
                                                                Z ⌧ (Q)
             ↵i ⇥            ⇤                     (ai (Q; Q))2
e r[⌧ (Q) t]      1 rQ⌧ 0 (Q) e r[⌧ (Q) t] ⌧ 0 (Q)                      e r(s                                  t)
                                                                                                                    ai (qs ; Q) @Q ai (qs ; Q) ds = 0.
              i                                          2       t
                                                                                                                                   (16)
   Now, by way of contradiction, suppose there exists some q such that Q1 (q) = Q2 (q) = Q⇤ .
Then we have Q1 (q) = Q2 (q) and @Q a1 (q; Q⇤ ) = @Q a2 (q; Q⇤ ) = 0 for all q  q. Therefore,
fixing some q  q and Q⇤ = Q1 (q), it follows from (16) that
          ⇥               ⇤            1                            2
         2 1 rQ⇤ ⌧ 0 (Q⇤ ) = ⌧ 0 (Q⇤ ) (a1 (Q⇤ ; Q⇤ ))2 = ⌧ 0 (Q⇤ ) (a2 (Q⇤ ; Q⇤ ))2 .
                                      ↵1                           ↵2
Observe that @Q a1 (q; Q⇤ ) = @Q a2 (q; Q⇤ ) = 0, which implies that @Q [a1 (q; Q⇤ ) + a2 (q; Q⇤ )] =
0, and hence ⌧ 0 (Q⇤ ) > 0.           By assumption,                   1
                                                                                <     2
                                                             , and we shall now show that
                                                             ↵1             q       q↵2
           ⇤ ; Q⇤ ))2 > 2 (a (Q⇤ ; Q⇤ ))2 . Let              1 e               2 e
 1
↵1 (a 1 (Q             ↵2   2                         D (q; Q⇤ )
                                                      =     ↵1 J 1 (q; Q ⇤)             ⇤
                                                                              ↵ J2 (q; Q ), and
                                                                    ⇣q      q 2⌘
                                                                         ↵1   ↵2
note that D (q; Q⇤ ) = 0 for q sufficiently small, D (Q⇤ ; Q⇤ ) =         1     2
                                                                                   Q⇤ > 0, and
D (·; Q⇤ ) is smooth. Therefore, either D0 (q; Q⇤ ) > 0 for all q, or there exists some extreme
point z such that D0 (z; Q⇤ ) = 0. If the former is true, then D0 (Q⇤ ; Q⇤ ) > 0, and we obtain
the desired result. Now suppose that the latter is true. It follows from (5) that
                                   h              i2
                                     Je10 (z; Q⇤ ) ✓r ↵          ◆
                              ⇤                        1 2
                      rD (z; Q ) =                             1 < 0,
                                            2        ↵1 2
which implies that any extreme point z must satisfy D (z; Q⇤ ) < 0 < D (Q⇤ ; Q⇤ ), and hence
D0 (Q⇤ ; Q⇤ ) > 0. Therefore,          1
                                      ↵1 (a1 (Q
                                                  ⇤ ; Q⇤ ))2       >        2
                                                                           ↵2 (a2 (Q
                                                                                          ⇤ ; Q⇤ ))2 ,   which contradicts the
assumption that there exists some q such that Q1 (q) = Q2 (q).
   We complete the proof of Proposition 3. From Lemma 7, we know that Q1 < Q2 . Steps
1 and 2 show that Q01 (q)  0 for all q  Q1 and Q02 (q)                                    0 for all q  Q2 , respectively,
while step 3 shows that there exists no q < Q2 such that Q1 (q) = Q2 (q). This proves part
2(a). To see part 2(b), Step 3 shows that Q2 (q) > Q1 (q) for all q (i.e. q = 0), which together
with Step 2, implies that Q02 (q) > 0 > Q01 (q) for all q > 0. Finally, it follows from the strict
concavity of Ji (q; Q) in Q that Qi (q) = q for all q                           Qi , which completes the proof of part
2(c). ⌅

A.4    Proof of Lemma 1
First, we characterize each agent i’s e↵ort and payo↵ function when he works alone on the
project (and receives ↵i Q upon completion).
   Let Jbi (q; Q) be agent i’s discounted payo↵ at state q for a project of scope Q. By standard


                                                          36
arguments, under regularity conditions, the function Jbi (·; Q) satisfies the HJB equation
                                             n                          o
                          rJbi (q; Q) = max      ǎ2i + ǎi Jbi0 (q; Q)                  (17)
                                         ǎi   2
subject to the boundary condition

                                          Jbi (Q; Q) = ↵i Q.                                     (18)

   The game defined by (17) subject to the boundary condition
                                                          q (18) has a unique solution
       ⇤                                                     2↵i Q
on q, Q in which the project is completed, where q = Q        r i . Then agent i’s e↵ort
strategy and discounted payo↵ satisfies
                                                           !     s
                                                     2↵i Q
                             b
                             ai (q; Q) = r q Q +
                                                      r i
                                                     s         !2
                                          r   i         2↵ i Q
                         and Jbi (q; Q) =       q Q+              ,
                                            2            r i
respectively. Define                                 n          o
                                    b i (q) = arg max Jbi (q; Q) .
                                    Q
                                                 Q q

                                     b i (q) =
It is straightforward to verify that Q              ↵i                       b 2 (q) < Q
                                                                                       b 1 (q) follows
                                                   2r i .     The inequality Q
from the fact that by assumption ↵11 < ↵22 .
    Next, we show that Q  b 1 (q) < Q1 . Define b (q) = J1 q; Q1         Jb1 q; Q1 . Note that
J10 Q1 ; Q1 = ↵1 , b Q1 = 0, b (q) = 0 for sufficiently small q, and b (·) is smooth.
Therefore, either b (q) = 0 for all q, or it has an interior local extreme point. In either case,
there exists some z such that b 0 (z) = 0. Using (3) and the fact that, from the single agent
                           h          i2
HJB equation, rJb1 (q; Q) = Jb0 (q; Q) /(2 1 ), it follows that
                                1

                                             J10 z; Q1 J20 z; Q1
                                r b (z) =                             .
                                                          2

Because J10 q; Q1 J20 q; Q1 > 0 for at least some q, it follows that it cannot be the case
that b (q) = 0 for all q. Because J10 q; Q1 J20 q; Q1  0, it follows that any extreme point
z must satisfy b (z) 0, which together with the boundary conditions implies that b (q) 0
for all q. Therefore,⇣ b 0 Q1 < 0, which⌘   in turn implies that Jb10 Q1 ; Q1 > J10 Q1 ; Q1 = ↵1 .
By noting that Jb0 Q
                  1
                       b 1 (q) ; Q
                                 b 1 (q) = ↵1 and Jb0 (Q; Q) is strictly increasing in Q, it follows
                                                      1
     b 1 (q) < Q1 .
that Q
                                                b 1 (q) < Q1 (q) for all q, and we know from
   Since Q01 (q) < 0 for all q, it follows that Q
Proposition 3 that Q1 (q) < Q2 (q) for all q. ⌅




                                                 37
A.5      Proof of Lemma 2
Let S (q; Q) = J1 (q; Q) + J2 (q; Q). Because, by assumption, Ji (q; Q) is strictly concave
in Q for all i and q  Q  Q2 , it follows that S (q; Q) is also strictly concave in Q for all
                                                  @                                          @
q  Q  Q2 . Therefore, Q⇤ (q) will satisfy      @Q S   (q; Q) = 0 at Q = Q⇤ (q) and        @Q S   (q; Q)
is strictly decreasing in Q for all q. We know from Proposition 3 that Q1 (q) < Q2 (q)
                                                   @                         @
for all q  Q2 . Moreover, we know that (i)       @Q J1 (q; Q)      0 and   @Q J2 (q; Q)   > 0 and so
 @                                                @                          @
@Q S   (q; Q) > 0 for all q  Q1 (q), and (ii)   @Q J1 (q; Q) <    0 and    @Q J2 (q; Q)    0 and so
 @                                               @
@Q S   (q; Q) < 0 for all q   Q2 (q). Because   @Q S   (q; Q) is strictly decreasing in Q, it follows
that    @
       @Q S   (q; Q) = 0 for some Q 2 (Q1 (q) , Q2 (q)). ⌅

A.6      Proof of Proposition 4
We first construct a project-completing MPE with project scope Qi (0), and then argue the
uniqueness of the equilibrium project scope.
   Consider the following strategy profile.

   • E↵ort levels: let both agents exert no e↵ort at all states before the project scope
       has been decided. Once a project scope Q has been decided, let both agents choose
       their respective e↵ort level as in the benchmark setting of Section 3 for a project of
       exogenous scope Q at all states q  Q, and let them exert no e↵ort for all states q > Q.

   • Dictator’s decision: at any state q where no scope has yet been decided, let the dictator
       set the project scope Qi (q).

We verify that such strategy profile is an MPE.
   First, let us fix the strategy of the dictator. Then at any state q, if the dictator’s decision
is yet to be made, agent j anticipates the scope to be set immediately, and exerting no e↵ort
is a best response. At any state q, if a decision of scope Q has been made by the dictator,
agent j’s e↵ort levels are, by definition, a best response to the dictator’s e↵ort strategy.
   Second, let us fix the e↵ort strategy of agent j. If, at state q, the project scope has not
been decided, the dictator never profits by delaying the decision to commit because agent
j exerts no e↵ort before the project scope is decided. Therefore, it is a best response to
commit at state q. Furthermore, if he commits to project scope Q 6= Qi (q), the dictator’s
discounted payo↵ is Ji (q; Q)  Ji (q; Qi (q)). Hence committing at state q to project scope
Qi (q) is a best response. The e↵ort levels of the dictator are, by definition, a best response
to agent j’s strategy.
   Finally, we note that in any MPE, the dictator commits at the beginning of the project.
Suppose he were to commit after the project started, say when the project reaches state
q̌ > 0. Since Ji (q̌; Q) has a unique maximum in Q, he commits to Qi (q̌) and obtains payo↵

                                                 38
Ji (·; Qi (q̌)). Then at state q = 0 there is a profitable deviation to commit immediately to
Qi (0) and obtain payo↵ Ji (0; Qi (0)) > Ji (0; Qi (q̌)). Hence there is no MPE in which the
dictator delays the announcement of the project scope. ⌅

A.7    Proof of Proposition 5
We begin by showing that if a project-completing equilibrium exists with scope Q, and if
agent i is dictator, then Q  Qi . This helps identify the set of Pareto-efficient equilibrium
outcomes.
   In an equilibrium of project scope Q, both agents anticipate that the project will be
completed at state Q. Therefore, they will both work as they would in the benchmark game
of fixed project scope Q described in Section 3. In particular, at any state q 2 [0, Q], each
agent k 2 {1, 2} gets continuation payo↵ Jk (q; Q).
   If Q > Qi , then at any state q 2 (Qi , Q), Proposition 3 implies that Ji (q; q) > Ji (q; Q),
i.e., the dictator is strictly better o↵ stopping the project when at state q, instead of stopping
at state Q. Thus, Q  Qi in equilibrium.
   Next, we show that, if agent 1 is the dictator, then Q = Q1 can be sustained in an MPE,
whereas if agent 2 is the dictator, then any Q 2 [Q1 (0), Q2 (0)] can be sustained in an MPE.
Observe that these project scopes are the Pareto-efficient ones, subject to the constraint
that Q  Qi when agent i is dictator.
   Let Q† = Q1 if agent 1 is the dictator and let Q† 2 [Q1 (0), Q2 (0)] if agent 2 is the
dictator. Recall that, as explained in Section 3, for any fixed, exogenous scope Q 2 [0, Q2 ),
the resulting MPE is completing, owing to the assumed strict concavity of Q 7! J2 (0, Q)
over that range. We verify that there exists an MPE with project scope Q† .
   Consider the following strategy profile:

   • E↵ort levels: for any state q  Q† , let both agents choose their e↵ort optimally in a
      game of fixed project scope Q† , and for all q > Q† let them exert no e↵ort. Note that,
      because the unique MPE of a project of fixed scope Q† is completing, both agents put
      positive e↵ort at every state up to Q† .

   • Dictator’s decision: let the dictator stop the project immediately whenever q           Q† .

To show such strategy profile is an MPE, we must show that agents play a best response to
each other at every state.
   First, fix the dictator’s strategy. Then agent j anticipates to be working on a project
of scope Q† , and it follows directly from agent j’s e↵ort strategy that agent j plays a best
response at every state q  Q† . At any state q > Q† , agent j anticipates that the dictator
completes the project immediately, and so putting no e↵ort is a weakly best response.


                                                 39
   Now, let us fix agent j’s strategy. If the dictator completes the project at state Q† , then
his e↵ort level is optimal given j’s e↵ort level, by definition of agent i’s e↵ort strategy.
   Let us check that terminating the project at every state q         Q† is optimal for the dictator.
Consider state q Q† . As agent j exerts no e↵ort for all states greater that Q† , and as
Q† Q1 > Q  b i , the dictator has no incentive to continue the project by himself: he is always
better o↵ stopping the project immediately.
   Now consider state q < Q† .

   • If agent 1 is the dictator, then as q < Q1 < Q1 (q), by our assumption that Q 7! J1 (q; Q)
      is strictly concave on [q, Q2 ) and is maximized for Q = Q1 (q), it is also strictly increasing
      [q, Q1 (q)]. This implies that J1 (q; Q1 (q)) > J1 (q; Q1 ) > J1 (q; q), and so the agent has
      no incentive to collect the termination payo↵ before reaching state Q1 .

   • If agent 2 is the dictator, then by Lemma 8 (see the proof of Proposition 3), Q 7!
      J20 (Q; Q) increases on [Q1 , Q2 ], and J20 (Q2 ; Q2 ) = J20 (Q2 (Q2 ); Q2 (Q2 )) = ↵2 . Besides,
      J2 (Q; Q) = ↵2 Q and Proposition 1 shows that J2 (q; Q) is strictly convex in q for
      q  Q  Q2 . Hence J20 (q; Q) < ↵2 for q < Q < Q2 , which in turn implies that
      J2 (q; Q) > ↵2 q for all q < Q with Q < Q2 . So, if q < Q† , then J2 (q; q) = ↵2 q <
      J2 (q; Q† ), and hence agent 2 has no incentive to complete the project before reaching
      state Q† .

In conclusion, the strategies defined above form a project-completing MPE with project
scope Q† . ⌅

A.8    Proof of Proposition 6
Fix some Q† 2 [Q1 (0), Q2 (0)]. We construct a project-completing MPE with project scope
Q† . Observe that any project scope Q0 2
                                       / [Q1 (0), Q2 (0)] is Pareto-dominated; that is ,
there exists some Q⇤ 2 [Q1 (0), Q2 (0)] such that Ji (0; Q⇤ )      Ji (0; Q0 ) for all i. Consider the
following strategy profile.

   • E↵ort levels: Before a project scope has been committed to, each agent i exerts e↵ort
      ai (q; 1) = ai (q; Q† )I{q<Q† } . After a project scope Q has been committed to, each
      agent exerts e↵ort ai (q; Q)I{q<Q} , where ai (q; Q) is characterized in the benchmark
      setting of Section 3 for a project of exogenous scope Q.

   • Agenda setter proposals: Let the agenda setter propose project scope Q† at every state
      q  Q† , and propose to stop the project immediately at every state q > Q† .

   • Agent j’s decisions: In a project state q > Q† , agent j accepts the agenda setter’s
      proposal to stop at Q for all Q with Jj (q; Q)           Jj (q; q), and rejects the proposal

                                                 40
     otherwise. In a state q  Q† , let agent j accept the agenda setter’s proposal to stop at
     Q whenever Jj (q; Q)     Jj (q; Q† ) and reject the proposal otherwise.

We now show that such strategy profile is an MPE. First, fix the agenda setter’s strategy.
It follows directly from agent j’s strategy that agent j plays a best response at every
state—both in terms of e↵ort and response to proposals of the agenda setter.
   Now take the strategy of agent j as given. If at state q a project scope Q has already
been agreed upon, the agenda setter, who can no longer change the project scope, plays a
best response (in terms of e↵ort level) to the strategy of agent j. It remains to show that
the agenda setter plays a best response at every q when no project state has been agreed on
yet. If he anticipates the project scope to be Q† , then his e↵ort levels are optimal in every
state. Let us check that the proposal strategy is indeed optimal, and yield project scope Q† .

   • If q   Q† , and agent 1 is the agenda setter, then agent 1 is better o↵ if the project
     stops immediately: since Q1 (q) = q as Q†       Q1 , J1 (q; q) > J1 (q; Q) for every Q > q.
     If agent 1 proposes to stop the project at state q, then agent 2 accepts, by definition
     of agent 2’s strategy. Hence it is optimal for agent 1 to propose to stop the project at
     state q, and the conjectured equilibrium strategy of agent 1 is a best response to agent
     2’s strategy.

   • If q   Q† , and agent 2 is the agenda setter, then agent 2 would prefer in some cases
     to pursue the project with agent 1, but never wants to pursue the project by himself,
     because Q† > Q b 2 . As agent 1 only accepts proposals to stop right away, and as he
     exerts no e↵ort past state Q† until a scope proposed is accepted, agent 2 is better o↵
     proposing to stop the project at the current state q—proposition accepted by agent 1.
     Hence the conjectured equilibrium strategy of agent 2 is a best response to agent 1’s
     strategy.

   • If q < Q† , and agent 1 is the agenda setter, then the agenda setter can guarantee
     himself a continuation payo↵ Ji (q; Q† ) by following the strategy defined in the above
     conjectured equilibrium profile. Assume by contradiction that there is an alternative
     strategy for the agenda setter that yields a strictly higher payo↵. Such strategy must
     generate a di↵erent project scope, Q. In addition, that project scope must be less
     than Q† for agent 1 to be better o↵, and so an agreement must be reached before state
     Q† . But then J2 (q; Q) < J2 (q; Q† ), and by definition of agent 2’s strategy, agent 2
     would not accept agent 1’s proposal to set scope Q at any state q < Q† . Hence the
     conjectured equilibrium strategy of agent 1 is a best response to agent 2’s strategy.

   • If q < Q† , and agent 2 is the agenda setter, then as before the agenda setter can
     guarantee himself a continuation payo↵ J2 (q; Q† ) by following the strategy defined

                                             41
      in the above conjectured equilibrium profile. Assume by contradiction that there is
      an alternative strategy for the agenda setter that yields strictly higher payo↵ with
      a di↵erent project scope Q. Then, as agent 2 is strictly better o↵, it must be that
      Q > Q† , as J2 (q; Q) is strictly increasing in Q when Q < Q† . However, agent 1 would
      not accept such a proposal of project Q before reaching state Q† . He may accept
      such a proposal in state q = Q, however, between state Q† and Q exerts no e↵ort. As
      Q† > Qb 2 , agent 2 is never better o↵ pursuing and completing the project by himself
      past state Q† , and thus a project scope Q = Q† is optimal. Hence the conjectured
      equilibrium strategy of agent 2 is a best response to agent 1’s strategy.

Therefore the conjectured strategy profile constitutes a project-completing MPE with project
scope Q† . ⌅

A.9       Proof of Proposition 7
Fix some Q† 2 [Q1 (0), Q2 (0)]. As in the proof of Proposition 6, we show that Q† can be
sustained in some MPE. Let us consider the following strategy profile.

  1. E↵ort levels: let both agents choose an e↵ort level optimal for a project of fixed scope
      Q† , and put zero e↵ort for any state q > Q† .

  2. Agenda setter proposals: let the agenda setter propose to stop the project for any state
      q      Q† , and continue to project for all q < Q† .

  3. Agent j’s decisions: let agent j accept the agenda setter’s proposal to stop for all
      states q     Q† , and otherwise accept to stop whenever J(q; q)      J(q; Q† ).

Let us show that such strategy profile is an MPE.
   Let us fix the strategy of the agenda setter and check that agent j’s strategy is a best
response at every state.

   • First, suppose agent 1 is the agenda setter. If he proposes to stop the project at a state
      q   Q† , agent 2 should accept: agent 1 puts no e↵ort past state Q† , and agent 2 would
      rather not work alone on the project as Qb 2 < Q† . If agent 1 proposes to stop at a state
      q < Q† , then agent 2 should accept only if the payo↵ he makes from immediate project
      termination, J2 (q; q) is no less than the payo↵ he makes by rejecting—which then
      pushes back the next anticipated proposal at state Q† , J2 (q; Q† ). Given the agenda
      setter’s strategy, agent 2 expects to complete the project in state Q† , and by definition
      of agent 2’s e↵ort strategy, the e↵ort levels of agent 2 are optimal at all states.

   • Second, suppose agent 2 is the agenda setter. If agent 1 is o↵ered to stop the project
      at q     Q† , then agent 1 finds it optimal to accept because Q1 (q) = q for all q    Q1 . If

                                                 42
      agent 1 is o↵ered to stop the project at q < Q† , then he should accept only if the payo↵
      from immediate project termination J1 (q; q) is no less than the payo↵ he expects to
      make from rejecting, which as before is J1 (q; Q† ). Given the agenda setter’s strategy,
      agent 1 expects to complete the project in state Q† , and by definition of agent 1’s
      e↵ort strategy, the e↵ort levels of agent 1 are optimal at all states.

Next let us fix the strategy of agent j and check that the agenda setter’s strategy is a best
response at every state.

   • First, suppose agent 1 is the agenda setter. Then agent 1 expects to make payo↵
      J1 (q; Q† ) by following the conjectured equilibrium strategy. To make a better payo↵, he
      would have to complete the project at a state Q < Q† . However such a proposal to stop
      the project early would not be accepted by agent 2, who is better o↵ working towards
      a project of scope Q† , because J2 (q; Q) is increasing in Q for all Q  Q†  Q2 (q) .
      Hence not proposing to stop before state Q† is a (weak) best response. As agent 2
      accepts to stop at all states q    Q† , agent 1 is better o↵ proposing to stop at all states
      q    Q† , because Q1 (q) = q for all q      Q†     Q1 . Therefore, agent 1 anticipates the
      project scope to be   Q†   and his e↵ort levels are optimal for such a project scope.

   • Second, suppose agent 2 is the agenda setter. Then agent 2 expects to make payo↵
      J2 (q; Q† ) by following the conjectured equilibrium strategy, and to make a larger payo↵
      would require completing the project at a state Q > Q† . Therefore it is never optimal
      for agent 2 to stop at any Q < Q† . However it is always optimal to stop at every
      Q    Q† , as agent 1 plans to put in no e↵ort after Q, and agent 2 prefers not to work
      alone on the project since Qb 2 < Q† .

Hence the conjectured strategy profile constitutes a project-completing MPE with project
scope Q† . ⌅

A.10      Proof of Proposition 8
Fix some Q > 0. We use the normalization Jei (q) = Ji (q)
                                                        i
                                                          as in the proof of Proposition 1.
                                    1     2
    To prove part 1, assume that ↵1 < ↵2 , let De (q) = Je1 (q) Je2 (q), and note that D e (·)
                                              ⇣         ⌘
is smooth, limq! 1 D  e (q) = 0 and D e (Q) = ↵1 ↵2 Q > 0. Suppose that D       e (·) has an
                                                1     2

interior global extreme point, and denote such extreme point by q. Because D e (·) is smooth,
it must be the case that D                                             e (q) = 2 D
                           e 0 (q) = 0. Then it follows from (5) that rD          e 00 (q). If q is a
                                                                                2
maximum, then D  e 00 (q)  0, so De (q)  0, which contradicts the fact that limq! 1 D   e (q) = 0
and the assumption that q is a maximum. On the other hand, if q is a minimum, then
e 00 (q)
D              e (q)
         0, so D                                                  e (q) = 0 and the
                       0, which contradicts the fact that limq! 1 D


                                                 43
                                           e 0 (q) > 0 for all q, which implies that
assumption that q is a minimum. Therefore, D
a1 (q) > a2 (q) for all q.
                                                J1 (q)       J2 (q)
    To prove part 2, let D (q) =                 ↵1           ↵2 ,    and note that D (·) is smooth, limq!                       1 D (q)         =
0, and D (Q) = 0. Therefore, either D (q) = 0 for all q, or D (·) has an interior global extreme
point. Suppose that the former is true. Then for all q, we have D (q) = D0 (q) = D00 (q) = 0,
which using (3) implies that
                                                         ✓                    ◆
                                 [J 0 (q)]2                  ↵2       ↵1
                         rD (q) = 1 2                                             = 0 =) J10 (q) = 0 .
                                    2↵1                       2         1

By Proposition 1, we have Ji0 > 0 in any project-completing MPE so this is a contradiction.
Thus the latter must be true. Then there exists some q such that D0 (q) = 0. Using (3), this
implies that
                                                                  ✓                    ◆
                                            [J 0 (q)]2                ↵2          ↵1            2
                                    rD (q) = 1 2                                           +        D00 (q) ,
                                               2↵1                      2          1           2
and note that J10 (q) > 0. Suppose that q is a maximum. Then D00 (q)  0, which together
                              ↵2       ↵1
with the fact that             2
                                   <    1
                                             implies that D (q) < 0. Therefore, D (q)  0 for all q, which
completes the proof of part 2.
    Finally, if   ↵1
                        =     ↵2                                                  e (q) = D
                                   , then it follows from the analysis above that D       e 0 (q) = 0 and
                   1           2
                                                                                  J1 (q)       J2 (q)
D (q) = 0, which implies that a1 (q) = a2 (q) and                                  ↵1      =    ↵2      for all q   0. ⌅


B     Additional Results
B.1    Propositions 1 and 2 hold under broader assumptions
In this Appendix, we show that Propositions 1 and 2 hold under a broader class of e↵ort cost
functions. In particular, suppose that e↵ort level a induces flow cost equal to ci (a) =                                                   i c (a)
to agent i, where         i   > 0, and c(·) is some arbitrary function that satisfies                               c0 , c00   > 0,   c 000     0,
c(0) = 0, and lima!1 c(a) = 1. Using similar arguments as in Section 3, it follows that for
any fixed Q > 0, each agent i’s payo↵ function satisfies the HJB equation

                                    rJi (q) = max                 i c(âi )   + (âi + aj (q)) Ji0 (q)
                                                   âi
                                                                                                                                          Ji (q)
subject to the boundary condition Ji (Q) = ↵i Q. By using the normalization J˜i (q) =                                                        i
                                                                                                                                                   ,
it follows that in a well-behaved MPE, each agent’s discounted payo↵ satisfies the following
system of ODE:
                                             ⇣ ⇣        ⌘⌘ h ⇣       ⌘   ⇣        ⌘i
                       rJ˜i (q) =           c f J˜i0 (q) + f J˜i0 (q) + f J˜j0 (q) J˜i0 (q)                                               (19)

subject to J˜i (Q) = ↵ii Q, where f (·) = c0 1 (·), and each agent’s e↵ort level is given by
          ⇣        ⌘
ai (q) = f J˜i0 (q) . Cvitanić & Georgiadis (2016) show that if a project-completing MPE


                                                                       44
exists, then Proposition 1, part 1 holds; i.e., Ji (q) > 0, Ji0 (q) > 0, and a0i (q) > 0 for all i and
q    0.
    The following result establishes conditions such that Proposition 2 holds under a broader
class of e↵ort cost functions.
                                             1        2
Proposition 9. Suppose that                 ↵1   <   ↵2 .   In any project-completing MPE:

    1. Agent 1 exerts higher e↵ort than agent 2 in every state; i.e., a1 (q)                 a2 (q) for all
       q    0.

    2. Agent 1’s e↵ort increases at a greater rate than agent 2 (i.e., a01 (q)               a02 (q) for all
       q    0) if c0 (·) is weakly log-concave; i.e., log c0 (a) is weakly concave in a.

    3. Agent 1 obtains a lower discounted payo↵ normalized by project state than agent 2
               J1 (q)       J2 (q)
      (i.e.,    ↵1          ↵2      for all q   0) if c(·) is weakly log-concave.


Proof of Proposition 9.

Statement 1.            Define D̃ (·) = J˜1 (·)
                                           J˜2 (·), and note
                                                          ⇣ that D̃
                                                                  ⌘ (·) is smooth, D̃ (q) = 0
                                                           ↵1  ↵2
for q sufficiently small (possibly q < 0), and D̃ (Q) = 1       2
                                                                    Q > 0. Therefore, either
D̃0 (q)    0 for all q, or D̃ (·) has at least one interior extreme point. Suppose that the latter
is true. Then there exists some z such that D̃0 (z) = 0 and substituting into (19) yields

                                                            rD̃ (z) = 0

Because any interior extreme point z must satisfy D̃ (z) = 0 and D̃ (·) is continuous, it must
be the case that D̃ (q) 0 and D̃0 (q) 0 for all q. Therefore, J˜10 (q) J˜20 (q) for all q, and
because f (·) is monotone, it follows that a1 (q)                     a2 (q) for all q.

Statement 2. To prove the second part, we di↵erentiate (19) with respect to q, which
yields in matrix form
                 "       # 2 ⇣ 0⌘           ⇣ ⌘            ⇣ ⌘      3"       #
                     ˜
                    J1 0     f J˜      + f   ˜
                                             J 0   J˜ 0 f 0 J˜0
                                                                       J˜00
                                 1             2      1       2
               r          =4           ⇣ ⌘        ⇣ ⌘           ⇣ ⌘ 5    1
                                                                               ,
                    J˜20       J˜20 f 0 J˜10     f J˜10 + f J˜20       J˜200
                                                                             n   o
where we used that c0 (f (x)) = x, and we omitted the dependence of J˜1 , J˜2 on q for
notational convenience. If the determinant of the above matrix is positive; i.e., if
                         h ⇣ ⌘       ⇣ ⌘i2                  ⇣ ⌘ ⇣ ⌘
                  det := f J˜10 + f J˜20       J˜10 J˜20 f 0 J˜10 f 0 J˜20 > 0 ,




                                                                45
then it is invertible. A sufficient condition for this to be true is that c000                                    0.27 Then we
have that
                   "           #         2 ⇣ ⌘           ⇣ ⌘                 ⇣ ⌘    3"      #
                                      r 4 f J˜1 +⇣f ⌘       J˜20     J˜10 f 0 J˜20
                                               0
                       J˜100                                      ⇣ ⌘           ⇣ ⌘ 5  J˜0
                                                                                         1
                                   =                                                          .
                       J˜00
                         2
                                     det      J˜20 f 0 J˜10      f J˜10 + f J˜20       J˜20

Note that a01 (q) a02 (q) if and only if J˜100 (q) J˜200 (q), which is true if and only if
  h ⇣ ⌘          ⇣ ⌘i                 ⇣ ⌘                     ⇣ ⌘ h ⇣ ⌘         ⇣ ⌘i
    f J˜10 + f J˜20 J˜10 J˜10 J˜20 f 0 J˜20      J˜10 J˜20 f 0 J˜10 + f J˜10 + f J˜20 J˜20
                        h ⇣ ⌘           ⇣ ⌘i ⇣                ⌘       h ⇣ ⌘        ⇣ ⌘i
                    , f J˜10 + f J˜20            J˜10 J˜20 + J˜10 J˜20 f 0 J˜10 f 0 J˜20                                   0 (20)
           h ⇣ ⌘      ⇣ ⌘i2                ⇣ ⌘ ⇣ ⌘
Recall that f J˜10 + f J˜20 > J˜10 J˜20 f 0 J˜10 f 0 J˜20 and J˜10                            J˜20 . Therefore, (20) is
satisfied if
                                  ⇣ ⌘⇣    ⌘           h ⇣ ⌘              ⇣ ⌘i
                          J˜20 f 0 J˜20 J˜10
                                      J˜20 + J˜10 J˜20 f 0 J˜10       f 0 J˜20         0
                                              h        ⇣ ⌘               ⇣ ⌘i
                                        , J˜20 J˜10 f 0 J˜10     J˜20 f 0 J˜20         0
             ⇣ ⌘                                                ⇣ ⌘
Noting that f J˜i0 = ai , J˜i0 = c0 (ai ), f = c0 1 , and f 0 J˜i0 = c00 (a    1
                                                                                 i)
                                                                                    > 0, it follows that the
                                                           0
above inequality holds if and only if cc00(a)
                                          (a) is increasing in a. This is true if and only if
                            ⇥ 00   ⇤2
                             c (a)         c0 (a) c000 (a) for all a ,

or equivalently if c0 (a) is weakly log-concave.

Statement 3.            Recall that in any well-defined MPE, each agent’s payo↵ satisfies the system
of ODE
                      ✓ ✓ 0     ◆◆  ✓ 0     ◆     ✓ 0     ◆
                         Ji (q)       Ji (q)        Jj (q)
 rJi (q) =        i c  f          + f          + f           Ji0 (q)                          s.t. Ji (Q) = ↵i Q . (21)
                                        i                      i          j
                               J1 (·)       J2 (·)
       Define D (·) =           ↵1           ↵2 ,    and note that D (·) is smooth, D (q) = 0 for q sufficiently
small, and D (Q) = 0. Therefore, there must exist an interior point z such that D0 (z) = 0,
and substituting into (21) yields
                                                         ✓ ✓ 0      ◆◆         ✓ ✓ 0       ◆◆
                                                       1     J1 (z)        2        J2 (z)
                           rD (z) =                     c f            +     c f
                                                     ↵1         1        ↵2            2
                                                         ✓ ✓ 0     ◆◆            ✓ ✓             ◆◆
                                                            J1 (z)      ↵1 2          ↵2 J10 (z)
                  ) r↵1 D (z) =                       1c f            +         c f
                                                               1          ↵           ↵1
                                                                        | {z2 }              2
                                                                           >   1

Notice that if D (z)  0, then this will imply that D (q)  0 for all q, which will complete
                                                                                                  c(f ( x))
the proof. To establish D (z)  0, notice that it suffices to show that                                       is increasing in
                                                                                              1                        ↵2
  for all x > 0 and                > 0. That is because letting x =        J10 (z),   1   =   1
                                                                                                   and        2   =   ↵1 2 ,   where
  27
       For details, see footnote 20 on on p. 29 in Cvitanic and Georgiadis.


                                                                   46
                              c(f (   1 x))       c(f (     2 x))
 1   >   2   we will have             1
                                              +             2
                                                                         0.
                                  c(f ( x))
     Fix x, and let g ( ) =                    . Then
                                                      x                                        c (f ( x))
                               g0 ( )         =           c0 (f ( x)) f 0 ( x)                       2
                                                            1                           c (f ( x))
                                              =       x2 00                                  2
                                                                                                         0
                                                        c (f ( x))
                                              , ( x)2                    c (f ( x)) c00 (f ( x))

Letting a = f ( x) = c0        1(     x), observe that x = c0 (a), and substituting this into the above
inequality yields
                                                  ⇥             ⇤2
                                                      c0 (a)                 c (a) c00 (a) ,

which holds for all a if and only if c (·) is weakly log-concave.



B.2      Social planner’s project scope and e↵ort level
A classic benchmark of the literature is the cooperative environment in which agents follow
the social planner’s recommendations for e↵ort. Here, we present, for completeness, the
solution when the social planner chooses both the agents’ level of e↵ort and the project
scope.
     For a fixed project scope Q, the social planner’s relevant HJB equation is

                          rS (q) = max                 2
                                                        1
                                                            a21          2
                                                                         2   a22 + (a1 + a2 ) S 0 (q) ,
                                      a1 ,a2
                                                                                                             S 0 (q)
subject to S (Q) = Q. Each agent’s first-order condition is ai =                                                  i
                                                                                                                       , and substitut-
ing this into the HJB equation, we obtain the ordinary di↵erential equation rS (q) =
2
 1+ 2
      [S 0 (q)]2 . This admits the closed form solution for the social planner’s value function
  1 2                                         q
            r 1 2         2                     2Q( 1 + 2 )(↵1 +↵2 )
S (q) = 2( 1 + 2 ) (q C) , where C = Q                 r 1 2         . Agent i’s e↵ort level is thus
             r   i
ai (q) =     1+ 2
                     (q   C). Note that a1 (q) > a2 (q) for all q if and only if                              1   <     2.   That is, the
social planner would have the efficient agent do the majority of the work, and incur the
majority of the e↵ort cost. It is straightforward to show that the social planner’s discounted
payo↵ function is maximized at
                                                                (   1   +      2 )(↵1   + ↵2 )
                                               Q⇤⇤ =
                                                                             2r   1 2
at every state of the project, and thus, the planner’s preferences are time-consistent. This
is intuitive, as the time-inconsistency problem is due to the agents not internalizing the
externality of their actions and choices.




                                                                         47
References
Acemoglu, D. & Robinson, J. A. (2008), ‘The Persistence of Power, Elites and Institutions’,
 The American Economc Review 98(1), 267–293.

Admati, A. & Perry, M. (1991), ‘Joint Projects without Commitment’, Review of Economic
  Studies 58, 259–276.

Aghion, P. & Tirole, J. (1997), ‘Formal and Real Authority in Organizations’, The Journal
  of Political Economy 105(1), 1–29.

Akerlof, R. J. (2015), ‘A Theory of Authority’, working paper .

Atkinson, K., Han, W. & Stewart, D. E. (2011), Numerical Solution of Ordinary Di↵erential
  Equations, Vol. 108, John Wiley & Sons.

Bagwell, K. & Staiger, R. W. (2002), The Economics of the World Trading System, MIT
  Press.

Baron, D. P. (1996), ‘A Dynamic Theory of Collective Goods Programs’, The American
  Political Science Review 90(2), 316–330.

Battaglini, M. & Coate, S. (2008), ‘A Dynamic Theory of Public Spending, Taxation and
  Debt’, American Economic Review 98(1), 201–236.

Battaglini, M. & Harstad, B. (forthcoming), ‘Particiation and Duration of Environmental
  Agreements’, Journal of Political Economy .

Battaglini, M., Nunnari, S. & Palfrey, T. (2014), ‘Dynamic Free Riding with Irreversible
  Investments’, American Economic Review 104(9), 2858–71.

Beshkar, M. & Bond, E. (2010), ‘Flexibility in Trade Agreements’, Working paper .

Besley, T. & Persson, T. (2011), Pillars of Propsperity: The Political Economics of Develop-
  ment Clusters, Princeton: Princeton University Press.

Bester, H. & Krähmer, D. (2008), ‘Delegation and Incentives’, RAND Journal of Economics
  39(3), 664–682.

Bhagwati, J. & Sutherland, P. (2011), The Doha Round: Setting a Deadline, Defining a
  Final Deal. Interim Report of the High Level Trade Experts Group. January.

Bonatti, A. & Rantakari, H. (2015), ‘The Politics of Compromise’, Working paper .

Bowen, T. R. (2013), ‘Forbearance in Optimal Multilateral Agreement’, Working paper .

                                             48
Bowen, T. R., Chen, Y. & Eraslan, H. (2014), ‘Mandatory Versus Discretionary Spending:
  The Status Quo E↵ect’, American Economic Review 104(10), 2941–2974.

Callander, S. (2008), ‘A Theory of Policy Expertise’, Quarterly Journal of Political Science
  3, 123–140.

Callander, S. & Harstad, B. (2015), ‘Experimentation in Federal Systems’, Quarterly Journal
  of Economics 130(2), 951–1002.

Compte, O. & Jehiel, P. (2004), ‘Gradualism in Bargaining and Contribution Games’, The
  Review of Economic Studies 71(4), 975–1000.

Cvitanić, J. & Georgiadis, G. (2016), ‘Achieving Efficiency in Dynamic Contribution Games’,
  American Economic Journal: Microeconomics Forthcoming.

Diermeier, D. & Fong, P. (2011), ‘Legislative Bargaining with Reconsideration’, Quarterly
  Journal of Economics 126(2), 947–985.

Dixit, A., Grossman, G. M. & Gul, F. (2000), ‘The Dynamics of Political Compromise’,
  Journal of Political Economy 108(3), 531–568.

Fershtman, C. & Nitzan, S. (1991), ‘Dynamic Voluntary Provision of Public Goods’, European
  Economic Review 35, 1057–1067.

Galbraith, J. K. (1952), American Capitalism: The Concept of Countervailing Power,
  Transaction Publishers.

Georgiadis, G. (2015), ‘Project and Team Dynamics’, Review of Economic Studies 82(1), 187–
  218.

Georgiadis, G. (2016), ‘Deadlines and Infrequent Monitoring in the Dynamic Provision of
  Public Goods’, Working Paper .

Georgiadis, G., Lippman, S. & Tang, C. (2014), ‘Project Design with Limited Commitment
  and Teams’, RAND Journal of Economics 45(3), 598–623.

Hirsch, A. V. & Shotts, K. W. (2015), ‘Competitive Policy Development’, American Economic
  Review 105(4), 1646–1664.

Kamien, M. I. & Schwartz, N. L. (2012), Dynamic Optimization: the Calculus of Variations
  and Optimal Control in Economics and Management, Dover Publications.

Levhari, D. & Mirman, L. J. (1980), ‘The Great Fish War: An Example Using a Dynamic
  Cournot-Nash Solution’, The Bell Journal of Economics 11(1), 322–334.

                                            49
Levy, N. (2014), ‘Domain Knowledge, Ability, and the Principal’s Authority Relations’,
  RAND Journal of Economics 45(2), 370–394.

Lizzeri, A. & Persico, N. (2001), ‘The Provision of Public Goods under Alternative Electoral
  Incentives’, American Economic Review 91(1), 225–239.

Maggi, G. (2014), International Trade Agreements in The Handbook of International Eco-
  nomics, Vol. 4, Elsevier. eds Gita Gopinath and Elhanan Helpman and Kenneth Rogo↵.

Marx, L. M. & Matthews, S. A. (2000), ‘Dynamic Voluntary Contribution to a Public
  Project’, Review of Economic Studies 67, 327–358.

Maskin, E. & Tirole, J. (2001), ‘Markov Perfect Equilibrium’, Journal of Economic Theory
  100(2), 191–219.

Nordhaus, W. (2015), ‘Climate Clubs: Overcoming Free-riding in International Climate
  Policy’, American Economic Review 105(4), 1339–1370.

Romer, T. & Rosenthal, H. (1979), ‘Bureaucrats Versus Voters: On the Political Economy
  of Resource Allocation by Direct Democracy’, The Quarterly Journal of Economics
  93(4), 563–587.

Strulovici, B. (2010), ‘Learning while Voting: Determinants of Collective Experimentation’,
  Econometrica 78(3), 933–971.

Yakovenko, A. (1999), ‘The Intergovernmental Agreement on the International Space Station’,
  Space Policy 15, 79–86.

Yamamoto, F. J., Miyairi, T., Regmi, M. B., Moon, J. R. & Cable, B. (2003), Asian Highway
  Handbook, United Nations.

Yildirim, H. (2006), ‘Getting the Ball Rolling: Voluntary Contributions to a Large-Scale
  Public Project’, Journal of Public Economic Theory 8(4), 503–528.




                                            50
