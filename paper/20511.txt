                                            1%(5:25.,1*3$3(56(5,(6




7+(,03$&72)12&+,/'/()7%(+,1'¶6
 $&&2817$%,/,7<6$1&7,216216&+22/3(5)250$1&(
                                  5(*5(66,21',6&217,18,7<(9,'(1&()5201257+&$52/,1$

                                                         7KRPDV$KQ
                                                         -DFRE9LJGRU

                                                   :RUNLQJ3DSHU
                                            KWWSZZZQEHURUJSDSHUVZ


                                  1$7,21$/%85($82)(&2120,&5(6($5&+
                                           0DVVDFKXVHWWV$YHQXH
                                             &DPEULGJH0$
                                                6HSWHPEHU




           7KHDXWKRUVJUDWHIXOO\DFNQRZOHGJHVXSSRUWIURPWKH,QVWLWXWHIRU(GXFDWLRQ6FLHQFHVJUDQW5$
           $QRQWHFKQLFDOVXPPDU\RIWKLVUHVHDUFKDSSHDUHGDVDSROLF\EULHIUHOHDVHGE\WKH$PHULFDQ(QWHUSULVH
           ,QVWLWXWHZKLFKSURYLGHGILQDQFLDOVXSSRUWIRUWKHEULHI:HWKDQN(ULND0DUWLQH]6DUDK&ULWWHQGHQ
           )XOOHU-DPHV5LGGOHVSHUJHUDQG-RKQ+ROEHLQIRURXWVWDQGLQJUHVHDUFKDVVLVWDQFH:HDOVRWKDQN
           0LNH/RYHQKHLP6FRWW,PEHUPDQSDUWLFLSDQWVDWWKH$($PHHWLQJVDQGVHPLQDUSDUWLFLSDQWV
           DWWKH8QLYHUVLW\RI9LUJLQLD8QLYHUVLW\RI.HQWXFN\DQG0LFKLJDQ6WDWH8QLYHUVLW\IRUKHOSIXOFRPPHQWV
           RQSUHYLRXVGUDIWV$Q\RSLQLRQVH[SUHVVHGLQWKLVSDSHUDUHWKRVHRIWKHDXWKRUVDQGQRWRIDQ\DIILOLDWHG
           LQVWLWXWLRQ7KHYLHZVH[SUHVVHGKHUHLQDUHWKRVHRIWKHDXWKRUVDQGGRQRWQHFHVVDULO\UHIOHFWWKHYLHZV
           RIWKH1DWLRQDO%XUHDXRI(FRQRPLF5HVHDUFK

           1%(5ZRUNLQJSDSHUVDUHFLUFXODWHGIRUGLVFXVVLRQDQGFRPPHQWSXUSRVHV7KH\KDYHQRWEHHQSHHU
           UHYLHZHGRUEHHQVXEMHFWWRWKHUHYLHZE\WKH1%(5%RDUGRI'LUHFWRUVWKDWDFFRPSDQLHVRIILFLDO
           1%(5SXEOLFDWLRQV

           E\7KRPDV$KQDQG-DFRE9LJGRU$OOULJKWVUHVHUYHG6KRUWVHFWLRQVRIWH[WQRWWRH[FHHG
           WZRSDUDJUDSKVPD\EHTXRWHGZLWKRXWH[SOLFLWSHUPLVVLRQSURYLGHGWKDWIXOOFUHGLWLQFOXGLQJQRWLFH
           LVJLYHQWRWKHVRXUFH
7KH,PSDFWRI1R&KLOG/HIW%HKLQG¶V$FFRXQWDELOLW\6DQFWLRQVRQ6FKRRO3HUIRUPDQFH5HJUHVVLRQ
'LVFRQWLQXLW\(YLGHQFHIURP1RUWK&DUROLQD
7KRPDV$KQDQG-DFRE9LJGRU
1%(5:RUNLQJ3DSHU1R
6HSWHPEHU
-(/1R,

                                             ABSTRACT

&RPSDULVRQVRIVFKRROVWKDWEDUHO\PHHWRUPLVVFULWHULDIRUDGHTXDWH\HDUO\SURJUHVV $<3 UHYHDO
WKDWVRPHVDQFWLRQVEXLOWLQWRWKH1R&KLOG/HIW%HKLQGDFFRXQWDELOLW\UHJLPHH[HUWSRVLWLYHLPSDFWV
RQVWXGHQWV(VWLPDWHVLQGLFDWHWKDWWKHVWURQJHVWSRVLWLYHHIIHFWVDVVRFLDWHZLWKWKHXOWLPDWHVDQFWLRQ
OHDGHUVKLSDQGPDQDJHPHQWFKDQJHVDVVRFLDWHGZLWKVFKRROUHVWUXFWXULQJ:HILQGVXJJHVWLYHLQFHQWLYH
HIIHFWVLQVFKRROVILUVWHQWHULQJWKH1&/%VDQFWLRQUHJLPHEXWQRVLJQLILFDQWHIIHFWVRILQWHUPHGLDWH
VDQFWLRQV)XUWKHUDQDO\VLVVKRZVWKDWJDLQVLQVDQFWLRQHGVFKRROVDUHFRQFHQWUDWHGDPRQJORZSHUIRUPLQJ
VWXGHQWVZLWKWKHH[FHSWLRQRIJDLQVIURPUHVWUXFWXULQJZKLFKDUHSHUYDVLYH:HILQGQRHYLGHQFH
WKDWVFKRROVDFKLHYHJDLQVDPRQJORZSHUIRUPLQJVWXGHQWVE\GHSULYLQJKLJKSHUIRUPLQJVWXGHQWV
RIUHVRXUFHV


7KRPDV$KQ
8QLYHUVLW\RI.HQWXFN\
%(;
/H[LQJWRQ.<
WKRPDVDKQ#XN\HGX

-DFRE9LJGRU
(YDQV6FKRRORI3XEOLF$IIDLUV
8QLYHUVLW\RI:DVKLQJWRQ
%R[
6HDWWOH:$
DQG1%(5
MYLJGRU#XZHGX




$Q2QOLQHDSSHQGL[LVDYDLODEOHDWVLWHVJRRJOHFRPVLWHWRPV\DKQ
1. Introduction

       The No Child Left Behind Act of 2001 (NCLB) required schools receiving Federal Title I

funding to track student performance, and to implement an escalating series of negative sanctions

in the event performance fell below a state-established threshold. This paper analyzes the impact

of these sanctions on student performance. We use school- and student-level data covering

North Carolina public schools to compare student test score growth in schools exposed to

varying sanctions. Since the NCLB sanction regime treated schools very differently if the

performance of a subgroup of students lay on either side of an arbitrary threshold, we identify

effects using regression discontinuity (RD) methodology.

       While previous literature has carefully considered the incentive effects of local, state, and

federal sanction regimes, less attention has been paid to evaluating what happens when responses

to incentives are not sufficient to evade punitive sanctions. Our contribution assesses whether

the sanctions incorporated into the nation’s most comprehensive accountability regime are

themselves positive or negative interventions, when assessed by their ability to yield significant

year-over-year improvements in student test scores. These sanctions are important to study for

two reasons. First, each of the sanctions could be – and in some cases have been – implemented

as stand-alone interventions, often in manners that do not invite rigorous evaluation. Knowledge

of the treatment effect of each sanction might inform future discussion over whether the

intervention is useful or wasteful. Second, reasonable models of school administrator behavior

suggest that responses to the threat of sanctions will evolve over time as knowledge regarding

the impact of those sanctions is disseminated. Sanctions that prove to be irrelevant may be

increasingly ignored over time.




                                                2
       Our results indicate that the sanctions incorporated into NCLB had widely varying

effects. On average, students attending schools that barely missed the cutoff for Adequate

Yearly Progress (AYP) in a given year posted test score improvements at most slightly greater

than those in schools that barely made the cutoff. Subsequent analyses stratifying schools by the

sanction for which they are at risk reveals a significant mix of estimated effects. Consistent with

prior literature, we find modest evidence of improvements for schools facing the threat of the

first NCLB sanction. We find more significant evidence of improvements among schools that

become subject to the ultimate sanction in the system, restructuring incorporating leadership or

management change. Intermediate sanctions, including mandatory tutoring services for low-

income students, have no demonstrable effect.

       Previous literature has raised concerns that a focus on proficiency will lead schools to

reallocate resources away from higher-performing students, or more generally that incentives to

focus on one group will result in a redirection of resources away from other groups. We assess

the importance of these concerns in two ways. First, we determine whether sanctions for low

proficiency result in poorer outcomes for students well above the proficiency threshold. While

we do find that the beneficial impacts of early-stage sanctions are concentrated among lower-

performing students, we find no evidence of countervailing negative impacts on higher-

performing students. In fact, the estimated impacts of restructuring appear to accrue throughout

the test score distribution. North Carolina’s independent accountability system, which focuses

on test score growth rather than accountability, may have restrained any impulse to deprive high-

performing students.

       Second, we examine whether test score improvements in schools sanctioned for the

performance of one specific subgroup are concentrated among members of that subgroup. A




                                                3
concentration of resources along these lines would be a rational response to the incentive. We

find evidence of particularly strong effects within the targeted subgroup, with the exception of

the restructuring sanction, which appears to generate improvements across the board.

             Overall, our results suggest that accountability systems can have modest impacts on

student performance, and if properly designed can in fact improve the performance of some

students without harming others. The association of strongest, and broadest, effects with

restructuring indicates that management and leadership issues are the most significant obstacles

to improvement in public schools marked by persistent low performance.



2. How to Think About Accountability Sanctions: Theory and Prior Evidence

2.1 The theoretical rationale for accountability
            The market for primary and secondary education is not likely to conform to the

assumptions underlying the standard prediction of economic efficiency in competitive markets.

Producers – schools – enjoy some degree of market power, and consumers – children and their

parents – may not be perfectly informed about the quality of the education they receive; even if

they are perfectly informed, acting on that information generally introduces significant

transaction costs – exchanging one house for another in a different attendance zone.

              A variety of public school reform initiatives can be conceptualized within this

framework. Efforts to introduce school choice via vouchers and similar mechanisms aim to

reduce transaction costs, which by enabling well-informed consumers to act on differences in

quality reduce the potential role of market power. Requiring schools to report basic information

on student performance improves the information available to consumers.1


1
 To be sure, the quality of this information may be limited, to the extent that non-school factors determine student
achievement or that standardized test scores are noisy signals (Kane and Staiger 2002).


                                                          4
             Accountability sanctions – rewards or punishments meted out to schools on the basis of

student performance data – are rationalized by the recognition that introducing choice and

information may be insufficient to motivate schools to operate efficiently. They attempt to

substitute punitive incentives for market incentives. Following basic principal-agent theory,

punishments or rewards can align agent (school) behavior with principal (government)

objectives, so long as they are in fact consequential to the agent and the principal has access to

an informative signal of the agent’s effort.

             In a traditional principal-agent model, the incentive itself is not expected to have any

impact on production ex post. Accountability sanctions may depart from this model, in that they

often involve interventions that may have treatment effects on students in a school. Thus even in

the absence of incentive effects, accountability sanctions could improve educational outcomes.

             The No Child Left Behind Act introduced a system of escalating sanctions into all

American public schools receiving Title I funding. A summary of the system appears in Table 1.

For schools serving students in grades 3-8, evaluation is based on standardized test score

performance in reading and math. To be identified as making “Adequate Yearly Progress” in a

subject, and thus avoid progressing further in the escalating sanction regime, the proportion of all

students meeting a state-defined proficiency threshold must exceed a discrete cutoff. The same

criterion is further applied to a series of subgroups in the school, defined by race, ethnicity,

program participation, English proficiency status, or disability. 2 Under some circumstances,

schools may qualify for limited exemptions to the proficiency requirements.3




2
  The AYP standard also incorporates a participation requirement, mandating that at least 95% of enrolled students
are tested.
͵The confidence interval exception effectively allows subgroups to be considered as meeting the target if their
observed proficiency rate is close enough to the predetermined threshold that the statistical hypothesis that the
“population” rate equals or exceeds the threshold cannot be rejected. The safe harbor exception exempts schools


                                                          5
             The set of sanctions applied to a school in any given year depends on that school’s recent

track record of performance. The sanctions threatened or imposed by the system include

permitting student transfers to other public schools, offering supplemental education services

(tutoring) to disadvantaged students, “corrective action,” and the formulation or implementation

of a restructuring plan.



2.2 Existing evidence on the impact of specific sanctions
             Many of the sanctions incorporated into NCLB had been elements of state- or district-

level accountability programs in earlier years. Since its implementation, several studies have

examined the impact of the entry-level sanctions incorporated into the law. This brief literature

review will examine existing evidence on four categories of sanctions: school choice sanctions,

personnel-focused sanctions, instructional interventions, and positive rewards.4



2.2.1 School choice sanctions

             Sanctions involving the introduction of school choice, either through the use of vouchers

for private school attendance or transfers to other public schools, are motivated by the theory of

market incentives. School choice serves as the first layer of sanction in the NCLB regime and in

Florida’s state-specific accountability program.

             Florida’s A+ Accountability and School Choice Program identified low-performing

schools and prioritized them for a range of educational interventions, while offering vouchers to



from negative sanctions if the subgroups with subpar proficiency have demonstrated a tangible improvement from
one year to the next.
4
  In addition to these studies of individual accountability sanctions and threats, there have been two noteworthy
studies comparing regimes with and without accountability systems to infer their total impact. Hanushek and
Raymond (2005) report better student performance in states with accountability systems using pre-NCLB data. Dee
and Jacob (2011) exploit the introduction of NCLB to perform a difference-in-difference analysis and similarly
report positive results.


                                                                                      6
students in schools that received multiple low-performing ratings in a short timespan. The

criteria for Florida’s school ratings permits the use of regression discontinuity methods to

identify the impact of exposure to the voucher threat. Several studies have documented positive

effects of the voucher threat on student performance (Greene and Winters 2003; West and

Peterson 2006; Chiang 2009). Schools exposed to the threat implement meaningful changes in

instructional practices (Rouse et al. 2013), leading to broad improvements that carry over to low-

stakes subjects (Winters, Trivitt and Greene 2010). Craig et al. (2013) find positive effects of

accountability threats on per pupil expenditure in a Texas system where the primary sanction was

a choice threat. On the more negative side, Florida’s voucher threat appears to lead schools to

suspend students more frequently around standardized testing time (Figlio, 2006).

       Prior studies of the school choice threats embedded in NCLB have found mixed results.

Chakrabarti (2014) and Springer (2008) report positive effects in Wisconsin and an unidentified

state respectively, concentrated in the subject areas or among the students where improvements

would most strongly mitigate the choice threat. By contrast, Hemelt (2011) finds negative

effects of choice threats on performance in Maryland, and West and Peterson (2006) conclude

that NCLB’s choice threats are inconsequential in Florida given the state’s use of vouchers in its

own accountability system.

       The mixed results in the literature on school choice threats is complemented by a

contentious and similarly mixed literature on the effects of school choice itself (Rouse 1998;

Hoxby 2000; Bettinger 2005; Bifulco and Ladd 2006; Angrist, Bettinger, and Kremer 2006; Sass

2006; Rothstein 2007; Chakrabarti 2008a, 2008b). Null effects of school choice might reflect the

low take-up of offered transfers, or unsophisticated choice behavior rooted in the complexity of

education as a consumer good.




                                                7
2.2.2 Personnel-focused sanctions

             School restructuring-type sanctions, involving the replacement of personnel, or in some

cases the complete closure or reconstitution of a school, comprise the ultimate sanction in the

NCLB regime. The sanction that precedes the development of a restructuring plan, corrective

action, can be thought of as a “light” version of the sanction. Restructuring sanctions were also a

component of some state- or district-level accountability systems predating NCLB. Of these, the

system introduced in Chicago Public Schools in 1996 has received the most attention. The

introduction of Chicago’s system has been associated with significant improvements in test

scores (Jacob, 2005). At the same time, studies of Chicago Public Schools under accountability

have unearthed a wide range of unintended and possibly detrimental side effects, ranging from

outright cheating (Jacob and Levitt 2003) to diverting instructional attention from students far

above or below the proficiency threshold (Neal and Schanzenbach, 2010).5 Analysis of a

comparable reconstitution threat in Virginia showed significant changes in school lunch menus

during standardized test season (Figlio and Winicki, 2005).



2.2.3 Instructional Interventions

             There have been several studies of the impact of supplemental education services (SES)–

NCLB-mandated tutoring – on student performance, arriving at widely varying conclusions

(Chatterji et al. 2006; Burch 2007; Zimmer et al. 2007; Heinrich et al., 2010; Munoz et al. 2012).

One consistent pattern emerging from the literature is that take-up rates tend to be low, in the

single digits in some cases, and that positive effects are conditional on extensive use of SES


ͷ  Ǧ ǡ  
  Ǥ


                                                          8
(Ryan and Fatani, 2005; Rickles and Barnhart 2007). From a causal inference perspective, this

pattern introduces concerns of self-selection. One qualitative study of SES in multiple settings

concludes that instructional shortcomings may also plague many programs, which are provided

by a wide array of contractors (Good et al. 2011). The literature, in summary, suggests that the

potential exists for positive impacts of SES, but that a variety of issues might limit this potential

in practice.



2.2.4 Rewards in Place of Negative Sanctions

        Accountability sanctions need not focus on punishing underperforming schools; in some

cases systems have been designed to deliver rewards at the other end of the performance

spectrum. The use of bonus payments for outstanding teaching has been associated with stronger

student performance in India (Muralidharan and Sundararaman 2011) and the United States

(Ladd 1999; Figlio and Kenny 2007). Cash bonuses have been shown to reduce teacher

turnover in disadvantaged schools (Clotfelter et al., 2008); however performance-based bonus

programs may exacerbate turnover problems if disadvantaged schools receive them less often

(Clotfelter et al., 2004). In North Carolina, the setting for this study, schools that barely fail to

receive a performance-based bonus in one year demonstrate significant improvements in the next

(Ahn and Vigdor, 2014). At the other end of the spectrum, other studies have shown no positive

impact of individual- or group-level performance incentives in rigorous randomized trials

(Springer et al., 2012; Yuan et al., 2013).

        In summary, the evidence base for effectiveness of any form of accountability sanction

on improving student performance is decidedly mixed. Most existing studies focus on a single

sanction in isolation, removed from an NCLB-style system where the imposition of one sanction




                                                  9
is conflated with the threat of the next. While there is considerable heterogeneity in

methodological rigor across studies, there is no general pattern of more rigorous studies – those

employing randomized trials, regression discontinuity, and like methods – reporting more or

fewer positive effects.



             3. Data and Methods

             We seek to analyze whether the imposition or threat of NCLB sanctions significantly

alters student performance. To do so, we make use of student and school-level data from North

Carolina, covering the period from inauguration of the NCLB system in the 2002/03 school year

to 2008/09. These data are a mix of public records and anonymized data made available to

researchers by the North Carolina Educational Research Data Center (NCERDC). To analyze

the impact of sanctions on student performance, we use longitudinally linked data on students

who attend the same school in consecutive years. This requires us to focus on schools that serve

students in grades 3-8.

             At present, AYP results from five school years are combined with test score results from

those years and the following years to form the heart of our dataset. The dataset consists of over

8,000 school-by-year observations and over 1.7 million individual-level computations of test

score gains.6 A summary of the data at the student level is presented in Table 2. We stratify the

student-level sample according to the consequences facing the student’s school in the event of

failure to make AYP, constituting either a direct sanction and/or the threat of a sanction in the

event of a subsequent failure. Generally, severity of sanctions increases from left to right. It is

readily apparent that schools facing tougher sanctions are bigger and serve more traditionally


6
 Sample sizes for reading and math analyses vary because in some small schools in some years we are unable to
match test score performance for any students from one year to the next.


                                                          10
disadvantaged students. Because these different schools are facing different threats and

sanctions, we must be cautious about drawing broad conclusions about the efficacy of particular

sanctions across all schools.

       3.1 Regression Discontinuity

       A simple comparison of student performance across schools subject or not subject to

sanctions in a given year will be prone to yielding misleading results, since the sanctions are

applied exclusively to schools in which proficiency rates are relatively low. To overcome this

obstacle, we take advantage of the structure of the NCLB sanction system, in which schools with

very similar patterns of student proficiency might be subject to very different sanctions if their

small differences place them on either side of the AYP threshold. Under certain assumptions,

this regression discontinuity analysis reveals an estimate of the average treatment effect of

interventions applied at the AYP threshold, local to the set of schools that find themselves close

to that threshold.

       In practice, it is not trivial to identify the set of schools whose performance places them

within an arbitrarily small neighborhood around the AYP threshold. Schools can miss AYP in a

subject if even one student subgroup posts a sufficiently low proficiency rate. Moreover,

because of the confidence interval and safe harbor exemptions, schools can make AYP even

when numerous subgroups fail to post proficiency rates that place them above the state-defined

standard.

       To identify schools that barely meet or miss the AYP standard, we first compute for each

subgroup in each school an “effective” proficiency threshold, defined as follows:



       Effective threshold = min(boundary for CI exemption, boundary for SH exemption)




                                                11
             Where CI and SH stand for the two exemptions made available to schools. The boundary

for the CI exemption is determined by the confidence interval formula employed by the state and

the number of students assessed. The boundary for the SH exemption is determined by the

subgroup’s performance in the prior academic year.

             We then compare the actual proficiency rate exhibited by a subgroup within a school with

the effective threshold for that subgroup:



             Subgroup gap = actual proficiency – effective threshold



             The assignment variable for our RD analysis is defined as the minimum subgroup gap,

across that set of subgroups with a sufficiently large number of tested students.7 In North

Carolina, the threshold is set at 40 students. When the assignment variable is positive, the school

qualified for AYP; when it is negative the school fails to make AYP. The cutoff for AYP, which

we refer to as the minimum effective threshold, is zero.

             To assess the impact of exposure to NCLB sanctions and threats, we evaluate the

performance of students in the affected school in the subsequent academic year. The dependent

variable of interest is the change in standardized test score over the period in which the treatment

is administered. Thus, when a school meets or misses the AYP cutoff in year t, we examine the





7
  Note that the assignment variable is not necessarily determined by the subgroup that performs worst in absolute
terms. The worst-performing subgroup may qualify for AYP by an exemption in situations where the school as a
whole fails to qualify. This would occur when the worst-performing group is numerically small and qualifies under
the confidence interval exemption (and the next-worst performing group is large and does not), or when the worst-
performing group has shown significant improvement over the prior year, thereby qualifying under safe harbor (and
the next-worst performing group does not).


                                                          12
effects by observing growth in test scores between the end of year t and the end of year t+1.8 In

our baseline specifications, we include only those students observed attending the school in

question in both years. In alternate specifications, we include students who attend the school in

year t regardless of the school attended in year t+1, so long as the students remain enrolled in any

North Carolina public school. This will permit us to include the hypothesized treatment effect of

offering transfers, and other family school choice behavior occasioned by the failure of a child’s

school to make AYP. We caution, however, that these short run effects may be dominated by

disruption effects that dissipate over time (Hanushek, Kain and Rivkin 2004).

             Regression discontinuity analysis can be performed either parametrically or

nonparametrically. For our analyses, we use the Hahn, Todd, and van der Klaauw (2001)

nonparametric specification, which entails the estimation of local linear regressions to fit a

smooth function to either side of the discontinuity. While there is no explicit functional form

choice associated with the local linear regression, in practice the shape of the smooth function is

heavily influenced by choice of bandwidth in the local linear regression – put simply, the number

of data points used to estimate a slope in the neighborhood of each individual data point. We

report results for a variety of bandwidths centered around the “optimal” bandwidth as defined by

Imbens and Kalyanaraman (2012).9 Bandwidth selection involves tradeoffs: larger bandwidths

permit more precise estimates, but at the cost of introducing potentially less relevant data points

at greater distance from the point of discontinuity.




8
  Note that our use of test score gains varies from NCLB’s focus on levels. Research has established a strong link
between test score gains and longer-run outcomes including earnings (Chetty, Friedman and Rockoff, 2011).
9
  We replicate each reported nonparametric RD estimate using a more traditional OLS-based parametric procedure.
The OLS regressions control for either a linear, quadratic, cubic or quartic function of the assignment variable, with
terms permitted to vary on either side of the point of discontinuity, as well as controls for student gender, English
proficiency status, race, disability status, and school enrollment. In all cases, conclusions supported by non-
parametric analysis are corroborated by parametric specifications.


                                                          13
             The nonparametric analysis is complicated by the nature of the data: we have individual-

level records for purposes of computing treatment effects, but assignment to the treatment occurs

at the school rather than individual level. In our analyses below, we address this problem by

collapsing the individual-level data to the school-level, weighting observations in the school-

level estimation by the number of individual-level observations used in computing school-

specific means of the dependent variable and covariates.10



             3.2 Analyzing the Impact of Specific Sanctions

             Our primary goal is to assess the impact of individual NCLB sanctions. As such, a

simple RD analysis on the entire dataset is unlikely to be informative, as it represents the average

effect of a number of different threats and sanctions. For most of our analyses, then, we focus

our attention on sets of school/year observations at risk for the same sanction or threat. For

example, to analyze the impact of being threatened with the requirement to offer transfers, we

will begin with the set of schools with no history of missing AYP prior to year t, and compare

student performance in year t+1 across schools that make or miss AYP in year t.

             While restriction to schools with similar AYP histories can help refine the sanction or

threat under analysis, we are still left with the difficulty that each failure to make AYP after the

first results in the simultaneous imposition of all previous sanctions and the threat of the next

sanction in the sequence shown in Table 1. Thus in the absence of additional information it is

impossible to separate the effect of offering transfers from the effect of the threat of offering

tutoring.



10
   We also estimate models using individual-level data, using a bootstrapping procedure to approximate clustered
standard errors. While point estimates are comparable with both procedures, the clustered standard errors are larger,
consistent with the notion that clustering is a conservative solution to the problem of grouped data. We additionally
estimated unweighted school-level models which yield qualitatively similar results.


                                                          14
             In practice, we take advantage of a waiver to standard NCLB policy that was offered to

seven North Carolina districts beginning in the 2006/07 school year, and expanded statewide

beginning in 2008/09.11 The waiver permitted affected districts to reverse the order of the first

two NCLB sanctions, implying that schools would be required to offer supplemental services

first and transfers second. Thus, under the assumption that the effects of each threat and sanction

are time invariant, we can uniquely identify not only the impact of being threatened with offering

transfers, but the threat of offering supplemental services, the transfers themselves, the

supplemental services themselves, and the threat of corrective action.

             Of course, there is no guarantee that these effects will be time-invariant. Revelation of

information about the effects of sanctions might well alter responses to the threat of those

sanctions.



             3.3 RD diagnostics

             A standard concern with regression discontinuity analysis is that agents may have some

capacity to manipulate the assignment variable. This would appear to be a valid concern in this

application, as the effective thresholds for each subgroup are in theory calculable at the

beginning of each school year. There is at least some evidence that school personnel might

manipulate testing data in a high-stakes setting (Jacob and Levitt, 2003).

             To assess this and other potential threats to validity, Figures 1-3 perform basic

diagnostics appropriate to fuzzy RD analysis (Imbens and Lemieux 2008; Lee and Lemieux,

2010). These figures are presented using the entire sample of schools at risk for missing AYP.




11
 The seven districts are Burke County, Cumberland County, Durham County, Guilford County, Moore County,
Northhampton County, and Pitt County. Three of these districts are among the state’s ten largest.


                                                          15
In certain analyses below, we restrict attention to subsets of schools at risk for specific sanctions

or threats. We show analogues of Figures 1-3 for each of these subsets in the online appendix.12

             Figure 1 begins by showing a basic density plot of our data, pooled across all available

years and subjects. A normal density function is overlaid. In these plots, we would be

particularly concerned if we found evidence of a mass on the right hand side of the minimum

effective threshold relative to the left hand side.13 The figure demonstrates that the AYP cut point

falls very nearly in the middle of the observed data, and that the density is in fact slightly greater

to the immediate right of the cut point. The histogram bar to the immediate right is about 20

percent higher than the one immediately to the left. A formal statistical test for a significant

break in density at the cut point fails to reject the null hypothesis of no difference (test statistic:

0.094, standard error: 0.079, see McCrary 2008).14

             Figure 2 plots average student characteristics for schools as a function of the minimum

subgroup gap. Included characteristics include percent nonwhite, percent receiving free or

reduced lunch, and percent female. While it is clear that schools with lower performance tend to

serve more disadvantaged students, there is no evidence of a significant trend or break in trend in

any of these student characteristics at the AYP threshold. Thus, any observed treatment effect is

most likely not due to sharp differences in demographic characteristics of students at schools

above or below the cut-off point.




12
  See sites.google.com/site/tomsyahn (Figures A1 – C9).
13
    It should be noted that this analysis differs from a typical RD analysis in one important respect: some of the
schools “at risk” for sanctions have already had sanctioned applied. To the extent that there is a positive treatment
effect of any sanction, this may lead to a scenario where the density to the right of the discontinuity exceeds that on
the left. Coupled with the insignificant McCrary test statistic reported below, this increases our confidence that
manipulation is not a significant concern in these data.
ͳͶBecause our analysis divides the full sample into groups of schools facing different threats and sanctions, the
density of the assignment variable is plotted for each subsample. Figures A1- A9 are available in the online
appendix.


                                                          16
       Third, Figure 3 verifies that there is indeed a discontinuous change in the probability of

treatment at the point where schools cross the AYP threshold. The magnitude of the probability,

revealed in nonparametric specifications based on local linear regression, is 0.854 for reading

and 0.828 for math. The “fuzziness” of the discontinuity, or the imperfections in our ability to

forecast which schools will make or miss AYP in a given year, stems from the fact that factors

other than test score performance are incorporated into AYP designations. Schools must meet

attendance and test participation benchmarks.

       Following discussion of our results below, we present the results of some additional

diagnostic tests that examine the sensitivity of our main results to bandwidth selection, and

report the results of “pseudo-RD” specifications intended to assess concerns regarding mean

reversion.



       4. Results

       In all results tables below, the signs obtained from RD analysis have been reversed, so

that we might interpret the reported effects as the impact of being exposed to NCLB sanctions or

threats, rather than the impact of avoiding them.



       4.1 The main effect of failure to make AYP

       Table 3 reports regression discontinuity estimates of the effect of meeting AYP criteria

using all school-year observations. As noted above, these estimates conflate a wide variety of

NCLB sanctions and threats. We report estimates derived from local linear regressions using the

“optimal” bandwidth (Imbens and Kalyanaraman 2012), but note in the table whether results are

statistically significant in specifications using twice or half this bandwidth. These specifications,




                                                17
as well as those reported below, condition on student race, free/reduced price lunch participation,

and English proficiency status.

             For reading test scores, estimation with optimal bandwidth yields an exceptionally small

point estimate, on the order of two-hundred-thousandths of a standard deviation. The effect is

estimated precisely enough to rule out any positive or negative impacts greater than one percent

of a standard deviation. Estimation using alternate bandwidths from 50% to 300% of the optimal

value yields similarly insignificant results. The point estimate remains extremely small when we

include students who transfer away from the school in the sample.15

             When analyzing math test scores, evidence is suggestive of a positive impact of failure to

make AYP. Using the optimally selected bandwidth, the point estimate suggests that students in

schools that miss AYP post test score gains of 2 percent of a standard deviation relative to

students at schools that do make AYP. The effect is marginally significant, with a p-value of

0.057. Estimation with larger bandwidths yields larger and more significant results, while

estimation with smaller bandwidths produces smaller estimates – in some cases reverse-signed –

that are statistically insignificant.16 Introducing students who transfer out in the sample increases

the point estimate slightly.

             Figure 4 presents a more comprehensive analysis of the sensitivity of our results to

bandwidth choice, plotting point estimates and confidence interval boundaries at 19 different

bandwidth levels. Estimates using very small bandwidths are very imprecise; as bandwidth

increases the increasingly precise estimates center on zero before converging to significant


15
  Estimation using parametric OLS regressions similarly yields insignificant results, with point estimates on either
side of zero and at most 0.013 in absolute value. See Table A in the online appendix.
ͳ͸ We present the standard RD graph using binned local average values with differing bandwidths (Figures D1- D3
for the entire sample and Figures D4 – D6 for the subsample of schools facing restructuring) in the online appendix.
In addition, we graph the RD using different order polynomials (from degree 0 to degree 3) in Figure D7 and D8 and
show that the observed discontinuity is not sensitive to the order of the polynomial. Binned local average values are
excluded for clarity.


                                                          18
positive estimates at bandwidths above 0.30.17 The observed pattern – with point estimates close

to zero until we include potentially less-relevant data points with a larger bandwidth – leads us to

consider these estimates suggestive.



             4.2 Effects of specific sanctions and threats

             The consequences of failing to make AYP vary dramatically depending on a school’s

history, and for this reason aggregate effects such as those reported above are quite likely to

misrepresent the impact of exposure to particular sanctions, or the threats of those sanctions.

This section summarizes the results of a number of additional nonparametric RD specifications,

which by restricting the sample to students in schools with comparable AYP histories report the

local average treatment effect of exposure to a certain combination of sanctions and/or threats of

sanctions.

             The estimates in Table 4 are based on sample restrictions to those schools not currently

subject to any threats or sanctions in the NCLB regime, because they have consistently met the

AYP criteria since the inception of the policy or for two consecutive years. Among these

schools, the failure to make AYP exposes them to the threat of the first sanction in the regime,

which varies by year and district in North Carolina. These schools face an incentive to make

AYP in the following year in order to avoid the imposition of this first sanction.

             Across the board, point estimates suggest modest positive impacts of failing to meet the

AYP standard for the first time. For reading test scores, the estimated effects are 2 percent of a

standard deviation or below, and fail to reach statistical significance at standard bandwidth

whether considering exposure to the tutoring or transfer threats. The point estimates are slightly

17
   Estimation using parametric OLS regressions yields positive and significant point estimates ranging from 0.021 in
a quadratic specification to 0.061 in a cubic specification. Estimates using a quartic functional form are not
statistically significant.


                                                          19
larger in magnitude with p-values of 0.074 when using a large bandwidth. Including students

who transfer away from the school in the sample leaves point estimates within the range already

established in other specifications.18

             Math test scores appear to improve more substantially when exposed to the first NCLB

threat. The effect is most pronounced with exposure to the transfer threat, where point estimates

indicate a statistically significant 4.7 percent of a standard deviation improvement in test scores.

This particular result is sensitive to bandwidth choice; larger and more significant at higher

levels, but reverse-signed and insignificant at half the optimal bandwidth. By contrast, the

impact of exposure to the tutoring threat is somewhat smaller at 2.8 percent of a standard

deviation, but statistically significant and robust to bandwidth choice.19 In both cases, including

students who transfer away from the school in the sample yields larger point estimates,

suggesting that the failure to make AYP – even when not attached to a particular sanction – leads

some families to make school choices resulting in better math instruction for their children.

             Table 5 presents estimates derived from specifications where the sample has been

restricted to a set of schools facing a common sanction/threat combination. For sake of brevity,

only estimates derived from optimal bandwidth specifications are reported here.20

             Normally, the first sanction applied in the NCLB system is a requirement to offer

students transfers to higher-performing public schools in the same district. We find no

statistically significant evidence of any impact of transfers, either applied as a first or second


18
   Estimation by parametric OLS yields a similar mix of insignificant results, with the exception of linear or
quadratic specifications in the sample of schools exposed to the SES threat, where point estimates are on the order of
0.04.
19
   Estimation by parametric OLS yields a mix of positive and negative insignificant coefficients among schools
exposed to the transfer threat; estimates are on the order of 0.05, significant and positive in most specifications for
schools exposed to the SES threat. The OLS and nonparametric results thus are not entirely consistent with one
another, which suggests caution in interpreting the impact of initial failure to make AYP on subsequent test score
gains.
ʹͲEstimates using alternate bandwidths are reported in the online appendix. See Table B1-B3.



                                                          20
sanction and coupled with differing threats, on student test score improvements in reading or

math. Although not reported here, specifications introducing transferred students into the sample

do not produce a significant change in point estimates – in fact, point estimates become more

negative in some cases. This suggests that the mechanism of improving student performance

through access to better public schools is at best canceled out by the negative impact of

switching schools in the short run. Together with the results in Table 4, they suggest that savvy

parents exercise school choice options in response to the initial information that their school has

failed to make AYP, rather than the explicit offer of transfers.

             Supplemental education services, implemented either as a first sanction or layered on top

of transfers, produce no significant association with achievement gains in either reading or math,

yielding consistent but insignificant negative point estimates. We similarly find no statistically

significant effects of the sanction imposed on schools missing AYP a fourth time, corrective

action.21

             Schools that fail to make AYP a fifth time are required to formulate a restructuring plan,

which they will be required to implement in the event they are unsuccessful a sixth time. Results

indicate that schools exposed to this sanction exhibit declines in reading test score performance

of nearly 6 percent of a standard deviation, a result that is both close to the standard statistical

significance threshold (p=0.053 using the optimal bandwidth) and fairly robust across bandwidth

selections as reported in the online appendix. Results for math test scores are statistically

insignificant across a wide range of bandwidths.



21
  Separate estimation for those schools that implemented sanctions in the standard order – transfers first, then
tutoring – reveals larger, statistically significant impacts on both reading and math test score gains, with coefficients
on the order of 7-8 percent of a standard deviation. In the full sample, these gains are offset by more modest and in
some cases reverse-signed impacts among those schools that implemented tutoring first. This may in fact be more
of a timing effect than a sanction order effect – those schools that reached the corrective action stage earlier in the
process may have been better able to forecast which corrective actions would improve test scores.


                                                          21
             Finally, schools that fail to make AYP a sixth time are required to implement their

restructuring plans. The estimated effects of restructuring on reading scores are sensitive to

bandwidth choice, with the optimal bandwidth yielding an estimated 2.6 percent of a standard

deviation improvement (p=0.066). Math results indicate a statistically significant 5.5 percent of

a standard deviation improvement in test scores at the optimal bandwidth. Figure 5 shows that

this result is quite robust to bandwidth choice, with point estimates slightly greater at narrower

bandwidths and all but one reported alternate estimate significant at the 5% level.

             In summary, across all the sanctions in the NCLB regime, the ultimate penalty,

implementation of a restructuring plan, shows the strongest evidence of positive test score

impacts across the board.22 No other sanction yields estimates of the same magnitude in both

subjects; the threat of exposure to the sanction system comes closest.



             4.3 Inspecting a possible mechanism for restructuring effects: staff turnover

             Restructuring plans constitute a heterogeneous treatment. It is not clear from the

reduced-form results above what components of restructuring are responsible for the observed

positive effects. The specifications in Table 6 attempt to shed some light on the mechanism

underlying the effect, by examining how exposure to restructuring influences staff turnover.

Since the outcomes analyzed here are based on school-level measures and not individual test

scores, the RD analyses are not weighted here.

             The first specification examines the rate of teacher turnover, defined as the proportion of

teachers observed in year t who do not return in year t+1. Coefficients indicate that the turnover

rate in schools exposed to restructuring increase by three to five percentage points. The baseline


22
  As noted above in footnote 21, exposure to the corrective action sanction appears to have even stronger positive
impacts among schools that proceed through the sanction system in the standard order.


                                                          22
rate of turnover for schools at risk for restructuring is around 20 percent, so these effects indicate

a 15 to 25 percent increase in the turnover rate associated with the restructuring sanction.

       In defining principal turnover, we are faced with the issue that the baseline rate of

principal turnover is very high in part because principals move between schools. It is unclear

whether to attribute a move between schools as an involuntary effect of restructuring. We

therefore define principal turnover more narrowly to be a scenario where the principal in year t is

not observed as a principal in any North Carolina public school in year t+1. Estimates in this

case span a broad range and are estimated somewhat imprecisely, attaining significance at the

10% level with smaller bandwidths. The estimates suggest a 6-18 percentage point increase in

principal turnover. The baseline rate of turnover in at-risk schools is on the order of 30 percent,

indicating that these estimates point to a 20-60 percent increase in the turnover rate.

       While these results do not exhaustively probe all possible mechanisms for the

improvements associated with restructuring, they are consistent with the notion that leadership

and personnel change are an important component.



       4.4 Effect heterogeneity: by initial student test performance

       One concern with school accountability systems based on proficiency rates is that they

provide incentives for schools to focus only on those students near the proficiency threshold,

focusing less attention on those either well above or below the cutoff (Reback 2008; Neal and

Schanzenbach 2010). In theory, the treatment effect estimates presented above could represent a

mix of very positive impacts for students near the threshold and very negative impacts for

students far from it. Table 7 assesses this concern by reporting treatment effect estimates




                                                23
specific to students’ initial test score quartile.23 An exclusive focus on moving students above

the proficiency threshold would lead schools to focus on the bottom two quartiles, shifting

resources away from students in higher quartiles.

             There is at least some evidence to indicate that schools respond to accountability

sanctions by focusing more resources on lower-performing students. In schools barely missing

the AYP criteria for the first time, students with below-average initial test scores post math test

score increases that are 5 percent of a standard deviation greater, relative to below-average

students in schools barely meeting the AYP criteria. Point estimates suggest a diminished effect

among students in the second-highest quartile, and no effect whatsoever among the highest-

performing students.

             There is also evidence that below-average students post significant reading test score

increases in schools that barely miss the AYP criteria for a second consecutive year, relative to

those that miss the first time but barely make it the second. These estimates are even greater in

magnitude, up to 11 percent of a standard deviation, and once again diminish at higher initial

achievement levels, to the point where top-quartile students have comparable performance on

either side of the discontinuity.

             Table 5 above showed that students post significantly higher test score gains in schools

required to undergo restructuring, after missing AYP for a sixth consecutive year. The final row

in Table 7 shows that the beneficial effects of restructuring, estimated somewhat imprecisely

here, appear to be spread fairly evenly throughout the initial test score distribution. Math test

score gains, in particular, accrue at the rate of 4-6 percent of a standard deviation across all four

quartiles. Point estimates are in fact slightly larger for students with higher initial test scores;


23
  Table 7 omits analysis of school/year observations subject to reversed order of the first two accountability
sanctions. Results in this subsample are uniformly insignificant.


                                                          24
estimates for the lower quartiles are not statistically distinguishable from zero. Point estimates

for reading test score gains by quartile are positive across the board, but never significantly

different from zero.

       There is one set of anomalous results worth mentioning. Lower-performing students in

schools required to formulate, but not implement, a restructuring plan post significantly worse

test score improvements than their counterparts in schools that avoid this sanction. This pattern

replicates the more basic results in Table 5 above. It is possible that schools tasked with

formulating a restructuring plan must devote resources to that activity that would otherwise be

productive in the instruction of reading to low-performing students. And of course, it is also

possible that this anomaly is just that – attributable to an outlier in the data. Aside from this

anomaly, the remaining results in Table 7 reveal no significant patterns of note.

       Overall, then, our results partly support those of existing literature showing that schools

focus resources on students near the proficiency threshold when subject to accountability

pressure. In contrast to this prior literature, we find no evidence that accountability leads schools

to “leave behind” their highest-performing students; results for these students are near zero but

never significantly negative. Moreover, we find that school restructuring leads to broad-based

improvements in math test scores.

       The lack of negative effects for inframarginal students might reflect the simultaneous

operation of North Carolina’s own accountability system, which is based on test score increases

rather than proficiency and offers cash bonuses to personnel in high-performing schools. Given

tradeoffs between qualifying for AYP by increasing proficiency and qualifying for a bonus by

promoting test score growth across the initial test score distribution, school personnel may have

responded rationally by reallocating resources only to the point where high-performing students




                                                 25
were not harmed on the margin. High-performing students may also have avoided relative test

score declines to the extent their parents substituted for resources allocated away from them

within the school system. To the extent that this occurred, the lack of test score declines among

high-performers should not be considered evidence that the gains to low-performing students

came at no cost.



       4.5 Effect heterogeneity: among critical subgroups

       For many schools in our sample, the failure to make AYP in a given year can be

attributed to the performance of a single subgroup, such as Limited English Proficiency students

or students receiving free or reduced price lunch. In these schools, there is a clear incentive to

focus efforts on improving the performance of just that subgroup. If the improvement is

sufficiently large, the group’s proficiency rate does not even need to make the NCLB target,

under the safe harbor exemption. Table 8 examines the impact of failure to make AYP, using

regression discontinuity analysis, on a sample comprised exclusively of students belonging to the

subgroup responsible for the school’s failure to make AYP.

       Consistent with a pattern of rational focus on the problematic subgroup, and with earlier

studies of NCLB, point estimates of the effects of failure to make AYP, estimated using the

Imbens-Kalyanaraman optimal bandwidth, tend to be more positive than analogous estimates for

the full sample. The pattern holds in 11 of 14 cases, comparing Table 8 point estimates to those

in earlier tables. The overall impact of failure to make AYP on the math scores of the

problematic subgroup, for example, is twice the magnitude of the effect in the overall population.

Despite the larger magnitudes of these coefficients, they only rarely achieve statistical

significance. The underlying sample size of students in the problematic subgroup is, of course,




                                                26
considerably smaller than the sample of students in schools overall, leading to larger standard

errors.

             The three exceptions to the larger-effect-size pattern in Table 8 include one case where

the Table 8 coefficient is wrong-signed relative to its earlier counterpart. In a second case, both

the original coefficient and the Table 8 coefficient are negative-signed, with the Table 8 version

bearing a larger magnitude. The final case pertains to the effect of the ultimate sanction, school

restructuring, on math achievement. Here, the point estimate in the full population is larger than

the effect in the problematic subgroup – the only case where point estimates have the same sign

and the point estimate in the problematic subgroup is closer to zero. While it may be

inappropriate to assign much interpretation to this pattern, given the imprecision of the

underlying estimates, this is consistent with the notion that mandated changes in school

leadership among schools that have persistently failed to make AYP yields benefits to all

students, and not only those who would be targeted by a rational administrator.



             4.6 Effect heterogeneity: SES effects among eligible students

             Supplemental education services were required to be offered to students eligible for free

or reduced price lunch in schools that had missed AYP in the same subject for three consecutive

years (two years following North Carolina’s reversal of sanction order). Table 5 above failed to

report any evidence that SES led to improved test score outcomes; in fact the preponderance of

point estimates are negative. Table 9 re-examines the effects of SES by restricting attention to

those students actually eligible to receive the services. Even in this subsample, there is no

evidence of a significant impact of SES on student performance.24



ʹͶ   See the online appendix Table C for alternate bandwidths.


                                                          27
       4.7 Falsification Tests

       As noted above, our procedure may yield spurious positive effects of missing the AYP

cutoff if the tendency to mean revert towards higher performance is, for any reason, significantly

greater on the left-hand side of the discontinuity point. To assess this possibility, we estimated

two sets of pseudo-regression discontinuity analyses. In the first set, we estimated our models

using a cut point 15 percentage points above the actual proficiency cutoff in each school. This

point lies towards the upper tail of the proficiency distribution as shown in Figure 1, implying

that a pattern of discontinuous mean reversion would produce spurious negative results. The

second set uses a cut point 15 percentage points below the actual cutoff, closer to the lower tail

of the distribution. Discontinuous mean reversion would produce spurious positive results in this

sample.

       Table 10 presents our basic optimal-bandwidth results from preceding tables, along with

results using an identical procedure at the pseudo-discontinuity points. These point estimates

will tend to be large in absolute magnitude, because they are derived from a Wald estimator with

a relatively small denominator. That is to say, there is not much evidence of a discontinuity in

treatment at either of these points, so any effect observed in the outcome variable will be

increased substantially. In analyzing these results, then, we are more interested in patterns of

sign and significance than the actual value of the point estimates per se.

       Significance patterns reveal few signs of concern. Across forty falsification tests, we

obtain 5 point estimates significant at the 10% level, 3 at the 5% level, and one at the 1% level.

In each case, these exceed the expected number of false positives under the null hypothesis of no

effects, but by no more than one. Moreover, the signs of the significant coefficients do not




                                                28
always concord with the hypothesized effects of mean reversion. In the first set of tests, where

we would be concerned about spurious negative mean reversion, only two of three significant

coefficients are in fact negative. In the second test, where our concern is positive mean

reversion, both significant coefficients are in fact negative.

             Looking more broadly, the first set of falsification tests yield 12 negative point estimate

in 20 tests, a plausible outcome under the null hypothesis of no effect in any test. The second set

provides an even split across positive and negative point estimates. In summary, using two sets

of regression discontinuity analyses where we might suspect mean reversion to be an even

greater concern, we find no evidence to validate these concerns.25



             5. Conclusions

             Previous research has raised a number of concerns about school accountability regimes.

Attaching high stakes to test scores, and in particular to proficiency rates on tests, may lead to a

number of resource allocation decisions that have the short-term impact of avoiding sanctions

but no impact, or in some cases even a negative impact, on long-term measures of student

productivity or well-being. While this study is incapable of providing a holistic estimate of the

impact of accountability relative to a counterfactual of no accountability (see Hanushek and

Raymond 2005 or Dee and Jacob 2011 for such exercises), we assess whether the sanctions

associated with the nation’s most comprehensive accountability system impact a fundamental

measure of student learning – year-over-year improvement in test scores.

             We find evidence that schools respond to the threat of initial sanctions in ways that

contribute to student learning, and that the ultimate sanction in the NCLB system – restructuring



ʹͷSee    online appendix Table D for complete results.


                                                          29
– yields even greater contributions to learning. Consistent with prior research, we find some

evidence that these gains are concentrated among students at or below the proficiency threshold.

Unlike prior research, we find that these gains are not accompanied by significant losses among

students well above the proficiency threshold – which may illustrate the importance of a

secondary accountability system measuring growth rather than accountability. We also find

evidence that schools focus in particular on improving the performance of the subgroup that

caused the school to miss AYP.

       The strong positive effects of restructuring – which appear to be broad, rather than

focused on the lowest-performing students – indicate that school management or leadership

problems constitute the single greatest obstacle to improved student performance. Indeed, the

existence of management or leadership problems might help explain why lesser sanctions –

including a targeted tutoring intervention associated with no positive effects even among the

targeted students – have no demonstrable effect. School leaders who cannot formulate strategies

to improve performance cannot be expected to react constructively to incentives to do so. The

association of positive effects with entry into the NCLB sanction system might also be

interpreted as evidence of effective leadership reactions – among those schools at the threshold

of AYP, the ones with effective leadership are the ones who find ways to increase proficiency

rates and exit the sanction system, leaving only schools with less-effective leaders behind.

       Even with this admittedly speculative interpretation of the results, one should not jump to

the conclusion that a No Child Left Behind-style sanction regime is an effective way to identify

schools in need of leadership change and implement that change. Presumably, more targeted

strategies could achieve the same results without the need to wait for six years’ worth of




                                               30
standardized test results. These results do highlight the need for further research into the nature

of effective school leadership and management.



References
Ahn, T. and J.L. Vigdor (2014) “When Incentives Matter Too Much: Explaining Significant
Responses to Irrelevant Information.” NBER Working Paper # 20321.
Angrist, J., E. Bettinger, and M. Kremer (2006) “Long-Term Consequences of Secondary School
Vouchers: Evidence from Administrative Records in Colombia.” American Economic Review
96(3): 847-862.
Bettinger, E.P. (2005) “The Effect of Charter Schools on Charter Students and Public Schools.”
Economics of Education Review 24(2): 133-147.
Bifulco, R. and H.F. Ladd (2006) “The Impacts of Charter Schools on Student Achievement:
Evidence from North Carolina.” Education Finance and Policy 1(1):50-90.
Burch, P. (2007) “Supplemental Education Services under NCLB: Emerging Evidence and
Policy Issues.” Boulder: Educational Policy Research Unit, University of Colorado.
Chakrabarti, R. (2014) “Incentives and Responses under No Child Left Behind: Credible Threats
and the Role of Competition.” Journal of Public Economics 110 (1) 124-146.
Chakrabarti, R. (2008a) “Can Increasing Private School Participation and Monetary Loss in a
Voucher Program Affect Public School Performance? Evidence from Milwaukee.” Journal of
Public Economics 92 (5-6) 1371-1393.
Chakrabarti, R. (2008b) “Impact of Voucher Design on Public School Performance: Evidence
from Florida and Milwaukee Voucher Programs.” FRB of New York Staff Report #315.
Chatterji, M., Y.A. Kwon, and C. Sng (2006) “Gathering Evidence on an After-School
Supplemental Instruction Program: Design Challenges and Early Findings in Light of NCLB.”
Education Policy Analysis Archives v.14 pp.1-44.
Chetty, R., J.N. Friedman, and J.E. Rockoff (2011) “The Long-Term Impacts of Teachers:
Teacher Value-Added and Student Outcomes in Adulthood.” NBER Working Paper #17699.
Chiang, H. (2009) “How Accountability Pressure on Failing Schools Affects Student
Achievement.” Journal of Public Economics v.93 pp.1045-1057.
Clotfelter, C.T., H.F. Ladd, J.L. Vigdor, and R.A. Diaz (2004) “Do School Accountability
Systems Make It More Difficult for Low-Performing Schools to Attract and Retain High-Quality
Teachers?” Journal of Policy Analysis and Management 23(2): 251-271.




                                                31
Clotfelter, C., E. Glennie, H. Ladd, and J. Vigdor (2008) “Would Higher Salaries Keep Teachers
in High-Poverty Schools? Evidence from a Policy Intervention in North Carolina.” Journal of
Public Economics v.92 pp.1352-1370.
Craig, S.G., S.A. Imberman and A. Perdue (2013) “Does it Pay to get an A? School Resource
Allocations in Response to Accountability Ratings.” Journal of Urban Economics v.73 pp.30-
42.
Dee, T.S. and B. Jacob (2011) “The Impact of No Child Left Behind on Student Achievement.”
Journal of Policy Analysis and Management 30(3):418-446.
Figlio, D.N. and L.W. Kenny (2007) “Individual Teacher Incentives and Student Performance.”
Journal of Public Economics v.91 pp.901-914.
Figlio, D.N. and J. Winicki (2005) “Food for Thought: The Effects of School Accountability
Plans on School Nutrition.” Journal of Public Economics 89(2-3): 381-394.
Figlio, D.N. (2006) “Testing, Crime, and Punishment.” Journal of Public Economics 90(4-5):
837-851.
Good, A., P. Burch, M. Stewart, R. Acosta, C. Heinrich, K. Jones and A.W. Herrera (2011)
“Instruction Matters: Lessons from a Mixed-Method Evaluation of Supplemental Education
Services under No Child Left Behind.” Unpublished manuscript.
Greene, J.P. and M.A. Winters (2003) “When Schools Compete: The Effects of Vouchers on
Florida Public School Achievement.” Manhattan Institute for Policy Research Education
Working Paper #2.
Hahn, J., P. Todd, and W. van der Klaauw (2001) “Identification and Estimation of Treatment
Effects with a Regression-Discontinuity Design.” Econometrica 69(1): 201-209.
Hanushek, E.A., J.F. Kain, and S.G. Rivkin (2004) “Disruption versus Tiebout Improvement:
The Costs and Benefits of Switching Schools.” Journal of Public Economics 88: 1721-1746.
Hanushek, E.A. and M.E. Raymond (2005) “Does School Accountability Lead to Improved
Student Performance?” Journal of Policy Analysis and Management 24(2): 297-327.
Heinrich, C., R.H. Meyer, and G. Whitten (2010) “Supplemental Education Services Under No
Child Left Behind: Who Signs Up, and What do They Gain?” Educational Evaluation and
Policy Analysis v.32 pp.273-298.
Hemelt, S.W. (2011) “Performance Effects of Failure to Make Adequate Yearly Progress (AYP):
Evidence from a Regression Discontinuity Approach.” Economics of Education Review v.30
pp.702-723.
Hoxby, C.M. (2000) “Does Competition Among Public Schools Benefit Students and
Taxpayers?” American Economic Review 90(5): 1209-38.
Imbens, G.W. and K. Kalyanaraman (2012) “Optimal Bandwidth Choice for the Regression
Discontinuity Estimator.” Review of Economic Studies 79(3): 933-959.


                                             32
Imbens, G.W. and T. Lemieux (2008) “Regression Discontinuity Designs: A Guide to Practice.”
Journal of Econometrics 142(2): 615-635.
Jacob, B.A. and S.D. Levitt (2003) “Rotten Apples: An Investigation of the Prevalence and
Predictors of Teacher Cheating.” Quarterly Journal of Economics 118(3): 843-877.
Jacob, B.A. (2005) “Accountability, Incentives, and Behavior: The Impact of High-Stakes
Testing in the Chicago Public Schools.” Journal of Public Economics v.89 pp.761-796.
Ladd, H.F. (1999) “The Dallas School Accountability and Incentive Program: An Evaluation of
its Impacts on Student Outcomes.” Economics of Education Review 18(1): 1-16.
Lee, D.S. and T. Lemieux (2010) “Regression Discontinuity Designs in Economics.” Journal of
Economic Literature 48(2): 281-355.
Kane, T.J. and D.O. Staiger (2002) “The Promise and Pitfalls of Using Imprecise School
Accountability Measures.” Journal of Economic Perspectives 16(4): 91-114.
McCrary, J. (2008) “Manipulation of the Running Variable in the Regression Discontinuity
Design: A Density Test.” Journal of Econometrics 142(2): 698-714.
Muñoz, M.A., F. Chang, and S.M. Ross (2012) “No Child Left Behind and Tutoring in Reading
and Mathematics: Impact of Supplemental Educational Services on Large Scale Assessment.”
Journal of Education for Students Placed At Risk v.17 pp.186-200.
Muralidharan, K. and V. Sundararaman (2011) “Teacher Performance Pay: Experimental
Evidence from India.” Journal of Political Economy v.119 pp.39-77.
Neal, D. and D. Schanzenbach (2010) “Left Behind By Design: Proficiency Counts and Test-
Based Accountability.” Review of Economics and Statistics 92(2): 263-283.
Reback, R. (2008) “Teaching to the Rating: School Accountability and the Distribution of
Student Achievement.” Journal of Public Economics 92(5-6): 1394-1415.
Rickles, J.H. and M.K. Barnhart (2007) “The Impact of Supplemental Educational Services
Participation on Student Achievement: 2005-06.” LAUSD Program Evaluation and Research
Branch. Planning, Assessment and Research Division Publication #352.
Rothstein, J. (2007) “Does Competition Among Public Schools Benefit Students and Taxpayers?
Comment.” American Economic Review 97(5): 2026-2037.
Rouse, C.E., J. Hannaway, D. Goldhaber, and D. Figlio (2013) “Feeling the Florida Heat? How
Low-Performing Schools Respond to Voucher and Accountability Pressure.” American
Economic Journal: Economic Policy v.5 pp.251-281.
Rouse, C.E. (1998) “Private School Vouchers and Student Achievement: An Evaluation of the
Milwaukee Parental Choice Program.” Quarterly Journal of Economics 113(2): 553-602.
Ryan, S. and S. Fatani (2005) “SES Tutoring Programs: An Evaluation of the Second Year: Part
One of a Two Part Report.” Chicago Public Schools Office of Research, Evaluation, and
Accountability.


                                             33
Sass, T.R. (2006) “Charter Schools and Student Achievement in Florida.” Education Finance
and Policy 1(1): 91-122.
Springer, M.G., J. Pane, V. Le, D. McCaffrey, S.F. Burns, L. Hamilton, and B. Stecher (2012)
“Team Pay for Performance: Experimental Evidence from the Round Rock Pilot Project on
Team Incentives.” Educational Evaluation and Policy Analysis v.34 pp.367-390.
Springer, M.G. (2008) “The Influence of an NCLB Accountability Plan on the Distribution of
Student Test Score Gains.” Economics of Education Review v.27 pp.556-563.
West, M.R. and P.E. Peterson (2006) “The Efficacy of Choice Threats Within School
Accountability Systems: Results from Legislatively Induced Experiments.” Economic Journal
116(510): C46-C62.
Winters, M.A., J.R. Trivitt, and J. Greene (2010) “The Impact of High-Stakes Testing on Student
Proficiency in Low-Stakes Subjects: Evidence from Florida’s Elementary Science Exam.”
Economics of Education Review v.29 pp.138-146.
Yuan, K., V. Le, D.F. McCaffrey, J.A. Marsh, L. Hamilton, B. Stecher and M.G. Springer (2013)
“Incentive Pay Programs Do Not Affect Teacher Motivation or Reported Practices: Results from
Three Randomized Studies.” Educational Evaluation and Policy Analysis v.35 pp.3-22.
Zimmer, R., B. Gill, P. Razquin, K. Booker, and J.R. Lockwood (2007) “State and Local
Implementation of the No Child Left Behind Act: Volume I – Title I School Choice,
Supplemental Educational Services, and Student Achievement.” Report to the U.S. Department
of Education Office of Planning, Evaluation, and Policy Development.




                                             34
                            Table 1: The NCLB sanction regime
Number of consecutive
 years missed AYP in
     same subject       Sanction
          1             None; placement on watch list, develop school improvement plan
                        District must offer transfers (with transportation) to higher-performing
         2              public schools in the same district. School listed as “needs
                        improvement.”
                        District must offer supplemental education services to students
         3
                        qualifying for free or reduced price lunch
                        School must undertake “corrective action.” Corrective actions may
         4              include staff/leadership changes, curriculum changes, instructional
                        time changes, or appointment of outside advisors.
         5              School must formulate a restructuring plan.
                        School must implement the restructuring plan. Restructuring must
                        involve either conversion to a charter school, replacement of the
         6
                        principal and most staff, state takeover, contracting with another entity
                        to manage the school, or similar major change to school governance.




                                            35
Table 2: Summary Statistics by NCLB Sanction Category
                                                          Sanction imposed in year t+1 upon failure in year t
                                                          (Threat invoked in year t+1 upon failure in year t)
                          None         None      Transfers         SES        Transfers          SES        Crctv. Act. Rstrctrg. Plan Rstrctrg.
Variable                  (SES)    (Transfers)     (SES)      (Transfers) (Crctv. Act.) (Crctv. Act.) (Rstrg. Plan)         (Rstrctrg.)      (none)
' reading score           0.030        0.015        0.011         0.006         0.034           0.029          0.044            0.032         0.103
                         (0.521)     (0.592)      (0.592)       (0.569)        (0.539)        (0.587)         (0.564)         (0.567)       (0.517)
' math score              0.092       -0.087       -0.009         0.117         0.125          -0.048          0.136            0.141         0.137
                         (0.512)     (0.577)      (0.549)       (0.549)        (0.529)        (0.581)         (0.540)         (0.536)       (0.510)
School made AYP           0.753        0.672        0.426         0.438         0.352           0.193          0.243            0.189         0.181
                         (0.431)     (0.470)      (0.494)       (0.496)        (0.478)        (0.395)         (0.429)         (0.391)       (0.385)
School score              0.052        0.032       -0.028        -0.033        -0.062          -0.108         -0.0990          -0.120        -0.130
                         (0.110)     (0.126)      (0.124)       (0.115)        (0.134)        (0.118)         (0.128)         (0.127)       (0.117)
School size               246.5        252.3        343.1         269.7         287.5           376.9          365.6            399.3         418.0
                         (162.0)     (179.1)      (183.5)       (176.9)        (183.0)        (178.1)         (177.0)         (167.6)       (158.0)
% Black                   0.186        0.203        0.281        0.344          0.321          0.308           0.292           0.345          0.364
                         (0.389)     (0.403)      (0.449)       (0.475)        (0.467)        (0.462)         (0.453)         (0.475)       (0.481)
% Hispanic                0.090        0.074        0.084         0.089         0.119           0.104          0.114            0.124         0.140
                         (0.286)     (0.261)      (0.277)       (0.284)        (0.324)        (0.306)         (0.318)         (0.330)       (0.347)
% FRL eligible            0.427        0.404        0.458         0.498         0.529           0.502          0.515           0.546          0.590
                         (0.495)     (0.491)      (0.498)       (0.500)        (0.499)        (0.500)         (0.500)         (0.498)       (0.492)
% LEP                     0.080       0.044        0.051         0.068          0.100           0.063          0.080            0.090         0.105
                         (0.272)     (0.205)      (0.219)       (0.252)        (0.300)        (0.244)         (0.272)         (0.286)       (0.306)
% Disabled                0.123        0.122        0.127         0.136         0.128           0.123          0.124            0.124         0.127
                         (0.328)     (0.328)      (0.333)       (0.343)        (0.335)        (0.329)         (0.329)         (0.330)       (0.333)
% Female                  0.491       0.490        0.490          0.492         0.491           0.489          0.490            0.489         0.488
                         (0.500)     (0.500)      (0.500)       (0.500)        (0.500)        (0.500)         (0.500)         (0.500)       (0.500)
Observations             164,067    546,464       358,050       32,609         60,464         201,196         145,827         135,392       125,560
Note: Standard deviation in parentheses. Unit of observation is student/year. Math and reading scores are c-scores. “School made AYP” is
fraction of schools that made AYP in t+1. “School score” is the RD assignment variable that is less than zero if school missed AYP. All prior
sanctions remain imposed in addition to new sanction in t+1. Peer calculations at school/year level. “School size” counts the number of test takers.


                                                                       36
            Table 3: Regression Discontinuity Estimates of the Effect of Missing AYP
                                        Reading (n=8,264)                  Math (n=8,266)
At optimal bandwidth                          -0.00002                         0.0180*
                                              (0.0056)                         (0.0095)
Half optimal bandwidth                          0.0061                          -0.0117
                                              (0.0071)                         (0.0137)
Twice optimal bandwidth                        -0.0025                        0.0282 ***
                                              (0.0053)                         (0.0081)
At optimal bandwidth,                          -0.0004                          0.022**
including transferred students                 (0.431)                          (0.011)
Note: Standard errors in parentheses. Unit of observation is school/year, weighted by number of
students used to compute dependent variable. Dependent variable is mean year-over-year
change in standardized test score in the indicated subject between the year of AYP status
determination and the following year. Bandwidth determination is by the Imbens-Kalyanaraman
algorithm. Specifications factor out school-level aggregate characteristics including percent
minority, percent limited English proficient, and percent free/reduced lunch.
*** denotes an estimate significant at the 1% level; ** the 5% level; * the 10% level.




                                             37
     Table 4: RD estimates of the impact of exposure to the threat of the first NCLB sanction
First sanction is transfers           Reading (n=3,241)                     Math (n=3,244)
At optimal bandwidth                         0.0203                             0.0473**
                                            (0.0140)                            (0.0204)
Half optimal bandwidth                       0.0086                              -0.0197
                                            (0.0218)                            (0.0322)
Twice optimal bandwidth                      0.0200*                           0.0681***
                                            (0.0111)                            (0.0170)
At optimal bandwidth,                        0.0160                            0.0759***
including transferred students              (0.0118)                             (0.017)

First sanction is SES                     Reading (n=958)                   Math (n=957)
At optimal bandwidth                           0.0161                           0.0285*
                                              (0.0136)                         (0.0163)
Half optimal bandwidth                         0.0119                          0.0350*
                                              (0.0170)                         (0.0204)
Twice optimal bandwidth                       0.0227*                          0.0241*
                                              (0.0127)                         (0.0147)
At optimal bandwidth,                         0.0221*                          0.0338**
including transferred students                (0.0131)                         (0.0153)
Note: Standard errors in parentheses. Unit of observation is school/year, weighted by number of
students used to compute dependent variable. Dependent variable is mean year-over-year
change in standardized test score in the indicated subject between the year of AYP status
determination and the following year. Bandwidth determination is by the Imbens-Kalyanaraman
algorithm. Specifications factor out school-level aggregate characteristics including percent
minority, percent limited English proficient, and percent free/reduced lunch.
*** denotes an estimate significant at the 1% level; ** the 5% level; * the 10% level.




                                              38
  Table 5: RD estimates of the impact of exposure to NCLB sanction and threat of next sanction
Sanction (threat)                                    Reading                       Math
Transfers (SES)                                       0.0178                      0.0144
n=1,486                                              (0.0124)                    (0.0181)
SES (Transfers)                                      -0.0064                      -0.0069
n=177                                                (0.0377)                    (0.0337)
SES (Corrective Action)                              -0.0244                      -0.0219
n=727                                                (0.0268)                    (0.0368)
Transfers (Corrective Action)                        -0.0289                      -0.0442
n=310                                                (0.0244)                    (0.0243)
Corrective Action (Restructuring Plan)                 0.035                      0.0231
n=549                                                (0.0261)                    (0.0247)
Restructuring Plan (Restructuring)                  -0.0558**                     0.0278
n=442                                                (0.0288)                    (0.0258)
Restructuring                                        0.0264*                     0.0547**
n=367                                                (0.0144)                    (0.0263)
Note: Standard errors in parentheses. Unit of observation is school/year, weighted by number of
students used to compute dependent variable. Dependent variable is mean year-over-year
change in standardized test score in the indicated subject between the year of AYP status
determination and the following year. Bandwidth determination is by the Imbens-Kalyanaraman
algorithm. Specifications factor out school-level aggregate characteristics including percent
minority, percent limited English proficient, and percent free/reduced lunch.
*** denotes an estimate significant at the 1% level; ** the 5% level; * the 10% level.




                                             39
         Table 6: RD estimates of the impact of restructuring on staff turnover
Teacher turnover
At optimal bandwidth                                          0.049**
                                                              (0.025)
Half optimal bandwidth                                        0.056*
                                                              (0.029)
Twice optimal bandwidth                                        0.033*
                                                              (0.019)

Principal turnover
At optimal bandwidth                                            0.134*
                                                                (0.071)
Half optimal bandwidth                                          0.187*
                                                                (0.104)
Twice optimal bandwidth                                          0.059
                                                                (0.058)
Note: Standard errors in parentheses. Unit of observation is school/year, weighted by
number of students used to compute dependent variable. Dependent variables defined
in the text. Bandwidth determination is by the Imbens-Kalyanaraman algorithm.
Specifications factor out school-level aggregate characteristics including percent
minority, percent limited English proficient, and percent free/reduced lunch.
*** denotes an estimate significant at the 1% level; ** the 5% level; * the 10% level.




                                              40
         Table 7: RD estimates of the effect of NCLB sanctions and threats on test score gains, by quartile of initial test score
Sanction                                        Reading                                                  Math
(Threat)                   Lowest           2nd           3rd        Highest        Lowest          2nd            3rd          Highest
General Impact of          -0.0023       -0.0137       -0.0026        0.0019      0.0363***      0.0146         0.0194*          0.0015
Missing AYP               (0.0130)       (0.0138)     (0.0103)      (0.0066)       (0.0116)     (0.0103)        (0.0103)        (0.0114)
None                       -0.0054       -0.0251       -0.0036        0.0014      0.0548**      0.0506**         0.0308          0.0039
(Transfers)               (0.0388)       (0.0375)     (0.0247)      (0.0173)       (0.0272)     (0.0236)        (0.0244)        (0.0261)
Transfers                 0.1045**     0.1127***       0.0506*        0.0195        0.0404       0.0237         -0.0077          0.0028
(SES)                     (0.0448)       (0.0421)     (0.0277)      (0.0200)       (0.0322)     (0.0299)        (0.0308)        (0.0239)
SES                        -0.0897       -0.0808        0.0050       -0.0065        0.0007       0.0160          0.0282          0.0090
(Corrective Action)       (0.0707)       (0.0603)     (0.0348)      (0.0223)       (0.0382)     (0.0413)        (0.0363)        (0.0391)
Corrective Action           0.0378        0.0427        0.0305        0.0222        0.0360       0.0042         0.0531*         -0.0021
(Restructuring Plan)      (0.0373)       (0.0444)     (0.0256)      (0.0182)       (0.0259)     (0.0294)        (0.0311)        (0.0299)
Restructuring Plan       -0.0788**      -0.0936**      -0.0373       -0.0349        0.0424       -0.0000         0.0078          0.0308
(Restructuring)           (0.0379)       (0.0387)     (0.0290)      (0.0231)       (0.0346)     (0.0300)        (0.0341)        (0.0380)
Restructuring               0.0346        0.0232        0.0087        0.0172        0.0418       0.0424        0.0598**         0.0605*
                          (0.0217)       (0.0194)     (0.0179)      (0.0206)       (0.0299)     (0.0298)        (0.0298)        (0.0313)
Note: Standard errors in parentheses. Unit of observation is school/year, weighted by number of students used to compute dependent
variable. Dependent variable is mean year-over-year change in standardized test score in the indicated subject between the year of
AYP status determination and the following year. All estimates utilize the optimal bandwidth as determined by the Imbens-
Kalyanaraman algorithm. Specifications factor out school-level aggregate characteristics including percent minority, percent limited
English proficient, and percent free/reduced lunch.
*** denotes an estimate significant at the 1% level; ** the 5% level; * the 10% level.




                                                                  41

    Table 8: RD estimates of the effect of NCLB sanctions on students in the critical subgroup
Sanction/                                                   Reading                   Math
Threat
General Impact of Missing AYP                                 0.009                 0.038**
                                                            (0.025)                  (0.015)
None/                                                       0.043**                   0.053
Transfers                                                   (0.022)                  (0.036)
Transfers/                                                   0.029                   -0.043
SES                                                         (0.049)                  (0.045)
SES/                                                         0.025                    0.040
Corrective Action                                           (0.032)                  (0.037)
Corrective Action/                                           0.068                    0.044
Restructuring Plan                                          (0.062)                  (0.046)
Restructuring Plan/                                          -0.203                 0.095**
Restructuring                                               (0.138)                  (0.038)
Restructuring/                                               0.044                    0.043
None                                                        (0.075)                  (0.042)
Note: Standard errors in parentheses. Unit of observation is school/year, weighted by number of
students used to compute dependent variable. Dependent variable is mean year-over-year
change in standardized test score in the indicated subject between the year of AYP status
determination and the following year. All estimates utilize the optimal bandwidth as determined
by the Imbens-Kalyanaraman algorithm. Specifications factor out school-level aggregate
characteristics including percent minority, percent limited English proficient, and percent
free/reduced lunch.
*** denotes an estimate significant at the 1% level; ** the 5% level; * the 10% level.
                              




                                             42
    Table 9: RD estimates of the impact of SES, Free/Reduced Lunch Eligible Students Only
                                                    Reading                        Math
SES implemented as second sanction                   -0.0393                      0.0437
                                                    (0.0501)                     (0.0382)
SES implemented as first sanction                    -0.0040                      0.0083
                                                    (0.0454)                     (0.0357)
Note: Standard errors in parentheses. Unit of observation is school/year, weighted by number of
students used to compute dependent variable. Dependent variable is mean year-over-year
change in standardized test score in the indicated subject between the year of AYP status
determination and the following year. All estimates utilize the optimal bandwidth as determined
by the Imbens-Kalyanaraman algorithm. Specifications factor out school-level aggregate
characteristics including percent minority, percent limited English proficient, and percent
free/reduced lunch.
*** denotes an estimate significant at the 1% level; ** the 5% level; * the 10% level.




                                             43
                            Table 10: Summary of Falsification Tests
Sanction/                     Actual result      Pseudo-RD at 15%           Pseudo-RD at 15%
Threat                                             above threshold            below threshold
                           Math       Reading     Math        Reading        Math       Reading
Overall                   0.018*       0.0002   -1.09***        0.061       0.0097        0.130
None/                     0.047**       0.021    -13.26        -0.864       -0.040       -0.036
Transfers
None/                       0.029*       0.016       -0.042       -0.844       0.083       0.032
SES
Transfers/                   0.014       0.018        0.004       -0.049       0.068       0.258
SES
SES/                        -0.007      -0.006        0.328        0.333      -0.586     -0.628**
Transfers
SES/                        -0.022      -0.024       -0.090        0.007       0.125      -0.111
Corrective Action
Transfers/                  -0.044      -0.029      0.132*         0.046      -0.077       0.121
Corrective Action
Corrective Action/           0.023       0.035       -0.038       -0.038      -0.132      -0.114
Restructuring Plan
Restructuring Plan/          0.028     -0.056**        1.86       -0.065      -.423*      -0.392
Restructuring
Restructuring/             0.055**      0.026*     -0.125**       -0.048       0.034       0.293
None
Note: Unit of observation is school/year, weighted by number of students used to compute
dependent variable. Dependent variable is mean year-over-year change in standardized test
score in the indicated subject between the year of AYP status determination and the following
year. All estimates utilize the optimal bandwidth as determined by the Imbens-Kalyanaraman
algorithm. Specifications factor out school-level aggregate characteristics including percent
minority, percent limited English proficient, and percent free/reduced lunch.
*** denotes an estimate significant at the 1% level; ** the 5% level; * the 10% level




                                              44
Figure 1: Density plot by assignment variable




Figure 2: Covariates by assignment variable



                                               45
    A. Reading




    B. Math
Figure 3: Probability of meeting the AYP criteria by assignment variable




                                             46
      ͲǤʹ


    ͲǤͳͷ


      ͲǤͳ
                                                                 Ǥ
    ͲǤͲͷ                                                         ͻͷΨ
                                                                 ͻͷΨ
       Ͳ
            Ͳ   ͲǤͳ         ͲǤʹ   ͲǤ͵   ͲǤͶ         ͲǤͷ   ͲǤ͸

    ǦͲǤͲͷ


     ǦͲǤͳ


Figure 4: Local Linear Regression Estimates with Varying Bandwidths. All schools.

      ͲǤʹ
    ͲǤͳͺ
    ͲǤͳ͸
    ͲǤͳͶ
    ͲǤͳʹ
                                                                  Ǥ
      ͲǤͳ
                                                                  ͻͷΨ
    ͲǤͲͺ
                                                                  ͻͷΨ
    ͲǤͲ͸
    ͲǤͲͶ
    ͲǤͲʹ
       Ͳ
            Ͳ         ͲǤʹ         ͲǤͶ         ͲǤ͸          ͲǤͺ
    ǦͲǤͲʹ


Figure 5: Local Linear Regression Estimates with Varying Bandwidths. Schools threatened with
restructuring.




                                                   47
