                                 NBER WORKING PAPER SERIES




                           A REVEALED PREFERENCE RANKING OF
                              U.S. COLLEGES AND UNIVERSITIES

                                          Christopher Avery
                                           Mark Glickman
                                           Caroline Hoxby
                                           Andrew Metrick

                                         Working Paper 10803
                                 http://www.nber.org/papers/w10803


                       NATIONAL BUREAU OF ECONOMIC RESEARCH
                                1050 Massachusetts Avenue
                                  Cambridge, MA 02138
                                     September 2004




The authors' affiliations are, respectively, John F. Kennedy School of Government at Harvard University;
Department of Health Services at the Boston University School of Public Health, Department of Economics
at Harvard University, and Department of Finance of The Wharton School at the University of Pennsylvania.
We thank Bruce Sacerdote, Joel Waldfogel and seminar participants at Columbia, Wharton, Yale, the
University of Texas at Austin, University of California Santa Cruz, Harvard, and the National Bureau of
Economic Research for helpful comments. We thank Andrew Fairbanks and Jim Barker, who helped to
design and implement the College Admissions Project survey. We also thank Michael Behnke, Larry Momo,
Jay Matthews, and the 510 high school counselors who made the survey happen. We are grateful for the aid
of many hard-working and perspicacious research assistants: Joshua Barro, James Carmichael, Rohit
Chandwani, Michael Cuthbert, Suzanne Ko, Ilyana Kuziemko, Michael McNabb, Kathryn Markham, Emily
Oster, Chris Park, Jenna Robins, Aaron Roth, Maria Shim, Catherine So, Rania Succar, Michael Thakur,
Kenneth Wang, and Jill Zitnik. Scott Resnick deserves very special thanks. The first version of this paper
appeared in October 2002. The views expressed herein are those of the author(s) and not necessarily those
of the National Bureau of Economic Research.

©2004 by Christopher Avery, Mark Glickman, Caroline Hoxby, and Andrew Metrick. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including © notice, is given to the source.
A Revealed Preference Ranking of U.S. Colleges and Universities
Christopher Avery, Mark Glickman, Caroline Hoxby, and Andrew Metrick
NBER Working Paper No. 10803
September 2004
JEL No. I2, C11, C25

                                           ABSTRACT

We show how to construct a ranking of U.S. undergraduate programs based on students' revealed

preferences. We construct examples of national and regional rankings, using hand-collected data on

3,240 high- achieving students. Our statistical model extends models used for ranking players in

tournaments, such as chess or tennis. When a student makes his matriculation decision among

colleges that have admitted him, he chooses which college "wins" in head-to-head competition. The

model exploits the information contained in thousands of these wins and losses. Our method

produces a ranking that would be difficult for a college to manipulate. In contrast, it is easy to

manipulate the matriculation rate and the admission rate, which are the common measures of

preference that receive substantial weight in highly publicized college rating systems. If our ranking

were used in place of these measures, the pressure on colleges to practice strategic admissions would

be relieved.

Christopher Avery                                     Caroline Hoxby
Harvard University                                    Department of Economics
John F. Kennedy School of Government                  Harvard University
79 John F. Kennedy Street                             Cambridge, MA 02138
Cambridge, MA 02138                                   and NBER
and NBER                                              choxby@harvard.edu
christopher_avery@ksg.harvard.edu
                                                      Andrew Metrick
Mark Glickman                                         The Wharton School
Department of Health Services                         University of Pennsylvania
School of Public Health                               3620 Locust Walk
Boston University                                     Philadelphia, PA 19104
mg@math.bu.edu                                        and NBER
                                                      metrick@wharton.upenn.edu
                                      Executive Summary

We show how to construct a ranking of U.S. undergraduate programs based on how desirable
students find them. We call this the revealed preference ranking of colleges. We construct
examples of national and regional rankings, using data we collected on the college
applications, admissions, and matriculation of 3,240 high- achieving students.

Our statistical model extends models used for ranking players in tournaments, such as chess or
tennis. When a student decides to matriculate at one college, among those that have admitted
him, he effectively decides which college "won" in head-to-head competition. The model
efficiently combines the information contained in thousands of these wins and losses.

Our method produces a ranking that would be very difficult for a college to manipulate. In
contrast, colleges can easily manipulate the matriculation rate and the admission rate, which
are the crude proxies commonly used to measure colleges' desirability. Because there is a
strong demand for measures of colleges' desirability, colleges are forced to advertise their
matriculation and admissions rates. Moreover, college guides like U.S. News are forced to give
substantial weight to the matriculation and admissions rates. These crude proxies are not only
misleading; they induce colleges to engage in distorted conduct that decreases the colleges' real
selectivity while increasing the colleges' apparent desirability. So long as colleges are judged
based on their crude admissions and matriculation rates, they are unlikely to eliminate
strategic admissions or roll back early decision programs, which are the key methods of
manipulating the proxies. Many college administrators correctly perceive that they are in a
bad equilibrium. Yet, so long as the crude proxies are used, the bad equilibrium is likely to
persist. If our ranking method were used, the pressure on colleges to practice strategic
admissions would be relieved.

We rank more than 100 colleges in the national ranking, and we show how each college is
likely to fare in a head-to-head match up against specific rival colleges. We also show regional
rankings and demonstrate that they combine up to generate a truly national ranking among
colleges that are highly preferred. We explain how to think about niche colleges, such as
California Institute of Technology, whose applicants are self-selected to an unusual degree; and
we propose useful sub-rankings for certain types of colleges.
                                                                                                    1

                             I. Why a Revealed Preference Ranking?

       In this study, we show how to construct a ranking of U.S. undergraduate programs

based on students' revealed preferences –that is, the colleges students prefer when they can

choose among them. The result is a ranking of colleges based on their desirability. We develop

a statistical model that logically extends models used for ranking players in tournaments, such

as chess and tennis. When a student makes his matriculation decision among colleges that

have admitted him, he chooses which college "wins" in head-to-head competition. The model

exploits the information contained in thousands of these wins and losses.

       We construct an example of our ranking using data from a survey of 3,240 highly

meritorious students that was specifically conducted for this study. Because we do not have a

fully representative sample of college applicants, we rank only about a hundred undergraduate

programs and our ranking is an example, not definitive. Nevertheless, we can show that our

ranking has advantages. In particular, it is less manipulable than crude measures of revealed

preference, such as the admissions rate and matriculation rate. A ranking constructed

according to our method would be a good substitute for the preference indicators that receive

substantial weight in formulas of high publicized college rating systems, like that of U.S. News

and World Report. Many colleges currently feel compelled to engage in strategic admissions

behavior in order to maximize their published college ratings. Use of our ranking method

would relieve this pressure.

       Rankings based on students' revealed preference measure a college's desirability in

students' eyes. Such desirability may reflect a college's quality, but it is unlikely to be identical

to quality. Indeed, the notion of what constitutes quality in a college is likely to differ from

person to person. Faculty, parents, policy makers, and students may all assign different

weights to colleges' characteristics. Why then construct a revealed preference ranking at all,

which merely shows the value that students (in combination with their parents) put on

colleges?

       The primary reason that we are motivated to construct a revealed preference ranking is

a practical one. Parents and students demand revealed preference information and college
                                                                                                    2

guides feel obliged to offer them some. The two measures of preference used by college guides

are the crude matriculation rate and crude admissions rate. One objection to these measures is

that they are inefficiently coarse. Our revealed preference ranking efficiently aggregates the

information contained in individual students' decisions. Another serious objection to these

measures is that colleges can manipulate them, though at a cost. Colleges do not necessarily

want to manipulate their matriculation rate and admissions rate; they feel compelled to do so.

A college that does not manipulate these rates, when its competitors do, loses ground in highly

publicized college ratings. Such lost ground will eventually have real effects on the college's

ability to recruit students, attract donations, and so on.1 In short, U.S. colleges are in a bad

equilibrium: colleges manipulate the rates even though they would all be better off if no

college manipulated the rates. If a revealed preference ranking like ours were used, colleges

would find it extremely hard to "defect" and the bad equilibrium would not arise. All parties

(including the college guides) should be pleased to have a measure of revealed preference that

limits or even eliminates manipulation.

       We have attempted to justify constructing a good indicator of revealed preference by

pointing out that one is demanded. But, why do students and their parents demand such

measures? There are a few possible answers.

       First, students believe and act as though their peers matter. This may be because peer

quality affects the level of teaching that is offered. Alternatively, students may learn directly

from their peers. If such channels for peer effects are important, then it is reasonable for

students to care about whether they are surrounded by peers with high college aptitude.

Students will want to see a revealed preference ranking because it will show them which

colleges can offer the highest concentration of desirable peers. A more preferred college wins

more often in matriculation tournaments. Thus, it can afford to be more selective and can offer

peers with higher aptitude.

       Second, students–especially the high achieving students on whom we focus–are not



       1
           See evidence on the real effects of the ratings, see Ehrenberg and M onks (1999).
                                                                                                             3

ignorant about college quality. They gather information about colleges' quality from

publications, older siblings, friends who are attending college, college counselors, and their

own visits to colleges. A student may place the greatest weight on his own observations of

quality, but he will also put some weight on the observations of other students, simply because

his own sample of observations is too small to be representative. A revealed preference

ranking efficiently aggregates observations about quality from thousands of students. There

are parallels to other industries. For instance, people judge restaurant and hotel quality based

partly on their own experiences, but they also want to know about other people's experiences.

This is why there is a demand for guides like Zagat's, which aggregate people's observations

about hotels and restaurants.

        Third, it has long been hypothesized that specific colleges' degrees serve as signals of a

student's aptitude, which is hard for future employers to observe directly [Spence, 1974]. In

equilibrium, a college's degree signals the aptitude of the students who actually attend it. For

instance, there will be an equilibrium only if a Princeton degree signals aptitude that is

consistent with the actual distribution of aptitude among Princeton students. This is another

reason for students to care about the ability of their peers and, thus, their college's tendency to

attract students.2

        In Section II of the paper, we further discuss the weaknesses of using the matriculation

rate and the admissions rate as measures of revealed preference, and show how these

measures can easily be manipulated. In Section III, we present our statistical model of college

choice as a multiple comparison problem. We show how to account for the potentially

confounding effects of tuition discounts, financial aid, and other factors that might make a

college "win" when it would lose on the basis of its intrinsic desirability.

        The data for our study was hand-collected in a survey of 510 high schools, with surveys



        2
           W e do not know, however, that such signaling is actually important. Students may be able to
use indicators other than their college degrees to inform future employers about their abilities. For
instance, a student whose abilities much exceed those of his college classmates could reveal his very high
grades, his leadership, his ability to win national fellowships, and so on.
                                                                                                  4

returned for 3,240 students. Section IV describes the survey methodology and provides

summary statistics for the sample. These data are used to estimate the model, with the results

discussed in Section V. Section VI concludes the paper.



             II. The Manipulability of Various Measures of Revealed Preference

       One of the two common measures of revealed preference is the matriculation rate–the

share of accepted students who matriculate at a college:

(1)


There are several methods by which a college can manipulate its matriculation rate. The

reason that most methods work is that the matriculation rate is just an aggregate statistic and

has no way of taking account of the composition of the pool of admittees (higher or lower

merit?) and or of which students within the pool of admittees are matriculating (those with the

best alternative offers or those with worst alternative offers?).

       An early decision program is the most dramatic means by which a college can

manipulate its matriculation rate. Every early decision admittee has a 100 percent probability

of matriculating, so –mechanically– the more students whom a college admits under its early

decision program, the higher is its matriculation rate. (It is important to distinguish between

early decision, in which a student commits to matriculate if admitted, and early action, in which

a student is admitted early but can apply to numerous other colleges and turn down the early

admission offer.) An early decision program is not without costs for the college. As Avery,

Fairbanks, and Zeckhauser (2003) show, college lowers their admissions standards for early

decision applicants in order to induce them to pre-commit to matriculating and pre-commit to

having no alternative offers when it comes to negotiating over financial aid. As a college

admits more and more of its class under early decision, its actual admissions standards fall and

students will therefore experience less meritorious peers. Yet, by the standard of the

matriculation rate, the college's desirability will have risen.

       Another method by which a college can manipulate its matriculation rate is deliberately
                                                                                                         5

not admitting students who are likely to be admitted by close competitors or colleges that are

often more highly preferred. A college administrator may say to himself, "My college will

ultimately fail to attract good applicants unless I raise its matriculation rate. I can achieve this

with a strategic policy that denies admission to students who seem likely to be accepted by

colleges more desirable than mine. By systemically denying them admission, my college will

of course lose of its some most desirable students (because some percentage of the highly

desirable students would have matriculated). However, it is worthwhile to sacrifice the actual

desirability of my college class in order to appear more desirable on a flawed indicator." To

make this strategy concrete, suppose that Princeton wanted to raise its matriculation rate. It

could decide to admit only students who were very likely to fall just short of the admissions

thresholds for Harvard, Yale, Stanford, MIT, and other close competitors. The students

admitted would thus have no colleges in their "menus" that were close competitors to

Princeton, and they would be likely to matriculate. Students who attend Princeton would

almost certainly prefer that the university not pursue such a policy because it would reduce the

peer quality of their fellow students. Yet, by the standard of the matriculation rate, Princeton's

measured appeal would rise just as its actual appeal fell.

        We have not arbitrarily selected Princeton for our example. It is by no means alone in

appearing to practice somewhat strategic admissions (for other examples, see "Glass Floor:

How Colleges Reject the Top Applicants and Boost Their Status," 2001), but it makes for a

particularly clear example in our data.3 Consider Figure 1, which shows admissions at

Harvard, MIT, and Princeton. If a college is not practicing strategic admissions, then the

probability that a student is admitted ought to rise monotonically in his or her merit. In

contrast, a college that is strategic will have non-monotonic admissions probabilities. A

student's probability of admission will first rise in his or her merit and then fall as his or her

merit moves into the range in which the strategic college faces stiff competition. In other



        3
          As described below, we have the most ample data on the colleges that are the most selective.
Princeton provides the clearest example among the top several such colleges.
                                                                                                    6

words, the college will avoid admitting students in the range in which it is likely to lose in a

matriculation tournament. Finally, if the student's merit is high enough, a strategic college will

probably admit the student even if the competition will be stiff. This is because the prospective

gains from enrolling a "star" will more than make up for the prospective losses from a higher

                                              Figure 1




admissions rate and lower matriculation rate. (Recall that the crude admissions rate and

matriculation rate do not record who is admitted or matriculates.)

       Although we realize that it is not a definitive measure of a student's merit, for the sake

of these purely illustrative figures, we use a student's combined SAT I score, measured in

national percentiles. This measure is at least readily understood and reasonably continuous. It

is also wholly unrelated to our ranking method.

       Examine MIT admissions in Figure 1. The probability of a student's being admitted
                                                                                                     7

rises steeply and monotonically in his or her combined SAT score, suggesting that MIT is not

engaging in strategic admissions. Now examine Harvard admissions in Figure 1. The line has

a flat region that suggests that the probability of a student's being admitted is about 10 percent

regardless of where his SAT scores in the range between the 93rd and the 98th percentiles.

Above the 98th percentile, a student's probability of admissions rises steeply. Finally, consider

Princeton admissions in Figure 1. At Princeton, the admissions probability rises to 20 percent

at the 93 percentile, then falls to 10 percent at the 98 percentile (precisely the region where

competition is toughest), and then rises again for students with SAT scores in the top 2

percentiles.

       In short, it appears that Princeton practices more strategic admissions than MIT or

Harvard. When we see the revealed preference ranking later in the paper, we will see that

Figure 1 makes sense because Harvard and MIT could benefit less from strategic admissions

than Princeton could. While Figure 1 is not definitive, it provides suggestive evidence that

even a highly prestigious school may practice potentially costly strategic admissions. Such

behavior is potentially costly to the actual quality of an admissions class, with no clear benefit

beyond a higher reported matriculation rate.

       The second of the two common proxies for revealed preference is the admission

rate–that is, the share of applicants who are admitted by a college:

(2)


There a several methods by which a college can manipulate its admissions rate. The reason

that most methods work is that the admissions rate is just an aggregate statistic. It does not

account for the composition of the pool of applicants (are they high or low merit?). It does not

account for which applicants a college admits.

       In forming a class of a given size, a college can admit fewer students if its matriculation

rate is higher. Therefore, the methods discussed above for manipulating the matriculation rate

are also methods for manipulating the admissions rate. For instance, if a college makes heavy

use of an early decision program, it only needs to admit only slightly more students than the
                                                                                                     8

number that it actually wishes to enroll. This is because the early decision admittees are pre-

committed to enrolling. The technique of not admitting applicants who are likely to be

admitted by close competitors also allows a college to publish a lower (better) admissions rate.

        In addition, colleges can manipulate their admissions rate by encouraging applications

from students who have little chance of actually gaining admission. A college can advertise

less stringent criteria than it actually applies. By doing so, it encourages marginal students to

apply, increases its number of applications, decreases its admissions rate, and raises its

apparent desirability, even though its real desirability has not changed. For instance, this is

how Toor (2000) described her job as an admissions officer at Duke University: "The job of

admissions officers is to recruit, to boost application numbers. The more applications, the lower

the admit rate, the higher the institutional ranking. Increasing application numbers is usually

the No. 1 mandate of the recruiting season. Partly, that means trying to get the very best

students to apply. But it also means trying to persuade those regular, old Bright Well-Rounded

Kids (B.W.R.K.'s, in admissionese) to apply -- so that the college can reject them and bolster its

selectivity rating."

        In short, the two conventional measures are manipulable by colleges, though at a cost.

If the goal of college admissions is to admit the optimal class, then colleges must systemically

deviate from this goal in order to manipulate their matriculation and admissions rates.

Colleges must sacrifice actual desirability for apparent desirability. Even if all colleges prefer

not to manipulate the crude rates, each college will lose if it refrains from manipulation when

other colleges do not refrain.

        How might colleges escape this bad equilibrium? If the measure of revealed preference

is not manipulable (or manipulable only by very complex, costly means), then all parties could

be better off. In the next section, we formally describe the statistical method we use to create a

revealed preference ranking of colleges. Here, we can give some intuition into why a ranking

based on our method is not prey to simple forms of manipulation. For this exercise, it may be

helpful for readers to think of some sport or game familiar to them.

        Our method is based on "wins" and "losses" in thousands of "tournaments" in which
                                                                                                     9

students are choosing the college at which to matriculate. Under this method, a college's

ranking vis-a-vis a competitor is based on its record of wins and losses. Colleges that rarely

compete directly in tournaments (because they are of very different selectivity) are ranked

using the win/loss records of intermediate colleges that link them through series of

tournaments: A routinely competes with B, B routinely competes with C, C routinely competes

with D, etc. Given our methods, there is no easy way for a college to artificially boost its

ranking with no true change in its appeal to students. For instance, recall the example in which

Princeton alters its acceptance decisions in order to avoid match-ups with Harvard, Yale,

Stanford and so on. We would be unable to rank Princeton rank vis-a-vis its close competitors

because its match-ups would always be against less selective colleges. That is, our estimates

would reflect the fact that Princeton was not admitting the highly meritorious students for

whom it should have been competing. We would see that, while it was consistently "winning,"

it was winning only among students who failed to get admitted to close competitors.

       Readers might also find it helpful if we stated what a college would need to do if it

were to manipulate our ranking successfully. None of the crude methods of manipulation

described above would work. A college would need to do something more subtle. Return to

the Princeton example, for concreteness. Princeton would need to find students in its applicant

pool who were likely to attend Princeton even if admitted to Harvard, Yale, MIT, Stanford, and

so on. Such students would have to exist exogenously; they could not be "created" by

Princeton's giving them extra aid to induce them to matriculate. (Giving them extra aid would

not work because we can observe and account for aid.) Moreover, Princeton would have to

identify these students using characteristics not observable to other colleges. If the trait that

Princeton used to pick out likely matriculators was observable (such as being a Princeton

alumnus' child), then this trait could be used as a control in any revealed preference ranking, as

we will do below with some characteristics collected in our study. Without an early decision

program to bind students or "secret" traits that distinguished its likely matriculators, a college

could not identify students whose matriculation tournaments it would win.
                                                                                                    10




                                          III. The Model

A. The Desirability of Colleges

       The exercise of ranking colleges is necessarily predicated on the notion that there are

latent indices of desirability on which college can be ranked. In the language of econometrics,

the exercise is based on the assumption there are latent variables that indicate the desirability

of each college (perhaps on multiple dimensions). Our measure of desirability encompasses

all characteristics of a school, including (perceived) educational quality, campus location, and

tuition. We do not claim to know how latent desirability is constructed. We simply assert that,

to the extent that students act in accordance with it, we can construct rankings.

       We suspect that latent desirability is well defined on a national basis for the most

academically elite colleges in the United States. We also suspect that latent desirability is

defined on a national basis for the most elite specialized colleges in the United States:

engineering schools, music schools, and so on. We would not be surprised to find, however,

that once we move below the most academically elite colleges, latent desirability is only well-

defined within regions of the country and perhaps within other dimensions. If we had a very

large, random sample of all college applicants, we could construct rankings within regions and

specialties and show where they joined up to become a national ranking. Given that the data

we use for our exercise is focused on high achieving students who do not apply much outside

the group of the most academically elite colleges, we will start by constructing a national

ranking of such colleges. We will rank only those that the data suggest have a national draw.

Subsequently, we construct regional rankings and discuss specialized rankings. Until then,

however, we encourage the reader to think of a college's latent desirability as being

unidimensional.

       For our exercise, is it necessary that all students identically perceive a college's

desirability? No. We will allow students' perception of a college's desirability to be distributed

around a mean level. Indeed, if there were no such distributions, all students would make

identical matriculation decisions when offered the same choices. We know that this does not
                                                                                                    11

occur. What we need for our exercise is a pattern of wins and losses that would arise if colleges

had latent desirabilities that were perceived with idiosyncratic noise added in.

        Finally, note that our exercise does not impose the existence of latent desirability; our

method simply will not work if widespread agreement on desirability does not exist. To see

this, suppose that there were no uniformity in how students perceived colleges' desirability.

Each student would act as though he had been randomly assigned a ranking of colleges, where

his ranking was independent of all other students' rankings. We would find no pattern in the

"wins" and "losses" because it would be random whether a college won or lost in head-to-head

competition for a student. Overall, we can afford to be agnostic about how students develop

preferences over colleges. Our data will only reveal such preferences to the extent that they are

systematic.

        The problem of ranking colleges can be framed as a collection of multiple comparisons.

Comparison data come from competitions in which alternatives are compared and an outcome

indicates that one alternative has been preferred over the others. Many sports and games fall

into this framework because players are compared via competition, and the winner of a

competition is deemed the "preferred alternative.'' Also, marketing applications, including

experiments in which consumers choose among products or services, are well-suited to

multiple comparison models. An important problem addressed by multiple comparison

models is how to rank objects when direct comparisons do not take place. For example, in the

context of a "Swiss system'' chess tournament, every competitor competes against only a few

other individuals rather than against every other competitor. That is, player A competes

against B, and B competes against C, but A does not compete against C. Yet, an inference is

still desired for the comparison of A versus C. In the context of college choice, every college

does not compete directly with every other college, though the goal is to draw conclusions

about all colleges' desirability.

B. Matriculation Tournaments as a Multiple Comparison Problem

        To understand how college choice can be viewed as a multiple comparison problem,

suppose that a collection of students has been admitted to a set of schools. Each schools’
                                                                                                             12

desirability is modeled as a latent distribution of values. Each student effectively holds a

tournament among the collection of schools that have admitted him; in our model this

tournament is played by taking one draw from each school’s distribution. The school with the

highest draw has "won" the multi-player tournament, and the student matriculates at that

school. Assuming that there are no confounding variables, a reasonable inference is that the

school that wins the multi-player tournament is preferred to the other schools in that

competition. By aggregating the information from all students' tournaments, inferences about

the desirability of schools can be constructed.

        David (1988) surveys the rich body of work on multiple comparison modeling, which

mainly focuses on paired comparison models, where each tournament contains only two

players. While no one has previously attempted to rank colleges using comparison models,

there are abundant applications for divining chess ability from tournament data-- see, for

example, Zermelo (1929), Good (1955), Elo (1978) and Glickman (1993, 1999, 2001).4

        We build on the Bradley-Terry (1952) and the Luce (1959) models in which the

distribution of desirability is an extreme value distribution. The assumption of an extreme

value distribution for potentially observed desirability leads to a logit model. The main

alternative to the assumption of an extreme value distribution for potentially observed

desirability is a normal distribution. This leads to a class of models studied by Thurstone

(1927) and Mosteller (1951) in the context of paired comparisons. When analyzing paired

comparison data in practice, it makes almost no difference whether one assumes that the

distribution of potentially observed desirability is extreme value or normal (see Stern, 1992).

Models based on extreme value distributions tend to be more tractable and computationally

efficient, which guides our choice.

        It is worth noting that the extreme-value or normal distribution of potential

desirabilities is a probabilistic assumption about the merit of an individual school, not an


        4
          Statistical comparison models have also been used to study which college characteristics
students like and which student characteristics colleges like. See, for example, M anski and W ise (1983),
Long (2003), Avery and Hoxby (2004).
                                                                                                           13

assumption about the distribution of mean desirabilities across schools. Because college

comparison data can provide strong information about the relative desirabilities of colleges,

any assumptions made about the distribution of mean desirabilities should be weak. Our

modeling approach allows for the possibility, for example, that a small number of schools are

estimated to have mean desirabilities substantially greater than the remaining schools

considered.

C. The Matriculation Model

        Assuming that each college's potentially observed desirability follows an extreme value

distribution with the same scale and shape, the relevant parameter is the location parameter of

the distribution. The latent variable is:

                                = the desirability parameter of college i,

where we index colleges with i=1,2,...,I.

        Students prefer colleges with higher desirability, among those in their choice set.

Suppose that student j is admitted to a set of colleges       consisting of     schools. Let the

indicator variable      tell us which college the student chooses:

(3)


The result of the multi-player competition among the           colleges that admitted student j is

assumed to follow a multinomial distribution:

(4)

where       is the probability that student j chooses to matriculate at college i among his

college choices.5 We assume Luce's choice model, of the form:

(5)




        5
          For expositional convenience, we have reindexed the colleges in student j set   , so that they
can be written 1,..., .
                                                                                                          14

This model can be rewritten as a conditional logit model, sometimes called McFadden's choice

model.

         The   s include all characteristics that do not vary within each college: such

characteristics include average perceptions about the quality of the education and the average

cost of attendance. For some characteristics, we can measure variation across applicants:

tuition, room fees, board fees, grants to the student, the subsidy value of loans to the student,

the subsidy value of the work-study it offers the student, the cost associated with its distance

from the student's home, its being in-state, its being in-region, and its being the alma mater of

one or more of the student's parents. We add these characteristics to the model to gain extra

explanatory power.6

         Let the vector                        be the K characteristics that can vary among

admittees and that are faced by admittee j who is considering whether to matriculate at college

i. Note well that each characteristic is de-meaned so that we obtain the college's desirability at

its average level in the data. It is not possible to separately identify the effect of these average

characteristics from the     for each school. We treat        as a vector of covariates which are

allowed to enter the model linearly. Specifically, the probabilities for the matriculation model

become:

(6)



In fitting the model, not only are the       inferred, but so are the    , which are the effects of the

characteristics on matriculation.

D. Self-Selection and the Application Decision

         We estimate the     from matriculation decisions of admitted applicants. Of course, to be

admitted, one must first apply, so our underlying data for each school is not a random sample

of all students, but rather of all students conditional on their application to that school. This is a



         6
          In practice, the covariates have a trivial effect on the rankings. Estimates of the model without
covariates are available from the authors.
                                                                                                          15

self-selected group, and we expect a group of applicants to find a school more desirable than

an otherwise identical set of non-applicants. Such self-selection does not induce any bias if the

applicant pool for every school is shifted equivalently: that is, if we are estimating a        for every

school based on the applicant pool, but the equivalent parameter for all students (applicants

and non-applicants) is      -     , and the     is the same for all schools, i. Since our ratings are

unique only up to a constant, such a shift would not change the interpretation of our results.

       Self-selection would cause a problem if the applicant pools are induced differently

across schools. This would appear to be a major issue only for “niche schools” that attract

applications from only the most interested students. Any speciality school could fall into this

category, with engineering schools, school with a religious affiliation, or single-sex schools

being the most likely. These schools might attract applicant pools with stronger preferences –

because students who are lukewarm about the speciality don’t bother to apply – and

effectively have a higher       , leading the estimated      to be biased upward.

       The ideal way to handle these selection issues would be to explicitly model the

application decision, but this is not feasible without many further assumptions. With

thousands of schools to choose from, even artificial constraints on the number of applications

leads to a complex combinatorial problem. In this case, the modeler – like the applicants

themselves – is forced to use shortcuts and assumptions. Since these assumptions would

ultimately drive the extent of selection bias, it seems more straightforward to acknowledge this

potential bias and discuss its implications where it is appropriate. Thus, we proceed under the

baseline assumption that the       are identical across schools. In Section V, we discuss the

implications of deviations from this assumption, point out specific schools for which these

deviations may make a difference, and propose a practical method for dealing with them.

       While we do not believe that self-selection is a major issue for the         estimates, it is of

greater concern for inference on the          coefficients For instance, suppose that price sensitivity

is heterogeneous and students who are especially price sensitive seek out colleges that offer

them substantial discounts. We might overestimate the effects of prices because the variation

in the data comes disproportionately from price-sensitive students. For this reason, we will not
                                                                                                       16

give strong interpretations to the coefficients on these characteristics. It is still useful to include

these characteristics in the regression, especially because they may proxy for otherwise

unobservable variables.

E. Model Fitting

        The complexity of our model lends itself naturally to fitting the model in the Bayesian

framework. We fit our model by computing the posterior distribution of model parameters

followed by summarizing important features of the distribution. The posterior distribution of

parameters is proportional to the product of the likelihood function with a prior distribution.

The likelihood can be written as a product of multinomial logit probabilities derived from

equation (6). We assume a locally uniform but proper prior distribution that factors into

independent densities. The prior distribution consists of the following components:




(7)




where      indexes the kth element of the vector delta.

        We summarize estimated college desirability by computing the posterior modes of the

  . These were carried out using a Newton-Raphson algorithm for multinomial logit models,

as implemented in Stata. The posterior modes are presented in Tables 3, 5 and 6. We also fit

the model using Markov chain Monte Carlo(MCMC) simulation from the posterior distribution

to infer more complex quantities of interest. For example, to answer questions like "is there a

meaningful distinction in desirability between the college ranked 15th and the college ranked

20th?" we cannot simply rely on comparing posterior modes. Instead, MCMC produces

simulated values from the posterior distribution of model parameters. Thus, using MCMC

simulation, pairs of values can be generated from the posterior distribution of (        ,    ), and

the probability that     is greater than      can be evaluated by computing the proportion of

pairs in which      is greater than     . An answer like 95 percent or more – analogous to a 95%
                                                                                                     17

significance test – tells us that the colleges are substantially more distinct than an answer like

55 percent.

       The MCMC algorithm proceeds as follows. Initial values of all parameters are set to the

prior mean values (though the initial values can be set arbitrarily). Then values are simulated

from the conditional posterior distributions of each model parameter. This process is repeated

until the distributions of values for individual parameters stabilize. The values simulated

beyond this point can be viewed as coming from the posterior distribution. A recent example

of MCMC methods applied to paired comparison models is Glickman (2001).

       We implemented the MCMC algorithm using the program BUGS (Spiegelhalter et al.,

1996). For each model, a burn-in period of 10,000 iterations was run, and parameter summaries

were based on every 5th iteration of a subsequent 30,000 iterations. Based on trace plots from

our data analyses, 10,000 iterations was sufficient to reach the stationary distribution. Every

5th iteration was sampled to reduce the autocorrelation in successive parameter draws. This

process produced 6000 values per parameter on which to calculate parameter summaries. In

Table 4, which shows pairwise match-ups for each college we rank, we display summaries

based on MCMC draws from the posterior distribution.



                                                IV. Data

       To construct an example of our revealed preference ranking, we use from the College

Admissions Project survey, in which we surveyed high school seniors in the college graduating

class of 2004.7 We designed the survey to gather data on students with very high college

aptitude who are likely to gain admission to the colleges with a national or broad regional

draw that are most appropriate for ranking. While such students are represented in surveys

that attempt to be nationally representative, such as the National Educational Longitudinal

Survey, they are a very small share of the population of American students. As a result, the

number of such students is so small in typical surveys that their behavior cannot be analyzed,



       7
           See Avery and Hoxby [2000] for additional detail.
                                                                                                            18

even if the survey contains a large number of students. By focusing on students with very

strong academic credentials, we end up with a sufficient number of tournaments among

colleges with a national draw to construct a revealed preference ranking among them.

        We reemphasize that we use the College Admissions Project data to construct an

example of a revealed preference ranking. If we had had much greater resources, we would

have surveyed a more fully representative sample of students in the United States. With more

data, our national ranking would be more definitive, and we would be able to rank many more

colleges (most of them in regional or specialized rankings, not the national ranking). At the

end of this section, we describe the cut-offs we used to determine which colleges we could

reasonably rank.

A. Survey Design

        In order to find students who were appropriate candidates for the survey, we worked

with counselors from 510 high schools around the United States. The high schools that were

selected had a record of sending several students to selective colleges each year, and they were

identified using published guides to secondary schools, such as Peterson's and the experience

of admissions experts. Each counselor selected ten students at random from the top of his

senior class as measured by grade point average. Counselors at public schools selected

students at random from the top 10% of the senior class, while counselors at private schools

(which tend to be smaller and have higher mean college aptitude) selected students at random

from the top 20% of the senior class.8 The counselors distributed the surveys to students,

collected the completed surveys, and returned them to us for coding.9 Students were tracked



        8
          The counselors were given detailed instructions for random sampling from the top 20, 30, 40, or
50 students in the senior class depending on the size of the school. For example, a counselor from a
public school with 157 students was asked to select 10 students at random from the top 20 students in the
senior class, with the suggestion that the counselor select students ranked #1, 3, 5, 7, 9, 11, 13, 15, 17, and
19.

        9
         The exception was the parent survey, which parents mailed directly to us in an addressed,
postage-paid envelope so that they would not have to give possibly sensitive financial information to the
high school counselor.
                                                                                                      19

using a randomly assigned number; we never learned the names of the students who

participated.

        Survey participants completed two questionnaires over the course of the academic year.

The first questionnaire was administered in January 2000. It asked for information on the

student's background and college applications; the majority of these questions were taken

directly from the Common Application, which is accepted by many colleges in place of their

proprietary application forms. Each student listed up to ten colleges where he had applied, his

test scores, and race. In addition, each student listed the colleges and graduate schools (if any)

attended by each parent and the colleges (if any) attended by older siblings along with their

expected graduation dates.

        The second questionnaire was administered in May 2000 and asked for information

about the student's admission outcomes, financial aid offers, scholarship offers, and

matriculation decision. Each student listed their financial aid packages with the amounts

offered in three categories: grants, loans, and Work Study. We obtained detailed information

on grants and scholarships. On a third questionnaire distributed to a parent of each survey

participant, we collected information on parents' income range (see Table 1 for the income

categories.)

        We matched the survey to colleges' administrative data on tuition, room and board,

location, and other college characteristics. In all cases, the ultimate source for the

administrative data was the college itself and the data were for the 2000-01 school year, which

corresponds to the survey participants' freshmen year.10

        The College Admissions Project survey produced a response rate of approximately 65%,

including full information for 3,240 students from 396 high schools.11 The final sample contains




        10
             See Avery and Hoxby [2004] for a complete description of administrative data sources.

        11
           The most comm on reasons for failure to return the survey were changes of high school
administration, an illness contracted by the counselor, and other administrative problems that were
unrelated to the college admissions outcomes of students who had been selected to participate.
                                                                                                      20

students from 43 states plus the District of Columbia.12 Although the sample was constructed

to include students from every region of the country, it is intentionally representative of

applicants to highly selective colleges and therefore non-representative of American high

school students as a whole. Regions and states that produce a disproportionate share of the

students who apply to selective colleges are given a weight in the sample that is approximately

proportionate to their weight at very selective colleges, not their weight in the population of

American high school students. Of course, all of the students in the sample have very strong

academic records.

         Because the students are drawn from schools that send several students to selective

colleges each year (though not necessarily to very selective colleges), the students in the sample

are probably slightly better informed than the typical high aptitude applicant. However, in

other work [Avery and Hoxby, 2004], we have found that students who make it into the sample

act very much like one another when they make college decisions, regardless of whether they

come from more or less advantaged backgrounds. This suggests that a revealed preference

ranking based on our sample may reflect slightly more information than one based on the

typical applicant, but the difference in the information embodied in the ranking is probably

small.

B. Sample Statistics

         The summary statistics shown in Tables 1 and 2 demonstrate show the students in the

sample are high achieving. The average (combined verbal and math) SAT score among

participants was 1357, which put the average student in the sample at the 90th percentile of all

SAT takers.13 About 5 percent of the students won a National Merit Scholarship; 20 percent of

them won a portable outside scholarship; and 46 percent of them won a merit-based grant from



         12
         The states missing from the sample are Alaska, Delaware, Iowa, M ississippi, North Dakota,
South Dakota, and W est Virginia.

         13
           W e converted American College Test (ACT) scores to SAT scores using the cross-walk
provided by The College Board. We converted all college admissions scores into national percentile
scores using the national distribution of SAT scores for the freshman class of 2000-01.
                                                                                                     21

at least one college. 45 percent of the students attended private school, and their parents'

income averaged $119,929 in 1999.14 However, 76 percent of the sample had incomes below the

cut-off where a family is considered for aid by selective private colleges, and 59 percent of the

students applied for need-based financial aid.15

                                                Table 1
              Description of the Students in the College Admission Project Data
Variable                                                  Mean      Std. Dev. Minimum Maximum
Male                                                        0.41          0.49        0.00         1.00
White, non-Hispanic                                         0.73          0.44        0.00         1.00
Black, non-Hispanic                                         0.04          0.18        0.00         1.00
Asian                                                       0.16          0.36        0.00         1.00
Hispanic                                                    0.04          0.19        0.00         1.00
Native American                                             0.00          0.03        0.00         1.00
Other race/ethnicity                                        0.04          0.19        0.00         1.00
Parents are married                                         0.83          0.38        0.00         1.00
Sibling(s) enrolled in college                              0.23          0.42        0.00         1.00
Parents' income                                        119,929         65,518        9,186     240,000
Expected family contribution                              27,653       16,524            0     120,000
Applied for financial aid?                                  0.59          0.49        0.00         1.00
National Merit Scholarship winner                           0.05          0.22        0.00         1.00
Student's combined SAT score                               1357           139          780        1600
Student's SAT score, in national percentiles                90.4          12.3        12.0       100.0
Median SAT score at most selective college
to which student was admitted                               86.4          10.4        33.5         98.0
Median SAT score at least selective college
to which student was admitted                               73.8          14.6        14.3         97.0
Student's high school was private                           0.45          0.50        0.00         1.00




        14
            See Avery and Hoxby [2004] for descriptions of how the aid variables were hand checked and
how some parents' income was estimated based on their Expected Family Contribution, a federal
financial aid measure.

        15
          The cut-off was approximately $160,000, but the actual cut-off depends on family
circumstances.
                                                                                                  22

       83 percent of the student's parents were currently married, and 23 percent of the

students had at least one sibling currently enrolled in college. The racial composition of the

survey participants was 73 percent white, 16 percent Asian, 3.5 percent black, and 3.8 percent

Hispanic.

       Looking at Table 2, which shows descriptive statistics on the colleges where the

students applied, were admitted, and matriculated; we can see that the survey participants

applied to a range of colleges that included "safety schools" (the mean college to which a

student applied had a median SAT score 8.5 percentiles below the student's own). However,

the participants also made ambitious applications: 47.5 percent of them applied to at least one

Ivy League college.

                                            Table 2
              Description of the Colleges in the College Admission Project Data
                                                        Colleges at Which Students
                                              Applied          Were Admitted      Matricalated
                                                        Std.              Std.                Std.
Variable                                    Mean        Dev.    Mean      Dev.    Mean        Dev.
Matriculated at this college                  0.28      0.45      0.18     0.39      1.00      0.00
Admitted to this college                      1.00      0.00      0.66     0.47      1.00      0.00
Grants from this college                     2720       5870     1778     4933     4029       7051
Loans from this college                        641      2282      413     1856     1020       2722
Work study amount from this college            172       593      111      483       296         768
Father is an alumnus of this college          0.04      0.20      0.03     0.17      0.07      0.25
Mother is an alumna of this college           0.03      0.17      0.02     0.14      0.04      0.19
Sibling attended or attends this college      0.05      0.21      0.04     0.19      0.08      0.28
College is public                           0.3325    0.4711    0.2631   0.4403   0.2843     0.4512
College's median SAT score, in
percentiles                                80.5947 12.5188 83.8816 12.0390 83.4215 12.5494
In-state tuition                            16435       9594    18181     9199    17432       9513
Out-of-state tuition                        19294       6191    20498     5891    19841       6371
Tuition that applies to this student        17671       8492    19277     7965    18340       8599
College is in-state                         0.3270    0.4691    0.2666   0.4422   0.3368     0.4727
Distance between student's high school
and this college, in miles                     597       809      673      873       576         827
                                                                                                   23

       We can see that the students made logical application decisions. The mean college to

which they applied had a median SAT score at the 83rd percentile; the mean college to which

they were admitted had median SAT score at the 81st percentile. This small difference suggests

that the students aimed a little high in their applications, a procedure that is optimal. 66

percent of the colleges to which students were admitted were private, and their mean tuition

was $17,671. Notice that we show the colleges' in-state tuition, out-of-state tuition, and the

tuition that actually applies to the students in the sample (in-state or out-of-state as

appropriate).

       The final column of Table 2 shows descriptive statistics for the colleges at which the

students matriculated. They are more selective, on average, than the colleges to which the

students were admitted: their median SAT score is at the 83.4th percentile, as opposed to the

81st percentile median SAT score of the colleges to which students were admitted. This makes

sense because it implies that students included "safety schools" in their choice sets, but often

did not matriculate at them. One measure of the unusual college aptitude of the survey

participants is the list of colleges at which the largest numbers of participants enrolled.

Seventeen institutions enrolled at least 50 students from the sample: Harvard, Yale, University

of Pennsylvania, Stanford, Brown, Cornell, University of Virginia, Columbia, University of

California–Berkeley, Northwestern, Princeton, Duke, University of Illinois, New York

University, University of Michigan, Dartmouth, and Georgetown.



                                            V. Results

       We show a college in the national ranking if it was not a military academy and if, in our

sample, it competed in matriculation tournaments in at least six of the nine regions of the U.S.

106 colleges met these criteria. The mean college shown in the national ranking competed in

73 matriculation tournaments, and the median college competed in 57. Admittedly, the six

region cut-off is somewhat arbitrary, but we show regional rankings after showing the national

rankings. The regional rankings pick up extra colleges. Please note that if a small college fails

to appear in the rankings, one should not conclude that its ranking is below 106 or that it does
                                                                                                       24

not have a national draw. For a small college, our sample might fail to pick up enough

applicants to include the college in the national ranking, even if its draw is national in

character.

A. National Ranking

        Table 3 presents the revealed preference ranking of colleges and universities with a

national draw. For each college, we present its mean desirability among students. Keep in

mind that Table 3 shows only an example of our ranking method. With more data, we would

produce a more definitive ranking. The rankings are on an arbitrary numerical scale of value,

Elo points, which are used in chess and other game rankings. The conversion multiplies the              s

by 173 and then adds whatever number gives 2800 points to the highest ranked college.16 The

following table contains rule-of-thumb relationships between point differences and probability

of winning:

                                      400                     .919
                                      300                     .853
                                      200                     .758
                                      100                     .637
                                       50                     .569
                                        0                     .500
                                       -50                    .431
                                      -100                    .363
                                      -200                    .242
                                      -300                    .147
                                      -400                    .081

        Note that Elo point differences tell us only about the college versus its mean competitor.

Put another way, attaching standard errors to the estimates in Table 3 would not be very useful



        16
          W e choose 2800 as the maximum number because this is approximately the rating for the
highest-rated chess player in the world. W e use the Elo scale because of its familiarity. In addition to
serving as the main rating system for chess and many other board games, the Elo scale has also been used
in a wide variety of sports. A partial list includes soccer (www.eloratings.net/), college football
(www.usatoday.com/sports/sagarin/fbt01.htm), cricket (www.ultra-sports.com/Cricket/UC4/
UC4abselo.html), and racquetball (www.eqp.com/pubs/rb/PlayerRankByELO.asp).
                                                                                                  25

because they would not reliably indicate whether any two colleges' rankings were statistically

distinct. This is because the statistical significance of the difference between any two colleges'

ranks depends on the overlap between their two groups of admittees. For this reason, it is best

to use Table 4 for head-to-head comparisons between colleges.

         Table 4 summarizes the results of posterior draws: the Bayesian analogue to a set of

paired significance tests. For instance, in 96 percent of the draws from the posterior

distribution, Harvard's ranking was higher than Yale's, and for 95 percent of the draws

Harvard was higher than Cal Tech. For all other colleges, Harvard's ranking was higher in at

least 99 percent of the draws. Put another way, we are 96 percent confident that Harvard's

ranking is higher than Yale's, 95 percent confident it is higher than Cal Tech, and at least 99

percent confident that it is higher than that of other colleges. For Yale, in turn, we are 88

percent confident that its ranking is higher than Stanford's, 78 percent confident that its

ranking is higher than Cal Tech's, and 91 percent confident that its ranking is higher than

MIT's.

         Table 4 helps us to understand the results for Cal Tech, which are somewhat

problematic. Because students self-select into applying to Cal Tech based on an orientation

toward math and science, Cal Tech's pool of admittees overlaps only slightly with that of most

other institutions, except for MIT, with which Cal Tech has substantial overlap. MIT, on the

other hand, does have substantial overlap with other top schools. Unlike the other institutions

in the top twenty, Cal Tech appears to draw a more focused group of applicants. In Section

III.D, we discussed how such self-selection might bias inference for some speciality schools,

with the possibility of some upward bias in the      estimate.

         All of the top twenty are private institutions and four-fifths are universities (the

exceptions being Amherst, Wellesley, Williams, and Swarthmore). The next twenty institutions
                                                             26

                         Table 3
       A Revealed Preference Ranking of Colleges
rank             College Name                      Elo pts
   1                Harvard                        2800
   2                   Yale                        2738
   3                Stanford                       2694
   4                Cal Tech                       2632
   5                   M IT                        2624
   6                Princeton                      2608
   7                  Brown                        2433
   8                Columbia                       2392
   9                Amherst                        2363
  10               Dartmouth                       2357
  11                W ellesley                     2346
  12                 U Penn                        2325
  13             U Notre Dame                      2279
  14              Swarthmore                       2270
  15                 Cornell                       2236
  16              Georgetown                       2218
  17                   Rice                        2214
  18                W illiams                      2213
  19                  Duke                         2209
  20               U Virginia                      2197
  21              Northwestern                     2136
  22                 Pom ona                       2132
  23                Berkeley                       2115
  24              Georgia Tech                     2115
  25               M iddlebury                     2114
  26                W esleyan                      2111
  27               U Chicago                       2104
  28             Johns Hopkins                     2096
  29                   USC                         2072
  30                 Furman                        2061
  31                   UNC                         2045
  32                 Barnard                       2034
  33                 Oberlin                       2027
  34                Carleton                       2022
  35               Vanderbilt                      2016
  36                  UCLA                         2012
  37                Davidson                       2010
  38                 U Texas                       2008
  39                   NYU                         1992
  40                   Tufts                       1986
  41           W ashington & Lee                   1983
  42               U M ichigan                     1978
  43                  Vassar                       1978
                                                             27

                         Table 3
       A Revealed Preference Ranking of Colleges
rank              College Name                     Elo pts
  44                 Grinnell                      1977
  45                U Illinois                     1974
  46            Carnegie Mellon                    1957
  47               U M aryland                     1956
  48            W illiam & M ary                   1954
  49                Bowdoin                        1953
  50               W ake Forest                    1940
  51               Claremont                       1936
  52               M acalester                     1926
  53                 Colgate                       1925
  54                  Smith                        1921
  55                U M iami                       1914
  56                Haverford                      1910
  57               M t Holyoke                     1909
  58           Connecticut College                 1906
  59                   Bates                       1903
  60                 Kenyon                        1903
  61                  Emory                        1888
  62              W ashington U                    1887
  63               Occidental                      1883
  64               Bryn M awr                      1871
  65                   SM U                        1860
  66                  Lehigh                       1858
  67               Holy Cross                      1839
  68              Reed College                     1837
  69                    RPI                        1835
  70              Florida State                    1834
  71                  Colby                        1820
  72                  UCSB                         1818
  73                   GW U                        1798
  74                Fordham                        1796
  75             Sarah Lawrence                    1788
  76                 Bucknell                      1784
  77               Catholic U                      1784
  78               U Colorado                      1784
  79              U W isconsin                     1780
  80              Arizona State                    1774
  81               W heaton (Il)                   1750
  82              Rose Hulman                      1745
  83                  UCSC                         1736
  84                Boston U                       1736
  85                  UCSD                         1732
  86                  Tulane                       1727
                                                                                                      28

                                                 Table 3
                             A Revealed Preference Ranking of Colleges
        rank                             College Name                                 Elo pts
          87                              U Richmond                                  1714
          88                                  CW RU                                   1704
          89                             Trinity College                              1703
          90                           Colorado College                               1698
          91                                Indiana U                                 1689
          92                                Penn State                                1686
          93                              American U                                  1681
          94                                Hamilton                                  1674
          95                             U W ashington                                1629
          96                               U Rochester                                1619
          97                             Lewis & Clark                                1593
          98                             W heaton (M A)                               1564
          99                                   Clark                                  1551
         100                                Skidmore                                  1548
         101                                  Purdue                                  1525
         102                             Colorado State                               1513
         103                                 Syracuse                                 1506
         104                                  Scripps                                 1479
         105                                 Loyola U                                 1221
               Tuition (In Thousands, In-state or Out-of-state, W hichever Applies)   -6.443
                                                                                      (3.129)
                                     Grants (In Thousands)                            28.156
                                                                                      (2.104)
                                     Loans (In Thousands)                             12.629
                                                                                      (3.018)
                                          W ork-study                                 3.023
                                                                                      (13.091)
                                   Indicator: Is Dad's College                        70.458
                                                                                      (29.450)
                                  Indicator: Is M om's College                        34.432
                                                                                      (24.797)
                                Indicator: Is a Sibling's College                     94.743
                                                                                      (25.290)
                               Indicator: College in Home State                       25.646
                                                                                      (38.033)
                              Indicator: College in Home Region                       15.191
                                                                                      (20.533)
                           Distance from Home (Hundreds of M iles)                    4.276
                                                                                      (2.137)
Notes: Estimates based on equation (6) converted into Elo points (see text). Standard errors are in
parentheses.
                                                                                                                                         29

               Table 4: Share of Draws in W hich College in the Row is Ranked Higher than the College Various Places Below It
                                                                    Num ber of Places Below
College              1     2     3     4     5     6      7     8       9    10    11    12    13    14    15    16    17    18    19    20
Harvard             96   100    95   100   100   100   100    100     100   100   100   100   100   100   100   100   100   100   100   100
Yale                88    78    91    95   100   100   100    100     100   100   100   100   100   100   100   100   100   100   100   100
Stanford            58    62    76   100   100   100   100    100     100   100   100   100   100   100   100   100   100   100   100   100
Cal Tech            51    57    89    94    96    96    96     98      98    99   100   100   100   100   100   100   100   100   100   100
M IT                63    99   100   100   100    99   100    100     100   100   100   100   100   100   100   100   100   100   100   100
Princeton           96    99    99    99    99   100   100    100     100   100   100   100   100   100   100   100   100   100   100   100
Brown               80    87    90    88    97    96    98    100     100   100   100   100   100   100   100   100   100   100   100   100
Columbia            65    66    72    80    85    92    99     99      99    98   100   100   100   100   100   100   100   100   100   100
Amherst             50    59    62    74    85    92    95     97      95    98    97   100    99   100   100    99    98   100   100   100
Dartmouth           60    65    76    86    95    97    98     96      99    98   100   100   100   100   100    99   100   100   100    99
W ellesley          50    64    75    82    85    93    90     92      90    98    98    98    99    97    94    99    99    99    97   100
U Penn              68    81    94    96    97    94    99     98     100    99   100   100   100    98   100   100   100    99   100   100
Notre Dame          65    73    78    89    84    88    85     97      96    98    98    95    91    99    99    99    96   100    99   100
Swarthmore          53    60    78    73    74    68    90     90      91    93    87    80    95    94    95    91    97    98    98    98
Cornell             61    82    75    81    73    97    95     98      97    94    85    99    99    99    94   100    99   100    99   100
Georgetown          77    68    71    62    93    91    95     95      89    78    97    97    98    91    99    99    99    99   100   100
Rice                45    38    31    62    68    64    75     60      49    75    75    76    77    86    87    89    89    92    93    92
W illiams           46    39    67    73    69    79    66     56      78    79    79    80    89    89    90    91    94    93    94    94
Duke                40    81    82    84    89    77    63     91      91    92    86    97    96    97    96    99    99    98    99   100
U Virginia          88    87    90    92    83    70    95     94      96    89    98    98    98    98   100   100    99    99   100   100
Northwestern        62    54    71    49    35    72    72     74      74    88    88    90    90    96    96    93    95    99    98    90
Pom ona             40    58    39    28    55    56    55     64      74    75    78    79    83    84    84    85    89    89    83    88
Berkeley            69    47    33    69    69    72    73     86      88    89    89    95    98    93    95    99    98    90    99    96
Georgia Tech        31    22    45    47    45    59    67     70      71    74    78    78    81    82    85    86    79    84    82    80
M iddlebury         37    67    69    69    72    84    85     88      87    92    92    92    92    96    96    89    96    94    90    97
W esleyan           78    79    80    79    90    90    91     92      95    96    94    95    98    98    92    97    97    93    98    98
UChicago            52    52    63    74    76    79    80     85      86    86    87    93    93    83    92    90    85    95    95    91
Johns Hopkins       49    62    72    74    77    78    83     84      84    85    91    91    81    91    88    83    93    94    89    95
                                                                                                                                        30

                 Table 4: Share of Draws in W hich College in the Row is Ranked Higher than the College Various Places Below It
                                                                      Num ber of Places Below
College                1     2     3     4     5     6      7     8       9    10    11    12   13   14    15     16    17    18   19   20
USC                   62    73    76    79    80    86    89     85      87    94    93    82   94   90    84     96    96    91   96   93
Furman                54    56    59    61    62    61    68     66      68    70    68    67   70   69    70     76    67    78   74   82
UNC                   54    58    61    63    61    70    68     73      75    69    71    71   71   76    82     70    84    79   88   72
Barnard               54    58    59    56    66    64    68     70      65    66    68    68   71   78    66     81    75    84   70   84
Oberlin               54    54    51    64    59    62    66     63      61    63    65    66   74   62    77     72    81    68   82   65
Carleton              49    47    58    55    57    60    59     55      58    62    60    68   55   72    66     75    64    77   59   65
Vanderbilt            47    61    57    61    64    60    59     61      63    65    74    60   79   70    82     65    81    64   68   81
UCLA                  64    61    65    68    62    62    64     66      70    77    63    81   74   85    68     85    67    70   83   87
Davidson              46    45    49    50    44    48    53     49      58    46    64    57   66   57    69     50    56    67   74   60
U Texas               50    55    55    49    53    58    55     65      51    70    63    74   61   75    55     61    74    79   65   66
NYU                   56    56    48    54    58    56    68     50      73    65    77    61   79   56    62     76    82    66   69   66
Tufts                 51    42    48    54    49    61    44     68      60    71    58    73   50   57    71     78    62    63   61   83
W ash & Lee           44    47    52    48    56    45    62     56      64    55    67    48   54   65    71     60    58    57   75   80
U M ichigan           54    59    58    70    52    74    66     79      62    79    58    63   77   83    68     70    67    87   96   98
Vassar                56    51    62    47    68    61    71     58      73    51    58    71   78   63    64     62    82    89   90   79
Grinnell              44    53    42    59    53    61    53     64      46    53    62    69   57   55    55     72    77    76   68   68
U Illinois            64    45    70    61    74    58    75     51      59    74    80    64   65   62    85     94    96    81   76   70
Carnegie Mell         34    57    50    61    51    65    40     49      64    71    55    53   52   75    85     85    71    69   63   76
U M aryland           72    64    75    61    76    55    62     74      80    65    67    64   85   93    95     82    78    72   86   79
W illiam M ary        44    53    46    58    33    43    56     64      49    46    45    69   76   76    64     63    57    69   63   72
Bowdoin               59    51    62    41    49    62    68     54      52    51    73    80   80   69    68     62    74    68   76   79
W ake Forest          44    55    29    40    54    62    46     42      42    67    74    74   62   62    55     68    62    71   75   84
Claremont             59    43    49    58    64    52    51     50      68    72    71    63   64   59    68     63    71    74   80   74
M acalester           28    37    50    57    43    38    38     61      67    65    56    58   51   61    56     67    68    78   69   77
Colgate               58    71    77    62    63    61    82     89      90    78    75    69   83   76    82     87    93    89   95   96
Smith                 62    69    55    54    52    73    78     77      68    69    62    73   68   75    78     85    80    85   88   60
U M iami              58    44    40    40    61    67    65     57      59    52    62    57   66   68    78     69    76    81   49   63
Haverford             37    32    32    53    57    56    49     52      45    54    49    59   61   71    62     69    72    42   56   66
                                                                                                                                       31

                Table 4: Share of Draws in W hich College in the Row is Ranked Higher than the College Various Places Below It
                                                                     Num ber of Places Below
College               1     2     3     4     5     6      7     8       9    10    11    12   13   14    15     16    17    18   19   20
M t Holyoke          48    47    67    72    70    62    64     57      67    62    70    72   80   74    80     83    55    67   77   68
Connecticut C.       48    72    80    79    68    66    60     73      67    74    80    86   81   87    90     58    71    85   71   83
Bates                72    79    79    68    66    61    72     67      74    78    86    80   86   88    58     70    83    71   82   90
Kenyon               53    51    44    48    42    49    46     56      56    68    58    64   70   39    53     64    56    61   73   76
Emory                46    40    45    38    46    41    55     54      68    56    65    72   34   50    62     55    61    76   76   62
W ash. U             43    47    41    49    44    57    59     73      59    70    77    36   53   67    57     65    81    80   65   75
Occidental           53    46    55    50    61    62    73     64      72    76    42    57   69   60    67     79    80    68   76   81
Bryn M awr           44    52    48    56    57    66    58     63      67    41    53    63   57   60    70     72    62    70   71   78
SM U                 58    54    63    63    72    64    70     74      47    60    69    62   67   76    78     69    76    78   85   88
Lehigh               46    57    58    68    58    65    71     38      53    65    57    62   75   77    64     73    77    87   90   89
Holy Cross           60    60    70    62    67    72    42     56      67    59    65    76   77   66    74     77    85    89   88   87
Reed College         49    58    49    54    59    33    46     54      51    51    61    66   55   64    64     71    77    77   77   78
RPI                  62    50    57    63    32    47    57     52      54    68    71    58   69   71    81     87    85    83   85   85
Florida State        38    43    49    24    37    45    43     41      53    60    47    59   58   67    74     74    74    76   75   68
Colby                57    64    31    47    57    51    54     68      71    57    68    70   81   87    86     84    86    86   79   88
UCSB                 59    25    42    52    48    47    63     68      53    65    68    81   88   85    83     85    85    77   88   82
GW U                 22    37    44    43    41    56    62     48      61    60    73    81   80   77    80     80    70    82   75   76
Fordham              63    73    64    72    81    82    71     78      82    89    92    91   90   91    91     87    93    90   89   89
Sarah Lawr.          59    53    56    66    70    60    68     69      76    81    81    81   82   81    76     83    79    79   80   91
Bucknell             47    46    60    65    51    63    63     74      80    80    78    81   81   73    82     76    78    78   92   94
Catholic U           51    60    64    54    63    62    67     73      74    73    74    73   69   75    70     72    73    84   87   78
U Colorado           64    69    54    66    68    80    86     84      83    84    84    77   86   81    81     81    94    97   87   57
U W isconsin         58    44    57    54    67    75    75     73      76    76    67    79   70   72    72     90    93    80   48   82
Arizona St           39    51    45    53    63    63    64     65      64    57    66    58   61   63    80     85    71    43   74   83
W heaton (IL)        60    59    67    73    74    73    75     74      69    76    69    72   73   86    89     79    53    82   88   87
Rose Hulman          46    52    59    60    61    62    61     56      62    55    58    60   75   79    68     42    72    78   77   48
UCSC                 61    71    69    70    71    71    63     73      65    67    69    87   91   77    45     80    89    86   53   94
Boston U             64    63    63    66    65    56    68     55      61    62    85    91   73   40    77     87    84    45   95   81
                                                                                                                                        32

                 Table 4: Share of Draws in W hich College in the Row is Ranked Higher than the College Various Places Below It
                                                                      Num ber of Places Below
College                1     2     3     4     5     6      7     8       9    10    11    12   13   14    15     16    17    18   19   20
Ucsd                  51    53    55    53    46    55    43     49      52    77    83    65   34   69    79     78    37    89   74   89
Tulane                52    53    52    45    54    42    48     52      73    80    63    33   68   77    76     37    87    73   87   61
U Richmond            50    49    44    51    41    46    49     68      74    59    33    65   73   73    36     82    69    83   60
CW RU                 47    43    50    39    45    49    68     75      60    32    65    74   72   35    84     70    85    59
Trinity Coll          44    52    40    46    51    72    78     62      33    66    76    74   36   85    71     86    61
Colorado Coll         58    48    53    56    75    80    67     37      69    78    77    41   86   74    87     64
Indiana U             38    45    48    71    77    60    32     66      75    74    34    85   70   86    60
Penn State            56    59    81    87    69    37    73     83      81    42    92    77   91   66
American U            54    75    80    65    34    69    78     76      39    88    74    87   63
Hamilton              69    75    61    33    65    73    72     36      82    69    84    60
U W ashington         57    44    21    51    57    59    21     70      55    74    47
U Rochester           38    17    46    51    52    17    64     50      70    43
Lewis&Clark           26    55    61    61    28    72    59     75      51
W heaton (M a)        77    82    82    56    87    79    88     72
Clark                 55    56    25    64    53    68    47
Skidmore              52    18    62    49    67    43
Purdue                19    60    48    64    41
Colorado St           88    78    90    69
Syracuse              39    58    35
Scripps               66    44
Loyola U              31
                                                                                                         33

are, however, a mix of public and private, small and large, colleges and universities. They are

also more geographically diverse. They include private schools from middle and southern

states: University of Chicago, Furman, Carleton, Davidson, Northwestern, Oberlin, Vanderbilt.

There are also several public universities: UC - Berkeley, UCLA, Georgia Tech, U Texas, North

Carolina.

        The colleges ranked from 41 to 106 include a good number of states' "flagship"

universities, numerous liberal arts colleges, several private universities, and a few more

institutes of technology.17 As a rule, the lower one goes in the revealed preference ranking, the

less distinct is a college's desirability from that of its immediate neighbors in the ranking.

Among the top ten colleges, we generally enjoy confidence of about 75 percent that a college is

ranked higher than the college listed one below it. To achieve the same level of confidence for

colleges ranked eleven to twenty, we need to compare a college with one that is about four

places below it. To achieve 75 percent confidence with the colleges ranked twenty to 30, we

need to compare a college with one that is about six places below it. In short, our confidence

about the exact rank order falls with colleges' measured desirability. There are two reasons

why our confidence falls. First, there may be less consensus among students about colleges'

desirability as we move from the best known colleges to those with less wide reputations.

Second, owing to the nature of our sample, our data are thickest for the most selective colleges.

We did a simple test to determine whether data thickness was primarily responsible for the fall

off in confidence: we randomly selected only 20 observations per college. With these data, we

found that about two-thirds of the drop-off in confidence disappeared. That is, if our data

were equally representative for all colleges, our confidence about the exact rank order would

probably fall only about one third as fast as it does.




        17
            The students in our sam ple who had a Florida resident as a parent were the first cohort to
receive Florida A-Plus Scholarships, which allowed them to attend public universities in Florida for free.
The initiation of the scholarships generated considerable excitement and may have raised the ranking of
public universities in Florida, such as Florida State, among students in our sample.
                                                                                               34

B. Comparing Measures of Revealed Preference

       For the colleges that are in the top twenty based on revealed preference, Table 5 shows

what their rankings would be if they were based on, respectively, the admissions and

matriculation rates. We use crude admissions and matriculation rates from the College

Board's Standard Research Complication, the same data as form the "Common Data Set"

published on colleges' websites and used by college guides like U.S. News.

                                          Table 5
                A Comparison of the Revealed Preference Ranking of Colleges
            and Rankings Based on the Crude Admissions and Matriculation Rates
                                            National Rank Based On:
                         Revealed Preference (based on Admissions Rate Matriculation Rate
                           Matriculation Tournaments)
Harvard                                              1                 4              139
Yale                                                 2                12              309
Stanford                                             3                 7              297
Cal Tech                                             4                 9              854
MIT                                                  5                13              422
Princeton                                            6                 5              266
Brown                                                7                14              561
Columbia                                             8                 6              438
Amherst                                              9                19              916
Dartmouth                                           10                20              647
Wellesley                                           11                23              492
U Penn                                              12               104              794
U Notre Dame                                        13                58              459
Swarthmore                                          14                28             1016
Cornell                                             15                45              649
Georgetown                                          16                22              703
Rice                                                17                25              996
Williams                                            18                29              797
Duke                                                19                32              859
U Virginia                                          20                76              630
Notes: Left-hand column shows rank based on Table 3. The admissions and matriculation
rates are based on the Common Data Set, used by most college guidebooks.

       Looking at Table 5, we observe that most of the top twenty colleges based on revealed

preference are not in the top twenty based on the admissions and matriculation rates. Indeed,
                                                                                                 35

the admissions rate puts 10 of them outside the top twenty and the matriculation rate puts all

of them outside the top 100. Clearly, there are many colleges with low admissions rates or high

matriculation rates that are not perceived to be highly desirable. Apart from convenience, we

are unable to frame an argument for why the crude rates have any advantage over the

procedures for revealing preference that we outline in this paper.

C. Regional Rankings

       Table 6 shows the rankings we obtain if we estimate the matriculation model separately

for students from each of the nine census divisions of the U.S. The nine divisions are:

Division 1: Connecticut, Massachusetts, Maine, New Hampshire, Rhode Island, Vermont;

Division 2: New Jersey, New York, Pennsylvania;

Division 3: Illinois, Indiana, Michigan, Ohio, Wisconsin;

Division 4: Kansas, Minnesota, Missouri, Nebraska;

Division 5: D.C., Florida, Georgia, Maryland, North Carolina, South Carolina, Virginia;

Division 6: Alabama, Kentucky, Tennessee;

Division 7: Arkansas, Louisiana, Oklahoma, Texas;

Division 8: Arizona, Colorado, Idaho, Montana, New Mexico, Nevada, Utah, Wyoming;

Division 9: California, Hawaii, Oregon, Washington.

       We make no great claims for these regional rankings because the sample for each region

is small. Rather, we show Table 6 so that the reader can see how the regional rankings

combine to form a truly national ranking at the top. Because the regional samples are small,

some schools do not get ranked in some regions, and thus we have left spaces where Elo points

suggest that a school ranked in other regions is missing. For instance, in division 6 (Alabama,

Tennessee, Kentucky), neither Cal Tech nor Stanford is ranked. Because the regional samples

are small, we merely group schools outside of the top 30 (see note below the table).

       Looking at Table 6, the most noteworthy thing is the great consistency of the ranking of

the top ten institutions. Each region reproduces the national ranking, with a couple of

exceptions. In region 7 and 9, Stanford is ranked above MIT, whereas MIT is usually ranked

higher. Also, Amherst and Dartmouth often trade places in the rankings. Among the
                                                                                                                                                  36

                                           Table 6: An Example of Regional Preference Rankings of Colleges
                                                              Ranking among Students From:
   Region 1:       Region 2:       Region 3:        Region 4:       Region 5:       Region 6:      Region 7:        Region 8:         Region 9:
   CT, MA, ME,     NJ, NY, PA      IL, IN, MI, OH, KS, MN, MO,      DC, FL, GA,     AL, KY, TN     AR, LA, OK, TX   AZ, CO, ID, MT,   CA, HI, OR,
   NH, RI, VT                      WI               NE              MD, NC, SC, VA                                  NM, NV, UT, WY    WA
 1 Harvard         Harvard         Harvard          Harvard         Harvard         Harvard        Harvard          Harvard           Harvard
 2 Cal Tech        Cal Tech        Cal Tech         Cal Tech        Cal Tech                       Cal Tech         Cal Tech          Cal Tech
 3 Yale            Yale            Yale             Yale            Yale            Yale           Yale             Yale              Yale
 4 MIT             MIT             MIT              MIT             MIT             MIT            Stanford         Stanford          Stanford
 5 Stanford        Princeton       Stanford         Princeton       Stanford                       MIT              Princeton         MIT
 6 Princeton       Stanford        Princeton        Stanford        Princeton       Princeton      Princeton        Brigham Young     Princeton
 7 Brown           Brown           Brown            Brown           Brown           Brown          Brown            Brown             Brown
 8 Columbia        Columbia        Columbia         Amherst         Columbia        Columbia       Columbia         Columbia          Columbia
 9 Dartmouth       Dartmouth       Amherst          Dartmouth       Dartmouth       Dartmouth      Dartmouth        Dartmouth         Dartmouth
10 Amherst         Amherst         Dartmouth        Notre Dame      Amherst         Wellesley      Amherst          U Penn            Amherst
11 Wellesley       Wellesley       Wellesley        U Penn          Notre Dame      U Penn         Wellesley        Amherst           U Penn
12 Notre Dame      Notre Dame      U Penn           Swarthmore      Wellesley       Amherst        U Penn           Notre Dame        Wellesley
13 U Penn          U Penn          Notre Dame       Williams        U Penn          Duke           Notre Dame       Williams          Notre Dame
14 Swarthmore      Cooper Union    Swarthmore       Cornell         Swarthmore      Swarthmore     Cornell          Swarthmore        Cornell
15 Rice            Swarthmore      Cornell          Duke            Cornell         Cornell        Rice             Cornell           Swarthmore
16 Cornell         Cornell         Duke             Georgetown      Duke            Georgia Tech Duke               Duke              Georgetown
17 Georgetown      Georgetown      Rice             U Virginia      Georgetown      Williams       Williams         Rice              Duke
18 Duke            Rice            Williams         Rice            Rice            Georgetown     Georgetown       U Virginia        Rice
19 Williams        Duke            Georgetown       Wesleyan        Williams        Rice           U Virginia       Georgetown        Cooper Union
20 U Virginia      Williams        U Virginia       USC             Harvey Mudd U Virginia         Wesleyan         Wesleyan          Williams
21 Wesleyan        U Virginia      Wesleyan         Northwestern    U Virginia      Wesleyan       Northwestern     Pomona            U Virginia
22 Harvey Mudd     Harvey Mudd     Harvey Mudd U Chicago            Wesleyan        Claremont      Berkeley         Middlebury        Harvey Mudd
23 Northwestern    Wesleyan        Northwestern     Pomona          Northwestern    Northwestern Georgia Tech       Berkeley          Wesleyan
24 Pomona          Northwestern    Pomona           Georgia Tech    Pomona          Fordham        USC              Northwestern      Pomona
25 U Chicago       Pomona          Middlebury       Johns Hopkins Georgia Tech      Berkeley       U Chicago        USC               Berkeley
26 Middlebury      U Chicago       Johns Hopkins U Texas            Berkeley        USC            Johns Hopkins    U Chicago         Northwestern
27 Johns Hopkins   Middlebury      Berkeley         UNC             Middlebury      Pomona         Pomona           Georgia Tech      Johns Hopkins
28 USC             Berkeley        USC              Vanderbilt      U Chicago       U Chicago      Middlebury       UNC               USC
29 Berkeley        Johns Hopkins   U Chicago        Carleton        Johns Hopkins UNC              U Texas          Johns Hopkins     U Chicago
30 Georgia Tech    Georgia Tech    U Texas          Oberlin         USC             Vanderbilt     UNC              Oberlin           Middlebury
                                                                                                                                                         37

Notes for Table 6
Next 30 colleges, for each region:
Region 1 (CT, MA, ME, NH, RI, VT): UNC, Oberlin, Vanderbilt, U Florida, Barnard, Carleton, Furman, George Mason, Davidson, U Michigan, UCLA, NYU,
Tufts, Claremont Mckenna, U Illinois, Vassar, Washington and Lee, Grinnell, Pitzer, Carnegie Mellon, U Maryland, Wake Forest, Kenyon, Bowdoin, William and
Mary, Colgate, SMU, Macalester, U Miami.
Region 2 (NJ, NY,PA): USC, U Texas, UNC, Carleton, Barnard, Vanderbilt, Oberlin, Davidson, Washington and Lee, UCLA, NYU, Tufts, U Michigan, U Florida,
Furman, Vassar, Grinnell, U Illinois, St. John's, Bowdoin, U Maryland, Kenyon, William and Mary, Carnegie Mellon, Wake Forest, Claremont Mckenna, Smith,
Colgate, Pitzer, Macalester.
Region 3 (IL, IN, MI, OH, WI): UNC, Claremont Mckenna, Fordham, Carleton, USC, Vanderbilt, Oberlin, Davidson, Barnard, UCLA, U Illinois, SMU,
Washington and Lee, Bradley, U Florida, U Michigan, Tufts, Vassar, NYU, Grinnell, U Missouri, Wake Forest, Bowdoin, Carnegie Mellon, Illinois Wesleyan, U
Oregon, Haverford, Macalester, Smith, William and Mary.
Region 4 (KS, MN, MO, NE): Washington and Lee, Vassar, Davidson, Tufts, Furman, Bowdoin, Colgate, Grinnell, U Michigan, New York, Rhodes, U Illinois,
SMU, Haverford, Macalester, Kenyon, Wake Forest, U Missouri, Connecticut College, U Maryland, Carnegie Mellon, Bradley, Sarah Lawrence, Lehigh,
Washington U., Bates, Bucknell, College of William and Mary, U Miami, Colby.
Region 5 (DC, FL, GA, MD, NC, SC, VA): UNC, U Texas, U Florida, Fordham, Barnard, Vanderbilt, Carleton, UCLA, Davidson, Oberlin, U Michigan, Tufts,
Vassar, U Maryland, Furman, U Illinois, Washington and Lee, NYU, Grinnell, U. of the South, Bowdoin, Kenyon, Carnegie Mellon, William and Mary, Wake
Forest, Macalester, Smith, U Miami, Colgate, Haverford.
Region 6 (AL, KY, TN): Furman, Johns Hopkins, Middlebury, UCLA, U Texas, Barnard, Davidson, U the South, Wake Forest, SMU, Carleton, Oberlin, U
Michigan, U Illinois, Texas A&M, NYU, Rhodes, Vassar, Occidental, Smith, Clemson, Kenyon, Carnegie Mellon, Bowdoin, William and Mary, Bates, U Miami,
Washington and Lee, Washington U., Haverford.
Region 7 (AR, LA, OK, TX): Furman, Oberlin, Carleton, UCLA, Rhodes, Vanderbilt, Barnard, Davidson, Fordham, U Michigan, Washington and Lee, Tufts, NYU,
Wake Forest, U Illinois, Bowdoin, Vassar, Carnegie Mellon, Colgate, Smith, U Maryland, SMU, Macalester, Haverford, Washington U., Connecticut College,
Emory, Mount Holyoke, Bucknell, Bryn Mawr.
Region 8 (AZ, CO, ID, MT, NM, NV, UT, WY): Barnard, Claremont Mckenna, Carleton, Vanderbilt, UCLA, NYU, Wake Forest, Tufts, Macalester, Washington
and Lee, U Michigan, Bowdoin, U Oregon, Vassar, Colgate, U Miami, Mount Holyoke, Carnegie Mellon, Grinnell, Haverford, William and Mary, Emory, U
Missouri, Whitman, U Colorado, Washington U., Santa Clara, U. Arizona, UCSB, Occidental.
Region 9 (CA, HI, OR, WA): U Texas, SMU, UNC, UCLA, Carleton, Barnard, Oberlin, Davidson, Vanderbilt, NYU, Washington and Lee, Tufts, U Illinois, U
Michigan, U Oregon, Pitzer, Vassar, Bowdoin, Carnegie Mellon, Grinnell, Smith, Wake Forest, Macalester, Fordham, St. John's, Claremont Mckenna, William and
Mary, Haverford, Emory, Whitman.
                                                                                                      38

institutions ranked 11 to 30, there is considerable consistency overall, and nearly all of the

changes in rank order appear to be noise, probably due to the small regional samples. The

overall impression is one of consistency: the national ranking is truly national, at least at the

top.

        Regionalism is more evident in the colleges ranked 31 to 60, which are shown in the

notes below Table 6. While much of the variation in the ranking is noise at this point, owing to

the small regional samples, it is notable that Southern colleges do better in the South (U. of the

South, Clemson, and Rhodes are the most obvious), Midwestern colleges do better in the

Midwest (Bradley is the most obvious), and Western colleges do better in the West (Whitman,

Santa Clara, Occidental, and Pitzer are the most obvious). In addition, flagship state

universities are likely to show up in their region, even if not in distant regions (U Oregon, U

Colorado, and U Arizona are the most obvious). However, for the colleges ranked 31 to 60, the

overwhelming impression is that the regional rankings are not very regional. The regional

favorites never represent more than ten percent of the 30, and most of the colleges that appear

show up in every region.

        Perhaps the single most interesting college in Table 6 is Brigham Young, which appears

in the top 10, between Princeton and Brown, in region 8 (which contains Utah). We have

checked and determined that, if we were to compute a Utah-specific ranking, Brigham Young

would rank even higher. The dramatic appearance of Brigham Young in the top 10 almost

certainly occurs because the college is particularly desirable in the eyes of Mormon students.18

We cannot verify this conjecture because we did not ask students about their religion, but this

leads us back to our general point about latent desirability and self-selection into applicant

pools. The reason that Brigham Young wins so many tournaments with Utah students is that it

is truly more desirable to them. Similarly, the reason that a bit of regionalism appears is that

University of the South, say, is truly more desirable to Southerners. This is not a problem we




        18
          The reason that Brigham Young does not appear in the national ranking is that, in our sample,
it competes in fewer than six regions.
                                                                                                    39

need to "fix" in the national ranking. It is simply an indicator that, with sufficient data, it

would be reasonable to compute sub-rankings for identifiable groups of students with well-

defined tastes. We know now that these rankings will tend to join up at the top. A benefit of

computing sub-rankings is that some colleges' performance in the national rankings depends

on the fact that they are especially popular with a well-defined set of students who self-select

into applying (think of Cal Tech). Self-selection does not appear to be an important concern

with our national ranking, except perhaps for the engineering schools. However, we speculate

that it would be appropriate to construct sub-rankings once we got much outside of this group.



                                          VI. Conclusions

       In this paper, we show how students' college choice behavior can be used to generate

revealed preference rankings of American colleges and universities. Using a data set on the

college application and matriculation choices of highly meritorious American students, we

construct examples of a national revealed preference ranking and regional revealed preference

rankings. Our procedure generates a revealed preference ranking which would be very

difficult for a college to manipulate with strategic admissions behavior.

       Given the strong demand for measures of revealed preference among parents and

students, it is clear that colleges will be forced to provide some such information and college

guides like U.S. News will be forced to give substantial weight to such information. In the

absence of a revealed preference ranking method such as ours, colleges and college guides use

two flawed, manipulable proxies: the crude admissions rate and crude matriculation rate.

These proxies are not only misleading; they induce colleges to engage in distorted conduct that

decreases the colleges' real selectivity while increasing the colleges' apparent desirability, as

measured by the proxies. So long as colleges are judged based on the crude admissions and

matriculation rates, it is unlikely that all colleges will eliminate strategic admissions or roll back

early decision programs, which are key means for manipulating the proxies. Many college

administrators correctly perceive that they are in a bad equilibrium. Yet, so long as colleges'

find it advantageous to use early decision and other costly admissions strategies, the bad
                                                                                              40

equilibrium is likely to persist.

       Gathering our data was a moderately costly undertaking for researchers, but the cost

would be a trivial share of the revenues associated with college guides. Moreover, at least

some of the data are already compiled by organizations like The College Board and the ACT, so

that gathering a highly representative sample should be very feasible. If a revealed preference

ranking constructed using our procedure were used in place of manipulable indicators like the

crude admissions rate and crude matriculation rate, much of the pressure on colleges to

manipulate admissions would be relieved. In addition, students and parents would be

informed by significantly more accurate measures of revealed preference. We close by

reminding readers that measures of revealed preference are just that: measures of desirability

based on students and families making college choices. They do not necessarily correspond to

educational quality.
                                                                                                41

                                             References

Avery, Christopher, Andrew Fairbanks, and Richard Zeckhauser. The Early Admissions Game:

       Joining the Elite. Cambridge, MA: Harvard University Press, 2003.

Avery, Christopher, and Caroline M. Hoxby. The College Admissions Project: Counselor Report.

       Cambridge, MA: The College Admissions Project, 2000.

Avery, Christopher, and Caroline M. Hoxby. "Do and Should Financial Aid Packages Affect

       Students' College Choices?" in Caroline M. Hoxby, ed. College Choice: The Economics of

       Where to Go, When to Go, and How to Pay for It. Chicago: University of Chicago Press,

       2004.

David, Herbert. The Method of Paired Comparisons. Oxford: Oxford University Press, 1988.

Ehrenberg, Ronald G., and James W. Monks. "The Impact of US News and World Report

       College Rankings on Admissions Outcomes and Pricing Decisions at Selective Private

       Institutions." National Bureau of Economic Research Working Paper Number 7227,

       1999.

Elo, Arpad E. The Rating of Chessplayers, Past and Present. London: Batsford, 1978.

Glickman, Mark E. "Paired Comparison Models with Time Varying Parameters," Doctoral

       thesis, Harvard University Dept of Statistics, 1993.

Glickman, Mark E. "Parameter Estimation in Large Dynamic Paired Comparison Experiments."

       Applied Statistics, 48 (1999), pp. 377-394.

Glickman, Mark E. "Dynamic Paired Comparison Models with Stochastic Variances," Journal of

       Applied Statistics, 28 (2001), pp. 673-689.

Good, Irving J. "On the Marking of Chess Players," Mathematical Gazette, 39 (1955), pp. 292-296.

Long, Bridget T. "Does the Format of a Financial Aid Program Matter? The Effect of State

       In-Kind Tuition Subsidies," National Bureau of Economic Research Working Paper

       Number 9720, 2003.

Luce , R. Duncan. Individual Choice Behavior. Wiley: New York, 1959.

Thurstone, L.L. "A Law of Comparative Judgment," Psychological Review, 34 (1927), pp. 273-286.
                                                                                             42

Manski, Charles F., and David A. Wise. College Choice in America. Cambridge: Harvard

       University Press, 1983.

Mosteller, Frederick. "Remarks on the Method of Paired Comparisons. I. The Least Squares

       Solution Assuming Equal Standard Deviations and Equal Correlations," Psychometrika,

       16 (1951), pp. 3-9.

Spence, Michael. "Education as a Signal," Chapter 2 in Market Signaling. Cambridge: Harvard

       University Press, 1974.

Spiegelhalter, DJ, A. Thomas, N.G. Best, and W.R. Gilks WR. BUGS: Bayesian Inference Using

       Gibbs Sampling, version 0.6, 1996.

Stern, Hal. "Are All Linear Paired Comparison Models Empirically Equivalent?" Mathematical

       Social Sciences, 23 (1992), pp. 103-117.

Toor, Rachel. "Pushy Parents and Other Tales of the Admissions Game," Chronicle of Higher

       Education, October 6 2000, p. B18.

Wall Street Journal. "Glass Floor: How Colleges Reject the Top Applicants and Boost Their

       Status," Wall Street Journal, May 29, 2001.

Zermelo, Ernst. "Die Berechnung der Turnier-Ergebnisse als ein Maximumproblem der

       Wahrscheinlichkeitsrechnung," Math. Zeit., 29 (1929), pp. 436-460.
