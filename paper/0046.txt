                  NBER WORNG PAPER SERIES




                 ThE SINGULAR VALUE ANALYSIS
                    IN MATRIX COMRJTATION



                      Richard Becker*
                      Neil I<.aden*
                      Virginia KLema*


                  Working Paper No. 6




COMPUFER RESEARCH (INTER FOR ECONOMICS AND MANAGEMENT SCIENCE
          National Beau of Economic Research, Inc.
                    575 Tethnolo, Square
                Cambridge, Massachusetts 02139


                          July l97L


              Pre]±ninary: not for quotation

NBER working papers are distr.thuted informally and in ]±ited
numbers for coimnts only. They should not be quoted without
written permission.
This report has not undergone the review accorded official NBER
publications; in particular, it has not yet been submitted for
approval by the Board of Directors.

NBER Coirputer Research Center. Research supported in part by
 National Science Foundation Grent GJ_1l5LX3 to the National
 Bureau of Economic Research, Inc.
                                 Abstract


This paper discusses the robusthess and the conutational stability of the
singular value decxmposition algorithm used at the NBER Caruter Research
Cneter. The effect of perturtaticris on input data is explored. Suggestions
are made for using the algorithm to get information about the rank of a
real square or rectangular matrix. The algorithm can also be used to
compute the best approximate solution of linear systerr of equations in the
least squares sense, to solve linear systens of equations with equality
constraints, and to determine dependencies or near dependencies anong the
rows or coLzrns of a matrix.
    A copy of the subroutine that is used and sai examples on which it has
been tested axe included in the appendixes.
                           Contents

The Singular Value Analysis in Matrix Computation .           1

References                                                   15




                          Appendixes

A. Listing of the Fortran IV Program M]IJFIT                 Al
B. TROLL Imp1enntation of MINFIT and Associated Output       Bi
C. Selected Matrices, Computed Solutions, and Illustrative
    Thcamples                                                Cl
The singular value decomposition of a matrix is one of the nost elegant algorithms
in nunerical algebra for exposing quantitative inforntion about the structure of
a system of linear equations. It can be used to get information about the rank of
a square or rectangular matrix, to compute the best approxiiite solution of a
linear system of equations in the least squares sense, to solve systems of linear
equations    with equality constraints, and   to   determine dependencies or near-
dependencies anng the rows or coliiris of a matrix. Occasionally the singular
value     decomposition is used in the iterations of linear systems that tend toward
the    solution of nonlinear systems of equations. The condition ranther of a matrix
with respect to the solution of a linear system of equations is a by-product of
the singular value decomposition as is the production of the pseudo-inverse and
the solution of homogeneous systems of equations.
         The condition nither of a matrix with respect to the solution of a linear
system of equations shows how well the vector x is defined by the transformation
Axb. The condition nunber K(A) of the nonsingular matrix A is the ratio
where         and c11 are, respectively, the maxiunun and    minimum singular values

of A   (i.e., the non-negative square roots of the eigenvalues of ATA where AT denotes

the transpose of A). For example, if K(A)1O6, a perturbation of 2_20 in the ele-

irents   of A can change the computed solution x by a factor of 2—20 •l06 , that     is

to   say, even the leading digit may be changed. For a more rigorously detailed
explanation, see [9J.

Nunera1s in square brackets refer to entries in the Pference section, p. 15.
                                            —2—



       In the discussion that follows, we seek to corrpute directly the best

approximate     solution to     the possibly over-determined or under-determined

system   of equations
                                          Ax    b.
The singular       value   deconosition is used to obtain this solution.

Frequently a user, or a problem originator, poses a                problem from   which
he wants to obtain a solution vector x in the sense                of least squares

from   the   system   of   equations

                                         ATAxATb.

Possibly     he thinks the    information he needs cones from the       solution

                                        x= (ATA) IATb.


Classically,       (1) if the   data matrix A and the vector b are exact          (that

is   to say, there is no uncertainty in the data A and b), (2) if the

precision     of   the arithjitic of the iradhine is such that ATA can be ford

and stored     exactly, and (3) if ATA is of full rank, the soli.rtion x           could

be   obtained from (ATA)IATb. However, given             that   these three   conditions

are   seldom attainable in      practice, the solution should not be conuted
in this way because of the extra precision that is required.                  Further!rcre,

unless   there is a priori exact information known about the rank of A, the
solution x cannot be obtained from the pseudo-inverse of A with any nre
                                     —3—


authenticity than fran (ATA)I. That is to say the rank should be detenrilned

during the course of computing the singular value decomposition. Reliable

inforniation   about rank   deficiency cannot be obtained from triangular

factorization.

      Sylvester wrote an article on the singular value decanposition of real
mm matrices in 1889 [10]. Eckert and             Young   extended the %.ork to general
matrices in 1936 [1]. The definitive paper on calculating the singular
value decomposition was written by Golub and Kahan [2]. Though the paper

was   published   in 1965, it is fair to say that its use as a robust tool of

mathematical software is recent and, as of now, is not very widespread             (see
[L] and    [5].
      The singular values of the matrix A and the non-negative square roots
of the eigenvalues of the symmetric matrix ATA are mathematically equal,
but may be different computationally. Singular values correct to working
accuracy   for the matrix A can often be computed when certain small
elgenvalues cannot be computed for ATA. This fact is not startling. It
is caused by the perturbation of an exact          ATA    introduced
                                                                   the multiplication
                                                                       in

of AT by A. There are       many   examples of such matrices, one of which is
illustrated in [9], assuming a 4-deciina1-place machine, as

                              A          1.005      0.995
                                          .995     1.005
                                     L

having singular values 2.0 and .01. The matrix ATA in '4-decimal arithmetic
is

                            ATA          2.000      2.000

                                         2.000      2.000
                                    ——


with eigenvalues i..0 and 0.0. Attrition in forming ATA has obscured all
information about the smaller singular value.
       The subroutine I'1I1'IFIT, using the notation in [2], reduces the system
of equations
                                 Ax    b

where A has m rows and n columns (m can be less than, equAl to, or greater
than n) to the form

                            UEvTxb
giving                         VxUb.
                                T T


The columns of V are the orrthonormal eigenvectors of ATA. The transforration
UTb is formed directly --    U is   not computed explicitly. The columns
of   U are the orthonormal eigenvectors of PAT           If   one needs the explicit

columns of U he should append the identity matrix                  to the right-hand side b.

There is no restriction, at the subroutine level, on the number of columns of b;

it can be zero.

       The diagonal matrix, E, contains the singular              values   of A. The

transformations   used to obtain the decomposition preserve unitarily invariant
norms, thereby assuring that the norm of Z is that of A. The diagonal
elements of Z, when ordered, are a]        a2   a3
                                                     .    .   .     a 0. MflFIT does
not order the singular values       Given information about the certainty of the
data A and b, one can choose the best approxiniatin matrix Ar of full rank
that   is nearest, in the norm sense, to the matrix A. From Ar the best

candidate solution x for Axb can be computed. If ar is chosen                   such   that
                                                      —5—



  a1     a2
              •    •              >    O              a2.         •
                                                                           a, whereby a1 ,   .     •a
  are   effectively          considered to be zero, the condition number of A is the

 ratio, a1— .            If the matrix A is equilibrated, i.e., scaled, so that
              ar
  a1l, Gr should be not less than   the square root of the                           machine     precision,
  or   a constant representing the uncertainty in the data,                              is larger.
                                                                                     whichever

  To   be arbitrary about the                  choice of    ar relative to a1 is difficult. At the

  NEER Conputer Psearch Center we have chosen a rank tolerance equal to the
  floating point representation of 2_26, the square root of the machine
  precision, 2_52. There is an obvious danger that this range rolerance may be
  inadequate for sone problesm. For example suppose that AU z vT such that

                                      1
                                                2
                                           2

                                                      2     —26
                                                           2

                                                                          26
                                                                      2
                                                                               227




 where 2_52              e    <   2_26,        say.


         The arbitrary rank                tolerance      u1d leave a4 unchanged but set a5 to zero.

Thus   Aa would be deemed to have full rank whereas a ncre judicious choice of rank is 3.
This example,          though artificial,             is given to encc'a all usnc to display
the diagonal matrix, E, to see his Dart icular Drohiem' s distribution of the
a..
 1
                                     —6—


      Given   an   appropriate choice of




                     hAil    - llI        (z 2)l/2
                                          ir+1

whe            indicates the Frobenius no, i.e.           lAP   (E       (a1.
                                                                                )2)112
                                                                 il,m
                                                                 j:l,n

Noting tha     uTu

the diagonal matrix
                       vTv    vvT
                                     I   and that the   pseudo-inverse of E is




                         a1
                              1
                              a2


                                     1
                                     ar
                                          0


                                               0




the   pseudo-inverse of A is



                    A4 v uT.

There   is seldom any reason to form a pseudo-inverse explicitly. MINPIT
accumulates Householder transformations to produce a bidiagonal matrix
having the same singular values as A, and continues, by a variant of the
QR algorithm (see [3]), to diagonalize the bidiagonaJL form to give
                                         —7—




                          EVxUb=c
                           T  T


from which

                          x VZ+C.

Various candidate solutions x can be provided by different choices of a rank
tolerance to fix ar. See [6], chapters 25 and 26.
    For suitably chosen ar, consider those columns of V associated with
             •   .   as   Vs,, namely the columns of V that span the null space of A. Then

                           AV       0.

When such columns V exist, they constitute the non-trivial solutions of
the homogenous system of equations
                           AX 0.
The elements of the columns of V can be inspected to reveal dependencies
or near dependencies among the columns, i.e., the variables of the
coefficient matrix A. Analogously, the columns of U can reveal dependencies
among the equations,            e., the rows of A.
     In using MINFIT, and providing it to other users, we are concerned with
three distinct but related items, (1) the stability of the algorithm
fran the standpoint of numerical algebra, (2) the robustness of the
mathematical software that inplements the algorithm, and (3) the
documentation that provides information on the use of the mathematical software.
     The numerical stability of an algorithm usually means that the solution
that is computed is the exact solution of a neighboring problem and that
the neighboring problem can be defined in the sense of a backward error
analysis. Such analysis for the singular value decomposition has been
                                           —8—




published    in [2], [11], [12], and              [13].   The singular   value   decomposition

is stable in the sense that               the   computation of eigensystems of Hermitiari

matrices is stable. In general, we expect


                                          JJA-       UEVTII
                                              HAIl

to be the order       of     precision, as is corroborated for the matrices
                                machine

in   Appendix C. If this criterion should not be net for sane matrix, A,
the authors xuld like to }a-iow about it. For computational convenience we

computed
             I   JAI I -    I   IUEVTI    for   the test matrices.
                     hAil
       Robustness     of this mathematical software is established to the extent
of exposing test matrices on which the algorittm                  has performed     correctly.
Professor Gene Golub              suggested   two additional tests.      These   are

       1)   Decompose A to give uzvT. Permute                 a, reform AUVT,
            and recompute the decomposition. This gives the

            effect of a perturbation              on A in the sense that the
            resulting decomposition will show a permutation of
            the columns of U and V, yet give the same singular
            va:Iues of A. As additional tests we have taken ortho-
            normal matrices U and V, particular a, formed uvTA
            and computed AUVT. Denote the maximum singular value by
                    and the minimum singular value by nin If emin is
                                                                             amax

            less    than the relative machine precision, the computed

            °nin may       not     be less than the relative precision of the

            machine        on   which it is computed, i.e. 2_52 for long
                                  —9--




   precision, 220 for short precision, on the IBM                 360/370
   machines.

2) Calculate the residuals r= Ax—b to observe the error

   between the   true solution x and         the   computed solution x.

   From   Golub' s   formulation



                             CK(A) + CK2(A)
                                                    ff-ff
                                                    a
   in which   the condition number K(A)
                                                    amjn

          The second term on the right-hand side is daminant
   for least   squares       problems. In seeking       the   candidate

   solution      of least norm we compute


                                         k
                       UK     K(A)
                                       HxkH
   for different     choices of k. We could compute 11k
   directly by forming ç and rk. However, taking
   advantage of       ui I   = I lvi     1   it follows that
                      - 10   -




                                  i/ m             2i\1/2
                                 21    E      C.
                                               1

                          () (k                    2\/2
                                   '           T)

where   c uTb. This formulation permits the
appropriate choice of the best approximating matrix
Ar UErVT from the minimum                  without explicitly
computing the candidate solutions xk. The best approximate
solution is   obtained when 11k S minimum.

        Frequently the question is raised alxut using

iterative methods for computing the singular                value
decomposition. There is an excellent discussion of

such issues in [8] along with suggestions for

constructing matrices with exact singular values.

        Informally,   we suggest certain guidelines for
using MINFIT. Whenevçr        possible one should avoid

forming   the product   of   a matrix by its transpose.
Note that the eigenvalues A and eigerivectors X for the real

syrrinetric matrix    eigenproblem

                             AX = XA


are inunediately available from MINFIT               without ever

forming ATA. However, if         the   original problem is

to   obtain the eigensystem of a real symmetric
positive definite, negative definite, or indefinite
                                  - 11     —




matrix, SYMEIG          (see   [7])   should be used. One should,
however, be warned that the appearance of zero or
negative        elgenvalues for a matrix        believed to be
positive        definite signals the need to analyze the

original        data   or the construction of the problem

nre carefully by obtaining the singular value
decomposition of the original data matrix.

         MINFIT can be used           to   obtain the solution
of   a   linear system of equations. However, if the
matrix of coefficients is ]iown                to   have full rank, and,

if   the   condition number of this matrix is small relative

to   the uncertainty in the data, one of the matrix
factorization methods should be used. Such matrix
factorization methods            are 1) the Choleski factorization,

2)   the LU      decomposition with partial           or   complete pivoting

where the elementary transformations have been stabilized

by   row and/or coluim- interchanges, arid 3) the orthogonal
factorization with column pivoting. However, such
factorizations          cannot   be guaranteed to       give definitive

information about the condition number of a matrix.
Consider from [lL] the bidiagonal matrix of order 100
                          —l
            r5ol
            I             .502        —l




                                                       .509      —l

                                                                 .600
                                       - 12   -


      This matrix is extremely ill-conditioned       with respect   to   the solution

of   a linear system of equations. Its smallest singular value is approximately
io_22 despite   the fact that its smallest eigenvalue is .501. This          matrix   also

shows that computation of the rllest eigenvalue is limited by the relative

finite precision of the machine on which it is computed. That is to say,

the small singular value, io_22 will appear computationally to be no smaller

than the order of machine precision. This result is not attributable to the

construction of the algorithm, but rather to the finite precision of the

'machine's arithmetic.

       We suggest everywhere the use of long precision on the IBM 360/370

machines to compute the solutions of linear systems of equations, eigen-

systems,   and the   singular   value decomposition. Even so, we urge extreme
caution wherever the number of rows, m, or the number of columns, n, of a
matrix is of more than modest size, say 200, if the matrix is dense.
                A - ,,  /
The quantity                  should be the order of machine precision.
                     IIAIIuInax(m,n)
However,   the computational algorithms are, in general,         0(n3) or 0(mn2)

processes. We advise a rigorous analysis of the structure of a matrix

of   high dinens ions before    any of   the numerical algebra   algorithms are used.
See   Appendix C for son timing results on random matrices.
       The singular values of a matrix can be substantially altered by scaling
the   original data matrix as is shown by the examples in Appendix C.

Deliberately, MThFIT does not include scaling of the rows or columns

 of the matrix A or right-band sides b. For the best perfonnance of the

 algorithm we suggest that columns of A be equili]riated such that the sums

 of their elements be as nearly equal as possible. Exact powers of
                                       — 13 —




16 for the 360/370 machines should be used for scaling            factors   so that

the    data is not perturbed in trailing digits. Rowscaling will have the
effect of introducing weights on the data in a least squares problem and

therefore should be done at a user's discretion. An excellent discussion
of scaling is in 16].

            further points out in [6] that it is important to take advantage
        Lawson

of infoniation about the certainty of data. For example, if data is known
to have uncertainty in the third decimal place, that digit and all that
follow are arbitrary. The matrix

                                          1.09
                               11.02
                                          1.01
                               [1.05
if    uncertain in the third figure could lead to

                                          1.00
                            [1.00
                              1.00        1.00
                            L

       The eigenvectors of a syrmietric matrix, and therefore, the singular

vectors      U and V from MINFIT   are known only to   within   a constant multiplier
of modulus 1. If anyone should attempt to recompute the results in
Appendix C      on a machine   .fnose aritblrEtic is different from that of•
the   I1vI   360/67 he may observe a change in sign on    the columns of U or V.

       The Fortran IV subroutine        MINFIT, imbedded in TROLL (see [7]), that
forms the singular value decomposition and obtains a best approximate solution
vector x is an adaptation of ANLF233S from the Argonne National Laboratory.
ANLF233S written by Burton Garbow, ANL, is a Fortran IV translation, with
certain modifications, of the Algol 60 procedure MINFIT [3]. We have aunented
                                    — lL   —




ANLF233S by adding cainnents and producing the numerically

best approxinate solution x based on a particular rank tolerance chosen for

the I1 360/370 long precision arithnetic. The machine epsilon, that is, the

smallest number, c >    0,   for which 1 + c > 1 is the floating point representation

of 16_13 = 2_52 for th IRI 360/370 machines. The comments and the Fortran IV

listing of the subroutine used at the Center is given in Appendix A. The

description of the parameters for the TROLL interface is given in Appendix B.

Appendix C contains selected ntrices, computed solutions, and residual

norm checks obtained fr driver programs that use the singular value

decomposition. These results were computed on          the   IHI 360/67. Comments,

questions,    or criticims of this subroutine should be brought         to the
attention    of the authors of this working paper.
                                       — 15 —




 References

 1.   Eckert, C., arid Young, G. (1936) "The Approxiiration of One Matrix
      by Another of Lower Rank," Psychometrika 1, 211-218.

 2. Golub, G. and Kahan, W., "Calculating the Singular Values and
     Pseudo-inverse of a Matrix," in J. SIAM. Numer. Anal. SER
      B 2, 205—224 (1965).

 3. Golub,    G. H. and Reinsch,       C., "Singular   Value   Decomposition and
      Least Squares Solutions," in J.       H. WiJidnson arid     C. Reinsch (eds.)
      Handbook for Automatic Computation, Volume II: Linear Algebra,
      Springer Verlag, 134-151 (1971); prepublished in Numer. Math.
      14, 403—420 (1970).
 4.   Hanson, R. and Lawson, C. L., "Extensions and Applications of
      the Householder Algorithn for Solving Linear Least Squares Problems,"
      Mathematics of Computation, vol. 23, no. 108, 787-812 (1969).
 5.   Lawson, C. L.. "Applications of Singular Value Analysis" in John Rice
      (ed.), Mathematical Software, Academic Press, Chapter 25 (1971).
 6. Lawson, C. L., and Hanson, R. J., Solving Least Squares Problems,
     Prentice-Hall, (1974).
 7. Natiorial Bureau of conic Research, ThOLL Experimental Programs:
      Numerical Methods,     (1974).
 8.   Soderstrom, Torsten and Stewart, G. W., "On the Numerical Properties
      of an Iterative Method for Computing the Moore-Penrose Generalized
      Inverse, SIAM J. Numer. Anal    Vol. 11, No. 1 (1974), 61-74.
 9. Stewart, G. W., Introduction to Matrix Computations, Academic Press,
      380—387 (1973).
10.   Sylvester, J. J., Messenger of       Math 19, 42 (1889).
11. Wedin, Per-Ake, "Perturbation Bounds in Connection with Singular Value
      Decomposition," BIT 12     (1972), 99—111.

12. Wedin, Per-Ake, "Perturbation Theory for Pseudo-Inverses," BIT              13 (1973),
     217—232.

13.   Wedin, Per-Ake, "On the Almost Rank Deficient Case of the Least Squares
      Problem,"   BIT (1973) 344—354.

14.   Wilkinson, J. H., The Algebraic Eigenvalue Problem, Clarendon Press
      (1965), 195.
    APPENDIX A: Listing of the Fortren IV Program MINFIT


          SUBROUTINE MINFIT(NM,M,N,A,W,IP,B,IERR,RV1,RETX)
    C
          INTEGER I,J,K,L,M,N,II,IP,I1,KK,Kj,LL,L1,M1,NM,ITS,IERR
          REAL*8 A(NM,N),W(N),B(NM,IP),RV1(N)
          REAL*8 C,F,G,H, S, X,Y, Z ,EPS,SCALE,MACHP,RKTOL
          REAL*8 DSQRT,DMAX1,DABS,DSIGN
          LOGICAL RETX
    C
    C     THIS SUBROUTINE DETERMINES, TOWARDS THE SULUTION OF THE LINEAR
    C                                                        T
C         SYSTEM AXB, THE SINGULAR VALUE DECOMPOSITION A=USV OF 4 REAL
C                                                T
C         M BY N RECTANGULAR MATRIX, FORMING U B REATHER THAN U, HUUSEHOLDER
C         BIDIAGONALIZATION AND A VARIANT OF THE OR ALGORITHM ARE USED.
C         THIS SUBROUTINE COMPUTES A CANDIDATE SOLUTION X WHEN THE
C         LOGICAL INPUT PARAMETER RETX IS SET .TRUE. THIS CANDIDATE
C         SOLUTION IS BASED ON THE RANK TOLERANCE SET TO
C         2.ODO**(—26), THE SQUARE ROOT OF THE MACHINE PRECISION
C         2.ODO**(—52).
C
C        ON INPUT:
C
C            NM MUST BE SET TO THE ROW DIMENSION OF THE TWO—DIMENSIONAL
C              ARRAY PARAMETERS AS DECLARED IN THE CALLING PROGRAM
C              DIMENSION STATEMENT. NOTE THAT NM MUST BE AT LEAST
C              AS LARGE AS THE MAXIMUM UF M AND N;
C
C           M IS THE NUMBER OF ROWS OF A AND B;
C
C           N IS THE NUMBER OF COLUMNS OF A AND THE ORDER OF V;
C
C           A CONTAINS THE RECTANGULAR COEFFICIENT MATRIX OF THE SYSTEM;
C
C            IP IS THE NUMBER OF COLUMNS OF B. IP CAN BE ZERO;
C
C           B CONTAINS THE CONSTANT COLUMN MATRIX OF THE SYSTEM
C             IF IP IS NOT ZERO. OTHERWISE B IS NOT REFERENCED.
C
C           RETX MUST BE SET .TRUE. IF THE CANDIDATE SOLUTION X IS TO
C             BE COMPUTED. IF ONLY THE SINGULAR VALUE DECOMPOSITION IS
C             DESIRED, SET RETX .FALSE.
C
C
C        ON OUTPUT:
C
C           A HAS BEEN OVERWRITTEN BY THE MATRIX V (ORTHOGONAL) O THE
C             DECOMPOSITION IN ITS FIRST N ROWS AND COLUMNS. IF AN
C             ERROR EXIT IS MADE, THE COLUMNS OF V CORRESPONDING TO
C             INDICES OF CORRECT SINGULAR VALUES SHOULD BE CORRECT;
C
C           W CONTAINS THE N (NON—NEGATIVE) SINGULAR VALUES OF A (THE
C             DIAGONAL ELEMENTS OF S). THEY ARE UNORDERED. IF AN
C             ERROR EXIT IS MADE, THE SINGULAR VALUES SHOULD BE CORRECT
C             FOR INDICES IERR+1,IERR+2,.,,,N;
C
                                        -A2-



C                                               T
C            B HAS BEEN OVERWRITTEN BY U B. IF AN ERROR EXIT IS MADE,
C                                   T
C              THE ROWS OF U B CORRESPONDING IL) INDICES OF CORRECT
C              SINGULAR VALUES SHOULD BE CORRECT;
C
C         IF RETX IS TRUE, W WILL CONTAIN THE DIAGONAL OF THE PSEUDOINVERSE
C           OF THE DIAGONAL MATRIX S. ANY SINGULAR VALUES THAT
C           ARE LESS THAN RKTOL TIMES THE LARGEST SINGLUAR VALUE ARE
C           SET TO ZERO IN THE PSEUDUINVERSE.
C
C           ALSO, THE SOLUTION X IS RETURNED IN B, REPLACING U B.
C
C            IERR IS SET TO
C              ZERO    FOR NORMAL RETURN,
C              K       IF THE K—TH SINGULAR VALUE HAS NOT BEEN
C                      DETERMINED AFTER 30 ITERATIONS,
C              —1      IF THE MAXIMUM SINGULAR VALUE IS ZERO (INDICATING
C                      A ZERO A MATRIX ON INPUT). ONLY SET IF
C                      RETX IS .TRUE..
C
C            RV1 IS A TEMPORARY STORAGE ARRAY.
C
C
C
C         :::;::::::   MACHEP IS A MACHINE DEPENDENT PARAMETER SPECIFYING
C                 THE RELATIVE PRECISION OF FLOATING POINT ARITHMETIC
C                 MACHEP = 1b.000**(—13) FOR LONG FORM ARITHMETIC
C
          DATA MACHEP/Z3410000000000000/
C         ::::::::::   RKTOL, FOR THESE APPLICATIONS, IS THE SQUARE
ç                 ROOTOFMACHEP::::::::::::::
          DATA RKTOL/Z3A40000000000000/
C         ;:w::::: HOUSEHOLDER REDUCTI[JN TO BIDIAGUNAL FORM ::::::::::
          IERR = 0
          G = 0.ODO
          SCALE = 0.000
          X = O.ODO
C
          00 300 1= 1, N
             L=I+1
             RVLII) = SCALE * G
             G   0.000
             S   0.000
             SCALE = O.ODO
             IF (I .GT. M) GO TO 210
C
            00 120 K   I, M
    120     SCALE = SCALE + DABS(A(K,I))
C
             IF (SCALE .EQ. 0.000) GO TO 210
C
             DO 130 K =    I,   M
                A(K,I) =    A(K,I) /    SCALE
                  = S +    A(K,I)**2
                                              -A3-



    130      CONTINUE
C
            F a A(I,I)
            Ga —DSIGN(L)SQRT(S),F)
            H a F * G — S
            A(I,I)   F — G
            IF (I .EO. N) GO TO 160
C
             00 150 J =      L,       N
                   S =   0.000
C
                   DO 140 K   I, M
    140            S = S + A(K,I) *                A(K,J)
C
                   F=S/H
C
                   DO 10 K =          I,      M
                   A(K,J) =               A(K,J)     + F    *   A(K,I)
    150      CONTINUE
C
    160 IF (IP .EQ. 0) GO TO 190
C
          00 180 J =         1,IP
             S =    0.000
C
             DO 170 K =    M     I,
    170      S = S + A(K,j) *                 B(K,J)
C
             F=S/H
C
           00 180 K =            I,   M
              B(K,J) =              B(K,J)        + F *    A(K,I)
    180 CONTINUE
C
    190     DO 200 K =    M      I,
    200     A(K,I)   SCALE *                  A(K,I)
C
    210     W(I) = SCALE *                G
            G = 0.000
            S =     0.000
            SCALE = 0.000
            IF (I .GT. M .OR. I .EQ. N) GO TO 290
C
            DO 220 K = L, N
    220     SCALE = SCALE + DABS(A(I,K))
C
             IF (SCALE .EQ. 0.ODO) GO TO 290
C
            00 230 K = L, N
               A(I,K) = A(I,K) / SCALE
                   S =   S   +   A(I,K)**2
    230     CONTINUE
C
            F       A(I,L)
            G = —DSIGN(DSQRT(S),F)
                                                    -A'-




              H —F *G— S
              A(I,L)               F —    G
C
              00 240 K = L, N
     240      RV1(K) = A(I,K) / H
C
           IF (I .EQ. M) GO TO 270
C
              DO 260 J =          L,          M
                    S -       0.000
C
                    DO 250 K = L, N
     250            S = S + A(J,K) *                 A(I,K)
C
                 00 260 K = L, N
                    A(J,K) = A(J,K)                    + S    * RV1(K)
     260      CONTINUE
C
    270       00 280 K z L, N
     280      A(I,K) = SCALE *                    A(I,K)
C
    290     X=DMAX1(X,DABS(W(I))+[)AbS(Rv1(j)))
    300 CONTINUE
C       ::::w::: ACCUMULATION OF RIGHT—HAND TRANSFORMATIONS ::::::::::
C       :::::::::: FOR I=N STEP —1 UNTIL 1 DO ——
        DO 400 II - 1, N
              I =    N    +    1   —     II
              IF (I .EQ. N) GO TO 390
              IF (G .E0. O.ODO) GO TO 360
              H = A(I,L) * G
C
              DO 320 J = L, N
    320       A(J,I) = A(I,J) / H
C
              DO 350 J = L, N
                 S = 0.ODO
C
                 DO 340 K   L, N
    340          S = S + A(I,K) *                   A(K,J)
C
                 DO350 K = L, N
                   A(K,J) = A(K,J) + S *                       A(K,I)
    350      CONTINUE
C
    360      D0380J=L,N
                A(I,J) = O.ODO
                A(J,I) = O.ODO
    380      CONTINUE
C
    390      All,!) = 1.000
             G = RV1(I)
             L=I
    400 CONTINUE
C
           IF (M .GE. N .OR. IP .E0. 0) GO TO 510
                                     -A5-




          Ml •   M +   1
C
          DO 500 I         Ml, N
C
           00 500 J — 1, IP
           B(I,J) = 0.000
    500 CONTINUE
C         ::::z:::8:DIAGONALIZATIONOFTHEBIDIAGONALFORM::::::::::
  510 EPS • MACHEP * X
C     :::::::::: FOR K=N STEP —1 UNTIL 1 DO ——
      DO 700 KK
                                                             ::::::::::
                  1, N
         Ki   N — KK
         K • Ki + 1
      ITS = 0
C     :::::::::: TEST FOR SPLITTING.
C                          FOR L=K STEP —1 UNTIL 1 1)1) ——
    520      00 530 LL • 1, K
                Li = K — LL
                L = Li + 1
                IF (DABS(RV1(L)) .LE. EPS) GO TO 565
C         :::::::::: RV1(i) IS ALWAYS ZEKO, SO THERE IS NO EXIT
C                          THRUUGH   THE BOTTOM UP- THE LUOP :::::::
                  IF (DABS(W(L1)) .LE. EPS) GO TO 540
    530    CONTINUE
C       :::::::::: CANCELLATION OF RV1(L) IF L GREATER THAN 1 :::::::
    540    C = 0.000
           S   1.000
C
             DO 560 1 = L, K
                F = S * RV1(I)
                RV1(I) = C * RVI(I)
                IF (DABSIF) .LE. EPS) GO TO 565
                G = W(I)
                H = DSQRT(F*F+G*G)
                W(I) = H
                 C=G/H
                  S = —F / H
                  IF (IP .EQ. 0) GO TO 560
C
                 DO 550 J = 1, IP
                    V = B(L1,J)
                    Z = B(I,J)
                    B(L1,J) = V *       C   + Z * 5
                    B(I,J) = —Y *       S   + Z * C
    550          CONTINUE
C
    560     CONTINUE
C         ::::::::::TESTFORCONvERGENcE::::::::::
    565      Z — W(K)
             IF (L .EQ. K) GO TO 650
C         :::::::::: SHIFT FROM BOTTOM 2 BY 2 MINOR ::::::::::
          IF (ITS .E0. 30) GO TO 1000
          ITS = ITS + 1
            X = W(L)
            Y = W(K1)
                                           -AS-


             G      RV1(K1)
             H      RV1(K)
             F =    ((V    — Z) * (V + Z) + (G — H) * (G +   H)) / (2.ODO *   H   * Y)
             G z DSQRT(F*F+1.000)
             F                    + H * (V / (F + USIGN(G,F)) — H)) / X
                 ((X — Z) * (X + Z)
C         ::::::::::NEXTQRTRANSFORMATIUN::::::::::
             C = 1.000
             S = 1.01)0
C
             DO 600 Il = L, Ki
                I   Ii + 1
                   G =    RV1(I)
                   V =    W(I)
                   H=S*G
                   G =C *G
                   Z = DSQRT(F*F+H*H)
                   RV1(I1) =       Z
                 C=F/Z
                 S=H/Z
                 F=X*C+G*S
                 G = —x * S + *        G   C
                 H=V*S
                 V=Y*c
C
                 DO 570 J = 1, N
                    X   A(J,I1)
                    Z = A(J,!)
                    A(J,I1) = X * C +            Z * S
                    A(J,I) = —x * S +            Z * C
    570          CONTINUE
C
                 1 = DSQRT(F*F+H*H)
                 W(I1) = Z
C         ::::::::::  ROTATION CAN BE ARBITRARY IF Z IS ZERO ::::::::::
                 IF (Z .EQ. 0.ODO) GO TO 580
                 C=F/Z
                 S=H/Z
    580          F=C*G+S*Y
                 X = * + *        y
                     —s   G   C
                 IF (IP .EQ. 0) GO TO 600
C
                 DO 590 J = 1, IP
                    V = B(I1,J)
                    Z = B(I,J)
                    B(I1,J) = V *          C   + Z *     S
                    B(I,J) = —Y *          S   + 1   *   C
    590          CONTINUE
C
    600     CONTINUE
C
             RV1(L) = 0.000
             RV1(K) = F
             W(K) = X
             GO TO 520
C         ::::::::::CONVERGENCE::::::::::
                                       -A7-



    650         IF (Z .GE. 0.ODO) GO TO 700
C
                W(K) =
C
                DO 690 J  1, N
    690         A(J,K) = —A(J,K)
C
    700 CONTINUE
        IF (.NOT. RETX) GO TO 1001
C
          Z    = O.ODO
          DO 750 J = 1, N
             X = W(J)
             IF (X .LE. 1)        GO   TO 70
                Z=X
    750 CONTINUE
        IF (Z .E0. 0) GO TO 999
C
           800 J = 1, N
          DO
           X   W(J) / Z
           IF (X .LE. RKTOL) GO TO 7Y0
           W(J) = 1.ODO / W(J)
           GO TO 800
    790    W(J) = 0.000
    800 CONTINUE
C         ::::::::::FORMX(RETURNED!NB)::::::::::
          DO900J=1,IP
C
                DO 810 I = 1, N
                   RV1(I) = W(I) *      B(I,J)
    810         CONTINUE
C
                DO 890 I = 1, N
C
                   X = O.ODO
                   00 850 Ii = 1, N
                      X = X + A(I,I1)      *   RV1(I1)
    850            CONTINUE
C
                   B(I,J) =   X
C
    890         CONTINUE
C
    900 CONTINUE
C
       GO TO 1001
C      :::::::::: ERROR IF MAX SINGULAR VALUE = 0 ::::::::::
   999 K=—1
C      :::::::::: SET ERROR —— NO CONVERGENCE TO A
C                 SINGULAR VALUE AFTE( 30 ItERATIONS ::::::::::::
  1000 IERR = K
  1001 RETURN
C
          END
APPENDIX B: TROLL Impleiintatiom of ?T\IFIT and Associated Output



The calling sequence for using the singular value decomposition
within the TROLL envirornnent is considerably different than that        for

the Fortran    subroutine listed in Appendix A. This is a consequence

of the basic design features of TROLL.         However   all computations are
actually performed by the routine listed in Appendix A.

     The TROLL version of the singular value decomposition is a function

named   MINFIT. Since it     is a function, it returns a single data file as its

result,   and by TROLL convention it may not modify any of its arguments.
The format of the TROLL call to MINFIT is

             result =   MINFIT   (A-matrix <, B-matrix <, code >>)

where   the <> indicate optional arguments.
     Since we may desire several matrices as output from MThTFIT, the data
file returned as result may be made up of several matrices. The precise
result returned by Mfl\IFIT is controlled by the code parameter as described
in the following table for the linear system:
                                             - B2 -




                           A    X B               whereAUZVT
                          1mm nxp                 and W diagonal of


            Code         B-matrix omitted             B-matrix present

             .0          illegal                      X (nxp) (default)


             1           V (nxri)    (default)        V (nxn)

             2           W (nxl)                      W (nxl)

                         .                             T
             3                                        U B




                                                       (U B) 'pxn



     The   correspondence between the TROLL parameters             and the   Fortran
parameters   is as follows:

             Inrniediately    prior to TROLL call to Fortran routine



            TROlL                                               Fortran parameter

           Max       (number of rows of A-matrix,                    NM
                      number of columns A-matrix)

            Number    of rows of A-matrix                            M
            Number of columns of A-matrix                             N

            A-matrix                                                 A

            free storage                                              W


            if B-matrix omitted then 0                                IP
                  else number   of   colunis of B-matrix
            not    set                                                IERR

            free    storage                                           RV1

            if    code   0 or code omitted and B-matrix is
                 present then .TRUE. else •FALSE.
                                                  — B3 -




                                 After call of Fortran routine

If    IERR    is not zero then print appropriate error messag; otherwise

                          Code                     Fortran variable to be used as result
                          0                             B        (the solution X is formed                in B)
                          1                            A

                          2                             w

                          3                             B
                                                                                                                            lxn
                                                        ]
                                                                                                                    .W

                                                                       or if B-matrix was specific [A]mm
                                                   {                                                B nxp



For more details on the use of the ThOLL function, see [7].

           The following output is          the   result       of   perfoniiing the TROLL version

of    IvNFIT on the Longley data described in Appendix C. Row 1 of the
matrix contains W, rs 2 through 8 contain the V matrix, and row 9 is
 (UTb)T.




M161T(IIIMc,,jyx,Iu,1(;i-yy,4)
     '}W     CIJUIMN I        CLI.N ?      CI;.IiN 3          CtILIIM'J 4       CULIIMN ,        1ILIIMN 6        CtI.IIM    1


1           1 .,371-+06    M.39OO+O4      4.47-+U3           1 .4M-+t)3         41 .65420fl     343?4-—fl4       3 6'fl4f-+Ofl
?          —?. 3417—h      I .u7—o       —.731 M—06          .16O—6           —. 1O3M—(4       —t .OflOOF+()     3.41 I —)5
I          —?.4376F—04     6. t"6Yf—O4   —4.'4-—I)4         —1 .43706—03      -1 .044?6—O1      1.fl76—fl',     —Q.94,4F—(1
4          —9.6034—0l     —. f7M6—0I     —?.t1 1-—I)         4.h4—()          —1 .I0—O3 —4.flR6—)N               1 ."411 F—4
',         —7.7734F—04     I .43'F—0?     7.844I—o1         —6.18 6,-—u1      —1 .7fl4—fl? —4•,77-—fl7           ?. '3'I-—fl3
6          —6.2675—(J      I.34??6—O?    —h• 166-—01        —7.854R1-—01       S.07??#—03      —l .40946—07      6.06176—04
7          —?.7M616—t)1    Y..991—01     —4.1466—0           I.8H3F—0?         2.13R16—O?       l.0430k—07      —l.60."6—03
8          —4.57946—03     ?.08926—0?    —l .S461-—0?        4.4) -—03        —4.941?'-—Ol      ' • I 1346—04    1 .)4'n-—r)1
9          —?.5151)6+05    4.6093F+04    —?.4A3?6+03         1 .h() 491-+0A   —1 .773tSE+fli    1 • 18906+03     ?1 0.q'0001
APPENDIX C:        Selected Matrices, Computed Soluticris, and Illustrative Examples

This appendix displays a representative sample of matrices on which
the subroutine IT'TFIT has perford satisfactorily. The input matrices
and the output computathns have been retained on magnetic tape. The
format      of the printing was      chosen   for convenience     and does    not include

the   full fifteen decimal         place   output that   was produced by the long
ecisn computation on the machine. If anyone should attempt to reproduce

these   results on a machine whose           arithmetic or relative precision is different

fran that of the IBM 3 60/67 he may get output that is different from that
which we display. However, such results should be                  correct to the order
of   machine    precision      on which the computation is perfonned.

       Though we include certain           matrices of   the Hubert    senents,     we do not

encoage        their use as test matrices for software validation. The Hilbert
senents are not representable cactly in a computing machine unless
appropriate multipliers are used to preclude a perturbation on input of the
data. We have used such multipliers.
       Other matrices exhibited are a 3x3 matrix that is contrived to display
infor!ation about near dependencies of rows or columns, a test matrix from
[l]* and [2] and a matrix suggested by Ed Kuh. The                  matrix from    [1]   is exactly

representable       in the machine though it is ill conditioned with respect to
the solution of linear systems of equations. The matrix in [J shows the
dependence of the solution vector x on the rank tolerance that is chosen.
       On the output that is         displayed, V   has its usual meaning, W contains
the   unordered singular values fran ML1FIT, P is an integer vector that
indicates the descending order of the singular values, MU contains
      for   i=l, 2,. .   . ,n for each   right-hand side   and   c contains   uTb. X contains

the candidate solution of Axb.                IERR is the error     indicator   from MINFTT;   it is
non-zero if the computation of any              singular value     requires more than 30

iterations or if the maximum singular             value    is zero.

*NmEraJs in square brackets refer to entries in the Reference section, p. C114.
                                           _C2 -



     This 3x3 matrix shows output that indicates rank 2 if the smallest
singular value is treated as zero. Given this interpretation, columns
1 and 2 are linearly dependent. This infotion is contained in column 2
of the V matrix,

                     A.
                      4108          1
                    0.10101 001) 01            (1 • 1009A001) 01 0.98000000 0))
                      ROW           2 ):
                    0.10098000 01              0.10104001) 01      0.98000001) 00
                      ROW           3
                    0 • 9)4000000 00 I) .9800000)) 1)11            0 • 101 00001) 01



                    C0?.UMN         1)
                    0.1000000)) 01 0.0                             0.0
                   (COLUMN          7)
                    0.0                        0.1000000)) 01 0.0
                   (COLUMN          3)
                    0.0                        0.0                 0.1000000)) 01



                    v=
                   (COLUMN          1)
                   —11.57977491) 00 —0 .5793330)1 0>1 —0. 5734230)) 00
                    CIII. INN       2I
                   —0 • 70)401 190 00 0.70619)43)) 00 0.176066 1l)—0
                   (COLUMN    3)
                   —0.40393051) 00 —0.4)170101)) 00 11.81925761) 00

                    8=
                    0.7990101) 01 0.44980760—03 0. 39948830—tI 1

                    C.
                    CtIl_IIMN I
                   —0.57927491) 00 —0. 70801 191) 0)) —0.40 493051) III)
                    COLUMN          7
                   —0.5793311)11 00            (I. 70619831) 0)) —11 • 40701 Iii)) 00
                   (COLUMN          3)
                   —0.5734? 11))) 00 (1.1 761)441 0—02             1). 8192576)) 00


                                I          3         2



                    Nil.
                   I COLUMN         1)
                    0.46(501 51) 02            11.418407601)   01) 11.54410011(1—1)2
                    CI)I_IJUN       7)
                    0.461455 11) 02 0.41773891)) 00 11.56945950—02
                    COlUMN          3)
                    0.466711))) 02 0.43594980 01)                   0.4282218)) 00


                   IJS 1510 MAC.HSP, X=
                    C)i(.UMN  1)
                    0.1118630)) 04 —0.1107352)) 04 —0.10943611) 1)2
                    CUIJJMN   7)
                   —0.110735711 04 11.11129911) 1)4 —1). 5471803>) 01
                   (COLUMN          3)
                   —0.10943610 02 —11.5471803)) 01 0.16917921) 1)2



                    ((SING RKIUL, X=
                   (COLUMN     1)
                    0.1 118631)>)        06 —0.11073521) 04 —0.1094361)1 11
                   (COLUMN     2)
                   —0.11073520 04 0.11129910 04 —)).54718031) 01
                   (COLUMN    3)
                   —0.1094361)> 02 —0.54718030 01 0.16917921) 02
                                     - C3 -




      The matrix whose data is displayed on the following page was suggested

by Ed Ith. The matrix is 32x10 and has singular values, to 4 decimal places,


              4921, '41.89, 30.33, 18.71, 8.573, 2.491,

              4.763, 5.532, 6.162, 6.091.

      The    indicated rank determination   is   that   the matrix is of rank 10

if   the   data is certain in all digits, of rank       1 if the   third   digit is

doubtful.
      The residual checks for the decomposition are




MAX—ROW—SliM lSjDtJAL =             O.18182413271)—14
UCLIDIAN RESIDUAL =              U .240?6Y7593D—14
1AX—C(JL—SlJM RtSIDlJAL =           O.1378022275D—14




       Thuncation of the data to integers 234,231,... 3l1 gives singular values

to 4 decimal places.


              '4911, '41.10, 30.07, 18.59, 8.356, 3,403,
              6.299, 5.727, 4.963, 5.198
                             - C4   -

Data    for A                           Right-hand   side   B
346.6      Row 32                       214.6
342.1           ow_31                   216.7
337.9               iow 30              225.0
337.9                                   228.4
331.2                                   230.1
326.7                                   231.0
321.8                                   230.3
314.5                                   232.3
312.2                                   234.6
311.7                                   237.3
311.6                                   241.8
307.4                                   247.7
303.8                                   252.7
300.8                                   256.8
294.6                                   260.4
290.7                                   262.0
286.4                                   264.4
283.2                                   267.5
278.9                                   272.8
272.6                                   277.2
266.2                                   279.3
262.4                                   283.8
257.3                                   285.4
254.7                                   284.5
255.3                                   287.4
254.0                                   292.2
253.8                                   296.2
253.4                                   304.0
249.2                                   309.8
245.8                                   314.8
240.9                                   316.3
234.4 ow 1                              321.1
231.7
231.2
227.9
226.0
220.8
214.7
209.0
201.5
202.2
                                            - C5    —




        The   Hubert matrix of order 7, generated in long precision, 7 digits
of which are given for each element, is inexact in the machine.


a=
  ROW     1   ):                                                                                           00
0.10000000 01      0.50000000 00   0.33333330 00   0.2500000() 00   O.2000000D 00     0.1666667D 00
  ROW     2   ):
0.50000000 00      0.33333330 00   0.25000000 00   0.2000000') 00   O.1h666671) 00    0.142R571D 00        00
  ROW     3   ):                                                                                           00
0.33333330    00   0.25000000 00   0.20000000 00   0.1,6h6671) 00   0.14285710 00     0.12500000 00
  ROW    4    ):                                                                      0.11111111) 00       00
0.25000000 00      0.20000000 00   0.16666670 00   0.1428571') 00   0.12500000 00
( ROW    5 ):                                                                                                    •

0.20000000 00      0.16666670 00   0.14285710 00   0.12500000 00    0.11111110 00     0.10000000 00
I ROW    6 I:
0.16666671) 00     0.14285710 00   0.12500000 00   0.11111111) 00   0.11)000001) 00   0.90909090—01
  ROW     7   ):




Its singular values are


0.166088,I) 01 0.27192021)00 0.212875D—O1 0.100R588)—02             0.2R637I)—O4 0.4M5h74S31)—06 0.34937440—08
                                              - CE    -



    Multiplication of the Hubert matrix of order 7 by the constant
360360 allows a machine representation that is exact.


 4=
I ROW    1 ):
0.36036000 06     0.18018000 06    0.12012000 06    0.9009000)) 05      0.72072000 05    0.60060000 05    0.51480000 05
  ROW    2 I:
0.18018000 06     0.12012000 06    0.90090000 05    0.7207200)) 05      0.6006000)) 05   0.51480000 05    0.45045000 05
I ROW    3 I:
0.12012001) 06    0.90090001) 05   0.72072001) 05   0.60060001) 05      0.5148000)) 05   0.45045000 05    0.40040000 05
I ROW    4   ):
0.90090000   Q5   0.72072001) 05   0.60060000 05    0.5148000') 05      0.4504500)) 05   0.40040000 05    0.36036000 05
  ROW    S   I:
0.7207200)) 05    0.60060000 05    0.51480001) 05   0.4504500)) 05      0.4004000)) 05   0.3603600)) 05   0.32760000 05
I ROW    6 ):
0.60060000 05     0.51480000 05    0.45045000 05    0.400400(1')   05   0.3603600)) 05   0.32760001) 05   0.3003000)) 05
                                                                                            .
I ROW    7 I:
0.51480000 05     0.45045000 05    0.40040001) 05   0.3603600') 05      0.32760000 05    0.10030000 05    0.27720001) 05




                                                                                                                           S
Its singular values are


0.59851661) 06 0.97989161) 05 0.76719761) 04 0.36345461) 03 0.10589670 02 0.17501830 00 0.12590610—0?




                                                                                                                           .
                                                                  - C7   -



             The             Longley data matrix [3J with its associated output is

 I ROW        1    I:
 0.10000000 01               0.83000000 02         0.23428900 06     0.2356)1000    1)4   0.15900001) 04      0.10760801) 06      0.19470001) ((4
 I ROW        2    I:
 0.10000000 01               0.88500000 02         0.25942600 04,    0.2325000')    (14   0.1456000)) 04      0.1086320)) 06      0.19480001) 04
 I ROW'       3    I:
 0.10000000 01               0.8820000D 02         0.25805400 06     0.36820001)    1)4   )).1616000)) 04     0.109773(11) 06     0.19490001) 04
 I 80W        4    'I:
                                •
 0.10000000 01               0.89500000 02         0.2845990)) 1)6   0.34510000 04        ((.16500001) 04     0.1109290))   0,5   0.1950000))   (14
 I ROW        5    I:                                     .
 0.10000000 01               0. 96200001) 02       0.32897501) 06    0.20990001)    1)4   0.3099000(1 04      0.1120750)) 06      0.1951000)) 04
 (ROW         6    I:
 0.10000000 01               0.98100000   02       0.3469990(1 06    0.1932000') 04       0.3594000)) 04      0.11327(10)) 06     0.1952(10(10 04
 I ROW        7    I
 0.10000000 01               0.99000000
                             •            02       0.3653850)) 06    0.18700000 04        0.3547000)) 04      0.1150940)) 06      0.19530000 04
 I ROW        8    I:
 0.1000000)) 01              0.10000000 03         0.36311200 06     0.35780000 04        0.43500001) 04      0.11621900 06       0.1954000)) 04
 I ROW        9    I:
 0.10000000 01               0.10120000 03         0.39746900 06     0.29041)001) ((4     l).'4048000)) 04    0.11738800 06       0.1955000)) 04
 I NOW       10 I:
 0.1000000)) 01              0.10460001) 03        0.41918000 06     0.28220001) 04       0.2857000)) 04      0.1187340)) 06      0.1956(100(1 04
 I ROW       ii    II
 0.1000000)) 01              0.10840000 03         0.44276901) 06    0.293601(0)) (4      0.2798000)) 04      0.1204450)) 06      0.1957000)) ((4
 I ROW       1?    I:
 0.10000000 01               0.1108000D   03       0.4445460)) 06    0.468101)01)   04    ((.26370001)   04   0.1219500))   04,   0.1958000(1 04
 I ROW    13 I:
 0.1000000)) 01              0.11260000 03         0.4827040006      0.3813000(1 04       0.2552000)) 04      0.12336600 06       0.19590000 04
 I ROW   14 I:
 0.10000000 01               0.11420001) 03        0.50260101) 04    0.49130001) ((4      0.2514000))    04   0.12536800 06       0.1960000)) 04
 I ROW       15    I:
 0.10000000 01               0.11570000 03         0.5181730(1 06    0.4806000!) 04       0.25720001) 04      0.12785200 06       0.1961000D 04
 I ROW       16    I:
 0.10000000 01               0.11690000 03         0.55489401) 08    0.40071)001) ))4     0.28210000 04       0.13008100 06       0.19620000 04

 8.
(COLUMN   1)
 0.60323000 05               0.61122000 05         0.60171001) 05 0.611870011 (iS 0.63221000 05 0.63639000 05 0.64989000 05
 0.63761000 05               0.6601900D 05         0.67857000 05 0.68169001) 1)5 0.66513000 05 0.6865500)) 05 0.6956400D 05
 0.6933100D 05               0.70S51000 05

(ERR •        0

 V.
 (COLUMN    1)
—0.2341720D—05 —0.24375680—03 —0.96034010 00 —0.17733770—02 —0.62675480—02 —0.27861480 00 —0.45794090—02
(COLUMN     2)
  0.10797810—04 0.61668600—03 —0.27878070 00 0.10334770—01 0.13421660—01 0.95997790 00 0.20891970—01
  COLUMN    3)
—0.97316110—05 —0.49653610—03 —0.22179310—02 0.78543941) 00 —0.6186589)) 00 —0.48045890—04 —0.18466820—01
(COLUMN     4)
  0.28160440—OS —0.14370220—02 0.46323930—02 —0.61856340 00 —O.7854783D 00 0.188828211—01 0.48025910—02
(COLUMN     5)
—0.5 103 8040—03 —0.10441850 00 —0.13504740—02 —0.17083690—01 0.80721570—02  0.2138102D—01 —0.99412300 00
(COLUMN     6)
—0.99999990 00 0.19307120—04 —0.30687980—07 —0.45777720—06 —0.13094330—06 0.10429930—06 0.51137880—03
(COLUMN     7)
  0.34 180980—04 —0.99453210 00 0.19871480—03 0.230360811—02 O.60617261)—03 —0.16085630—02 0.10439200 00


 W.
 0.16636680 07               0.83899620 05 0.34056741) 04 0.15847881) 04 0.41654200 02 0.34322890—03 0.36503800 01

 C.
(COLUMN   11
—0.15328510 00               0.45378580 00 0.89857260—01 0.26517570 00 0.30558470 00 0.11393900—01 0.15302070 00
—0. 4 84 652 90—0 1
               —0.4020948D—02 —0.19433730 00 —0.34302910 00 —U.8976866))—O1 —0.11988820 00 —0.29862080 00
—0.29740200 00 —0.46626980 00


                         2      3     4        5      7       6


 MU.
(COLUMN       1)
 0.19577650 20 0.33345700 18 0.66973430 17 0.10643310 17 0.24581320 15 0.42386460 14 0.54338150 11

 USING MACHEP, 8.
 (COLUMN   1)
 —0.3464269D 07 0.13849520 02 —0.35218390—01 —0.20094190 01 —0.10251330 01 —0.52347820—01 O.181994a0 04


  USING AKTOI., 8.
 (COLUMN   1)
  0.23724110—01 —0.53035530 02 0.71033030—01 —0.42355560 00 —0.5715101D 00 —0.41366870 00 0.48394360 02
                                                              -C8-


            The Bauer matrix                     with its associated output is

  A.
   ROW        I
—0. 74000001) 02          0.8000000)) 02 0.18000001) I)? —0.11 000)0)1)           12 —O • 4)10)10000    01 —0.8000000!) 01
      ROW     2
 0.14000000 02 —0.6900000)) 02 0.2100000)) 1?                     0.281)001)01)   12   0.0                    0.70000001) 01
 I ROW        3
 0.66000000 02 —0. 72000000 02 —0. 50000001)                01 0.7000000) III          0.1(100000))     0)    0.40000000 (11
      ROW     4
—0.1 2000001) 02          0.66000001) 02 —0.3000000)) 12 —0.23000001) 0?               0.3000000))      01   —0.30000000 01
 I ROW    5
 0.30000000 01 0.80000000 01 —0. 7000000)) ii —0.60000001) 1)1                         0 •   11)000001) 01    0.0
   ROW    6
 0.40000000 01 —0.12000000 02 0.401)00000 I)) I) .4000001il) 01                        0 • I)                 0.10000000 01

 B.
(COLUMN       1)
 0.51000000 02 —0.6100001)!) 0? —0.5600000))                02 0.69000001) 02 0.10000001) 02 —0.12000000                  0?
I CDL))MN     7
—0.56000001) 02           0.52000000 02          0.76400001) 03 0.409600!)!) 04 —0.1327600!) 05               0.8421000!) 04
(COLUMN    3)
—0.50000000 01 —0.900000011            1)1       0.70800001) 03   1)   .4165000)' 04 —0.13266000 05           0.84090000 04


(1)88 •       0

 V.
 COLUMN    1

 0.53159590 00 —0.82429841) 00 0.38242860—01 0.17q49251) 00 0.10,76910—01 0.64390190—01
(COLUMN    2)




                                                                                                                               .
—0.62509500 00 —0.2981574)) 00 0.62845081) 00 0.3481670)) 1)0 —0.6)9569011—01 0.1049137)7—01
(COLUMN    3)
 0.33696201) 00 0. 1042175)) 00 0.65658481) 00 —O.'i?3)l)901) 0)) —0 • 2 3501 73!) 00 —0.33892800 00
(COLUMN    4)
—0.40A2480 00 —0.4082483)) 00 —0.40824830 01) —0.408248311 (0) —0.41)824831) 00 —0.40874830 00
(COLUMN    5)
 0.21539230 00 0.2325(74)) 00 —0.704591911—01 0.6062083)) 00 —0.6389627)) 00 —0.34469610 00
(COLUMN    6)
 0.76299760—02 —0.64905330—02 —0.29192670—01 0.1949887!) 00 0 • 60467951) 00 —0.7716144)) 00

 .W.
 0.17383930 03            0.64861870 02 0.10667160 02 0.100000)))) 1)1                 0.1752477)) 00 0.47441820—04

 C.
(COLUMN          1)
—0.11457290 03—0.3566961002 —0.79211710 01 —0.4082483)) 00 0.891420800 00 —0.85865440—04
(COLUMN          2)
 0.37040050—03 0.16174950—03 —0.31773030—01 —0.4082483)) 00 —0.19669080 01 —0.16264440 05
(COLUMN   3)
—0.11457260 03 —0.35669450 02 —0.79529440 01 —0.81649661) 00 —0.10687000 01 —0.16264440 05


 P.          1        2       3    4         5      6


  MU.
(COLUMN          1)
 0.55143120 07 0.42339880 07 0.32020640 07                        0 •   3013079)7 07 0.69023290 06 0.65274640 06
(COLUMN   2)
 0.73068101) 15 0.14984950 15 0.16501570 12                       0.120392 51)    10 0.43763960 08 0.1433698)) 01
(COLUMN   3)
 0.74578680 09 0.57262870 09 0.4323217D 09                        0 •   3511 520)) 09 0.78558700 08 0.14337370 01



 USING MACHEP, 8.
  COLUMN   1)
  0.10000000 01 0.20000000 01 —0.10000000 01 0 • 3000000)) 01 —O.4000000D 01 —0.12249380—09
 (COLUMN   2)
 —0.26157640 07 0.2225142)) 07 0.1000810D OR —0.66847850 08 —0.2073018D 09 0.26453220 09
 (COLUMN   3)
 —0.26157630 07 0.22251440 07 0.1000810D 08 —0.66847850 08 —0.20730180 09 0.26453220 09


  USING RKTOL, 8—
 (COLUMN   1)
  0.10000000 01 0.2000000D 01 —0.10000000 01 0 • 30000000 01 —0.40000000 01 —0.12249380—09
 (COLUMN   2)
 —0.26157640 07 0.22251421) 07 O.1000810D 08 —0.66847850 08 —0.20730180 09 0.26453720 09
 (COLUMN   3)
 —0.26157630 07 0.22251440 07 0.10008100 08 —0.668478 50 08 —0.20730180 09 0.26453220 09
                                               - CS   —




          The   condition number of a nonsingular matrix may be improved by
 row or column scaling. The Bauer matrix, scaled as


  4=
 I ROW      1   1:
—0.74000000 02       0.80000001) 02   O.3600000u 02 —0.33000000 02 —0.40000000 02 —0.80000000 02
   8IJW     2   ):
 0.14000000 02 —0.69000001) 02        0.42000000 02   0.84000000 02                   0.70000001) 02
   ROW      3   ):
 0.66000000 02 —0.72000000 02 —0.I000000D 02 0.21000001) 02                      02
 I ROW    4 ):                                                                        0.40000000 02
—0.12000000 02 0.66000000 02 —0.60000000 02 —0.6900000!) 02                      02 —0.30000000 02
   0W       5   ):
 0.24000000' 02      0.64000001) 02 —0.11200000 03 —0.ThQO0OO) 02     0.80000000 02   0.0
 I UW       6   )
 0.28000000 02 —0.84000000 02         0.56000001)




 with singular values



 0.29594490 03 0.18165700 03 0.48937800 02 0.12882170 02 O.70Q59950 00 0.13971070—02
                                                       — C].O —




           singular value decomposition provides uzvT as the decomposition
         The

 of a matrix A. Given the orthononiial columns U and V one can form another
 matrix uzvT for arbitrary E. Using U and V from the inexact Hubert matrix
 of order 7, the reformed matrix


 THE REFORMED A
 I ROW      1 I:
 0.20106490 02 —0.1119 1230        03 0.23250410 03 —0.24893840 03 0.1411430 03 —0.46373310 02 0.60402080 01
 I ROW      2 I:
—0.11191230 0 0.13209940           04 —0.41280010 04 0.78498420 04 —0.67653190 04 0.29490710 04 —0.51555810 03
.1 ROW      3 1:
 0.23250410 03 —0 .472 8 00 10     04 0.25364010 05 —0.58889481) 05 0.6799662D 05 —0.38558890 05 0.85824910 04
 I ROW      4 I:
—0.24893840 03 0.78498420          04 —0.58889480 05 0.18005690 06 —0.26360290 06 0.18470440 06 —0.49868680 05
    ROW     5 ):
 0.1477433D 03 —0.67653190         04 0.61996620 05 —0.26360291) 06 0.47139410 06 —0.39302090 06 0.1238620!) 06
 I ROW      6 I:
—0.46373370 02 0.294907 10         04 —0.38558090 05 0.18470440 06 —0.39302090 06 0.37926500 06 —0.13550680 06
 I ROW      1 1:
 0.60402080 01   —0 .5 155 58 10   03 0.8582491D 04 —0.49868680 05 0.12386200 06 —0.13550680 06 0.53689920 05




 where the a1 are io8,                          io_6, 1O, lO, lO and io_2.
         The computed a1 from the reformed A are



 0.10000000 07 0.10000000 06 0.10000000 05 0.10000000 04 0.10000000 03 0.10000000 01 0.10000000 02
MAX—ROW—SUM RESIDUAL =           0.12283894900—14
EUCLIDEAN RESIDUAL =           0.99904912580—15
MAX—COL—SUM RESIDUAL               0.12263894901)—14
                                                      -cli -




         However, choosing aj                 io21, io20, io16, io12, ion, iou, 100 gives



 w.
 0.10000000 2 0.10000000 21 0.10000000 17 0.2608)441) 08 0.10000011) 13              O.21R9020   08 0.354464650 07

4AX—RUW—SUM 8ESIOUAL •            0.604675626030—16
EUCI.10E*N RESIDUAL             0.4697620457L)—15
4A*—COL—SUM RESIDUAL              0.4045041 f35D—1




         The   singular values           rial1er         tn io12   are   effected   by the order

of machine precision relative to amax
         Choosing       ai      io0, io, io8, l0_12, io6, io20, l0_2 gives



  0.   10000110 lii   U. 10000001)—Il   u. 10000000—07 0.04 1711-12 0.1 1040820—15 1. lM6?77(lU—14, 0.?307j40—l 7
 8AX140W—SIIM R4SjIIIi. •          (I.1i160610?01)—1'.
 EIlClII)iA4 RESIDUAl.           0.681417H41531)—15
 8AX—C(IL—Slh., 4,-Silpi •         0.26 1)1071391)—I,
                                         - C12 -




       The order 100 matrix

                       .501      —l

                                  .502      —l




                                             .600   —l




has a maxinum singular        value   l.587 arid a miniuim singular value l022.

The minimi.nn singular value computed on the IBM 360/67 is .3 329410 xl05.

Using long precision on the IBM 360/195 at Argonne National Laboratory,

Jack Dongerra computed the same singular values as those from the 67

 except for the rniniiinim singular value which was .33292721xl05. The

 arithiretic of the 195 is not the sane as that of the 67. Multiplying

 this matrix by 1O3 (so that the input was internally representable as

 exact integers) gave the smallest singular value .3329095xl012.

 Brian Smith suggested riiining this matrix on the 195 using short

 precision   from which the sn11est singular        value was .l287991xl05 and

 .l323073xl0
               —2                .
                    for the matrix scaled by 10 3
      We have done some -timing tests on the singular value decomposition.
In general, accessing data is more costly than           computing   the singular   value

decomposition, so we u1d expect the use of Fortran H (opt:2) to reduce the
computation times listed below by about 50%. From a Fortran IV G compilation
on the 360 / 67 computer, the computation time for U, V, and using SVD from

[2]   on random square   matrices     of dimension N is as follows:
                               - C13    -


                   .1         Tiji     in seconds
                    5             .0714
                   10             .14614

                   20            3.1490
                   140          25.010
                   60           79.353
                   80          185.653

     These times were obtained from the interval timer on the 67 which
gives approximate microseconds at 13 microsecond intervals. These
timings were obtained at the NB. Computer Research Center by Harry Bochner.
     The time required by ML'JFIT is approximately that of SVD if U, V, and
E are computed. However, in general, U is not needed. The time that is
used to form V, , and UTb is therefore reduced by alinost 50% of the times
listed here.
     The time for computation of the singular value decomposition will be
matrix dependent in that fewer iterations may be required when there are
multiplicities or clusters of singular values.
                                 - Cl'4 -



References

1. Bauer, F. L., "Elimination with Weighted Row Canbinations for
   Solving Linear Equations arid Least Squares Problems," in
   J. H. Wilkinson and C. Reinsch (eds.) Handbook for Autariatic
    Corrutation, Volume II: Linear Algebra, Springer Verlag, 7,
    338—362 (1965).

2. Goluh,  G. H. and Reinsch, C., "Singular Value Decomposition and
    Least Squares Solutions," in J. H. Wilkinson and C. Reinsch (eds.)
    Handbook  forAutaiatic Computation, Volume      II:
                                                    Linear Algebra,
    Springer Verlag, 134-151 (1971); prepubli.shed in Numer. Math.
    14, 403—420 (1970).

3. Lcngley,   James W., "An Appraisal   of Least   Squares   Programs   for
    the E1econic Computer from the Point of View of the User,"
    JASA 62, 819_8141, 1967.




                                                                              .



                                                                              .
