                              NBER WORKING PAPER SERIES




              WHAT MARGINAL OUTCOME TESTS CAN TELL US ABOUT
                     RACIALLY BIASED DECISION-MAKING

                                           Peter Hull

                                      Working Paper 28503
                              http://www.nber.org/papers/w28503


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                    February 2021




I thank David Arnold, Ivan Canay, Will Dobbie, Nicolás Grau, Jim Heckman, Conrad Miller,
Magne Mogstad, Jack Mountjoy, Damián Vergara, and Crystal Yang for many helpful comments
and conversations. Jerray Chang provided excellent research assistance. The views expressed
herein are those of the author and do not necessarily reflect the views of the National Bureau of
Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2021 by Peter Hull. All rights reserved. Short sections of text, not to exceed two paragraphs,
may be quoted without explicit permission provided that full credit, including © notice, is given
to the source.
What Marginal Outcome Tests Can Tell Us About Racially Biased Decision-Making
Peter Hull
NBER Working Paper No. 28503
February 2021
JEL No. C21,C36,J15,J71

                                           ABSTRACT

Marginal outcome tests compare the expected effects of a decision on individuals who are of
different races but at the same indifference point of the decision-maker. I present a simple
formalization of how such tests can detect racial bias, defined as a deviation from accurate
statistical discrimination. Namely, the tests can reject that the decision-maker ranks individuals
according to some accurate prediction of a mandated outcome, given some unspecified race-
inclusive information set. The frontier of marginal effects can furthermore rule out canonical
taste-based discrimination. I relate this analysis to other interpretations of marginal outcome tests,
other notions of racial discrimination, and recent identification strategies.


Peter Hull
University of Chicago
5757 South University Avenue
Chicago, IL 60637
and NBER
hull@uchicago.edu
1     Introduction
Marginal outcome tests compare the average effects of a binary decision Di on an outcome Yi
between individuals i who are of different races (or another protected characteristic) but at
the same indifference point of the decision-maker. The decision-maker has a narrow stated
or legal mandate pertaining to the outcome. Such tests are increasingly conducted in the
criminal justice setting (e.g. Arnold et al., 2018, 2020a; Marx, 2018; Feigenberg and Miller,
2020; Grau and Vergara, 2020), where the decision-maker (e.g. a judge or police officer) takes
an action Di (e.g. the granting of pretrial release or the searching of a vehicle) that affects a
given measure of criminal activity Yi (e.g. pretrial misconduct or the finding of contraband).
Motivated by the classic theory of Becker (1957), the finding of racially disparate marginal
outcomes in such settings is often taken as an indication of biased decision-making.
    Despite their recent proliferation, however, it is not always clear what marginal outcome
tests reveal about racial bias, and under what conditions. In contrast to an earlier litera-
ture which specifies and estimates complete decision-making models (e.g. Knowles et al.,
2001; Antonovics and Knight, 2009; Persico and Todd, 2006; Anwar et al., 2012), recent em-
pirical applications leverage quasi-experimental variation to identify and compare marginal
outcomes while assuming minimal structure. An advantage of this quasi-experimental ap-
proach is a robustness to alternative models, requiring only the identification of race-specific
marginal treatment effects (MTEs). But how such MTE comparisons can be interpreted in
terms of racial bias, and under what assumptions, can be unclear (Canay et al., 2020).
    This paper presents a simple theoretical framework for interpreting marginal outcome
tests in terms of racially biased decision-making, without specifying a decision-making model.
The only maintained assumption is one sufficient to define the marginal outcome test: that
the decision-maker acts according to some subjective ranking of individuals by their perceived
appropriateness for the treatment. The existence of such a decision rule defines a set of
race-specific marginal treatment effect frontiers, which capture the relationship between the
decision-maker's subjective ranking and the objective effects on the outcome. I do not assume
this ranking arises from a particular optimization problem (as in Knowles et al. (2001)) nor
that it satisfies certain separability conditions (as in Canay et al. (2020)).
    I first show that the marginal outcome test can generally detect a notion of racial bias
that is defined as a deviation from canonical statistical discrimination (Phelps, 1972; Arrow,
1973; Aigner and Cain, 1977). Formally, I show the test can reject that the decision-maker's
ranking of individuals reflects some accurate prediction of outcomes, given by some subjective
information set that includes the individual's race. Forms of racial bias that drive test
rejections include canonical taste-based discrimination, as in Becker (1957), as well as biased
beliefs or stereotypes, as in Bordalo et al. (2016) and Bohren et al. (2020). I show that while



                                               1
marginal outcome tests generally cannot differentiate between these alternative hypotheses,
the slopes of the MTE frontiers can reject canonical taste-based discrimination.1 I discuss
how rejecting accurate statistical discrimination and canonical taste-based discrimination
can be relevant to policy, even though the decision-making model is unspecified.
     I then relate this definition of racial bias, and interpretation of marginal outcome tests,
to existing definitions and analyses. In contrast to the recent analysis of Canay et al. (2020),
I find that marginal outcome tests can be informative about racial bias without an extended
Roy model restriction (Heckman and Vytlacil, 2007; D'Haultfoeuille and Maurel, 2013).
This different conclusion stems from my definition of racial bias as a deviation from accurate
statistical discrimination.2 In contrast, Canay et al. (2020) define racial bias with respect to
a particular decision-maker information set, which can be restrictive or difficult to specify
in practice. I further discuss how this paper's definition of bias differs from broader notions
of discrimination, as estimated recently by Arnold et al. (2020a) and Feigenberg and Miller
(2020), and how it aligns with the notion of algorithmic "calibration" in the computer science
literature (e.g. Barocas and Selbst, 2016; Kleinberg et al., 2017a; Chouldechova, 2017).
     I conclude with a discussion of how marginal outcome tests might be conducted. Identi-
fication of marginal effects can follow from an experimental intervention, in which decision-
makers are induced to increase or decrease their treatment rates among a random set of
white and Black individuals. Some quasi-experimental applications are based on this ideal-
ized within-agent comparison (e.g. Feigenberg and Miller (2020); see also Grau and Vergara
(2020) for an observational approach in the same spirit). In other settings, identification may
come from observing multiple as-good-as-randomly assigned decision-makers (e.g. Arnold
et al., 2018, 2020a; Marx, 2018). Across-agent variation can be used to estimate within-agent
margins under restrictions on the heterogeneity in MTE frontiers: either conventional mono-
tonicity assumptions that impose MTE uniformity, or alternative restrictions that tractably
parameterize MTE heterogeneity (Arnold et al., 2020a).
     The remainder of this paper is organized as follows. Section 2 presents the setting and
defines the marginal outcome test. Section 3 formalizes how this test can detect racial bias,
and how canonical taste-based discrimination can be further detected. Section 4 links this
analysis to others in the literature. Section 5 discusses identification. Section 6 concludes.
   1
     As discussed below, this relates to results in Marx (2018), Canay et al. (2020), and Gelbach (2021).
   2
     This definition appears to align with the motivation for some recent empirical applications of the
marginal outcome test (e.g Arnold et al., 2018; see also Arnold et al., 2020b), though as Canay et al. (2020)
note these motivations are not always precisely formalized. I emphasize that the purpose of this paper is
not to promote any particular interpretation of the marginal outcome test as the intended one in a given
application. Rather, my goal is to provide a novel formalization that is in line with the canonical theory of
Becker (1957), Phelps (1972), Arrow (1973), and Aigner and Cain (1977); has potential policy consequences;
and requires minimal assumptions on the decision-making model and information set.




                                                     2
2       Setting
I consider a population of individuals i differentiated by an observable characteristic Ri 
{w, b}. For concreteness I refer to Ri as individual i's race (either "white" or "Black")
though it could of course index another characteristic such as age or sex. A decision-maker
(for concreteness, a "judge") observes individual race and some other information Si . Her
binary decision, or "treatment," is then given by Di  {0, 1}. The judge has some mandate
to base treatment decisions around their likely effect on an individual outcome Yi . Letting Yi1
and Yi0 denote individual i's potential outcome with and without treatment, these treatment
effects are written Yi = Yi1 - Yi0 . Throughout I assume that Yi is an adverse outcome which
the judge seeks to minimize. Otherwise Yi can be interpreted as the negation of her mandate.
    A concrete example of the setting is given by Arnold et al. (2018), who study pretrial
release decisions. Here Di = 1 indicates that the pretrial judge releases a defendant before
trial, with Di = 0 when a defendant is detained. The legal mandate of such judges is
typically narrow: to control the rate of pretrial misconduct (often defined as either a failure
to subsequently appear in court or the participation in further crimes), an adverse outcome
measured by a binary Yi . In this setting Yi is a binary latent variable. Since a detained
defendant cannot conduct pretrial misconduct, Yi0 = 0 for all i. Thus the effect of release is
simply a defendant's potential for misconduct if released: Yi = Yi1  {0, 1}. Another setting
with binary Yi is given by Feigenberg and Miller (2020), who study traffic stop decisions Di .
Here Yi = 1 indicates the failure to detect illegal contraband. Since contraband cannot be
detected among non-stopped drivers, we again have Yi0 = 0 and Yi = Yi1  {0, 1} indicates
latent contraband status. I use the binary Yi case to strengthen and build intuition for some
results, though the main analysis holds for Yi with generic support.3
    Throughout the paper I maintain a single assumption on the judge's decision-making
process: that it can be represented by a subjective ranking of individuals by their appropri-
ateness for treatment, with some individuals of each race marginal in the decision:

Assumption 1. There exists a random variable Ui such that

                                             Di = 1[Ui  0],                                              (1)

Ui | Ri is continuously distributed, and r  P r(Ui  0 | Ri = r)  (0, 1) for each r  {w, b}.

I refer to Ui as the judge's "ranking" of individuals. The existence of this latent variable is
without much conceptual loss, saying only that one could in principle order individuals in
    In the binary case it may be more natural to think of Yi as a latent state instead of a treatment effect.
    3

This is more in line with the earlier model-based approach (e.g. Knowles et al., 2001) and may be more
natural for some identification strategies (e.g. Grau and Vergara, 2020).



                                                     3
the population according to the judge's perception of their qualification for treatment (with
the threshold for qualification normalized to zero). Individuals with Ui > 0 are those the
judge thinks are unqualified for treatment while those with Ui  0 are deemed qualified.
The continuity condition implies that the judge is in principle indifferent to treating some
individuals of each race. Finally, Assumption 1 requires that some individuals of each race
are both treated and untreated, with race-specific treatment shares of w and b .
    We first use Assumption 1 to define the marginal outcome test:

Definition 1. The marginal outcome test is that of  = 0, where

                       = E [Yi | Ui = 0, Ri = w] - E [Yi | Ui = 0, Ri = b].                            (2)

The two terms of  give the expected treatment effects of the white or Black individuals
that the judge is indifferent to treating. The test asks whether these marginal effects differ.
    Applications of the marginal outcome test often draw on the theory of marginal treatment
effects (MTEs; Heckman and Vytlacil, 2005). Our first result establishes the equivalence of
 and the difference in two race-specific MTEs:

Lemma 1.  = µ(w , w) - µ(b , b), where

                                 µ(m, r) = E [Yi | Wi = m, Ri = r]                                     (3)

and Wi | Ri  U(0, 1) define a conditional MTE frontier: i.e., Di = 1[Wi  Ri ].

The proof to Lemma 1, as with other results in this paper, is given in the appendix. It defines
Wi by applying a simple conditional probability integral transform to Ui | Ri . Under some
assumptions the MTE frontiers µ(m, r), and thus  , may be identified from the observed
decisions of judges.4 I discuss such identification strategies in Section 5, but focus first on
what  = 0 could reveal about racially biased decision-making if it were known.


3       Main Results
To analyze  , I first define a notion of racial bias that contrasts with accurate statistical
discrimination. Such bias can arise either from the judge's racial preferences or from biased
"beliefs" (e.g. stereotypes). I then show how the marginal outcome test can detect this
notion of bias, and how other information on the race-specific MTE curves can furthermore
rule out canonical taste-based discrimination as a driver.
    4
     Importantly, here we allow Ui and thus µ(m, r) to be judge-specific. Differences in the rankings of
individuals across judges will generally violate the conventional monotonicity assumption from using judge
assignment to instrument for Di and measure MTEs. We return to this issue in the identification discussion.


                                                    4
3.1      Defining Racial Bias
To define racial bias, I first define accurate statistical discrimination. Statistical discrim-
ination models were originally proposed by Phelps (1972), Arrow (1973), and Aigner and
Cain (1977) to explain persistent differences in an employer's treatment of equally produc-
tive white and Black workers, in the absence of the preference-based racial bias considered
by Becker (1957). The statistical discrimination models show how such differences can arise
when employers act in a race-neutral way on accurate predictions of worker productivity,
given by the worker's observed race and a noisy "signal" of their productivity.
    Consistent with this theoretical literature, I define accurate statistical discrimination by
the existence of a race-inclusive information set that can rationalize the judge's ranking of
individuals for treatment as being based on an accurate prediction of her mandate Yi (in
place of labor market productivity). I define racial bias by the lack of such an information set:
that is, by the inability to rationalize the judge's ranking in terms of an accurate prediction
of individual treatment effects, based on race and some non-race signal Si :

Definition 2. The judge can be said to be engaged in accurate statistical discrimination if
there exists an Si such that Ui = E [Yi | Ri , Si ] - t for some t. If not, we say her decisions
exhibit racial bias.

Here t denotes a threshold the judge puts on the accurate predictions E [Yi | Ri , Si ] when
engaged in accurate statistical discrimination.5
    In the case of binary Yi , like the pretrial release setting of Arnold et al. (2018), accurate
statistical discrimination and racial bias have intuitive representations in terms of rational
expected utility maximization:

Lemma 2. If Yi  {0, 1} then a judge's decisions exhibit racial bias if and only if there is
no Si such that

                                Di  arg max E [U (Yi , D(Ri , Si )) | Ri , Si ] ,                                     (4)
                                            D(·)D


for some U (y, d) : {0, 1}2  R, where D is the set of decision rules D(r, s)  {0, 1} for
r  {w, b} and s in the support of Si .

This result follows from the fact that when Yi is binary it has only one moment (the mean)
that is relevant to the judge's mandate. The existence of a utility function U (y, d) that
rationalizes her behavior along with some signal Si is thus equivalent to her decisions being
    5
      Note that since a judge's decision-making process is only unique up to an increasing transformation of
Ui , racial bias more generally implies there is no Si , t, and increasing f (·) such that Ui = f (E [Yi | Ri , Si ] - t).
I abstract away from such f (·) to keep the notation and discussion as simple as possible.



                                                            5
based on an accurate mean prediction of E [Yi | Ri , Si ]. The appendix proof shows that a
similar result follows for general Yi if we restrict to the judge maximizing the expectation
of a utility function that is linear in y : that is, if we assume the judge is risk-neutral in
evaluating the effects of her decisions on the outcome.
    It is also natural to define a notion of taste-based discrimination, inspired by Becker
(1957). In this scenario the judge accurately predicts Yi according to some race-inclusive
information set, but uses race-specific thresholds for treatment reflecting racial preferences:

Definition 3. The judge can be said to be engaged in canonical taste-based discrimination
if there exists an Si such that Ui = E [Yi | Ri , Si ] - t(Ri ) for some t(w) = t(b).

Thus, a judge engaged in canonical taste-based discrimination has a decision rule of

                                 Di = 1[E [Yi | Ri , Si ]  t(Ri )],                            (5)

with different thresholds t(r) for white and Black individuals. We may think of t(w) >
t(b) as taste-based discrimination against Black individuals and t(b) > t(w) as taste-based
discrimination against white individuals. I show below that a judge who can be said to be
engaged in canonical taste-based discrimination cannot be said to be engaged in accurate
statistical discrimination, aligning Definitions 2 and 3 with the original theoretical division
of Becker (1957) and Aigner and Cain (1977).
    Like statistical discrimination, canonical taste-based discrimination has an intuitive rep-
resentation in terms of rational expected utility maximization when Yi is binary:

Lemma 3. If Yi  {0, 1} then a judge can be said to be engaged in canonical taste-based
discrimination if and only if there exists an Si and U (y, d, r) : {0, 1}2 × {w, b}  R such that
(U (0, 1, r) - U (0, 0, r)) / (U (1, 1, r) - U (0, 1, r)) depends on r and

                        Di  arg max E [U (Yi , D(Ri , Si ), Ri ) | Ri , Si ] ,                 (6)
                                  D(·)D


where D is as in Lemma 2.

Here we consider an expanded set of utility functions U (·) which depend explicitly on race.
In particular, we consider those which yield a differential utility cost to treatment when
Yi = 0 (i.e. U (0, 1, r) - U (0, 0, r)), relative to the utility cost of the undesired outcome when
Di = 1 (i.e. U (1, 1, r) - U (0, 1, r)), by race r. The appendix proof shows that this condition
can be interpreted as a racial difference in the relative utility cost of type-I error (failing to
treat an individual with Yi = 0) and type-II error (treating an individual with Yi = 1).
As with Lemma 2, the appendix shows that a similar result follows in the general case of
non-binary Yi whenever we restrict to utility functions that are linear in y .


                                                  6
    Lemmas 2 and 3 make clear that a categorization of judge behavior by accurate statistical
discrimination vs. taste-based discrimination is incomplete, due to the restriction of rational
beliefs and utility functions with limited arguments. I thus define a third residual category:

Definition 4. The judge can be said to have biased beliefs if she is neither engaged in
accurate statistical discrimination nor canonical taste-based discrimination.

While the classic theoretical analysis of Becker (1957), Phelps (1972), Arrow (1973), and
Aigner and Cain (1977) only considered agents acting on rational beliefs, in practice judges
may base their decisions on inaccurate beliefs or racial stereotypes (Bordalo et al., 2016).
The notion of biased beliefs captures this form of racial discrimination, as well as other
departures from accurate statistical or taste-based discrimination. For example, it could
capture a judge that strays from her mandate and bases decisions on an accurate prediction
of some other Y  ~i = Y  . Kleinberg et al. (2017b) label this "omitted payoff bias."
                       i
    Distinguishing between racial bias due to racial animus and biased beliefs is challenging,
as preferences and beliefs can manifest equivalently in a judge's decisions (Bohren et al.,
2020). To see this equivalence simply, consider a parametric decision-making model inspired
by Aigner and Cain (1977), in which Yi | Ri is normally distributed and the judge observes
both race and a noisy signal Si = Yi + i , with i | Ri , Yi  N (0,  2 ). In this case
E [Yi | Ri , Si ] = (1 - Ri )¯ µRi + Ri Si where µ ¯Ri = E [Yi | Ri ] and Ri  (0, 1) is the
slope coefficient from a regression of Yi on Si . A judge engaging in canonical taste-based
discrimination will thus have a decision rule of Di = 1[(1 - Ri )¯µRi + Ri Si  t(Ri )] for some
t(w) = t(b). But an equivalent decision rule can be obtained from a judge with biased beliefs.
For example a judge with a prior belief that E [Yi | Ri ] in fact equals µ  ~Ri = µ ¯Ri - 1t-
                                                                                            (Ri )
                                                                                              Ri
                                                                                                  ,
but who observes the same signal and otherwise understands the statistical environment, will
have an identical decision rule when attempting to statistically discriminate with a threshold
of t = 0. Thus, it is impossible here to distinguish between a judge exhibiting racial bias
because of racial tastes or inaccurate beliefs by her behavior alone: i.e., by her ranking Ui .
It is further unclear at this stage whether these judges can be distinguished from a judge
engaged in accurate statistical discrimination, and if so by what information. I next show
how the marginal outcome test answers this question.


3.2    Interpreting Marginal Effects
I now present two results relating the marginal outcome test to the previous definitions.

Proposition 1. If the judge is engaged in canonical taste-based discrimination then  = 0.

Proposition 2. If  = 0 then the judge's decisions exhibit racial bias.


                                                7
Proposition 1 shows that a judge who accurately predicts Yi but places different thresholds
on these predictions by race (as in Becker (1957)) will "fail" the outcome test, in that her
marginal treatment effects will differ by race. Proposition 2 shows instead that a failure of
the test implies a lack of accurate race-neutral decision-making (as in Phelps (1972), Ar-
row (1973), and Aigner and Cain (1977)). In other words, Proposition 2 shows that the
marginal outcome test can reject the null hypothesis of accurate statistical discrimination,
while Proposition 1 shows that the alternative hypothesis of canonical taste-based discrimi-
nation can drive such rejections. That Proposition 2 is not the strict converse of Proposition
1 reflects the fact that test rejections can also arise from biased beliefs.
    The proofs of both propositions are simple, following just from the law of iterated expec-
tations. For Proposition 1, we have under canonical taste-based discrimination

         E [Yi | Ui = 0, Ri ] = E [Yi | E [Yi | Ri , Si ] = t(Ri ), Ri ]
                              = E [E [Yi | Ri , Si ] | E [Yi | Ri , Si ] = t(Ri ), Ri ] = t(Ri ),   (7)

showing that the marginal outcome test yields  = t(w) - t(b) = 0. In particular, canonical
taste-based discrimination against Black (white) defendants manifests as  > 0 ( < 0). The
proof to Proposition 2 similarly follows by showing that accurate statistical discrimination
implies  = 0. Note that together Propositions 1 and 2 imply that the decisions of a judge
engaged in canonical taste-based discrimination exhibit racial bias, as promised above.
    In the binary Yi case, Lemma 2 and Proposition 2 show that the marginal outcome test
can reject that a judge's decisions are derived from her optimizing some expected race-neutral
utility function of misconduct outcomes and treatment U (y, d), given some race-inclusive
information set (Ri , Si ). That is, she is either acting rationally according to a race-specific
utility function U (y, d, r) as in Lemma 3, which causes  = 0 by Proposition 1, or she has
biased beliefs. As in the general case, biased beliefs could mean a failure to optimize her
intended mandate of Yi because of inaccurate predictions or because she predicting some
other outcome that is not her mandate (i.e. omitted payoff bias). As the simple normal-
signal example in Section 3.1 shows, it is generally difficult to distinguish between bias due
to tastes and beliefs, and the marginal outcome test is correspondingly uninformative.
    I next show that additional information on the race-specific marginal treatment effects
frontiers allows a more nuanced analysis of racial bias:
Proposition 3. There exists an Si such that Ui = E [Yi | Ri , Si ] - t(Ri ) for some {t(w), t(b)}
if and only if µ(m, r) is strictly increasing in m for each r  {w, b}.
This result shows that the slope of the MTE frontiers determine whether or not a judge's
behavior can be rationalized by accurate beliefs (either statistical or taste-based discrimina-
tion). Intuitively, when the judge is acting on an accurate prediction of Yi , perhaps with


                                                   8
        Table 1: Possible Characterizations of Judge Behavior from Marginal Effects
                                                         Marginal Outcome Test
                                                   Pass ( = 0)          Fail ( = 0)
                         Increasing in m      Accurate Stat. Disc.        Canonical T.-B. Disc.
        MTE Slopes
         µ(m, r)
                         Non-Increasing           Biased Beliefs              Biased Beliefs

Notes: This table illustrates possible descriptions of judge decision-making, depending on whether or not
the marginal outcome test passes (columns) and whether or not both race-specific MTE frontiers are strictly
increasing (rows). Underlined descriptions indicate forms of racial bias.

race-specific thresholds, her race-specific MTEs must be increasing in the share of treated
individuals. Proposition 3 shows that the converse also holds: when the race-specific MTE
frontiers µ(m, r) are increasing in the treated share m, there exists an information set {Ri , Si }
that can rationalize the judge as acting on accurate predictions of Yi .6 To my knowledge
this converse is novel to the recent literature on interpreting such tests, though Marx (2018),
Canay et al. (2020), and Gelbach (2021) prove related results on how canonical taste-based
discrimination yields monotone MTE functions.7
    Table 1 summarizes the possible characterizations of judge behavior from knowledge of
both the slope of µ(m, r) and  . One consequence of Proposition 3 is that when µ(m, r)
is increasing and the marginal outcome test "passes" (i.e.  = 0) we can say the judge is
engaged in accurate statistical discrimination (t(w) = t(b)). A second consequence is that
when µ(m, r) is increasing and the marginal outcome test "fails" (i.e.  = 0) we can say
the judge is engaged in canonical taste-based discrimination (t(w) = t(b)). A non-increasing
MTE frontier rules out these explanations, implying biased beliefs regardless of  . This
could again either imply inaccurate predictions of Yi or omitted payoff bias.
    It is worth emphasizing that these conclusions of accurate statistical discrimination,
canonical taste-based discrimination, and biased beliefs reflect what can be said about the
judge's behavior from her actions, and not necessarily her "true" or intended behavior. For
example, a judge who fails to accurately predict Yi can still base her decisions on a rank-
ing Ui that yields a strictly increasing MTE frontier because of some offsetting preferences
among individuals of each race. If she equalizes marginal outcomes despite this combination
of inaccurate prediction and omitted payoffs (i.e.  = 0) we would not be able to distinguish
her from a judge who is accurately statistically discriminating absent further information.
   6
      The requirement that µ(m, r) be strictly increasing in m reflects the requirement that Ui | Ri be
continuously distributed. It can be shown by a straightforward extension of Proposition 3 that weakly
increasing µ(m, r) are equivalent to the existence of an Si with Ui = E [Yi | Ri , Si ] - t(Ri ) - i for some
independent and continuously distributed i that breaks indifferences in E [Yi | Ri , Si ] - t(Ri ).
    7
      In the setting of traffic stops, Marx (2018) shows that unconditional "hit rate" functions increase
concavely with search probabilities under canonical taste-based discrimination. Canay et al. (2020) and
Gelbach (2021) derive similar results and show how they imply monotone MTE functions.


                                                     9
Similarly, if her inaccurate ranking fails to equalize marginal outcomes ( = 0) we would
not be able to say that she is not engaged in canonical taste-based discrimination. An "as-
if" characterization of behavior is inherent to the exercise of inferring bias from behavior,
since preferences and beliefs are typically difficult to disentangle. Recall again the simple
normal-signal model of Section 3.1, where canonical taste-based discrimination and biased
beliefs are indistinguishable except by knowing the judge's true intentions.8
    Despite not knowing a judge's true intentions, the ability to rule out accurate statistical
discrimination and give an "as-if" characterization of behavior can be valuable in practice.
In the pretrial release setting, the finding of racial bias (by  = 0) may call for policy reforms
that attempt to align judge behavior more closely with accurate statistical discrimination:
for example, by providing more accurate algorithmic predictions of pretrial misconduct (e.g.
Kleinberg et al., 2017b) or some form of implicit bias training (e.g. Morris, 2020). The
finding of biased beliefs (by decreasing MTE frontiers) is perhaps even more consequential,
as it suggests judges may be badly misinterpreting their mandate or mispredicting outcomes.
    To summarize, we have seen a general interpretation of marginal outcome tests in terms
of policy-relevant concepts linked to classic economic models of racial bias and statisti-
cal discrimination. I emphasize that this interpretation requires no assumptions on judge
decision-making beyond the existence of some continuous ranking (Assumption 1). I next
contrast this interpretation with the analysis of Canay et al. (2020), who propose a behavioral
restriction necessary to interpret marginal outcome tests in terms of a different definition of
bias. I further relate this section's definition with others in the recent literature.


4       Relationships to Other Analyses
This section first contrasts the previous analysis with the alternative definition of racial
bias in Canay et al. (2020)--hereafter CMM--and the restriction on decision-making which
they claim is necessary to restore the "validity" of marginal outcome tests. I then discuss
connections to other definitions from the recent economics and computer science literatures.


4.1     Canay et al. (2020)
CMM consider a model of judge-decision making that can be written

                                   Di = 1[(Ri , Vi )   (Ri , Vi )],                                  (8)
    8
     Bohren et al. (2020) discuss how biased beliefs and animus can be potentially distinguished through
an experimental information provision (see also Bottan and Perez-Truglia (2020)). Such interventions may
change the judge's ranking Ui , and are thus outside the scope of this paper's framework which treats the
distribution of Ui as fixed.



                                                   10
where (Ri , Vi ) = E [Yi | Ri , Vi ] is interpreted as an accurate prediction of Yi , which CMM
refer to as the "cost function." The corresponding "benefit function"  (Ri , Vi ) captures the
residual determinants of the judge's decision, and is allowed to depend on both race Ri
and what CMM refer to as "non-race characteristics" Vi .9 In terms of the general model
presented in Section 2, the CMM model is nested by Ui = (Ri , Vi ) -  (Ri , Vi ).
    CMM use the benefit function to define a different notion of racial bias than in Definition
2. They state that the judge is biased against Black individuals if  (b, v ) <  (w, v ) for all v
in the support of Vi , is biased against white individuals if  (b, v ) >  (w, v ) for all v in the
support of Vi , and is racially unbiased if  (w, v ) =  (b, v ) for all v in the support of Vi .10
They then show that the marginal outcome test is generally uninformative for this definition
of bias, except under a restriction on the benefit function which removes Vi : i.e.

                                        Di = 1[(Ri , Vi )   (Ri )],                                           (9)

which has the form of an extended Roy model (Heckman and Vytlacil, 2007; D'Haultfoeuille
and Maurel, 2013).11 CMM thus conclude that in order to interpret the marginal outcome
test in terms of racial bias, researchers must justify the extended Roy model as a behavioral
restriction--a model which they view as very restrictive.
    It is first worth noting that, in contrast with the Section 3 analysis, the CMM bias
definition generally requires the information set {Ri , Vi } to be specified. Many pairs of Vi
and  (r, v ) functions will generally yield equivalent decision rules, so a definition of bias based
on  (r, v ) is only unambiguous when Vi is defined. An arguable strength of the Section 3
definition, which instead considers the existence of any Vi rationalizing decisions by accurate
statistical discrimination, is that such specification is unnecessary.12
    To see why the specification of Vi matters for the CMM analysis, consider a simple
example in which a judge engages in canonical taste-based discrimination, with her decisions
given by Di = 1[E [Yi | Ri , Si ] < t(Ri )] for some signal Si and thresholds t(w) > t(b).
Clearly, if Vi = Si , the CMM definition aligns with Definition 2 in saying that the judge is
racially biased against Black individuals. But an identical set of decisions are generated by
    9
       CMM index the benefit function by the identity of the judge (see their Equation (1)). I suppress this
indexing since, as in CMM's conceptual analysis (their Section 3), I here consider a single judge.
    10
       Unlike the Section 3 typology this definition leaves an omitted category, of judges where  (w, v ) and
 (b, v ) are neither always higher than, lower than, or equal to each other.
    11
       The extended Roy model is not the only restriction that CMM consider to restore "logical validity" of
the marginal outcome test. However they note that the alternative restriction (that the cost function does
not depend on race) is likely harder to justify in practice, since race is likely to predict Yi .
    12
       Another strength of the Section 3 analysis is that it allows for evaluations of bias along multiple lines:
i.e., a marginal outcome test that splits the sample by race can be interpreted alongside a test that splits by an
individual's sex. In contrast the extended Roy model restriction of CMM cannot hold for both characteristics
jointly when sex is included in Vi , making at least one of these tests uninformative by their analysis.




                                                       11
a model in which the judge has a broader information set of Vi = {Si , Ti } for some other
signal Ti and sets  (Ri , Vi ) appropriately: i.e.,

                Di = 1[E [Yi | Ri , Vi ] < t(Ri ) + E [Yi | Ri , Vi ] - E [Yi | Ri , Si ]].        (10)
                            (Ri ,Vi )                          (Ri ,Vi )


With this rationalization, of the same decisions, we can no longer say the judge is biased under
CMM's definition, since  (r, v ) need not always be larger for white (or Black) individuals.
     Specifying Vi is also important for CMM's claim on the restrictiveness of the extended
Roy model. Indeed, the above Proposition 3 shows that whenever the race-specific MTE
curves are strictly increasing there exists a Vi such that decisions have an extended Roy
model representation. Thus, when Vi is unspecified, the CMM restriction can be imposed
without loss to the decision-making process in this case. Our two definitions of bias, and
two conclusions on the marginal outcome tests' ability to detect bias, would then agree.
     While taking at least a conceptual stand on the judge's information set Vi is inherent to
the CMM analysis, it may be challenging or undesirable. The challenge comes from the fact
that in practice decision-makers may combine a wide range of objective and subjective infor-
mation that can be difficult to specify in Vi , even conceptually. In the pretrial example, one
could imagine collecting all objective (not necessarily observed) measures of defendant and
case characteristics--such as demographics, charge type, and previous criminal activity--in
Vi . This fixes the  (r, v ) functions, and thus the CMM bias definition, as residuals from
the objective prediction (Ri , Vi ) = E [Yi | Ri , Vi ], in essence benchmarking the judge's
behavior to an objective (perhaps unmeasured) risk score. But in practice pretrial judges
may also base decisions on face-to-face interviews with defendants, and vary in what "soft"
information or signals are taken from such interactions. It can be difficult to conceptualize
a well-defined notion of bias, from a well-defined Vi , in such cases.
     Moreover, even when it is possible to conceptualize collecting all available information in
Vi , a bias definition based on this set may be unsatisfying when judges vary in their skill at
incorporating signals. A given pretrial judge may, for example, be highly skilled at inferring
misconduct potential from a defendant's demeanor, while another judge chooses to rely
more on the "hard" information in a defendant's criminal record.13 To see how such variation
complicates the CMM analysis, suppose we are able to put (along with all defendant and case
characteristics) a "complete" record of objective information from pretrial interviews in Vi ,
including sophisticated data on, e.g., a defendant's demeanor and ability to answer standard
questions. But suppose a judge is only partially attentive to this rich data, observing a signal
Si which is strictly less informative: i.e., Vi = {Si , Ti }, where Ti is the subset of information
  13
    Evidence for such variation in predictive skill has recently been documented in the pretrial setting
(Arnold et al., 2020a) and in medical testing decisions (Chan et al., 2020).


                                                    12
for individual i that is missed by the judge (such as the answers to questions she forgets to
ask, or elements of the defendant's demeanor she overlooks). Suppose the judge uses this
signal to engage in accurate statistical discrimination, forming an accurate but inefficient
posterior of E [Yi | Ri , Si ] = E [Yi | Ri , Vi ]. Her otherwise race-neutral decision rule is then

   Di = 1[E [Yi | Ri , Si ]  t] = 1[E [Yi | Ri , Vi ]  t + E [Yi | Ri , Vi ] - E [Yi | Ri , Si ]],   (11)
                                         (Ri ,Vi )                       (Ri ,Vi )


with the final expression having the form of CMM's representation (8). This decision-rule
generally does not satisfy the extended Roy model restriction, since  (Ri , Vi ) will generally
vary nontrivially with Vi . The CMM analysis will thus conclude the marginal outcome
test is uninformative of the judge's bias, even though she is engaged in classic statistical
discrimination. In contrast, the Section 3 analysis would say the marginal outcome test
"passes" in this scenario, with  = 0 indicating a lack of racial bias. This conclusion appears
warranted given the judge's accurate beliefs and race-neutral threshold t.
    In summary, there are several important differences between the Section 3 analysis of
marginal outcome tests and CMM's. The former does not require specification of the judge's
information set for bias to be well-defined, and for  to detect canonical taste-based dis-
crimination (in the sense of Becker (1957)). At the same time, the Section 3 interpretation
can "clear" an agent engaged in classic statistical discrimination (in the sense of Aigner
and Cain (1977)) from suspicions of bias, even when her skill at using an objective set of
available information is imperfect. Neither of these conclusions require the extended Roy
model restriction of CMM, which we have shown is without loss to impose when the judge's
information is unspecified and the race-specific MTE curves are increasing.


4.2    Unwarranted Disparity
One critique of marginal outcome tests, given the Section 3 analysis, is that they capture a
narrow form of racial discrimination. In particular, the kinds of accurate statistical discrimi-
nation which cause such tests to "pass" can be viewed as undesirable or even illegal in many
settings, including potentially the pretrial setting (Yang and Dobbie, 2020). Motivated by
this shortcoming, Arnold et al. (2020a) propose a broader measure of discrimination which
aligns with Aigner and Cain (1977) in capturing any "unwarranted" racial disparities in
treatment rates that cannot be justified by differences in an individual's "qualification" for
treatment (as given by their Yi ). Formally, they define unwarranted disparity as

                         = E [E [Di | Ri = w, Yi ] - E [Di | Ri = b, Yi ]],                          (12)




                                                     13
or the average treatment rate disparity of white and Black individuals with identical Yi .
Arnold et al. (2020a) show how this notion of discrimination can capture racial bias, defined
similarly to the Section 3 analysis, as well as accurate statistical discrimination.14
    Because it is based on a narrower measure of discrimination, a finding of no racial bias
(i.e.  = 0) need not imply the equal treatment of equally qualified individuals (i.e.  = 0).
Interestingly, however, the converse also holds: a finding of no unwarranted disparity need
not imply a lack of racial bias. This follows from a general trade-off between such "fairness"
notions and unbiased prediction in this kind of decision-making problem (Kleinberg et al.,
2017a). Some bias "at the margin" of treatment (as captured by  ) is generally required for
fair treatment "on average" (as captured by ).
    Feigenberg and Miller (2020) discuss a scenario in which the difference between a measure
like  and a measure like  is especially stark. In an analysis of Texas traffic stop data,
they find that the marginal outcome test passes despite significant unwarranted disparities
in state trooper stop rates between white and Black drivers. The reason for these disparities
appears to be that, conditional on observables, the typical trooper effectively searches drivers
at random but with minority drivers searched more. Here it is worth noting that while
marginal outcome tests cannot generally detect such unequal treatment, knowledge of the
race-specific MTE frontiers can: under random decision-making the µ(m, r) will be constant
over m and equal to the average treatment effect E [Yi | Ri = r].


4.3     Algorithmic Calibration
While the Section 3 analysis presumed a human decision-maker, its definition of bias has
a close link to the notion of "calibration" in the literature on algorithmic decision-making
(Barocas and Selbst, 2016; Kleinberg et al., 2017a; Chouldechova, 2017). This literature
typically considers decisions based on some statistical prediction of Yi , P (Xi ), from some
observed covariates Xi . For example, P (Xi ) may be generated by a machine learning algo-
rithm. Calibration bias is then defined by a racial disparity in prediction error,

                 (p) = E [Yi | P (Xi ) = p, Ri = w] - E [Yi | P (Xi ) = p, Ri = b],                       (13)

for some p (Obermeyer et al., 2019). It is immediate that this definition coincides with
the Section 3 definition of racial bias when treatment decisions are algorithmic: formally, if
Di = 1[P (Xi )  t] for some t then  = (t). A marginal outcome test applied to such an
algorithmic decision-rule therefore reveals calibration bias.
    An important feature of investigations of algorithmic bias is that while the ranking P (Xi )
  14
     This  is also closely related to notions of algorithmic discrimination in the computer science literature,
in particular "conditional procedure accuracy equality" (Berk et al., 2018).



                                                      14
is known, and may even be under the researcher's control, it need not coincide with an ac-
curate prediction E [Yi | Xi ]. This is because the treatment effects Yi need not be observed
for some or all individuals, a fundamental challenge that here Lakkaraju et al. (2017) term
the "selective labels problem." This feature highlights the need for allowing for what Sec-
tion 3 calls biased "beliefs" in testing for calibration bias, although this terminology is less
natural for algorithmic decisions. For especially severe cases of the selective labels problem,
calibration bias can manifest with non-increasing race-specific MTE frontiers.15


5        Identification Strategies
I lastly turn to the question of how marginal outcome tests can be conducted in prac-
tice. Lemma 2 shows that identification of  follows from the identification of judge- and
race-specific MTE curves, at least near the judge's treatment cutoff. The recent empirical
literature has devised several strategies leveraging different sources of variation. In some
cases, these strategies permit full identification of the MTE frontiers and thus the more
nuanced analysis of behavior summarized in Table 1.
    It is first worth considering an experimental ideal, in which a judge is induced to increase
or decrease her treatment rate among a random set of both white and Black individuals.
By comparing the "treatment" and "control" groups within each race, one may obtain an
experimental estimate of race-specific treatment effects near the judge's cutoff. For small
changes these effects can be interpreted as the two marginal treatment effects that enter  :
the finding of a larger effect among white individuals relative to Black individuals would be
consistent, for example, with canonical taste-based discrimination in inaccurate stereotypes
favoring white individuals, while the failure to reject  = 0 would be consistent with accurate
statistical discrimination. Larger changes may require parametric assumptions to interpret
average effects in terms of marginal effects, but may trace out larger portions of the MTE
curves that can be used to diagnose the extent of biased beliefs. Multiple treatment groups
could be contrasted with a single control group within each race to fit polynomial race-
specific MTE curves, for example. Per Proposition 3, one cannot rule out that the judge is
acting on accurate predictions of Yi when the estimated curves are increasing.
    In practice, where the scope for such experimentation is limited, researchers may lever-
age quasi-experimental or observational variation in judge- and race-specific treatment rates.
Feigenberg and Miller (2020), for example, use the variation in race-specific search rates for
a given state trooper to estimate within-trooper MTE frontiers and study issues related to
    15
     Kleinberg et al. (2017b) and Arnold et al. (2021) discuss quasi-experimental solutions to the selective
labels problem in the pretrial setting. The former show how algorithms can be used to improve human
decision-making in spite of this problem, while the latter show how the problem can be overcome to estimate
measures like  and (p).


                                                    15
racial bias. They show that this variation is largely idiosyncratic with respect to motorist
characteristics, as would be guaranteed in an idealized experimental manipulation of trooper
search rates. Grau and Vergara (2020) instead propose an observational approach to identi-
fying marginal outcomes, which can in principle be conducted for an individual judge.16
    When it is difficult to justify using within-judge treatment rate variation, a natural
quasi-experimental alternative is to leverage exogenous variation across judges. Arnold et al.
(2018) introduce this approach in the pretrial setting, where judges are plausibly as-good-
as-randomly assigned to cases after adjusting for courtroom and time fixed effects. The
key assumption they invoke to leverage this across-judge variation is conventional MTE
monotonicity, which restricts the race-specific MTE curves to be common across judges.
Under this assumption the different as-good-as-randomly assigned judges trace out a single
race-specific MTE frontier, which can be used to both detect racial bias and probe the extent
of biased beliefs.17 A conceptually similar approach is taken by Marx (2018) in the setting
of police search. Feigenberg and Miller (2020) show that an analysis leveraging the quasi-
random assignment of state troopers yields similar estimates as their within-trooper analysis,
building confidence in the common MTE assumption in their setting.
    In some settings, however, the assumption of common MTE frontiers may be untenable.
In terms of the behavioral models in Section 3, this assumption generally restricts different
judges to act on a common prediction of Yi , given common signals Si . In reality judges are
likely to vary in their predictive skill, inducing different judge-specific MTE frontiers that
violate the monotonicity assumption used by Arnold et al. (2018) and Marx (2018).18
    A solution to this challenge is given by Arnold et al. (2020a), who develop a hierarchical
MTE model to estimate racial discrimination and bias from the as-good-as-random assign-
ment of pretrial judges. The model specifies race-specific distributions of signals, and thus
distributions of MTE curves, across judges, in violation of conventional MTE monotonicity;
Arnold et al. (2020a) show that this distribution can be estimated from certain reduced-form
moments. Notably, in contrast to the conventional MTE approach of Arnold et al. (2018),
the Arnold et al. (2020a) approach uses parametric restrictions. This reflects the general
fact that other assumptions are required once the uniformity condition of monotonicity is
relaxed.19 In their setting Arnold et al. (2020a) show that uniformity is an especially unap-
   16
      Grau and Vergara (2020) also discuss how their approach can be used to probe omitted payoff bias,
which they refer to as "incentive-driven prejudice."
   17
      In addition to monotonicity, Arnold et al. (2018) discuss assumptions that are needed to overcome the
core inframarginality problem of only observing a finite number of judges with discrete differences in race-
specific treatment rates. I note that this problem exists in any evaluation of marginal effects from discrete
treatment rate interventions, including the experimental ideal.
   18
      Marx (2018) considers a model where judges can act on different but equally informative signals. This
yields a common MTE frontier despite a violation of strict monotonicity (where judges observe identical
signals). See Chan et al. (2020) and Feigenberg and Miller (2020) for discussions of similar assumptions.
   19
      While Arnold et al. (2020a) specify their model in terms of accurate statistical discrimination and taste-


                                                      16
pealing restriction, as there appears to be sizable variation in judge predictive skill.
    Overall, the recent empirical literature leveraging quasi-experimental variation to con-
duct marginal outcome tests (and related exercises) is nascent and only represents some of
the possible identification strategies. Ways to relax the parametric structure of Arnold et al.
(2020a) and estimate racial bias from as-good-as-random judge assignment without a clas-
sic MTE monotonicity assumption seem worth future study. Settings where within-judge
variation can be credibly used to avoid such across-judge restrictions also appear valuable.


6     Conclusion
Since Becker (1957), economists have long theorized about the ways in which racial bi-
ases can differentially affect the outcomes of white and Black individuals at the margin of
treatment. A recent empirical literature has proposed using quasi-experimental variation to
estimate such effects, drawing on the tractable MTE framework and avoiding the specifica-
tion of complete decision-making models. It is not always clear, however, what this approach
generally reveals about racial bias.
    This paper has presented a formal definition of racial bias which can be revealed by the
marginal outcome test: the lack of accurate statistical discrimination, which Phelps (1972),
Arrow (1973), and Aigner and Cain (1977) derived to contrast with Becker's theory of taste-
based discrimination. We have seen how this definition encompasses different forms of bias,
from canonical taste-based discrimination to inaccurate beliefs or stereotypes, and how in
some cases these explanations can be distinguished by knowing complete MTE frontiers.
This analysis contrasts with the alternative bias definition in Canay et al. (2020), which
leads to a more pessimistic view of marginal outcome tests. The notion of bias which I
show marginal outcome tests reveal also contrasts with other recent definitions of discrimi-
nation, while aligning with a notion of algorithmic bias from the computer science literature.
Finally, we have seen some ways that marginal outcome tests have been conducted in the
recent empirical literature, under different identifying assumptions. More work is needed on
developing tractable restrictions on judge MTE curves which can reveal racial bias while also
allowing for heterogeneity in judge predictive skill.




based discrimination, they note that its parameterization also allows judges to have biased beliefs (similar
to the simple normal-signal example in Section 3). In practice they find upward-sloping MTE frontiers.


                                                    17
References
Aigner, D. J. and G. G. Cain (1977): "Statistical Theories of Discrimination in Labor
  Markets," Industrial and Labor Relations Review, 30, 175­187.
Antonovics, K. and B. Knight (2009): "A New Look at Racial Profiling: Evidence
 from the Boston Police Department," Review of Economics and Statistics, 91, 163­177.
Anwar, S., P. Bayer, and R. Hjalmarsson (2012): "The Impact of Jury Race in
 Criminal Trials," Quarterly Journal of Economics, 127, 1017­1055.
Arnold, D., W. Dobbie, and P. Hull (2020a): "Measuring Racial Discrimination in
 Bail Decisions," NBER Working Paper No. 26999.
------ (2021): "Measuring Racial Discrimination in Algorithms," American Economic As-
  sociation: Papers & Proceedings.
Arnold, D., W. Dobbie, and C. S. Yang (2018): "Racial Bias in Bail Decisions,"
 Quarterly Journal of Economics, 133, 1885­1932.
------ (2020b): "Comment on Canay, Mogstad, and Mountjoy (2020)," Mimeo.
Arrow, K. J. (1973): "The Theory of Discrimination," in Discrimination in Labor Markets,
 ed. by O. Ashenfelter and A. Rees, Princeton University Press, 3­33.
Barocas, S. and A. D. Selbst (2016): "Big Data's Disparate Impact," California Law
 Review, 104, 671.
Becker, G. S. (1957): The Economics of Discrimination, University of Chicago Press.
Berk, R., H. Heidari, S. Jabbari, M. Kearns, and A. Roth (2018): "Fairness
 in Criminal Justice Risk Assessments: The State of the Art," Sociological Methods &
 Research, 1­42.
Bohren, J. A., K. Haggag, A. Imas, and D. G. Pope (2020): "Inaccurate Statistical
 Discrimination: An Identification Problem," NBER Working Paper No. 25935.
Bordalo, P., K. Coffman, N. Gennaioli, and A. Shleifer (2016): "Stereotypes,"
 The Quarterly Journal of Economics, 131, 1753­1794.
Bottan, N. L. and R. Perez-Truglia (2020): "Betting on the House: Subjective
 Expectations and Market Choices," NBER Working Paper No. 27412.
Canay, I. A., M. Mogstad, and J. Mountjoy (2020): "On the Use of Outcome Tests
 for Detecting Bias in Decision Making," NBER Working Paper No. 27802.
Chan, D., M. Gentzkow, and C. Yu (2020): "Selection with Variation in Diagnostic
 Skill: Evidence from Radiologists," NBER Working Paper No. 26467.
Chouldechova, A. (2017): "Fair Prediction with Disparate Impact: A Study of Bias in
 Recidivism Prediction Instruments," Big Data, 5, 153­163.
D'Haultfoeuille, X. and A. Maurel (2013): "Inference on an Extended Roy Model,
 with an Application to Schooling Decisions in France," Journal of Econometrics, 174,
 95­106.


                                          18
Feigenberg, B. and C. Miller (2020): "Racial Disparities in Motor Vehicle Searches
 Cannot Be Justified By Efficiency," Unpublished Working Paper.
Gelbach, J. B. (2021): "Testing Economic Models of Discrimination in Criminal Justice,"
 Unpublished Working Paper.
Grau, N. and D. Vergara (2020): "A Simple Test for Prejudice in Decision Processes:
 The Prediction-Based Outcome Test," Unpublished Working Paper.
Heckman, J. J. and E. Vytlacil (2005): "Structural Equations, Treatment Effects, and
 Econometric Policy Evaluation," Econometrica, 73, 669­738.
------ (2007): "Econometric Evaluation of Social Programs, Part II: Using the Marginal
  Treatment Effect to Organize Alternative Econometric Estimators, to Evaluate Social Pro-
  grams, and to Forecast their Effects in New Environments," in Handbook of Econometrics,
  ed. by J. J. Heckman and E. Leamer, Elsevier, 4875­5143.
Kleinberg, J., 20020503, S. Mullainathan, and M. Raghavan (2017a): "Inherent
 Trade-Offs in Algorithmic Fairness," Proceedings of Innovations in Theoretical Computer
 Science, 43:1­43:23.
Kleinberg, J., 20020603, H. Lakkaraju, J. Leskovec, J. Ludwig, and S. Mul-
 lainathan (2017b): "Human Decisions and Machine Predictions," The Quarterly Journal
 of Economics, 133, 237­293.
Knowles, J., N. Persico, and P. Todd (2001): "Racial Bias in Motor Vehicle Searches:
 Theory and Evidence," Journal of Political Economy, 109, 203­229.
Lakkaraju, H., J. Kleinberg, J. Leskovec, J. Ludwig, and S. Mullainathan
 (2017): "The Selective Labels Problem: Evaluating Algorithmic Predictions in the Pres-
 ence of Unobservables," Proceedings of the 23rd ACM SIGKDD International Conference
 on Knowledge Discovery and Data Mining, 275­284.
Marx, P. (2018): "An Absolute Test of Racial Prejudice," Unpublished Working Paper.
Morris, A. (2020): "Confronting Implicit Bias: Texas Judges Would Get Annual Training
 Under New Resolution," Texas Lawyer, https://bit.ly/36REEhI.
Obermeyer, Z., B. Powers, C. Vogeli, and S. Mullainathan (2019): "Dissecting
 Racial Bias in an Algorithm Used to Manage the Health of Populations," Science, 366,
 447­453.
Persico, N. and P. Todd (2006): "Generalizing the Hit Rate Tests for Racial Bias in
 Law Enforcement, with an Application to Vehicle Searches in Wichita," Economic Journal,
 116, F351­F367.
Phelps, E. S. (1972): "The Statistical Theory of Racism and Sexism," American Economic
 Review, 62, 659­661.
Yang, C. and W. Dobbie (2020): "Equal Protection Under Algorithms: A New Statistical
 and Legal Framework," Michigan Law Review, 119, 291­396.




                                           19
A     Appendix Proofs
A.1     Lemma 1
Let FU |R (u, r) denote the cumulative distribution function for Ui | (Ri = r). Then

                  Di = 1[FU |R (Ui , Ri )  FU |R (0, Ri )]  1[Wi  FU |R (0, Ri )]        (A1)

where Wi | Ri  U(0, 1). This defines the MTE frontiers µ(m, r). Furthermore,

                            FU |R (0, r) = P r(Di = 1 | Ri = r) = r ,                    (A2)

so E [Yi | Ui = 0, Ri = r] = E [Yi | Wi = r , Ri = r] = µ(r , r).


A.2     Lemma 2
First consider an arbitrary U (·) and Si . In the binary case, where Yi = Di Yi , we have for
any decision rule Di ,

              U (Yi , Di ) = U (1, 1)Yi Di + U (0, 1)(1 - Yi )Di + U (0, 0)(1 - Di )
                         = Yi Di - Di + ,                                                (A3)

where  = U (1, 1) - U (0, 1),  = U (0, 0) - U (0, 1), and  = U (0, 0). Therefore the optimiza-
tion in Equation (4) can be written

                       max D(Ri , Si )E [Yi | Ri , Si ] - D(Ri , Si ) + ,                (A4)
                      D(·)D


It is clear that solutions to this problem are given by

                                   Di = 1[E [Yi | Ri , Si ]  t],                         (A5)

where t = /. Thus, if a judge's decisions can be written as in Equation (4) for some U (·)
and Si , she can be said to be engaged in accurate statistical discrimination. Conversely, if
a judge's decisions can be written as in Equation (A5) for some Si and t, there exist utility
functions U (·) such that her decisions can be represented by Equation (4).
    Note that this equivalence means the maintained Assumption 1 implicitly restricts the
set of U (·) considered in Lemma 2: for the judge's decisions to be non-degenerate, we at
minimum require (U (0, 0) - U (0, 1))/(U (1, 1) - U (0, 1))  (0, 1). Note also that the same
steps can be used to show the equivalence between accurate statistical discrimination and



                                                20
solutions to Equation (4) in the general case of non-binary Yi , when restricting to U (y, d)
that are linear in y . Specifically, if U (y, d) = y + U0 (d) then

  U (Yi , Di ) = Yi1 Di + U0 (1)Di + Yi0 (1 - Di ) + U0 (0)(1 - Di ) = Yi Di - Di + , (A6)

as before, except now  = U0 (0) - U0 (1) and  = Yi0 + U0 (0).


A.3     Lemma 3
The proof follows similarly to that of Lemma 2. For arbitrary U (·) and any decision rule Di

        U (Yi , Di , Ri ) = U (1, 1, Ri )Yi Di + U (0, 1, Ri )(1 - Yi )Di + U (0, 0, Ri )(1 - Di )
                       = (Ri )Yi Di -  (Ri )Di + (Ri ),                                              (A7)

where (Ri ) = U (1, 1, Ri ) - U (0, 1, Ri ),  = U (0, 0, Ri ) - U (0, 1, Ri ), and  = U (0, 0, Ri ).
Therefore the optimization in Equation (6) can be written

                  max (Ri )D(Ri , Si )E [Yi | Ri , Si ] -  (Ri )D(Ri , Si ) + (Ri ),                 (A8)
                 D(·)D


It is clear that solutions to this problem are given by

                                   Di = 1[E [Yi | Ri , Si ]  t(Ri )],                                (A9)

where t(Ri ) =  (Ri )/(Ri ). Thus, if a judge's decisions can be written as in Equation (6) for
some U (·) and Si with  (w)/(w) =  (b)/(b), she can be said to be engaged in canonical
taste-based discrimination. Conversely, if a judge's decisions can be written as in (A9) for
some Si and t(w)(b), there exist utility functions U (·) with  (w)/(w) =  (b)/(b) such that
her decisions can be represented by Equation (6).
    As in the proof to Lemma 2, this equivalence means the maintained Assumption 1 implic-
itly restricts the set of U (·) considered in Lemma 3. Also that the same steps can be used to
show the equivalence between accurate statistical discrimination and solutions to Equation
(4) in the general case of non-binary Yi , when restricting to linear U (y, d, r) = (r)y +U0 (d, r).
    Finally, I show that the condition of  (w)/(w) =  (b)/(b) has an interpretation in
terms of preferences over type-I and type-II error rates in the binary Yi case. Note that
without loss we can normalize one of the utility levels from the four combinations of (Yi , Di )
to zero within each race. By normalizing U (0, 0, r) = 0 it can be seen that  (r)/(r) gives
the ratio of utility from failing to treat an individual without the adverse outcome, U (0, 0, r),
(i.e. type-I error) to utility from treating an individual with the adverse outcome, U (1, 1, r).



                                                   21
A.4     Proposition 1
A full proof is given in the main text: see Equation (7).


A.5     Proposition 2
The proof is by contradiction. Suppose an Si exists such that Ui = E [Yi | Ri , Si ] - t for
some t. Then following Equation (7) we have by the law of iterated expectations

                E [Yi | Ui = 0, Ri ] = E [Yi | E [Yi | Ri , Si ] = t, Ri ]]
                                     = E [E [Yi | Ri , Si ] | E [Yi | Ri , Si ] = t, Ri ]]
                                     = t,                                                    (A10)

so  = E [Yi | Ui = 0, Ri = w] - E [Yi | Ui = 0, Ri = b] = t - t = 0.


A.6     Proposition 3
First suppose there exists an Si such that Ui = E [Yi | Ri , Si ] - t(Ri ) for some t(r). Then

                                                               -1
              µ(m, r) = E [Yi | E [Yi | Ri = r, Si ] - t(r) = FU |R (m, r ), Ri = r ]        (A11)

        -1
where FU |R (·) denotes the inverse of the distribution function defined in the proof to Lemma
1. By the law of iterated expectations, as in Equation (7),

                                              -1
                                   µ(m, r) = FU |R (m, r ) + t(r )                           (A12)

which is strictly increasing in m, with Ui | Ri continuously distributed.
     Now suppose µ(m, r) is strictly increasing in m. Let Si = Wi be the uniformly distributed
index in the MTE representation of the judge's decisions. Then E [Yi | Ri , Wi ] = µ(Wi , Ri )
is itself a Ui which is continuously distributed given Ri . Furthermore

       Di = 1[Wi  Ri ] = 1[E [Yi | Ri , Wi ]  µ(Ri , Ri )] = 1[E [Yi | Ri , Si ]  t(Ri )].

The first equality applies the strictly monotone µ(·, Ri ) to both sides of the inequality, while
the second equality substitutes Wi = Si and defines t(Ri ) = µ(Ri , Ri ).




                                                  22
