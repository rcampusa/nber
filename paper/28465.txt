                              NBER WORKING PAPER SERIES




                    LEARNING FROM SHARED NEWS:
        WHEN ABUNDANT INFORMATION LEADS TO BELIEF POLARIZATION

                                          Renee Bowen
                                         Danil Dmitriev
                                         Simone Galperti

                                       Working Paper 28465
                               http://www.nber.org/papers/w28465


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                    February 2021




We thank S. Nageeb Ali, Myles Ellis, Harry Pei, Jacopo Perego, Joel Sobel, and participants in
conferences and seminars at UCSD, PhDEI, SIOE, PennState, NBER POL, UC Berkeley, UC
Davis, NYU, and MEDS for helpful comments and suggestions. All remaining errors are ours.
The views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2021 by Renee Bowen, Danil Dmitriev, and Simone Galperti. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.
Learning from Shared News: When Abundant Information Leads to Belief Polarization
Renee Bowen, Danil Dmitriev, and Simone Galperti
NBER Working Paper No. 28465
February 2021
JEL No. D82,D83,D90

                                          ABSTRACT

We study learning via shared news. Each period agents receive the same quantity and quality of
first-hand information and can share it with friends. Some friends (possibly few) share
selectively, generating heterogeneous news diets across agents akin to echo chambers. Agents are
aware of selective sharing and update beliefs by Bayes' rule. Contrary to standard learning
results, we show that beliefs can diverge in this environment leading to polarization. This requires
that (i) agents hold misperceptions (even minor) about friends' sharing and (ii) information
quality is sufficiently low. Polarization can worsen when agents' social connections expand.
When the quantity of first-hand information becomes large, agents can hold opposite extreme
beliefs resulting in severe polarization. Our results hold without media bias or fake news, so
eliminating these is not sufficient to reduce polarization. When fake news is included, we show
that it can lead to polarization but only through misperceived selective sharing. News aggregators
can curb polarization caused by shared news.

Renee Bowen                                      Simone Galperti
Department of Economics and                      Department of Economics
School of Global Policy and Strategy             University of California, San Diego
University of California, San Diego              9500 Gilman Dr. #0508
9500 Gilman Dr. #0519                            La Jolla, CA 92093-0519
La Jolla, CA 92093-0519                          sgalperti@ucsd.edu
and NBER
trbowen@ucsd.edu

Danil Dmitriev
Department of Economics
University of California, San Diego
9500 Gilman Dr. #0508
La Jolla, CA 92093-0519
ddmitrie@ucsd.edu
1       Introduction
Social divisions have been linked to economic and political issues such as inequality, political
gridlock, poor legislation, weak property rights, low trust, investment, and growth.1 Recent
decades have witnessed rising polarization in politics, media, and public opinions--especially
in the United States.2 "Americans are polarized not only in their views on policy issues
and attitudes towards government and society, but also about their perceptions of the same,
factual reality" (Alesina et al., 2020). Economists have thus been studying the causes of
belief polarization. Some have suggested a connection with the use of the Internet as a
source of information.3 Others have blamed misinformation --that is, fake news, bots, and
media bias--leading to discussions about regulating social media.4 Even if successful, will
such regulations curb polarization? Can polarization simply result from how people consume
and share information through their social connections, even without misinformation? Will
the abundance and extensive sharing of information brought by technology lead to more or
less polarization?
    We provide a theoretical framework to answer these questions and discuss implications
for policies aimed at curbing polarization. To this end, we build a simple benchmark model
that incorporates key empirical findings about how people share first-hand information via
social connections and absorb the resulting second-hand information. In a nutshell, people
often share selectively ; as a result, some people consume unbalanced diets of second-hand
information; moreover, they tend to misinterpret this information because they misperceive
how others share it selectively.5 We study the consequences for learning and belief polar-
ization. We find that misperceptions and quality of first-hand information (as opposed to
quantity) play critical and subtle roles. Our results do not require preexisting dierences in
people's worldviews nor misinformation. Yet, they imply that selective sharing is one (and
in a sense the only) channel through which fake news can lead to polarization. We sug-
gest mechanisms whereby changes in people's information ecosystem and social connections
brought on by the Internet may contribute to polarization.
    In our baseline model, agents learn about a binary state of the world, A or B, over time.
In every period, each agent gets an objective signal about the state with probability g and
    1 See Zak and Knack (2001); Keefer and Knack (2002); Bartels (2008); Bishop (2009); McCarty et al.
(2009); Gilens (2012); Barber and McCarty (2015).
   2 See Pew Research Center (2014, 2020); Desmet and Wacziarg (2018) Bertrand and Kamenica (2018).
   3 See Periser (2011); Flaxman et al. (2016); Sunstein (2017); Azzimonti and Fernandes (2018); Tucker
et al. (2019); Zhuravskaya et al. (2020).
   4 See, for example, "Should the Government Regulate Social Media?", Wall Street Journal (June 25, 2019)
and "Facebook Throws More Money at Wiping Out Hate Speech and Bad Actors", Wall Street Journal
(May 15, 2018).
   5 For evidence of selective sharing, see Shin and Thorson (2017); Weeks et al. (2017); Shin et al. (2018);
Pogorelskiy and Shum (2019); Levy (2020); Zhuravskaya et al. (2020). Unbalanced news diets are a distinctive
aspect of so-called echo chambers or media bubbles, which appear in a wealth of evidence (see Levy and Razin,
2019a; Zhuravskaya et al., 2020, for a review). Bertrand and Kamenica (2018) also stress the importance of
media diet driving social dierences. Pogorelskiy and Shum (2019) provide evidence of misperception about
selective sharing.


                                                     2
no signal otherwise (first-hand information). Signals are i.i.d. across agents and periods.
We refer to their informativeness as quality. In every period, each agent can remain silent
or share her signal with her social connections--called friends. She cannot tamper with
her signals, but can select which to share. We assume that some agents--called normal --
share every signal; other agents--called dogmatic --selectively share only signals supporting
one state. To fix ideas, some people (possibly a tiny minority) may hold a dogmatic view
on whether to vaccinate children and share only articles in its favor; others simply share
any article on the topic. We refer to an agent's sources of second-hand signals as her echo
chamber. If a majority of her dogmatic friends supports one state, it creates an unbalanced
news diet. We model misperception of selective sharing in a way that renders the agents
partially unresponsive to it (as found in Pogorelskiy and Shum (2019)) and is inspired by
the psychology literature.6 Each agent interprets all signals correctly, but thinks that they
arrive with probability g^ 6= g. This is akin to assuming that friends read the newspaper less
or more often than they actually do. Thus, our agents have a common misspecified model
of selective sharing, based on which they update beliefs using Bayes' rule. We also consider
other misperceptions and show that they have similar implications.
    We find that people's understanding of the selectivity of shared news turns out to be
crucial. Without any misperception, unbalanced selective sharing alone cannot lead to po-
larization (Remark 1). This is an important qualification of a common intuition about the
eects of echo chambers. If a person took at face value what her friends say supporting only
one view, her opinion could be swayed accordingly. In reality, however, only a few friends
may share information selectively and often people also get first-hand information. Even in
the absence of these mitigating factors, if a person fully understands how her friends select
what to share, she will adjust for it and her beliefs will not be distorted. It is unrealistic
that people are completely naive about selective sharing, but experimental evidence suggests
they do not fully take it into account either.
    We analyze learning both in the short run (after one round of signals) and in the long
run (after infinitely many rounds). In the short run, an agent's expected posterior can dier
from her prior, even when she has many normal friends. The intuition is that the silence of
a dogmatic friend indicates bad news for the state he supports. Yet, if an agent thinks that
this friend is informed less often than he is (g  ^ < g), she reads too little into his silence,
thus enabling him to distort her posterior towards the state he supports. By contrast, if
an agent thinks that her friends are informed more often than they are (g    ^ > g), she reads
too much into their silence, which distorts her posterior away from the state supported by
a dogmatic friend. Thus, if a majority of such friends favors, say, state A, her expected
posterior is distorted towards (away from) A if g   ^ < g (g^ > g)--at least when the signal
quality is su ciently low. Perhaps unexpectedly, we find that even balanced echo chambers
can distort an agent's posterior.
    For the long run, abundant information can boost the distorting power of dogmatic
friends--instead of curbing it--thereby exaggerating incorrect learning. We identify a precise
quality threshold below which the agent's long-run belief assigns probability one to a given
  6 See   Cross (1977); Svenson (1981); Odean (1998); Zuckerman and Jost (2001).


                                                    3
state, irrespective of the truth. For higher quality, her belief converges to the truth despite
the echo-chamber eect. Long-run incorrect learning requires unbalanced dogmatic friends:
If their majority favors A, the agent's belief converges to A if g  ^ < g and to B if g ^ > g.
Note that the imbalance can be arbitrarily small, yet oset many unfiltered signals.
    It is easy to see how these forces can cause polarization. If the echo chambers of some
agents are unbalanced towards dierent states and information quality is su ciently low,
their beliefs can move apart on average in the short run and almost surely in the long
run. One of our main contributions is to highlight the role of information quality. Indeed,
we find that for intermediate qualities polarization can occur even if all echo chambers are
unbalanced towards the same state. One may also expect that raising information quality
would undoubtedly help curb polarization. However, it can actually increase polarization
under some simple conditions, which we identify. The role of information quality also implies
that polarization in echo chambers and in beliefs need not go hand in hand.
    We find that the expansion of social connections can be another driver of polarization.
This is not obvious, as more connections may provide greater scope for echo chambers to
distort beliefs but also bring more information. Fixing its quality, we obtain conditions on
how the internal structure of echo chambers has to change for polarization to weaken. For
instance, it is possible that society is not polarized when people have small echo chambers,
but becomes polarized when they have similarly divided, but larger, echo chambers. This
could happen if social media recommend new friends in ways that depend only marginally
(or not at all) on how they share information.
    Our analysis goes to the heart of why new communication technologies and formats
enabled by the Internet can increase polarization. They speed up the arrival of information
and possibly lower its quality--for instance, tweets and social-media posts tend to be short.
Moreover, overwhelmed by the stream of information, people may spread their attention
across more sources, thereby absorbing less content from each. This may eectively lower the
quality of consumed information. All of this can lead to polarization even without deliberate
misinformation.
    Finally, we return to the motivating question of what policies may reduce the eects of the
Internet and news sharing more generally on polarization. Some of the drivers we highlight
may be o limits, as they result from legitimate personal rights: making friends and sharing
information as one pleases. Possible solutions may emerge from our focus on information
quality. An immediate one is that news outlets provide higher-quality information, but this
may be hard to incentivize and decentralize. Another solution is to exploit news aggregators.
Although their reasons to exist may be dierent, we show how aggregators can provide
higher-quality information even when they lose some information by summarizing facts. We
identify a minimal degree of aggregation that su ces to remove polarization. The catch is
that reaching this degree may require institutional aggregators that take into account the
externalities caused by selective sharing. These insights provide a rationale for authorities
to commit to releasing information only rarely in "digested" batches.




                                              4
Related Literature. The economics literature discusses at least three possible causes of
belief polarization. The one most closely related to our work is behavioral biases.7 Our
contribution to this literature is to highlight misperception of selective sharing as a driver
of polarization. Another cause is heterogeneity in preferences.8 Such heterogeneity would
exacerbate the polarization we find. A third cause is biased or multidimensional information
sources, where biases usually come from media competition over viewers.9 In our analysis,
the sources of first-hand information--which can be interpreted as media outlets--are not
biased. Thus, removing all media biases may still not be enough to curb polarization.
    This paper fits into the growing literature on model misspecification and social learning.
The classic work of Berk (1966) provides a general model of individual misspecified learning
in the long run. We analyze short- and long-run learning in a more specialized model and
demonstrate the interaction with social information sharing to generate polarization. Bohren
(2016), Bohren and Hauser (2018), and Frick et al. (2020) analyze how model misspecification
impacts long-run learning in environments where agents learn from private signals and the
actions of others. In particular, Bohren and Hauser (2018) study when agents with dierent,
yet reasonable, models of the world have no limit beliefs (i.e., beliefs cycle) or dierent limit
beliefs (disagreement). Although close in spirit, our disagreement results are driven by a
fundamentally dierent mechanism, as all our agents have the same model of the world. We
also emphasize the role of information quality and its implications for curbing polarization.
Like Bohren and Hauser (2018), Mailath and Samuelson (2020) consider agents with dierent
misspecified models of the world. Molavi et al. (2018) study long-run learning on social
networks when non-Bayesian agents exhibit imperfect recall. They show that such agents
may overweight evidence encountered early on, which can lead to mislearning. Unlike these
authors, we assume that agents update beliefs via Bayes' rule.10
    A key element of our model is the idea of an echo chamber as the group of friends from
whom one receives information. This connects our work to a large literature that studies both
Bayesian and non-Bayesian learning in networks.11 One closely related paper is Levy and
Razin (2019a), which shows that an updating heuristic called "Bayesian Peer Influence" can
cause limit beliefs in networks to become polarized. However, their meaning of polarization
is dierent from ours: There the entire society's consensus shifts towards a common extreme
belief; here the agents' beliefs diverge to dierent extreme beliefs.
    Recent empirical studies show that social media is an important source of news for people
   7 See, e.g., Levy and Razin (2019b); Homann et al. (2019); Enke et al. (2019).
   8 See Dixit and Weibull (2007); Pogorelskiy and Shum (2019).
   9 See, e.g., Mullainathan and Shleifer (2005); Andreoni and Mylovanov (2012); Levendusky (2013); Conroy-
Krutz and Moehler (2015); Reeves et al. (2016); Perego and Yuksel (2018).
  10 A nonexhaustive list of other recent work on misspecified learning includes Nyarko (1991); Esponda and
Pouzo (2016); Fudenberg et al. (2017); He (2018); Heidhues et al. (2018); Jehiel (2018); Esponda et al. (2019);
Ba and Gindin (2020); Dasaratha and He (2020); He and Libgober (2020); Frick et al. (2020); Fudenberg
et al. (2020); Li and Pei (2020).
  11 See DeMarzo et al. (2003); Golub and Jackson (2010); Eyster and Rabin (2010); Acemoglu et al. (2010);
Perego and Yuksel (2016); Azzimonti and Fernandes (2018); Pogorelskiy and Shum (2019); Spiegler (2019).




                                                      5
and can lead beliefs and attitudes to diverge.12 Other evidence by Boxell et al. (2018)
suggests that the Internet does not drive polarization. Our model can predict in which
environments we expect to see the Internet drive polarization. We, thus, contribute to this
literature by providing a theoretical framework to better understand how social media can
contribute to polarization and to guide future empirical investigation and policy discussion.


2      Model
We consider a stylized model of learning from information shared through social connections.
Time t is discrete, where t = 0, . . . , T and T  ·. A state of the world w 2 { A, B} realizes
at t = 0. For example, w can represent whether preserving the environment requires higher
national spending than the current level, or whether vaccines can harm children. There is a
fixed group of agents who seek to learn w .
Information. Each agent receives first-hand information from original sources and second-
hand information shared by other agents. For each t 1, agent i receives first-hand infor-
mation with probability g 2 (0, 1] in the form of a private signal sit 2 { a, b}; with proba-
bility 1 g she receives no signal. Signals are partially informative:
                        P (sit = a|w = A) = P (sit = b|w = B) = q,                                       (1)
                        P (sit = b|w = A) = P (sit = a|w = B) = 1 q,
where 12 < q < 1. We refer to q as the information quality. The events of receiving a signal
and its realization are i.i.d. across agents and time.13
Selective Sharing. Agents share their first-hand information with other agents with whom
they have a social connection. We call these social connections friends. We aim to capture key
aspects of social information sharing suggested by experimental evidence (see Footnote 5).
The first is selectivity. In our model, after receiving her own signal, an agent can share
it with all her friends or stay silent. If she receives no signal, she stays silent. Thus, she
can selectively suppress information, but cannot fabricate information, which rules out fake
news. Concretely, an agent can share a newspaper article, but cannot edit its content.
    We introduce three types of agents characterized by their information-sharing behavior.
An agent is normal if she shares any signal she receives, A-dogmatic if she shares only
signals sit = a, and B-dogmatic if she shares only signals sit = b. One interpretation is that
some agents dogmatically believe in their conviction that only one state is true and share
only information that supports it. Formally, in each period the dogmatic types share their
  12 See, e.g., Allcott and Gentzkow (2017); Bursztyn et al. (2019); Mosquera et al. (2019); Levy (2020). See
also Barber´ a (2020) and Zhuravskaya et al. (2020) for recent reviews of this literature.
  13 In reality, people receive correlated news. However, strong evidence suggests that they often neglect
correlation, especially in second-hand news (Enke and Zimmermann, 2017; Eyster et al., 2018; Pogorelskiy
and Shum, 2019). Under correlation neglect, we can allow for arbitrary correlation between the agents'
signals within each period and our main results are qualitatively unchanged.



                                                     6
received signals as follows:
                 (                                                    (
                   share              if sit = a                          stay silent     if sit = a
     sA (sit ) =                                        sB (sit ) =
                   stay silent        if sit = b,                         share           if sit = b.
Each agent's type is exogenous and known to her friends.14
    A key aspect of social news sharing is that it contributes to creating heterogeneous
information diets (Pew Research Center, 2014; Levy and Razin, 2019a).15 Agent i's diet
depends on the composition of friends she listens to, namely, the number d Ai                   0 of A-
dogmatic friends, d Bi           0 of B-dogmatic friends, and ni        0 of normal friends. We refer to
ei = (d Ai , d Bi , ni ) as i's echo chamber. If d Ai 6= d Bi , we say that i's echo chamber--hence, her
information diet--is unbalanced and we refer to d Ai d Bi as its imbalance. Otherwise, we
say that ei is balanced. Finally, we refer to the majority (minority) of an agent's dogmatic
friends as her dogmatic majority (minority).
Timing. Within each period t          1 the timing is as follows: (1) signals realize; (2) each
agent i receives sit with probability g; (3) each agent i shares her signal (if any) with friends
as specified by her type; (4) agents update beliefs based on all received signals.
Beliefs. We are interested in the beliefs of normal agents. They share a common prior
p 2 (0, 1) that w = A. Given a sequence si    t of information that agent i receives up to t (i.e.,

her signals, her friends' signals, and their silence), let µ(sit ) be her Bayesian posterior that

w = A. To examine learning in the short run, we will consider µ(s1      i ); to examine learning in
the long run and so the eects of abundant information, we will consider the (probability)
limit of µ(siT ) as T ! ·, denoted by µ(si  · ) = plim             T
                                                         T !· µ (s ). We will introduce a formal
measure of belief polarization in Section 4. However, intuitively, polarization requires that
beliefs move systematically apart between agents. It is well known that µ(s1                      1
                                                                                     i ) and µ (s j )
for i 6= j can dier in completely standard Bayesian models simply because agent i and j
observe dierent signal realizations. Therefore, for the short run we adopt a moredemanding      
condition   for polarization that looks at di  erences  between   the expectations  E   µ ( s1 ) and
  h       i                                                                                   i
E µ(s1
     j ) . Recall that both must equal the prior p in standard Bayesian models.
                                                                               16

   At first glance, one might think that selective sharing and unbalanced echo chambers
should su ce to give rise to belief polarization. This is not the case. Hereafter, let I{w = A}
equal 1 if w = A and 0 otherwise.

  14 InSection 6 we consider a more general model where dogmatic friends share their signals probabilistically
and their type may not be perfectly known.
  15 People also have heterogeneous news diets because they choose to listen to dierent first-hand sources.
We abstract from this aspect to focus on the eects of news sharing.
  16 As another interpretation, we can view each agent i and j as representative of a large group of individuals
                                                                                                          1 
that are      i within their group but dier between groups. Then, by the law of large numbers E µ(si )
       h similar
and E µ(s1 j ) approximate the empirical average belief of the respective group and may be used to assess
intra-group polarization.



                                                       7
Remark 1. For any echo chamber ei and g 2 (0, 1], we have
                      h       i
                                                    ·
                    E µ(s1i )   =p    and      µ ( si ) = I{w = A} .

This is because if an agent fully understands the eects of her echo chamber on her informa-
tion diet, selective sharing simply results in a specific information structure that is perhaps
less informative than under full sharing. Nonetheless, the agent gets some information ev-
ery period, so her belief must satisfy standard properties of Bayesian updating.
Misperception. To break the impossibility implied by Remark 1, we again refer to the em-
pirical evidence for guidance. Pogorelskiy and Shum (2019) suggest a third aspect specific to
learning from shared news: Agents often misperceive the selectivity of second-hand informa-
tion. When friends share their first-hand information, an agent simply has to absorb what
she receives. But if they share nothing, she faces a more complex inference problem: Why
did a friend remain silent? Did he get no signal? Did he suppress his signal? When does
he do so? It is reasonable that her answer to any of these questions may be miscalibrated.
In the baseline model, we consider the simplest form of miscalibration, which involves only
one parameter: the arrival probability of signals. Formally, we let each agent think that the
                                          ^ 2 (0, 1]. We will refer to g
i.i.d. probability of getting a signal is g                              ^ < g as under-estimating
news arrival and to g  ^ > g as over-estimating news arrival. The agents continue to use Bayes'
rule to calculate µ(st ), yet applied to this slightly misspecified model of the world. The  rest
of the model is unchanged. Note that we, as the external observer, will calculate E µ(st )
and µ(s· ) using the correct model of the world (i.e., g not g    ^ ).17

Discussion of the Model

We discuss the motivation for our modeling choices. The analysis beginning in Section 3 does
not rely on anything mentioned here, so a reader may skip this section without confusion.
    We can interpret misperceptions about news arrival as follows. An agent may under- or
                                                                   ^ < g, this may be a man-
over-estimate the probability that her friends receive signals. If g
ifestation of the so-called "illusory superiority" or "better-than-average" heuristic,18 which
can lead an agent to think that others are less informed than she is even though everyone is
equally informed. People often have unjustifiably favorable views of themselves relative to
the population average or even in person-to-person comparisons on various characteristics,
which may include how well informed they are or how good they are at getting and under-
standing information. By contrast, some agent may be insecure and think that her friends
are more informed than she is, even though everyone is equally informed (i.e., g ^ > g). The
case of g^ < g seems more consistent with introspection and the psychology literature, but
we also analyze the case of g   ^ > g for completeness. An agent may also misperceive the
  17 In Section 6 we will consider misperceptions about the friends' types, their news-sharing behavior, or
                                                                                                      ^ 6 = g.
the information quality and show that they all lead agents to misinterpret silence in ways similar to g
  18 See, e.g., Cross (1977); Svenson (1981); Odean (1998); Zuckerman and Jost (2001).




                                                      8
probability of receiving her own signals. However, this turns out to have no eect because
she cannot selectively share signals with herself.
    The key feature of misperception is that the agent's view of the world rules out the true g
from the set of possibilities. This is a defining feature of models with misspecification (like
those listed in the related literature). Thus, even if we allowed the agent to learn about the
probability of signal arrivals, she would not converge to the truth.
    For simplicity, we assumed that each agent cannot choose which friends to share her signal
with: She either shares it with all friends or none. This is similar to posting a newspaper
article on one's social-media page where all friends can see it. Also, our model is consistent
with the possibility that an agent may knowingly receive a friend's shared signal through
another friend. This is similar to knowing the origin of a re-tweet on Twitter.
    Sharing a signal takes the form of verifiable information in our model. By ruling out
fake news, we highlight the role of selective sharing in a baseline model to which these other
aspects can be added. The verifiability of shared information and the possibility of not
receiving first-hand information renders our model similar to Dye (1985). Allowing for this
possibility is one often-used way to give selective sharing a chance to be eective: Otherwise,
silence can be immediately interpreted as negative news.19
    We take the types of news-sharing behavior as given because they approximate the find-
ings in the empirical literature (see, e.g., Pogorelskiy and Shum (2019)). Moreover, our focus
is not understanding why people tend to share to a greater extent news that supports their
convictions, but understanding its consequences for social learning. Future research may en-
dogenize news-sharing behavior in settings similar to ours. With regard to how we model
dogmatic agents, we can view such agents as having extreme beliefs that are very hard to
change--perhaps because they are stubborn, narrow minded, or blindly follow and promote
some ideas. Thus, we can model them as having degenerate prior beliefs in A or B, which
do not change with new information. One can also interpret our model as situations where
dogmatic agents can change their views, yet much more slowly than non-dogmatic agents.20
As a result, how they selectively share information is very persistent. Note that for our re-
sults to hold it is enough to have a few dogmatic agents.
    Finally, a brief comment is in order on the heterogeneity between agents that we al-
low. We assume that the prior p , the true and misperceived probability of receiving signals
(g and g ^ ), and the signal distribution (1) are the same for all normal agents. Only the com-
position of echo chambers can dier between them. Starting from a setting where they are all
ex-ante identical and have the same model of the world helps to highlight the role of dierent
information diets due to echo chambers as a driver of belief polarization. It is intuitive that
adding dierences between agents can introduce other drivers of polarization. One can eas-
ily infer the consequences of such additional dierences from our results in the next section.
 19 For example, see Ben-Porath et al. (2018) and DeMarzo et al. (2019).
 20 For studies on people's reluctance to change worldview see, e.g., Edwards (1968), Nisbett and Ross
(1980), Evans (1989), Nickerson (1998), and Galperti (2019).




                                                  9
3     Single-Agent Learning
Before examining belief polarization among agents, we study how each individually updates
her belief under the eects of selective sharing and misperceptions. Since we focus on a
generic normal agent, we drop all i subscripts in this section.


3.1     Short Run
We begin with short-run learning. Recall that µ(s1 ) is the Bayesian posterior probability
that the agent assigns to state A given all the information she obtains after one period.
    Our first result shows that, in the presence of misperception, selective news sharing can
distort learning even if it does not give rise to unbalanced news diets. Specifically, if the
agent under-estimates news arrival (g ^ < g), her expected posterior is distorted towards the
state she deems more likely ex ante. This is reminiscent of updating distortions usually
called confirmatory bias (Rabin (1998)). Conversely, if the agent over-estimates news arrival
(g^ > g), her expected posterior is distorted towards the state she deems less likely ex ante.
Proposition 1. Fix any agent with a balanced echo chamber.
                                         
        ^ < g, then E [µ(s1 )] p p 1
  1. If g                               2 > 0.
                                         
        ^ > g, then E [µ(s1 )] p p 1
  2. If g                               2 < 0.

    To give some intuition, it is useful to explicitly write the agent's posterior after one
period. Denote by a A the number of a-signals her A-dogmatic friends received and by bB the
number of b-signals her B-dogmatic friends received. From her perspective, a A is distributed
as a Binomial random variable with probability g        ^ (1 q) and sample size d A , whereas bB
is distributed as a Binomial random variable with probability g       ^ q and sample size d B . The
agent also receives n + 1 independent private signals: n from her normal friends plus her own
signal. Among these signals, let a N and b N denote the number of a-signals and b-signals,
which are multinomial random variables with probabilities g      ^ (1 q) and g  ^ q and sample size
                                                                                1
n + 1. Note that ( a A , bB , a N , b N ) summarizes the agent's information s . By Bayes's rule
her posterior belief is21
                                                        p
                                    µ(s1 ) =                       ,                             (2)
                                               p + (1 p ) Q M G ^S
where
                                               1    q
                                      Q          ,
                                            q
                                     M  a A + a N ( b B + b N ),
                                         ^ (1 q ) + (1 g
                                      ^  g                ^)
                                     G                       ,
                                             g^ q + (1 g
                                                       ^)
 21 This   representation is derived in the proof of Proposition 2.


                                                        10
                                  S  (d B        bB )   (d A   a A ).
    We can understand this expression as follows. The term Q M captures the agent's in-
terpretation of the received signals, which is always correct: By verifiability of information,
the act of sharing a signal leaves no uncertainty regarding whether the signal was actually
received--hence, g  ^ is irrelevant. The term G  ^ S captures how the agent incorrectly interprets
the silence of her dogmatic friends. She observes silence from d B bB B-dogmatic friends
and from d A a A A-dogmatic friends. She attributes each instance of silence to an unfa-
vorable signal for the friend with probability g    ^ or to no signal with probability 1 g   ^ . Note
that G^ is a decreasing function of g ^ . Thus, a higher g             ^ S if S < 0 and decreases G
                                                           ^ increases G                           ^S
if S > 0, thereby distorting the posterior downward or upward depending on S. It is there-
fore not immediate that the average distortion goes in any specific direction. For instance,
the agent's misperception could inflate or deflate updating, but have no eect on average.
    The agent's prior resolves this ambiguity. To see why, suppose she deems state A as
very unlikely ex ante (small p ). Consider g       ^ < g. Silence of A-dogmatic friends induces
her to update the probability that w = A downward, while silence of B-dogmatic friends
induces her to update it upward. In both cases, the agent updates less than she should
because she excessively attributes silence to lack of news. However, this under-reaction has
asymmetric consequences for A- and B-dogmatic friends. When p is small, B-dogmatic
friends are relatively less likely to receive an unfavorable signal and thus remain silent than
A-dogmatic friends are. Put dierently, p < 1         2 magnifies the under-reaction to the silence
of B-dogmatic friends relative to A-dogmatic friends, which distorts updating downward.
Figure 1a illustrates Proposition 1.
    Our second result focuses on the eects of an imbalance in the agent's echo chamber.
It states that if the agent under-estimates news arrival (g      ^ < g), her expected posterior is
distorted towards the conviction of her dogmatic majority. By contrast, if the agent over-
estimates news arrival (g    ^ > g), her expected posterior is distorted against her dogmatic
majority. However, for the dogmatic majority to have such eects the information quality
has to be su ciently low.
Proposition 2. Fix any agent with an unbalanced echo chamber e = (d A , d B , n) that satisfies
                                    ^) > 1
d A > d B . There exists qSR (e, g, g                                    ^ ), then
                                         2 such that, if q < qSR ( e, g, g
                                                 
                                    E [µ(s1 )] p (g ^ g) < 0.

Our proof actually shows that the expected posterior is distorted as stated also conditional
on any true state of the world. Figures 1b and 1c illustrate Proposition 2.
    Consider again how the agent updates (see (2)). If she has more A- than B-dogmatic
friends, she will tend to receive more signals supporting state A than B. Yet, this does not
imply that her posterior will be distorted towards A. To see why, it helps to consider extreme
misperceptions. Suppose she severely under-estimates news arrival: g > g      ^  0. She then
interprets silence as almost certainly no news, rather than bad news for her dogmatic friends.
Thus, she essentially ignores silence and updates based only on the shared signals, which
tend to favor A. By contrast, suppose she severely over-estimates news arrival: g < g    ^  1.

                                                 11
                                    (a) n = 1, d A = 2, d B = 2




          (b) n = 1, d A = 3, d B = 2                        (c) n = 1, d A = 4, d B = 2

Figure 1: Graphs of the ratio between the expected posterior and the prior as a function of
q, for dierent echo chambers (determined by the values of n, d A and d B ). Other parameters
                                       ^ = 0.5.
are as follows: p = 0.001, g = 0.8 and g


She then interprets silence as almost certainly bad news for her dogmatic friend, rather than
no news. Thus, she reads too much into the silence of her dogmatic majority and incorrectly
updates her belief away from their preferred state. Put dierently, her dogmatic majority
always drives her belief through selective sharing, but this can backfire and push her to
believe that the state is B. The case of g   ^ < g seems more consistent with the common
understanding of the eects of echo chambers. It is, however, interesting that these eects
do not disappear when g   ^ > g, but rather change direction.
    Clearly, for such distortions to arise the information quality cannot be perfect (i.e., q =
1). Proposition 2 shows that for su ciently low quality the imbalance between dogmatic
friends--however small--always prevails over the information
                                                                  coming from normal friends
                                                         1
and own signals. In some cases, it prevails for all q 2 2 , 1 (for an example, see Figure 1c).

Corollary 1. Fix any agent with an unbalanced echo chamber that satisfies d A > d B .


                                                12
         ^ < g and p > 1
   1. If g                              1
                       2 , then E [ µ (s )] > p for all q 2
                                                                 1
                                                                 2, 1   .

         ^ > g and p < 1
   2. If g                              1
                       2 , then E [ µ (s )] < p for all q 2
                                                                 1
                                                                 2, 1   .

However, it is not true that an agent's echo chamber always distorts her learning towards
her dogmatic majority, even if her under-reaction to silence favors that majority (for an
example, see Figure 1b).


3.2    Long Run - Abundant Information
We showed that with one round of information echo chambers can systematically distort be-
liefs. One may expect these distortions to vanish when information becomes abundant (i.e.,
in the long run after many signals). In fact, the opposite can occur: Abundant information
can exacerbate the eect of misperceived selective sharing and cause beliefs to be almost cer-
tainly incorrect, but only if information quality is su ciently low. In this case, with prob-
ability 1 and irrespective of the true state, the agent's posterior converges to a degenerate
belief on one state (denoted by dw ). This is the state favored by her dogmatic majority if
g^ < g and by her dogmatic minority if g  ^ > g.

Proposition 3. Fix any agent with an      unbalanced
                                                      echo chamber e = (d A , d B , n) that satisfies
                                           1
                                     ^ ) 2 2 , 1 such that the following holds:
d A > d B . There exists q LR (e, g, g

                        ^ ) and g
  1. If q < q LR (e, g, g       ^ < g, then the agent's belief converges to dA with probability 1
               ·
     (i.e., µ(s ) = 1).

                        ^ ) and g
  2. If q < q LR (e, g, g       ^ > g, then the agent's belief converges to dB with probability 1
               ·
     (i.e., µ(s ) = 0).

                        ^ ), then the agent's belief converges to dw with probability 1, where w
  3. If q > q LR (e, g, g
     is the true state (i.e., µ(s· ) = I{w = A} ).

It follows from the proof that for balanced echo chambers the agent's posterior always con-
verges to dw with probability 1, where w is the true state. Thus, the distortion in Proposi-
tion 1 does not survive in the long run.
    We can intuitively understand this result as the outcome of a non-trivial race between
two kinds of information over time. The agent's first-hand information provides an increas-
ingly accurate estimate of the state, which would result in perfect learning in a standard
setting. The second-hand signals from her friends also provide more information, but are se-
lected in ways she does not correctly take into account. It turns out that with low quality
signals the distortion in each step of updating unveiled in Proposition 2 accumulates over
time leading the posterior astray. Thus, only high-quality information eventually removes
both the intrinsic distortions caused by selective sharing (Proposition 1 and Corollary 1) and
the distortions caused by echo-chamber imbalance (Proposition 2 and Corollary 1). Another


                                                 13
way to see the role of q is to reconsider the correct updating term Q M and incorrect updat-
ing term G^ S in formula (2). As q increases from 1 (low informativeness) to 1 (high informa-
                                                   2
tiveness), Q M falls from 1 to zero, thereby curtailing the misperception eect through G    ^ S.
While in the short run this curtailment may be complete only at q = 1, in the long run it is
always complete for a range of q < 1.
    The threshold q LR that distinguishes correct and incorrect long-run learning has intuitive
comparative statics properties.
                                         ^ ) is strictly increasing in |d A
Proposition 4. The threshold q LR (e, g, g                                                    d B | and |g   ^|
                                                                                                             g
and decreasing in n.
The threshold increases with the degree of echo-chamber imbalance and of misperception,
as both strengthen the forces leading posteriors astray. The threshold decreases with the
number of normal friends, as they provide more unfiltered information.
   These properties uncover some subtleties in how echo chambers can drive people's beliefs
apart. Even if the underlying information is the same for all, an agent with many but
moderately unbalanced dogmatic friends can learn the truth over time, while another with
few but severely unbalanced dogmatic friends can end up believing something false.


3.3    Making and Losing Friends
Advances in technology--such as the development of social media--have expanded the group
of friends from which many agents receive second-hand information. How do these changes
aect individual learning? This section addresses this, focusing on the long run.
    Suppose a normal agent makes or loses friends of any type, which changes the composition
of her echo chamber. How does this aect the range of information qualities that result in
incorrect learning?22
Proposition 5. Fix any agent with echo chamber e = (d A , d B , n) that satisfies d A > d B
and n 1. For any other echo chamber e0 = (l A d A , l B d B , l N n) with l N 0, l A 0 and
                                                           ^ ) < q LR (e0 , g, g
l B 0 that satisfy l A d A > l B d B , we have q LR (e, g, g                   ^ ) if
                                                              
                            l A d A lB dB                  1
           lN 1                                1      1+                                (3)
                                d A dB                     n
                                                 
                              d A dB     1                         2
                          +             · · max (l A l B )              , (l A l B ) .
                            d A dB n                            2 g   ^
To understand this condition, start from the first term in parentheses, which measures the
net growth rate of the echo-chamber imbalance. If this is positive, then (3) requires normal
friends to grow su ciently faster in order to decrease q LR . If instead more dogmatic connec-
tions reduce the echo-chamber imbalance, the number of normal friends can even fall --but
not too much--without increasing q LR . The second line of (3) takes into account what hap-
pens individually to the group of A- and B-dogmatic friends and hence to the flow of selected
 22 Appendix   E provides a more general result that also covers the case of l A d A < l B d B .


                                                       14
signals the agent receives from each group. If the A-group grows more, then (3) requires an
even larger growth of normal friends to decrease q LR . If the B-group grows more, this par-
tially compensates the change in the imbalance and hence requires a smaller growth of normal
friends. One can show that q LR always increases if scaling is proportional (l A = l B = l N ).
This could happen on social media, for instance, if how they suggest new connections is in-
dependent of what news people share. In short, an increase in the number of friends involves
a trade-o between access to information and the scope for echo-chambers to distort beliefs.
    We now ask a dierent question: Given the existing information quality, what changes
in an agent's friends are su cient to overcome her echo-chamber's power to distort beliefs
and re-establish correct learning? Specifically, given any q^ < q LR and l A = l B = l, what
l N su ces to lower q LR below q^?

Proposition 6. Fix any
                    agent with echo    chamber e = (d A , d B , n) that satisfies d A > d B and
                     1
n   1 and any q                    ^ ) . For any other echo chamber e0 = (ld A , ld B , l N n)
               ^ 2 2 , q LR (e, g, g
with l    0 and l N     0, we have that q LR (e0 , g, g    ^ if the following holds:
                                                      ^) < q

           ^ < g,
    1. for g
                                            dA      ^( d A + d B )
                                                    q                        1
                                    lN >                           l           ;
                                                    ^ 1) n
                                                  (2q                        n
           ^ > g,
    2. for g
                                                
                                        ^
                                        g
                                        g     ^ (d A
                                             2q               d B ) + 2d B         1
                              lN >                                           l       .
                                              ^
                                            (2q     1) n (2      ^)
                                                                 g                 n

    Propositions 5 and 6 may have several practical implications. For instance, the growth
and types of an agent's friends may be estimated using data from social-media platforms
about their news-sharing habits and composition. Given the desired l N , one can estimate
how long (if ever) it will take before her echo chamber stops distorting her beliefs (i.e., before
                 ^). Alternatively, algorithms designed by social-media platforms often control
q LR falls below q
how people form new connections. Knowing the eects of echo chambers' composition on
people's learning can inform the design of such algorithms so as to limit the distortions of
selective news sharing.


4     Belief Polarization in Society
We build on the previous results to examine belief polarization in society. We will treat the
set of normal agents as our society of interest, which we denote by N . We exclude dogmatic
agents based on the interpretation that they have degenerate beliefs, which therefore do not
respond to new information.
    We begin by defining a measure of belief polarization. Polarization does not simply
mean heterogeneous beliefs but rather the existence of groups with sharply dierent beliefs

                                                   15
(Esteban and Ray (1994)), which usually emerge over time. For this reason, we start by
examining polarization in long-run beliefs. Denote the vector of echo chambers in N by
                                         e = {(d Ai , d Bi , ni )}i2N .
By Proposition 3, every e gives rise to a distribution of long-run beliefs across the agents
in N , which is characterized by the agents who converge to having a degenerate belief on
state w 2 { A, B}: Let
                                   Nw (e) = {i 2 N : µ(si· ) = dw }.
We then define long-run polarization as23
                                 2                                        4|N A (e)||N B (e)|
                      P (e)           Â
                               |N |2 i, j2N
                                                 ·
                                            µ ( si )     µ ( s·
                                                              j ) =
                                                                                 |N |2
                                                                                              .

Note that P(e) takes values in [0, 1] and attains its maximum when |N A (e)| = |N B (e)|.
Given the true state w , we will call Nw (e) the set of "eventually correct" agents and N w (e)
the set of "eventually incorrect" agents.
    Our previous results imply that selective information sharing can cause beliefs to polarize
in the long run if and only if it is combined with misperceptions. Indeed, P(e) = 0 if
there are no misperceptions (Remark 1), or if all echo chambers are balanced. Otherwise,
Proposition 3 implies the following.

Corollary 2. Fix any society N with echo chambers e that satisfy d Ai > d Bi and d Aj < d Bj
for some i, j 2 N . There always exists q > 1
                                            2 such that P (e) > 0.

This formalizes the common narrative that, if some agents in society have echo chambers
that skew their news diets in opposite directions--where the imbalances can be small--then
their beliefs can polarize.24 However, our results qualify this narrative: Belief polarization
requires su ciently low quality of information and some misperception of the eects of echo
chambers, but does not require fake news nor that people look at the world in fundamentally
incompatible ways. Our results also show that oppositely unbalanced echo chambers are not
necessary for polarization to arise. By Propositions 3 and 4, if we take any society N such
that d Ai d Bi for all i 2 N and d Aj d Bj > d Ak d Bk for some j, k 2 N , then there always
exists q > 12 such that P (e) > 0 if the true state is w = B. For this society, if the informa-
tion quality is extremely low or high, long-run polarization is zero because either everybody
is eventually incorrect or everybody is eventually correct. But for intermediate information
  23 Note   that by standard continuity arguments
                                                    2
                                   P(e) = plim
                                            t!·
                                                         Â
                                                  |N |2 i, j2N
                                                                    t
                                                               µ ( si )   µ (st
                                                                              j) .



 24 Rich evidence shows that people on the left and right of the political spectrum tend to have more like-
minded friends than not, a fact that is often cited as a possible cause of polarization (e.g., Pew Research
Center (2014)).


                                                        16
quality some agents will be eventually correct despite their unbalanced echo chamber, while
others will be eventually incorrect.
    These observations highlight the importance of information quality for echo chambers to
give rise to belief polarization. Intuition may suggest that as people receive better informa-
tion, disagreement should decline. In fact, this need not be true. The following result pro-
vides a necessary and su cient condition for polarization to be non-monotonic in q.25 To
this end, let Dw be the set of agents who will be eventually incorrect if their long-run belief
agrees with their w -dogmatic friends, but the true state is not w :
                                D A = {i 2 N : (d Ai     d Bi )(g   ^ ) > 0}
                                                                    g
and D B is defined similarly by swapping d Ai and d Bi (Proposition 3).

Proposition 7. Fix any society N that has echo chambers e which satisfy                           ^ ) 6=
                                                                                    q LR (ei , g, g
                                                                                    
                                                                               1
               ^ ) for all i, j and fix w . Then, P(e) is decreasing in q over 2 , 1 if and only if
q LR (e j , g, g
              1
|D   w|       2   (|N | + 1). Otherwise, P(e) is single peaked.

    To see the intuition, it helps to consider how N B (e)     and N A (e) change as q increases.
                                                                1
Assume the true state is B and g     ^ < g. Fix some q 2 2 , 1 . Then, N B (e) contains the
agents for whom (1) q > q LR and so learn correctly, or (2) d B > d A and q < q LR and so
have µ(s· ) = 0 irrespective of the true state; N A (e) contains all agents for whom d A > d B
and q < q LR . As q increases, all agents in N B (e) will remain there: For agents in group (1)
nothing changes; agents in group (2) may stay there or pass to group (1). By contrast, agents
in N A (e) will switch to N B (e) one by one:26 When q becomes larger than q LR for an agent in
N A (e), her echo chamber no longer distorts her long-run belief, which now converges to dB .
Thus, if the eventually incorrect agents outnumber the eventually correct agents initially
(i.e., for q  1
              2 ), then as q increases it will cause a gradual migration into the set of eventually
correct agents and polarization will initially increase and then decrease towards zero.
    To recap, our results suggest that increasing the quality of first-hand information for the
agents can be a way to counteract the power of echo chambers to polarize beliefs. However,
such quality increases may need to be significant to actually curb polarization.
    Shifting perspective, one may wonder how changes in the distribution of echo chambers
in society aects the distribution of long-run beliefs and hence polarization. Propositions 5
and 6 show that the answer is not obvious--even in our stylized model--as both changes in
the echo-chamber imbalances and changes in the number of normal friends matter. Fix any q
and e such that P(e) > 0. Suppose the agents make and lose friends, which results in e0 .
By Proposition 6, if for each agent her normal friends grow su ciently more than her echo-
chamber imbalance, then P(e0 ) = 0. Thus, technology advances that expand the agents'
  25 The  same result holds for other, more general, measures of polarization, such as that axiomatized by
Esteban and Ray (1994). Applied to our long-run beliefs, their measure takes the form n1+a (1 n) + (1
n)1+a n, where n = |N A (e)|/|N |, a 2 (0, a ], and a  1.6. One can show that this form is single peaked in
n, which is key for the non-monotonicity in q.
  26 This is where we use the assumption that q ( e , g, g
                                                         ^ ) 6= q LR (e j , g, g
                                                                               ^ ) for all i, j.
                                                  LR i



                                                    17
echo chambers can curb belief polarization. But the opposite can also happen: An agent
can learn correctly in a small echo chamber, but incorrectly after her echo chamber expands,
which can cause her belief to polarize from others. Our results highlight that what matters
is the composition of echo chambers, not their absolute size. These observations may oer a
new perspective on the evidence showing that polarization seems to be more pronounced for
demographic groups that are least likley to use the Internet and social media (Zhuravskaya
et al., 2020). Their echo chambers may be smaller, but also more unbalanced.
    Our analysis also suggests that polarization in echo chambers need not lead to polariza-
tion in beliefs. Imagine two societies characterized by e and e0 , where each distribution is
evenly divided in terms of echo-chamber imbalances (i.e., |D A | = |D B | = 12 |N |). The only
                                                                     0
dierence is that, for all agents, e involves small imbalances and e large imbalances. In terms
of echo chambers, we may view e as less polarized than e0 . Yet, we can have P(e) > P(e0 ).
This may be counterintuitive, but becomes clear once we take into account the role of infor-
mation quality that we highlight, which may be high in the society with e0 and low in the
society with e. Importantly, our results provide tools to handle this complexity and predict
what happens based on the observable characteristics of a society summarized by e. Such
predictions can also guide policy interventions.
    Finally, our theory also oers insights about belief polarization in the short run. To this
end, we now interpret each i 2 N as a group of individuals who all have an echo chamber
with the same composition ei . Removing redundancies, assume ei 6= e j if i 6= j. We can
summarize the beliefs within each group with their empirical average and then use these
summary statistics to quantify intra-group polarization in society. Importantly, if group i is
large enough, its empirical average belief in the short run is well approximated by E [µ(s1 i )]
by the Law of Large Numbers. Thus, we can define short-run polarization as
                                       2
                                                  E [µ(s1    E [µ(s1
                                      |N | i, jÂ
                          PSR (e) =                     i )]       j )] .
                                               2N

Standard Bayesian learning without misperceptions implies PSR (e) = 0 (Remark 1). By
contrast, selective news sharing with misperceptions can lead to PSR (e) > 0. For instance,
Proposition 2 implies the following.27

Corollary 3. Fix any society N with echo chambers e that satisfies d Ai > d Bi and d Aj < d Bj
for some groups i, j. There always exists q > 1
                                              2 such that PSR (e) > 0.

Thus, as long as some groups of people have echo chambers with opposite imbalances, our
model can also account for belief polarization in the short run. In contrast to the long run,
where this requires low information quality, for the short run polarization can arise even for
high information quality (Propositions 1 and 2 and Corollary 1). This could cause temporary
polarization: Even if all agents eventually learn correctly, their beliefs may polarize in the
short run.
 27 The   same result holds for the general measures of polarization axiomatized by Esteban and Ray (1994).




                                                    18
5     Mitigating Polarization
Ferejohn et al. (2020) note that challenges to shaping the character of democratic institutions
include "managing the development of media and information technologies to ensure they
enhance, rather than degrade, robust pluralism and civil political engagement." We take a
step in that direction in this section.
     How could a social planner address polarization generated by shared news? Selective
sharing and misperceptions seem hard to influence, as they belong to each individual's private
life and personal freedom. It may instead be easier to influence people's echo chambers and,
in particular, the quality of their first-hand information. With regard to echo chambers,
Section 3.3 described how influencing the rate at which people connect with friends on social-
media platforms may help avoid incorrect learning and hence belief polarization.
     Acting on the quality of information seems the least intrusive intervention. One obvious
way is to directly increase q at the source. This may be di cult, however, due to technological
or economic reasons. For instance, it may involve incentivizing or forcing newspapers to
spend more on reporters, data gathering, and fact checking. Other ways may still exist to
increase the quality of information that people ultimately receive without changing q of the
primitive signals sit .
     The last decades have witnessed the expansion of so-called news aggregators, namely,
online platforms that summarize the news for their users. Examples include The Drudge
Report, Apple News, or Yahoo! News. This may have several explanations: Aggregators
may help people handle the overload of daily news given time or attention constraints, or
may help pool news from dierent sources into one convenient access point. By filtering and
summarizing news, aggregators throw away some information relative to the totality of the
aggregated signals. Nonetheless, the resulting output can have higher information quality
than each aggregated signal individually, which is the key observation for our purposes.
Through the lens of our theory news aggregators can serve another function, which is to
curb polarization by undermining the distortions of selective news sharing.28
     There are many ways to aggregate signals. To make our point we consider the following
simple form, which has the advantage that one can easily provide a su cient degree of
aggregation to ensure no polarization. Divide time into blocks of M periods, where M is an
odd number. For every agent i and t = 1, 2, . . ., define s ^iMt as a new signal that is released to
i at the end of each time block and reports whether more a or b signals realized in that block:
                                  (
                            i
                                    0, if ÂtM                        M
                                            k=(t 1) M+1 I{sik = a} < 2
                          s^ Mt =
                                    1, if ÂtM                        M
                                            k=(t 1) M+1 I{sik = a} > 2 .

         ^iMt conveys less information than do the aggregated M signals together. However,
Clearly, s
  28 Other  papers studying news aggregators in an economic context include Athey et al. (2017) and Hu
et al. (2019). Athey et al. (2017) explore experimentally the impact of news aggregators on the consumption
of news from other outlets, while the focus of Hu et al. (2019) is dierentiation between personalized news-
aggregation providers.



                                                    19
^iMt has higher quality than each sit . To see this, suppose M = 3 and w = A. We have
s
                                                              !
                                             3
                   i
                 ^3
              P (s   = 1| w = A ) = P       Â I{sik =a}      2w=A
                                            k =1
                                    = q + 3q2 (1
                                        3
                                                       q) > q = P (sit = a|w = A).
                            ^iMt worsens the quantity of information for the agents but im-
Thus, substituting sit with s
proves its quality. Note that in standard models this substitution would be irrelevant for
long-run learning.
   The remaining question is how much aggregation is enough to curb polarization. The
next proposition gives an answer in terms of a su cient finite number M of aggregated
periods.29 Let P^ be the limit polarization when signals sit are replaced with s
                                                                               ^iMt .

Proposition 8. Fix any society N with echo chambers e and information quality q such
                   ¯ LR = maxi2N q LR (ei , g, g
that P(e) > 0. Let q                                      ^ (e) equals zero if
                                               ^ ). Then, P
                                                   2 ln (1   ¯ LR )
                                                             q
                                         M>                           .
                                                     (2q     1)2

    A few remarks are in order. Note that s   ^iMt essentially reports whether the sample average
of a signals is above 12 or not. By the Law of Large Numbers, as M ! · that average is
q > 2 if w = A and 1 q < 1
     1
                                 2 if w = B with probability 1. In other words, with infinite
               ^i
aggregation, s Mt can learn the state and then report it to the agents. Clearly, this implies
correct learning, but is not how news aggregators work in reality. We can still conclude that
partial news aggregation can help curb polarization, because we showed that undoing the
eects of misperceived selective sharing in the long run does not require perfect information
quality.
    Another observation is that our aggregators summarize the primitive signals for each
individual, but have a common degree of aggregation M. Since incorrect learning is caused
by news sharing, how much we aggregate agent i's signals has to take into account the
information quality required for her friends to learn correctly. This is why our finite threshold
                                 ¯ LR of the agents for whom the eects of misperceived selective
for M is in terms of the quality q
sharing are the hardest to overcome. This is where Proposition 4 can guide how to adjust
M as echo chambers change. Also, if we knew that a subgroup of agents shares signals only
among themselves--essentially forming a sub-society N 0  N --it would be possible to pick
a lower M tailored to this group. These points suggest that if agents choose degrees of news
aggregation for themselves based on their individual reasons, they may not internalize the
eects of the news they then share and create too little aggregation from society's viewpoint.
This may call for institutional intermediaries or platforms that aggregate news taking into
account these externalities.
  29 The threshold in Proposition 8 is a conservative condition based on tail bounds for Binomial cumulative
distributions, which do not have a closed form. Numerical methods may provide tighter conditions.



                                                     20
6      Extensions: Other Misperceptions
We now consider other ways in which agents may misperceive information. This clarifies
the main mechanism through which selective news sharing can lead to polarization: the
combination of unbalanced echo chambers and incorrect interpretation of friends' silence.
    Throughout this section, the true properties of first-hand information as well as timing
remain as in the baseline model. We now assume that all agents correctly assign probability g
                                                               ^ = g) in order to isolate the
to the arrival of first-hand information in each period (i.e., g
eects of other misperceptions. We consider three:

    (I) Agents misperceive the probabilities with which friends shares signals. To model this, we
        allow for probabilistic selective sharing. Normal agents share any first-hand signal sit
        with probability n 2 (0, 1] and stay silent with probability 1 n. An A-dogmatic agent
        shares sit = b with probability f 2 [0, 1] and sit = a with probability g 2 [0, 1], where
        0  f < g  1; with the remaining probabilities, the agent stays silent. B-dogmatic
        agents are like A-dogmatic agents, except for swapping probabilities of sharing a and b
        signals. Note that our baseline model corresponds to n = g = 1 and f = 0. We
        continue to assume that all agents of a specific type are the same. Misperception (I)
        means that each agent knows all her friends' types, but replaces the true sharing
        probabilities f , g, and n with incorrect ones f^, g       ^ where f^ < g
                                                           ^ , and n            ^.

 (II) Agents misclassify some of their friends' types. With three types, there are in principle
      many possible misclassifications. For conciseness, we consider the case where dogmatic
      friends are misclassified as normal. The sharing behavior is deterministic as in the
      baseline model (n = g = 1 and f = 0). Let n    ^ A be the number of A-dogmatic friends
      that an agent misclassifies as normal; define n  ^ B similarly. That is, the agent treats
      these friends as always sharing any signal they receive, while in reality they share only
      signals favorable to one state.

(III) Agents misperceive the quality of first-hand information. Each agent thinks that the
                                                                 1
      probability with which a signal matches the state is q^ 2 2 , 1 instead of the true q
      given in equation (1). Note that this misperception diers conceptually from all other
      misperceptions considered in this paper, which are about how friends share news.
Proposition 9. Each of misperceptions (I), (II), and (III) alone can cause belief polarization
as the result of incorrect learning. This happens if and only if the true information quality q
is su ciently low and there are appropriate, real or perceived, imbalances in echo chambers.

An echo-chamber imbalance means slightly dierent things depending on the misperception
(see Online Appendix A for a detailed analysis). For (I), it means a dierent number of
A- and B-dogmatic friends as well as a dierent gap in the probabilities of sharing signals
( f g 6= f^ g^ ). For (II), it means a disagreement between the real and perceived dierence
in the number of dogmatic friends (d A d B 6= d    ^A d ^B ). For (III), it means a dierent
number of A- and B-dogmatic friends.

                                                21
    Despite the dierences between these misperceptions, they all cause incorrect learning
and polarization through the same fundamental mechanism as in the baseline model. That
is, the agents interpret silence incorrectly by misunderstanding how much of it depends
on lack rather than suppression of information. This is also the only mechanism through
which misperceptions of information quality cause polarization: If g = 1 and selective
sharing unravels, the agents always learn correctly in the long run despite q   ^ 6= q. For this
misperception to cause polarization the agents must over-estimate the information quality,
         ^ > q.
that is, q
    One may interpret the case of q   ^ > q as related to the idea of "fake news:" Such news
are false or very uninformative (low q), yet people mistakenly take them as reliable and
informative (high q ^). Our results then suggest that this form of fake news can cause incorrect
learning and polarization, but only indirectly through selective news sharing. This may
explain why, even though fake news have always existed, they may have become especially
powerful in the age of social media. This may provide a rationale for fact-checking as a way
to realign q^ with q.
    Finally, another takeaway in common with the baseline model is the role of low and
high quality in enabling and preventing polarization, respectively. This further supports our
insights about the ability to mitigate polarization by aggregating news.


7    Concluding Remarks
We studied if and when learning from shared news can lead to belief polarization. Our
positive answer is consistent with some common narratives about news sharing, yet highlights
several qualifications. Selective sharing alone does not lead to polarization, even if it gives
rise to unbalanced news diets. It has to be combined with some misperception that causes
people to misinterpret when others do not share information. Moreover, this key mechanism
leads to polarization if (and only if) the quality of first-hand information is su ciently low.
Our insights about the importance of information quality (in contrast to quantity) and echo-
chamber imbalances shed light on how policies that aim to improve news quality or diversify
people's diet of shared news can curb or inflate polarization. We hope this advances our
understanding of some of the mechanisms behind polarization in modern societies.
    Our analysis goes to the heart of why new communication technologies and formats en-
abled by the Internet may contribute to polarization. First, the dramatic expansion of com-
munication between people may have increased the consumption of selected second-hand
news (e.g., on social media). Second, the quality of consumed information may have wors-
ened: Tweets and social-media posts tend to be short and imprecise, and overwhelmed by
the information abundance, people may spread their limited attention across more sources
and hence absorb less content from each. Third, the Internet has oered bad actors a mega-
phone to spread fake news, and we found that it is the selective sharing of fake news--not
fake news per se--that can distort beliefs. However, our results suggest that even in the ab-
sence of fabricated news, specific aspects of how people share and process information online


                                              22
would still cause polarization. To the extent that its causes are legitimate behaviors within
people's rights to free speech and self-determination, our analysis oers a new perspective
on whether the Internet--and in particular social media--may be held accountable for po-
larization and what regulations may address it.
    While we focused on mitigating polarization, our theory also sheds light on how malev-
olent actors can leverage news sharing among people and misperceptions to exacerbate po-
larization. Obvious ways include using fake news to directly lower information quality or
expanding echo chambers' imbalances. A more subtle way is to release bits of true but low-
quality news with high frequency (like Tweets) so as to leverage the power of misperceived
selective sharing. This may also serve to draw attention away from high-quality information
sources. A better understanding of what malevolent actors may try to do could oer guide-
lines for preemptive countermeasures.
    Several directions remain for future research. We briefly mention two. We took selective
news-sharing behavior as given and fixed, modeling its key aspects found in the empirical
evidence. In reality, people choose what to share strategically--for example, to persuade
friends to take an action. As long as it involves suppressing specific information, our insights
about its consequences should be valid and may in turn be a steppingstone to understanding
what drives selective sharing in the first place.
    Finally, the role of unbalanced echo chambers in our analysis begs the question of what
happens if we allow social links to form endogenously. In this process, people may follow
their demand for information or other socio-economic forces (identity, class, race, ideology,
work career, etc.).30 On the one hand, they may tend to link with like-minded friends, which
may create a vicious cycle where belief polarization and echo chambers' imbalances reinforce
each other. On the other hand, they may be more likely to link with reliable sources of
objective information, which would have opposite implications. Which tendency prevails is
ultimately an empirical question. We hope our framework can guide further theoretical and
empirical investigations of the relation between evolving social relations and polarization.


    Renee Bowen, UC San Diego and NBER
    Danil Dmitriev, UC San Diego
    Simone Galperti, UC San Diego




  30 Recentstudies on homophily in social networks include, for example, Golub and Jackson (2012), Baccara
and Yariv (2013), and Halberstam and Knight (2016).


                                                   23
                                                     Appendix
A       Proof of Proposition 1
Consider an agent with n normal friends and d dogmatic friends of each type.
    Without loss of generality, we can ignore the normal friends and assume that n = 0. Using
the Law of Total Expectation, we can rewrite E [µ] as a sum over all possible signal realizations
of dogmatic friends, where in each term we have the expected posterior conditional on a given
signal realization. The remaining uncertainty in this conditional posterior are signal realizations of
normal friends. Since the agent is not misspecified with respect to them, the expectation of that
conditional posterior must be equal to the "prior." That is, it equals the posterior updated only
on the signals of dogmatic friends. Hence, we can focus on the dogmatic friends.
    Let a A be the number of signals s = a that the A-dogmatic friends receive, and bB be the
number of s = b that the B-dogmatic friends receive. Denote s = { a A , bB }. Given the correct g,
the posterior that w = A is
                                                                p P  (s| A )
                                        µ  (s) =                                     ,
                                                     p P  (s| A ) + (1 p )P  (s| B )
where
                            d!d!
P  (s| A ) =                                     g a A + b B q a A (1    q ) b B ( g (1   q ) + (1   g))d      aA
                                                                                                                    ( g q + (1   g))d   bB
                                                                                                                                             ,
               a A !(d   a A )!bB !(d    bB )!
                            d!d!
P  (s| B ) =                                     g a A + b B (1     q ) a A q bB ( g q + (1   g))d   aA
                                                                                                          ( g (1     q ) + (1    g))d   bB
                                                                                                                                             .
               a A !(d   a A )!bB !(d    bB )!
                    ^ , the agent's posterior belief given s will be
Given the incorrect g
                                                                 p P (s| A )
                                         µ (s) =                                    ,                                               (4)
                                                      p P (s| A ) + (1 p )P (s| B )
where P (s| A) and P (s| B) are calculated replacing g with g^ . To understand each term consider
P (s| A), which is the conditional probability of observing s given w = A. Then, (gq) a A is the
  

probability of getting a A signals s = a from A-dogmatic friends; (g(1 q))bB is the probability of
getting bB signals s = b from B-dogmatic friends; (gq + (1 g))dB bB is the probability of observing
d B bB B-dogmatic friends staying silent, as it is either a genuine silence (with prob. 1 g) or a
suppressed signal s = a (with prob. gq); (g(1 q) + (1 g))d A a A is the probability of observing
d A a A A-dogmatic friends staying silent, as it is either a genuine silence (with prob. 1 g) or
a suppressed signal s = b (with prob. g(1 q)). For P  (s| B), the probabilities q and 1 q are
reversed because the true state is B.
    Consider the expectation of the dierence between µ and µ:
                E [µ     µ ] =   Â ( p P  (s| A ) + (1             p )P  (s| B)) (µ(s)         µ (s))
                                 s
                                                                                                                           
                                              P (s| A ) p P  (s| A ) + (1                        p )P  (s| B )
                             = Â p P (s| A )
                                         
                                                         ·                                                             1
                               s              P  (s| A ) p P (s| A ) + (1                        p )P (s| B )
                                                                       
                                              1 + r Q a A bB G a A bB
                             = Â p P (s| A )
                                    
                                                                      1 ,
                               s
                                                             ^ a A bB
                                              1 + r Q a A bB G

                                                                    24
where
                      1       q          g (1 q ) + (1 g ) ^   ^ (1 q ) + (1 g
                                                               g               ^)      1 p
               Q=                 , G=                    , G=                    , r=     .                                        (5)
                          q                 g q + (1 g )          g^ q + (1 g
                                                                            ^)          p
Using the expression of P  (s| A), we can write
                                                                                                                                 
    E [µ µ ] = p Â a A ,bB a !(dd! a )! · b !(dd! b )! g a A +bB q a A +bB (g(1 q) + (1 g))2d a A bB
                                A         A       B         B
                                                   bB                                                                       
                                                            g(1 q)+(1 g) bB d 1+r Q a A bB G a A bB
                                       1qq                    gq+(1 g)                                       ^ a A bB
                                                                                              1+ r Q a A b B G
                                                                                                                          1
                                                                                                                                 
                = p Â a A ,bB a A !(dd! a A )! · bB !(dd! bB )! g a A +bB q a A +bB (g(1 q) + (1 g))2d a A bB
                                                            b b                                                    
                                                                 B G B +r Q a A G a A
                                                 G d Q        QbB G^ bB +r Q a A G
                                                                                 ^ aA Q  bB G^ bB      Q bB G bB
                                                                                                                                
                                                          !d!
                  = p G d Â0xyd x!(d xd                 )!y!(d y)!
                                                                      g x + y q x + y ( g (1      q )  +   ( 1     g  )) 2d x y     (6)
                                       y y                                                                                   
                                             G +r Q G x y ^ y
                                                      x                                  x x
                                                                           y Gy + Q G +r Q G Q x G
                                                                                                    y y
                                   Q     Qy G^ y +r Q x G
                                                        ^x  Q   G        Q             Qx G^ x +r Qy G^y
                                                                                                               ^ x    Q  x Gx .


The key is that while the original distribution P  (s| A) is not symmetric between a A and bB , the
last line involves a symmetric distribution between x and y. We want to prove that the sum in (6)
is negative for r > 1, which will imply E [µ µ ] < 0 for p < 1  2.
    Consider the derivative with respect to r of the term in the second line of (6), denoted by D xy :
                          D xy                ^ y Gy G
                                 Q x +y ( G x G      ^ x ) y y Q x +y ( Gy G
                                                                           ^ x Gx G ^ y) x x
                               =                          Q ^ +
                                                            G                             ^ ,
                                                                                        Q G
                          r            ^ y + rQx G
                                  ( Qy G          ^ x )2        (Qx G ^ x + r Qy G
                                                                                 ^ y )2
which is negative if and only if
                                      Gx G^ y Gy G
                                                 ^x        y ^y     Gx G^ y Gy G^x
                                                         Q  G   <                          ^ x.
                                                                                        Qx G
                                        ^ y + rQx G
                                   ( Qy G         ^ x )2              ^ x + r Qy G
                                                                  (Qx G          ^ y )2

Recall that y x. Note that G x G^ y Gy G^ x > 0 if and only if G
                                                               ^ y x > Gy x . If y = x, this holds with
equality and the derivative above is 0. If y > x, G^ y x > Gy x is equivalent to G^ > G, which in turn
                 ^ < g. From here on, we assume y > x.
is equivalent to g
    Suppose g ^ < g. Then the derivative of D xy is negative if and only if
                                                     ^y
                                                  Qy G                      ^x
                                                                         Qx G
                                                                <                       .
                                               ^ y + rQx G
                                          ( Qy G         ^ x )2       ^ x + r Qy G
                                                                  (Qx G          ^ y )2
           ^ < 1, which implies ( QG
Note that QG                       ^ )y < ( QG  ^ ) x . Using this, we can obtain the equivalent
inequality
                      (2 (1 + r)2 )( QG^ ) x+y < r2 (( QG^ )2 x + ( Q G
                                                                      ^ )2y )
For r > 1, this inequality holds, as the left side is negative and the right side is positive. Given
that this holds for any x < y, it follows that the derivative of the entire sum in (6) is negative for
r > 1. Note that this sum is equal to 0 (term by term) at r = 1. This implies that the sum becomes
negative for all r > 1 as desired. In other words, given g ^ < g, moving the prior from 50-50 towards
a state will make the unconditional expected posterior of that state higher than the prior.
       ^ > g holds, than the argument above applies in a symmetric way with all inequalities flipping
    If g
                      ^ y Gy G
after dividing by G x G       ^ x , which is negative. It will follow that moving the prior from 50-50
towards a state will make the unconditional expected posterior of that state lower than the prior.

                                                                   25
B      Proof of Proposition 2
We will prove that there exists qSR > 1                         1
                                        2 such that, if q 2 2 , qSR , then E [ µ | w ] > p or E [ µ | w ] < p
for any w depending on the signs of d A d B and g g      ^ . To this end, we will first find the derivative
                                      1
of E [µ|w ] with respect to q at q = 2 and then show how its sign depends on d A d B and g g                ^.
                                                                                 1
Using continuity of E [µ|w ] in q and the fact that E [µ|w ] = p at q = 2 , we will obtain the desired
conclusion.
    Using (4) and (5), for a given realization s = ( a A , bB , a N , b N ), an agent's posterior that w = A
can be written as
                                                        p
                                     µ (s) =                           .
                                              p + (1 p ) Q M G     ^S

    To compute E [µ|w ], it is useful to use iterated expectations and condition on the set of friends
who receive a signal. Let E [µ|w , x A , x B , x N ] be the expected posterior conditional on the event
that the state is w and that x A A-dogmatic friends, x B B-dogmatic friends, and x N normal friends
received a signal. For simplicity, x N includes the agent's own signal. Abusing notation a bit, let
N = n + 1. We can then write
                          dA      dB          N
                                                                                 d A !d B ! N !
          E [µ|w ] =      Â Â Â                    x A !(d A           x A )! x B !(d B x B )! x N !( N                      x N )!
                                                                                                                                       ·
                        x A =0 x B =0 x N =0

                                                   · g x A + x B + x N (1              g )d A +d B + N     x A xB x N
                                                                                                                             E [µ|w , x A , x B , x N ] .

The derivative of E [µ|w ] with respect to q is
                        dA       dB       N
                                                                              d A !d B ! N !
     q
       E [µ|w ] =      Â Â Â                      x A !(d A         x A )! x B !(d B x B )! x N !( N                      x N )!
                                                                                                                                   ·
                      x A =0 x B =0 x N =0                                                                                                                            (7)
                                                       x A +xB +x N                      d A +d B + N x A x B x N          
                                                  ·g                   (1           g)                                       E [µ|w , x A , x B , x N ] .
                                                                                                                           q

We now find     q E [ µ | w , x A , x B , x N ]
                
                                                       and evaluate it at q = 1
                                                                              2.

Lemma 1.
                                                         xN                                    xN
                                                                         xN !                 1   
       q
         E [µ|w , x A , x B , x N ]
                                          q= 1
                                                  =      Â       a N !( x N a N )!            2   q
                                                                                                    E [µ| a N , w , x A , x B , x N ]
                                                                                                                                                           q= 1
                                                                                                                                                                  .
                                             2          a N =0                                                                                                2


Proof. Letting H (q; A) = q and H (q; B) = 1                                       q, we can write
                                  xN
                                                  xN !
  E [µ|w , x A , x B , x N ] =    Â       a N !( x N a N )!
                                                            H ( q; w ) a N (1                          H (q; w )) x N        aN
                                                                                                                                  E [µ| a N , w, x A , x B , x N ] .
                                 a N =0

The derivative of E [µ|w , x A , x B , x N ] can thus be represented as
                                                                              h
                                       xN                         xN !                                 1 (1
         E [µ|w , x A , x B , x N ] = Âa N =0             a N !( x N a N )!
                                                                                  a N H ( q; w ) a N          H (q; , w )) x N             aN
       q
                                                                                                                  i
                                                  (xN       a N ) H ( q; w ) a N (1       H (q; w )) x N   aN 1       Hq (q; w )E [µ| a N , w , x A , x B , x N ] +
                                          xN                    xN !
                                       + Âa N =0        a N !( x N a N )!
                                                                          H ( q; w ) a N (1      H (q; w )) x N       a N  E µ| a , w , x , x , x
                                                                                                                          q [    N       A B N]              .

                                                                                    26
If q = 1                             1
        2 , then H ( q; w ) = 2 for each w . Also, the agent will not update her prior based on any
signals: E [µ| a N , w , x A , x B , x N ] = p . The above expression thus simplifies to

                                                                                              1 xN 1
                  E [µ|w , x A , x B , x N ]                    x
                                                             = Âa  N
                                                                   N =0
                                                                                  xN !
                                                                                              2         (2 a N     x N ) Hq   1
                                                                                                                              2; w   p+
                q                                  q= 1
                                                      2
                                                                          a N !( x N a N )!


                                                                  xN                 xN !           1 xN 
                                                               + Âa N =0     a N !( x N a N )!      2    q E [ µ | a N , w , x A , x B , x N ]          .
                                                                                                                                                 q= 1
                                                                                                                                                    2


Note that                                                                  xN
                                        xN                                                    1
                                                      xN !                1
                                    Â         a N !( x N a N )!           2
                                                                                                  (2 a N         x N ) = 0,
                                   a N =0

because for each positive term in the sum there is an identical term with a negative sign. We can
then write
                                             xN                        xN
                                                           xN !        1  
         E [µ|w , x A , x B , x N ]      =   Â                              E [µ| a N , w , x A , x B , x N ]      .
      q                             q= 1
                                       2   a N =0 a N ! ( x N   a N )! 2  q                                   q= 1
                                                                                                                 2


                                                                                                                                                                       

                                   q E [ µ | a N , w , x A , x B , x N ]
                                   
    It remains to evaluate                                                                    . The following is a first intermediate step.31
                                                                                      q= 1
                                                                                         2


Lemma 2.
                                        j               k
                                            x A +xB 1

                                                                                                                                                                          
                                                 2
                                                                   ( x A + x B )!
q
  E [µ| a N , w , x A , x B , x N ] =         Â             a D !( x A + x B a D )! q
                                                                                      f ( a D , q, a N ) + f ( x A + x B                                    a D , q, a N ) ,
                                             a D =0

where
                                                     p H (q; w )k (1 H (q; w )) x A + xB k
                           f ( k , q, a N ) =                                                                                    .
                                                                                ^ k x B (d A
                                                  p + (1 p ) Q k x B +2 a N x N G                                         dB )


Proof. Let a D  x A + x B be the total number of s = a that A- and B-dogmatic friends have
received. Using a B = x B bB and b N = x N a N , we can write
                                                                                     p
                             µ=
                                    p + (1              p )QaD                     ^ aD x A (d A x A )+(dB xB )
                                                                    x B +2 a N x N G


Note that µ includes the dogmatic friends who have not received a signal (d A x A A-dogmatic
and d B x B B-dogmatic), as the agent does not know whether they did not get a signal or they
suppressed it. Using this, we can obtain
                                                  "
                                          x A +xB
                                                            ( x A + x B )!
       E [µ| a N , w , x A , x B , x N ] = Â                                       H (q; w ) aD (1 H (q; w )) x A + xB aD
                                           a D =0   a D ! ( x A  + x B     a D ) !
                                                                                                                     #
                                                                                      p
                                                     ·                                                                 .
                                                       p + ( 1 p ) Q a D x B +2 a N x N G       ^ a D x B (d A d B )

  31 The   symbol b x c denotes the largest integer smaller than x.


                                                                              27
Using binomial symmetry, we get
                                              j               k
                                                  x A +xB 1
                                                       2
                                                                         ( x A + x B )!                                                                                    
E [µ| a N , w , x A , x B , x N ] =                 Â             a D !( x A + x B a D )!
                                                                                           f ( a D , q, a N ) + f ( x A + x B                                a D , q, a N ) ,
                                                   a D =0

where f (k, q, a N ) is as defined in the lemma. Taking the derivative with respect to q gives the
result.                                                                                         

                                                                                                       q E [ µ | a N , w , x A , x B , x N ]
                                                                                                       
     The next is a second intermediate step to evaluate                                                                                                       .
                                                                                                                                                       q= 1
                                                                                                                                                          2


Lemma 3. At q = 1
                2,

                                                                      
                     f D
                      ( a , q , a N ) + f ( x A + x B a D , q , a N )
                   q
                      x A +xB 1                   
                     1                                                  2                                                                     ^
                                                                                                                                             2g
                   =                 2p (1 p ) 2(2 a N x N ) +              (x A                                        xB )                          (d A         dB ) .
                     2                                                 2 g^                                                              2        ^
                                                                                                                                                  g
                                                            ^ ) [ln( Q)]                                                           1
                                                   ^ ) = ln(G
Proof. To simplify subsequent algebra, define z(q, g                                                                                   . Taking the derivative of
f (k, q, a N ) with respect to q gives
                                                                                      p
               f ( k , q, a N ) =                                                                                             ·
             q                    p + (1                                                               ^)
                                                              p ) Qk xB +2a N x N +(k xB (d A dB ))z(q,g
                                                                                                                                                                                    
                       ·      (x A + xB    k ) H ( q; w ) k (1       H (q; w )) x A + xB    k 1    Hq (q; w ) + kH (q; w )k       1 (1       H (q; w )) x A + xB     k H ( q; w )
                                                                                                                                                                        q


                           + H ( q; w ) k (1             H (q; w )) x A + xB          k p (1       p )·
                           "
                                                                                            ^) 1
                              (k   d B +2a N x N ) Qk x B +2a N x N 1+(k x B (d A d B ))z(q,g
                                                                                               q2
                       ·                                                               2                     +
                                      ( p +(1 p ) Qk x B +2a N x N Gk x B (d A d B)               )
                                                                                                                          ^)
                                                                                   x B +2a N x N +(k x B 1 (d A d B ))z(q,g                          ^ )g
                                                                                                                                                  (2 g  ^            #
                              (k     xB           (d A        d      B)) Qk                                                                    ^ q+(1 g
                                                                                                                                              (g        ^ ))2
                       +                                                                                                                                                 ,
                                                          p + (1            p ) Qk         x B +2 a N x N G k x B ( d A d B ) 2


which evaluated at q = 1 2 equals
               x A +xB 1
                1                                         p
                            (2k x A x B ) Hq (q; w )
                2                                    p + (1 p )
                 x A +xB                                                           ^
                  1                     (k x B + 2a N x N ) + (k x B (d A d B )) 2 g ^
                                                                                     g
              +             4p (1 p ) ·                                2
                  2                                       (p + (1 p ))
                               h
                  1 x A +xB 1
              = 2             · (2k x A x B ) Hq (q; w )p
                                                                             i
                                                                         ^
                +2p (1 p ) (k x B + 2a N x N ) + (k x B (d A d B )) 2 g    ^
                                                                           g   .

                                       1
     Therefore, at q =                 2   we have
                                                                                                                                                                                    
                                                                          1 x A +xB 1
   
   q   ( f ( a D , q, a N ) + f ( x A + x B        a D , q, a N ))   =    2           2p (1           p ) 2(2 a N    xN ) +    2
                                                                                                                              2 g^ (x A           xB )         ^
                                                                                                                                                              2g
                                                                                                                                                             2 g ^   (d A    dB )      .

                                                                                                                                                                                           

                                                                                            28
                                            q E [ µ | w , x A , x B , x N ]
                                            
   We now further simplify                                                                      .
                                                                                         q= 1
                                                                                            2

Lemma 4.
                                                                               4p (1 p )
                       E [µ|w , x A , x B , x N ]                      =                 (( x A                    xB )      ^ (d A
                                                                                                                             g               d B )) .
                     q                                          q= 1
                                                                   2
                                                                                 2 g ^
Proof. From Lemma 2 and 3 we have
                                                           j               k
                                                               x A +xB 1
                                                                    2                ( x A + x B )!        1 x A +xB 1
   E [µ| a N , w , x A , x B , x N ]                = Â a D =0                 a D !( x A + x B a D )!     2           2p (1                 p )·
 q                                        q= 1
                                             2
                                                                                                                                                                       
                                                                                                                                                                 ^
                                                        · 2(2 a N              xN ) + (x A               xB ) + (x A            xB         2( d A       d B )) 2 g ^
                                                                                                                                                                   g

                                                                                                          4p (1 p )
                                                    = 4p (1            p )(2a N             xN ) +                  (( x A                   xB )        ^ (d A
                                                                                                                                                         g             d B )) .
                                                                                                            2 g ^
The second equality follows from observing that the sum
                                           j               k
                                               x A +xB 1
                                                    2                                                   x A +xB             1
                                                                      ( x A + x B )!                   1
                                                    Â          a D !( x A + x B a D )!                 2
                                                a D =0
                                                         x A +xB
is a binomial expansion of 1   1
                           2 + 2                                    = 1.
    Using Lemma 2, we then have
                                                                                                                    h
                                                                   xN                      xN !           1 xN
                 E [µ|w , x A , x B , x N ]                     = Âa N =0          a N !( x N a N )!      2             4p (1      p )(2a N             xN )
               q                                        q= 1
                                                           2
                                                                                                                                        i
                                                                    + 4p2
                                                                        (1 p )
                                                                          g^   (( x A                  xB )        ^ (d A
                                                                                                                   g             d B ))
                                                                    4p (1 p )
                                                                =             (( x A                      xB )          ^ (d A
                                                                                                                        g             d B )) ,
                                                                      2 g ^
                                                  xN                                                         xN !
where the equality follows from the symmetry of Â a N =0                                             a N !( x N a N )!
                                                                                                                       (2 a N          x N ) we used before.                  

   Finally, we return to the derivative of E [µ|w ]. Using Lemma 4, equation (7) simplifies to
                                     dA         dB       N
                                                                                               d A !d B ! N !
        q
          E [µ|w ]
                        q= 1
                               =    Â Â Â                        x A !(d A           x A )! x B !(d B x B )! x N !( N x N )!
                                                                                                                              gx A +xB +x N ·
                           2       x A =0 x B =0 x N =0
                                                                                                                                           
                                                                                            4p (1 p )
                                      g )d A +d B + N x A x B
                                   · (1                                              xN
                                                                                                                           ^ (d A d B ))
                                                                                                              (( x A x B ) g
                                                                                                 2 g   ^
                                              "
                                 4p (1 p ) d A                dA!
                               =
                                   2 g  ^         Â x A ! ( d A x A ) ! g x A (1                                    g)d A        xA
                                                                                                                                      xA
                                                x A =0
                                                                                                                                                  #
                                               dB
                                                            dB !
                                            Â        x B !(d B x B )!
                                                                      g x B (1                      g)dB      xB
                                                                                                                   xB      ^ (d A
                                                                                                                           g               dB )
                                           x B =0
                                 4p (1 p )
                               =           [E [ x A ] E [ x B ] g   ^ (d A                                    d B )]
                                   2 g ^
                                 4p (1 p )
                               =           (d A d B )(g g      ^ ).
                                   2 g ^

                                                                                    29
    Thus, if d A > d B and g > g   ^ , then the derivative is positive, which means that E [µ|w ] is
                                                        ^ > g, then the derivative is negative, which
distorted towards A for low q. If instead d A > d B and g
means that E [µ|w ] is distorted towards B for low q.


C      Proof of Proposition 3
Recall that agent i has d A A-dogmatic, d B B-dogmatic, and n normal friends and that d A > d B .32
   Given T periods, denote the number of signals s = a received by

    · agent i as ai ,

    · A-dogmatic friend j of agent i as a jA , j 2 {1, 2, . . . , d A },

    · B-dogmatic friend j of agent i as a B
                                          j , j 2 {1, 2, . . . , d B },

    · normal friend j of agent i as a N
                                      j , j 2 {1, 2, . . . , n }.

Denote the number of signals s = b received by

    · agent i as bi ,

    · A-dogmatic friend j of agent i as b jA , j 2 {1, 2, . . . , d A },

    · B-dogmatic friend j of agent i as b jB , j 2 {1, 2, . . . , d B },

    · normal friend j of agent i as b jN , j 2 {1, 2, . . . , n}.

Then, the number of no-signal arrivals for the same agents is given by

    · (T     ai     bi ) for agent i,

    · (T     a jA   b jA ) for A-dogmatic friend j of agent i, j 2 {1, 2, . . . , d A },

    · (T     aB
              j     b jB ) for B-dogmatic friend j of agent i, j 2 {1, 2, . . . , d B },

    · (T     aN
              j      b jN ) for normal friend j of agent i, j 2 {1, 2, . . . , n}.

Over the T periods, i's A-dogmatic friend j stayed silent bjA times, whereas her B-dogmatic friend k
               B times.
stayed silent ak
    Agent i's posterior satisfies
                                                            p
                                        µ (s T ) =                     ,
                                                                    ^S
                                                     p + (1 p ) Q M G
  32 Our argument relates to that in Berk's (1966) main characterization result. We provide a direct proof,
as this helps us show the dependence of the limit beliefs on the parameters of interest in this paper.




                                                          30
where
                                                                   n                             dA                dB
                                M = ( ai             bi ) + Â ( a N
                                                                  j                b jN ) + Â a jA                 Â bjB ,
                                                               j =1                              j =1              j =1
                                             dB                         dA
                                S =         Â (T          b jB )       Â (T            a jA ).
                                            j =1                       j =1

Thus, plimT !· µ(sT ) = 1 (resp. plimT !· µ(sT ) = 0) if and only if Q M G ^ S converges to zero
                                                                ^ S converges to · (resp. +·)
(resp. +·) with probability 1 as T ! · or, equivalently, ln Q M G
with probability 1 as T ! ·. Using z(q, g              ^
                                            ^ ) = ln(G)[ln( Q)] 1 , we can write ln Q M G ^ S as
                   ^ ), where
ln( Q)K (x, T ; q, g
                                                                              n                           dA                 dB
                                     ^ ) = ( ai
                        K (x, T ; q, g                        bi ) + Â ( a N
                                                                           j                b jN ) + Â a jA                 Â bjB
                                                                            j =1                          j =1              j =1
                                                                                                                   !
                                                             dB                          dA
                                                     +      Â (T              b jB )     Â (T             a jA )               ^ ),
                                                                                                                        z ( q, g
                                                            j =1                         j =1

and
                                                                           A A dA               B B dB
                                 x = ( a i , bi , ( a N     N n
                                                      j , b j ) j =1 , ( a j , b j ) j =1 , ( a j , b j ) j =1 ).

Given ln( Q) < 0, we require that K (x, T ; q, g^ ) converge to +· (resp.                                                    ·) with probability 1 as
T ! ·. Note that                                                            
                                                            K (x, T ; q, g)
                                            ^ ) = lim T
                           lim K (x, T ; q, g                                .
                          T !·                     T !·           T
Using H (q; A) = q and H (q; B) = 1                   q, by the Law of Large Numbers we have
                                                                                                      n
                          ^)
             K (x, T ; q, g
      plim                      = ( g H ( q; w )            g (1         H (q; w ))) + Â (g H (q; w )                              g (1       H (q; w )))
      T !·         T                                                                               j =1
                                          dA                           dB
                                      + Â g H ( q; w )                 Â g (1           H (q; w )) +
                                          j =1                         j =1
                                                                                                                                      !
                                               dB                                                 dA
                                      +      Â (1         g (1          H (q; w )))              Â (1            g H (q; w ))                    ^)
                                                                                                                                          z ( q, g
                                             j =1                                                j =1
                                =                             ^ ))d B ) (d A d B )z(q, g
                                       g (1 + n + (1 + z ( q, g                        ^) +
                                                                                
                                      +g 2(1 + n) + (d A + d B )(1 + z(q, g ^ )) H (q; w ).

                                      ^ ) = +· (resp.
    Given this, plimT !· K (x, T ; q, g                                            ·) if and only if this last expression is positive
(resp. negative), which is equivalent to
                                                            1     ((2 g)z(q, g ^ ) g) (d A d B )
               H (q; w ) > (resp. <) t (q) =                  +                                          .                                                  (8)
                                                                                                   ^ )))
                                                            2 2g (2(1 + n) + (d A + d B )(1 + z(q, g
Note that
                                            1                      (g^ g) (d A d B )
                         lim t (q) =          +                                                    ,
                         q! 1
                            2
                                            2 g (2            ^ )(2(2 g
                                                              g        ^ )(1 + n) + 2(d A + d B ))

                                                                         31
                                            1         g(d A d B )
                           lim t (q) =        +                            2 (0, 1).
                           q !1             2 2g (2(1 + n) + (d A + d B ))
In Online Appendix B, we show that t (q) is decreasing and concave for q 2 1                 0 1
                                                                                2 , 1 and t 2 = 0.
    There are two cases to consider. Suppose w = B and hence H (q; B) = 1 q. If g          ^ < g, con-
                                       1
dition (8) holds with ">" at q = 2 and with "<" at q = 1. Given the aforementioned prop-
erties of t (q), there exists a unique q LR 2 1                              T
                                                2 , 1 such that plimT !· µ (s ) = 1 if q < q LR and
                                       ^ > g, condition (8) holds with "<" at q = 1
plimT !· µ(sT ) = 0 if q > q LR .33 If g                                            2 and hence at all
      1                                                             T                   1
q 2 2 , 1 by the properties of t (q). It follows that plimT !· µ(s ) = 0 for all q 2 2    ,1 .
   Now suppose w = A and hence H (q; A) = q. If g         ^ < g, condition (8) holds with ">" at q = 1       2
and hence at all q 2 1   2 , 1 by the properties of  t ( q ) . It follows that plim T ! · µ ( s T ) = 1 for all

q 2 1            ^ > g, condition (8) holds with "<" at q = 1
      2 , 1 . If g                                                     2 and with ">" at q = 1. By the
                                                   1
properties of t (q), there exists a unique q LR 2 2 , 1 such that plimT !· µ(sT ) = 0 if q < q LR and
plimT !· µ(sT ) = 1 if q > q LR .


D          Proof of Proposition 4
Assuming d A > d B , we prove that q LR is increasing in d A and g and decreasing in d B , n and g   ^.
The case of d A < d B follows similarly.
   Consider the case of w = B and g   ^ < g. The value of q LR is the unique fixed point that satisfies
                                                                                ^)
                                                                          z ( q,g
                                                              ^ ))d B +
                                          1 + n + (1 + z ( q, g               g (d A     dB )
                            1        q=                                                           ,
                                                                               ^ ))
                                              2(1 + n) + (d A + d B )(1 + z(q, g

or equivalently
                                     1                         ^ )) (d A d B )
                                             ( g (2 g ) z ( q, g
                                q      =                                                                          (9)
                                     2   2g (2(1 + n) + (d A + d B )(1 + z(q, g^ )))
                                                                                  ^ , which implies that
The right-hand side of the latter condition is strictly decreasing in d B , n and g
q LR is also decreasing in these variables. Since the right-hand side is increasing in g, so is q LR .
Finally, one can show that the derivative of the right-hand side of the former condition with respect
to d A equals

                (2              ^)
                     g ) z ( q, g      g (1 + z2 ( q, g
                                                      ^ )) d B + (1 + n) ((1 g)z(q, g
                                                                                    ^)                g)
                                                                              2
                                                                                                           < 0,
                                     g(2 + 2n + (d A + d B )(1 + z(q, g ^ )))

where the inequality follows from (2 g)z(q, g      ^ ) < g < g (1 + z2 ( q, g
                                                                            ^ )) and (1 g)z(q, g
                                                                                               ^ ) < g.
This implies that q LR is increasing in d A .
   Now consider the case of w = A and g       ^ > g. The value of q LR is determined by the equation
                                                                             ^)
                                                                       z ( q,g
                                                           ^ ))d B +
                                       1 + n + (1 + z ( q, g               g (d A      dB )
                                q=                                                            .
                                                                            ^ ))
                                           2(1 + n) + (d A + d B )(1 + z(q, g
  33 For q = q LR , plimT !· µ(sT ) may not be unique, consistent with Berk's (1966) discussion of his asymp-
totic carrier set A0 when this contains more than one point.


                                                           32
We can rewrite it as
                                  1       ((2 g)z(q, g ^ ) g) (d A d B )
                             q      =                                            .                                         (10)
                                  2                                        ^ )))
                                      2g (2(1 + n) + (d A + d B )(1 + z(q, g
By similar arguments, the right-hand side of the former condition is increasing in d A ; the right-
                                                                                             ^ . The
hand side of the latter condition is strictly decreasing in n, d B , and g and increasing in g
properties of q LR follow similarly.


E       Complete Proposition 5 and its Proof
While Proposition 5 focused on the case l A d A > l B d B , we state and prove a more general result
that also covers the case l A d A < l B d B .

Proposition 10. Fix any agent with echo chamber e = (d A , d B , n) that satisfies d A > d B and
n 1. For any other echo chamber e0 = (l A d A , l B d B , l N n) with l N 0, l A 0 and l B 0, we
                 ^ ) < q LR (e0 , g, g
have q LR (e, g, g                   ^ ) if
                                                     
                          |l A d A l B d B |       1         d d      1
           lN 1 +                            1  1+     + A B · · J( d A , d B , g
                                                                                ^ , l A , l B ), (11)
                                d A dB             n       d A dB n
where
                                        8   n                            o
                                        <max (l A l B ) 2 , (l A l B ) , if l A d A > l B d B
                                            n          2 g^                        o
                       ^ , l A , lB ) =
        J( d A , d B , g
                                        :max l B dB l A d A   2
                                                                  ,  l B
                                                                         dB
                                                                            l A
                                                                                dA
                                                                                     , otherwise.
                                                 dA      dB  2 g^        dA     dB

Proof. We need to consider the fixed-point condition that defines q LR , which is (9) or (10) depending
on which state results in incorrect learning.

        ^ < g. Suppose l A d A
Case 1: g                           l B d B > 0. Then incorrect learning can occur in state B under
both the original and the new echo chamber. A su cient condition for q LR (e, g, g^ ) < q LR (e0 , g, g
                                                                                                      ^)
is the following: 34


     ( g (2 g ) z ( q, g ^ )) (l A d A l B d B )                                   ^ )) (d A d B )
                                                                 ( g (2 g ) z ( q, g
                                                          <                                           ,             for all q.
  2(1 + l N n) + (l A d A + l B d B )(1 + z(q, g ^ ))                                            ^ ))
                                                                2(1 + n) + (d A + d B )(1 + z(q, g

Given g^ < g, one can show that g (2 g)z(q, g
                                            ^ ) > 0 for all q. Using this and rearranging, the
previous condition becomes
                                             
                       l A d A lB dB       1      (l                               ^ )) 1
                                                         l B ) d A d B (1 + z ( q, g
           lN > 1 +                  1  1+      + A                                    · .
                          d A dB           n                (d A d B )                  n
                                                   ^
                                                   g
           ^ ) takes values between 0 and
Since z(q, g                                      2 g^,   we obtain the su cient condition
                                                                       
                 lAdA     lB dB               1          d A dB  1                                 2
  lN > 1 +                          1      1+        +          · · max (l A            lB )               , (l A     lB ) .
                   dA     dB                  n        d A dB n                                2       ^
                                                                                                       g
  34 Note                  ^ ) > q LR (e0 , g, g
          that q LR (e, g, g                   ^ ) if the opposite inequality holds, which happens if l A = l B = l N
for instance.


                                                           33
    Now suppose l A d A l B d B < 0. In this case, incorrect learning occurs in state B for the
                                                                              ^ ) < q LR (e0 , g, g
original echo chamber and state A for the new echo chamber. Then, q LR (e, g, g                   ^ ) if
the following holds:
     ((2 g)z(q, g  ^ ) g) (l A d A l B d B )                                   ^ )) (d A d B )
                                                             ( g (2 g ) z ( q, g
                                                      <                                           ,       for all q.
                                               ^ ))
  2(1 + l N n) + (l A d A + l B d B )(1 + z(q, g                                             ^ ))
                                                            2(1 + n) + (d A + d B )(1 + z(q, g
Dividing by (g      (2             ^ )) and simplifying as before we obtain the su cient condition
                        g ) z ( q, g
                                                          
                          lB dB l A d A                 1
             lN > 1 +                         1    1+
                              d A dB                    n
                                                                                        
                       d A dB       1              dB       dA     2         dB      dA
                  +               · · max       lB       lA            , lB       lA        .
                     d A dB n                      dA       dB 2 g   ^       dA      dB

        ^ > g. Suppose l A d A
Case 2: g                            l B d B > 0. Then incorrect learning can occur in state A under
                                                              ^ ) < q LR (e0 , g, g
both the original and the new echo chamber. Then, q LR (e, g, g                   ^ ) if the following holds:
     ((2 g)z(q, g  ^ ) g) (l A d A l B d B )                 ((2 g)z(q, g  ^ ) g) (d A d B )
                                                      <                                           ,       for all q.
                                               ^ ))
  2(1 + l N n) + (l A d A + l B d B )(1 + z(q, g                                             ^ ))
                                                            2(1 + n) + (d A + d B )(1 + z(q, g
                                                                         1
    ^ > g, the dierence (2 g)z(q, g
For g                               ^ ) g is positive when q is close to 2 . It also must be positive
                1
to have q LR > 2 . Thus, we can divide both sides by it and simplify in the same way as above,
obtaining the su cient condition
                                                               
              l A d A lB dB            1       d A dB  1                         2
  lN > 1 +                    1   1+      +           · · max (l A l B )             , (l A l B ) .
                 d A dB                n     d A dB n                         2 g  ^
     Now suppose l A d A l B d B < 0. Then, incorrect learning occurs in state A for the original
                                                                             ^ ) < q LR (e0 , g, g
echo chamber and state B for the new echo chamber. In this case, q LR (e, g, g                   ^ ) if the
following holds:
       ( g (2 g ) z ( q, g ^ )) (l A d A l B d B )         ((2 g)z(q, g  ^ ) g) (d A d B )
                                                        <                                       ,     for all q.
    2(1 + l N n) + (l A d A + l B d B )(1 + z(q, g ^ ))                                    ^ ))
                                                          2(1 + n) + (d A + d B )(1 + z(q, g
Following the same steps as before, we obtain the su cient condition
                                                   
                       lB dB l A d A             1
           lN > 1 +                     1    1+
                          d A dB                 n
                                                                                                   
                     d d     1               dB      dA     2        dB                       dA
                 + A B · · max            lB      lA            , lB                     lA           .
                   d A dB n                  dA      dB 2 g   ^      dA                       dB
                                                                                                                       


F      Proof of Proposition 6
                  ^ < g. In this case, q LR is defined by condition (9). Fix d A , d B , n, l and
Case 1: w = B and g
^, we need to find l N such that
q
                              1      (g (2 g)z(q LR , g   ^ )) (ld A ld B )
                         ^>
                         q      +                                                    .
                                                                               ^ )))
                              2 2g (2(1 + l N n) + (ld A + ld B )(1 + z(q LR , g

                                                       34
Since the right-hand side is decreasing in z(q, g^ ), we obtain a su cient condition by imposing the
                                        ^ ), which is 0. Rearranging yields the following condition:
inequality for the lowest value of z(q, g
                                                    dA     ^( d A + d B )
                                                           q                     1
                                           lN >                           l        .
                                                           ^ 1) n
                                                         (2q                     n

                  ^ > g. In this case, q LR is defined by condition (10). Fixing again
Case 2: w = A and g
                     ^, we need to find l N such that
d A , d B , n, l and q
                                 1      ((2 g)z(q, g ^ ) g) (ld A ld B )
                            ^>
                            q      +                                               .
                                                                             ^ )))
                                 2 2g (2(1 + l N n) + l(d A + d B )(1 + z(q, g
Since the right-hand side is increasing in z(q, g ^ ), we obtain a su cient condition by imposing the
                                                          ^
                                         ^ ), which is 2 g
inequality for the highest value of z(q, g                  ^ . Rearranging gives the following:
                                                            g
                                                                      
                                    ^
                                    g                  ^
                                                       g
                                    g   2 ^
                                          q   d A      g   2 ( 1  ^
                                                                  q )  dB    1
                           lN >                                           l
                                            (2q^ 1) n (2 g     ^)            n


G        Proof of Proposition 7
For this proof, we will use the notation P(q; e), Nw (q; e), and N w (q; e) to explicitly account for
the dependence of P and these sets on q. We start with the following Lemma 5.
Lemma 5. As q increases, the set Nw (q; e) weakly expands and the set N                           w ( q; e)   weakly shrinks,
both in the sense of set inclusion.

Proof. Fix any q     ^ > 12 . Suppose i 2 Nw ( q^; e). There are two possibilities. If q LR (ei , g, g ^) > q   ^,
then i's dogmatic majority must be towards the correct state w . Increasing q beyond q LR (ei , g, g           ^)
will lead the agent to learn correctly that the state is w . Hence, i 2 Nw (q; e) for all q > q             ^. If
                   ^ (for simplicity we omit the knife-edge case of equality), then i is already learning
              ^) < q
q LR (ei , g, g
correctly and increasing q will not change her asymptotic beliefs. Thus, i 2 Nw (q; e) for all q > q            ^.
We conclude that Nw (q; e) does not shrink as q increases.
     Now consider j 2 N w (q    ^; e). This means that q LR (ei , g, g    ^. Increasing q beyond q LR (ei , g, g
                                                                     ^) > q                                    ^)
will lead j to learn correctly, which means she will leave N w (q; e).
                                                                                                               

     Without loss of generality, label the agents so that q LR (ei , g, g       ^ ) < q LR (e j , g, g
                                                                                                     ^ ) if and only if
                                                1
i < j. Suppose w = A. Fix any q            ^ > 2 and consider sets N A (q   ^; e) and N B (q ^; e). Let i (q     ^) be the
lowest i such that q LR (ei , g, g  ^) > q  ^. As q increases to any q0 that satisfy q LR (ei(q       ^) , g , ^
                                                                                                               g ) < q0 <
                                 ^) will flip from N B (q; e) to N A (q; e). This implies
                   ^ ), agent i (q
         ^)+1 , g, g
q LR (ei(q
                      |N A (q0 ; e)| = |N A (q
                                             ^; e)| + 1 and |N B (q0 ; e)| = |N B (q
                                                                                   ^; e ) |          1.
Consider the long-run polarization:
                                               4
                                  ^; e ) =
                                P(q                        ^; e)||N B (q
                                                   · |N A (q              ^; e ) |
                                              |N |
                                               4
                               P ( q 0 ; e) =      · (|N A (q^; e ) | + 1 ) ( N B ( q
                                                                                    ^; e )   1)
                                              |N |

                                                              35
            ^; e )
Note that P(q         P(q0 ; e) if and only if

                                               ^)|  |N A (q
                                         |N B (q          ^)| + 1.

Hence, P(q; e) weakly decreases as q increases if and only if initially (i.e., at q = q        ^) the set of
eventually incorrect agents is smaller than the set of eventually correct agents plus one. Since
N B (q; e) weakly shrinks in q, a necessary and su cient condition for P(q; e) to be weakly decreasing
in q is that |N B ( 1
                    2 ; e) | = |D B | is weakly smaller than |N |
                                                                                               1
                                                                  |D B | + 1, that is, |D B |  2 (|N | + 1).


H      Proof of Proposition 8
Consider w = A--the argument is the same for w = B. We want to find M such that P (s        ^iM =
1| w = A ) > q¯ LR . This ensures by Proposition 3 that all agents in N learn correctly and hence
P^ (e) = 0. Now, note that
                                                                       !
                                                M
                                                             M
                      P (s^iM = 0|w = A) = P Â I{sik =a} <      |w = A
                                               k =0
                                                              2
                                                 bM
                                                  2 c
                                                       M!
                                             =   Â ( M  k ) ! k !
                                                                  q k (1 q ) M k
                                              k =0
                                                   0                   M  !2 1
                                                                        2
                                              exp @ 2 M q                    A,
                                                                       M

where the last inequality follows from Hoeding's inequality (Hoeding (1963)). Therefore, our
desired condition holds if
                                         M  !2
                                                 2
                                  2M     q                >    ln(1     ¯ LR ).
                                                                        q
                                                 M
Recalling that M is an odd number by assumption (i.e., M = 2m + 1 for m 2 N), we have that
                                              M  !2                         2
                                                 2                      1
                                  2M    q                 > 2M q                .
                                                 M                      2

Therefore, it su ces that
                                                     2
                                                 1
                                    2M q                 >    ln(1    ¯ LR ).
                                                                      q
                                                 2




                                                         36
           Online Appendix: Additional Proofs
                                (For Online Publication Only)

A       Other Misperceptions
In this appendix, we state and prove the formal results about long-run learning under each of
misperceptions considered in Section 6. Together, they imply Proposition 9.


A.1      Misperception (I): Random Selective Sharing
Proposition 11. Fix any agent with echo chamber e = (d A , d B , n), true probabilities of selective
                                                                   ^ and f^.
sharing g and f , and perceived probabilities of selective sharing g

    · If d A > d B and g f > g    ^ f^, there exists su ciently small q >                                      1
                                                                                                               2   such that the agent's
      belief converges to dA with probability 1 (i.e., µ(s· ) = 1).

    · If d A > d B and g f < g    ^ f^, there exists su ciently small q >                                      1
                                                                                                               2   such that the agent's
      belief converges to dB with probability 1 (i.e., µ(s· ) = 0).

    · In either case, there exists su ciently large q < 1 such that the agent's belief converges to dw
      with probability 1, where w is the true state (i.e., µ(s· ) = I{w = A} ).

    · If d A = d B , the agent's belief converges to dw with probability 1, where w is the true state
      (i.e., µ(s· ) = I{w = A} ).

Proof. Adapt the terminology of Proposition 3's proof as follows. Let ak
                                                                       j be the number of signals
s = a that have been shared by agent i's friend j of type k 2 { A, B, N }. Define bk
                                                                                   j similarly for s = b.
   Then, agent i's posterior that w = A is
                                                                            p
                     µ (s T ) =                                                                        S           ,
                                                                                     ^ )+(1 q)(1 f^))
                                                                         (1 g)+g(q(1 g
                                  p + (1            p) ·   QM     ·      (1 g)+g((1 q)(1 g^ )+q(1 f^))

where
                                              n                            dA                    dB
                    M = ( ai         bi ) + Â ( a N
                                                  j         b jN ) + Â ( a jA           b jA )   Â (bjB        aB
                                                                                                                j ),
                                             j =1                          j =1                  j =1
                           dB                              dA
                     S=    Â (T         aB
                                         j        b jB )   Â (T             a jA   b jA ).
                           j =1                            j =1


             ^ , f^), define the function
        ^ = (g
    For p
                                                                                                          !
                                       (1                     ^ ) + (1 q)(1
                                               g ) + g ( q (1 g                                    f^))                1
                z ( q, g, p
                          ^ ) = ln                                                                            [ln Q]       .
                                       (1      g) + g((1 q)(1 g      ^ ) + q (1                    f^))


                                                                      37
    Similarly to Proposition 3, we have plimT !· µ(sT ) = 1 (resp. plimT !· µ(sT ) = 0) if and only
            K (x,T ;q,g,p,p
                          ^)
if plimT !·         T        > 0 (resp. < 0), where
        K (x, T ; q, g, p, p
                           ^)
 plim                         = g(1 + nn)(2 H (q; w )      1)
 T !·             T
                             + gd A ( gH (q; w ) f (1 H (q; w ))) gd B ( g(1 H (q; w )) f H (q; w ))
                             + d B (1 g f H (q; w ) g g(1 H (q; w ))z(q, g, p^)
                               d A (1 g gH (q; w ) g f (1 H (q; w ))z(q, g, p^)
                            = g(1 + nn) g f d A g gd B + ((1 g g)d B (1 g f )d A ) z(q, g, p  ^)
                                 
                             + g 2(1 + nn) + g(d A + d B )(1 + z(q, g, p^ ))
                                                            
                             + f (d A + d B )(1 z(q, g, p
                                                        ^ )) H (q; w ).

The required inequality is then
                        g (1 + n n ) + g f (1 z ( q, g, p
                                                        ^ )) d A + g g (1 + z(q, g, p^ )) d B + (d A d B )z(q, g, p
                                                                                                                  ^)
H (q; w ) > (resp. <)                                                                                                ,
                             g (2(1 + nn) + g(d A + d B )(1 + z(q, g, p   ^ )) + f (d A + d B )(1 z(q, g, p^ )))
which is equivalent to

                     1              1 g                       ^) g
                                        2 ( f + g ) z ( q, g, p    2 (g   f ) (d A d B )
H (q; w ) > (resp. <) +                                                                               .
                     2 g (2(1 + nn) + g(d A + d B )(1 + z(q, g, p
                                                                ^ )) + f (d A + d B )(1 z(q, g, p
                                                                                                ^ )))

   Fix state w = B so that H (q; B) = 1           q. The inequality above takes form
                             g
               1              2 (g  f)     1 g  2 ( f + g ) z ( q, g, p
                                                                      ^ ) (d A d B )
  q < (resp. >) +                                                                                . (12)
               2 g (2(1 + nn) + g(d A + d B )(1 + z(q, g, p^ )) + f (d A + d B )(1 z(q, g, p
                                                                                           ^ )))

This implies that if d A = d B , then plimT !· µ(sT ) = 0.
   It can be shown that
                                                                               g
                                                                                  ^ f^)
                                                                               2 (g
                lim z(q, g, p
                            ^) = 0       and        lim z(q, g, p
                                                                ^) =                                  ,
                q !1                               q! 1
                                                      2
                                                                       (1    g) + g2 (2    ^
                                                                                           g    f^)

                   ^ and decreases in f^. Using this limit, condition (12) at q = 1
which increases in g                                                                2 becomes
                                                                  
                                           1
                                              ( g    f )  ( ^
                                                            g   ^) (d A d B )
                                                                f
             1             1               2
               < (resp. >) +                                                              ,
             2             2 2(1 + nn)(1 g         ^ + f^)) + g(d A + d B )(1 g( g
                                                2 (g                             ^ + f^))
and at q = 1 it becomes
                                                      ( g f )(d A d B )
                              1 < (resp. >)                                        .
                                               (2(1 + nn) + ( g + f )(d A + d B ))

                                                                          ^ f^); the second holds
Given d A > d B , the first condition holds with "<" whenever ( g f ) > ( g
                                                             1
with ">". By continuity, there exists q and q that satisfy 2 < q  q < 1, plimT !· µ(sT ) = 1
                                          0      00               0    00

if q < q0 , and plimT !· µ(sT ) = 0 if q > q00 .

                                                          38
   Now suppose w = A so that H (q; A) = q. The key inequality takes form
               1              1 g                       ^) g
                                  2 ( f + g ) z ( q, g, p    2 (g   f ) (d A d B )
  q > (resp. <) +                                                                               . (13)
               2 g (2(1 + nn) + g(d A + d B )(1 + z(q, g, p
                                                          ^ )) + f (d A + d B )(1 z(q, g, p
                                                                                          ^ )))
At q = 1
       2 , it takes form
                                                                                             
             1             1
                                                 1
                                                 2       (g         f)       ^
                                                                            (g            f^) (d A     dB )
               > (resp. <)
             2             2      2(1 + nn)(1             g
                                                             ^+
                                                          2 (g           f^)) + g(d A + d B )(1                  ^ + f^))
                                                                                                              g( g
and at q = 1, it takes the form
                                                       ( g f )(d A d B )
                           1 > (resp. <)                                          .
                                                 2(1 + nn) + ( f + g)(d A + d B )
                  ^ f^), the first condition holds with "<"; the second condition holds with ">".
Given ( g f ) < ( g
By continuity, there exists q0 and q00 that satisfy 1    0   00                  T             0
                                                    2 < q  q < 1, plimT !· µ (s ) = 0 if q < q ,
and plimT !· µ(sT ) = 1 if q > q00 .
                                                                                               


A.2     Misperception (II): Friends' Types
Proposition 12. Fix any agent with echo chamber e = (d A , d B , n) and misperceived number of
dogmatic friends d^A  d A and d^B  d B .

   · If d A d B > d  ^A d ^B , there exists su ciently small q >                                  1
                                                                                                       such that the agent's belief
                                                                                                  2
     converges to dA with probability 1 (i.e., µ(s· ) = 1).
   · If d A d B < d  ^A d  ^B , there exists su ciently small q >                                 1
                                                                                                       such that the agent's belief
                                                                                                  2
     converges to dB with probability 1 (i.e., µ(s· ) = 0).
   · In either case, there exists su ciently large q < 1 such that the agent's belief converges to dw
     with probability 1, where w is the true state (i.e., µ(s· ) = I{w = A} ).

   · If d A d B = d ^A d   ^B = 0, the agent's belief converges to dw with probability 1, where w is
     the true state (i.e., µ(s· ) = I{w = A} ).

Proof. Let the perceived number of A-dogmatic and B-dogmatic friends be d ^A = d A                                          ^ A and
                                                                                                                            n
 ^
dB = dB n  ^ B . Then agent's i posterior belief is
                                                       p
                            µ (s T ) =                                  ,
                                                           (1 g)+g(1 q) S
                                       p + (1 p ) · Q M ·    (1 g)+gq

where
                                                     n                             dA           dB
                           M = ( ai      bi ) + Â ( a N
                                                      j             b jN ) + Â a jA             Â bjB ,
                                                 j =1                              j =1         j =1
                                  d^B                    d^A
                            S=    Â (T      b jB )       Â (T            a jA ).
                                  j =1                   j =1


                                                               39
   Define the function
                                                                         
                                                 (1     g ) + g (1 q )
                              z(q, g) = ln                                  [ln Q] 1 .
                                                      (1 g ) + g q

   Similar to Proposition 3, we have plimT !· µ(s T ) = 1 (resp. plimT !· µ(s T ) = 0) if and only if
         K (x,T ;q,g)
plimT !·      T       > 0 (resp. < 0), where

                K (x, T ; q, g)
        plim                    = g(1 + n)(2 H (q, w ) 1) + gd A H (q, w ) gd B (1 H (q, w ))+
         T !·         T
                                                                                    
                                   + d ^B (1 g(1 H (q, w ))) d    ^A (1 g H (q, w )) z(q, g)

                             =    g (1 + n ) g d B + d^B (1 g)z(q, g) d       ^A z(q, g)+
                                                                                       
                                  + g 2(1 + n ) + ( d A + d B ) + ( d^A + d^B )z(q, g) H (q, w ).

   The required inequality is then

                                        g (1 + n ) + g d B + g d^B z(q, g) + (d^A d   ^B )z(q, g)
                H (q; w ) > (resp. <)                                                          ,
                                          g 2(1 + n ) + ( d A + d B ) + ( d ^A + d^B )z(q, g)

which is equivalent to
                                          g
                                            (d A d B ) + 1 g      ^      ^B )z(q, g)
                                     1    2                   2 (d A    d
                H (q; w ) > (resp. <) +                                               .
                                     2 g 2(1 + n ) + ( d + d ) + ( d^A + d^B )z(q, g)
                                                        A   B


Note that if d^A d^B = d A d B = 0, this inequality holds with ">" when w = A and "<" when
w = B, implying plimT !· µ(sT ) = I{w = A} .
   Fix state w = B so that H (q; B) = 1 q. Then the inequality above takes form

                                1     g(d A d B ) (2 g)(d        ^A d   ^B )z(q, g)
                   q < (resp. >) +                                                       .          (14)
                                2 2g (2(1 + n ) + ( d A + d B ) + ( d^A + d ^B )z(q, g))

It can be shown that
                                                                                     g
                           lim z(q, g) = 0            and     lim z(q, g) =                  .
                           q !1                               q! 1
                                                                 2
                                                                                 2       g

                                             1
Using this limit, condition (14) at q =      2   becomes
                                                                                        
                                                    g (d A     dB )      (d^A   d^B )
                    1            1
                      < (resp. >) +                                            ,
                    2            2 2g 2(1 + n ) + ( d + d ) + ( d^A + d^B ) g
                                                     A   B                 2 g

and at q = 1 it becomes

                                          1        g(d A d B )
                             1 < (resp. >) +                            .
                                          2 2g(2(1 + n) + (d A + d B ))

                                                         40
The first inequality holds with "<" if and only if d^A d^B < d A d B ; the second holds with ">".
                                                   1
By continuity, there exists q and q that satisfy 2 < q  q00 < 1, plimT !· µ(sT ) = 1 if q < q0
                             0       00                0

and plimT !· µ(sT ) = 0 if q > q00 .
   Now suppose w = A so that H (q; A) = q. The key inequality takes form
                                   g
                                     (d A d B ) + 1 g      ^      ^B )z(q, g)
                              1                        2 (d A    d
                 q > (resp. <) +  2                                                 .                (15)
                              2 g 2(1 + n ) + ( d + d ) + ( d^  + d^  ) z ( q , g )
                                                 A   B        A     B

At q = 1
       2 , it takes form
                                                                                                  
                                                       g (d A        dB )          (d^A   d^B )
                  1             1
                    > (resp. <)                                                        ,
                  2             2      2g 2(1 + n ) + ( d A + d B ) + ( d^A + d^B ) g
                                                                                   2 g

and at q = 1, it takes form
                                            1                 g(d A d B )
                           1 > (resp. <)                                           .
                                            2          2g(2(1 + n) + (d A + d B ))
The first inequality holds with "<" whenever d ^A d ^B > d A d B ; the second holds with ">". By
                                              1
continuity, there exists q and q that satisfy 2 < q  q00 < 1, plimT !· µ(sT ) = 0 if q < q0 and
                          0      00                0

plimT !· µ(sT ) = 1 if q > q00 .
                                                                                               


A.3     Misperception (III): Information Quality
Proposition 13. Fix any agent with echo chamber e = (d A , d B , n) and any perceived information
        ^> 1
quality q  2.

   · If d A > d B and g < 1, there exists su ciently small q 2 1      ^ such that the agent's belief
                                                                   2, q
                                                   ·
     converges to dA with probability 1 (i.e., µ(s ) = 1) and su ciently large q < 1 such that
     the agent's belief converges to dw with probability 1, where w is the true state (i.e., µ(s· ) =
     I{w = A} ).
   · If either d A = d B or g = 1, the agent's belief converges to dw with probability 1, where w is
     the true state (i.e., µ(s· ) = I{w = A} ).

Proof. Fix echo chamber e = (d A , d B , n). Keep notations the same as in the proof of Proposition 3.
After T periods, the agent's posterior in state A is
                                                         p
                        µ (s T ) =                       M                  ,
                                                   1 q ^     g (1 q^)+(1 g) S
                                   p + (1 p ) · q    ^     ·     ^+(1 g)
                                                                gq

where
                                                   n                          dA          dB
                           M = ( ai    bi ) + Â ( a N
                                                    j             b jN ) + Â a jA         Â bjB ,
                                                j =1                          j =1        j =1
                                dB                      dA
                           S=   Â (T      b jB )       Â (T         a jA ).
                                j =1                   j =1


                                                             41
Define the function
                                                                                                  1
                                                (1     g ) + g (1 q^)              1       ^
                                                                                           q
                            ^, g) = ln
                          z(q                                              ln                         .
                                                     (1 g ) + g q^                     ^
                                                                                       q

   Similar to Proposition 3, we have plimT !· µ(sT ) = 1 (resp. plimT !· µ(sT ) = 0) if and only if
                   ^, g )
         K (x,T ;q,q
plimT !·       T          > 0 (resp. < 0), where

                                  ^, g )
                     K (x, T ; q, q
              plim                       =                          ^, g))d B )
                                                g (1 + n + (1 + z ( q                      (d A          ^, g)+
                                                                                                  d B )z(q
              T !·          T
                                                                                  ^, g))) H (q; w ).
                                                + g(2(1 + n) + (d A + d B )(1 + z(q

The required inequality is then

                                                                ^, g))d B + (d A d B)z(q
                                        g (1 + n ) + g (1 + z ( q                        ^, g )
              H (q; w ) > (resp. <)                                                             ,
                                               g (2(1 + n) + (d A + d B )(1 + z(q^, g)))

which is equivalent to

                                          1     ((2 g)z(q ^, g) g)(d A d B )
                     H (q; w ) > (resp. <) +                                         .
                                                                             ^, g)))
                                          2 g (2(1 + n) + (d A + d B )(1 + z(q

                                                 ^, g) = 1), then the inequality holds with ">"
Note that if d A = d B or g = 1 (which implies z(q
when w = A and "<" when w = B, implying plimT !· µ(sT ) = I{w = A} .
   Fix state w = B so that H (q; B) = 1 q. Then the inequality above takes form

                                     1     ((2 g)z(q ^, g) g)(d A d B )
                        q < (resp. >) +                                         .
                                                                        ^, g)))
                                     2 g (2(1 + n) + (d A + d B )(1 + z(q

At q = 1
       2 , it takes form

                        1            1                    ^, g))(d A d B )
                                           ( g (2 g ) z ( q
                          < (resp. >) +                                         ,
                        2                                               ^, g)))
                                     2 g (2(1 + n) + (d A + d B )(1 + z(q

and at q = 1, it takes form

                                     1                    ^, g))(d A d B )
                                           ( g (2 g ) z ( q
                        1 < (resp. >) +                                         .
                                                                        ^, g)))
                                     2 g (2(1 + n) + (d A + d B )(1 + z(q

As shown in the Online Appendix B, z(q         ^, g) is a (weakly) decreasing function that achieves max-
imum at q   ^= 1  2 , with value  of  g
                                     2 g . Thus,   g (2 g ) z ( q                  ^> 1
                                                                 ^, g) > 0 for any q    2 . Given this and
d A > d B , the first inequality above holds with "<"; the second holds with ">". By continuity, there
exist q0 and q00 that satisfy 1        0    00                    T              0
                                 2 < q  q < 1, plimT !· µ (s ) = 1 if q < q and plimT !· µ (s ) = 0
                                                                                                    T
         00
if q > q .
     Now suppose w = A so that H (q; A) = q. The key inequality then is

                                     1     ((2 g)z(q ^, g) g)(d A d B )
                        q > (resp. <) +                                         .
                                                                        ^, g)))
                                     2 g (2(1 + n) + (d A + d B )(1 + z(q

                                                             42
At q = 1
       2 , this inequality takes form

                          1            1     ((2 g)z(q ^, g) g)(d A d B )
                            > (resp. <) +                                         ,
                          2                                               ^, g)))
                                       2 g (2(1 + n) + (d A + d B )(1 + z(q
and at q = 1, it takes form
                                       1     ((2 g)z(q ^, g) g)(d A d B )
                          1 > (resp. <) +                                         .
                                                                          ^, g)))
                                       2 g (2(1 + n) + (d A + d B )(1 + z(q
Given (2 g)z(q   ^, g) g < 0 and d A > d B , both inequalities hold with ">". Therefore, for any
    1
q > 2 , plimT !· µ(sT ) = 1.
                                                                                              


B       Properties of t (q)
                                                                                1                         1
We will prove that t (q) in condition (8) is concave for q 2                    2, 1   and that t 0       2     = 0. Recall that
we assume d A > d B . We can write
                                                    ^)
                                              z ( q,g
                                  ^ ))d B +
              1 + n + (1 + z ( q, g               g (d A         dB )                 ^)
                                                                            A + Bz(q, g   B     AD BC
    t (q) =                                                             =                = +                  ,
                                                   ^ ))
                  2(1 + n) + (d A + d B )(1 + z(q, g                                  ^)
                                                                            C + Dz(q, g                  ^ ))
                                                                                          D D (C + Dz(q, g
where
                                                  dA       dB
               A = 1 + n + dB , B = dB +                        , C = 2 + 2n + d A + d B , D = d A + d B .
                                                       ^
                                                       g
Also, we have that
                                                                                       
                                                 d A + dB   (2          ^ )(1 + n)
                                                                        g
                          AD      BC =                    +                               (d A   dB ) ,
                                                     ^
                                                     g                    g^
which is strictly negative. Therefore, t (q) is concave if and only if g(q) is convex, where
                                                                 1
                                                 g(q) =                  .
                                                                      ^)
                                                            C + Dz(q, g
We will prove this in steps.
                                          1
                ^ )  0 for q 2
Lemma 6. zq (q, g                         2, 1                      ^ ) = 0.
                                                 and limq! 1 zq (q, g
                                                                  2


Proof. Consider the derivative of z(q, g    ^ ) with respect to q:
                                                                                                  
              ^ (1 q)+(1 g
              g            ^)              g^ (2 g
                                                 ^)                1 q            ^ (1 q)+(1 g
                                                                                  g            ^)                 1
          ln     ^ q+(1 g
                        ^)
                 g                 g  2
                                    ^ q(1 q)+(1 g       ^)
                                                           · ln      q   + ln        ^ q+(1 g
                                                                                            ^)
                                                                                     g
                                                                                                   ·          q (1 q )
                               =                                              
        q     ln q
                    1 q
                                                                    ln2 q
                                                                         1 q

                                                                                        
                                            ^ (2 g
                                                 ^)                                            ^
                                   g
                                           g
                                    ^ 2 q(1 q)+(1 g     ^)
                                                           · ln q + ln q · qz((1q,gq))
                                                                   1 q            1 q

                               =                                                                                            (16)
                                                                     1 q
                                                              ln2 q
                                                      
                                     1 g  ^         2 z ( q, g
                                   q (1 q )
                                               + g^             ^ ) (2 g    ^ )g^
                               =                                                   .
                                        1 q
                                 ln q · (g          ^ 2 q (1 q ) + (1 g      ^ ))

                                                                43
                                   ^
                                   g
                        ^) =
Note that limq! 1 z (q, g         2 g^              ^ ). This immediately implies that limq! 1 zq (q, g
                                         > 0 = z(1, g                                                 ^ ) = 0.
                    2                                                                                         2

            ^ ) is continuously dierentiable for q 2 1
    As z(q, g                                            2 , 1 , it is enough to prove that there are
                          1
no local maximum on 2 , 1 in order to show that zq (q, g       ^ )  0 holds on this interval. At an
intermediate local maximum, zq (q, g^ ) = 0 must hold. This requires that
                                               
                                  1 g ^      2
                                         +g ^ z ( q, g
                                                     ^ ) (2 g     ^ )g
                                                                     ^ =0
                                q (1 q )

and hence
                                                                 ^ (2
                                                                 g           ^)
                                                                             g
                                                 ^) =
                                          z ( q, g                        1 g^
                                                                                                                   (17)
                                                             ^2
                                                             g    +     q (1 q )
                                                             ^ (2
                                                             g           ^)
                                                                         g                ^
                                                                                          g
                                                                          ^
                                                                        1 g
                                                                                  =               .
                                                             ^2
                                                             g    +      1
                                                                                      2       ^
                                                                                              g
                                                                         4


This rules out that z(q, g        ^ ) is increasing at q = 1 2 , since it would need to achieve a local maximum
                            ^
with value above 2 g          ^
                              g . Now    note that   the right-hand   side of (17) is strictly decreasing in q over
  1                                                                   1
                    ^ ) was to decrease at first (as q rises from 2 ) and then increase before going down to 0,
  2 , 1 . If z ( q, g
the value of z(q, g     ^ ) at the corresponding local maximum would be necessarily above the right-hand
side of (17), which is a contradiction. One final case is that z(q, g               ^ ) is decreasing at first, passing
through a local minimum, and then is increasing until q = 1. This would mean that the value at
the local minimum is less than z(1, g            ^ ), which is equal to 0. Since z(q, g     ^ ) > 0 for q 2 ( 1
                                                                                                              2 , 1) and
                                                                                                              1
g^ 2 (0, 1), this case is also impossible. We conclude that z(q, g          ^ ) is weakly decreasing over 2 , 1 . 

    This implies that limq! 1 g0 (q) = 0 because
                                  1


                                                                           ^)
                                                                   Dzq (q, g
                                              g0 (q) =                                    .
                                                                        ^ ))2
                                                             (C + Dz(q, g

Lemma 7. g(q) is convex.

Proof. Since
                                                             2
                                         2 D 2 z q ( q, g
                                                        ^)                      ^ ))zqq (q, g
                                                                   D (C + Dz(q, g           ^)
                           g00 (q) =                                                                      ,
                                                                        ^ ))3
                                                             (C + Dz(q, g
                                                                                              1
                                                ^ ) < 0 for all q 2
the result follows if we can prove that zqq (q, g                                             2, 1    .




                                                                 44
                                                                          1
   Using (16) and letting K (q) =                         h 
                                                              1 q
                                                                  i2                    ,                    we have
                                                           ln q         2         ^ ))2
                                                                      ^ q(1 q)+(1 g
                                                                     (g
                               "
                                                                                                      
                                       (1 g ^ )(1 2q)
          ^ ) = K (q)
  zqq (q, g                              q2 (1 q )2
                                                          +        1 g^
                                                                 q (1 q )
                                                                            +g            ^ ) ln 1 q q g
                                                                             ^ 2 z q ( q, g            ^ 2 q (1                                   q ) + (1           ^)
                                                                                                                                                                     g
                                                                                                                                                                               #
                                                                                                                                                                            
           1 g^                                                            1                                                                    1 q
         q (1 q )
                     ^ 2 z ( q, g
                    +g          ^)                ^ (2
                                                  g         ^)
                                                            g          q (1 q )
                                                                                   ^ 2 q (1
                                                                                   g                  q ) + (1              ^ ) + ln
                                                                                                                            g                    q         ^ 2 (1
                                                                                                                                                           g         2q )
             "
                                                                                    
                    (1 g ^ )(2q 1)
   = K (q)            q2 (1 q )2
                                       +        1 g^
                                              q (1 q )
                                                          +g            ^ ) ln 1 q q g
                                                           ^ 2 z q ( q, g            ^ 2 q (1                                  q ) + (1          ^) +
                                                                                                                                                 g
                                                                                                                                                                               #
                                                                                                                                                                            
           1 g^                                                            1                                                                    1 q
  +      q (1 q )
                     ^ 2 z ( q, g
                    +g          ^)                ^ (2
                                                  g         ^)
                                                            g          q (1 q )
                                                                                   ^ 2 q (1
                                                                                   g                  q ) + (1              ^ ) + ln
                                                                                                                            g                    q         ^ 2 (2q
                                                                                                                                                           g          1)           .

   Let
                                                                            
                                        (1 ^ )(2q 1)
                                           g                  1 g^        2
                          C1 (q) =                      +             +g            ^ ),
                                                                         ^ z q ( q, g
                                       q2 (1 q )2           q (1 q )
                                                        
                                        1 g   ^       2
                          C2 (q) =               +g  ^ z ( q, g
                                                              ^) g ^ (2 g  ^ ),
                                      q (1 q )
                                                                                        
                                         1        2                              1 q
                          C3 (q) =              g^ q (1 q ) + (1 g   ^ ) + ln            ^ 2 (2q
                                                                                         g                                                           1).
                                   q (1 q )                                        q
Then we can write
                                                                                
                                                1                           q
                         ^ ) = K (q) C1 (q) ln
                 zqq (q, g                                                         ^ 2 q (1
                                                                                   g                  q ) + (1               ^ ) + C2 (q)C3 (q)
                                                                                                                             g
                                                                        q

                                  ^ ), we can write C1 (q) as
   Using the expression of zq (q, g
                                                                                    
                                                                   1 g ^          2 z ( q, g
              (1 g ^ )(2q 1) g       2
                                    ^ q (1 q ) + (1 g      ^)    q (1 q )
                                                                           +   g^          ^) g ^ (2 g  ^)
     C1 (q) =    2        2
                               +                              ·            
                q (1 q )                  q (1 q )             ln q (g
                                                                      1 q
                                                                                 ^ 2 q (1 q ) + (1 g  ^ ))
                                         
              (1 g ^ )(2q 1) ln 1 q q + g     ^ (2 g ^ ) q (1 q )        g^ 2 q (1 q ) + (1 g     ^ ) z ( q, g
                                                                                                             ^)
            =                                                          
                                                                    q
                                                q2 (1 q)2 ln 1 q
and therefore
                                  
               1              q
    C1 (q) ln                         ^ 2 q (1
                                      g            q ) + (1 g^) =                          ^ 2 q (1
                                                                                           g                q ) + (1              ^) ·
                                                                                                                                  g
                          q
                                                            
                                                          q
                          (1       ^ )(2q
                                   g              1) ln 1 q + g^ (2                      ^ ) q (1
                                                                                         g                 q)           ^ 2 q (1
                                                                                                                        g                  q ) + (1          ^ ) z ( q, g
                                                                                                                                                             g          ^)
                      ·
                                                                                         q2 (1        q )2
   Using
                                                                                   h                                                                          i
                                                                                                                               1 q
                                               ^ 2 q (1
                                              (g                ^ ) ) z ( q,g
                                                          q)+(1 g           ^ )·        ^ 2 q (1
                                                                                       (g                ^ ))+ln
                                                                                                   q)+(1 g                      q       ^ 2 (2q 1) q (1 q )
                                                                                                                                        g
                    C2 (q)C3 (q) =                                                            q2 (1 q )2
                                                                                                                        
                                                                                                                  1 q
                                                                 ^ 2 q (1
                                                                (g                ^ ))q(1 q)+ln
                                                                            q)+(1 g                                q       ^ 2 (2q 1) q2 (1 q )2
                                                                                                                           g
                                                 ^ (2
                                                 g         ^)
                                                           g                                       q2 (1   q )2
                                                                                                                                                    ,

                                                                                   45
we can write
         ^ ) q2 (1
 zqq (q, g           q )2                                                                                                 
                                                                                         1 q
                                 ^ 2 q (1
                             = 2 g                 q ) + (1           ^ ) + ln
                                                                      g                   q         ^ 2 (2q
                                                                                                    g         1)(1      q) ·
          K (q)
                                                                                   ^ 2 q (1
                                                                                 · g                  q ) + (1 g  ^ ) z ( q, g
                                                                                                                             ^)
                                                                            h                                                                              i
                                                                                                              1 q
                              + g ^ 2 q (1 q ) + (1 g  ^ ) (1 g     ^ )(2q                            1) ln q         2g  ^ (2 g^ ) q (1              q)
                                          
                              + ln 1 q q g ^ 3 (2 g^ )(2q 1)q2 (1 q)2
                                                                               
                                                          2
                             =2 g^ 2 q (1 q ) + (1 g             ^ ) + ln 1 q q g
                                                      ^ ) z ( q, g              ^ 3 (2                               ^ )(2q
                                                                                                                     g              1) q2 (1       q )2
                                                                                 2                                                                             
                                 g^ 2 q (1 q ) + (1 g  ^ ) ln 1 q q (2q 1) g    ^ (1                                            ^ ) + (1
                                                                                                                     q ) z ( q, g                       ^ ))
                                                                                                                                                 z ( q, g
                                             ^ )2 q (1
                                    2 z ( q, g                q ) + (1                 ^ )) z(q, g
                                                                                z ( q, g         ^ )(2                 ^ ))q(1
                                                                                                                z ( q, g               q ).

    Let
                                 ^ )2 q (1 q ) + (1 z ( q, g
                 D1 (q) = 2 z(q, g                          ^ )) z(q, g
                                                                      ^)
                                    
                                 q
                           ln 1 q (2q 1)(1 z(q, g        ^ )) 2z(q, g  ^ )(2                                          ^ ))q(1
                                                                                                               z ( q, g                q)
and
                                   ^ )3 (2
                     D2 (q) = z(q, g                            ^ ))q2 (1
                                                         z ( q, g                 q )2
                                                 ^ )2 q (1
                                          z ( q, g                 q ) + (1                        ^ )2 (1
                                                                                         ^ )) z(q, g
                                                                                  z ( q, g                                      ^)
                                                                                                                     q ) z ( q, g
Then we have
                                                                                                                                    
              ^ ))q2 (1
 zqq (q, z(q, g                 q )2                 2                                                                      q
                                                ^ ) q (1
                                       = z ( q, g                  q ) + (1                  ^ )) D1 (q) + ln
                                                                                      z ( q, g                                         (2q      1) D2 (q).
             K (q)                                                                                                      1       q
                                                                                                                                                           (18)
    Note that
                                                                                         ^
        D1 (q)  2 z(q, g    ^ )2 q (1 q ) + (1 z ( q, g   ^ )) 2 z(zq(,q
                                                                       g)
                                                                         ,g^)
                               
                            q
                   ln 1 q (2q 1)(1 z(q, g              ^ )) 2z(q, g       ^ )(2 z(q, g^ ))q(1 q)
                            h
               = 2 z1    ^)
                     ( q,g
                                      ^ )3 q (1 q ) + 2z ( q, g
                              2z ( q, g                       ^ )(1 z(q, g      ^ ))
                                                                                                                                                      i
                            q
                   ln 1 q (2q 1)(1 z(q, g              ^ ))(2 z(q, g        ^ )) 2z(q, g           ^ ))2 q(1
                                                                                        ^ )(2 z(q, g                                             q)
                     1             ^)
                            z ( q, g
                =                     E ( q ),
                     2             ^)
                            z ( q, g
                                                                            
                                                                       q
where E(q) = 2z(q, g^ )(1 4q(1                    q))         ln      1 q       (2q          1)(2             ^ )). Dierentiating this expres-
                                                                                                       z ( q, g
sion with respect to q, we get
                                                                                                                                
         0                                                1                                                             q
                         ^ ) · 4(2q 1)
       E ( q ) = 2z ( q, g                                   (2q          1)(2 z(q, g ^ )) 2 ln             (2                                     ^ ))
                                                                                                                                            z ( q, g
                                                    q (1 q )                                       1 q
                                                                                      
                                                            ^)
                                                   2 z ( q, g                     q
               = (2q 1) 4z ( q, g   ^)                                    2 ln                     ^ ))
                                                                                         (2 z ( q, g
                                                     q (1 q )                   1 q
                                                                                        
                                                                                    q
              < (2q                     ^)
                            1) (4z ( q, g        4(2                ^ ))) 2 ln
                                                             z ( q, g                     (2 z ( q, g^ )) < 0
                                                                                 1 q

                                                                            46
          1
for q 2   2, 1   . Therefore, E(q) < E 1               1
                                        2 for any q 2 2 , 1 , where
                                                                  
                      1                      1               1
                   E                ^) 1 4 ·
                          = 2z ( q, g             ln(1) 2 ·      1 (2                  ^ )) = 0.
                                                                                z ( q, g
                      2                      4               2

Therefore, we can conclude that D1 (q) < 0 for q 2 1     2, 1 .
   Returning to D2 (q), note that
                                                                                                               
D2 (q) = z(q, g ^ )2 (1 q ) z ( q, g          ^ ))q2 (1 q)
                                   ^ )(2 z(q, g                z ( q, g^ )2 q (1 q ) + (1 z ( q, g          ^)
                                                                                                  ^ )) z(q, g
                                                                                                              
                ^ )2 (1 q ) z ( q, g
       < z ( q, g                  ^ )(2 z(q, g
                                              ^ ))q(1 q)             ^ )2 q (1 q ) + (1 z ( q, g
                                                              z ( q, g                          ^ )) z(q, g^)

The expression in the brackets is the negative of the           numerator
                                                                                           ^ )). Given that
                                                                            in zq (q, z(q, g
                                                                1 q
                ^ )) is negative and its expression includes ln q , it follows that the numerator has to
z q ( q, z ( q, g
be positive. This implies that the expression above is negative, and therefore, D2 (q) must be neg-
ative as well.
    Using D1 (q) < 0 and D2 (q) < 0 for q 2 1                                                     ^ )) < 0
                                             2 , 1 and (18), we can conclude that zqq ( q, z ( q, g
         1
for q 2 2 , 1 .
                                                                                                        


References
Acemoglu, D., A. Ozdaglar, and A. ParadehGheibi (2010). Spread of (Mis)information in
  Social Networks. Games and Economic Behavior 70, 194­227.

Alesina, A., A. Miano, and S. Stantcheva (2020). The Polarization of Reality. In AEA
  Papers and Proceedings, Volume 110, pp. 324­28.

Allcott, H. and M. Gentzkow (2017). Social Media and Fake News in the 2016 Election.
  Journal of Economic Perspectives 31(2), 211­36.

Andreoni, J. and T. Mylovanov (2012, February). Diverging Opinions. American Economic
 Journal: Microeconomics 4(1), 209­32.

Athey, S., M. M. Mobius, and J. P´
                                 al (2017). The Impact of Aggregators on Internet News
  Consumption.

Azzimonti, M. and M. Fernandes (2018). Social Media Networks, Fake News, and Polariza-
  tion. Working paper.

Ba, C. and A. Gindin (2020). A Multi-Agent Model of Misspecified Learning with Overcon-
  fidence. Available at SSRN 3691728.

Baccara, M. and L. Yariv (2013). Homophily in Peer Groups. American Economic Journal:
  Microeconomics 5(3), 69­96.


                                                      47
Barber, M. and N. McCarty (2015). Causes and Consequences of Polarization. Political
  Negotiation: A Handbook 37, 39­43.

Barber´a, P. (2020). Social Media, Echo Chambers, and Political Polarization, Chapter 3,
  pp. 34­55. Cambridge University Press.

Bartels, L. M. (2008). Unequal Democracy: The Political Economy of the New Gilded Age.
  Princeton University Press.

Ben-Porath, E., E. Dekel, and B. Lipman (2018). Disclosure and Choice. Review of Economic
  Studies 85(3), 1471­1501.

Berk, R. H. (1966, 02). Limiting Behavior of Posterior Distributions when the Model is
  Incorrect. Ann. Math. Statist. 37(1), 51­58.

Bertrand, M. and E. Kamenica (2018). Coming Apart? Cultural Distances in the United
  States over Time. NBER Working Papers 24771, National Bureau of Economic Research,
  Inc.

Bishop, B. (2009). The Big Sort: Why the Clustering of Like-Minded America is Tearing us Apart.
  Houghton Miin Harcourt.

Bohren, A. and D. Hauser (2018). Social Learning with Model Misspecification: A Frame-
  work and a Robustness Result. PIER Working Paper Archive 18-017, Penn Institute for
  Economic Research, Department of Economics, University of Pennsylvania.

Bohren, J. A. (2016). Informational Herding with Model Misspecification. Journal of
  Economic Theory 163(C), 222­247.

Boxell, L., M. Gentzkow, and J. Shapiro (2018). Greater Internet Use is Not Associated with
  Faster Growth of Political Polarization Among US Demographic Groups. Proceedings of
  the National Academy of Sciences 115(3).

Bursztyn, L., G. Egorov, R. Enikolopov, and M. Petrova (2019). Social Media and Xeno-
  phobia: Evidence from Russia. NBER Working Paper No. 26567.

Conroy-Krutz, J. and D. C. Moehler (2015). Moderation from Bias: A Field Experiment on
  Partisan Media in a New Democracy. The Journal of Politics 77(2), 575­587.

Cross, P. (1977). Not Can But Will College Teachers Be Improved? New Directiosn for
  Higher Education 17, 1­15.

Dasaratha, K. and K. He (2020). Network Structure and Naive Sequential Learning.
 Theoretical Economics 15(2), 415­444.

DeMarzo, P., I. Kremer, and A. Skrzypacz (2019). Test Design and Minimum Standards.
  American Economic Review 109(6), 2173­2207.

                                            48
DeMarzo, P., D. Vayanos, and J. Zweibel (2003). Persuasion Bias, Social Influence, and
  Unidimensional Opinions. Quarterly Journal of Economics 118(3), 909­968.

Desmet, K. and R. Wacziarg (2018). The Cultural Divide. CEPR Discussion Papers 12947,
  C.E.P.R. Discussion Papers.

Dixit, A. and J. Weibull (2007). Political Polarization. Proceedings of the National Academy
  of Sciences 104(18), 7351­7256.

Dye, R. (1985). Disclosure of Nonproprietary Information.           Journal of Accounting
 Research 23(1), 123­145.

Edwards, W. (1968).      Conservatism in Human Information Processing.              Formal
  Representation of Human Judgment.

Enke, B. and F. Zimmermann (2017). Correlation Neglect in Belief Formation. The Review
  of Economic Studies 86(1), 313­332.

Enke, B., F. Zimmermann, and F. Schwerter (2019). Associative Memory and Belief Forma-
  tion. Working paper.

Esponda, I. and D. Pouzo (2016). Berk­Nash Equilibrium: A Framework for Modeling
  Agents With Misspecified Models. Econometrica 84, 1093­1130.

Esponda, I., D. Pouzo, and Y. Yamamoto (2019). Asymptotic Behavior of Bayesian Learners
  with Misspecified Models. arXiv preprint arXiv:1904.08551.

Esteban, J.-M. and D. Ray (1994). On the Measurement of Polarization. Econometrica 62(4),
  819­851.

Evans, J. S. B. (1989). Bias in Human Reasoning: Causes and Consequences. Lawrence
  Erlbaum Associates, Inc.

                                  ive Herding in Rich-Information Settings. American
Eyster, E. and M. Rabin (2010). Na¨
  Economic Journal: Microeconomics 2, 221­243.

Eyster, E., M. Rabin, and G. Weizs¨acker (2018). An Experiment On Social Mislearning.
  Rationality and Competition Discussion Paper Series 73, CRC TRR 190 Rationality and
  Competition.

Ferejohn, J., I. Katznelson, and D. Yashar (2020). Social Media and Democracy: The
  State of the Field, Prospects for Reform, Chapter SSRC Anxieties of Democracy, pp. ii.
  Cambridge University Press.

Flaxman, S., S. Goel, and J. M. Rao (2016, 03). Filter Bubbles, Echo Chambers, and Online
  News Consumption. Public Opinion Quarterly 80(S1), 298­320.



                                            49
Frick, M., R. Iijima, and Y. Ishii (2020). Misinterpreting Others and the Fragility of Social
  Learning. Econometrica 88(6), 2281­2328.

Fudenberg, D., G. Lanzani, and P. Strack (2020). Limits Points of Endogenous Misspecified
  Learning. Available at SSRN.

Fudenberg, D., G. Romanyuk, and P. Strack (2017). Active Learning with a Misspecified
  Prior. Theoretical Economics 12(3), 1155­1189.

Galperti, S. (2019). Persuasion: The Art of Changing Worldviews. American Economic
 Review 109(3), 996­1031.

Gilens, M. (2012). Auence and Influence: Economic Inequality and Political Power in America.
  Princeton University Press.

Golub, B. and M. O. Jackson (2010). Na¨
                                      ive Learning in Social Networks and the Wisdom
 of Crowds. American Economic Journal: Microeconomics 2(1), 112­49.

Golub, B. and M. O. Jackson (2012). How Homophily Aects the Speed of Learning and
 Best-Response Dynamics. The Quarterly Journal of Economics 127(3), 1287­1338.

Halberstam, Y. and B. Knight (2016). Homophily, Group Size, and the Diusion of Political
  Information in Social Networks: Evidence from Twitter. Journal of public economics 143,
  73­88.

He, K. (2018). Mislearning from Censored Data: The Gambler's Fallacy in Optimal-Stopping
  Problems. arXiv preprint arXiv:1803.08170.

He, K. and J. Libgober (2020). Evolutionarily Stable (Mis) specifications: Theory and
  Applications. arXiv preprint arXiv:2012.15007.

Heidhues, P., B. Koszegi, and P. Strack (2018). Convergence in Misspecified Learning Models
  with Endogenous Actions. Available at SSRN 3312968.

Hoeding, W. (1963). Probability Inequalities for Sums of Bounded Random Variables.
 Journal of the American Statistical Association 58(301), 13­30.

Homann, F., K. Khalmetski, and M. Le Quement (2019). Disliking to Disagree. Working
 paper.

Hu, L., A. Li, and I. Segal (2019). The Politics of News Personalization. arXiv preprint
 arXiv:1910.11405.

Jehiel, P. (2018). Investment Strategy and Selection Bias: An Equilibrium Perspective on
  Overoptimism. American Economic Review 108(6), 1582­97.

Keefer, P. and S. Knack (2002). Polarization, Politics and Property Rights: Links between
  Inequality and Growth. Public choice 111(1-2), 127­154.

                                             50
Levendusky, M. S. (2013). Why Do Partisan Media Polarize Viewers? American Journal of
  Political Science 57(3), 611­623.

Levy, G. and R. Razin (2019a). Echo Chambers and Their Eects on Economic and Political
  Outcomes. Annual Review of Economics forthcoming.

Levy, G. and R. Razin (2019b). Information Diusion in Networks with the Bayesian Peer
  Influence Heuristic. Working paper.

Levy, R. (2020). Social Media, News Consumption and Polarization: Evidence from a Field
  Experiment. Working paper.

Li, Y. and H. Pei (2020). Misspecified Beliefs about Time Lags. Working paper.

Mailath, G. and L. Samuelson (2020). Learning under Diverse World Views: Model-Based
 Inference. American Economic Review 110(5), 1464­1501.

McCarty, N., K. T. Poole, and H. Rosenthal (2009). Does Gerrymandering Cause Polariza-
 tion? American Journal of Political Science 53(3), 666­680.

Molavi, P., A. TahbazSalehi, and A. Jadbabaie (2018). A Theory of NonBayesian Social
 Learning. Econometrica 86(2), 445­490.

Mosquera, R., M. Odunowo, T. McNamara, X. Guo, and R. Petrie (2019). The Eco-
 nomic Eects of Facebook. Available at SSRN: https://ssrn.com/abstract=3312462 or
 http://dx.doi.org/10.2139/ssrn.3312462.

Mullainathan, S. and A. Shleifer (2005).    The Market for News.     American Economic
 Review 95(4), 1031­1053.

Nickerson, R. (1998). Confirmation Bias: A Ubiquitous Phenomenon in Many Guises. Review
  of General Psychology 2(2), 175­220.

Nisbett, R. E. and L. Ross (1980). Human Inference: Strategies and Shortcomings of Social
  Judgment.

Nyarko, Y. (1991). Learning in Mis-Specified Models and the Possibility of Cycles. Journal
 of Economic Theory 55(2), 416­427.

Odean, T. (1998). Volume, Volatility, Price and Profit When All traders Are Above Average.
 Journal of Finance 53(6), 1887­1934.

Perego, J. and S. Yuksel (2016). Searching for Information and the Diusion of Knowledge.
  Unpublished manuscript, New York University.

Perego, J. and S. Yuksel (2018). Media Competition and Social Disagreement. Working
  paper.


                                           51
Periser, E. (2011). The Filter Bubble: What the Internet is Hiding from You. Penguin, Lon-
  don.
Pew Research Center (2014). Political Polarization and Media Habits. pp. October, 2014.
Pew Research Center (2020). U.S. Media Polarization and the 2020 Election: A Nation
  Divided. pp. January, 2020.
Pogorelskiy, K. and M. Shum (2019).          News We Like to Share: How News
  Sharing on Social Networks Influences Voting Outcomes.          Available at SSRN:
  https://ssrn.com/abstract=2972231 or http://dx.doi.org/10.2139/ssrn.2972231.
Rabin, M. (1998). Psychology and economics. Journal of economic literature 36(1), 11­46.
Reeves, A., M. McKee, and D. Stuckler (2016). `It's The Sun Wot Won It': Evidence of
  Media Influence on Political Attitudes and Voting from a UK Quasi-Natural Experiment.
  Social science research 56, 44­57.
Shin, J., L. Jian, K. Driscoll, and F. Bar (2018). The Diusion of Misinformation on Social
  Media: Temporal Pattern, Message, and Source. Computers in Human Behavior 83, 278­
  287.
Shin, J. and K. Thorson (2017). Partisan Selective Sharing: The Biased Diusion of Fact-
  Checking Messages on Social Media. Journal of Communication 67(2), 233­255.
Spiegler, R. (2019). Behavioral Implications of Causal Misperceptions. Working paper.
Sunstein, C. (2017). Divided Democracy in the Age of Social Media. Princeton University
  Press.
Svenson, O. (1981). Are We all Less Risky and More Skillful Than Our Fellow Drivers?
  Acta Psychologica 47(2), 143­148.
Tucker, J., A. Guess, P. Barbera, C. Vaccari, A. Siegel, S. Sanovich, D. Stukal, and B. Ny-
  han (2019). Social Media, Political Polarization, and Political Disinformation: A Re-
  view of Scientific Literature. Available at SSRN: https://ssrn.com/abstract=3144139 or
  http://dx.doi.org/10.2139/ssrn.3144139.
Weeks, B. E., D. S. Lane, D. H. Kim, S. S. Lee, and N. Kwak (2017). Incidental Exposure,
 Selective Exposure, and Political Information Sharing: Integrating Online Exposure Pat-
 terns and Expression on Social Media. J. Computer-Mediated Communication 22, 363­379.
Zak, P. J. and S. Knack (2001). Trust and Growth. The economic journal 111(470), 295­321.
Zhuravskaya, E., M. Petrova, and R. Enikolopov (2020). Political Eects of the Internet and
  Social Media. Annual Review of Economics 12, 415­438.
Zuckerman, E. and J. Jost (2001). What Makes you Think you are so Popular?           Social
  Psychology Quarterly 64(3), 207­223.

                                            52
