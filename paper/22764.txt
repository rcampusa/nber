                              NBER WORKING PAPER SERIES




                      MOBILE PHONES, CIVIC ENGAGEMENT, AND
                        SCHOOL PERFORMANCE IN PAKISTAN

                                          Minahil Asim
                                          Thomas Dee

                                      Working Paper 22764
                              http://www.nber.org/papers/w22764


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                                    October 2016




The authors would like to Zubair Bhatti and Ali Inam at the World Bank, staff at the School
Education Department in Punjab, Pakistan, and seminar participants at Stanford University, UC
Davis, and the Association for Education Finance and Policy for helpful comments. The view
expressed herein are those of the authors and do not necessarily reflect the views of the National
Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2016 by Minahil Asim and Thomas Dee. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including © notice, is given to the source.
Mobile Phones, Civic Engagement, and School Performance in Pakistan
Minahil Asim and Thomas Dee
NBER Working Paper No. 22764
October 2016
JEL No. I2,O1

                                          ABSTRACT

The effective governance of local public services depends critically on the civic engagement of
local citizens. However, recent efforts to promote effective citizen oversight of the public-sector
services in developing countries have had mixed results. This study discusses and evaluates a
uniquely designed, low-cost, scalable program designed to improve the governance and
performance of primary and middle schools in the Punjab province of Pakistan. The School
Council Mobilization Program (SCMP) used mobile-phone calls to provide sustained and
targeted guidance to local school-council members on their responsibilities and authority. We
examine the effects of the SCMP on school enrollment, student and teacher attendance, and
school facilities using a “difference in difference in differences” (DDD) design based on the
targeted implementation of the SCMP. We find that this initiative led to meaningful increases in
primary-school enrollment, particularly for young girls (i.e., a 12.4 percent increase), as well as
targeted improvements in teacher attendance and school facilities, most of which were sustained
in the months after the program concluded.


Minahil Asim
University of California, Davis
School of Education
1 Shield Ave
Davis, CA 95616
masim@ucdavis.edu

Thomas Dee
Stanford University
520 Galvez Mall, CERAS Building, 5th Floor
Stanford, CA 94305-3084
and NBER
tdee@stanford.edu
                                                                                                     1


1. Introduction
   The informed oversight of citizens can promote effective governance of their local public
services by mitigating the moral hazard that can exist in the presence of information asymmetry
and a divergence between the goals of individuals operating government agencies and the public
interest (Azfar et al. 1999; Mansuri and Rao 2014). That is, informed civic engagement can
support accountability of public sector workers, tailor public services to the unique needs of
particular communities, improve poverty targeting, and, in general, increase the demand for good
governance. A growing body of empirical evidence however, suggests that the manner in which
citizens are given information and the opportunities to participate in the delivery of public
services, influences the impact of civic engagement on the quality of local governance (Olken
2007; Bjorkman and Svensson 2009; Banerjee et al. 2010; Duflo et al. 2014; Blimpo 2015).
   Our paper contributes to the literature on strengthening local governance to improve public
service delivery in developing countries by studying a novel and low-cost intervention.
Specifically, we examine the School Council Mobilization Program (SCMP), a unique program
piloted in five districts in Pakistan’s largest province Punjab. The SCMP focused on providing
sustained and targeted guidance to school council (SC) members (i.e., parents, community
members, the head-teacher) on their civic responsibilities through regular, low-cost engagement
over mobile phones. The provincial government hired a call center for 17 months and, every
month, calling agents provided information to SC members on their roles and responsibilities.
These design features (i.e., a one-to-one, low-cost and sustained engagement mechanism
between the provincial government and the SCs to encourage citizen participation in improving
school governance) have not, to our knowledge, been evaluated in local governance settings.
Moreover, Pakistan provides a unique cultural and political setting to evaluate this impact where
public services are plagued by under-provision and corruption.
   We use publically available school-level administrative data for 26 districts, 5 of which were
exposed to SCMP, collected regularly by the Program Monitoring and Implementation Unit
(PMIU) of the School Education Department in Punjab. We organized these school-level panel
data into four distinct time periods. The earliest observations consist school-level data from the
months just prior to the implementation of the SCMP. The next two periods correspond to a
time-period when the SCMP was actively engaging SC members in the field and the fourth
provides us data in the months shortly after SCMP activity had concluded. Schools are
                                                                                                     2


segregated by gender in Pakistan. Within the 5 program districts, only primary and middle
schools were chosen for SCMP. The eligibility criteria, whereby only schools with median or
higher enrollment within each district-by-level-by-gender cell were intended to participate,
informs our quasi-experimental research design. We leverage the existence of school-by-period
panel data across districts with and without the intervention in “difference in differences” (DD)
and “difference in difference in differences (DDD) designs. Using data from districts in which
the SCMP was piloted, our DD identification strategy compares the changes in outcomes across
treatment-eligible schools to the contemporaneous change observed in treatment-ineligible
schools. We also examine the key identifying assumption of the DD specifications (i.e., common
trends across treatment-eligible and ineligible schools) in DDD specifications that include panel
data from districts in which the SCMP was not piloted.
   We find that the program increased student enrollment by 5.7 percent relative to baseline
enrollment. However, the impact was statistically significant for primary schools only.
Furthermore, we find that the SCMP also reduced student attendance modestly (i.e., 1.2 percent),
suggesting that the marginal student enrollee was comparatively unlikely to attend school as
consistently as other students. Interestingly, the increase in enrollment and the decline in
attendance were the highest for female primary schools (i.e., girls aged 5-12). Specifically, we
find that the SCMP increased the enrollment of young girls by 12.4 percent (i.e., roughly 13 girls
per school). We also find that the SCMP increased teacher attendance by roughly 2 percent
relative to baseline attendance. The SCMP also increased the likelihood a school had functional
facilities but this impact statistically significant for male-primary schools only. In general, we
find that these effects grew during the duration of the program and continued in the months after
the program ceased operations.
   Overall, our results suggest that the engagement mechanism informed council members and
encouraged them to participate in school governance that improved school outcomes. We
speculate that continuous engagement with calling agents, who were of the same sex as the
members, and the fact that it was spearheaded by the provincial government, assisted their
engagement and added credibility to the calls. Moreover, we think that members, either through
passive oversight, or proactive engagement and monitoring of the school were able to impact
outcomes in their community’s schools. Our results also provide broader evidence on improving
public services through proactive citizen participation in low-cost and highly scalable ways (e.g.,
                                                                                                   3


compared to in-person training) via continuous engagement mechanisms between the state and
its citizens.
    The remainder of the paper is organized as follows: section 2 provides a discussion on the
theoretical framework and prior literature, section 3 describes the School Council Mobilization
Program, section 4 and 5 include a description of the data and identification strategies
respectively. Section 6 describes our results and section 7 provides a discussion and conclusion
to the paper.


2. Theoretical Framework and Prior Literature
        A broad and long-standing concern, both among policy-makers and in diverse academic
literatures, involves the question of whether (and when) representative government agencies are
ineffective in carrying out their core functions. The problem of poor representative governance is
widely viewed as a particularly critical impediment to improving the delivery of much-needed
public services within developing countries (World Bank 2004). The general theoretical frame
for understanding how such governance failures may persist in any context can be explained by
asymmetric information (i.e., a principal-agent problem). Funders and voters cannot easily or
efficiently observe the behavior of their representative government agents. Moreover, the
individuals operating government agencies may have private goals that diverge from the public
interest with regard to their own effort as well as the goals of the public agency. In these
circumstances, public services may be misaligned, underprovided, or even characterized by
outright corruption.
        An institutional design that may attenuate such problems involves the devolution of
authority for public services from centralized to local governments. For example, the literature
on fiscal federalism suggests that the local financing and provision of public goods, combined
with residential mobility (Tiebout 1956), can impose competitive pressures that may improve
public-sector performance. Furthermore, a more localized authority for the provision of public
services can enhance the relative capacity for direct democratic engagement and oversight by
concerned local citizens. Stiglitz (2002) stresses the unique policy relevance of such local
engagement in developing countries, noting that because community members are those who
benefit from a program, they have better incentives to monitor compared to the central-
government bureaucrats. However, the fact that the financing for public services in developing
                                                                                                                  4


countries is often centralized may weaken the incentives for local oversight and citizen
engagement.
        These concerns have motivated an increased interest in promoting the prevalence and
quality of local engagement in the provision of public services (World Bank 2004). In particular,
citizen participation in public sector delivery is one external mechanism that may mitigate the
problems of information asymmetry and moral hazard between the goals of individuals operating
government agencies and public interest, through oversight and engagement (Azfar et al. 1999;
Mansuri and Rao 2014). Participation may, for example, support accountability of public sector
workers who are rarely held accountable for their absences or corrupt practices.1 Local
engagement may also support the tailoring of public services to the unique needs of particular
communities, improve poverty targeting, and, overall, increase demand for good governance.
However, the efficacy of increased citizen engagement is, by no means, certain; community
members may have poor information on their rights and responsibilities with respect to local
governance as well as on the goals and challenges involved in the delivery of public services.
Grassroots monitoring may be prone to capture by local elites or free-rider problems (Bardhan
2002). Mansuri and Rao (2014) argue that absence of strong institutions at the center may also
constrain the ability of citizens to be fully engaged in service provision.
        A recent and growing empirical literature provides mixed evidence on how local
communities can be engaged to participate in improving public-sector performance in
developing countries. For example, Bjorkman and Svensson (2009) conducted a randomized
field experiment in Uganda in which localized NGOs informed communities about the status of
health facilities and encouraged them to hold their local providers accountable for performance.
The intervention provided information on the quality of services while also reducing the risk of
elite capture. It also addressed the participation constraint by involving large number of
community members and by encouraging them to develop a monitoring plan. They found the
intervention generated large increases in utilization of services and improved health outcomes as
measured by child mortality and child weight. However, Banerjee, Deaton and Duflo (2004)
designed an RCT in Udaipur in India where a member of the community was paid to monitor
clinics for 8 months and to take action using the collected information on absenteeism. They


1
  Chaudhry et al. (2004) document high absence rates among publically funded health workers and school teachers
in six developing who are not held accountable for their absences.
                                                                                                                   5


found that absence rates were the same in program and control facilities. The authors argue that
the key reason for this is that the community member did not manage to use his or her
information on absenteeism to invoke community participation. Similarly, Olken (2007) found
little impact of grassroots participation through increased attendance at community meetings and
issuance of anonymous comment forms to villagers on reducing corruption overall in over 600
Indonesian village road projects.2 The experiments sought to enhance participation at village
level meetings in which project officials account for how they spend project funds. Inviting more
members to monitoring meetings reduced only missing labor expenditures with no impact on
missing material expenditures. Issuing anonymous comment forms reduced missing expenditures
only if the comment forms were distributed via schools in the village, effectively bypassing
village officials. Because the entire village gains from reducing corruption in materials, the
authors suggest that grassroots monitoring can be effective in circumstances where local civic
engagement is robust.
         In studies focusing specifically on education, empirical evidence on the impact of
strengthening citizen participation to improve service delivery is also mixed. For example, in
Kenya, Duflo et al. (2014) found that giving school councils (SCs) the autonomy and funds to
hire an extra contract teacher in schools over whom the committee had direct control led to an
improvement in student test scores. The effects were larger when the SCs received school-based-
management (SBM) empowerment training on how to select job applicants, monitor and assess
teachers’ effort and performance and review the performance to renew teachers’ contracts. Civil-
service teachers were more likely to be present in class and teaching and relatives of civil
services teachers were less likely to be hired. Similarly, preliminary results from a randomized
control trial of 610 villages across three states in India, show that that structured information
campaigns about community roles and responsibilities in school management and services
available to schools, conducted through repeated village meetings over two months, led to a
significant and positive impact on community participation, provision of school entitlements, and
teacher effort (Goyal et al. 2008).3 In Gambia, also, results of an experiment in which principals,


2
  An anonymous invitation form was distributed along with the invitations to attend meetings, providing villagers an
opportunity to relay information about the project without fear of retaliation. The results on the comment forms were
discussed in the meetings.
3
  In one state, Karnataka, the community was also given information on the economic benefits of schooling and
there was explicit advocacy in campaign meetings to monitor learning in schools however there was no additional
                                                                                                                     6


teachers and members of the communities received comprehensive training in developing school
management plans as complements to a grant, improved teacher and student attendance but did
not have an impact on test scores (Blimpo et al. 2015).
        On the other hand, in Kenya, Kremer and Vermeerch (2005) found no effect of
empowering school committees by increasing the frequency of meetings with school
administration at the sub-district level and making them responsible for evaluating teacher
performance. Providing voice and control over resources did not reduce teacher absenteeism or
improve children’s performance on tests. Similarly, Banerjee et al. (2010) found that providing
information to villagers in India about the Village Education Committee and the status of
education in their villages, and pedagogical training for teaching basic reading skills to the
communities did not improve school performance, as measured by community participation in
schools, teacher and student attendance and learning outcomes.4 In both studies, information on
performance on outcomes was not relayed to SC members.
        These contrasting results for interventions aimed at improving service delivery via citizen
engagement suggest that the context and the way citizens are given a chance to participate in the
process of service delivery are imperative in predicting whether or not interventions will work to
improve public services. Our paper contributes in several ways to this literature on strengthening
local governance. From a design standpoint, the School Council Mobilization Program (SCMP)
has several uniquely compelling features. In particular, it uses a one-to-one, low-cost and
sustained engagement mechanism between the provincial government and the School Councils
(SCs) to encourage citizen participation in improving school governance. These design features
(i.e., provincial government directly engaging with leading citizens on a sustained and individual
basis) may play an important role in terms of influencing their behaviors. However, interventions
with these features have not, to our knowledge, been evaluated in local governance settings.
        Moreover, Pakistan provides a unique cultural and political setting to evaluate this
impact. Public services are plagued by under-provision and corruption. However, with growing
mobile and internet usage, several ICT-based citizen engagement initiatives are being piloted and


impact of this information. The study also measures the impact only 2-3 months after the intervention was
administered and the results are preliminary.
4
  Village Education Committees in India consist of the elected head of the village government, the head teacher of
the local school, and three parents who are nominated by their community. These committees are responsible for
monitoring school performance, allocating school resources and hiring additional contract teachers in the event of
overcrowding.
                                                                                                                     7


scaled up in the Punjab province to improve performance of services.5 SCMP, in particular, adds
to our understanding of whether this engagement mechanism improves school performance
through SC members who are autonomous but often unaware of their responsibilities. Also, it
provides broader evidence on improving public services through proactive citizen participation
through mechanisms spearheaded by a strong center. Lastly, our quasi-experimental
identification strategy helps us estimate a credible causal impact of the program that has
important policy implications.


3. The School Council Mobilization Program (SCMP)
         The School Council Mobilization Program (SCMP) was a pilot project conducted for 17
months and situated in the Punjab province of Pakistan. This program, which is described in
more detail below, focused on providing sustained and targeted guidance to school council
members on their civic responsibilities through low-cost engagement over mobile phones. The
Punjab province in which this pilot was situated comprises of almost 60% of the total population
of Pakistan. Approximately, 44% of Punjab’s population are children aged fewer than 18 years.
The province contains approximately 54,000, primary, middle (lower secondary), high (upper
secondary), and religious public schools spread across a total of thirty-six districts (PMIU
2012).6 Compared to other provinces in the country, Punjab has performed better in improving
key education indicators such as enrollment, student and teacher attendance, infrastructural
development and performance on test scores. However, the government is still struggling to
provide universal access to quality education. The net enrollment rate for example, is 62% at the
primary level and only 25% at the secondary level with a higher proportion of out-of-school girls
than boys (PSLM 2014).7 The World Bank is currently funding the Punjab Education Sector
Reform Program (PESRP), a highly visible province-wide program endorsed by the head of the
provincial government to improve access, quality and governance in the education sector. The
SCMP pilot was a component of the PESRP initiative.
School Councils in Punjab

5
  However, none of these programs (Bhatti et al. 2015; Masud 2015) has a timing and placement such that they
would confound this study’s inferences.
6
  Religious schools or Madrassas are usually situated within mosques and have their own religious curriculum
instead of the one prescribed by the provincial government.
7
  The net enrollment rate refers to the number of age-appropriate students enrolled in a level of education divided by
the total number of age-appropriate children for that level of education.
                                                                                                                 8


          The Government of Punjab established school councils (SCs) in 1994 in both primary
and middle schools as part of province-wide school-based management (SBM) reforms. These
SCs consist of a head-teacher (or principal) who serves as the chairperson and 7-15 elected
members, including parents (at least 50% of the SC membership), and notable individuals from
the community, such as shopkeepers. The members mostly belong to low-income backgrounds
with little or no education and serve on the council for a year. The School Council Policy 2007
(i.e., the official government guidance document for SCs) states that members are required to
meet monthly, keep records of their meetings and ensure two-thirds of the members attend them.
The SC members are also responsible for monitoring teacher, staff, and student attendance,
making efforts to increase enrolment, reducing dropouts, monitoring and assisting the provision
of textbooks, hiring temporary teachers and staff, managing the SC Fund, planning
infrastructural development, and keeping records of all transactions (Government of Punjab
2007).8
          In 2007, Punjab’s School Education Department initiated a capacity-building program for
SCs to inform them of their role in local governance. The National Rural Support Program
(NRSP) was contracted to conduct a three-day training in all primary and middle schools.9 The
trainings were held via community organizations in all schools between 2008 and 2011 and cost
the government PKR 8,000 ($180) per school for a one-time group-based session (Cambridge
Education 2014). A recent descriptive study examined 800 SCs in the province and found that
despite the on-going capacity building program, 21% failed to conduct the required one meeting
every month and 48% of the head teachers did not perceive the members to be aware of their
responsibilities (GTZ & I-SAPS 2010). The fact that SC performance remained uneven,
combined with the substantive implementation challenges (and comparatively high cost)
associated with in-person training, provided an important motivation for the phone-based SCMP
pilot. Another motivation is that, on average, 71% of Punjab’s households own a mobile phone
(MICS 2007-08) and this average ownership rate is likely to be higher among those serving on
school councils.
8
  Primary school councils are given PKR 20,000 ($200) and middle schools PKR 40,000 ($400) annually for
spending on school maintenance, hiring of an extra teacher and providing refreshments in council meetings. The
implementation review found that most councils did not spend the money that they were allotted at the start of the
fiscal year (Cambridge Education 2013).
9
  NRSP is a not-for-profit organization doing development and advocacy work in the country. It has a presence in 61
districts in all four provinces and works with 170,320 community organizations for rural development.
(http://nrsp.org.pk).
                                                                                                                    9


Program Description
        The SCMP began call-center operations in April of 2013 under the aegis of PESRP and
with the financial assistance of the World Bank. The call center was located in the provincial
capital, Lahore. A total of 15 individuals (i.e., 5 men and 10 women) trained as phone agents for
the SCMP.10 These agents placed monthly, informational phone calls to individual SC members;
each lasting approximately 6 minutes.11 The agents added credibility to the calls by informing
the members that the call was being made directly from the provincial school education
department. The members received calls from the same calling agent for the entire 17-month
duration of the intervention. In light of the cultural context, SC members were assigned same-sex
agents. In “Phase I” of the program (i.e., April 2013 to April 2014), the call center used a
purposefully time-varying (but integrated) script to engage with SC members every month. The
aim of the scripts was to discuss a unique SC responsibility each month and also to follow up
with SC members about that responsibility at the next call. The timeline for the calls and more
specific information on their content (e.g., the fourth call from July 15 to August 25 informed the
members of the process of conducting the monthly meetings) are provided in Table 1.
        In each call, the calling agent provided scripted information to the SCs on one area of
responsibility but the scripts did not specifically address how those tasks could be achieved
(Cambridge Education 2014). During some calls, SCs were also asked to give their feedback on
the current state of school management for their respective schools. In “Phase II” of the program
(i.e., May 2014 to August 2014), the order and content of the scripts was modified in response to
feedback from the field and from centrally monitored process data. The Phase II script also
emphasized the enrollment campaign to meet the Millennium Development Goal (MDG) of
achieving universal primary education.12 The agents also shared data on the number of out-of-
school children in the district and province.




10
   Abacus Consulting, a private call center in Lahore, was hired to carry out the operations.
11
   Initially, these monthly calls were complemented by two text messages to each SC member. However, the text
messages were discontinued owing to low-literacy levels of most council members who were unable to read them.
12
   The Chief Minister launched a province-wide awareness campaign to enroll every school-aged child in school to
meet the MDG in 2015. Interventions under PESRP incorporated this campaign as part of their design. The
existence of this province-wide effort implies a context that might conceivably attenuate the impact estimates we
report.
                                                                                                                  10


         This SCMP pilot was conducted among a subset of schools from 5 of Punjab’s 36
districts (i.e., Attock, Chiniot, Jehlum, Lodhran, and Sargodha).13 All of the schools in the
province are segregated by gender and the school-council members typically share the gender of
the students in the school they serve. Only primary schools (i.e., grades 1 to 5) and middle
schools (i.e., grades 6 to 8) were chosen for this program. School eligibility for the pilot was also
a function of school size. Specifically, within each of the 20 district-by-level-by-gender cells,
only the schools with median or higher enrollment were intended to participate. This criterion,
set by the World Bank, reflected both an interest in reaching more students and in increasing the
likelihood that SC members had mobile phones. We define treatment eligibility based on this
assignment rule. That is, the intent to treat (ITT) is a binary indicator equal to one for schools at
or above median baseline school enrollment within their district-level-gender cell. However,
there are several reasons that uptake of the “treatment” was sometimes inconsistent with this
eligibility rule. In particular, accurate mobile phone numbers were available for most but not all
of the SC members in eligible schools. Furthermore, to ensure that a fixed number of schools
were called every month, the district governments were instructed to add schools to the sample
that had SC members with valid phone numbers. To avoid the internal-validity threats created by
such non-random take-up of the treatment, our panel-based design, which is described in more
detail below, relies on the intent to treat implied by baseline enrollment and the intended
eligibility rule.14
         The fundamental goal of the SCMP was to utilize low-cost technology to inform and
mobilize SC members through sustained and thoughtfully designed engagement with school
governance and performance. Policy makers intended to combine the SCMP initiative with a
reconstitution of SCs in eligible schools (i.e., election of new SC members and a modest increase
of the minimum membership from 7 to 9). However, according to the SCMP implementation
review (2013), no elections were held and the head-teachers mostly added approximately two
members to the existing list of council members when needed.15 Given this modest change in SC

13
   These 5 districts provided a geographically dispersed sample across the province (Cambridge Education 2013).
The SCMP intervention expanded to 10 additional districts near the end of our study window (i.e., Phase II). We
exclude these districts from our study.
14
   We carefully considered but rejected using this assignment rule in a regression-discontinuity design (RDD). The
lack of a crisp “first-stage” jump around these thresholds weakened the credibility (and statistical power) of that
design for this context.
15
   SCMP districts were given only three days to carry out the reconstitution before call center operations began
hence elections were not held. Membership categories were revised and additional members added could be
                                                                                                                           11


membership, we view the treatment contrast created by SCMP eligibility as effectively defined
by the call-center intervention. However, the modest increase in SC membership may be a
relevant contextual factor.
         The program cost the government PKR 5000 ($50) per school for a year-long
engagement with SC members. The earlier NGO-delivered trainings, which were delivered in
person, cost nearly 4 times as much per school. As noted earlier, the SCMP also has other
distinctive design features. In particular, it provided more sustained and one-to-one engagement
of the provincial government with SC members compared to a one-time NGO-led training. This
type of continuous and personal engagement, spearheaded by a well-run center, may play an
important role in terms of influencing behaviors. However, whether this intervention was
actually effective in terms of influencing key school outcomes is ultimately an empirical
question. In the next two sections, we turn to the data and research design that will take up that
broad question.


4. Data
    The main source of data for our analysis is publically available school-level administrative
data collected regularly by the Program Monitoring and Implementation Unit (PMIU) of the
School Education Department in Punjab. This dataset includes administrative information on
total enrollment in schools, teacher and student attendance, district-administrator visits per
month, the provision of text books, their monthly expenditure, and the functionality of school
facilities such as toilets, electricity, and water and the presence of a boundary wall around the
school.16 Approximately 900 monitoring and evaluation assistants (MEAs), hired by Punjab’s
provincial government, administer the monthly survey (except for June, July and August) in all
36 districts (54,000 public schools).17
         We use data for the primary and middle schools in 26 out of the 36 districts in the
province. This data set includes the 5 districts that were exposed to Phases I and II of the SCMP



grandparents or siblings of existing students, local mosque representatives, retired teachers, and local elected
leaders.
16
   Functional facilities refer to running tap water or availability of utensils to store water in schools, a toilet that is in
order, functioning electricity connections, and a complete boundary wall around the school.
17
   The schools monitored by individual agents are rotated to attenuate the risk for intentional misreporting. We take
up the question of whether our findings might reflect, to an unknown extent, policy-endogenous misreporting in the
data. We argue that our pattern of results is inconsistent with this concern.
                                                                                                                12


but excludes 10 districts added to the pilot near the end of our study window.18 Our monthly data
from these 26 districts span the period from November 2012 to December 2014. It should be
noted that this panel data structure makes it possible to implement “difference in difference”
(DD) designs. For example, we can compare the change in outcomes across treatment eligible
and ineligible schools in the five districts where treatment occurred. Alternatively, we can
compare the outcome changes in treatment-eligible schools (i.e., sufficiently large schools)
across districts that did and did not participate in the pilot. Combining these data also allows us
to adopt a “difference in difference in differences” (DDD) approach. As we describe in the next
section, these data make it possible to examine (and, under certain assumptions, correct for)
violations of the identifying assumptions of the DD approach.
        The timeline for the intervention and corresponding data collection is summarized in
Table 2. It should be noted that there is no monitoring in June and July and only 50% of the
schools are monitored in May and August because of summer vacations from mid-May to mid-
August. Given that and the fact that not every school is surveyed in every month, we use the
averaged school data from four distinct time periods: November 2012 to April 2013, September
to November 2013, January to April 2014 and September to December 2014.19 This data
structure is an appropriate one for our analysis. The first time period captures school-level data
from the period just prior to the implementation of the SCMP. The next two periods correspond
to a time-period when the SCMP was actively engaging SC members in the field. And the third
period provides us monitoring data in the months shortly after SCMP activity had concluded.
This data period is an important one because it gives us some window into whether the effects of
the SCMP persist once direct engagement has ceased. We explore the possible treatment
heterogeneity by time period explicitly in our analysis.
        To identify our “intent to treat” (ITT) population and to construct our analytical sample,
we first relied on the baseline PMIU school-census data for 2012 that were utilized by the SCMP
team to identify eligible schools and to select program participants in the five program districts.20
In these five program districts, a school was identified as SCMP eligible if it had median or
higher enrollment in each of the 20 district-by-level-by-gender cells. We matched this baseline

18
   The data are not yet available to study this expanded pilot but this is a compelling opportunity for follow-up
research.
19
   The publicly available data file for December 2013 was corrupted and, therefore, excluded from our analysis.
20
   From this sample of 5,592 schools, we excluded schools that had no reported enrollment at baseline (n=53); none
of these schools participated in the SCMP pilot.
                                                                                                                 13


sample of schools to their corresponding PMIU monitoring data from the one pre and three post-
treatment periods described above. Our analytical sample also includes similarly constructed
school-period panel data drawn from the PMIU data files for schools in the 21 other districts
where the SCMP was not available. In particular, we identified schools in these 21 districts that
would have been SCMP eligible (i.e., if SCMP had been available) as those with median or
higher enrollment in each district-by-level-by-gender cells.
        Our final analytical sample, collapsed by time-period consists of 123,235 school-by-
period observations from 32,309 unique schools. However, this school-by-period panel data is a
somewhat unbalanced one, reflecting the fact that some schools in our baseline intent-to-treat
(ITT) population failed to participate in the PMIU monitoring in one or more of the follow-up
periods (or possibly merged into other schools or closed). Specifically, the rate of missingness
among baseline schools in the data increases from 5.1% in the first post-treatment period to 7.1%
in the final period. This missingness in the administrative data implies a modest external-validity
caveat.21 However, it also raises more substantive internal-validity concerns. That is, our
estimated impact of the SCMP eligibility could be biased if SCMP eligibility influenced the
likelihood of participating in the subsequent school-level monitoring. In fact, an auxiliary DD
regression in which missingness is the dependent variable indicates that SCMP-eligible were
modestly but significantly less likely to be missing from the post-treatment school monitoring.
That is, over this study period, schools with larger enrollments (i.e., SCMP eligible) increased
their monitoring participation relative to schools with lower-baseline enrollments (i.e., by
roughly 2 to 3 percent). Fortunately, there is a similar pattern among the schools in the 21 non-
program districts, suggesting that these trends in missingness were related to school size. An
auxiliary DDD specification in which missingness is the dependent variable indicates that
missingness is unrelated to SCMP eligibility. This evidence of “missingness at random” is one of
the reasons that we view the DDD specification as our preferred one. However, as a complement
to the concerns raised by missingness, we also report both DD and DDD results based on a
“balanced” sample of schools (i.e., each school observed in each time period).
        Table 3 presents key descriptive statistics for the unbalanced sample. By design, slightly
more than 50% of the schools were eligible to receive the program in program districts (or would


21
  The rate of missingness is higher for primary schools (5.0%) compared to middle schools (3.0%). It is also higher
for male schools (7.2%) compared to female schools (2.2%)
                                                                                                     14


have been eligible in non-program districts). Forty-four percent of the schools in the 5 program
districts (i.e., 2,159 out of 4,909 schools) participated in the SCMP. Treated schools are
identified as schools that received calls in the first month of the intervention (April 2013).
However, schools that received calls in the first month subsequently received all calls in the
proceeding months for the duration of the program. There are roughly the same number of male
and female schools in the sample. However, roughly 82% of these schools are primary rather
than middle schools.
       Table 3 also provides suggestive evidence on how the key school outcomes (e.g., average
student enrollment, student and teacher attendance, functioning school facilities) change over the
study period. In general, we see that these measures improved over time in both the program and
non-program districts. For example, average student enrollment shows an increase of 14 students
in the program districts, post-treatment. On average, these gains are somewhat larger in the
program districts than in the non-program districts, suggesting the existence of treatment effects.
In the next section, we describe more formally the research designs we use to examine such
questions.


5. Identification Strategies
       Our quasi-experimental approach to identifying the impact of the SCMP on school
outcomes leverages both the existence of school-by-period panel data across districts with and
without the intervention and our knowledge of school eligibility for the treatment. That is, we
effectively view a school i’s treatment eligibility, Ti, (i.e., whether its baseline enrollment was at
or above the median in its district-level-gender cell) interacted with being observed in the post-
treatment period as an instrumental variable (IV) for whether it actually participated in the
SCMP treatment. Our initial approach to estimating the effect of this “intent to treat” (ITT) is
based on a “difference in differences” specification of the following form:
                             Yit = α i + λt + β(Ti × POSTt ) + ε it                                 (1)
in which Yit is an outcome for school i observed in period t, αi represents school fixed effects, λt,
represents period fixed effects and the coefficient of interest, β, identifies the effects unique to
                 €
being a treatment-eligible school in the post-treatment period. The term, εit, is a mean-zero error
that accommodates school-level clustering (Liang and Zeger 1986; Bertrand et al. 2004). We use
the same general approach to estimate the “first-stage” effect of treatment eligibility on treatment
                                                                                                                    15


uptake. The ratio of the “reduced-form” and “first-stage” estimates identifies the effect of taking
up the SCMP intervention on school outcomes (i.e., the “treatment on treated” estimate). The
outcomes of interest are school enrollment, school-level student and teacher attendance and the
functionality of school facilities (toilets boundary wall, drinking water and electricity).22
         The impact estimate based on this DD approach (and the data from the five treatment
districts) controls for time-invariant traits unique to each school and time-varying determinants
shared by all schools. The estimated impact effectively compares the change observed among
treatment-eligible schools (i.e., schools with above-median enrollment) to the contemporaneous
change observed among treatment-ineligible schools (i.e., schools with below-median
enrollment). The critical identifying assumption in this approach is that the change observed over
time among the treatment-ineligible districts provides a valid counterfactual for the changes that
would have been observed in the treatment-eligible districts if the treatment had never occurred.
         One compelling way to assess the “common trends” assumption underlying a DD
approach (Angrist and Pischke 2008) is to examine the comparative trends across high and low-
enrollment schools (i.e., treatment eligible and ineligible) in the neighboring districts that have
not had the intervention (i.e., a “naïve” or “placebo” DD). The comparative data from schools in
the untreated 21 districts provide information on the existence and potential direction of biases in
DD inferences. Moreover, these data facilitate a “triple difference” (DDD) approach that isolates
the impact of interest (under weaker assumptions than the DD), using the data from all 26
districts. More specifically, the DDD approach is based on the following specification:
               Yigt = Ti + Pg + λt + (Ti × λt ) + (Ti × Pg ) + (Pg × λt ) + β(Ti × Pg × POSTt ) + ε igt            (2)

where Pg is a dummy variable that identifies schools in the five “program” districts where the
intervention was fielded. In the DDD approach, the coefficient of interest reflects the three-way
  €
interaction of being a treatment-eligible school during the post-treatment period and in a district
that offered the treatment. This approach controls unrestrictedly for several two-way interactions




22
  Our choice of outcome variables is constrained by the availability of administrative data. Prior studies that
evaluated local governance in the education setting have examined teacher and student attendance and test scores as
primary outcome measures. The literature also evaluates intermediate or process outcomes such as participation of
community members at meetings to assess the mechanism of impact. In our analysis, we are unable to evaluate
effects on SC attendance or test scores (which would reflect possible enrollment effects as well as student learning).
                                                                                                                     16


(e.g., period effects unique to treatment eligible schools across all districts and period effects
unique to the program status of a district).23
         The compelling feature of the DDD approach is that it provides a plausible way to correct
for violations of the “common trends” assumption that may vex DD inferences. In particular, the
DDD effectively controls for time effects that may be unique to treatment-eligible schools and to
treated locations. One way to acknowledge this feature of the DDD approach is to recognize the
parameter of interest, β, can be understood as the difference in two “difference in differences”.
That is, this DDD impact estimate is the difference between the “true” DD based on data from
the five program districts and the “naïve” DD based on data from the 21 non-program districts.
However, it should be noted that the DDD approach also embeds an identifying assumption.
Specifically, it assumes that the comparative trends across low and high-enrollment in the non-
program districts (i.e., the naïve DD) provides a valid counterfactual for the comparative changes
that would have been observed across such schools in the program districts and in the absence of
the program. Given the geographic proximity of the non-program districts and the fact that they
share provincial governance, this assumption has some face validity to it. However, we also note
that our DD impact estimates tend to be larger in absolute value than the corresponding DDD
estimates. This implies that we could view the DDD estimates as conservatively small estimates
of the effects of interest given the empirical evidence for the direction of the biases implied by
violations of the common-trends assumption.


6. Results
     We begin presenting our results by examining the effects of SCMP eligibility on school
participation in the SCMP intervention. Specifically, Table 4 presents such “first-stage”
estimates from DD and DDD specifications in which SCMP participation is the dependent
variable. The results consistently indicate (i.e., across both types of specifications and balanced
as well as unbalanced samples) that eligibility increased SCMP participation by a substantial
amount: 58 percentage points. In Table 5, we begin examining whether SCMP eligibility (and
the implied sharp uptake in SCMP participation) similarly influenced our outcome measures,



23
  As a practical matter, we continue to control for fixed effects specific to each school, which are perfectly collinear
with a school’s other fixed traits such as treatment eligibility and whether it resides in a program district.
                                                                                                       17


using DD specifications based on schools in the “program” districts where the SCMP was
implemented.
   Columns (1) and (2) in Table 5 present reduced-form DD estimates (i.e., based on equation
(1)) of the impact of being a treatment eligible school on outcomes for the unbalanced and
balanced panels, respectively. These results suggest that student enrollment went up by
approximately 5 students in SCMP eligible schools. Given the corresponding results in Table 4,
the implied IV/2SLS estimates suggest that SCMP participation increased student enrollment by
nearly 9 students (i.e., 5/0.58), an increase of roughly 7.5 percent relative to the pre-treatment
baseline. However, the DD estimates in Table 5 also suggest that these marginal enrollees were
less likely to attend school consistently, as SCMP eligibility implies a modest reduction in school
attendance. The results in Table 5 also indicate that SCMP eligibility increased teacher
attendance by 1 percentage point. This implies that SCMP participation increased teacher
attendance by 1.7 percentage points (i.e., 1.0/0.58), an increase of roughly 2 percent relative to
the baseline mean. The remaining DD results in columns (1) and (2) of Table 5 suggest that
SCMP eligibility had mixed effects on aspects of school facilities (e.g., improving the water
facility but reducing the likelihood that the school met standards for both toilets and electricity.
   The internal validity of these DD results turns critically the identifying assumption that both
SCMP-eligible and ineligible schools (i.e., schools with above vs. below-median enrollment)
would have shared “common trends” in the absence of the treatment. One compelling, ad-hoc
way to examine this assumption is to consider the comparative trends from schools in
neighboring districts in the province where the SCMP was not implemented (i.e., “non-program”
districts). More specifically, we imputed whether schools would have been eligible for the
SCMP if their district had participated in the pilot (i.e., was their baseline enrollment at or above
the median for their district-level-gender cell). Then, we used DD specifications to estimate the
“effect” of SCMP eligibility on our key outcomes.
       Columns (3) and (4) in Table 5 present the key results from these “naïve” or “placebo”
DD specifications based on panel data from schools in the 21 districts that were not exposed to
the program. We find that SCMP eligibility implied small but statistically significant and
positive effects on student enrollment and attendance. We also find that SCMP eligibility implied
consistently negative effects on the four school-facility measures. These results are consistent
across both balanced and unbalanced samples. Overall, these results suggest that the DD results
                                                                                                    18


are biased by independent trends in these outcome measures that are unique to higher-enrollment
schools but unrelated to the SCMP intervention.
       In light of this evidence, our preferred estimates are based on DDD specifications. These
estimates are based on pooled data from schools in program and non-program districts and they
control unrestrictively for time-varying determinants unique to higher and lower-enrollment
schools (i.e., through fixed effects unique to each eligibility-period cell). These DDD estimates
can be constructed by the “true” DD estimates in Table 5 from the “naïve” DD estimates (i.e., as
the difference in two difference in differences). However, we report the key DDD estimates
directly in Table 6, both for the balanced and the unbalanced samples. Across both samples,
these results indicate that SCMP eligibility generated statistically significant increases in student
enrollment, teacher attendance, and all four facilities measures. We also find consistent evidence
of a modest but statistically significant reduction in student attendance, in all likelihood,
reflecting the low attendance rates of marginal school enrollees.
       The implied IV estimates suggest that these gains in school performance are
meaningfully sized particularly relative to the comparatively low cost of the intervention. For
example, our estimates imply that the SCMP increased school enrollment by 6.7 students (i.e.,
3.905/0.584), an increase of 5.7 percent relative to the baseline mean. Similarly, our estimates
imply that participation in the SCMP increased teacher attendance by 1.9 percentage points, an
increase of 2.1 percent relative to the baseline mean. We find similarly sized gains for all four of
the facility measures, though it should be noted that, even at baseline, most schools in the
program districts met the requirements for toilets and water (i.e., roughly 99 percent). However,
only 88 percent of schools met the standard for electricity at baseline and we find that SCMP
participation increased this likelihood by 2.1 percentage points (i.e., 0.012/0.584) or 2.3 percent
relative to the baseline mean.
       These full-sample impact estimates may mask several forms of treatment heterogeneity.
For example, there are several reasons to suspect that the impact of the SCMP varies by time
period. School-council members may become more effective as their engagement with the call
center accumulated. Furthermore, the structured engagement of the call center (Table 1) indicates
that more explicit guidance around enrollment, teachers, and the use of funds began only in the
latter half of Phase 1. Furthermore, it may be that the effects of the SCMP intervention faded
once Phase II concluded. We examined these questions by modifying our DDD specification to
                                                                                                                19


allow our impact estimates to vary by each of the three post-treatment periods described in Table
2. We report the key results from these specifications in Table 7.
         The F-tests reported in column (4) of Table 7 indicate that we cannot always reject the
hypothesis that the effects are the same across these periods. Nonetheless, these results indicate
that the effects of the SCMP were consistently smaller and often statistically insignificant in the
first post-treatment period (i.e., midway through Phase 1). However, we also find that the effects
are larger in period 2 (i.e., near the end of Phase 1) and that they persist in period 3 (i.e., the four
months after operations ceased). These findings indicate that the effects of the SCMP grew over
time and did not immediately fade out.24 However, at least two caveats are appropriate. First, as
more data become available, a longer, post-treatment time window might find more evidence for
the existence of fade-out. Second, in period 3, the estimated effect of the SCMP on student
enrollment fell somewhat and the estimated effect on student attendance fell more sharply. This
pattern suggests that sustaining the gains in student enrollment, in particular, may require a
sustained or redesigned effort. The design of the SCMP calls did not inform SC members about
how enrollment could be increased or students could be encouraged to attend school. Qualitative
evidence suggests that the members either visited households door-to-door to encourage parents
to send out-of-school children to school or made announcements via the local mosque, efforts
that may have abated when the SCMP concluded (Cambridge Education 2014).
         There are also multiple reasons to speculate that the effects of the SCMP intervention
may vary by school level (i.e., primary vs. middle school) and by the gender of the students
served at the school. We examine this question by presenting our key DDD estimates in Table 8
for samples defined by the school level served and the gender of the students. Interestingly, we
find, for middle schools, no statistically significant effects of the SCMP on any of our 7 outcome
measures. This is striking because the net enrollment rate (NER) for middle schools in the
Punjab province (i.e., 25%) is substantially lower than the NER for primary schools (i.e., 62%;
PSLM 2012-2013). This pattern also suggests that the SCMP’s emphasis on meeting the
Millennium Development Goal of universal primary education may have narrowed its impact
towards early grades.



24
  One exception is that the teacher attendance gains are no longer statistically significant when the program
concluded. However, we cannot reject the hypothesis of a common treatment effect across all periods.
                                                                                                                      20


         Though the effects of the SCMP are concentrated in primary schools, the results in Table
8 also indicate that they varied by whether the school served boys or girls. For boys’ primary
schools, the effect of the SCMP on student enrollment is more modest. SCMP participation
increased enrollment by 4.9 students (i.e., 3.275/0.670), an increase of 4.6 percent relative to the
baseline mean. Interestingly, the increase in boys’ enrollment was not accompanied by a
statistically significant decline in student attendance. In boys’ primary schools, the SCMP did
lead to statistically significant increases in teacher attendance and in three of the four facility
measures. In contrast, the SCMP only increased one of the four facility measures in girls’
schools (i.e., water). This heterogeneity in facilities improvement may reflect cultural factors.
The school council members for girls’ schools are typically woman, who may be culturally
restricted from facilitating improvements in school construction (e.g., engaging contractors,
negotiating prices, etc.).25
         However, the results in Table 8 indicate that the SCMP was particularly successful in
increasing the enrollment of young girls. Specifically, these estimates imply that SCMP
participation increased a school’s enrollment of girls by 12.9 students (i.e., 6.816/0.527), an
increase of 12.4 percent relative to baseline enrollment in girls’ primary schools. However, the
results in Table 8 also indicate that the declines in student attendance were concentrated among
these young girls. The implied IV estimate indicates that SCMP participation reduced the student
attendance rate at girls’ schools by 2.1 percentage points (i.e., -0.011/0.527).
         Given this pattern of enrollment and attendance results, a reasonable question is whether
the gains in girls’ enrollment are meaningfully attenuated by the corresponding decline in student
attendance. Some simple back-of-the-envelope calculations allow us to engage this question. To
begin, consider designating the girls observed in these schools as either (i) those already enrolled
or (ii) those newly enrolled because of the SCMP. Then consider the empirical implications of
the conjecture that the newly enrolled students actually had attendance rates of zero. Specifically,
how would the overall student attendance rate change if the SCMP did not influence of already
enrolled students but each of the newly enrolled 12.9 students had an attendance rate of zero? It
is straightforward to show that the attendance rate would fall from 88.6 percent to 78.8 percent, a


25
  Provision of devices for storing water is incorporated in the definition of functional water facilities and these that
may easily be provided by females that could explain why we may see a positive impact on this facility for female
schools.
                                                                                                                    21


decline of 9.8 percentage points.26 The fact that the observed reduction in student attendance
attributable to the SCMP is substantially smaller than this suggests that the newly enrolled young
girls were indeed attending school for an appreciable amount of time.
         However, an alternative interpretation for our overall finding is that newly enrolled
students had little to no school attendance while already enrolled students experienced sharp
increases in attendance. But how large would the growth in student attendance among the
already enrolled have to be in order to explain our findings? It is straightforward to show that,
when newly enrolled students have zero attendance, the already enrolled students would need a
8.6 percentage point increase in attendance rates (i.e., from 88.6 percent to 97.2 percent) to
explain the modest overall attendance declines we observe. The implausibility of such large and
targeted effects suggests that the young girls who became newly enrolled because of the SCMP
had meaningful rates of school attendance. Nonetheless, the fact that we do observe modest
declines in overall school attendance also underscores the challenge of promoting sustained
school engagement among young girls in this region.


7. Discussion and Conclusion
     Local participation in the delivery of public services is a promising way to improve poverty
targeting, build community-level social capital, increase demand for good governance, and
improve outcomes for public services. However, local governance may not be effective because
of low levels of literacy among the community members, information asymmetry, lack of
incentives, and collective action that constrain the ability of citizens to be fully engaged in
service provision (Mansuri and Rao 2014). Various interventions involving local participation
have relaxed some of these constraints in order to understand the mechanisms of community
engagement that do improve public service delivery. The empirical evidence is mixed and, as
pointed out by Banerjee et al., (2010), it is difficult to disentangle if the mixed findings are
driven by differences in the details of the interventions or context or both.
         In this paper, we examine the same approach to governance reform (i.e., strengthening
local participation by informing community members of their roles and responsibilities) through
an intervention that has unique and compelling features. SCMP utilized low-cost mobile


26
  This calculation is based on the fact that, at baseline, girl’s primary schools in the program districts had an
average enrollment of 104.3 students and an average student attendance rate of 88.6 percent.
                                                                                                   22


technology to regularly engage with autonomous school council members in public schools
through scheduled calls via a call center. The provincial government that actively advocates the
devolution of school management responsibilities to the SCs initiated the calls and the SCs have
historically followed the mandate set by the government. The calls provided information on the
responsibilities of the SC in Phase I of the intervention (Table 1) to encourage direct
participation. This focus on participation is typical for most Community Driven Development
(CDD) programs in which participation is facilitated but information on performance on
outcomes is not provided (Bjorkman and Svensson 2009). In Phase II of the intervention,
specific information on enrollment rates in the province, and the need to enroll out-of-school
children was relayed.
       Overall, the program increased student enrollment but not attendance. The impacts were
statistically significant for primary schools only. The treatment-induced increases in enrollment
(and the decline in attendance) were the highest for female primary schools. Females have a
lower net enrollment rate to begin with, and the results suggest that girls enrolled through the
program had a low propensity to attend. Teacher attendance and the likelihood of functional
facilities increased but the impact was statistically significant for male-primary schools only. The
novelty in program design (i.e., continuous engagement as opposed to a one-time training)
appeared to relate to the change in outcomes. The impact of the SCMP grew as the cumulative
experience with the phone calls grew and as the advice conveyed by the call agents became more
specific. Moreover, these effects appeared to persist in the months after the program ceased
operations. In all, the results suggest that the engagement mechanism did induce behavioral
changes among council members that results in appreciable, though targeted, improvements in
school performance. Through proactive engagement, oversight, or monitoring, the council
members were able to improve enrollment (but not attendance among girls, especially), deter
male teachers from absenteeism, and improve facilities for schools for young boys.
       In order to situate our findings, it is important to understand the context and the nature of
the interventions in prior literature that have evaluated improving service delivery through local
civic engagement. First, there is some evidence that either providing information on public-
sector performance or supporting civic participation is, in isolation, largely ineffective. For
example, in field experiments in Uganda, Bjorkman and Svensson (2009) found that health care
outcomes improved when efforts to enhance participation of community members were linked to
                                                                                                  23


performance data. Similarly, Duflo et al. (2014) found that linking school-based management
(SMB) training to the collection of performance data meaningfully improved school outcomes.
In contrast, Banerjee et al. (2010) found that, in India, providing training and information to
Village Education Committees through non-governmental organizations (NGOs) was ineffective.
       In light of this literature (and the qualified success of the SCMP in improving school
outcomes), at least two SCMP design features should be underscored. One is that the
effectiveness of the SCMP may be due in part to the fact that it had the imprimatur of the
government rather than being organized by an NGO. Second, unlike other interventions, the
SCMP fostered sustained engagement with local SCs. The persistence of this engagement may
be central to creating and sustaining the performance benefits we found in this study. The other
important and compelling features of using mobile phone technology to support civic
engagement concern cost and scalability. The continuous engagement conducted under the
SCMP cost only PKR 5000 ($50) per school. In contrast, a prior effort to conduct one-time
training of SC members in Pakistan cost more than three times as much. Furthermore, the SCMP
model is likely to be substantially easier to scale up with high fidelity than more time and labor-
intensive training efforts. The qualified success of the SCMP in improving local oversight and
school performance, at least at the primary level, suggest that these design features merit further
replication and careful study.
                                                                                               24


References
Angrist, J. D., & Pischke, J. S. (2008). Mostly harmless econometrics: An empiricist's
       companion. Princeton university press.
Azfar, O., Kahkonen, S., Lanyi, A., Meagher, P., & Rutherford, D. (1999). Decentralization,
       governance and public services: the impact of institutional arrangements. Centre for
       Institutional Reform and the Informal Sector.
Banerjee, A. V., Banerji, R., Duflo, E., Glennerster, R., & Khemani, S. (2010). Pitfalls of
       Participatory Programs: Evidence from a randomized evaluation in education in
       India. American Economic Journal: Economic Policy, 1-30.
Banerjee, A., Deaton, A., & Duflo, E. (2004). Health, health care, and economic development:
       Wealth, health, and health services in rural Rajasthan. The American economic
       review, 94(2), 326.
Bardhan, P. (2002). Decentralization of governance and development. Journal of Economic
       perspectives, 185-205.
Bertrand, M., Duflo, E., & Mullainathan, S. (2004). How Much Should We Trust Differences-in-
       Differences Estimates?. Quarterly Journal of Economics, 119(1).
Bhatti, Z. K., Kusek, J. Z., & Verheijen, T. (2014). Logged On: Smart Government Solutions
       from South Asia. World Bank Publications.
Björkman, M., & Svensson, J. (2009). Power to the People: Evidence from a Randomized Field
       Experiment on Community-Based Monitoring in Uganda. The Quarterly Journal of
       Economics, 124(2), 735–769.
Blimpo, M., Evans, D. K., & Lahire, N. (2015). Parental human capital and effective school
       management: evidence from The Gambia. World Bank Policy Research Working Paper,
       (7238).
Cambridge Education. (2014). Review of Implementation of School Council Policy 2013
Chaudhury, N., Hammer, J., Kremer, M., Muralidharan, K., & Rogers, F. H. (2004, October).
       Provider absence in schools and health clinics. In Northeast Universities Development
       Consortium Conference, HEC Montreal, October.
Duflo, E., Dupas, P., & Kremer, M. (2015). School governance, teacher incentives, and pupil–
       teacher ratios: Experimental evidence from Kenyan primary schools. Journal of Public
       Economics, 123, 92-110.
                                                                                                25


Kremer, Mi., & Christel, V.(2005). School Committee Empowerment: Preliminary
       Notes. Mimeo, Harvard University
Liang, K. Y., & Zeger, S. L. (1986). Longitudinal data analysis using generalized linear models.
       Biometrika, 73(1), 13-22.
Mansuri, G., & Rao, V. (2012). Localizing development: does participation work?. World Bank
       Publications.
Masud, E., 2014, Calling the Public to Empower the State: Pakistan’s Citizen Feedback
       Monitoring Program, 2008-2014, Innovations for Successful Societies, Princeton
       University, http://successfulsocieties.princeton.edu/
Olken, B. A. (2007). Monitoring Corruption: Evidence from a Field Experiment in Indonesia.
       Journal of Political Economy, 115(2).
Social, P. (2014). Living Standards Measurement Survey (PSLM) 2012-13. Statistics Division,
       Government of Pakistan, Statistics Division, Pakistan Bureau of Statistics, Islamabad.
Pandey, P., Goyal, S., & Sundararaman, V. (2006). Community Participation in Public Schools -
     The Impact of Information Campaigns in Three Indian States. Policy Research Working
     Paper, The World Bank, Impact Evaluation Series No. 26(4776), 1-40.
Tiebout, C. M. (1956). A pure theory of local expenditures. The journal of political economy,
     416-424.
Stiglitz, J. E. (2002). Participation and development: Perspectives from the comprehensive
     development paradigm. Review of development economics, 6, 163-182.
World Bank. (2004). Making Services Work for Poor People. World Development Report 2004.
                                                                                         26


Table 1: Structure, Content and Timeline of SCMP Calls

Call      Year        Month calls are made Call Content
                                         Phase I
1         2013        Apr 15 – May 15        Introduction to the program
2         2013        May 15 – Jun 15        Introduction to the new School Council policy
3         2013        Jun 15 – Jul 15        School council meeting
4         2013        Jul 15 – Aug 15        Process of conducting the meeting
5         2013        Aug 15 – Sep 15        Procedure of changing SC membership
6         2013        Sep 15 – Oct 15        Managing the bank account
7         2013        Oct 15 – Nov 15        Enrollment and attendance
8         2013        Nov 15 – Dec 15        Hiring of temporary teachers
9         2013/2014   Dec 15 – Jan 15        Utilization of funds and audit
10        2014        Jan 15 – Feb 15        School planning
11        2014        Feb 15 – Mar 15        Record keeping
12        2014        Mar 15 – Apr 15        Advocacy (This call was not made)
                                        Phase II
1         2014        May
                                             Introduction to the program
2         2014        Jun
3         2014        Jul                    Emphasis on Millennium Development Goal of
4         2014        Aug                    achieving Universal Primary Enrollment

Source: Government of Punjab, 2014
                                                                        27



Table 2: Timeline of SCMP and Availability of Monthly Monitoring Data

   Year       Month         Calls                 Data Availability
               Nov
  2012
               Dec
                Jan
                                              Pre-treatment Period
               Feb
               Mar
               Apr
               May
                Jun
  2013         July
               Aug
               Sep
                           Phase I
                Oct                          Post-treatment Period 1
               Nov
               Dec
                Jan
               Feb
                                             Post-treatment Period 2
               Mar
               Apr
               May
               June        Phase II
  2014
               July
               Aug
               Sep
                Oct
                                             Post-treatment Period 3
               Nov
               Dec

Source: PMIU Monthly Monitoring Data, 2012-2014
                                                                                                                                  1


Table 3: Descriptive Statistics

                                          Program Districts                                    Non-Program Districts
                             Pre-Treatment              Post-Treatment               Pre-Treatment            Post-Treatment
VARIABLES                   Mean         SD           Mean          SD             Mean          SD          Mean          SD
Student Enrollment         117.152     88.665       131.141      100.026          135.792     116.245       145.400     124.686
Student Attendance          0.874       0.082         0.891        0.081           0.861        0.100        0.858        0.112
Teacher Attendance          0.895       0.119         0.914        0.129           0.889        0.125        0.907        0.137
Toilet Facility             0.984       0.109         0.987        0.098           0.956        0.179        0.979        0.121
Boundary Wall               0.928       0.230         0.955        0.191           0.912        0.257        0.929        0.236
Water Facility              0.998       0.024         0.991        0.072           0.987        0.076        0.991        0.069
Electricity                 0.880       0.308         0.911        0.271           0.806        0.372        0.844        0.345
SCMP Eligible               0.516       0.500         0.524        0.499           0.501        0.500        0.505        0.500
SCMP Participant              0           0           0.445        0.497             0            0            0            0
Female School               0.507       0.500         0.544        0.498           0.509        0.500        0.522        0.499
Primary School              0.830       0.376         0.809        0.393           0.833        0.373        0.823        0.382
Sample Size                      5,250                      14,344                       27,059                    76,582

Notes: The data are taken from the monthly monitoring reports of the Program Monitoring and Implementation Unit, School
Education Department in Punjab, Pakistan. The estimation sample consists of school-level panel data from 26 districts monitored
between November 2012 and December 2014. These statistics are from a mildly unbalanced school-by-period sample. We show
results for both balanced and unbalanced samples.
                                                                                                                                        2


Table 4: First-Stage Estimates - The Estimated Effects of SCMP Eligibility on Participation


                                                    Difference in Differences (DD)                   Triple Difference (DDD)
                                                   Unbalanced               Balanced              Unbalanced            Balanced
INDEPENDENT VARIABLE                                   (1)                     (2)                    (3)                  (4)
                                                    0.577***                0.584***               0.577***             0.584***
SCMP Eligibility
                                                     (0.013)                 (0.014)                (0.013)              (0.012)
Eligibility X Period FE                                No                      No                     Yes                  Yes
Program District X Period FE                           No                      No                     Yes                  Yes
Eligibility X Program District FE                      No                      No                     Yes                  Yes
Observations                                         19,594                  17,645                 123,235              109,834

Notes: The dependent variable is a binary variable for whether the school participated in SCMP. All specifications include school and
time-period fixed effects. Standard errors (in parentheses) are clustered at the school level.
 *** p<0.01, ** p<0.05, * p<0.1
                                                                                                                                      3


Table 5: Difference-in-Differences Reduced-Form Estimates - The Estimated Effects of SCMP Eligibility on School Outcomes

                                            Program Districts                                    Non-Program Districts
                                    Difference in Differences (DD)                       Naïve Difference in Differences (DD)
                                   Unbalanced                 Balanced                  Unbalanced                     Balanced
       OUTCOMES                         (1)                       (2)                       (3)                            (4)
                                    5.000***                  4.868***                    0.876*                        0.963*
Student Enrollment
                                     (0.933)                   (0.964)                    (0.470)                       (0.493)
                                     -0.004*                   -0.004*                   0.003**                        0.002*
Student Attendance
                                     (0.002)                   (0.002)                    (0.001)                       (0.001)
                                     0.010**                   0.010**                     0.000                         -0.002
Teacher Attendance
                                     (0.004)                   (0.004)                    (0.002)                       (0.002)
                                    -0.006**                  -0.006**                  -0.016***                     -0.016***
Toilet Facility
                                     (0.003)                   (0.003)                    (0.002)                       (0.002)
                                      0.000                     -0.000                  -0.010***                     -0.009***
Boundary Wall
                                     (0.004)                   (0.004)                    (0.002)                       (0.002)
                                    0.008***                  0.007***                  -0.004***                     -0.003***
Water Facility
                                     (0.002)                   (0.002)                    (0.001)                       (0.001)
                                   -0.017***                  -0.014**                  -0.029***                     -0.026***
Electricity
                                     (0.006)                   (0.006)                    (0.003)                       (0.003)

Notes: Each cell is a separate regression. All specifications include school and time-period fixed effects. The standard errors (in
parentheses) are clustered at the school level.
*** p<0.01, ** p<0.05, * p<0.1.
                                                                                                                                    4


Table 6: Triple-Difference Reduced-Form Estimates - The Estimated Effects of SCMP Eligibility on Outcomes

                                                                                              Triple Difference (DDD)
                                                                                     Unbalanced                     Balanced
OUTCOMES                                                                                  (1)                           (2)
                                                                                      4.066***                      3.905***
Student Enrollment
                                                                                       (1.041)                       (1.083)
                                                                                     -0.007***                      -0.006**
Student Attendance
                                                                                       (0.003)                       (0.003)
                                                                                       0.010**                       0.011**
Teacher Attendance
                                                                                       (0.005)                       (0.005)
                                                                                       0.010**                       0.009**
Toilet Facility
                                                                                       (0.004)                       (0.004)
                                                                                       0.010**                        0.008*
Boundary Wall
                                                                                       (0.004)                       (0.005)
                                                                                      0.012***                      0.010***
Water Facility
                                                                                       (0.002)                       (0.002)
                                                                                        0.012*                        0.012*
Electricity
                                                                                       (0.007)                       (0.007)
Eligibility X Period FE                                                                  Yes                           Yes
Program District X Period FE                                                             Yes                           Yes
Eligibility X Program District FE                                                        Yes                           Yes

Notes: Each cell is a separate regression. All specifications include school and time-period fixed effects. The standard errors (in
parentheses) are clustered at the school level. The R2 ranges from 0.427 to 0.976 in the unbalanced sample and from 0.393 to 0.975 in
the balanced panel.
*** p<0.01, ** p<0.05, * p<0.1.
                                                                                                                                       5


Table 7: Triple-Difference Reduced-Form Estimates - The Estimated Effects of SCMP Eligibility on Outcomes by Period

                                                Post-period 1            Post-period 2            Post-period 3              p-value
OUTCOMES                                             (1)                      (2)                       (3)                    (4)
                                                 3.485***                 4.731***                  4.014***
Student Enrollment                                                                                                            0.163
                                                   (1.076)                 (1.054)                   (1.268)
                                                  -0.007**                  -0.002                 -0.012***
Student Attendance                                                                                                            0.005
                                                   (0.003)                 (0.003)                   (0.003)
                                                    0.009                  0.014**                     0.008
Teacher Attendance                                                                                                            0.568
                                                   (0.006)                 (0.006)                   (0.006)
                                                    0.005                 0.015***                   0.011**
Toilet Facility                                                                                                               0.021
                                                   (0.004)                 (0.004)                   (0.005)
                                                    0.004                 0.015***                   0.012**
Boundary Wall                                                                                                                 0.063
                                                   (0.005)                 (0.005)                   (0.006)
                                                 0.016***                 0.013***                  0.006***
Water Facility                                                                                                                0.004
                                                   (0.003)                 (0.003)                   (0.002)
                                                    0.002                  0.017**                    0.018*
Electricity                                                                                                                   0.076
                                                   (0.006)                 (0.008)                   (0.010)

Eligibility X Period FE                              Yes                      Yes                      Yes                       -
Program District X Period FE                         Yes                      Yes                      Yes                       -
Eligibility X Program District FE                    Yes                      Yes                      Yes                       -

Notes: Each cell is a separate regression. All specifications include school and time-period fixed effects. The standard errors (in
parentheses) are clustered at the school level. There was no exposure to treatment in Period 3. The p-value in column 4 tests if
estimates across the three periods statistically differ from each other. The sample is mildly unbalanced.
 *** p<0.01, ** p<0.05, * p<0.1.
                                                                                                                                      6



Table 8: Triple-Difference Reduced-Form Estimates - The Estimated Effects of SCMP Eligibility by School Level and Gender

                                                                    Primary                                     Middle
                                                           Male                 Female                Male                 Female
OUTCOMES                                                    (1)                   (2)                  (3)                    (4)
                                                        0.670***               0.527***             0.527***              0.464***
First Stage: SCMP Participation
                                                         (0.020)                (0.021)              (0.051)               (0.046)
                                                         3.275**               6.816***              -7.930                  0.323
Student Enrollment
                                                         (1.296)                (1.588)              (4.892)               (3.557)
                                                          -0.005              -0.011***               0.003                 -0.007
Student Attendance
                                                         (0.004)                (0.004)              (0.007)               (0.007)
                                                         0.015**                 0.013               -0.007                 -0.006
Teacher Attendance
                                                         (0.007)                (0.009)              (0.010)               (0.011)
                                                        0.021***                 0.002                0.001                  0.004
Toilet Facility
                                                         (0.008)                (0.006)              (0.005)               (0.003)
                                                        0.025***                 0.006               -0.027                  0.003
Boundary Wall
                                                         (0.009)                (0.005)              (0.017)               (0.007)
                                                        0.014***               0.014***               0.005                  0.002
Water Facility
                                                         (0.004)                (0.004)              (0.005)               (0.004)
                                                           0.013                 0.017               -0.006                  0.003
Electricity
                                                         (0.012)                (0.011)              (0.013)               (0.012)

Eligibility X Period FE                                   Yes                    Yes                   Yes                   Yes
Program District X Period FE                              Yes                    Yes                   Yes                   Yes
Eligibility X Program District FE                         Yes                    Yes                   Yes                   Yes

Notes: Each cell is a separate regression. All specifications include school and time-period fixed effects. The standard errors (in
parentheses) are clustered at the school level.
*** p<0.01, ** p<0.05, * p<0.1.
