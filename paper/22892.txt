                              NBER WORKING PAPER SERIES




   BOUNDS ON TREATMENT EFFECTS IN REGRESSION DISCONTINUITY DESIGNS
                WITH A MANIPULATED RUNNING VARIABLE

                                        François Gerard
                                        Miikka Rokkanen
                                        Christoph Rothe

                                       Working Paper 22892
                               http://www.nber.org/papers/w22892


                     NATIONAL BUREAU OF ECONOMIC RESEARCH
                              1050 Massachusetts Avenue
                                Cambridge, MA 02138
                           December 2016, Revised May 2018




We thank Joshua Angrist, Wilbert van der Klaauw, Henrik Kleven, Ismael Mourifié, Johannes
Schmieder, Edward Vytlacil and seminar audiences at Boston University, Columbia, Institute for
Fiscal Studies, London School of Economics, Princeton, University College London, University
of Jyvaskyla, University of Luxemburg, University of Toronto, University of Turku, University
of Warwick, Yale and several conferences for their helpful comments. Earlier versions of this
paper were circulated under the titles “Identification and Inference in Regression Discontinuity
Designs with a Manipulated Running Variable” or “Bounds on Treatment Effects in Regression
Discontinuity Designs under Manipulation of the Running Variable, with an Application to
Unemployment Insurance in Brazil.” This research project was supported by a grant from the
National Science Foundation titled “Non-Standard Issues in Regression Discontinuity Designs.”
The views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.

NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.

© 2016 by François Gerard, Miikka Rokkanen, and Christoph Rothe. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.
Bounds on Treatment Effects in Regression Discontinuity Designs with a Manipulated Running
Variable
François Gerard, Miikka Rokkanen, and Christoph Rothe
NBER Working Paper No. 22892
December 2016, Revised May 2018
JEL No. C14,C21,C31,J65

                                          ABSTRACT

The key assumption in regression discontinuity analysis is that the distribution of potential
outcomes varies smoothly with the running variable around the cutoff. In many empirical
contexts, however, this assumption is not credible; and the running variable is said to be
manipulated in this case. In this paper, we show that while causal effects are not point identified
under manipulation, they remain partially identified under a general model that covers a wide
range of empirical patterns. We derive sharp bounds on causal parameters for both sharp and
fuzzy designs under our general model, and show how additional structure can be used to further
narrow the bounds. We use our methods to study the disincentive effect of unemployment
insurance on (formal) reemployment in Brazil, and show that our bounds remain informative,
despite the fact that manipulation has a sizable effect on our estimates of causal parameters.

François Gerard                                  Christoph Rothe
Department of Economics                          Department of Economics
Columbia University                              Columbia University
1022 IAB                                         cr2690@columbia.edu
420 West 118th Street
New York, NY 10027
and NBER
fgerard@columbia.edu

Miikka Rokkanen
Department of Economics
Columbia University
mr3454@columbia.edu
                                           1. Introduction
In a regression discontinuity (RD) design, treatment assignment is determined by whether a
special covariate, the running variable, falls to the left or the right of a fixed cutoff value.
The treatment’s average causal effect among units at the cutoff is then estimated by what
effectively amounts to a comparison of the average outcomes (and treatment probabilities, in
the case of a fuzzy design with imperfect compliance) of units in small neighborhoods on
either side of the cutoff. Thus, the key assumption for the validity of such an analysis is that
the distribution of units’ potential outcomes varies continuously with the running variable
around the cutoff. This ensures that the only systematic difference between units that are
close to but on different sides of the cutoff is their treatment assignment.
    Continuity of the potential outcome distribution given the running variable, however, may
not be a credible assumption in many empirical settings where the running variable is not
exogenously determined. Consider, for instance, studying the effect of a program that offers
financial aid to students who score above a certain threshold on a test. Since the program
affects incentives, it likely affects the running variable, i.e. test scores. This fact alone does
not invalidate the key identifying assumption for an RD analysis, and published empirical
papers in which the running variable is not exogenous abound in the literature (e.g., Solis,
2017). Yet, problems arise in such settings if, for instance, students whose score came up
short might bargain with their teacher for extra points, or teachers might proactively give
extra points to certain students with scores below the threshold. If the potential outcomes of
students who become eligible for financial aid through such channels differ from those of the
overall student population close to the cutoff, a conventional RD analysis is generally invalid.
Evidence for violations of the continuity condition on the distribution of potential outcomes
has been documented in many contexts.1
    Following now standard terminology, we refer to all setups in which such violations
occur as RD designs with a manipulated running variable.2 The practical importance of
this issue is widely recognized in the literature. Following McCrary (2008), who argues
that a jump in the density of the running variable at the cutoff is a strong indication of
manipulation, it has become common empirical practice to test for the presence of such a
jump. If the corresponding null hypothesis is not rejected, researchers typically proceed with
their RD analysis under the assumption that continuity of the potential outcome distribution
   1
     See, for instance, Urquiola and Verhoogen (2009), Camacho and Conover (2011), Scott-Clayton (2011),
Card and Giuliano (2014), or Dee, Dobbie, Jacob, and Rockoff (2016), among many others.
   2
     This terminology is not unproblematic, as it can be understood as suggesting that observational units
are engaging in a form of wrongdoing. This might be the case in some settings. However, as we argue more
carefully below, there can also be other actors within the respective institutional contexts that are violating
the rules, and manipulated running variables can even occur if no rules are violated at all.



                                                      1
is satisfied. In contrast, the cutoff is often no longer used for inference on treatment effects if
the null hypothesis is rejected.3 This practice is problematic for at least two reasons. First, a
non-rejection may not be due to the absence of manipulation but to a lack of statistical power,
e.g. due to a small sample size. Units just to the left and right of the cutoff could still differ in
their unobservable characteristics in this case, and estimates ignoring this possibility may be
severely biased. Second, even if one correctly rejects the null hypothesis of no manipulation,
the extent of the problem may be modest, and the data may remain informative. In this
paper, we propose a systematic approach to dealing with the issue of potentially manipulated
running variables in RD designs, which addresses both of these concerns.
    We begin by laying out a simple yet general model that posits the existence of two
unobservable types of units: always-assigned units, for which the realization of the running
variable is always on one side of the cutoff (normalized to be the right side); and potentially-
assigned units, for which the standard assumptions of an RD design are valid. The standard
RD framework is a special case of our model in which always-assigned units are absent. This
setup is able to capture a wide range of empirical scenarios of manipulation by appropriately
assigning the two labels to specific groups of units. The only substantial requirement is that
manipulation of the running variable occurs through a form of “one-sided” selection.
    We then avoid making a binary decision about whether the RD design is affected by
manipulation (i.e. whether always-assigned units are present), and let the data decide about
the extent and “worst case” impact of the issue. This line of reasoning leads to bounds
on causal parameters in two steps. First, we use the magnitude of the discontinuity in the
density of the running variable at the cutoff to identify the proportion of always-assigned
units among all units close to the cutoff. Second, we use this information to bound treatment
effects by finding those “worst case” scenarios in which the distribution of outcomes among
always-assigned units takes its “highest” and “lowest” feasible value (in a stochastic dominance
sense). For sharp RD designs, the bounds are simply obtained by trimming the tails of the
outcome distribution among units just to the right of the cutoff.4 For fuzzy RD designs, the
bounds are more elaborate in structure due to the various shape restrictions implied by our
model. To the best of our knowledge, these types of bounds are new to the literature. As
   3
     Some studies also rely on ad-hoc “fixes.” For instance, the “doughnut-hole” approach is sometimes used
in the existing literature to estimate causal parameters in cases of potential manipulation. This method
excludes observations around the cutoff somewhat heuristically, and then relies on extrapolation outside the
range of the remaining data to recover estimates of treatment effects at the cutoff for a population of units
that may or may not be actually observed at the cutoff under any circumstances. As we discuss below, this
approach is problematic in several ways and goes against the spirit of the usual RD identification argument.
   4
     This result shares similarities with that of Horowitz and Manski (1995) or Lee (2009); and some applied
papers have used heuristic arguments to arrive at some version of this strategy (e.g. Card, Dobkin, and
Maestas, 2009; Sallee, 2011; Anderson and Magruder, 2012; Schmieder, von Wachter, and Bender, 2012). Our
contribution with regard to the sharp design is thus mainly to formalize this approach.


                                                     2
extensions of our main results, we show that the bounds can be sharpened by using covariate
information, or by imposing further assumptions about the behavior of economic agents. We
also show that one can identify the distribution of covariates among always-assigned and
potentially-assigned units at the cutoff, which is helpful to characterize these groups.
    To implement our identification results in practice, we describe computationally convenient
sample analogue estimators of our bounds, and confidence intervals for the causal parameters
of interest based on recent methods from the literature on set inference (e.g., Imbens and
Manski, 2004; Stoye, 2009; Andrews and Soares, 2010). Software packages that implement
our methods in R and Stata are available on the authors’ websites. Our confidence intervals
provide reliable inference on treatment effects in cases where manipulation clearly occurs.
However, we also recommend their use in applications where it seems unclear whether the
standard RD assumptions are satisfied in order to ensure that inference is robust against the
possibility of manipulation.
    Lastly, we illustrate the usage of our approach by applying it to estimate the effect
of unemployment insurance (UI) around an eligibility cutoff in Brazil. We find significant
evidence of manipulation and selection at the cutoff, and our bounds imply that the magnitude
of naive RD estimates may be heavily affected by selection. Nevertheless, we are able to infer
that UI takeup increases the covered UI duration by at least 35.4 days or at least .236 month
per month of potential UI duration. This estimate is almost twice as large as estimates
around another discontinuity, and thus for another group of workers, in Brazil (Gerard and
Gonzaga, 2016). Behavioral responses to UI benefits are thus relatively large in our sample.
    The rest of the paper is organized as follows. Section 2 introduces our general framework
for RD designs with a manipulated running variable. Section 3 contains our main partial
identification results, and Section 4 presents useful extensions. Sections 5 discusses estimation
and inference. Section 6 then implements our approach in our empirical application. Section 7
concludes. Proofs and additional material can be found in the Appendix.


                        2. Model and Parameters of Interest
The conventional identification argument used in the RD literature relies on the assumption
that the conditional distribution of units’ unobservable characteristics given the running
variable does not change in a discontinuous manner at the cutoff. This condition implies
that units on different sides of the cutoff are “comparable” except for their treatment
assignments. Treatment effects can then be identified by comparing their respective outcomes
(and treatment probabilities). As pointed out above, however, this assumption might not
be credible in many empirical contexts. We refer to all setups where the usual continuity
condition on the distribution of potential outcomes does not hold as RD designs with a

                                               3
manipulated running variable. In this section, we introduce a general model for setups in
which manipulation (possibly) occurs, discuss its applicability, and clarify the interpretation
of the parameters of interest.

2.1. Model. The general structure of our setup is the same as that of a conventional RD
design. We observe independent data points (Xi , Yi , Zi , Di ), i = 1, . . . , n, where Xi is the
running variable, Yi is the outcome of interest; Zi denotes the treatment assignment, with
Zi = 1 if unit i is assigned to receive the treatment, and Zi = 0 otherwise, and Di is the actual
treatment status, with Di = 1 if unit i receives the treatment, and Di = 0 otherwise. The
treatment assignment satisfies Zi = I (Xi ≥ c) for some fixed cutoff value c. The RD design
is said to be sharp if every unit complies with its treatment assignment, i.e. Di = Zi for all i;
otherwise it is said to be fuzzy. Following Rubin (1974), we then posit potential outcomes Yi (d),
for d ∈ {0, 1}, corresponding to the outcome unit i would have experienced had it received
treatment d; and potential treatment states Di (x), for x ∈ supp(Xi ), corresponding to the
treatment status unit i would have experienced if its realization of the running variable had
been x. The observed outcome and treatment status are thus Yi = Yi (Di ) and Di = Di (Xi ),
respectively. We also define Di+ = Di (c+ ) ≡ limx↓c Di (x) and Di− = Di (c− ) ≡ limx↑c Di (x).5
     Extending the conventional RD setup, we now posit the existence of two unobservable
types of units in the observed data: always-assigned units, whose value of the running variable
always takes values on only one side of the cutoff, which we normalize to be the right side
without loss of generality; and potentially-assigned units, who can potentially be observed
on both sides of the cutoff, and for which we will assume the standard RD framework to be
valid. The standard “no manipulation” RD framework is a special case of this setup in which
always-assigned units are absent. We discuss how a wide range of empirical scenarios fit this
framework below. Let Mi ∈ {0, 1} denote the unobserved type of unit i, with Mi = 1 if unit
i is always-assigned and Mi = 0 if it is potentially-assigned. We use the following notation to
categorize units according to their compliance with the treatment assignment, and whether
they are potentially- or always-assigned:

                    Cm = {D+ > D− , M = m}, compliers of type m;
                    Am = {D+ = D− = 1, M = m}, always-takers of type m;
                    Nm = {D+ = D− = 0, M = m}, never-takers of type m;
   5
    Throughout the paper, we use the notation that g(c+ ) = limx↓c g(x) and g(c− ) = limx↑c g(x) for a generic
function g(·). We also follow the convention that whenever we take a limit we implicitly assume that this
limit exists and is finite. Similarly, whenever an expectation or some other moment of a random variable is
taken, it is implicitly assumed that the corresponding object exists and is finite.




                                                      4
for m ∈ {0, 1}.6 As shown below, it can be necessary to allow for all three types of compliance
patterns among always-assigned units in some settings, although it may be reasonable to
restrict always-assigned units to be compliers in other contexts. We formally impose three
assumptions.

Assumption 1. (i) P(D = 1|X = c+ , M = 0) > P(D = 1|X = c− , M = 0); (ii) P(D+ ≥
D− |X = c, M = 0) = 1; (iii) P(Y (d) ≤ y|D+ = d1 , D− = d0 , X = x, M = 0), E(Y (d)|D+ =
d1 , D− = d0 , X = x, M = 0) and P(D+ = d1 , D− = d0 |X = x, M = 0) are continuous in x at
c for d, d0 , d1 ∈ {0, 1} and all y; (iv) FX|M =0 (x) is differentiable in x at c, and the derivative
is strictly positive.

    This assumption implies that the standard conditions from the RD literature are satisfied
among potentially-assigned units.7 Assumption 1(i) requires that the treatment probability
changes discontinuously at the cutoff value. Assumption 1(ii) is a monotonicity condition
stating that the response of treatment selection to crossing the cutoff is monotone for
every unit. This rules out the existence of so-called “defiers”. Assumption 1(iii) is the key
continuity condition which roughly speaking requires the distributions of potential outcomes
and potential treatment states to be the same on both sides of the cutoff. Assumption 1(iv)
implies that the running variable has a positive density at the cutoff, and thus that there
are potentially-assigned units close to the cutoff on either side. Without this condition,
it would not be possible to compare units just above and below the cutoff. Note that
Assumptions 1(i)-(iii) simplify to the condition that E(Y (d)|X = x, M = 0) is continuous in
x at c for d ∈ {0, 1} for the special case of a sharp RD design.

Assumption 2. The derivative of FX|M =0 (x) is continuous in x at c.

    Assumption 2 is a weak regularity condition on the distribution of the running variable
among potentially-assigned units. Together with Assumption 1(iv), this assumption implies
that the density of Xi among potentially-assigned units is smooth and strictly positive over
some open neighborhood of c. Continuity of the running variable’s density around the cutoff
is a reasonable condition in applications, and is generally considered to be an indication for
the absence of manipulation in the applied literature (e.g. Lee, 2008; McCrary, 2008).
    6
      The existence of “defiers”, i.e. units with D+ < D− , is ruled out by Assumption 1(ii). We therefore do
not introduce notation for defiers in our paper. Note that assuming the absence of defiers is standard in the
literature on RD designs without manipulation.
    7
      We formalize the notion of a RD design in terms of continuity conditions on the distributions of potential
outcomes and treatment states as in Frandsen, Frölich, and Melly (2012), Dong (2017) or Bertanha and
Imbens (2016). This leads to the same identification results as directly imposing the local independence
condition that the treatment effect is independent of the treatment status conditional on the running variable
near the cutoff, as in Hahn, Todd, and Van der Klaauw (2001).


                                                       5
Assumption 3. (i) P(X ≥ c|M = 1) = 1, (ii) FX|M =1 (x) is right-differentiable in x at c.

    Assumption 3 is the only restriction we impose on always-assigned units. Its first part,
together with Assumption 1, implies that the running variable only takes on values to the
right of the cutoff among those units that are problematic for the validity of the RD design.
This (local) one-sided manipulation assumption is key for the identification argument in
the next section as it allows us to identify the proportion of always-assigned units among
all units close to the cutoff. As we discuss below, it is also realistic in many (although not
in all) empirical settings. The second part rules out mass points in the distribution of Xi
among always-assigned units around the cutoff. In particular, it rules out that the running
variable is exactly equal to the cutoff value for some (or all) always-assigned units. If this
was the case, one could identify units whose value of the running variable is equal to the
cutoff as always-assigned, and simply remove them from the analysis. Finally, together with
Assumption 2, Assumption 3 also implies that the running variable is continuously distributed
in the full population, with a density that is generally discontinuous at c.

Remark 1. Our parameters of interest, formally defined below, are treatment effects for
populations of units whose actual realization of the running variable is at the cutoff. Our
approach therefore does not require assuming the existence of a hypothetical “true” running
variable value that one would observe if one could “close” the institutional channel that leads
to a manipulated running variable. It also avoids making strong assumptions about how such
a “true” value and the actually observed value are related, which means that our setup can
be applied to a wider range of empirical settings, as we illustrate below.

2.2. Applicability of our Model. Our simple model turns out to be quite general, as
it is able to capture a wide range of empirical scenarios of manipulation by appropriately
assigning the labels of always-assigned and potentially-assigned to specific groups of units.
To illustrate this point, consider a transfer program for which eligibility is based on a cutoff
value of a poverty score, and the formula that creates the score takes as inputs household
characteristics and assets recorded during home visits by local administrators. There might
also be other criteria that make a household (in-)eligible irrespective of the poverty score, so
that the resulting RD design could in principle be fuzzy.8 The following examples illustrate
how various empirical scenarios are accommodated by our model. They also show why it may
be necessary to allow always-assigned units to be compliers, never-takers, or always-takers in
some settings, while in others it can be reasonable to assume that all of them are compliers.
  8
    These types of programs are common in developing countries, and various types of manipulation have
been documented for them (Camacho and Conover, 2011).



                                                  6
Example 1 (“Unsystematic” Misreporting). There might be concerns of manipulation
whenever a running variable can be affected by some agents’ behaviors. Running variables are
commonly endogenous, misreported, or mismeasured in the empirical literature, and this may
certainly affect the composition of the units observed around the cutoff. However, it is not
sufficient to create a manipulated running variable in the sense used in this paper. Suppose for
example that the formula for the poverty score is not publicly known. Then, even if households
might misreport or genuinely modify their input variables (within reasonable bounds), they
may not be able to ensure program assignment. All households are potentially-assigned in
this case; households just above and below the cutoff are still comparable; and a standard RD
analysis could estimate causal parameters for those households with realized poverty scores
at the cutoff. This is a trivial special case of our general model in which always-assigned
units are absent.

Example 2 (“Systematic” Misreporting). Suppose that some households know the poverty
score formula, and local administrators are unwilling or unable to recognize whether a
household reports inaccurate information as long as it is within reasonable bounds. Some
households with knowledge of the formula, and whose poverty score would otherwise fall to
the left of the cutoff, may then be able to misreport their inputs such that their score is to the
right of the cutoff. The assumption of one-sided manipulation is likely to hold, e.g. if program
assignment is weakly desirable for all households (they can always refuse to participate).
They might also have an incentive to report data that put them barely above the cutoff but
not exactly at the cutoff, e.g. in order to avoid detection. This makes the assumption of a
continuously distributed running variable among always-assigned units palatable. If these
misreporting households are systematically different from the other households with poverty
scores in the vicinity of the cutoff, the distribution of potential outcomes may be discontinuous
at the cutoff, and conventional RD analysis is invalid. In our model, the households with
knowledge of the formula that misreport data are always-assigned, while all other households
are potentially-assigned. Given that always-assigned households actively violate the rules of
the program, it may be reasonable to assume that all of them are compliers (i.e. all of them
participate in the transfer program if and only if their poverty score is above the cutoff).

Example 3 (“Systematic” Misreporting with Partial Verification Checks). Suppose that the
same households as above misreport their data to try to ensure program assignment, but
that some local administrators now thoroughly verify the information provided to them. As a
result, only a fraction of the households is able to carry out its intended misreporting. Those
households that succeed in misreporting their data are always-assigned in our setup. The
households whose misreporting efforts fail are classified as potentially-assigned along with


                                                7
those that did not make any misreporting attempt, provided that local administrators simply
enter the correct information if they detect misreporting. Indeed, this type of households –
that would unsuccessfully misreport their information if their correct score fell to the left of
the cutoff – also exists on the right of the cutoff; they just did not need to try to misreport
any data given that they were already on the right of the cutoff. Suppose instead that
local administrators apply a penalty by removing households from the data if they detect
misreporting. In that case, the same type of households will not be observed on the left of
the cutoff anymore, but only exists on the right of the cutoff. They will thus be classified as
always-assigned together with the households who were able to carry out their misreporting.
In both cases, it seems reasonable to assume again that all always-assigned units are compliers.

Example 4 (“Systematic” Misreporting by Administrators). Suppose that all households
report their information truthfully, but that local administrators sometimes misreport the
information that they receive. This may lead to a manipulated running variable even though
the observational units, i.e. the households, do not engage in any manipulation themselves.
For instance, local administrators may increase the score of households who support the local
government and whose score would otherwise fall to the left of the cutoff. Conventional RD
analysis is invalid in this case too, e.g. if a household’s political leanings correlates with the
effect of program participation. Our general model also likely applies. Manipulation is likely
to be one-sided and local administrators are unlikely to misreport information such that the
modified scores are equal to the cutoff (e.g. to avoid detection by central administrators).
Households with misreported data are then always-assigned, and all others are potentially-
assigned. Note that some always-assigned households might now refuse to participate in the
program (e.g. if it comes with social stigma), or might have qualified even with a lower poverty
score. Always-assigned households may thus be compliers, never-takers, or always-takers
in this scenario. Alternatively, suppose that local administrators also decrease the score of
political opponents whose score would otherwise fall to the right of the cutoff. This would be
a situation in which our model does not apply because of two-sided manipulation.

Example 5 (Manipulation through Location Selection). Manipulation of the running variable
does not require that any agent engages in some form of wrongdoing. Suppose that there is no
misreporting whatsoever, but that the program only exists in some localities. Households in
other localities may then choose to move to become eligible for the program. If the formula is
known, the probability of moving may increase discontinuously for households whose poverty
score would fall above the cutoff conditional on living in an eligible locality. As a result, the
density of the poverty score may be discontinuous at the cutoff and, to the extent that the
potential outcomes of movers differ from those of incumbent residents observed around the


                                                8
cutoff, a conventional RD analysis may be invalid. Moreover, the assumptions of one-sided
manipulation and of a continuously distributed running variable among always-assigned units
are reasonable if the program is weakly desirable. Those households who move because they
know that they are eligible for the program at destination are then the always-assigned units
in our model (they are responsible for the discontinuity in the moving probability) and they
are all likely to be compliers in this setting.

Example 6 (Second Home Visit). Suppose that households’ information is measured with
some error in any given home visit, and that households can request a second home visit
after learning the value of their score by arguing that their information was mismeasured in
the first visit. Additionally, only the score based on the most recent visit, which determines
program eligibility, is observed by the econometrician. Let Xji be the poverty score for
household i based on visit j, which is assumed to be smoothly distributed at the cutoff, and
suppose that households request a second visit if and only if they were ineligible based on the
first visit. The observed poverty score is then: Xi = X1i · I (X1i ≥ c) + X2i · I (X1i < c). Its
density is discontinuous at the cutoff as long as error terms are imperfectly correlated across
visits. The excess density is due to households whose score fell on the right side of the cutoff
in the first visit; those are the always-assigned units in our model. Moreover, to the extent
that their potential outcomes differ from those of households observed on the left of the cutoff
(whose poverty score fell on the left in both visits), a conventional RD analysis is invalid.9
Depending on the details of the program, this is also a case in which it may be reasonable to
allow always-assigned households to be compliers, never-takers, or always-takers.

    Having gone through the above examples, one can easily construct further variants that
also fit into our model. The examples also have natural analogues in other contexts. For
instance, Example 3 and 4 correspond to the two manipulation scenarios for the financial aid
example of the introduction. In sum, our model applies to a wide range of empirical settings,
although with some exceptions.

2.3. Parameter of Interest. The parameter of interest in RD designs without manipulation
is usually the local average treatment effect among compliers at the cutoff, which in our
notation is given by

                                   Γ ≡ E(Y (1) − Y (0)|X = c, D+ > D− ).
   9
       In contrast, if feasible, a RD analysis based on X1i or X2i |X1i < c could be valid in this setting.




                                                         9
When the running variable is potentially manipulated one has to be careful with this definition,
however, as the concern about manipulation implies that the function

                            x Ô→ E(Y (1) − Y (0)|X = x, D+ > D− )

may not be continuous at x = c due to the possible shift in the composition of units. Even if
we assume that the function is either right- or left-continuous, there is generally no economic
reason that dictates whether its value at x = c should be equal to its right or its left limit.
Under manipulation, Γ could therefore be equal to either of two local average treatment
effects among compliers at the cutoff, based on the left and right limits:

                       Γ− ≡ E(Y (1) − Y (0)|X = c− , D+ > D− ) and
                       Γ+ ≡ E(Y (1) − Y (0)|X = c+ , D+ > D− ).

It is important to note that we can always define Γ− and Γ+ , irrespective of whether the
running variable is manipulated or not. The two quantities simply coincide with each
other, and with Γ, in the absence of manipulation. In contrast, we generally have Γ− Ó= Γ+
when the composition of units shifts discontinuously around the cutoff. In this paper, we
present identification results for both Γ− and Γ+ , which are well-defined causal effects for the
population that is actually observed at the cutoff.
    For two reasons, we focus on Γ− in our main analysis, and present results for Γ+ as an
extension. First, we consider Γ− to be the more natural analogue of the usual RD parameter
under manipulation, as both can be interpreted as the causal effect among the subgroup of
units at the cutoff for which the usual RD assumptions hold. To see that Γ− carries this
interpretation, note that in our setup the defining property of potentially-assigned (M = 0)
units is that the usual RD framework applies to them, that the function

                       x Ô→ E(Y (1) − Y (0)|X = x, D+ > D− , M = 0)

is therefore continuous at x = c, and that there are only potentially-assigned units to the left
of the cutoff in our setup. Taken together, it follows that

                       Γ− = E(Y (1) − Y (0)|X = c, D+ > D− , M = 0).

This is important because it means that we can consider inference on Γ in the absence of
manipulation as a special case of inference on Γ− in our general setup, the special case
being the absence of always-assigned units. Inference on Γ− is therefore a meaningful goal
in empirical applications in which it is unclear whether the RD design is impacted by


                                               10
manipulation or not, while Γ could potentially not be well-defined in such contexts (if the
design is in fact impacted by manipulation).
    Second, Γ− carries the same notion of “policy relevance” under manipulation of the running
variable as the usual RD parameter does in setups without manipulation, in the sense that it
corresponds to the treatment effect for a group of units whose treatment status would change
following a marginal change in the level of the cutoff. In many settings, potentially-assigned
compliers may in fact be the only group of units whose treatment assignment changes in
response to a marginal cutoff change: whenever always-assigned units are above the cutoff
due to some active behavior on their part, such as misreporting information, they would
likely remain above the cutoff even if its value increases slightly.10

Remark 2. Quantile treatment effects can be an attractive alternative to average effects
in applications because they are less sensitive to variation in the outer tails of the outcome
distribution. We show below that it is straightforward to extend our results regarding the
identification of Γ− and Γ+ to their respective quantile counterparts, given by

                   Ψ− (u) ≡ QY (1)|X=c− ,D+ >D− (u) − QY (0)|X=c− ,D+ >D− (u)             and
                   Ψ+ (u) ≡ QY (1)|X=c+ ,D+ >D− (u) − QY (0)|X=c+ ,D+ >D− (u),

for some quantile level u ∈ (0, 1).

Remark 3. We would like to emphasize that our parameters of interest are causal effects for a
population that is actually observed at the cutoff, and not some hypothetical population that
one would observe at the cutoff under some circumstance. We see this as an advantage relative
to the “doughnut hole” approach that is sometimes used in applications where manipulation
is a concern. This method excludes observations around the cutoff, and extrapolates trends
estimated among units outside of the excluded range to the cutoff. The result of this exercise
in then often interpreted as a causal effect for a population that would be observed at the
cutoff if the distribution of potential outcomes there would follow its trend from outside the
excluded range. This hypothetical population is in particular often considered to be the
one that would be observed in a counterfactual setting in which the channel that leads to a
manipulated running variable has been “closed”. Such an interpretation does not only require
strong assumptions regarding how manipulation occurs, but also statistical assumptions
  10
     This is likely, for instance, in the examples of Systematic Misreporting by households or administrators.
In contrast, always-assigned units just above the cutoff would likely change their treatment status in the
Location Selection example. Finally, in the Second Home Visit example, units whose poverty score was just
above the cutoff after the first visit would not be automatically eligible anymore following a small increase in
the cutoff; some units, however, would likely remain eligible thanks to a higher poverty score after the second
visit. Of course, by definition, no always-assigned unit would gain eligibility following a decrease in the cutoff.


                                                       11
implying that extrapolation biases are small. No such assumptions are required in our case.


                                3. Identification: Main Results
In this section, we derive our main results regarding the identification of Γ− . We first state
some preliminary results, then consider the relatively simple case of a sharp RD design, before
finally analyzing the general case of a fuzzy RD design.

3.1. Preliminaries. Since it is not possible to determine whether a specific unit is of
the always-assigned or the potentially-assigned type, this parameter is generally not point
identified under manipulation of the running variable. We therefore derive sharp lower and
upper bounds on Γ− for both sharp and fuzzy RD designs. Our general strategy is to first
obtain sharp lower and upper bounds, in a first-order stochastic dominance sense, on the
c.d.f.s FY (d)|X=c,C0 for d ∈ {0, 1}.11 Once these have been obtained, it follows from Stoye
(2010, Lemma 1) that sharp upper and lower bounds on Γ− are given, respectively, by
                     Ú                 Ú                           Ú                 Ú
             ΓU− ≡       ydF1U (y) −       ydF0L (y) and ΓL− ≡         ydF1L (y) −       ydF0U (y).

Given bounds on the c.d.f.s of potential outcomes, it would be straightforward to consider
quantile treatment effects as well. Note that, for notational convenience, all results in this
section are stated for the special case of a continuously distributed outcome variable; we
extend our results to outcomes whose distribution has mass points in Appendix B.
   Our analysis repeatedly uses an important intermediate quantity, the proportion of
always-assigned units among all units just to the right of the cutoff, which we denote by

                                            τ ≡ P(M = 1|X = c+ ).                                         (3.1)

While we cannot observe or infer the type of any given unit, under our assumptions we can
point identify τ from the size of the discontinuity in the density fX of the observed running
variable at the cutoff. We formally state this insight in the following Lemma.

Lemma 1. If Assumptions 1–3 hold, then τ = 1 − fX (c− )/fX (c+ ) is point identified.

3.2. Sharp RD Designs. In a sharp RD design every unit is a complier, and thus receives
the treatment if and only if its value of the running variable is to the right of the cutoff. Since
every unit just to the left of the cutoff is potentially-assigned, the distribution of Y in this
  11
    That is, we derive c.d.f.s FdU and FdL that are feasible candidates for FY (d)|X=c,C0 in the sense that they
are compatible with our assumptions and the population distribution of observable quantities, and that are
such that FdU ² FY (d)|X=c,C0 ² FdL , where ² denotes first-order stochastic dominance. For two generic c.d.f.s
A and B, we say that A ² B if and only if A(y) ≤ B(y) for all y.



                                                      12
subpopulation coincides with the distribution of Y (0) among potentially-assigned compliers
(C0 ) at the cutoff:

                                   FY (0)|X=c,C0 (y) = FY |X=c− (y).

To bound Γ− , we therefore only need to bound the distribution of Y (1) among potentially-
assigned compliers at the cutoff. Information about Y (1) is only contained in the subpopula-
tion of treated units, which contains potentially- and always-assigned compliers (C0 and C1 ).
Sharpness of the RD design then implies that

                                         P(C1 |X = c+ ) = τ,

Since this quantity is point identified by Lemma 1, we proceed analogously to Horowitz and
Manski (1995) or Lee (2009) to obtain a bound on FY (1)|X=c,C0 (y). In particular, a sharp
upper bound on FY (1)|X=c,C0 (y), in a first-order stochastic dominance sense, is obtained by
truncating the distribution FY |X=c+ (y) below its τ -quantile. A sharp lower bound is obtained
analogously by truncating FY |X=c+ (y) above its (1 − τ )-quantile. That is, the bounds on
FY (1)|X=c,C0 (y) are given, respectively, by

     U                                               L
    F1,SRD (y) = FY |X=c+ ,Y ≥QY |X=c+ (τ ) (y) and F1,SRD (y) = FY |X=c+ ,Y ≤QY |X=c+ (1−τ ) (y).

These bounds correspond to the “extreme” scenarios in which the proportion 1 − τ of units
just to the right of the cutoff with either the highest or the lowest outcomes are the potentially-
assigned units. These bounds are sharp because both “extreme” scenarios are empirically
feasible. The following theorem translates these findings into explicit bounds on Γ− .

Theorem 1. Suppose Assumptions 1–3 hold, that P (D+ > D− ) = 1, and that FY |X=c+ (y) is
continuous in y. Then sharp lower and upper bounds on Γ− are given by

                ΓL−,SRD = E(Y |X = c+ , Y ≤ QY |X=c+ (1 − τ )) − E(Y |X = c− )       and
                ΓU−,SRD = E(Y |X = c+ , Y ≥ QY |X=c+ (τ )) − E(Y |X = c− ),

respectively.

3.3. Fuzzy RD Designs. In a fuzzy RD design with a manipulated running variable, the
population might contain always-takers and never-takers in addition to compliers, and each
unit is either potentially assigned or always-assigned. As shown in Table 1, there are thus
six different types of units and four possible combinations of treatment assignments and
treatment decisions that are relevant for our analysis. To derive bounds on the distributions
of the two potential outcomes among potentially-assigned compliers (C0 ) at the cutoff, we

                                                  13
                  Table 1: Allocation of Units’ Types in the Fuzzy RD Design
                      Subset of population       Types of units present
                        X = c+ , D = 1              C0 , C1 , A0 , A1
                        X = c− , D = 1                    A0
                        X = c+ , D = 0                   N0 , N1
                        X = c− , D = 0                   C0 , N0
                      Note: See Section 2.1 for a definition of units’ types.




begin by introducing the following notation for the proportion of always-assigned units among
those units with treatment status d ∈ {0, 1} just to the right of the cutoff:

                        τd ≡ P(M = 1|X = c+ , D = d),         d ∈ {0, 1}.                 (3.2)

We then proceed in three steps. In Step 1 and 2 we obtain bounds on the distribution of
potential outcomes under treatment and non-treatment, respectively, for the hypothetical
case in which the true values of τ1 and τ0 are known. In Step 3, we then derive our final
bounds on Γ− , given that the true values of τ1 and τ0 are in fact unknown.

Step 1: Distribution of Potential Outcome under Treatment. We begin by consid-
ering bounds on FY (1)|X=c,C0 . Information about the distribution of Y (1) is only contained in
the data on treated units. From Table 1, we see that the subpopulation of treated units just
to the left of the cutoff consists exclusively of potentially-assigned always-takers (A0 ). The
c.d.f. FY (1)|X=c,A0 is therefore point identified:

                              FY (1)|X=c,A0 (y) = FY |X=c− ,D=1 (y).

Using simple algebra, we find that the proportion of A0 units among treated units just to the
right of the cutoff, which we denote by κ1 , is point identified as well:

                                       +                   E(D|X = c− )
                    κ1 ≡ P(A0 |X = c , D = 1) = (1 − τ ) ·              .                 (3.3)
                                                           E(D|X = c+ )

To simplify the notation, we also define

                                 G(y) ≡ FY (1)|X=c,C0 ∪C1 ∪A1 (y).




                                                14
It then follows from the law of total probability that this c.d.f. is also point identified:12
                                      1 1                                          2
                      G(y) =               FY |X=c+ ,D=1 (y) − κ1 FY |X=c− ,D=1 (y) .
                                    1 − κ1
The c.d.f. FY (1)|X=c,C0 can now be bounded sharply by considering the two “extreme” scenarios
in which potentially-assigned compliers (C0 ) are those units just to the right of the cutoff in
the subpopulation C0 ∪ C1 ∪ A1 with either the highest or the lowest outcomes. The share of
C0 units in this subpopulation is
                                                                          τ1
                              P(C0 |X = c+ , C0 ∪ A1 ∪ C1 ) = 1 −              .
                                                                        1 − κ1
Given knowledge of τ1 , we therefore obtain a sharp upper bound on FY (1)|X=c,C0 , in a first-
order stochastic dominance sense, by truncating the distribution G below its τ1 /(1 − κ1 )
quantile. Analogously, we obtain a sharp lower bound by truncating G above its 1−τ1 /(1−κ1 )
quantile. With some algebra, these bounds on FY (1)|X=c,C0 given knowledge of (τ1 , τ0 ) can be
written, respectively, as
                                                               ;           3        4<
             U                     (1 − κ1 ) · G(y) − τ1                    τ1
            F1,F RD (y, τ1 , τ0 )=                        · I y ≥ G−1                      and
                                       1 − κ1 − τ1                        1 − κ1
                                                        ;          3            4<
             L                     (1 − κ1 ) · G(y)             −1         τ1
            F1,F RD (y, τ  ,
                          1 0τ ) =                  · I  y  ≤ G      1 −           ,
                                          τ1                             1 − κ1

Step 2: Distribution of Potential Outcome under Non-Treatment. Next, we consider
bounds on FY (0)|X=c,C0 . Information about the distribution of Y (0) is only contained in the
data on untreated units. From Table 1, we see that untreated potentially-assigned compliers
(C0 ) are never observed in isolation just to the left of the cutoff, but only together with
potentially-assigned never-takers (N0 ). Given knowledge of τ0 , the share of the latter type of
units, which we denote by κ0 · (1 − τ0 ), is point identified:

                                                                     1    1 − E(D|X = c+ )
        P(N0 |X = c− , D = 0) = κ0 · (1 − τ0 ),            κ0 =         ·                  .           (3.4)
                                                                   1 − τ 1 − E(D|X = c− )

If we were to use only information from untreated units just to the left of the cutoff, we could
therefore obtain lower and upper bounds on FY (0)|X=c,C0 (y) by truncating the distribution
FY |X=c− ,D=0 (y) below its κ0 ·(1−τ0 ) quantile and above its 1−κ0 ·(1−τ0 ) quantile, respectively.
However, such bounds are generally not sharp. This is because they correspond to “extreme”
scenarios in which potentially-assigned never-takers (N0 ) have either the highest or the lowest
outcomes among untreated units just to the left of the cutoff. By Assumption 1, however, the
  12
     Note that the quantity on the right-hand-side of the following equation is guaranteed to be a proper
c.d.f. in our model. If empirically that would turn out not to be the case, this would mean that our model is
rejected by the data.


                                                      15
c.d.f. FY (0)|X=x,N0 (y) varies continuously in x around the cutoff, and thus these two “extreme”
scenarios might be at odds with the distribution of outcomes that we observe among untreated
units just to the right of the cutoff. Indeed, from Table 1, we see that the subpopulation of
untreated units just to the right of the cutoff also contains potentially-assigned never-takers,
together with always-assigned never-takers (N1 ), and their share in this subpopulation is

                                      P(N0 |X = c+ , D = 0) = 1 − τ0 .

We can thus write the density fY (0)|X=c,N0 (y) in two different ways using information from
either side of the cutoff (assuming κ0 > 0 and τ0 < 1):

                           fY |X=c− ,D=0 (y) − (1 − κ0 · (1 − τ0 ))fY (0)|X=c,C0 (y)
       fY (0)|X=c,N0 (y) =                                                                             and   (3.5)
                                                κ0 · (1 − τ0 )
                           fY |X=c+ ,D=0 (y) − τ0 fY (0)|X=c,N1 (y)
       fY (0)|X=c,N0 (y) =                                          .                                        (3.6)
                                           1 − τ0
To be compatible with the distribution of Y among untreated units on either side of the
cutoff, any feasible candidate for fY (0)|X=c,N0 (y) thus has to be such that

                                           fY (0)|X=c,N0 (y) ≤ s(y, τ0 )

for all y ∈ R, where
                                                ;                                                  <
                                1          1
                s(y, τ0 ) ≡          · min    · fY |X=c− ,D=0 (y), fY |X=c+ ,D=0 (y) .
                              1 − τ0       κ0
This is because otherwise one of the density functions fY (0)|X=c,C0 (y) or fY (0)|X=c,N1 (y) would
have to take a negative value in order for equations (3.5)–(3.6) to be satisfied. The most
“extreme” feasible candidates for FY (0)|X=c,N0 (y), which put as much probability mass as
possible to one of the tail regions of the support of the outcome variable, are then given by
                                                Ú   y
                     FYU(0)|X=c,N0 (y) =                s(t, τ0 )I {t ≥ qU (τ0 )} dt         and
                                                 −∞
                                                Ú y
                     FYL(0)|X=c,N0 (y) =                s(t, τ0 )I {t ≤ qL (τ0 )} dt,
                                                 −∞

respectively, where qU (τ0 ) and qL (τ0 ) are constants such that
                              Ú   ∞                        Ú   qL (τ0 )
                                           s(t, τ0 )dt =                  s(t, τ0 )dt = 1.                   (3.7)
                                qU (τ0 )                    −∞


We illustrate this construction in Figure 3.1. The “extreme” candidates for FY (0)|X=c,N0 (y)
directly correspond to “extreme” candidates for the density fY (0)|X=c,C0 (y) through the
relationship (3.5), which in turn yields the following sharp upper and lower bounds, in a

                                                           16
                       f Y|X =c−,D=0( y)/(κ 0(1−τ 0))

                                                            f Y|X =c+,D=0( y)/(1−τ 0)




                             !!"#$
                               "#$                      !%#$


                                                                                        y
                                          qL qU
Figure 3.1: Construction of upper and lower bounds for FY (0)|X=c,N0 . The solid and dotted lines
represent the graph of the functions fY |X=c− ,D=0 (y)/((1 − τ0 )κ0 ) and fY |X=c+ ,D=0 (y)/(1 − τ0 ),
respectively. The function s(y, τ0 ) is the pointwise minimum of these two functions. The upper
contours of the shaded areas (1) and (2) then correspond to the densities of FYL(0)|X=c,N0 and
FYU(0)|X=c,N0 , respectively, as the constants qL (τ0 ) and qU (τ0 ) are chosen such that the surface of
the shaded areas is equal two 1. Note that it is not necessarily the case that qL (τ0 ) < qU (τ0 ).




first-order stochastic dominance sense, on the c.d.f. FY (0)|X=c,C0 given knowledge of (τ1 , τ0 ):

             U
                                     FY |X=c− ,D=0 (y) − κ0 · (1 − τ0 )FYL(0)|X=c,N0 (y)
            F0,F RD (y, τ1 , τ0 ) =                                                        and
                                                     1 − κ0 · (1 − τ0 )
             L
                                     FY |X=c− ,D=0 (y) − κ0 · (1 − τ0 )FYU(0)|X=c,N0 (y)
            F0,F RD (y, τ 1 , τ0 ) =                                                     .
                                                     1 − κ0 · (1 − τ0 )

If the envelope function s(·, τ0 ) happens to be a proper density these two bounds coincide,
and the c.d.f. FY (0)|X=c,C0 is point identified. This would be the case, for example, if τ0 = 0
(no untreated always-assigned units just to the right of the cutoff) or E(D|X = c+ ) = 1 (no
untreated units of any type just to the right of the cutoff).

Step 3: Bounds on Parameter of Interest. The analysis in Steps 1 and 2 shows that if
we knew the values of τ1 and τ0 , sharp upper and lower bounds on the local average treatment




                                                   17
effect Γ− would be given by
                                        Ú                                 Ú
              ΓU−,F RD (τ1 , τ0 )   ≡          U
                                            ydF1,F RD (y, τ1 , τ0 )   −          L
                                                                              ydF0,F RD (y, τ1 , τ0 ) and
                                        Ú                                 Ú                                  (3.8)
              ΓL−,F RD (τ1 , τ0 ) ≡            L
                                            ydF1,F RD (y, τ1 , τ0 ) −
                                                                                 U
                                                                              ydF0,F RD (y, τ1 , τ0 ),


respectively. However, these bounds are not directly feasible, as the population values of τ1
and τ0 are generally unknown. Nevertheless, the two values can be shown to be partially
identified. To see this, note that there are four logical restrictions on the range of their
plausible values. First, since τ1 and τ0 are probabilities, it has to be the case that

                                                    (τ1 , τ0 ) ∈ [0, 1]2                                     (3.9)

Second, by the law of total probability, it must hold that

                          τ = τ1 · E(D|X = c+ ) + τ0 · (1 − E(D|X = c+ )).                                  (3.10)

Third, our monotonicity condition in Assumption 1(i) implies that
                                                        1 − τ1
                                    E(D|X = c+ ) ·             > E(D|X = c− ).                              (3.11)
                                                        1−τ
Note that this condition can be equivalently stated as τ1 < 1 − κ1 , and ensures that the c.d.f.
G in Step 1 is truncated at a proper quantile level. Finally, requiring the terms qU (τ0 ) and
qL (τ0 ), defined in (3.7), to be well-defined implies that
                                                    Ú
                                                        s(y, τ0 ) ≥ 1.                                      (3.12)

These four conditions exhaust the informational content of our model regarding the possible
values of (τ1 , τ0 ). Therefore the set T of candidates that satisfy these four restrictions,
formally given by

                        T ≡ {(τ1 , τ0 ) : conditions (3.9)–(3.12) are satisfied},

is the sharp identified set for (τ1 , τ0 ). Using this result, we can now find sharp bounds on Γ−
by finding those values of (τ1 , τ0 ) ∈ T that lead to the most extreme values of the quantities
defined in (3.8).13 These bounds on Γ− are sharp because they are based on assigning “worst
case” distributions of the potential outcomes to each of the six groups mentioned in Table 1
that satisfy our assumptions and are compatible with the distribution of observables.

  13
    Note that under the model in Section 2.1 the set T has to be non-empty. If empirically this would turn
out not to be the case, this would mean that our model is rejected by the data.



                                                            18
Theorem 2. Suppose that Assumptions 1–3 hold, and that FY |XD (y|c+ , d) and FY |XD (y|c− , d)
are continuous in y for d ∈ {0, 1}. Then sharp lower and upper bounds on Γ− are given by

           ΓL−,F RD =       inf        ΓL−,F RD (t1 , t0 ) and ΓU−,F RD =      sup ΓU−,F RD (t1 , t0 ),
                        (t1 ,t0 )∈T                                         (t1 ,t0 )∈T


respectively.

                 4. Identification: Further Results and Extensions
The results in the previous section can be extended in various ways. In this section, we
show that additional behavioral assumptions can lead to more narrow bounds on Γ− , that
covariates can be used to tighten the bounds as well, and that the distribution of covariates
among always-assigned and potentially-assigned units is point identified in our model. Finally,
we present results regarding the identification of the parameter Γ+ .

4.1. Adding Behavioral Assumptions in Fuzzy RD Designs. The bounds in Theorem 2
can be narrowed by imposing stronger assumptions on the units’ behavior, which relate to
behavioral restrictions that arise naturally in certain empirical contexts. Consider for instance
settings where always-assigned units obtain values of the running variable to the right of
the cutoff by taking conscious actions. Since such units actively choose to be eligible for
the treatment, it seems plausible to assume that their probability of actually receiving the
treatment conditional on being eligible is relatively high in some appropriate sense.
   First, one might be willing to assume that always-assigned units are at least as likely to
get treated as eligible potentially-assigned units, implying the following corollary:
Corollary 1. Suppose that the conditions of Theorem 2 hold, and that E(D|X = c+ , M =
1) ≥ E(D|X = c+ , M = 0). Then and sharp lower and upper bounds on Γ− are given by

        ΓL−,F RD(a) =      inf         ΓL−,F RD (t1 , t0 ) and ΓU−,F RD(a) =      sup         ΓU−,F RD (t1 , t0 ),
                        (t1 ,t0 )∈Ta                                           (t1 ,t0 )∈Ta


respectively, where Ta ≡ {(t1 , t0 ) : (t1 , t0 ) ∈ T and t1 ≥ τ }.
    We see that the additional restriction of Corollary 1 relative to Theorem 2 increases the
lowest possible value of τ1 from max{0, 1 + (τ − 1)/E(D|X = c+ )} to τ , and correspondingly
decreases the largest possible value for τ0 from min{1, τ /(1 − E(D|X = c+ ))} to τ . This
follows from a simple application of Bayes’ Rule, and means that Ta ⊂ T . We then obtain
bounds on Γ− that are (weakly) narrower, as optimization is carried out over a smaller set.
   Second, in some cases, it may be reasonable to drive this line of reasoning further and
assume that always-assigned units always receive the treatment, which is equivalent to
assuming that no always-assigned unit is a never-taker. This implies the following corollary:

                                                         19
Corollary 2. Suppose that the conditions of Theorem 2 hold, and that E(D|X = c+ , M =
1) = 1. Then τ1 = τ /E(D|X = c+ ) and τ0 = 0 are point identified; and sharp lower and
upper bounds on Γ− are given by
                           A                     B                                   A                 B
                                    τ                                                         τ
  ΓL−,F RD(b) = ΓL−,F RD                    ,0         and ΓU−,F RD(b) = ΓU−,F RD                     ,0 ,
                               E(D|X = c+ )                                              E(D|X = c+ )

respectively.

    Under the conditions of Corollary 2, the set of feasible values of (τ1 , τ0 ) shrinks to a
singleton, which means that sharp bounds on our parameter of interest can be defined without
invoking an optimization operator. Moreover, we can see from Table 1 that due to the
absence of always-assigned never-takers the distributions FY (0)|X=c,N0 and FY (0)|X=c,C0 are
point identified in this case. Finally, inspection of Table 1 shows that assuming that all
always-assigned unit are compliers does not provide any additional identifying power.

4.2. Using Covariates to Tighten the Bounds. Following arguments similar to those in
Lee (2009), covariates that are measured prior to treatment assignment can also be used to
narrow the bounds on Γ− that we derived above. Let W be a vector of such covariates, and
denote its support by W. The idea is that, if the outcome distribution or the proportion of
always-assigned units varies with W , trimming units based on their position in the outcome
distribution conditional on W leads to units with less extreme values in the overall outcome
distribution being trimmed, which narrows the bounds.
   For the sharp RD design, the sharp upper and lower bounds on FY (1)|X=c,C0 become:
                               Ú
          U
         F1,SRD(W ) (y) =          FY |X=c+ ,W =w,Y ≥QY |X=c+ ,W =w (τ (w)) (y)dFW |X=c− (w) and
                               Ú
          L
         F1,SRD(W ) (y) =          FY |X=c+ ,W =w,Y ≤QY |X=c+ ,W =w (1−τ (w)) (y)dFW |X=c− (w),

where τ (w) = P(M = 1|X = c+ , W = w) is a conditional version of τ defined as in (3.1),
which is point identified as τ (w) = 1−fX|W (c− , w)/fX|W (c+ , w) through arguments analogous
to those used in the proof of Lemma 1, conditioning on W = w throughout. The next corollary
gives the resulting sharp lower and upper bounds on Γ− .

Corollary 3. Suppose that the assumptions of Theorem 1 hold, mutatis mutandis, with




                                                        20
conditioning on the covariates W . Then sharp lower and upper bounds on Γ− are given by
                         Ú
       ΓL−,SRD(W )   =       E(Y |X = c+ , W = w, Y ≤ QY |X=c+ ,W =w (1 − τ (w)))dFW |X=c− (w)

                         − E(Y |X = c− ) and
                         Ú
       ΓU−,SRD(W ) =         E(Y |X = c+ , W = w, Yi ≥ QY |X=c+ ,W =w (τ (w)))dFW |X=c− (w)

                         − E(Y |X = c− ),

respectively.

     To state a similar result for the fuzzy RD design, we need to define conditional versions of τ1 ,
τ0 , T , κ1 and κ0 in the same fashion. We denote the resulting quantities by τ1 (w), τ0 (w), T (w),
                                                                                 U
κ1 (w) and κ0 (w), respectively. We then define conditional versions of Fd,F        RD (y, τ1 , τ0 ) and
  U                                  U                                  U
Fd,F RD (y, τ1 , τ0 ), denoted by Fd,F RD|W =w (y, τ1 (w), τ0 (w)) and Fd,F RD|W =w (y, τ1 (w), τ0 (w)),
respectively, for d ∈ {0, 1}. These objects are constructed following the steps in the previous
section by conditioning on W = w throughout. We also define the set TW = {(t1 (·), t1 (·)) :
(t1 (w), t1 (w)) ∈ T (w) for all w ∈ W}. Finally, we denote the proportion of potentially-
assigned compliers (C0 ) conditional on W = w just to the left of the cutoff by

                                            1 − τ1 (w)
      P(C0 |X = c− , W = w) =                          E(D|X = c+ , W = w) − E(D|X = c− , W = w)
                                            1 − τ (w)
                                        ≡ Π−,W =w (τ1 (w), τ0 (w)).

With this notation, we can then construct sharp upper and lower bounds on FY (1)|X=c,C0
and FY (0)|X=c,C0 given (hypothetical) knowledge of the function w Ô→ (τ1 (w), τ0 (w)). These
bounds are given by
                                        Ú
   U                                         U
  Fd,F RD(W ) (y, τ1 (·), τ0 (·)) =         Fd,F RD|W =w (y, τ1 (w), τ0 (w))ω(w, τ1 (w), τ0 (w))dFW |X=c− (w)
                                        Ú
   L                                         L
  Fd,F RD(W ) (y, τ1 (·), τ0 (·))   =       Fd,F RD|W =w (y, τ1 (w), τ0 (w))ω(w, τ1 (w), τ0 (w))dFW |X=c− (w),


for d ∈ {0, 1}, where

                                                          Π−,W =w (τ1 (w), τ0 (w))
                     ω(w, τ1 (w), τ0 (w)) ≡ s                                              .
                                                     Π−,W =w (τ1 (w), τ0 (w))dFW |X=c− (w)

The resulting sharp upper and lower bounds on the local average treatment effect Γ− given




                                                           21
(hypothetical) knowledge of the function w Ô→ (τ1 (w), τ0 (w)) are given by

           ΓU−,F RD(W ) (τ1 (·), τ0 (·))
                    Ú                                              Ú
                           U                                              L
                ≡       ydF1,F RD(W ) (y, τ1 (·), τ0 (·))     −        ydF0,F RD(W ) (y, τ1 (·), τ0 (·)) and

           ΓL−,F RD(W ) (τ1 (·), τ0 (·))
                    Ú                                              Ú
                           L                                              U
                ≡       ydF1,F RD(W ) (y, τ1 (·), τ0 (·))     −        ydF0,F RD(W ) (y, τ1 (·), τ0 (·)),


respectively. The following corollary gives the feasible sharp bounds on Γ− , using the fact
that the function w Ô→ (τ1 (w), τ0 (w)) is partially identified.

Corollary 4. Suppose that the assumptions of Theorem 2 hold, mutatis mutandis, with
conditioning on the covariates W . Then sharp lower and upper bounds on Γ− are given by

                           ΓL−,F RD(W ) =           inf            ΓL−,F RD (t1 (·), t0 (·)) and
                                              (t1 (·),t0 (·))∈TW

                           ΓU−,F RD(W )   =         sup            ΓU−,F RD (t1 (·), t0 (·)),
                                              (t1 (·),t0 (·))∈TW


respectively.

4.3. Characteristics of Always- and Potentially-Assigned Units. It is not possible to
determine whether any given unit belongs to the group of always-assigned or potentially-
assigned units in our model. This does not mean, however, that it is impossible to give any
further characterization of these two groups. In particular, if the data include a vector W of
covariates that are measured prior to treatment assignment, and whose conditional distribution
given the running variable does not change discontinuously at c among potentially-assigned
units, one can identify the distribution of these covariates among both always-assigned and
potentially-assigned units. This information could be useful, for instance, for targeting policies
aimed at mitigating manipulation. The following corollary formally states this result.

Corollary 5. Suppose that Assumptions 1–2 hold, that P(W ≤ w|X = x, M = m) is
continuous in x at c for m ∈ {0, 1}. Then
                                                    1
          P(W ≤ w|X = c, M = 1) =                     (P(W ≤ w|X = c+ ) − P(W ≤ w|X = c− ))
                                                    τ
                                                    + P(W ≤ w|X = c− ) and
          P(W ≤ w|X = c, M = 0) = P(W ≤ w|X = c− ).

  Of course, identification of the distribution of W immediately implies identification of
moments, quantiles, and related summary statistics.

                                                              22
4.4. Causal Effects for Units Just to the Right of the Cutoff. The parameter Γ− that
we considered so far is the local average treatment effect among compliers whose realization
of the running variable is just to the left of the cutoff. As pointed out in Section 2.3, a
possible alternative parameter of interest is

                           Γ+ ≡ E(Y (1) − Y (0)|X = c+ , D+ > D− ),

the causal effects among compliers whose realization of the running variable is just to the
right of the cutoff. The main conceptual difficulty for identification in this case is that,
by definition, there is no always-assigned complier that does not receive the treatment.
Any bounds analysis therefore must rely on some additional assumption, at least for the
average treatment effect, that specifies a “worst case” value for the outcome variable in this
counterfactual scenario. To make progress, we impose the assumption that the outcome
variable has bounded support conditional on the running variable in some neighborhood of
the cutoff. This type of assumption is common in the partial identification literature (cf.
Manski, 1990) and is natural for binary outcomes, for example. However, it is restrictive in
general and difficult to justify for some outcomes commonly studied in economics, like wages.

Assumption 4. There are constants Y L and Y U such that P(Y L ≤ Y (0) ≤ Y U |X = x) = 1
and P(Y L ≤ Y (1) ≤ Y U |X = x) = 1 for every x in some open neighborhood of the cutoff.

   Note that this assumption is not necessary for obtaining bounds on the c.d.f.s of the two
potential outcomes, but only to translate bounds on these c.d.f.s into bounds on the (local)
average treatment effect. Bounds on quantile treatment effects could be obtained without the
assumption that the outcome has bounded support (except for extreme quantile levels).
    We now study identification of Γ+ under this additional assumption. Paralleling the
discussion in Section 3, we begin with the sharp RD design before turning to the more general
fuzzy RD design. Note that, using notation from Section 3, we have that {D+ > D− } = C0 ∪
C1 , and thus the parameter of interest can be written as Γ+ = E(Y (1)−Y (0)|X = c+ , C0 ∪C1 ).

Sharp RD Designs. In the Sharp RD design every unit just to the right of the cutoff is a
complier, and thus the distribution of Yi given Xi = c+ coincides with the distribution of
Yi (1) among compliers (C1 or C0 ) just to the right of the cutoff:

                               FY (1)|X=c+ ,C0 ∪C1 (y) = FY |X=c+ (y).

On the other hand, we have that

             FY (0)|X=c+ ,C0 ∪C1 (y) = τ FY (0)|X=c+ ,C1 (y) + (1 − τ )FY (0)|X=c+ ,C0 (y).

                                                  23
Since there exist no untreated always-assigned compliers, we can only deduce from Assumption
4 that the potential outcome Yi (0) of always-assigned compliers is bounded between Y L and
Y U . This, and the continuity conditions on potentially-assigned units in Assumption 1, then
lead to the following sharp bounds on FY (0)|X=c+ ,C0 ∪C1 (y):
                                                                î          ï
                     U
                    F0,+,SRD (y) = (1 − τ )FY |X=c− (y) + τ I y ≥ Y U           and
                                                                î          ï
                     L
                    F0,+,SRD (y) = (1 − τ )FY |X=c− (y) + τ I y ≥ Y L .

The following corollary gives the resulting sharp lower and upper bounds on the average
treatment effect Γ+ .

Corollary 6. Suppose Assumptions 1–4 hold, that P (D+ > D− ) = 1. Then sharp lower and
upper bounds on Γ+ are given by

                 ΓL+,SRD = E(Y |X = c+ ) − (1 − τ )E(Y |X = c− ) − τ Y U              and
                 ΓU+,SRD = E(Y |X = c+ ) − (1 − τ )E(Y |X = c− ) − τ Y L ,

respectively.

Fuzzy RD Designs. For the Fuzzy RD design, our strategy is to first derive bounds for the
hypothetical case in which the true values of (τ1 , τ0 ) and λ ≡ P(A1 |X = c+ , D = 1, M = 1),
the proportion of always-takers among the treated always-assigned units just to the right of
the cutoff, are known. In a second step, we then extend this result to our actual setting in
which we only know that (τ1 , τ0 ) ∈ T and that λ ∈ [0, 1].
    We begin by considering the c.d.f. FY (1)|X=c+ ,C0 ∪C1 (y). Recall from Step 1 in Section 3.3
that we can point identify the c.d.f. G(y) ≡ FY (1)|X=c+ ,C0 ∪C1 ∪A1 (y) from the data on treated
units, and note that P(A1 |X = c+ , C0 ∪ C1 ∪ A1 ) = 1 − λτ1 /(1 − κ1 ). By truncating the
distribution G(y) appropriately, we thus arrive at the following sharp upper and lower bounds
on FY (1)|X=c+ ,C0 ∪C1 (y):
                                                               I           A          BJ
          U                           (1 − κ1 )G(y) − λτ1                 λτ1
         F1,+,F RD (y, τ1 , τ0 , λ) =                     · I y ≥ G−1                        and
                                         1 − κ1 − λτ1                   1 − κ1
                                                      I          A           BJ
          L                           (1 − κ1 )G(y)           −1        λτ1
         F1,+,F RD (y, τ1 , τ0 , λ) =               ·I y ≤G       1−            .
                                           λτ1                        1 − κ1

Now consider the c.d.f. FY (0)|X=c+ ,C0 ∪C1 (y), which can be written as

        FY (0)|X=c+ ,C0 ∪C1 (y) = s(τ1 , λ)FY (0)|X=c+ ,C0 (y) + (1 − s(τ1 , λ))FY (0)|X=c+ ,C1 (y)




                                                    24
where
                                                            (1 − τ1 )E(D|X = c+ ) − (1 − τ )E(D|X = c− )
    s(τ1 , λ) ≡ P(C0 |X = c+ , C0 ∪ C1 ) =                                                               .
                                                           (1 − λτ1 )E(D|X = c+ ) − (1 − τ )E(D|X = c− )

is the proportion of potentially-assigned units among all compliers just to the right of the
cutoff. The term FY (0)|X=c+ ,C0 (y) = FY (0)|X=c− ,C0 (y) can then be bounded as in Step 2 of
Section 3.3, and bounds on FY (0)|X=c+ ,C1 (y) follow from Assumption 4:
                                                                                                     î          ï
         U                                     U                                             U
        F0,+,F RD (y, τ1 , τ0 , λ) = s(τ1 , λ)F0,F RD (y, τ1 , τ0 ) + (1 − s(τ1 , λ))I y ≥ Y                         and
                                                                                                     î          ï
         L                                     L                                             L
        F0,+,F RD (y, τ1 , τ0 , λ) = s(τ1 , λ)F0,F RD (y, τ1 , τ0 ) + (1 − s(τ1 , λ))I y ≥ Y   ,

Taken together, the sharp bounds on the local average treatment effect Γ+ for known values
of τ1 , τ0 and λ are
                                         Ú                                           Ú
            ΓU+,F RD (τ1 , τ0 , λ)   ≡          U
                                             ydF1,+,F RD (y, τ1 , τ0 , λ)        −          L
                                                                                         ydF0,+,F RD (y, τ1 , τ0 , λ),
                                         Ú                                           Ú
            ΓL+,F RD (τ1 , τ0 , λ) ≡            L
                                             ydF1,+,F RD (y, τ1 , τ0 , λ) −
                                                                                            U
                                                                                         ydF0,+,F RD (y, τ1 , τ0 , λ).


We can then give sharp bounds on Γ+ by finding those values of (τ1 , τ0 ) ∈ T and λ ∈ [0, 1]
that lead to the most extreme values of the just-defined quantities.14

Corollary 7. Suppose Assumptions 1–4 hold, and that FY |XD (y|c+ , d) and FY |XD (y|c− , d)
are continuous in y for d ∈ {0, 1}. Then sharp lower and upper bounds on Γ+ are given by

                             ΓL+,F RD =              inf             ΓL+,F RD (t1 , t0 , l) and
                                              (t1 ,t0 ,l)∈T ×[0,1]

                             ΓU+,F RD =              sup             ΓU+,F RD (t1 , t0 , l),
                                              (t1 ,t0 ,l)∈T ×[0,1]


respectively.


                                         5. Estimation and Inference
While our main focus in this paper is on deriving identification results for causal effects in
RD designs with a manipulated running variable, this section also discusses some methods for
estimation and inference, based on the results in Section 3. These methods can be extended
in a straightforward manner to the results derived in Section 4. Software packages that
implement these methods are available on the authors’ websites. Our approach uses a number
of different techniques that are well-understood individually, but whose combination requires
  14
     Note that more narrow versions of these bounds on Γ+ can be obtained by using arguments analogous to
those used to tighten the bounds on Γ− in Sections 4.1 and 4.2.



                                                                 25
a tedious theoretical analysis. We therefore do not present any formal results in this paper; a
full econometric analysis will be developed separately.

5.1. Estimation of the Bounds. Our bounds on Γ− can be estimated through a “plug-in”
approach that replaces unknown population quantities with suitable sample counterparts.
Following the recent RD literature, we focus on flexible nonparametric methods, and in
particular local polynomial smoothing (Fan and Gijbels, 1996), for the construction of these
sample counterparts. To simplify the exposition, we use the same polynomial order p,
bandwidth h and kernel function K(·) in all intermediate estimation steps in this paper. We
also use the notation that π p (x) = (1/0!, x/1!, x2 /2!, . . . , xp /p!)′ and Kh (x) = K(x/h)/h for
any x ∈ R, and define the (p + 1)-vector e1 = (1, 0, . . . , 0)′ . The data are an independent
sample {(Yi , Di , Xi ), i = 1, . . . , n} of size n.

Proportion of Always-Assigned Units. Following the result in Lemma 1, estimating τ
requires estimates of the right and left limits of the density at the cutoff. There are a number
of nonparametric estimators that can be used to estimate densities at boundary points; see
for example Lejeune and Sarda (1992), Jones (1993), Cheng (1997) or Cattaneo, Jansson,
and Ma (2017). Here we use a minor variation of the procedure in Cheng (1997), which also
forms the basis for the McCrary (2008) test, and estimate fX (c+ ) and fX (c− ) by
                              n
                              Ø
           fâ+ = e′1 argmin         (fâ(Xi ) − π p (Xi − c)′ β)2 Kh (Xi − c)I {Xi ≥ c} , and
                     β∈Rp+1   i=1
                              n
                              Ø
           fâ− = e′1 argmin         (fâ(Xi ) − π p (Xi − c)′ β)2 Kh (Xi − c)I {Xi < c} ,
                     β∈Rp+1 i=1

                                          q
respectively, where fâ(Xi ) = (1/n) nj=1 Kb (Xj − Xi ) and b is another bandwidth. Since by
assumption the proportion of always-assigned units among units just to the right of the cutoff
has to be non-negative, our estimate of τ is then given by

                              τâ = max{τå, 0},     with τå = 1 − fâ− /fâ+ .

Conditional Expectation, Distribution, and Density Functions. The local polyno-
mial regression estimates of g + = E(Di |Xi = c+ ) and g − = E(Di |Xi = c− ), the conditional
treatment probabilities on either side of the cutoff, are given by
                                n
                                Ø
             gâ+ = e′1 argmin         (Di − π p (Xi − c)′ β)2 Kh (Xi − c)I {Xi ≥ c} , and
                       β∈Rp+1   i=1
                                n
                                Ø
             gâ− = e′1 argmin         (Di − π p (Xi − c)′ β)2 Kh (Xi − c)I {Xi < c} ,
                       β∈Rp+1 i=1




                                                     26
respectively (Fan and Gijbels, 1996). The conditional c.d.f.s FY |X=c+ ,D=d (y) and FY |X=c− ,D=d (y)
are estimated by
                                        n
                                        Ø
      FâY |X=c+ ,D=d (y) = e′1 argmin         (I {Yi ≤ y} − π p (Xi − c)′ β)2 Kh (Xi − c)I {Xi ≥ c} , and
                              β∈Rp+1    i=1
                                        n
                                        Ø
  FâY |X=c− ,D=d (y) = e′1 argmin             (I {Yi ≤ y} − π p (Xi − c)′ β)2 Kh (Xi − c)I {Xi < c} ,
                              β∈Rp+1 i=1


respectively, which for every y ∈ R corresponds to a local polynomial regression with
I {Yi ≤ y} as the dependent variable (Hall, Wolff, and Yao, 1999). Finally, we estimate the
conditional p.d.f.s fY |X=c+ ,D=d (y) and fY |X=c− ,D=d (y) by
                                       n
                                       Ø
  fâY |X=c+ ,D=d (y) = e′1 argmin            (Kb (Yi − y) − π p (Xi − c)′ β)2 Kh (Xi − c)I {Xi ≥ c} , and
                             β∈Rp+1 i=1
                                    Øn
  fâY |X=c− ,D=d (y) = e′1 argmin            (Kb (Yi − y) − π p (Xi − c)′ β)2 Kh (Xi − c)I {Xi < c}
                             β∈Rp+1    i=1

respectively, which for every y ∈ R corresponds to a local polynomial regression with Kb (Yi −y)
as the dependent variable, where b is another bandwidth (Fan, Yao, and Tong, 1996).

Final Bounds Estimates. We describe the construction of our final estimates of the bounds
on Γ− for the general case of a Fuzzy RD design described in Theorem 2. Bounds for the
sharp case can be obtained similarly. We begin by noting that the set T is a straight line in
the unit square, and can therefore be represented in terms of the location of the endpoints of
the line. That is, we can write

                  T = {(η1 (t), η0 (t)) : t ∈ [0, 1]}      with ηd (t) = τdL + t · (τdU − τdL )

for d ∈ {0, 1}, where
              I               J                    I                                     s                  J
                 1−τ                                (1 − τ ) · g − τ − max{0, 1 − s̃(y)dy}(1 − g + )
τ1L= max 0, 1 − +                 ,   τ1U= min 1 −                ,                                  ,
                  g                                      g+                           g+
        I          J                          I                                     Ú       J
 U             τ                       L               (1 − τ ) · (g + − g − )
τ0 = min 1,          ,                τ0 = max 0, τ −                          , 1 − s̃(y)dy ,
            1 − g+                                             1 − g+

with s̃(y) = min{fY |X=c− ,D=0 (y)/κ0 , fY |X=c+ ,D=0 (y)}. Dropping the “FRD” subscript to
simplify the notation, the bounds on Γ− from Theorem 2 can then be written as

                    ΓL− = inf ΓL− (η1 (t), η0 (t)) and ΓU− = sup ΓU− (η1 (t), η0 (t)).
                           t∈[0,1]                                   t∈[0,1]




                                                          27
This expression is convenient because it makes the area over which optimization takes place
free of unknown quantities that have to be estimated. Next, we put
                                   Ú                            Ú
                â j (t , t ) =
                Γ                      ydFâ1j (y, t1 , t0 ) −       ydFâ0j (y, t1 , t0 ),   j ∈ {U, L},
                  − 1 0


where for j ∈ {U, L} and d ∈ {0, 1} the function Fâdj (y, t1 , t0 ) is a sample analogue estimator
                 j
of the function Fd,F RD (y, t1 , t0 ) defined in Section 3. Specifically, we put

                                               â             ;             3          4<
                â U                (1 − κâ 1 )G(y)  − t1             â −1       t1
                F1 (y, t1 , t0 ) =                       ·I y ≥G                         ,
                                        1−κ  â 1 − t1                        1−κ   â1

                â U
                                   FâY |X=c− ,D=0 (y) − κâ 0 · (1 − t0 )FâYL(0)|X=c,N (y, t0 )
                                                                                       0
                F0 (y, t1 , t0 ) =                                                             .
                                                      1−κ   â 0 · (1 − t0 )

The functions Fâ1L and Fâ0L are defined similarly. Here we use the notation that

                       â            FâY |X=c+ ,D=1 (y) − κ
                                                         â 1 FâY |X=c− ,D=1 (y)
                       G(y) =                                                   ,
                                                     1−κ  â1
                                                      Ú   y
                       Fâ L
                         Y (0)|X=c,N0 (y, t0 )    =           sâ(u, t0 )I {u ≥ qâL (t0 )} du,
                                                       −∞
                                             î                                                  ï
                                       min fâY |X=c− ,D=0 (y)/κ
                                                              â 0 , fâY |X=c+ ,D=0 (y)
                       sâ(y, t0 ) =                                                                 ,
                                                           1 − t0
                              (1 − τâ)gâ−                   1 − gâ+
                       κ
                       â1 =               ,        κ
                                                   â0 =                    ;
                                  gâ+                   (1 − τâ)(1 − gâ− )
                                       sâ
                                        qL (t0 )
with qâL (t0 ) the value that satisfies −∞       sâ(y, t0 )dy = 1. We then define the functions

                                  ηâd (t) = τâdL + t · (τâdU − τâdL ),       d ∈ {0, 1},

where for j ∈ {U, L} and d ∈ {0, 1} the term τâdj is the obvious sample analogue estimator of
the point τdj introduced above. Finally, our estimates of the lower and upper bounds on Γ−
are given, respectively, by

                 Γ         â L (ηâ (t), ηâ (t)) and Γ
                 â L = inf Γ                                  â U (ηâ (t), ηâ (t)).
                                                    â U = sup Γ
                   −         − 1          0           −         − 1          0
                        t∈[0,1]                                               t∈[0,1]


In our application below, we use grid search to solve the two optimization problems in the
previous equation.

5.2. Inference. In order to quantify sampling uncertainty about Γ− , we construct confidence
intervals that are “manipulation-robust” in the sense that they are valid irrespective of the
true value of τ . Such a construction involves a number of complications which we describe in
this subsection. We focus again on the general setup of Theorem 2, as the procedure works

                                                              28
analogously for the sharp case.
    The first conceptual complication is due to the presence of an optimization operator in
the definition of the bounds, which we address using the intersection-union testing principle
of Berger (1982).15 The main idea is the following. Suppose that for every t ∈ [0, 1] we had a
                               F RD
1 − α confidence interval C1−α      (t) for Γ− that was valid if the true value of (τ1 , τ0 ) was equal
                                                                           F RD                F RD
to (η1 (t), η0 (t)). Then the intersection-union principle implies that C1−α    = ∪t∈[0,1] C1−α     (t) is
                                                                                             F RD
a 1 − α confidence interval for Γ− . That is, a candidate value for Γ− is outside of C1−α          if and
                           F RD
only if it is outside of C1−α (t) for all t ∈ [0, 1]. An important feature of this approach is that
both the “fixed t” and the overall confidence interval have level 1 − α: there is no need for a
multiplicity adjustment to account for the fact that we are implicitly testing a continuum of
hypotheses. Berger (1982) also shows that this approach has strong power properties.
    The second conceptual complication then involves the construction of a “fixed t” confidence
interval. If the estimates Γâ L (ηâ (t), ηâ (t)) and Γ
                                                     â U (ηâ (t), ηâ (t)) were jointly asymptotically
                              − 1          0           − 1          0

normal irrespective of the true value of τ , one could use the approach proposed by Imbens
and Manski (2004) and Stoye (2009) for this purpose. However, our bound estimates are
only jointly asymptotically normal (under appropriate regularity conditions) if τ > 0. For
τ = 0, their limiting distribution is non-Gaussian, as the estimated level of manipulation
τâ = max{0, 1 − fâ− /fâ+ } fails to be asymptotically normal in this case.16 A Gaussian
approximation to the distribution of the “fixed t” estimates is thus typically poor in finite
samples if τ is not well-separated from zero. The standard bootstrap is unable to provide a
remedy in this case (Andrews, 2000).
    We therefore propose an approach similar to moment selection in the moment inequality
literature (e.g. Andrews and Soares, 2010; Andrews and Barwick, 2012). Roughly speaking,
we estimate the limiting distribution of the estimated bounds for a level of manipulation that
is tilted away from zero, unless the empirical estimate τâ is very large relative to its standard
error.17 For convenience, we implement this approach via the bootstrap. Specifically, we
construct a bootstrap distribution under which the bootstrap analogue of τå = 1 − fâ− /fâ+ is
centered around max{τâ, κn σâåτ }, where σâåτ is the standard error of τå, and κn is a sequence of
constants that slowly tends to infinity. Following much of the moment inequality literature,
  15
     Our problem differs from the one in Chernozhukov, Lee, and Rosen (2013), who study inference on
intersection bounds of the form [supv θ(v), inf v θ(v)]. It is more accurately described as an example of union
bounds, as the role of the inf and the sup operator in the definition of the identified set is reversed relative
to Chernozhukov, Lee, and Rosen (2013). We are not aware of any existing general results on inference for
union bounds, but the intersection-union testing principle provides a straightforward solution.
  16
                                            √              d
     Under standard regularity conditions nh(â     τ − τ ) → max{0, Z} if τ = 0, where Z is a Gaussian random
variable with mean zero.
  17
     Note that the distributions of Γâ L (â                   â U (â
                                                 â0 (t)) and Γ
                                       − η1 (t), η              − η1 (t), η
                                                                          â0 (t)) are increasing in τ in a stochastic
sense.


                                                         29
we choose κn = log(n)1/2 in this paper. The algorithm for our bootstrap is as follows.

   1. Generate bootstrap samples {Yi,b , Di,b , Xi,b }ni=1 , b = 1, . . . , B by sampling with replace-
      ment from the original data {Yi , Di , Xi }ni=1 ; for some large integer B.
   2. Calculate τåb∗ = 1 − fâb− /fâb+ , and put σâåτ as the sample standard deviation of {τåb∗ }Bb=1 .
   3. Calculate τåb = τåb∗ − τå + max{τâ, κn σâåτ } and τâb = max{τåb , 0}.
   4. For j ∈ {U, L}, calculate Γ       â j (ηâ (t), ηâ (t)) using the redefined estimate τâ from the
                                          − 1          0                                    b
                                                                                    â j
      previous step, and put σâ (t) as the sample standard deviation of {Γ− (ηâ1 (t), ηâ0 (t)}B
                                    j
                                                                                                   b=1 .


Now define Γ  â L∗ (t) and Γ
                           â U ∗ (t) exactly as Γ
                                                â L (ηâ (t), ηâ (t)) and Γ
                                                                         â U (ηâ (t), ηâ (t)), with the excep-
                −            −                    − 1          0           − 1          0
            ∗
tion that τâ = max{τå, κn σâåτ } is used instead of τâ. Following Imbens and Manski (2004) and
Stoye (2009), our “fixed t” confidence interval for Γ− with level 1 − α is then given by
                                          è                                                   é
                     F RD
                    C1−α        â L∗ (t) − r (t) · σ
                          (t) = Γ                           â U ∗ (t) + r (t) · σ
                                                   â L (t), Γ                   â U (t) ,
                                  −         α                 −          α


where rα (t) is the value that solves the equation
                         A                                            B
                                  â U ∗ (t) − Γ
                                  Γ           â L∗ (t)
                                    −           −
                      Φ rα (t) +                         − Φ(−rα (t)) = 1 − α,
                                 max{σâ L (t), σâ U (t)}

and Φ(·) is the CDF of the standard normal distribution. The final intersection-union
confidence interval for Γ− is then given by
                        C                                                                             D
                                      1                           2             1                 2
              F RD
             C1−α  =         inf          â L (t) − r (t) · σ
                                          Γ                               â U (t) + r (t) · σ
                                                            â L (t) , sup Γ                 â U (t)       .
                                            −        α                      −        α
                            t∈[0,1]                                   t∈[0,1]


    We remark that this construction does not account for discontinuities in the limiting
distribution of the “fixed t” estimates at those values of τ under which one of the various
max and min operators in the definition of the function ηd (·) becomes binding. We expect
this to have only minor importance in practice, and therefore do not include any “safeguards”
against such cases into our bootstrap procedure. We also note that construction implicitly
assumes that the two functions involved in the definition of the term s(y, τ0 ) cross at a finite
number of points. If that was not the case the presence of the max operator would generate
a bias, and one would have to use techniques analogous to those in Anderson, Linton, and
Whang (2012) to remove it.

5.3. “Fixed τ ” Inference. The confidence interval construction in the previous subsection
takes a deliberately agnostic view about the true value of τ . This view can be overly
pessimistic in certain contexts. Suppose for example that a researcher strongly believes that
manipulation is either fully absent or at least of negligible magnitude in a particular setting,
and that this belief is confirmed by a point estimate of τ that is close to zero. Now, if the

                                                             30
corresponding standard error of τâ is large, the confidence interval proposed in the previous
subsection is typically rather wide, as the data by themselves do not rule out a high level of
manipulation. We argue that in such a scenario researcher might want to consider alternative
confidence intervals for Γ− that are computed under the assumption that the value of τ is
known to be some τ ∗ ≥ 0. Such a confidence interval C1−α (τ ∗ ) can be calculated through the
following modified bootstrap algorithm.

   1. For τ ∗ ∈ [0, 1] and t ∈ [0, 1], define Γ   â L (τ ∗ , t) and Γ    â U (τ ∗ , t) exactly as Γ
                                                                                                  â L (ηâ (t), ηâ (t))
                                                    −                      −                        − 1          0
           â U â                                                  ∗
      and Γ− (η1 (t), η0 (t)), with the exception that τ is used instead of τ .
                       â                                                                     â
   2. Generate bootstrap samples {Yi,b , Di,b , Xi,b }ni=1 , b = 1, . . . , B by sampling with replace-
      ment from the original data {Yi , Di , Xi }ni=1 ; for some large integer B.
   3. For j ∈ {U, L}, calculate Γ  â j (τ ∗ , t), and put σ    â j (τ ∗ , t) as the sample standard deviation
                                     −,b
          â j (τ ∗ , t)}B .
      of {Γ −,b         b=1
   4. Compute the 1 − α confidence interval

        F RD ∗
       C1−α (τ )
               C                                                                                                                       D
                             1                                           2             1                                           2
           =        inf          â L (τ ∗ , t)
                                 Γ                      ∗       L   ∗
                                                 − rα (τ , t) · σâ (τ , t) , sup           â U (τ ∗ , t)
                                                                                           Γ                       ∗       U   ∗
                                                                                                           + rα (τ , t) · σâ (τ , t)       ,
                                   −                                                         −
                   t∈[0,1]                                                   t∈[0,1]


      where rα (τ ∗ , t) is the value that solves the equation
                          A                                                       B
                                      â U (τ ∗ , t) − Γ
                                      Γ                â L (τ ∗ , t)
                                       ∗−                 −
                      Φ rα (τ , t) +                                     − Φ(−rα (τ ∗ , t)) = 1 − α.
                                     max{σâ L (τ ∗ , t), σâ U (τ ∗ , t)}

For τ ∗ = 0 this algorithm yields the usual “no manipulation” confidence interval, and generally
C1−α (τ ∗ ) becomes wider as τ ∗ increases.
    To see why such confidence intervals can be useful, suppose that researcher’s main goal
is testing the hypothesis that Γ− = 0 against the alternative that Γ− =   Ó 0. Remember that
Γ− corresponds to the usual “no manipulation” RD parameter if τ = 0 (i.e. always-assigned
units are absent). The researcher can then plot the upper and lower boundary of C1−α (τ ∗ )
as a function of τ ∗ , and check graphically for which levels of manipulation the value of 0 is
contained in the confidence interval. The largest value of τ ∗ for which 0 ∈ / C1−α (τ ∗ ) is then
called the breakdown point of the null hypothesis that Γ− = 0 (cf. Horowitz and Manski, 1995;
Masten and Poirier, 2017). For example, suppose that 0 ∈   / C1−α (0), but that 0 ∈ C1−α (τ ∗ ) for
τ ∗ ≥ 0.1. Then the researcher can report that in his preferred “no manipulation” specification
the null hypothesis Γ− = 0 is rejected at the critical level α, and that at least a 10% level of
manipulation around the cutoff would be needed to reverse this result (the researcher can
then argue why for institutional reason such a high value of τ is implausible in the particular
setting, even if it is not formally rejected by the data). We believe that such an exercise

                                                                    31
is a useful robustness check for every RD study, including those in which manipulation is
generally not believed to be an issue.


                                     6. Empirical Application
In this section, we apply the methods developed above to bound treatment effects of un-
employment insurance (UI) on (formal) reemployment around an eligibility cutoff in Brazil.
UI programs often feature discontinuities in the level or duration of potential UI benefits
based on the value of some running variable, such as age at layoff or the number of months
of employment prior to layoff. RD designs are thus natural empirical strategies to estimate
this effect. At the same time, the possibility that manipulation of the running variable could
invalidate the standard assumption for a RD design is a concern in the UI context, and it
is discussed explicitly in prominent papers in the literature (e.g. Card, Chetty, and Weber,
2007; Schmieder, von Wachter, and Bender, 2012). Employers may put some workers on
temporary layoff once they are eligible for UI (Feldstein, 1976). Some workers may provoke
their layoff or ask their employer to report their quit as a layoff once they are eligible for
UI (Hopenhayn and Nicolini, 2009).18 Finally, our key identifying assumption (“one-sided
manipulation”) is likely to apply, as displaced workers are likely to have a weak preference
for being eligible for UI benefits (they always have the choice to not take up UI). Moreover,
in most countries (the US being a notable exception), employers have no incentive to lay off
their workers before they become eligible for UI as UI benefits are not experienced-rated.
    The setting of our application is also interesting in itself. UI programs have been adopted in
a number of developing countries. Yet, the existing evidence for countries with high informality
remains limited. One reason is that the concern of manipulation around discontinuities in
potential UI benefits may be more severe in these countries, complicating the estimation of
treatment effects. The utility costs of being formally laid off when eligible for UI may be
relatively low for some workers if they can work informally while drawing UI benefits.

6.1. Institutional Details, Data, and Sample Selection. Our empirical exercise focuses
on an eligibility cutoff in the Brazilian UI program. In the interest of space, we present
the institutional details and the data succinctly. For more details, see Gerard and Gonzaga
(2016), which study other aspects of the Brazilian UI program.

Institutional Details. In Brazil, a worker who is reported as involuntarily laid off from
a private-sector formal job is eligible for UI under two conditions. First, she must have at
  18
    Alternatively, workers laid off with a value of the running variable to the left of the relevant cutoff may
lobby their employers to lay them off on a later date. The manipulation in our empirical application is likely
the result of a combination of these different types of behaviors (and possibly others).


                                                      32
least six months of continuous job tenure at layoff. Second, there must be at least 16 months
between the date of her layoff and the date of the last layoff after which she applied for
and drew UI benefits. We focus on the eligibility cutoff created by the second condition.
The 16-month cutoff is more arbitrary and thus less likely to coincide with other possible
discontinuities.19 Workers who satisfy the two conditions can withdraw monthly UI payments
after a 30-day waiting period and until they are formally reemployed or exhaust their potential
UI duration. The potential UI duration is equal to three, four, or five months of UI benefits if
workers accumulated more than 6, 12, or 24 months of formal employment in the 36 months
prior to layoff, respectively. The benefit level depends on workers’ average wage in the three
months prior to layoff. The replacement rate is 100% at the bottom of the wage distribution
but is already down to 60% for a worker who earned three times the minimum wage (see
Appendix for the full schedule). Finally, UI benefits are not experience-rated in Brazil.

Data. Our empirical analysis relies on two administrative datasets. The first one is a
longitudinal matched employee-employer dataset covering by law the universe of formal
employees. Every year, firms must report all workers formally employed at some point during
the previous calendar year. The data include information on wage, tenure, age, gender,
education, and sector of activity. The data also include hiring and separation dates, as
well as the reason for separation. The second dataset is the registry of all UI payments.
Individuals can be matched in both datasets as they are identified through the same ID
number. Combining the datasets (we have both from 2002 to 2010), we can study the effect
of UI on the time it takes for displaced formal workers to find a new formal job. Gerard
and Gonzaga (2016) show that it is the relevant outcome to study in order to measure the
efficiency cost from the usual moral hazard of UI in a context of high informality.

Sample selection. Our sample of analysis is constructed as follows. First, we consider all
workers, between 18 and 55 years old, who lost a private-sector full-time formal job between
2004 and 2008. We start in 2004 to identify workers who were displaced from another formal
job about 16 months earlier. We end in 2008 to observe two years after layoff for all workers.
Second, we keep workers who had more than six month of job tenure at layoff (the other
eligibility condition). Third, we restrict attention to workers for whom the difference between
the layoff date and the date of their previous layoff fell within 50 days of the 16-month
eligibility cutoff. Finally, we limit the sample to workers who exhausted their UI benefits
after the previous layoff such that the change in eligibility at the 16-month cutoff is sharp.
  19
    For instance, six months of job tenure may be a salient milestone for evaluating employees’ performance.
Gerard and Gonzaga (2016) show evidence of manipulation around the six-month cutoff as well. This has
been confirmed recently by Carvalho, Corbi, and Narita (2017).



                                                    33
Workers who find a new formal job before exhausting their benefits are entitled to draw
the remaining benefits after a new layoff, even if it occurs before the 16-month cutoff. To
implement this restriction, we select workers who drew the maximum number of benefits
after the previous layoff (about 40% of cases) because we measure the number of UI benefits
a worker is eligible for imprecisely in the data.20
   Our sample ultimately consists of 169,575 workers with a relatively high attachment to
the formal labor force, high turnover rate, and high ability to find a new formal job rapidly.21
These are not the characteristics of the average displaced formal employee or UI taker in
Brazil, but characteristics of workers for whom the 16-month cutoff may be binding.

6.2. Graphical Evidence. Figure 6.2 displays some patterns in our data. Observations
are aggregated by day between the layoff date and the 16-month cutoff. Panels A and B
provide some evidence of potential manipulation of the running variable. The density of the
running variable and the average UI replacement rate (benefit/wage) increase at the cutoff,
highlighting the possibility of selection at the cutoff. Panel C suggests that workers were
partially aware of the eligibility rule. The share of workers applying for UI benefits jumps
at the cutoff. Panel D shows that the eligibility rule was enforced. The share of workers
drawing some UI benefits is close to zero to the left of the cutoff, but takeup jumps to 73%
at the cutoff. Eligible workers drew on average 3.1 months of UI benefits (panel E); UI
takers thus drew on average 3.1/.73 =4.25 months of UI benefits. Finally, Panel F shows that
the non-formal-employment duration (censored at two years), the time it takes a displaced
formal worker to find a new formal job, jumps from about 220 days to 280 days at the cutoff.
The average non-formal-employment duration is high on both sides of the cutoff because the
distribution of this variable has a long upper tail: about 15% of workers remain without a
formal job two years after layoff (see the full distribution in the Appendix).

6.3. Estimates. The discontinuity in non-formal-employment duration in Figure 6.2 could
be due to a treatment effect, but also to a selection bias. Workers on each side of the cutoff
may have different potential outcomes in the presence of manipulation. Our methods allow
us to bound treatment effects, despite the possibility of selection effects.
    Table 2 displays results for non-formal-employment duration censored at 6 and 24 months
after layoff, respectively. The 6-month duration proxies for the covered UI duration (up to 5
  20
      We drop workers previously laid off after the 28th of a month. Otherwise, there is bunching in the layoff
density at the 16-month cutoff even in the absence of manipulation (because February has only 28 days).
   21
      They were previously eligible for five months of UI, so they accumulated 24 months of formal employment
within a 36-month window. They were laid off again within 16 months and had at least six months of
continuous tenure at layoff, so they found a job relatively quickly after their previous layoff (50% of workers
eligible for five months of UI benefits remain without a formal job one year after layoff).

                                                      34
                                                                      A. Density                                                                                                       B. Replacement rate




                                                                                                                                             .74
                      .014
  Share of observations
                 .012




                                                                                                                     Replacement rate
                                                                                                                                 .73
      .01




                                                                                                                      .72
                      .008




                                                                                                                                             .71
                                           -50                            0                                50                                                     -50                            0                                50
                                                 Difference in days between layoff and eligibility dates                                                                Difference in days between layoff and eligibility dates


                                                             C. Share applying for UI                                                                                    D. Share drawing some UI benefits (takeup)



                                                                                                                                            .8
                      .8




                                                                                                                     Share drawing some UI benefits
  Share applying for UI




                                                                                                                                           .6
                  .6




                                                                                                                                   .4
      .4




                                                                                                                          .2
                      .2




                                                                                                                                            0




                                           -50                            0                                50                                                     -50                            0                                50
                                                 Difference in days between layoff and eligibility dates                                                                Difference in days between layoff and eligibility dates


                                                           E. Average benefit duration                                                                            F. Duration without a formal job (censored at two years)
                                                                                                                                                            300
                                       4




                                                                                                                       Duration without a formal job (in days)
  Average benefit duration (in months)




                                                                                                                                                    280
                              3




                                                                                                                                            260
                   2




                                                                                                                                    240
         1




                                                                                                                     200    220
                      0




                                           -50                            0                                50                                                     -50                            0                                50
                                                 Difference in days between layoff and eligibility dates                                                                Difference in days between layoff and eligibility dates



                                                                Figure 6.2: Graphical evidence for our empirical application

The figure displays the mean of different variables on each side of the cutoff by day between the layoff and
eligibility dates, as well as local linear regressions on each side of the cutoff using an edge kernel and a
bandwidth of 30 days. The figure is based on a RD sample of 169,575 displaced formal workers.




                                                                                                                35
months after a 30-day waiting period); Gerard and Gonzaga (2016) show that the increase in
the covered duration caused by changes in benefits is the main source of efficiency cost for UI
programs. Considering both the 6-month and 24-month durations also allows us to illustrate
how our bounds for average treatment effects are affected by long tails in the distribution of
the outcome variable. Relatedly, it allows us to illustrate the usefulness of looking at quantile
treatment effects, as these are rather insensitive to long tails. We present results for an edge
kernel (Cheng, Fan, and Marron, 1997) and a bandwidth of 30 days around the cutoff.22 For
bounds in the Fuzzy RD case that involve numerical optimization, we use a grid search to
look for the infimum and supremum using 51 values for t ∈ [0, 1] and λ ∈ [0, 1]. Confidence
intervals are based on 500 bootstrap samples.23
    Panel A reports estimates of key inputs for our bounds. The density is estimated to
increase by 6.5% at the cutoff (τ ), implying that always-assigned units account for 6.5%
of observations just to the right of the cutoff, and UI takeup is estimated to increase by
71%-points at the cutoff. Note that the value of τ appears well-separated from zero, so that
the safeguards that ensure uniform validity of the confidence intervals for our bounds in case
of small and imprecisely estimated values of τ are not of any practical importance here.
    Panels B and C then report results from two types of exercises. First, we consider a Sharp
RD design (SRD), in which UI eligibility is defined as the treatment (panel B). The causal
effect on the outcome can be interpreted as an intention-to-treat (ITT) parameter in this case.
Second, we consider the Fuzzy RD design (FRD) with UI takeup as the treatment (panel C).
    Naive RD estimates that assume no manipulation yield an average increase in non-formal-
employment duration from UI eligibility (SRD) of 29.4 and 61.9 days for censoring points of
6 and 24 months, respectively. The corresponding figures are 41.6 and 87.7 days for the effect
of UI takeup (FRD). Naive treatment effects at the median are larger, at 86 days (SRD) and
99 days (FRD; outcome censored at 24 months). The median worker is always reemployed
within a year, and is thus more likely to respond to UI given the short potential duration.
    The above estimates may confound treatment effects and selection bias. Table 2 therefore
provides estimates of our bounds for the treatment effects. A few points are useful to
highlight for the behavior of our bounds in this application. First, the bounds for the average
treatment effects among potentially-assigned units (Γ− ) are relatively tight for the non-formal-
employment duration censored at 6 months after layoff. The lower bounds, in particular,
are close to the naive RD estimates, with point estimates of 26.4 days (SRD) and 35.4 days
(FRD). Second, the bounds for the average treatment effects become wider on both sides of
  22
     We do not have theoretical results on the optimal bandwidth for the estimation of our bounds. Our
estimates are similar if we use bandwidths of 10 or 50 days around the cutoff (available upon request).
  23
     Due to the censoring of the outcome variable, we use identification results for non-continuously distributed
outcomes described in the appendix.


                                                       36
the naive estimates when we consider higher censoring points. This difference comes from the
fact that the distribution of the outcome becomes more dispersed and has less probability
mass at the censoring point when we increase the censoring threshold. Third, bounds for
quantile treatment effects, which are less sensitive to tails of the outcome distribution, can be
tighter than bounds on average treatment effects in these cases. When we censor the outcome
at 24 months, we obtain bounds for the average treatment effect between 42.9 and 110 days,
but between 67 and 120 days for the treatment effect at the median (FRD). Bounds are even
tighter at other percentiles of the distribution (see Appendix); for instance they are between
87 and 114 days at the 30th percentile. Fourth, estimates that use behavioral assumptions to
tighten our Fuzzy RD bounds are often similar to estimates for the standard bounds in our
application. Yet, assuming that all always-assigned units take up the treatment (refinement
from Corollary 2) closes half of the gap between our lower bound and the naive RD estimate
when we censor the outcome at 6 months after layoff. Fifth, estimates that use covariates
(here, a dummy for a replacement rate above/below the median) to tighten our Fuzzy RD
bounds have no meaningful identifying power.24 Sixth, and lastly, bounds for the average
treatment effect among units just to the right of the cutoff (Γ+ ) are very similar to bounds
for the potentially-assigned units. This is partly because the distributions of our outcome
variables have a lot of probability mass at the extreme values of their support.
    Finally, we present the results of two additional exercises. First, we illustrate the
alternative strategy for inference that we recommend when researchers have strong beliefs
that manipulation is unlikely in their setting. After all, it is not obvious from Figure 6.2 that
there is manipulation in our data. Figure 6.3 displays point estimates and confidence intervals
for our bounds in the Fuzzy RD case for various fixed levels of the extent of manipulation
(hypothetical values of τ ). Panel A shows that inference on the average treatment effect can
be quite sensitive to the extent of manipulation. The width of the confidence intervals doubles
when we assume a small degree of manipulation (τ = .025) rather than no manipulation. This
illustrates the importance of taking into account the possibility of manipulation even when
the McCrary (2008) test fails to reject the null hypothesis of no manipulation. The width of
the confidence intervals grows quickly with larger degrees of manipulation. Panel B shows
that inference on quantile treatment effects is less sensitive to the extent of manipulation;
inference may remain meaningful in this case, even for large degrees of manipulation. This
illustrates again the usefulness of looking at quantile treatment effects.
  24
    Bounds that use covariates are sometimes even wider than standard bounds. Despite our identification
results, nothing guarantees that the bounds will actually be tighter in finite samples. In particular, we split
the sample in two when estimating effects for the two categories, leading to less precise estimates.



                                                      37
                               Table 2: Estimated treatment effects of UI on non-formal-employment duration

                                                                         Duration without a formal job censored at:
                                                               6 months                 24 months                   24 months
                                                             Average effect            Average effect         Effect at the median
                                                         Estimate     95% CI       Estimate        95% CI Estimate           95% CI

     A. Basic Inputs
     Share of always-assigned workers                      0.065      [0.040;0.087]      0.065       [0.040;0.087]    0.065     [0.040;0.087]
     Increase in UI takeup at the cutoff                   0.706      [0.698;0.713]      0.706       [0.698;0.713]    0.706     [0.698;0.713]

     B. ITT/SRD estimates
     Ignoring manipulation                                 29.4        [27.6;31.0]       61.9         [55.3;67.5]       86       [80.9;91.1]
     Bounds for Γ−                                      [26.4;38.8]    [24.2;42.6]     [31;81.2]      [16.8;90.7]     [75;99]   [67.7;106.8]




38
     Bounds for Γ− using covariates                     [26.4;38.7]    [24.0;42.9]     [31;81.1]      [15.4;91.4]     [75;99]   [66.7;107.0]
     Bounds for Γ+                                      [24.7;36.5]    [22.2;39.5]     [29;76.2]      [15.1;83.9]    [75;101]   [65.1;108.7]

     B. LATE/FRD estimates
     Ignoring manipulation                                 41.6        [39.4;43.7]        87.7        [78.5;95.5]       99      [91.0;107.0]
     Bounds for Γ−                                      [35.4;51.7]    [32.6;55.7]    [42.9;110.0]   [23.3;121.7]    [67;120]   [52.4;131.2]
     Bounds for Γ− : Refinement from Th. 3              [37.7;50.0]    [34.7;53.3]    [43.2;110.0]   [23.3;121.7]    [76;120]   [60.6;131.2]
     Bounds for Γ− : Refinement from Th. 4              [38.5;48.2]    [35.6;51.0]    [45.1;110.0]   [24.9;121.7]    [77;120]   [66.2;131.2]
     Bounds for Γ− using covariates                     [35.7;51.7]    [32.7;56.1]    [41.9;109.7]   [20.3;122.3]    [65;120]   [49.4;132.5]
     Bounds for Γ+                                      [34.9;51.9]    [31.5;56.0]    [40.3;110.0]   [20.6;121.8]    [67;120]   [51.3;131.6]
     Bounds for Γ+ : Refinement from Cor. 6             [34.9;51.6]    [31.5;55.8]    [41.0;107.8]   [21.3;118.6]    [68;119]   [52.9;131.5]
     Notes: Total number of observations within our bandwidth of 30 days around the cutoff: 102,791 displaced formal workers. Confidence
     intervals have nominal level of 95% and are based on 500 bootstrap samples. Bounds that use covariates only use a dummy variable for
     having a wage at layoff above/below the median.
                                                 A. Average Treatment Effect (FRD)                                                                               B. Median Treatment Effect (FRD)
                   50 100 150 200       (Fixed-manipulation inference, outcome censored at 24 months)                                                   (Fixed-manipulation inference, outcome censored at 24 months)




                                                                                                                                   50 100 150 200
        Average treatment effect




                                                                                                                         Median treatment effect
             0




                                                                                                                             0
  -100 -50




                                                                                                                  -100 -50
                                    0      .025   .05 .065          .1                                  .2                                          0      .025   .05 .065          .1                                  .2
                                             Hypothetical share of always-assigned workers                                                                   Hypothetical share of always-assigned workers



                                                  Figure 6.3: Fixed-manipulation inference for our empirical application

The figure displays point estimates and confidence intervals for our bounds for fixed levels of the degree of
manipulation. We consider LATE/FRD estimates (standard bounds) for the average treatment effect and the
quantile treatment effect at the 50th percentile for the outcome censored at 24 months. The solid vertical
line (resp. dashed vertical lines) corresponds to our point estimate (resp. confidence interval) for the extent
of manipulation (see Table 2).


    Second, we estimate the characteristics of potentially-assigned and always-assigned workers,
which could be useful for policies aimed at mitigating manipulation in the timing of layoff.
Results are in the Appendix. We find significant evidence of selection at the cutoff in terms
of wage and thus replacement rate, and sector of activity. Always-assigned workers earned on
average .24 log point less, and were 30%-points less likely to come from the service sector
than potentially-assigned workers. The large difference in wages and thus replacement rates
is the reason why we used replacement rate as a covariate to refine our bounds in Table 2.
    In sum, we find significant evidence of manipulation and selection at the cutoff, and our
bounds imply that the magnitude of naive RD estimates may be heavily affected by selection.
Nevertheless, we can still draw useful conclusions from this empirical exercise. For instance,
we estimate a lower bound for the effect of UI takeup on the duration covered by UI (i.e. the
outcome censored at 6 months) to be around 35.4 days. This corresponds to an increase of
at least 35.4/(5 · 30) = .236 month per month of potential UI duration (given a maximum
potential UI duration of 5 months). In comparison, Gerard and Gonzaga (2016) find an
increase of only .126 month in the covered UI duration per additional month of potential UI
duration among UI takers. Behavioral responses to UI benefits are thus relatively large in
our setting, which is consistent with the composition of our sample (high attachment to the
formal labor force, high turnover rate, and high ability to find a new formal job rapidly).




                                                                                                             39
                                        7. Conclusions
In this paper, we propose a partial identification approach to deal with the issue of potentially
manipulated running variables in RD designs. We show that while the data are unable to
uniquely pin down treatment effects if a running variable is subject to manipulation, they
are generally still informative in the sense that they imply bounds on the value of causal
parameters in both sharp and fuzzy RD designs. Our main contribution is to derive and
explicitly characterize these bounds. We also propose methods to estimate our bounds in
practice, and discuss how to construct confidence intervals. The approach is illustrated with
an application to the Brazilian unemployment insurance (UI) system. We recommend the
use of our approach in applications irrespective of the outcome of McCrary’s (2008) test for
manipulation.

                                           A. Proofs
A.1. Proof of Lemma 1. Since the density of the running variable is continuous around
the cutoff among potentially-assigned units by Assumption 2, we have that fX|M =0 (c− ) =
fX|M =0 (c+ ), and therefore fX (c+ ) = (1 − P (M = 1)) fX|M =0 (c− ) + P (M = 1) fX|M =1 (c+ ) .
Since there are no always-assigned units below the cutoff by Assumption 3, we have
fX|M =1 (x) = 0 for x < c, and thus fX (c− ) = (1 − P (M = 1)) fX|M =0 (c− ). Hence (fX (c+ ) −
fX (c− ))/fX (c+ ) = fX|M =1 (c+ )P(M = 1)/fX (c+ ) = τ , where the last equality follows from
Bayes’ Theorem.

A.2. Proof of Theorem 1. The result is a minor variation of results in Horowitz and Manski
(1995) and Lee (2009).

A.3. Proof of Theorem 2. It follows from the arguments presented in the main body of
the paper that the bounds on Γ− given knowledge (τ1 , τ0 ), formally stated in equation (3.8),
are valid and sharp. That is, any value of Γ− outside of these bounds is clearly incompatible
with the distribution of (Y, D, X); and every value within the bounds is feasible, because the
main body of the paper explicitly describes distributions of potential outcomes for the six
types of units listed in Table 1 (again, given knowledge (τ1 , τ0 )). Moreover, it is clear that
any value of (τ1 , τ0 ) ∈
                        / T is incompatible with the distribution of observable quantities. It
thus remains to be shown that any point (τ1 , τ0 ) ∈ T is compatible with our model and the
observed joint distribution of (Y, D, X).
    Note that it suffices to consider the latter distribution for X ∈ (c − ǫ, c + ǫ) for some small
ǫ > 0, as our model has no implications for the distribution of observables outside of that
range. Let (Ỹ (1), Ỹ (0), D̃+ , D̃− , M̃ , X̃) be a random vector taking values on the support of
(Y (1), Y (0), D+ , D− , M, X), and define D̃ and Ỹ analogous to D and Y in our Section 2.1.

                                                40
For x ∈ (c − ǫ, c + ǫ), let
                                                         
                                                         
                                                         1 − fX (c− )/fX (x)           if x ≥ c
          fX̃ (x) = fX (x) and P(M̃ = 1|X̃ = x) =
                                                         
                                                         0                             if x < c.

Moreover, let
                                            
                                            
                                            P(D = 1|X = x) ·         1−τ1
                                                                              − P(D = 1|X = c− )
                                            
                                                                     1−τ
                                            
                                            
                                            
                                            
                                               if x ≥ c,
   P(D̃− = 0, D̃+ = 1|X̃ = x, M̃ = 0) = 
                                        
                                        P(D = 1|X = c+ ) ·            1−τ1
                                                                                  − P(D = 1|X = x)
                                        
                                                                      1−τ
                                            
                                            
                                            
                                               if x < c,
                                            
                                            
                                            P(D = 1|X = c− )          if x ≥ c,
   P(D̃− = 1, D̃+ = 1|X̃ = x, M̃ = 0) =
                                            
                                            P(D = 1|X = x)            if x < c,
   P(D̃− = 0, D̃+ = 0|X̃ = x, M̃ = 0) = 1 − P(D̃− = 0, D̃+ = 1|X̃ = x, M̃ = 0)
                                               − P(D̃− = 1, D̃+ = 1|X̃ = x, M̃ = 0),
   P(D̃− = 1, D̃+ = 0|X̃ = x, M̃ = 0) = 0,

and
                                               
                                               
                                               P(D = 1|X = x) ·        τ1
           −        +                                                   τ
                                                                              − h(x)       if x ≥ c,
      P(D̃ = 0, D̃ = 1|X̃ = x, M̃ = 1) =
                                               
                                               P(D = 1|X = c+ ) ·           τ1
                                                                             τ
                                                                                  − h(c+ ) if x < c,
                                               
                                               
                                               h(x)  if x ≥ c,
      P(D̃− = 1, D̃+ = 1|X̃ = x, M̃ = 1) =
                                               
                                               h(c+ )    if x < c,
      P(D̃− = 0, D̃+ = 0|X̃ = x, M̃ = 1) = 1 − P(D̃− = 0, D̃+ = 1|X̃ = x, M̃ = 1),
                                               − P(D̃− = 1, D̃+ = 1|X̃ = x, M̃ = 1),
      P(D̃− = 1, D̃+ = 0|X̃ = x, M̃ = 1) = 0,

where h(·) is an arbitrary continuous function satisfying that 0 ≤ h(x) ≤ P(D = 1|X =
x) · τ1 /τ . With these choices, the implied distribution of (D̃, X̃)|X̃ ∈ (c − ǫ, c + ǫ) is the same
as that of (D, X)|X ∈ (c − ǫ, c + ǫ) for every (τ1 , τ0 ) ∈ T . It thus remains to be shown that
one can construct a distribution of (Ỹ (1), Ỹ (0)) given (D̃+ , D̃− , X̃, M̃ ) that is compatible
with our assumptions, and such that the distribution of Ỹ given (D̃, X̃) for X̃ ∈ (c − ǫ, c + ǫ)
is the same as the distribution of Y given (D, X) for X ∈ (c − ǫ, c + ǫ) for every (τ1 , τ0 ) ∈ T .
But this is possible by setting (Ỹ (1), Ỹ (0)) as independent given (D̃+ , D̃− , X̃, M̃ ), and then
assigning one of the respective extreme distributions derived in the main body of the text to

                                                 41
the respective marginals. This completes our proof.


              B. Bounds for Non-Continuously Distributed Outcomes
Theorem 1 and 2 are stated for the case in which the outcome variable is continuously
distributed. This is for notational convenience only, and our results immediately generalize
to the case of a discrete outcome variable, which occurs frequently in empirical applications.
Suppose that supp(Y ) is a finite set. Then in the case of a Sharp RD design our sharp upper
and lower bounds on FY (1)|X=c,C0 are
                                                                                   î                     ï
         U
        F1,SRD (y) = (1 − θU )FY |X=c+ ,Y >QY |X=c+ (τ ) (y) + θU I y ≥ QY |X=c+ (τ )                         and
                                                                                       î                       ï
         L
        F1,SRD (y) = (1 − θL )FY |X=c+ ,Y <QY |X=c+ (1−τ ) (y) + θL I y ≥ QY |X=c+ (1 − τ ) ,

where
        P(Y ≥ QY |X=c+ (1 − τ )|X = c+ ) − τ                                       P(Y ≤ QY |X=c+ (τ )|X = c+ ) − τ
 θL =                                                               and θU =                                        .
                      1−τ                                                                      1−τ
The following Corollary uses these bounds to obtain explicit sharp bounds on the local average
treatment effect Γ− .

Corollary 8. Suppose that the assumptions of Theorem 1 hold, and that supp(Y ) is a finite
set. Then sharp lower and upper bounds on Γ− are given by

           ΓL−,SRD = (1 − θL )E(Y |X = c+ , Y < QY |X (1 − τ |c+ )) + θL QY |X (1 − τ |c+ )
                         − E(Y |X = c− ) and
           ΓU−,SRD = (1 − θU )E(Y |X = c+ , Y > QY |X (τ |c+ )) + θU QY |X (τ |c+ )
                         − E(Y |X = c− ),

respectively.

   In a Fuzzy RD design, we modify the expressions for the sharp upper and lower bounds
on FY (1)|X=c,C0 and FY (0)|X=c,N0 for known values of τ1 and τ0 as follows:
                                                                                    ;       3            4<
       U                                                    1          2 (y) + θ U I y ≥ Q        τ1
      F1,F RD (y, τ1 , τ0 )   = (1 −   θ1U )G                    τ1             1         G                    and
                                              Y |Y >Q   G       1−κ1                            1 − κ1
                                                                                        ;      3               4<
       L                                                    1              2 (y) + θ L I y ≥ Q         τ1
      F1,F RD (y, τ1 , τ0 )   = (1 −   θ1L )G                      τ                1         G 1−                  ,
                                              Y |Y <Q   G
                                                                     1
                                                                1− 1−κ
                                                                       1
                                                                                                     1 − κ1




                                                                  42
where
                      1                     1           22                                1             1                 22
                                              τ1                    τ1                                              τ1              τ1
                  PG Y ≤ QG                 1−κ1
                                                              −    1−κ1
                                                                                    PG Y ≥ QG 1 −                  1−κ1
                                                                                                                               −   1−κ1
          θ1U =                              τ1                           θ1L =                               τ1                          .
                                 1−         1−κ1
                                                                                                       1−    1−κ1

The modified expressions for bounds on FY (0)|X=c,N0 are given by
                                        Ú   y
          FYU(0)|X=c,N0 (y)     =                   s(t, τ0 )I {t ≤ qU (τ0 )} dt + θ0U I {y > qU (τ0 )}                        and
                                         −∞
                                        Ú y
          FYL(0)|X=c,N0 (y) =                       s(t, τ0 )I {t ≥ qL (τ0 )} dt + θ0L I {y > qL (τ0 )} ,
                                        −∞

where
                                                        Ú   qU (τ0 )
                               θ0U      =1−                            s(t, τ0 )I {t ≤ qU (τ0 )} dt,
                                                        −∞
                                                        Ú∞
                                θ0L = 1 −                          s(t, τ0 )I {t ≥ qL (τ0 )} dt,
                                                        qL (τ0 )
                                                                                Ú     ∞
                          qL (τ0 ) = inf{y ∈ supp(Y ) :                                   s(t, τ0 )dt ≤ 1}, and
                                                                                  y
                                                                                  Ú   y
                          qU (τ0 ) = sup{y ∈ supp(Y ) :                                    s(t, τ0 )dt ≤ 1}.
                                                                                    −∞

We then obtain the following expressions for sharp bounds on the local average treatment
effect Γ− given knowledge of τ1 and τ0 :
                                                    Ú                                          Ú
                  ΓU−,F RD (τ1 , τ0 ) ≡                    U
                                                        ydF1,F RD (y, τ1 , τ0 ) −
                                                                                                      L
                                                                                                   ydF0,F RD (y, τ1 , τ0 ),
                                                    Ú                                          Ú
                  ΓU−,F RD (τ1 , τ0 )           ≡          L
                                                        ydF1,F RD (y, τ1 , τ0 )            −          U
                                                                                                   ydF0,F RD (y, τ1 , τ0 ).


The following Corollary finally states the sharp bounds on Γ− given that the values of τ1 and
τ0 are only partially identified.

Corollary 9. Suppose that the assumptions of Theorem 2 hold, and that supp(Y ) is a finite
set. Then sharp lower and upper bounds on Γ− are given by

           ΓL−,F RD =        inf        ΓL−,F RD (t1 , t0 ) and ΓU−,F RD =                              sup ΓU−,F RD (t1 , t0 ),
                          (t1 ,t0 )∈T                                                                (t1 ,t0 )∈T


respectively.


                                   C. Additional Tables and Graphs
We present here some supporting graphs. Figure C.4 displays the distribution of our outcome
variable (duration without a formal job, censored at two years after layoff) on the left and on
the right of the cutoff (30-day window around the cutoff). Figure C.5 displays the distribution


                                                                           43
of our outcome variable on the right of the cutoff for workers with wages at layoff above/below
the median (and thus replacement rates below/above the median). Figure C.6 displays the
full schedule of the UI benefit level, which is a function of a beneficiary’s average monthly
wage in the three years prior to her layoff. Figure C.7 displays the mean of different covariates
on each side of the cutoff by day between the layoff and eligibility dates.

                                                      Left of the eligibility cutoff                                                                 Right of the eligibility cutoff
                       30




                                                                                                                        30
                                 25




                                                                                                                                  25
          Percent of observations




                                                                                                           Percent of observations
                          20




                                                                                                                           20
                    15




                                                                                                                     15
             10




                                                                                                              10
                       5




                                                                                                                        5
                       0




                                                                                                                        0
                                       0 50 100 150 200 250 300 350 400 450 500 550 600 650 700 750                                    0 50 100 150 200 250 300 350 400 450 500 550 600 650 700 750
                                        Non-formal-employment duration (censored at 24 months)                                          Non-formal-employment duration (censored at 24 months)




                                      Figure C.4: Distribution of our outcome variable on each side of the cutoff

The figure displays the distribution of our outcome variable (duration without a formal job, censored at two
years after layoff) on the left and on the right of the cutoff (30-day window on each side of the cutoff). The
figure is based on a sample of 102,791 displaced formal workers.




                                                                                                      44
                                                   Right of the eligibility cutoff                                                                                                                                     Right of the eligibility cutoff
                                                  (wage at layoff above the median)                                                                                                                                   (wage at layoff below the median)
                      30




                                                                                                                                                                                         30
                                25




                                                                                                                                                                                                   25
          Percent of observations




                                                                                                                                                                             Percent of observations
                         20




                                                                                                                                                                                            20
                    15




                                                                                                                                                                                       15
             10




                                                                                                                                                                                10
                      5




                                                                                                                                                                                         5
                      0




                                                                                                                                                                                         0
                                     0 50 100 150 200 250 300 350 400 450 500 550 600 650 700 750                                                                                                       0 50 100 150 200 250 300 350 400 450 500 550 600 650 700 750
                                      Non-formal-employment duration (censored at 24 months)                                                                                                             Non-formal-employment duration (censored at 24 months)




Figure C.5: Distribution of our outcome variable on the right side of the cutoff by wage at layoff

The figure displays the distribution of our outcome variable (duration without a formal job, censored at two
years after layoff) on the right of the cutoff (30-day window on each side of the cutoff) for workers with wages
at layoff above/below the median (and thus replacement rates below/above the median). The figure is based
on a sample of 102,791 displaced formal workers.
                                                                                                    2
                                                                                                    1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9
                                                                 Benefit amount (in minimum wage)
                                                                                                    1




                                                                                                                                          1    1.5    2    2.5    3    3.5                       4        4.5     5     5.5     6
                                                                                                                                          Average wage in the 3 months prior to layoff (in minimum wage)




                                                                                Figure C.6: Monthly UI benefit amount

The figure displays the relationship between a UI beneficiary’s average monthly wage in the three months
prior to her layoff and her monthly UI benefit level. All monetary values are indexed to the federal minimum
wage, which changes every year. The replacement rate is 100% at the bottom of the wage distribution as the
minimum benefit level is equal to one minimum wage. The graph displays a slope of 0% until 125% of the
minimum wage, then of 80% until 165% of the minimum wage, and finally of 50% until 275% of the minimum
wage. The maximum benefit level is equal to 187% of the minimum wage.




                                                                                                                                                                      45
                               Table 3: Quantile treatment effects of UI on non-formal-employment duration

                                                                      Duration without a formal job censored at 24 months
                                                                Percentile 10%          Percentile 30%            Percentile 50%
                                                            Estimate      95% CI    Estimate      95% CI     Estimate       95% CI

     A. Basic Inputs
     Share of always-assigned workers                         0.065     [0.04;0.087]     0.065    [0.040;0.087]     0.065    [0.040;0.087]
     Increase in UI takeup at the cutoff                      0.706    [0.698;0.713]     0.706    [0.698;0.713]     0.706    [0.698;0.713]

     B. ITT/SRD estimates
     Ignoring manipulation                                      10       [7.6;12.4]       74        [69.4;78.7]      86        [80.9;91.1]
     Bounds for Ψ− (u)                                        [8;35]     [5.6;47.1]     [64;95]    [57.4;102.6]    [75;99]    [67.7;106.8]




46
     Bounds for Ψ− (u) using covariates                       [8;35]     [5.5;48.2]     [64;95]    [56.3;102.6]    [75;99]    [66.7;107.0]
     Bounds for Ψ+ (u)                                        [9;17]     [6.7;19.1]     [69;87]     [64.4;94.2]   [75;101]    [65.1;108.7]

     B. LATE/FRD estimates
     Ignoring manipulation                                     90        [86.3;93.7]      96       [91.0;101.0]      99       [91.0;107.0]
     Bounds for Ψ− (u)                                      [84;130]    [76.4;149.1]   [87;114]    [81.8;121.9]   [67;120]    [52.4;131.2]
     Bounds for Ψ− (u): Refinement from Th. 3               [84;121]    [77.4;130.8]   [87;111]    [81.8;118.8]   [76;120]    [60.6;131.2]
     Bounds for Ψ− (u): Refinement from Th. 4               [84;121]    [77.6;130.8]   [88;111]    [82.5;117.8]   [77;120]    [66.2;131.2]
     Bounds for Ψ− (u) using covariates                     [83;130]    [75.1;148.8]   [87;114]    [81.1;122.4]   [65;120]    [49.4;132.5]
     Bounds for Ψ+ (u)                                      [84;131]    [76.3;151.3]   [87;114]    [81.6;121.9]   [67;120]    [51.3;131.6]
     Bounds for Ψ+ (u): Refinement from Cor. 6              [85;121]    [77.4;126.8]   [89;114]    [83.6;121.8]   [68;119]    [52.9;131.5]
     Notes: Total number of observations within our bandwidth of 30 days around the cutoff: 102,791 displaced formal workers. Confidence
     intervals have nominal level of 95% and are based on 500 bootstrap samples. Bounds that use covariates only use a dummy variable for
     having a wage at layoff above/below the median.
              Table 4: Characteristics of always- and potentially-assigned workers

                                       Difference at       Potentially-              Always-
                                        the cutoff          assigned                 assigned

Share male                                   -0.0031           0.714                  0.665
                                       [-0.0168;0.0105]    [0.704;0.724]         [0.439;0.892]
Average age                                  -0.0729          32.475                31.345
                                       [-0.3091;0.1633]   [32.304;32.645]      [27.627;35.063]
Average years of education                    0.0011           9.104                  9.121
                                       [-0.0803;0.0825]    [9.049;9.160]        [7.836;10.406]
Average tenure                                0.0103           8.802                  8.961
                                       [-0.0418;0.0623]    [8.771;8.833]         [8.100;9.821]
Average log wage                              -0.016           6.704                  6.456
                                      [-0.0308;-0.0012]    [6.693;6.716]         [6.208;6.704]
Average replacement rate                      0.0051           0.720                  0.800
                                        [0.0005;0.0098]    [0.717;0.724]         [0.722;0.878]
Share from commercial sector                  0.0071           0.355                  0.465
                                         [-0.0059;0.02]    [0.346;0.365]         [0.264;0.665]
Share from construction sector                0.0073           0.106                  0.218
                                       [-0.0015;0.0161]    [0.099;0.112]         [0.079;0.358]
Share from industrial sector                  0.0061           0.225                  0.319
                                        [-0.006;0.0182]    [0.216;0.234]         [0.131;0.507]
Share from service sector                    -0.0204           0.314                 -0.002
                                      [-0.0332;-0.0077]    [0.305;0.324]        [-0.201;0.197]
Share from small firm                        0.0083            0.367                  0.496
  (<10 employees)                      [-0.0057;0.0224]    [0.357;0.377]         [0.268;0.730]
Notes: Total number of observations within our bandwidth of 30 days around the cutoff: 102,791
displaced formal workers. Numbers in square brackets are 95% confidence intervals calculated by
adding ±1.96×standard error to the respective point estimate,where standard errors are calculated
via the bootstrap with 500 replications.




                                              47
                                                                     Share male                                                                                                     Age                                                                                         Years of education




                                                                                                                                                                                                                                         9.3
                                                                                                                                  32.8
                      .74




                                                                                                                                                                                                                                            9.2
                                                                                                                             32.6




                                                                                                                                                                                                                           Years of education
          .72




                                                                                                                Age (in years)
  Share male




                                                                                                                                                                                                                                  9.1
                                                                                                                   32.4
                      .7




                                                                                                                                  32.2




                                                                                                                                                                                                                          9              8.9
                      .68




                                                                                                                                  32
                                           -50                            0                                50                                        -50                            0                                50                                   -50                            0                                50
                                                 Difference in days between layoff and eligibility dates                                                   Difference in days between layoff and eligibility dates                                              Difference in days between layoff and eligibility dates


                                                               Tenure in the lost job                                                                                   Log wage in the lost job                                                                               B. Replacement rate




                                                                                                                                                                                                                                         .74
                                      10




                                                                                                                                              6.74
   Tenure in the lost job (in months)




                                                                                                                Log wage in the lost job (R$)
                              9.5




                                                                                                                                      6.72




                                                                                                                                                                                                                          Replacement rate
                                                                                                                                                                                                                                      .73
                                                                                                                             6.7
                     9




                                                                                                                                                                                                                           .72
                                                                                                                    6.68
         8.5




                                                                                                                                 6.66
  8




                                                                                                                                                                                                                                         .71
                                           -50                            0                                50                                        -50                            0                                50                                   -50                            0                                50
                                                 Difference in days between layoff and eligibility dates                                                   Difference in days between layoff and eligibility dates                                              Difference in days between layoff and eligibility dates


                                                         Share from construction sector                                                                              Share from industrial sector                                                                          Share from service sector
                      .13




                                                                                                                                             .26




                                                                                                                                                                                                                                                    .32
  Share from construction sector




                                                                                                                Share from industrial sector




                                                                                                                                                                                                                          Share from service sector
                         .12




                                                                                                                                      .25




                                                                                                                                                                                                                                              .31
                                                                                                                              .24




                                                                                                                                                                                                                                        .3
                .11




                                                                                                                                                                                                                                 .29
                                                                                                                       .23
        .1




                                                                                                                                                                                                                          .28
                                                                                                                .22
                      .09




                                                                                                                                                                                                                                         .27
                                                                                                                                  .21




                                           -50                            0                                50                                        -50                            0                                50                                   -50                            0                                50
                                                 Difference in days between layoff and eligibility dates                                                   Difference in days between layoff and eligibility dates                                              Difference in days between layoff and eligibility dates


                                                              Share from large firms                                                                                Share from medium-size firms                                                                             Share from small firms
                      .26




                                                                                                                                                                                                                                         .42
                                                                                                                                           .46
                                                                                                                Share from medium-size firms
                      .24




                                                                                                                                                                                                                                                 .4
                                                                                                                                                                                                                            Share from small firms
  Share from large firms




                                                                                                                                  .44




                                                                                                                                                                                                                                        .38
           .22




                                                                                                                           .42




                                                                                                                                                                                                                                .36
   .2




                                                                                                                   .4




                                                                                                                                                                                                                          .34
                      .18




                                                                                                                                  .38




                                                                                                                                                                                                                                         .32




                                           -50                            0                                50                                        -50                            0                                50                                   -50                            0                                50
                                                 Difference in days between layoff and eligibility dates                                                   Difference in days between layoff and eligibility dates                                              Difference in days between layoff and eligibility dates




Figure C.7: Graphical evidence for the characteristics of always-assigned units in our empirical
application

The figure displays the mean of different covariates on each side of the cutoff by day between the layoff
and eligibility dates, as well as local linear regressions on each side of the cutoff using an edge kernel and a
bandwidth of 30 days. The figure is based on a RD sample of 169,575 displaced formal workers.




                                                                                                                                                                                48
                                         References
Anderson, G., O. Linton, and Y.-J. Whang (2012): “Nonparametric estimation and inference
 about the overlap of two distributions,” Journal of Econometrics, 171(1), 1–23.

Anderson, M., and J. Magruder (2012): “Learning from the Crowd: Regression Discontinuity
 Estimates of the Effects of an Online Review Database,” Economic Journal, 122(563), 957–989.

Andrews, D. (2000): “Inconsistency of the bootstrap when a parameter is on the boundary of the
 parameter space,” Econometrica, 68(2), 399–405.

Andrews, D., and P. Barwick (2012): “Inference for parameters defined by moment inequalities:
 A recommended moment selection procedure,” Econometrica, 80(6), 2805–2826.

Andrews, D., and G. Soares (2010): “Inference for parameters defined by moment inequalities
 using generalized moment selection,” Econometrica, 78(1), 119–157.

Berger, R. (1982): “Multiparameter hypothesis testing and acceptance sampling,” Technometrics,
  24(4), 295–300.

Bertanha, M., and G. W. Imbens (2016): “External Validity in Fuzzy Regression Discontinuity
  Designs,” Working Paper.

Camacho, A., and E. Conover (2011): “Manipulation of Social Program Eligibility,” American
 Economic Journal: Economic Policy, 3(2), 41–65.

Card, D., R. Chetty, and A. Weber (2007): “Cash-on-Hand and Competing Models of
 Intertemporal Behavior: New Evidence from the Labor Market,” Quarterly Journal of Economics,
 122(4), 1511–1560.

Card, D., C. Dobkin, and N. Maestas (2009): “Does Medicare Save Lives?,” The Quarterly
 Journal of Economics, 124(2), 597–636.

Card, D., and L. Giuliano (2014): “Does Gifted Education Work? For Which Students?,”
 Working Paper.

Carvalho, C., C. Corbi, and R. Narita (2017): “Unintended consequences of unemployment
 insurance: Evidence from stricter eligibility criteria in Brazil,” Economic Letters.

Cattaneo, M. D., M. Jansson, and X. Ma (2017): “Simple Local Polynomial Density Estima-
  tors,” Working Paper.

Cheng, M.-Y. (1997): “A bandwidth selector for local linear density estimators,” Annals of
 Statistics, 25(3), 1001–1013.

Cheng, M.-Y., J. Fan, and J. Marron (1997): “On Automatic Boundary Corrections,” Annals
 of Statistics, 25, 1691–1708.

Chernozhukov, V., S. Lee, and A. Rosen (2013): “Intersection Bounds: estimation and
 inference,” Econometrica, 81(2), 667–737.

Dee, T. S., W. Dobbie, B. A. Jacob, and J. Rockoff (2016): “The causes and consequences
 of test score manipulation: Evidence from the new york regents examinations,” NBER Working
 Paper.

                                             49
Dong, Y. (2017): “Alternative Assumptions to Identify LATE in Fuzzy Regression Discontinuity
 Designs,” Working Paper.

Fan, J., and I. Gijbels (1996): Local Polynomial Modelling and Its Applications. Chapman &
  Hall, London.

Fan, J., Q. Yao, and H. Tong (1996): “Estimation of conditional densities and sensitivity
  measures in nonlinear dynamical systems,” Biometrika, 83(1), 189–206.

Feldstein, M. (1976): “Temporary Layoffs in the Theory of Unemployment,” Journal of Political
  Economy, 84, 937–958.

Frandsen, B. R., M. Frölich, and B. Melly (2012): “Quantile treatment effects in the
  regression discontinuity design,” Journal of Econometrics, 168(2), 382–395.

Gerard, F., and G. Gonzaga (2016): “Informal Labor and the Efficiency Cost of Social Programs:
 Evidence from the Brazilian Unemployment Insurance Program,” NBER Working Paper, 22608.

Hahn, J., P. Todd, and W. Van der Klaauw (2001): “Identification and Estimation of
 Treatment Effects with a Regression-Discontinuity Design,” Econometrica, 69(1), 201–209.

Hall, P., R. C. Wolff, and Q. Yao (1999): “Methods for estimating a conditional distribution
 function,” Journal of the American Statistical Association, 94(445), 154–163.

Hopenhayn, H., and J. P. Nicolini (2009): “Optimal Unemployment Insurance and Employment
 History,” Review of Economic Studies, 76, 1049–1070.

Horowitz, J. L., and C. F. Manski (1995): “Identification and robustness with contaminated
 and corrupted data,” Econometrica, 63(2), 281–302.

Imbens, G., and C. Manski (2004): “Confidence Intervals for Partially Identified Parameters,”
  Econometrica, 72(6), 1845–1857.

Jones, M. C. (1993): “Simple boundary correction for kernel density estimation,” Statistics and
  Computing, 3(3), 135–146.

Lee, D. (2009): “Training, Wages, and Sample Selection: Estimating Sharp Bounds on Treatment
  Effects,” Review of Economic Studies, 76(3), 1071–1102.

Lee, D. S. (2008): “Randomized experiments from non-random selection in US House elections,”
  Journal of Econometrics, 142(2), 675–697.

Lejeune, M., and P. Sarda (1992): “Smooth estimators of distribution and density functions,”
 Computational Statistics & Data Analysis, 14(4), 457–471.

Manski, C. (1990): “Nonparametric bounds on treatment effects,” American Economic Review,
 80(2), 319–323.

Masten, M. A., and A. Poirier (2017): “Inference on Breakdown Frontiers,” Working Paper.

McCrary, J. (2008): “Manipulation of the Running Variable in the Regression Discontinuity
 Design: A Density Test,” Journal of Econometrics, 142(2), 698–714.


                                              50
Rubin, D. (1974): “Estimating Causal Effects of Treatments in Randomized and Nonrandomized
 Studies,” Journal of Educational Psychology, 66(5), 688–701.

Sallee, J. (2011): “The Surprising Incidence of Tax Credits for the Toyota Prius,” American
  Economic Journal: Economic Policy, 3, 189–219.

Schmieder, J., T. von Wachter, and S. Bender (2012): “The Effects of Extended Unemploy-
  ment Insurance Over the Business Cycle: Evidence from Regression Discontinuity Estimates over
  Twenty Years,” Quarterly Journal of Economics, 127(2), 701–752.

Scott-Clayton, J. (2011): “On Money and Motivation: A Quasi-Experimental Analysis of
  Financial Incentives for College Achievement,” Journal of Human Resources, 46(3), 614–646.

Solis, A. (2017): “Credit Access and College Enrollment,” Journal of Political Economy, 125(2),
  562–622.

Stoye, J. (2009): “More on confidence intervals for partially identified parameters,” Econometrica,
  77(4), 1299–1315.

         (2010): “Partial identification of spread parameters,” Quantitative Economics, 1(2),
  323–357.

Urquiola, M., and E. Verhoogen (2009): “Class-Size Caps, Sorting, and the Regression
 Discontinuity Design,” American Economic Review, 99(1), 179–215.




                                                51
